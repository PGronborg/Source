Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.245784 * 100, metric = 24.07% * 100;
 Minibatch[ 101- 200]: loss = 0.989642 * 100, metric = 22.68% * 100;
 Minibatch[ 201- 300]: loss = 0.908177 * 100, metric = 22.07% * 100;
 Minibatch[ 301- 400]: loss = 0.914124 * 100, metric = 21.79% * 100;
 Minibatch[ 401- 500]: loss = 0.820775 * 100, metric = 19.29% * 100;
 Minibatch[ 501- 600]: loss = 0.802392 * 100, metric = 18.67% * 100;
 Minibatch[ 601- 700]: loss = 0.777106 * 100, metric = 17.46% * 100;
 Minibatch[ 701- 800]: loss = 0.732610 * 100, metric = 16.52% * 100;
 Minibatch[ 801- 900]: loss = 0.735491 * 100, metric = 16.78% * 100;
 Minibatch[ 901-1000]: loss = 0.740308 * 100, metric = 17.06% * 100;
 Minibatch[1001-1100]: loss = 0.731304 * 100, metric = 16.75% * 100;
 Minibatch[1101-1200]: loss = 0.715031 * 100, metric = 16.10% * 100;
 Minibatch[1201-1300]: loss = 0.711840 * 100, metric = 16.44% * 100;
 Minibatch[1301-1400]: loss = 0.681256 * 100, metric = 15.18% * 100;
 Minibatch[1401-1500]: loss = 0.705306 * 100, metric = 15.88% * 100;
 Minibatch[1501-1600]: loss = 0.685382 * 100, metric = 15.46% * 100;
 Minibatch[1601-1700]: loss = 0.665934 * 100, metric = 14.83% * 100;
 Minibatch[1701-1800]: loss = 0.670134 * 100, metric = 14.81% * 100;
 Minibatch[1801-1900]: loss = 0.665417 * 100, metric = 14.86% * 100;
 Minibatch[1901-2000]: loss = 0.645824 * 100, metric = 14.27% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.777192 * 2000, metric = 17.55% * 2000 652.754s (  3.1 samples/s);
Finished Evaluation [1]: Minibatch[1-1000]: metric = 31.71% * 1000;
0.8432145222127437
 Minibatch[   1- 100]: loss = 0.643149 * 100, metric = 14.25% * 100;
 Minibatch[ 101- 200]: loss = 0.656314 * 100, metric = 14.78% * 100;
 Minibatch[ 201- 300]: loss = 0.637146 * 100, metric = 13.80% * 100;
 Minibatch[ 301- 400]: loss = 0.646886 * 100, metric = 13.97% * 100;
 Minibatch[ 401- 500]: loss = 0.638357 * 100, metric = 14.22% * 100;
 Minibatch[ 501- 600]: loss = 0.645288 * 100, metric = 13.74% * 100;
 Minibatch[ 601- 700]: loss = 0.617168 * 100, metric = 13.40% * 100;
 Minibatch[ 701- 800]: loss = 0.632087 * 100, metric = 13.86% * 100;
 Minibatch[ 801- 900]: loss = 0.603506 * 100, metric = 12.93% * 100;
 Minibatch[ 901-1000]: loss = 0.594848 * 100, metric = 12.61% * 100;
 Minibatch[1001-1100]: loss = 0.618549 * 100, metric = 13.38% * 100;
 Minibatch[1101-1200]: loss = 0.601033 * 100, metric = 12.67% * 100;
 Minibatch[1201-1300]: loss = 0.594893 * 100, metric = 12.81% * 100;
 Minibatch[1301-1400]: loss = 0.611974 * 100, metric = 13.04% * 100;
 Minibatch[1401-1500]: loss = 0.578460 * 100, metric = 12.14% * 100;
 Minibatch[1501-1600]: loss = 0.577083 * 100, metric = 12.28% * 100;
 Minibatch[1601-1700]: loss = 0.594383 * 100, metric = 12.72% * 100;
 Minibatch[1701-1800]: loss = 0.600118 * 100, metric = 12.86% * 100;
 Minibatch[1801-1900]: loss = 0.600006 * 100, metric = 13.19% * 100;
 Minibatch[1901-2000]: loss = 0.558624 * 100, metric = 11.75% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.612494 * 2000, metric = 13.22% * 2000 586.152s (  3.4 samples/s);
Finished Evaluation [2]: Minibatch[1-1000]: metric = 18.78% * 1000;
0.6610279184728861
 Minibatch[   1- 100]: loss = 0.577544 * 100, metric = 12.31% * 100;
 Minibatch[ 101- 200]: loss = 0.585152 * 100, metric = 12.46% * 100;
 Minibatch[ 201- 300]: loss = 0.562186 * 100, metric = 11.85% * 100;
 Minibatch[ 301- 400]: loss = 0.572182 * 100, metric = 12.14% * 100;
 Minibatch[ 401- 500]: loss = 0.575788 * 100, metric = 12.19% * 100;
 Minibatch[ 501- 600]: loss = 0.581313 * 100, metric = 12.31% * 100;
 Minibatch[ 601- 700]: loss = 0.571188 * 100, metric = 12.10% * 100;
 Minibatch[ 701- 800]: loss = 0.551914 * 100, metric = 11.27% * 100;
 Minibatch[ 801- 900]: loss = 0.570105 * 100, metric = 11.92% * 100;
 Minibatch[ 901-1000]: loss = 0.544017 * 100, metric = 11.59% * 100;
 Minibatch[1001-1100]: loss = 0.566993 * 100, metric = 12.00% * 100;
 Minibatch[1101-1200]: loss = 0.549985 * 100, metric = 11.76% * 100;
 Minibatch[1201-1300]: loss = 0.553036 * 100, metric = 11.70% * 100;
 Minibatch[1301-1400]: loss = 0.556532 * 100, metric = 11.72% * 100;
 Minibatch[1401-1500]: loss = 0.551594 * 100, metric = 11.85% * 100;
 Minibatch[1501-1600]: loss = 0.550967 * 100, metric = 11.38% * 100;
 Minibatch[1601-1700]: loss = 0.542070 * 100, metric = 11.14% * 100;
 Minibatch[1701-1800]: loss = 0.561565 * 100, metric = 11.95% * 100;
 Minibatch[1801-1900]: loss = 0.545381 * 100, metric = 11.35% * 100;
 Minibatch[1901-2000]: loss = 0.540345 * 100, metric = 11.15% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.560493 * 2000, metric = 11.81% * 2000 577.213s (  3.5 samples/s);
Finished Evaluation [3]: Minibatch[1-1000]: metric = 17.32% * 1000;
0.6173649839162827
 Minibatch[   1- 100]: loss = 0.557243 * 100, metric = 11.22% * 100;
 Minibatch[ 101- 200]: loss = 0.517396 * 100, metric = 10.55% * 100;
 Minibatch[ 201- 300]: loss = 0.540189 * 100, metric = 11.18% * 100;
 Minibatch[ 301- 400]: loss = 0.512263 * 100, metric = 10.60% * 100;
 Minibatch[ 401- 500]: loss = 0.538366 * 100, metric = 11.20% * 100;
 Minibatch[ 501- 600]: loss = 0.507933 * 100, metric = 10.32% * 100;
 Minibatch[ 601- 700]: loss = 0.517564 * 100, metric = 10.44% * 100;
 Minibatch[ 701- 800]: loss = 0.527736 * 100, metric = 10.89% * 100;
 Minibatch[ 801- 900]: loss = 0.524392 * 100, metric = 10.91% * 100;
 Minibatch[ 901-1000]: loss = 0.528013 * 100, metric = 11.12% * 100;
 Minibatch[1001-1100]: loss = 0.540046 * 100, metric = 11.18% * 100;
 Minibatch[1101-1200]: loss = 0.509058 * 100, metric = 10.35% * 100;
 Minibatch[1201-1300]: loss = 0.529621 * 100, metric = 11.11% * 100;
 Minibatch[1301-1400]: loss = 0.539135 * 100, metric = 11.31% * 100;
 Minibatch[1401-1500]: loss = 0.536151 * 100, metric = 11.15% * 100;
 Minibatch[1501-1600]: loss = 0.508908 * 100, metric = 10.54% * 100;
 Minibatch[1601-1700]: loss = 0.532061 * 100, metric = 11.03% * 100;
 Minibatch[1701-1800]: loss = 0.527632 * 100, metric = 10.93% * 100;
 Minibatch[1801-1900]: loss = 0.518641 * 100, metric = 10.85% * 100;
 Minibatch[1901-2000]: loss = 0.506953 * 100, metric = 10.46% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.525965 * 2000, metric = 10.87% * 2000 576.005s (  3.5 samples/s);
Finished Evaluation [4]: Minibatch[1-1000]: metric = 19.81% * 1000;
 Minibatch[   1- 100]: loss = 0.525519 * 100, metric = 10.74% * 100;
 Minibatch[ 101- 200]: loss = 0.516738 * 100, metric = 10.68% * 100;
 Minibatch[ 201- 300]: loss = 0.511237 * 100, metric = 10.56% * 100;
 Minibatch[ 301- 400]: loss = 0.540865 * 100, metric = 11.39% * 100;
 Minibatch[ 401- 500]: loss = 0.497405 * 100, metric = 10.19% * 100;
 Minibatch[ 501- 600]: loss = 0.498247 * 100, metric = 9.90% * 100;
 Minibatch[ 601- 700]: loss = 0.506900 * 100, metric = 10.13% * 100;
 Minibatch[ 701- 800]: loss = 0.514103 * 100, metric = 10.80% * 100;
 Minibatch[ 801- 900]: loss = 0.502162 * 100, metric = 10.27% * 100;
 Minibatch[ 901-1000]: loss = 0.499962 * 100, metric = 10.40% * 100;
 Minibatch[1001-1100]: loss = 0.508606 * 100, metric = 10.30% * 100;
 Minibatch[1101-1200]: loss = 0.479037 * 100, metric = 9.56% * 100;
 Minibatch[1201-1300]: loss = 0.502007 * 100, metric = 10.03% * 100;
 Minibatch[1301-1400]: loss = 0.516758 * 100, metric = 10.59% * 100;
 Minibatch[1401-1500]: loss = 0.503353 * 100, metric = 10.33% * 100;
 Minibatch[1501-1600]: loss = 0.505276 * 100, metric = 10.47% * 100;
 Minibatch[1601-1700]: loss = 0.507219 * 100, metric = 10.47% * 100;
 Minibatch[1701-1800]: loss = 0.513478 * 100, metric = 10.50% * 100;
 Minibatch[1801-1900]: loss = 0.503242 * 100, metric = 10.23% * 100;
 Minibatch[1901-2000]: loss = 0.483292 * 100, metric = 9.61% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.506770 * 2000, metric = 10.36% * 2000 565.335s (  3.5 samples/s);
Finished Evaluation [5]: Minibatch[1-1000]: metric = 17.89% * 1000;
 Minibatch[   1- 100]: loss = 0.497635 * 100, metric = 10.39% * 100;
 Minibatch[ 101- 200]: loss = 0.481648 * 100, metric = 9.84% * 100;
 Minibatch[ 201- 300]: loss = 0.504213 * 100, metric = 10.41% * 100;
 Minibatch[ 301- 400]: loss = 0.490374 * 100, metric = 9.83% * 100;
 Minibatch[ 401- 500]: loss = 0.478537 * 100, metric = 9.79% * 100;
 Minibatch[ 501- 600]: loss = 0.488548 * 100, metric = 10.34% * 100;
 Minibatch[ 601- 700]: loss = 0.491669 * 100, metric = 10.22% * 100;
 Minibatch[ 701- 800]: loss = 0.496885 * 100, metric = 10.11% * 100;
 Minibatch[ 801- 900]: loss = 0.490331 * 100, metric = 10.15% * 100;
 Minibatch[ 901-1000]: loss = 0.477330 * 100, metric = 9.57% * 100;
 Minibatch[1001-1100]: loss = 0.479187 * 100, metric = 9.46% * 100;
 Minibatch[1101-1200]: loss = 0.492825 * 100, metric = 10.05% * 100;
 Minibatch[1201-1300]: loss = 0.502464 * 100, metric = 10.21% * 100;
 Minibatch[1301-1400]: loss = 0.482526 * 100, metric = 9.93% * 100;
 Minibatch[1401-1500]: loss = 0.489594 * 100, metric = 10.29% * 100;
 Minibatch[1501-1600]: loss = 0.471238 * 100, metric = 9.46% * 100;
 Minibatch[1601-1700]: loss = 0.477006 * 100, metric = 9.64% * 100;
 Minibatch[1701-1800]: loss = 0.472791 * 100, metric = 9.47% * 100;
 Minibatch[1801-1900]: loss = 0.480654 * 100, metric = 9.86% * 100;
 Minibatch[1901-2000]: loss = 0.468932 * 100, metric = 9.55% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.485719 * 2000, metric = 9.93% * 2000 573.888s (  3.5 samples/s);
Finished Evaluation [6]: Minibatch[1-1000]: metric = 19.18% * 1000;
 Minibatch[   1- 100]: loss = 0.468569 * 100, metric = 9.25% * 100;
 Minibatch[ 101- 200]: loss = 0.483114 * 100, metric = 9.66% * 100;
 Minibatch[ 201- 300]: loss = 0.475966 * 100, metric = 9.57% * 100;
 Minibatch[ 301- 400]: loss = 0.463111 * 100, metric = 9.06% * 100;
 Minibatch[ 401- 500]: loss = 0.478582 * 100, metric = 9.46% * 100;
 Minibatch[ 501- 600]: loss = 0.460387 * 100, metric = 9.11% * 100;
 Minibatch[ 601- 700]: loss = 0.473111 * 100, metric = 9.33% * 100;
 Minibatch[ 701- 800]: loss = 0.473008 * 100, metric = 9.14% * 100;
 Minibatch[ 801- 900]: loss = 0.481336 * 100, metric = 9.75% * 100;
 Minibatch[ 901-1000]: loss = 0.470137 * 100, metric = 9.58% * 100;
 Minibatch[1001-1100]: loss = 0.478983 * 100, metric = 9.51% * 100;
 Minibatch[1101-1200]: loss = 0.462533 * 100, metric = 9.17% * 100;
 Minibatch[1201-1300]: loss = 0.477321 * 100, metric = 9.87% * 100;
 Minibatch[1301-1400]: loss = 0.458596 * 100, metric = 8.96% * 100;
 Minibatch[1401-1500]: loss = 0.464157 * 100, metric = 9.33% * 100;
 Minibatch[1501-1600]: loss = 0.473566 * 100, metric = 9.69% * 100;
 Minibatch[1601-1700]: loss = 0.476962 * 100, metric = 9.69% * 100;
 Minibatch[1701-1800]: loss = 0.467392 * 100, metric = 9.23% * 100;
 Minibatch[1801-1900]: loss = 0.468247 * 100, metric = 9.52% * 100;
 Minibatch[1901-2000]: loss = 0.467799 * 100, metric = 9.67% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.471144 * 2000, metric = 9.43% * 2000 569.301s (  3.5 samples/s);
Finished Evaluation [7]: Minibatch[1-1000]: metric = 16.34% * 1000;
0.5825468419939279
 Minibatch[   1- 100]: loss = 0.482696 * 100, metric = 9.87% * 100;
 Minibatch[ 101- 200]: loss = 0.473062 * 100, metric = 9.55% * 100;
 Minibatch[ 201- 300]: loss = 0.454729 * 100, metric = 9.12% * 100;
 Minibatch[ 301- 400]: loss = 0.460778 * 100, metric = 9.52% * 100;
 Minibatch[ 401- 500]: loss = 0.479950 * 100, metric = 9.79% * 100;
 Minibatch[ 501- 600]: loss = 0.488489 * 100, metric = 10.15% * 100;
 Minibatch[ 601- 700]: loss = 0.457867 * 100, metric = 9.43% * 100;
 Minibatch[ 701- 800]: loss = 0.468494 * 100, metric = 9.54% * 100;
 Minibatch[ 801- 900]: loss = 0.449861 * 100, metric = 9.11% * 100;
 Minibatch[ 901-1000]: loss = 0.439962 * 100, metric = 8.76% * 100;
 Minibatch[1001-1100]: loss = 0.454081 * 100, metric = 9.22% * 100;
 Minibatch[1101-1200]: loss = 0.449509 * 100, metric = 9.04% * 100;
 Minibatch[1201-1300]: loss = 0.467147 * 100, metric = 9.53% * 100;
 Minibatch[1301-1400]: loss = 0.468213 * 100, metric = 9.75% * 100;
 Minibatch[1401-1500]: loss = 0.464330 * 100, metric = 9.39% * 100;
 Minibatch[1501-1600]: loss = 0.463069 * 100, metric = 9.45% * 100;
 Minibatch[1601-1700]: loss = 0.458524 * 100, metric = 9.28% * 100;
 Minibatch[1701-1800]: loss = 0.449938 * 100, metric = 8.74% * 100;
 Minibatch[1801-1900]: loss = 0.462427 * 100, metric = 9.27% * 100;
 Minibatch[1901-2000]: loss = 0.456924 * 100, metric = 9.16% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.462503 * 2000, metric = 9.38% * 2000 571.010s (  3.5 samples/s);
Finished Evaluation [8]: Minibatch[1-1000]: metric = 14.95% * 1000;
0.5437426479160785
 Minibatch[   1- 100]: loss = 0.439567 * 100, metric = 8.89% * 100;
 Minibatch[ 101- 200]: loss = 0.468393 * 100, metric = 9.47% * 100;
 Minibatch[ 201- 300]: loss = 0.459705 * 100, metric = 9.19% * 100;
 Minibatch[ 301- 400]: loss = 0.467790 * 100, metric = 9.39% * 100;
 Minibatch[ 401- 500]: loss = 0.454235 * 100, metric = 9.04% * 100;
 Minibatch[ 501- 600]: loss = 0.451706 * 100, metric = 9.19% * 100;
 Minibatch[ 601- 700]: loss = 0.449715 * 100, metric = 9.18% * 100;
 Minibatch[ 701- 800]: loss = 0.440818 * 100, metric = 9.00% * 100;
 Minibatch[ 801- 900]: loss = 0.435809 * 100, metric = 8.70% * 100;
 Minibatch[ 901-1000]: loss = 0.452334 * 100, metric = 9.12% * 100;
 Minibatch[1001-1100]: loss = 0.427663 * 100, metric = 8.51% * 100;
 Minibatch[1101-1200]: loss = 0.448759 * 100, metric = 8.84% * 100;
 Minibatch[1201-1300]: loss = 0.440010 * 100, metric = 8.97% * 100;
 Minibatch[1301-1400]: loss = 0.432648 * 100, metric = 8.46% * 100;
 Minibatch[1401-1500]: loss = 0.456089 * 100, metric = 9.34% * 100;
 Minibatch[1501-1600]: loss = 0.446445 * 100, metric = 8.88% * 100;
 Minibatch[1601-1700]: loss = 0.449648 * 100, metric = 9.03% * 100;
 Minibatch[1701-1800]: loss = 0.432236 * 100, metric = 8.68% * 100;
 Minibatch[1801-1900]: loss = 0.440130 * 100, metric = 8.74% * 100;
 Minibatch[1901-2000]: loss = 0.448684 * 100, metric = 8.91% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.447119 * 2000, metric = 8.98% * 2000 558.115s (  3.6 samples/s);
Finished Evaluation [9]: Minibatch[1-1000]: metric = 14.81% * 1000;
0.5366067038625478
 Minibatch[   1- 100]: loss = 0.464975 * 100, metric = 9.56% * 100;
 Minibatch[ 101- 200]: loss = 0.433667 * 100, metric = 8.64% * 100;
 Minibatch[ 201- 300]: loss = 0.447018 * 100, metric = 9.03% * 100;
 Minibatch[ 301- 400]: loss = 0.445887 * 100, metric = 8.74% * 100;
 Minibatch[ 401- 500]: loss = 0.456995 * 100, metric = 9.25% * 100;
 Minibatch[ 501- 600]: loss = 0.434826 * 100, metric = 8.73% * 100;
 Minibatch[ 601- 700]: loss = 0.434887 * 100, metric = 8.76% * 100;
 Minibatch[ 701- 800]: loss = 0.426995 * 100, metric = 8.38% * 100;
 Minibatch[ 801- 900]: loss = 0.444634 * 100, metric = 9.17% * 100;
 Minibatch[ 901-1000]: loss = 0.437762 * 100, metric = 8.77% * 100;
 Minibatch[1001-1100]: loss = 0.440604 * 100, metric = 8.88% * 100;
 Minibatch[1101-1200]: loss = 0.442352 * 100, metric = 8.88% * 100;
 Minibatch[1201-1300]: loss = 0.441251 * 100, metric = 8.87% * 100;
 Minibatch[1301-1400]: loss = 0.435192 * 100, metric = 8.69% * 100;
 Minibatch[1401-1500]: loss = 0.426530 * 100, metric = 8.61% * 100;
 Minibatch[1501-1600]: loss = 0.436461 * 100, metric = 8.81% * 100;
 Minibatch[1601-1700]: loss = 0.427078 * 100, metric = 8.38% * 100;
 Minibatch[1701-1800]: loss = 0.445997 * 100, metric = 9.01% * 100;
 Minibatch[1801-1900]: loss = 0.449219 * 100, metric = 9.13% * 100;
 Minibatch[1901-2000]: loss = 0.421762 * 100, metric = 8.22% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.439705 * 2000, metric = 8.83% * 2000 562.488s (  3.6 samples/s);
Finished Evaluation [10]: Minibatch[1-1000]: metric = 13.94% * 1000;
0.5165819894224405
 Minibatch[   1- 100]: loss = 0.416032 * 100, metric = 8.08% * 100;
 Minibatch[ 101- 200]: loss = 0.425862 * 100, metric = 8.50% * 100;
 Minibatch[ 201- 300]: loss = 0.437778 * 100, metric = 8.76% * 100;
 Minibatch[ 301- 400]: loss = 0.433650 * 100, metric = 8.41% * 100;
 Minibatch[ 401- 500]: loss = 0.420395 * 100, metric = 8.32% * 100;
 Minibatch[ 501- 600]: loss = 0.440737 * 100, metric = 8.85% * 100;
 Minibatch[ 601- 700]: loss = 0.423696 * 100, metric = 8.50% * 100;
 Minibatch[ 701- 800]: loss = 0.439097 * 100, metric = 8.80% * 100;
 Minibatch[ 801- 900]: loss = 0.434890 * 100, metric = 8.75% * 100;
 Minibatch[ 901-1000]: loss = 0.440700 * 100, metric = 8.64% * 100;
 Minibatch[1001-1100]: loss = 0.433056 * 100, metric = 8.64% * 100;
 Minibatch[1101-1200]: loss = 0.440781 * 100, metric = 8.87% * 100;
 Minibatch[1201-1300]: loss = 0.425313 * 100, metric = 8.40% * 100;
 Minibatch[1301-1400]: loss = 0.412100 * 100, metric = 8.00% * 100;
 Minibatch[1401-1500]: loss = 0.438620 * 100, metric = 8.82% * 100;
 Minibatch[1501-1600]: loss = 0.423802 * 100, metric = 8.45% * 100;
 Minibatch[1601-1700]: loss = 0.430613 * 100, metric = 8.71% * 100;
 Minibatch[1701-1800]: loss = 0.431979 * 100, metric = 8.63% * 100;
 Minibatch[1801-1900]: loss = 0.426188 * 100, metric = 8.51% * 100;
 Minibatch[1901-2000]: loss = 0.424440 * 100, metric = 8.41% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.429987 * 2000, metric = 8.55% * 2000 563.397s (  3.5 samples/s);
Finished Evaluation [11]: Minibatch[1-1000]: metric = 14.42% * 1000;
 Minibatch[   1- 100]: loss = 0.416329 * 100, metric = 8.19% * 100;
 Minibatch[ 101- 200]: loss = 0.427403 * 100, metric = 8.11% * 100;
 Minibatch[ 201- 300]: loss = 0.421010 * 100, metric = 8.68% * 100;
 Minibatch[ 301- 400]: loss = 0.446365 * 100, metric = 9.12% * 100;
 Minibatch[ 401- 500]: loss = 0.424438 * 100, metric = 8.30% * 100;
 Minibatch[ 501- 600]: loss = 0.412021 * 100, metric = 8.10% * 100;
 Minibatch[ 601- 700]: loss = 0.412198 * 100, metric = 8.29% * 100;
 Minibatch[ 701- 800]: loss = 0.428720 * 100, metric = 8.68% * 100;
 Minibatch[ 801- 900]: loss = 0.418602 * 100, metric = 8.14% * 100;
 Minibatch[ 901-1000]: loss = 0.426837 * 100, metric = 8.79% * 100;
 Minibatch[1001-1100]: loss = 0.430862 * 100, metric = 8.81% * 100;
 Minibatch[1101-1200]: loss = 0.432780 * 100, metric = 8.70% * 100;
 Minibatch[1201-1300]: loss = 0.431913 * 100, metric = 8.95% * 100;
 Minibatch[1301-1400]: loss = 0.410561 * 100, metric = 8.07% * 100;
 Minibatch[1401-1500]: loss = 0.427950 * 100, metric = 8.67% * 100;
 Minibatch[1501-1600]: loss = 0.401847 * 100, metric = 8.13% * 100;
 Minibatch[1601-1700]: loss = 0.425938 * 100, metric = 8.56% * 100;
 Minibatch[1701-1800]: loss = 0.413111 * 100, metric = 8.28% * 100;
 Minibatch[1801-1900]: loss = 0.417529 * 100, metric = 8.23% * 100;
 Minibatch[1901-2000]: loss = 0.423105 * 100, metric = 8.54% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.422476 * 2000, metric = 8.47% * 2000 561.575s (  3.6 samples/s);
Finished Evaluation [12]: Minibatch[1-1000]: metric = 14.92% * 1000;
 Minibatch[   1- 100]: loss = 0.424973 * 100, metric = 8.36% * 100;
 Minibatch[ 101- 200]: loss = 0.413908 * 100, metric = 8.25% * 100;
 Minibatch[ 201- 300]: loss = 0.410852 * 100, metric = 8.06% * 100;
 Minibatch[ 301- 400]: loss = 0.422690 * 100, metric = 8.43% * 100;
 Minibatch[ 401- 500]: loss = 0.422297 * 100, metric = 8.50% * 100;
 Minibatch[ 501- 600]: loss = 0.428722 * 100, metric = 8.62% * 100;
 Minibatch[ 601- 700]: loss = 0.406002 * 100, metric = 7.72% * 100;
 Minibatch[ 701- 800]: loss = 0.403734 * 100, metric = 8.01% * 100;
 Minibatch[ 801- 900]: loss = 0.405957 * 100, metric = 8.10% * 100;
 Minibatch[ 901-1000]: loss = 0.421316 * 100, metric = 8.56% * 100;
 Minibatch[1001-1100]: loss = 0.424918 * 100, metric = 8.59% * 100;
 Minibatch[1101-1200]: loss = 0.405246 * 100, metric = 7.91% * 100;
 Minibatch[1201-1300]: loss = 0.422863 * 100, metric = 8.30% * 100;
 Minibatch[1301-1400]: loss = 0.416423 * 100, metric = 8.19% * 100;
 Minibatch[1401-1500]: loss = 0.409896 * 100, metric = 8.17% * 100;
 Minibatch[1501-1600]: loss = 0.402023 * 100, metric = 7.71% * 100;
 Minibatch[1601-1700]: loss = 0.395368 * 100, metric = 7.69% * 100;
 Minibatch[1701-1800]: loss = 0.412718 * 100, metric = 8.16% * 100;
 Minibatch[1801-1900]: loss = 0.395730 * 100, metric = 7.55% * 100;
 Minibatch[1901-2000]: loss = 0.414452 * 100, metric = 8.33% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.413004 * 2000, metric = 8.16% * 2000 563.799s (  3.5 samples/s);
Finished Evaluation [13]: Minibatch[1-1000]: metric = 17.27% * 1000;
 Minibatch[   1- 100]: loss = 0.401794 * 100, metric = 7.75% * 100;
 Minibatch[ 101- 200]: loss = 0.401373 * 100, metric = 7.80% * 100;
 Minibatch[ 201- 300]: loss = 0.418410 * 100, metric = 8.30% * 100;
 Minibatch[ 301- 400]: loss = 0.409853 * 100, metric = 8.14% * 100;
 Minibatch[ 401- 500]: loss = 0.411093 * 100, metric = 8.25% * 100;
 Minibatch[ 501- 600]: loss = 0.416673 * 100, metric = 8.45% * 100;
 Minibatch[ 601- 700]: loss = 0.413295 * 100, metric = 8.47% * 100;
 Minibatch[ 701- 800]: loss = 0.429812 * 100, metric = 8.56% * 100;
 Minibatch[ 801- 900]: loss = 0.419982 * 100, metric = 8.68% * 100;
 Minibatch[ 901-1000]: loss = 0.417940 * 100, metric = 8.54% * 100;
 Minibatch[1001-1100]: loss = 0.420769 * 100, metric = 8.44% * 100;
 Minibatch[1101-1200]: loss = 0.407872 * 100, metric = 8.01% * 100;
 Minibatch[1201-1300]: loss = 0.392354 * 100, metric = 7.79% * 100;
 Minibatch[1301-1400]: loss = 0.417388 * 100, metric = 8.35% * 100;
 Minibatch[1401-1500]: loss = 0.417968 * 100, metric = 8.37% * 100;
 Minibatch[1501-1600]: loss = 0.400798 * 100, metric = 7.95% * 100;
 Minibatch[1601-1700]: loss = 0.411879 * 100, metric = 8.19% * 100;
 Minibatch[1701-1800]: loss = 0.420987 * 100, metric = 8.33% * 100;
 Minibatch[1801-1900]: loss = 0.407770 * 100, metric = 7.96% * 100;
 Minibatch[1901-2000]: loss = 0.412126 * 100, metric = 8.16% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.412507 * 2000, metric = 8.22% * 2000 559.930s (  3.6 samples/s);
Finished Evaluation [14]: Minibatch[1-1000]: metric = 15.57% * 1000;
 Minibatch[   1- 100]: loss = 0.398271 * 100, metric = 7.86% * 100;
 Minibatch[ 101- 200]: loss = 0.414260 * 100, metric = 8.18% * 100;
 Minibatch[ 201- 300]: loss = 0.409301 * 100, metric = 8.29% * 100;
 Minibatch[ 301- 400]: loss = 0.399584 * 100, metric = 7.87% * 100;
 Minibatch[ 401- 500]: loss = 0.408438 * 100, metric = 8.11% * 100;
 Minibatch[ 501- 600]: loss = 0.396235 * 100, metric = 7.72% * 100;
 Minibatch[ 601- 700]: loss = 0.388777 * 100, metric = 7.69% * 100;
 Minibatch[ 701- 800]: loss = 0.412042 * 100, metric = 8.02% * 100;
 Minibatch[ 801- 900]: loss = 0.416670 * 100, metric = 8.40% * 100;
 Minibatch[ 901-1000]: loss = 0.409382 * 100, metric = 8.41% * 100;
 Minibatch[1001-1100]: loss = 0.413037 * 100, metric = 8.26% * 100;
 Minibatch[1101-1200]: loss = 0.404396 * 100, metric = 8.05% * 100;
 Minibatch[1201-1300]: loss = 0.393165 * 100, metric = 7.66% * 100;
 Minibatch[1301-1400]: loss = 0.420093 * 100, metric = 8.44% * 100;
 Minibatch[1401-1500]: loss = 0.384762 * 100, metric = 7.42% * 100;
 Minibatch[1501-1600]: loss = 0.394199 * 100, metric = 7.75% * 100;
 Minibatch[1601-1700]: loss = 0.406124 * 100, metric = 8.05% * 100;
 Minibatch[1701-1800]: loss = 0.389665 * 100, metric = 7.61% * 100;
 Minibatch[1801-1900]: loss = 0.407794 * 100, metric = 8.17% * 100;
 Minibatch[1901-2000]: loss = 0.395869 * 100, metric = 7.95% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.403103 * 2000, metric = 8.00% * 2000 557.987s (  3.6 samples/s);
Finished Evaluation [15]: Minibatch[1-1000]: metric = 13.84% * 1000;
 Minibatch[   1- 100]: loss = 0.424672 * 100, metric = 8.83% * 100;
 Minibatch[ 101- 200]: loss = 0.416430 * 100, metric = 8.30% * 100;
 Minibatch[ 201- 300]: loss = 0.410328 * 100, metric = 8.04% * 100;
 Minibatch[ 301- 400]: loss = 0.412217 * 100, metric = 8.16% * 100;
 Minibatch[ 401- 500]: loss = 0.391630 * 100, metric = 7.70% * 100;
 Minibatch[ 501- 600]: loss = 0.397912 * 100, metric = 7.93% * 100;
 Minibatch[ 601- 700]: loss = 0.402941 * 100, metric = 8.13% * 100;
 Minibatch[ 701- 800]: loss = 0.400881 * 100, metric = 7.98% * 100;
 Minibatch[ 801- 900]: loss = 0.396453 * 100, metric = 7.75% * 100;
 Minibatch[ 901-1000]: loss = 0.403278 * 100, metric = 8.11% * 100;
 Minibatch[1001-1100]: loss = 0.389570 * 100, metric = 7.84% * 100;
 Minibatch[1101-1200]: loss = 0.393399 * 100, metric = 7.99% * 100;
 Minibatch[1201-1300]: loss = 0.389805 * 100, metric = 7.46% * 100;
 Minibatch[1301-1400]: loss = 0.390341 * 100, metric = 7.70% * 100;
 Minibatch[1401-1500]: loss = 0.397000 * 100, metric = 7.88% * 100;
 Minibatch[1501-1600]: loss = 0.402894 * 100, metric = 8.09% * 100;
 Minibatch[1601-1700]: loss = 0.400075 * 100, metric = 8.02% * 100;
 Minibatch[1701-1800]: loss = 0.408282 * 100, metric = 8.25% * 100;
 Minibatch[1801-1900]: loss = 0.403145 * 100, metric = 8.11% * 100;
 Minibatch[1901-2000]: loss = 0.392360 * 100, metric = 7.88% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.401181 * 2000, metric = 8.01% * 2000 570.827s (  3.5 samples/s);
Finished Evaluation [16]: Minibatch[1-1000]: metric = 14.88% * 1000;
 Minibatch[   1- 100]: loss = 0.383252 * 100, metric = 7.55% * 100;
 Minibatch[ 101- 200]: loss = 0.401142 * 100, metric = 8.04% * 100;
 Minibatch[ 201- 300]: loss = 0.399115 * 100, metric = 7.95% * 100;
 Minibatch[ 301- 400]: loss = 0.394745 * 100, metric = 7.73% * 100;
 Minibatch[ 401- 500]: loss = 0.409238 * 100, metric = 8.03% * 100;
 Minibatch[ 501- 600]: loss = 0.394117 * 100, metric = 7.70% * 100;
 Minibatch[ 601- 700]: loss = 0.381391 * 100, metric = 7.49% * 100;
 Minibatch[ 701- 800]: loss = 0.397961 * 100, metric = 7.71% * 100;
 Minibatch[ 801- 900]: loss = 0.397289 * 100, metric = 7.98% * 100;
 Minibatch[ 901-1000]: loss = 0.389249 * 100, metric = 7.63% * 100;
 Minibatch[1001-1100]: loss = 0.391523 * 100, metric = 7.69% * 100;
 Minibatch[1101-1200]: loss = 0.407670 * 100, metric = 8.25% * 100;
 Minibatch[1201-1300]: loss = 0.397560 * 100, metric = 7.98% * 100;
 Minibatch[1301-1400]: loss = 0.375682 * 100, metric = 7.33% * 100;
 Minibatch[1401-1500]: loss = 0.395866 * 100, metric = 7.82% * 100;
 Minibatch[1501-1600]: loss = 0.389969 * 100, metric = 7.78% * 100;
 Minibatch[1601-1700]: loss = 0.396908 * 100, metric = 7.86% * 100;
 Minibatch[1701-1800]: loss = 0.382532 * 100, metric = 7.68% * 100;
 Minibatch[1801-1900]: loss = 0.406088 * 100, metric = 8.18% * 100;
 Minibatch[1901-2000]: loss = 0.406412 * 100, metric = 8.22% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.394886 * 2000, metric = 7.83% * 2000 574.107s (  3.5 samples/s);
Finished Evaluation [17]: Minibatch[1-1000]: metric = 14.57% * 1000;
 Minibatch[   1- 100]: loss = 0.382727 * 100, metric = 7.42% * 100;
 Minibatch[ 101- 200]: loss = 0.401600 * 100, metric = 8.10% * 100;
 Minibatch[ 201- 300]: loss = 0.380879 * 100, metric = 7.67% * 100;
 Minibatch[ 301- 400]: loss = 0.393230 * 100, metric = 7.84% * 100;
 Minibatch[ 401- 500]: loss = 0.380642 * 100, metric = 7.50% * 100;
 Minibatch[ 501- 600]: loss = 0.386917 * 100, metric = 7.67% * 100;
 Minibatch[ 601- 700]: loss = 0.394317 * 100, metric = 7.97% * 100;
 Minibatch[ 701- 800]: loss = 0.378904 * 100, metric = 7.42% * 100;
 Minibatch[ 801- 900]: loss = 0.392208 * 100, metric = 7.97% * 100;
 Minibatch[ 901-1000]: loss = 0.393052 * 100, metric = 7.85% * 100;
 Minibatch[1001-1100]: loss = 0.400640 * 100, metric = 8.07% * 100;
 Minibatch[1101-1200]: loss = 0.392619 * 100, metric = 7.95% * 100;
 Minibatch[1201-1300]: loss = 0.400074 * 100, metric = 8.04% * 100;
 Minibatch[1301-1400]: loss = 0.394392 * 100, metric = 7.95% * 100;
 Minibatch[1401-1500]: loss = 0.371509 * 100, metric = 7.24% * 100;
 Minibatch[1501-1600]: loss = 0.385778 * 100, metric = 7.51% * 100;
 Minibatch[1601-1700]: loss = 0.370176 * 100, metric = 7.11% * 100;
 Minibatch[1701-1800]: loss = 0.389427 * 100, metric = 7.62% * 100;
 Minibatch[1801-1900]: loss = 0.384576 * 100, metric = 7.55% * 100;
 Minibatch[1901-2000]: loss = 0.375424 * 100, metric = 7.37% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.387455 * 2000, metric = 7.69% * 2000 577.396s (  3.5 samples/s);
Finished Evaluation [18]: Minibatch[1-1000]: metric = 14.90% * 1000;
 Minibatch[   1- 100]: loss = 0.399943 * 100, metric = 7.98% * 100;
 Minibatch[ 101- 200]: loss = 0.395337 * 100, metric = 7.90% * 100;
 Minibatch[ 201- 300]: loss = 0.377452 * 100, metric = 7.14% * 100;
 Minibatch[ 301- 400]: loss = 0.388645 * 100, metric = 7.80% * 100;
 Minibatch[ 401- 500]: loss = 0.387351 * 100, metric = 7.58% * 100;
 Minibatch[ 501- 600]: loss = 0.381315 * 100, metric = 7.41% * 100;
 Minibatch[ 601- 700]: loss = 0.389424 * 100, metric = 7.82% * 100;
 Minibatch[ 701- 800]: loss = 0.379879 * 100, metric = 7.61% * 100;
 Minibatch[ 801- 900]: loss = 0.408781 * 100, metric = 8.32% * 100;
 Minibatch[ 901-1000]: loss = 0.380174 * 100, metric = 7.51% * 100;
 Minibatch[1001-1100]: loss = 0.392652 * 100, metric = 7.73% * 100;
 Minibatch[1101-1200]: loss = 0.395699 * 100, metric = 8.09% * 100;
 Minibatch[1201-1300]: loss = 0.391031 * 100, metric = 7.79% * 100;
 Minibatch[1301-1400]: loss = 0.387325 * 100, metric = 7.83% * 100;
 Minibatch[1401-1500]: loss = 0.384595 * 100, metric = 7.71% * 100;
 Minibatch[1501-1600]: loss = 0.391616 * 100, metric = 7.86% * 100;
 Minibatch[1601-1700]: loss = 0.377584 * 100, metric = 7.62% * 100;
 Minibatch[1701-1800]: loss = 0.379017 * 100, metric = 7.54% * 100;
 Minibatch[1801-1900]: loss = 0.372608 * 100, metric = 7.53% * 100;
 Minibatch[1901-2000]: loss = 0.374386 * 100, metric = 7.34% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.386741 * 2000, metric = 7.71% * 2000 644.082s (  3.1 samples/s);
Finished Evaluation [19]: Minibatch[1-1000]: metric = 14.72% * 1000;
 Minibatch[   1- 100]: loss = 0.384375 * 100, metric = 7.60% * 100;
 Minibatch[ 101- 200]: loss = 0.379639 * 100, metric = 7.71% * 100;
 Minibatch[ 201- 300]: loss = 0.382994 * 100, metric = 7.59% * 100;
 Minibatch[ 301- 400]: loss = 0.397036 * 100, metric = 7.93% * 100;
 Minibatch[ 401- 500]: loss = 0.382856 * 100, metric = 7.60% * 100;
 Minibatch[ 501- 600]: loss = 0.393805 * 100, metric = 8.25% * 100;
 Minibatch[ 601- 700]: loss = 0.390995 * 100, metric = 8.03% * 100;
 Minibatch[ 701- 800]: loss = 0.380201 * 100, metric = 7.86% * 100;
 Minibatch[ 801- 900]: loss = 0.395412 * 100, metric = 8.11% * 100;
 Minibatch[ 901-1000]: loss = 0.395260 * 100, metric = 7.91% * 100;
 Minibatch[1001-1100]: loss = 0.378928 * 100, metric = 7.46% * 100;
 Minibatch[1101-1200]: loss = 0.390630 * 100, metric = 7.84% * 100;
 Minibatch[1201-1300]: loss = 0.390324 * 100, metric = 7.78% * 100;
 Minibatch[1301-1400]: loss = 0.388520 * 100, metric = 7.76% * 100;
 Minibatch[1401-1500]: loss = 0.384111 * 100, metric = 7.85% * 100;
 Minibatch[1501-1600]: loss = 0.397619 * 100, metric = 8.07% * 100;
 Minibatch[1601-1700]: loss = 0.376897 * 100, metric = 7.49% * 100;
 Minibatch[1701-1800]: loss = 0.390729 * 100, metric = 7.84% * 100;
 Minibatch[1801-1900]: loss = 0.389243 * 100, metric = 7.86% * 100;
 Minibatch[1901-2000]: loss = 0.384649 * 100, metric = 7.70% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.387711 * 2000, metric = 7.81% * 2000 744.349s (  2.7 samples/s);
Finished Evaluation [20]: Minibatch[1-1000]: metric = 14.34% * 1000;
 Minibatch[   1- 100]: loss = 0.385838 * 100, metric = 7.64% * 100;
 Minibatch[ 101- 200]: loss = 0.386377 * 100, metric = 7.80% * 100;
 Minibatch[ 201- 300]: loss = 0.382447 * 100, metric = 7.76% * 100;
 Minibatch[ 301- 400]: loss = 0.380327 * 100, metric = 7.58% * 100;
 Minibatch[ 401- 500]: loss = 0.371653 * 100, metric = 7.45% * 100;
 Minibatch[ 501- 600]: loss = 0.374855 * 100, metric = 7.44% * 100;
 Minibatch[ 601- 700]: loss = 0.375589 * 100, metric = 7.56% * 100;
 Minibatch[ 701- 800]: loss = 0.361011 * 100, metric = 7.18% * 100;
 Minibatch[ 801- 900]: loss = 0.385336 * 100, metric = 7.53% * 100;
 Minibatch[ 901-1000]: loss = 0.370136 * 100, metric = 7.33% * 100;
 Minibatch[1001-1100]: loss = 0.381309 * 100, metric = 7.76% * 100;
 Minibatch[1101-1200]: loss = 0.372365 * 100, metric = 7.38% * 100;
 Minibatch[1201-1300]: loss = 0.379352 * 100, metric = 7.48% * 100;
 Minibatch[1301-1400]: loss = 0.368419 * 100, metric = 7.30% * 100;
 Minibatch[1401-1500]: loss = 0.382087 * 100, metric = 7.64% * 100;
 Minibatch[1501-1600]: loss = 0.384041 * 100, metric = 7.69% * 100;
 Minibatch[1601-1700]: loss = 0.377293 * 100, metric = 7.51% * 100;
 Minibatch[1701-1800]: loss = 0.376773 * 100, metric = 7.56% * 100;
 Minibatch[1801-1900]: loss = 0.391014 * 100, metric = 7.70% * 100;
 Minibatch[1901-2000]: loss = 0.370178 * 100, metric = 7.12% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.377820 * 2000, metric = 7.52% * 2000 703.075s (  2.8 samples/s);
Finished Evaluation [21]: Minibatch[1-1000]: metric = 13.70% * 1000;
 Minibatch[   1- 100]: loss = 0.383699 * 100, metric = 7.61% * 100;
 Minibatch[ 101- 200]: loss = 0.378995 * 100, metric = 7.38% * 100;
 Minibatch[ 201- 300]: loss = 0.387873 * 100, metric = 7.78% * 100;
 Minibatch[ 301- 400]: loss = 0.377552 * 100, metric = 7.59% * 100;
 Minibatch[ 401- 500]: loss = 0.369323 * 100, metric = 7.22% * 100;
 Minibatch[ 501- 600]: loss = 0.382667 * 100, metric = 7.71% * 100;
 Minibatch[ 601- 700]: loss = 0.371600 * 100, metric = 7.38% * 100;
 Minibatch[ 701- 800]: loss = 0.371933 * 100, metric = 7.57% * 100;
 Minibatch[ 801- 900]: loss = 0.385266 * 100, metric = 7.75% * 100;
 Minibatch[ 901-1000]: loss = 0.381353 * 100, metric = 7.57% * 100;
 Minibatch[1001-1100]: loss = 0.366338 * 100, metric = 7.19% * 100;
 Minibatch[1101-1200]: loss = 0.359786 * 100, metric = 7.09% * 100;
 Minibatch[1201-1300]: loss = 0.366714 * 100, metric = 7.36% * 100;
 Minibatch[1301-1400]: loss = 0.380630 * 100, metric = 7.50% * 100;
 Minibatch[1401-1500]: loss = 0.376515 * 100, metric = 7.42% * 100;
 Minibatch[1501-1600]: loss = 0.364067 * 100, metric = 7.10% * 100;
 Minibatch[1601-1700]: loss = 0.364465 * 100, metric = 7.34% * 100;
 Minibatch[1701-1800]: loss = 0.372057 * 100, metric = 7.44% * 100;
 Minibatch[1801-1900]: loss = 0.372520 * 100, metric = 7.39% * 100;
 Minibatch[1901-2000]: loss = 0.368439 * 100, metric = 7.13% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.374090 * 2000, metric = 7.43% * 2000 748.202s (  2.7 samples/s);
Finished Evaluation [22]: Minibatch[1-1000]: metric = 14.47% * 1000;
 Minibatch[   1- 100]: loss = 0.378379 * 100, metric = 7.54% * 100;
 Minibatch[ 101- 200]: loss = 0.380222 * 100, metric = 7.75% * 100;
 Minibatch[ 201- 300]: loss = 0.373796 * 100, metric = 7.40% * 100;
 Minibatch[ 301- 400]: loss = 0.385949 * 100, metric = 7.73% * 100;
 Minibatch[ 401- 500]: loss = 0.380108 * 100, metric = 7.77% * 100;
 Minibatch[ 501- 600]: loss = 0.374521 * 100, metric = 7.27% * 100;
 Minibatch[ 601- 700]: loss = 0.371033 * 100, metric = 7.38% * 100;
 Minibatch[ 701- 800]: loss = 0.362232 * 100, metric = 7.12% * 100;
 Minibatch[ 801- 900]: loss = 0.367832 * 100, metric = 7.46% * 100;
 Minibatch[ 901-1000]: loss = 0.386689 * 100, metric = 7.67% * 100;
 Minibatch[1001-1100]: loss = 0.368805 * 100, metric = 7.35% * 100;
 Minibatch[1101-1200]: loss = 0.377282 * 100, metric = 7.55% * 100;
 Minibatch[1201-1300]: loss = 0.381696 * 100, metric = 7.54% * 100;
 Minibatch[1301-1400]: loss = 0.389315 * 100, metric = 7.76% * 100;
 Minibatch[1401-1500]: loss = 0.365493 * 100, metric = 7.09% * 100;
 Minibatch[1501-1600]: loss = 0.375240 * 100, metric = 7.67% * 100;
 Minibatch[1601-1700]: loss = 0.379247 * 100, metric = 7.70% * 100;
 Minibatch[1701-1800]: loss = 0.375558 * 100, metric = 7.67% * 100;
 Minibatch[1801-1900]: loss = 0.371309 * 100, metric = 7.49% * 100;
 Minibatch[1901-2000]: loss = 0.382784 * 100, metric = 7.71% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.376375 * 2000, metric = 7.53% * 2000 674.849s (  3.0 samples/s);
Finished Evaluation [23]: Minibatch[1-1000]: metric = 14.92% * 1000;
 Minibatch[   1- 100]: loss = 0.357336 * 100, metric = 7.20% * 100;
 Minibatch[ 101- 200]: loss = 0.377888 * 100, metric = 7.61% * 100;
 Minibatch[ 201- 300]: loss = 0.366885 * 100, metric = 7.30% * 100;
 Minibatch[ 301- 400]: loss = 0.368394 * 100, metric = 7.33% * 100;
 Minibatch[ 401- 500]: loss = 0.368319 * 100, metric = 7.42% * 100;
 Minibatch[ 501- 600]: loss = 0.357543 * 100, metric = 6.98% * 100;
 Minibatch[ 601- 700]: loss = 0.371806 * 100, metric = 7.27% * 100;
 Minibatch[ 701- 800]: loss = 0.372204 * 100, metric = 7.57% * 100;
 Minibatch[ 801- 900]: loss = 0.381610 * 100, metric = 7.64% * 100;
 Minibatch[ 901-1000]: loss = 0.376497 * 100, metric = 7.49% * 100;
 Minibatch[1001-1100]: loss = 0.364294 * 100, metric = 7.24% * 100;
 Minibatch[1101-1200]: loss = 0.385551 * 100, metric = 7.64% * 100;
 Minibatch[1201-1300]: loss = 0.378554 * 100, metric = 7.60% * 100;
 Minibatch[1301-1400]: loss = 0.366443 * 100, metric = 7.21% * 100;
 Minibatch[1401-1500]: loss = 0.368550 * 100, metric = 7.23% * 100;
 Minibatch[1501-1600]: loss = 0.375485 * 100, metric = 7.55% * 100;
 Minibatch[1601-1700]: loss = 0.359402 * 100, metric = 7.04% * 100;
 Minibatch[1701-1800]: loss = 0.372989 * 100, metric = 7.44% * 100;
 Minibatch[1801-1900]: loss = 0.366678 * 100, metric = 7.24% * 100;
 Minibatch[1901-2000]: loss = 0.375713 * 100, metric = 7.55% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.370607 * 2000, metric = 7.38% * 2000 755.163s (  2.6 samples/s);
Finished Evaluation [24]: Minibatch[1-1000]: metric = 14.60% * 1000;
 Minibatch[   1- 100]: loss = 0.375924 * 100, metric = 7.52% * 100;
 Minibatch[ 101- 200]: loss = 0.377329 * 100, metric = 7.59% * 100;
 Minibatch[ 201- 300]: loss = 0.373421 * 100, metric = 7.51% * 100;
 Minibatch[ 301- 400]: loss = 0.370151 * 100, metric = 7.38% * 100;
 Minibatch[ 401- 500]: loss = 0.372840 * 100, metric = 7.17% * 100;
 Minibatch[ 501- 600]: loss = 0.367063 * 100, metric = 7.33% * 100;
 Minibatch[ 601- 700]: loss = 0.368513 * 100, metric = 7.24% * 100;
 Minibatch[ 701- 800]: loss = 0.358138 * 100, metric = 6.97% * 100;
 Minibatch[ 801- 900]: loss = 0.363985 * 100, metric = 7.21% * 100;
 Minibatch[ 901-1000]: loss = 0.375707 * 100, metric = 7.49% * 100;
 Minibatch[1001-1100]: loss = 0.371188 * 100, metric = 7.57% * 100;
 Minibatch[1101-1200]: loss = 0.377825 * 100, metric = 7.51% * 100;
 Minibatch[1201-1300]: loss = 0.385669 * 100, metric = 7.75% * 100;
 Minibatch[1301-1400]: loss = 0.368885 * 100, metric = 7.30% * 100;
 Minibatch[1401-1500]: loss = 0.367809 * 100, metric = 7.27% * 100;
 Minibatch[1501-1600]: loss = 0.379619 * 100, metric = 7.79% * 100;
 Minibatch[1601-1700]: loss = 0.373571 * 100, metric = 7.50% * 100;
 Minibatch[1701-1800]: loss = 0.370684 * 100, metric = 7.25% * 100;
 Minibatch[1801-1900]: loss = 0.359655 * 100, metric = 7.00% * 100;
 Minibatch[1901-2000]: loss = 0.352709 * 100, metric = 6.76% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.370534 * 2000, metric = 7.35% * 2000 694.017s (  2.9 samples/s);
Finished Evaluation [25]: Minibatch[1-1000]: metric = 14.89% * 1000;
 Minibatch[   1- 100]: loss = 0.359364 * 100, metric = 6.98% * 100;
 Minibatch[ 101- 200]: loss = 0.347341 * 100, metric = 6.75% * 100;
 Minibatch[ 201- 300]: loss = 0.368720 * 100, metric = 7.26% * 100;
 Minibatch[ 301- 400]: loss = 0.355300 * 100, metric = 7.06% * 100;
 Minibatch[ 401- 500]: loss = 0.362917 * 100, metric = 7.31% * 100;
 Minibatch[ 501- 600]: loss = 0.359600 * 100, metric = 7.02% * 100;
 Minibatch[ 601- 700]: loss = 0.371041 * 100, metric = 7.14% * 100;
 Minibatch[ 701- 800]: loss = 0.363910 * 100, metric = 7.40% * 100;
 Minibatch[ 801- 900]: loss = 0.352685 * 100, metric = 6.99% * 100;
 Minibatch[ 901-1000]: loss = 0.355034 * 100, metric = 7.07% * 100;
 Minibatch[1001-1100]: loss = 0.367868 * 100, metric = 7.43% * 100;
 Minibatch[1101-1200]: loss = 0.369299 * 100, metric = 7.18% * 100;
 Minibatch[1201-1300]: loss = 0.359081 * 100, metric = 7.05% * 100;
 Minibatch[1301-1400]: loss = 0.353356 * 100, metric = 6.79% * 100;
 Minibatch[1401-1500]: loss = 0.362773 * 100, metric = 7.27% * 100;
 Minibatch[1501-1600]: loss = 0.361453 * 100, metric = 6.87% * 100;
 Minibatch[1601-1700]: loss = 0.379332 * 100, metric = 7.66% * 100;
 Minibatch[1701-1800]: loss = 0.369521 * 100, metric = 7.25% * 100;
 Minibatch[1801-1900]: loss = 0.362388 * 100, metric = 7.09% * 100;
 Minibatch[1901-2000]: loss = 0.374549 * 100, metric = 7.37% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.362777 * 2000, metric = 7.15% * 2000 790.041s (  2.5 samples/s);
Finished Evaluation [26]: Minibatch[1-1000]: metric = 15.47% * 1000;
 Minibatch[   1- 100]: loss = 0.365927 * 100, metric = 7.23% * 100;
 Minibatch[ 101- 200]: loss = 0.373516 * 100, metric = 7.30% * 100;
 Minibatch[ 201- 300]: loss = 0.360364 * 100, metric = 7.17% * 100;
 Minibatch[ 301- 400]: loss = 0.362781 * 100, metric = 7.20% * 100;
 Minibatch[ 401- 500]: loss = 0.361626 * 100, metric = 7.22% * 100;
 Minibatch[ 501- 600]: loss = 0.354335 * 100, metric = 7.22% * 100;
 Minibatch[ 601- 700]: loss = 0.355493 * 100, metric = 6.98% * 100;
 Minibatch[ 701- 800]: loss = 0.359646 * 100, metric = 7.17% * 100;
 Minibatch[ 801- 900]: loss = 0.366871 * 100, metric = 7.38% * 100;
 Minibatch[ 901-1000]: loss = 0.363004 * 100, metric = 7.26% * 100;
 Minibatch[1001-1100]: loss = 0.351502 * 100, metric = 6.78% * 100;
 Minibatch[1101-1200]: loss = 0.369610 * 100, metric = 7.39% * 100;
 Minibatch[1201-1300]: loss = 0.351771 * 100, metric = 6.80% * 100;
 Minibatch[1301-1400]: loss = 0.367274 * 100, metric = 7.41% * 100;
 Minibatch[1401-1500]: loss = 0.355379 * 100, metric = 7.09% * 100;
 Minibatch[1501-1600]: loss = 0.355433 * 100, metric = 7.01% * 100;
 Minibatch[1601-1700]: loss = 0.340691 * 100, metric = 6.65% * 100;
 Minibatch[1701-1800]: loss = 0.360620 * 100, metric = 6.98% * 100;
 Minibatch[1801-1900]: loss = 0.351796 * 100, metric = 6.96% * 100;
 Minibatch[1901-2000]: loss = 0.355963 * 100, metric = 6.89% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.359180 * 2000, metric = 7.10% * 2000 894.049s (  2.2 samples/s);
Finished Evaluation [27]: Minibatch[1-1000]: metric = 14.29% * 1000;
 Minibatch[   1- 100]: loss = 0.361950 * 100, metric = 7.22% * 100;
 Minibatch[ 101- 200]: loss = 0.351346 * 100, metric = 6.75% * 100;
 Minibatch[ 201- 300]: loss = 0.357806 * 100, metric = 7.15% * 100;
 Minibatch[ 301- 400]: loss = 0.359933 * 100, metric = 7.00% * 100;
 Minibatch[ 401- 500]: loss = 0.354851 * 100, metric = 7.13% * 100;
 Minibatch[ 501- 600]: loss = 0.373466 * 100, metric = 7.65% * 100;
 Minibatch[ 601- 700]: loss = 0.355458 * 100, metric = 6.94% * 100;
 Minibatch[ 701- 800]: loss = 0.345557 * 100, metric = 6.72% * 100;
 Minibatch[ 801- 900]: loss = 0.352827 * 100, metric = 7.11% * 100;
 Minibatch[ 901-1000]: loss = 0.365082 * 100, metric = 7.32% * 100;
 Minibatch[1001-1100]: loss = 0.357604 * 100, metric = 6.98% * 100;
 Minibatch[1101-1200]: loss = 0.354908 * 100, metric = 6.80% * 100;
 Minibatch[1201-1300]: loss = 0.357143 * 100, metric = 6.95% * 100;
 Minibatch[1301-1400]: loss = 0.352777 * 100, metric = 6.98% * 100;
 Minibatch[1401-1500]: loss = 0.362047 * 100, metric = 7.10% * 100;
 Minibatch[1501-1600]: loss = 0.356917 * 100, metric = 7.03% * 100;
 Minibatch[1601-1700]: loss = 0.353545 * 100, metric = 6.89% * 100;
 Minibatch[1701-1800]: loss = 0.352548 * 100, metric = 6.91% * 100;
 Minibatch[1801-1900]: loss = 0.360640 * 100, metric = 7.20% * 100;
 Minibatch[1901-2000]: loss = 0.359415 * 100, metric = 7.06% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.357291 * 2000, metric = 7.05% * 2000 929.216s (  2.2 samples/s);
Finished Evaluation [28]: Minibatch[1-1000]: metric = 14.07% * 1000;
 Minibatch[   1- 100]: loss = 0.349587 * 100, metric = 6.86% * 100;
 Minibatch[ 101- 200]: loss = 0.346148 * 100, metric = 6.88% * 100;
 Minibatch[ 201- 300]: loss = 0.358015 * 100, metric = 7.24% * 100;
 Minibatch[ 301- 400]: loss = 0.372269 * 100, metric = 7.38% * 100;
 Minibatch[ 401- 500]: loss = 0.352413 * 100, metric = 6.70% * 100;
 Minibatch[ 501- 600]: loss = 0.357767 * 100, metric = 7.22% * 100;
 Minibatch[ 601- 700]: loss = 0.350478 * 100, metric = 6.99% * 100;
 Minibatch[ 701- 800]: loss = 0.363726 * 100, metric = 7.32% * 100;
 Minibatch[ 801- 900]: loss = 0.354520 * 100, metric = 7.13% * 100;
 Minibatch[ 901-1000]: loss = 0.359333 * 100, metric = 7.21% * 100;
 Minibatch[1001-1100]: loss = 0.355195 * 100, metric = 7.11% * 100;
 Minibatch[1101-1200]: loss = 0.352195 * 100, metric = 6.91% * 100;
 Minibatch[1201-1300]: loss = 0.355015 * 100, metric = 7.10% * 100;
 Minibatch[1301-1400]: loss = 0.350769 * 100, metric = 6.96% * 100;
 Minibatch[1401-1500]: loss = 0.365200 * 100, metric = 7.44% * 100;
 Minibatch[1501-1600]: loss = 0.347397 * 100, metric = 6.93% * 100;
 Minibatch[1601-1700]: loss = 0.366320 * 100, metric = 7.32% * 100;
 Minibatch[1701-1800]: loss = 0.351104 * 100, metric = 7.11% * 100;
 Minibatch[1801-1900]: loss = 0.368384 * 100, metric = 7.45% * 100;
 Minibatch[1901-2000]: loss = 0.357735 * 100, metric = 7.18% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.356678 * 2000, metric = 7.12% * 2000 950.697s (  2.1 samples/s);
Finished Evaluation [29]: Minibatch[1-1000]: metric = 15.70% * 1000;
 Minibatch[   1- 100]: loss = 0.364753 * 100, metric = 7.20% * 100;
 Minibatch[ 101- 200]: loss = 0.339877 * 100, metric = 6.63% * 100;
 Minibatch[ 201- 300]: loss = 0.348585 * 100, metric = 7.04% * 100;
 Minibatch[ 301- 400]: loss = 0.358704 * 100, metric = 7.48% * 100;
 Minibatch[ 401- 500]: loss = 0.351064 * 100, metric = 6.86% * 100;
 Minibatch[ 501- 600]: loss = 0.335143 * 100, metric = 6.62% * 100;
 Minibatch[ 601- 700]: loss = 0.351346 * 100, metric = 7.07% * 100;
 Minibatch[ 701- 800]: loss = 0.348721 * 100, metric = 6.94% * 100;
 Minibatch[ 801- 900]: loss = 0.364383 * 100, metric = 7.22% * 100;
 Minibatch[ 901-1000]: loss = 0.340834 * 100, metric = 6.63% * 100;
 Minibatch[1001-1100]: loss = 0.356828 * 100, metric = 6.88% * 100;
 Minibatch[1101-1200]: loss = 0.358212 * 100, metric = 7.28% * 100;
 Minibatch[1201-1300]: loss = 0.353210 * 100, metric = 7.02% * 100;
 Minibatch[1301-1400]: loss = 0.351561 * 100, metric = 7.08% * 100;
 Minibatch[1401-1500]: loss = 0.348054 * 100, metric = 6.98% * 100;
 Minibatch[1501-1600]: loss = 0.357516 * 100, metric = 7.51% * 100;
 Minibatch[1601-1700]: loss = 0.349565 * 100, metric = 7.08% * 100;
 Minibatch[1701-1800]: loss = 0.354121 * 100, metric = 7.04% * 100;
 Minibatch[1801-1900]: loss = 0.353291 * 100, metric = 7.14% * 100;
 Minibatch[1901-2000]: loss = 0.360096 * 100, metric = 7.39% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.352293 * 2000, metric = 7.05% * 2000 926.190s (  2.2 samples/s);
Finished Evaluation [30]: Minibatch[1-1000]: metric = 14.72% * 1000;
