Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.344217 * 100, metric = 24.79% * 100;
 Minibatch[ 101- 200]: loss = 1.138206 * 100, metric = 23.86% * 100;
 Minibatch[ 201- 300]: loss = 1.028025 * 100, metric = 22.55% * 100;
 Minibatch[ 301- 400]: loss = 1.048593 * 100, metric = 21.64% * 100;
 Minibatch[ 401- 500]: loss = 0.981388 * 100, metric = 20.62% * 100;
 Minibatch[ 501- 600]: loss = 0.953010 * 100, metric = 19.13% * 100;
 Minibatch[ 601- 700]: loss = 0.928153 * 100, metric = 18.05% * 100;
 Minibatch[ 701- 800]: loss = 0.884170 * 100, metric = 17.35% * 100;
 Minibatch[ 801- 900]: loss = 0.898541 * 100, metric = 17.46% * 100;
 Minibatch[ 901-1000]: loss = 0.914559 * 100, metric = 17.87% * 100;
 Minibatch[1001-1100]: loss = 0.891168 * 100, metric = 17.51% * 100;
 Minibatch[1101-1200]: loss = 0.886415 * 100, metric = 17.03% * 100;
 Minibatch[1201-1300]: loss = 0.878923 * 100, metric = 17.02% * 100;
 Minibatch[1301-1400]: loss = 0.839690 * 100, metric = 15.96% * 100;
 Minibatch[1401-1500]: loss = 0.855139 * 100, metric = 16.26% * 100;
 Minibatch[1501-1600]: loss = 0.844053 * 100, metric = 16.14% * 100;
 Minibatch[1601-1700]: loss = 0.831431 * 100, metric = 15.88% * 100;
 Minibatch[1701-1800]: loss = 0.842244 * 100, metric = 15.57% * 100;
 Minibatch[1801-1900]: loss = 0.834276 * 100, metric = 15.88% * 100;
 Minibatch[1901-2000]: loss = 0.816285 * 100, metric = 15.08% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.931924 * 2000, metric = 18.28% * 2000 807.820s (  2.5 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 27.41% * 2000;
0.9076765580102801
 Minibatch[   1- 100]: loss = 0.813832 * 100, metric = 15.03% * 100;
 Minibatch[ 101- 200]: loss = 0.824980 * 100, metric = 16.03% * 100;
 Minibatch[ 201- 300]: loss = 0.820435 * 100, metric = 14.75% * 100;
 Minibatch[ 301- 400]: loss = 0.831101 * 100, metric = 15.15% * 100;
 Minibatch[ 401- 500]: loss = 0.811107 * 100, metric = 15.14% * 100;
 Minibatch[ 501- 600]: loss = 0.818633 * 100, metric = 14.79% * 100;
 Minibatch[ 601- 700]: loss = 0.784465 * 100, metric = 14.36% * 100;
 Minibatch[ 701- 800]: loss = 0.810045 * 100, metric = 15.33% * 100;
 Minibatch[ 801- 900]: loss = 0.783361 * 100, metric = 14.57% * 100;
 Minibatch[ 901-1000]: loss = 0.767953 * 100, metric = 13.77% * 100;
 Minibatch[1001-1100]: loss = 0.793614 * 100, metric = 14.73% * 100;
 Minibatch[1101-1200]: loss = 0.785326 * 100, metric = 14.39% * 100;
 Minibatch[1201-1300]: loss = 0.768212 * 100, metric = 13.93% * 100;
 Minibatch[1301-1400]: loss = 0.783866 * 100, metric = 14.30% * 100;
 Minibatch[1401-1500]: loss = 0.760541 * 100, metric = 13.57% * 100;
 Minibatch[1501-1600]: loss = 0.752296 * 100, metric = 13.52% * 100;
 Minibatch[1601-1700]: loss = 0.763964 * 100, metric = 13.94% * 100;
 Minibatch[1701-1800]: loss = 0.766785 * 100, metric = 14.01% * 100;
 Minibatch[1801-1900]: loss = 0.770923 * 100, metric = 14.05% * 100;
 Minibatch[1901-2000]: loss = 0.736785 * 100, metric = 13.43% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.787411 * 2000, metric = 14.44% * 2000 760.150s (  2.6 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 21.26% * 2000;
0.7919037014245986
 Minibatch[   1- 100]: loss = 0.745824 * 100, metric = 13.58% * 100;
 Minibatch[ 101- 200]: loss = 0.756155 * 100, metric = 13.90% * 100;
 Minibatch[ 201- 300]: loss = 0.743885 * 100, metric = 13.67% * 100;
 Minibatch[ 301- 400]: loss = 0.754745 * 100, metric = 13.93% * 100;
 Minibatch[ 401- 500]: loss = 0.763375 * 100, metric = 13.94% * 100;
 Minibatch[ 501- 600]: loss = 0.753543 * 100, metric = 13.74% * 100;
 Minibatch[ 601- 700]: loss = 0.749487 * 100, metric = 13.57% * 100;
 Minibatch[ 701- 800]: loss = 0.733769 * 100, metric = 13.03% * 100;
 Minibatch[ 801- 900]: loss = 0.754145 * 100, metric = 13.77% * 100;
 Minibatch[ 901-1000]: loss = 0.721127 * 100, metric = 13.39% * 100;
 Minibatch[1001-1100]: loss = 0.735574 * 100, metric = 13.61% * 100;
 Minibatch[1101-1200]: loss = 0.715236 * 100, metric = 12.74% * 100;
 Minibatch[1201-1300]: loss = 0.713691 * 100, metric = 12.87% * 100;
 Minibatch[1301-1400]: loss = 0.731368 * 100, metric = 13.01% * 100;
 Minibatch[1401-1500]: loss = 0.732443 * 100, metric = 13.11% * 100;
 Minibatch[1501-1600]: loss = 0.713058 * 100, metric = 12.39% * 100;
 Minibatch[1601-1700]: loss = 0.700773 * 100, metric = 12.29% * 100;
 Minibatch[1701-1800]: loss = 0.724337 * 100, metric = 13.00% * 100;
 Minibatch[1801-1900]: loss = 0.717852 * 100, metric = 12.53% * 100;
 Minibatch[1901-2000]: loss = 0.712253 * 100, metric = 12.67% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.733632 * 2000, metric = 13.24% * 2000 761.807s (  2.6 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 20.46% * 2000;
0.7605179527997971
 Minibatch[   1- 100]: loss = 0.743664 * 100, metric = 12.93% * 100;
 Minibatch[ 101- 200]: loss = 0.697498 * 100, metric = 12.16% * 100;
 Minibatch[ 201- 300]: loss = 0.713990 * 100, metric = 12.74% * 100;
 Minibatch[ 301- 400]: loss = 0.674916 * 100, metric = 11.90% * 100;
 Minibatch[ 401- 500]: loss = 0.708775 * 100, metric = 12.52% * 100;
 Minibatch[ 501- 600]: loss = 0.680319 * 100, metric = 11.58% * 100;
 Minibatch[ 601- 700]: loss = 0.690901 * 100, metric = 12.02% * 100;
 Minibatch[ 701- 800]: loss = 0.706901 * 100, metric = 12.77% * 100;
 Minibatch[ 801- 900]: loss = 0.700776 * 100, metric = 12.44% * 100;
 Minibatch[ 901-1000]: loss = 0.700113 * 100, metric = 12.41% * 100;
 Minibatch[1001-1100]: loss = 0.726910 * 100, metric = 13.19% * 100;
 Minibatch[1101-1200]: loss = 0.689449 * 100, metric = 12.23% * 100;
 Minibatch[1201-1300]: loss = 0.688864 * 100, metric = 12.11% * 100;
 Minibatch[1301-1400]: loss = 0.716768 * 100, metric = 12.94% * 100;
 Minibatch[1401-1500]: loss = 0.713712 * 100, metric = 12.82% * 100;
 Minibatch[1501-1600]: loss = 0.682513 * 100, metric = 11.91% * 100;
 Minibatch[1601-1700]: loss = 0.706179 * 100, metric = 12.66% * 100;
 Minibatch[1701-1800]: loss = 0.702783 * 100, metric = 12.56% * 100;
 Minibatch[1801-1900]: loss = 0.695516 * 100, metric = 12.19% * 100;
 Minibatch[1901-2000]: loss = 0.693373 * 100, metric = 12.26% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.701696 * 2000, metric = 12.42% * 2000 757.447s (  2.6 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 21.68% * 2000;
 Minibatch[   1- 100]: loss = 0.715641 * 100, metric = 12.73% * 100;
 Minibatch[ 101- 200]: loss = 0.687991 * 100, metric = 11.89% * 100;
 Minibatch[ 201- 300]: loss = 0.676970 * 100, metric = 11.93% * 100;
 Minibatch[ 301- 400]: loss = 0.723132 * 100, metric = 12.91% * 100;
 Minibatch[ 401- 500]: loss = 0.672821 * 100, metric = 11.31% * 100;
 Minibatch[ 501- 600]: loss = 0.662634 * 100, metric = 11.42% * 100;
 Minibatch[ 601- 700]: loss = 0.667190 * 100, metric = 11.30% * 100;
 Minibatch[ 701- 800]: loss = 0.684429 * 100, metric = 12.07% * 100;
 Minibatch[ 801- 900]: loss = 0.669764 * 100, metric = 11.40% * 100;
 Minibatch[ 901-1000]: loss = 0.670217 * 100, metric = 11.83% * 100;
 Minibatch[1001-1100]: loss = 0.677373 * 100, metric = 11.70% * 100;
 Minibatch[1101-1200]: loss = 0.653922 * 100, metric = 11.25% * 100;
 Minibatch[1201-1300]: loss = 0.682992 * 100, metric = 11.77% * 100;
 Minibatch[1301-1400]: loss = 0.697632 * 100, metric = 12.28% * 100;
 Minibatch[1401-1500]: loss = 0.669339 * 100, metric = 11.80% * 100;
 Minibatch[1501-1600]: loss = 0.672379 * 100, metric = 11.72% * 100;
 Minibatch[1601-1700]: loss = 0.684380 * 100, metric = 12.12% * 100;
 Minibatch[1701-1800]: loss = 0.692723 * 100, metric = 12.27% * 100;
 Minibatch[1801-1900]: loss = 0.672751 * 100, metric = 11.96% * 100;
 Minibatch[1901-2000]: loss = 0.656388 * 100, metric = 11.36% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.679533 * 2000, metric = 11.85% * 2000 757.444s (  2.6 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 19.67% * 2000;
0.7348752270117402
 Minibatch[   1- 100]: loss = 0.662300 * 100, metric = 11.32% * 100;
 Minibatch[ 101- 200]: loss = 0.654698 * 100, metric = 11.49% * 100;
 Minibatch[ 201- 300]: loss = 0.664277 * 100, metric = 11.51% * 100;
 Minibatch[ 301- 400]: loss = 0.673417 * 100, metric = 11.65% * 100;
 Minibatch[ 401- 500]: loss = 0.646266 * 100, metric = 11.09% * 100;
 Minibatch[ 501- 600]: loss = 0.653295 * 100, metric = 11.34% * 100;
 Minibatch[ 601- 700]: loss = 0.658625 * 100, metric = 11.50% * 100;
 Minibatch[ 701- 800]: loss = 0.661198 * 100, metric = 11.34% * 100;
 Minibatch[ 801- 900]: loss = 0.650424 * 100, metric = 11.09% * 100;
 Minibatch[ 901-1000]: loss = 0.646192 * 100, metric = 11.28% * 100;
 Minibatch[1001-1100]: loss = 0.643029 * 100, metric = 10.62% * 100;
 Minibatch[1101-1200]: loss = 0.662583 * 100, metric = 11.37% * 100;
 Minibatch[1201-1300]: loss = 0.670297 * 100, metric = 11.48% * 100;
 Minibatch[1301-1400]: loss = 0.646782 * 100, metric = 11.03% * 100;
 Minibatch[1401-1500]: loss = 0.652581 * 100, metric = 11.32% * 100;
 Minibatch[1501-1600]: loss = 0.636780 * 100, metric = 10.75% * 100;
 Minibatch[1601-1700]: loss = 0.636254 * 100, metric = 10.54% * 100;
 Minibatch[1701-1800]: loss = 0.628170 * 100, metric = 10.49% * 100;
 Minibatch[1801-1900]: loss = 0.652574 * 100, metric = 11.05% * 100;
 Minibatch[1901-2000]: loss = 0.638407 * 100, metric = 10.60% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.651907 * 2000, metric = 11.14% * 2000 763.710s (  2.6 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.60% * 2000;
 Minibatch[   1- 100]: loss = 0.641233 * 100, metric = 11.14% * 100;
 Minibatch[ 101- 200]: loss = 0.647533 * 100, metric = 10.80% * 100;
 Minibatch[ 201- 300]: loss = 0.646608 * 100, metric = 11.08% * 100;
 Minibatch[ 301- 400]: loss = 0.625677 * 100, metric = 10.53% * 100;
 Minibatch[ 401- 500]: loss = 0.643887 * 100, metric = 10.75% * 100;
 Minibatch[ 501- 600]: loss = 0.617247 * 100, metric = 10.18% * 100;
 Minibatch[ 601- 700]: loss = 0.638396 * 100, metric = 10.46% * 100;
 Minibatch[ 701- 800]: loss = 0.653461 * 100, metric = 10.77% * 100;
 Minibatch[ 801- 900]: loss = 0.645124 * 100, metric = 11.03% * 100;
 Minibatch[ 901-1000]: loss = 0.633382 * 100, metric = 10.66% * 100;
 Minibatch[1001-1100]: loss = 0.648313 * 100, metric = 11.32% * 100;
 Minibatch[1101-1200]: loss = 0.630291 * 100, metric = 10.56% * 100;
 Minibatch[1201-1300]: loss = 0.646744 * 100, metric = 11.13% * 100;
 Minibatch[1301-1400]: loss = 0.632380 * 100, metric = 10.66% * 100;
 Minibatch[1401-1500]: loss = 0.617419 * 100, metric = 10.20% * 100;
 Minibatch[1501-1600]: loss = 0.634130 * 100, metric = 10.75% * 100;
 Minibatch[1601-1700]: loss = 0.636894 * 100, metric = 10.75% * 100;
 Minibatch[1701-1800]: loss = 0.625734 * 100, metric = 10.60% * 100;
 Minibatch[1801-1900]: loss = 0.625789 * 100, metric = 10.72% * 100;
 Minibatch[1901-2000]: loss = 0.640245 * 100, metric = 10.96% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.636524 * 2000, metric = 10.75% * 2000 762.354s (  2.6 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 17.30% * 2000;
0.6781235533058644
 Minibatch[   1- 100]: loss = 0.643483 * 100, metric = 10.90% * 100;
 Minibatch[ 101- 200]: loss = 0.630590 * 100, metric = 10.81% * 100;
 Minibatch[ 201- 300]: loss = 0.616351 * 100, metric = 10.54% * 100;
 Minibatch[ 301- 400]: loss = 0.629058 * 100, metric = 10.87% * 100;
 Minibatch[ 401- 500]: loss = 0.630394 * 100, metric = 10.88% * 100;
 Minibatch[ 501- 600]: loss = 0.649189 * 100, metric = 11.34% * 100;
 Minibatch[ 601- 700]: loss = 0.603436 * 100, metric = 10.09% * 100;
 Minibatch[ 701- 800]: loss = 0.622461 * 100, metric = 10.25% * 100;
 Minibatch[ 801- 900]: loss = 0.602213 * 100, metric = 9.90% * 100;
 Minibatch[ 901-1000]: loss = 0.596490 * 100, metric = 9.48% * 100;
 Minibatch[1001-1100]: loss = 0.598024 * 100, metric = 10.05% * 100;
 Minibatch[1101-1200]: loss = 0.603854 * 100, metric = 9.94% * 100;
 Minibatch[1201-1300]: loss = 0.613314 * 100, metric = 10.26% * 100;
 Minibatch[1301-1400]: loss = 0.629936 * 100, metric = 10.64% * 100;
 Minibatch[1401-1500]: loss = 0.614495 * 100, metric = 10.22% * 100;
 Minibatch[1501-1600]: loss = 0.618477 * 100, metric = 10.37% * 100;
 Minibatch[1601-1700]: loss = 0.608048 * 100, metric = 9.90% * 100;
 Minibatch[1701-1800]: loss = 0.611552 * 100, metric = 9.85% * 100;
 Minibatch[1801-1900]: loss = 0.619049 * 100, metric = 10.18% * 100;
 Minibatch[1901-2000]: loss = 0.615975 * 100, metric = 10.04% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.617819 * 2000, metric = 10.33% * 2000 755.152s (  2.6 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 17.61% * 2000;
 Minibatch[   1- 100]: loss = 0.587690 * 100, metric = 9.25% * 100;
 Minibatch[ 101- 200]: loss = 0.622686 * 100, metric = 10.15% * 100;
 Minibatch[ 201- 300]: loss = 0.621932 * 100, metric = 10.11% * 100;
 Minibatch[ 301- 400]: loss = 0.636616 * 100, metric = 10.74% * 100;
 Minibatch[ 401- 500]: loss = 0.614133 * 100, metric = 9.92% * 100;
 Minibatch[ 501- 600]: loss = 0.602496 * 100, metric = 9.96% * 100;
 Minibatch[ 601- 700]: loss = 0.613857 * 100, metric = 10.16% * 100;
 Minibatch[ 701- 800]: loss = 0.597633 * 100, metric = 9.60% * 100;
 Minibatch[ 801- 900]: loss = 0.591552 * 100, metric = 9.89% * 100;
 Minibatch[ 901-1000]: loss = 0.618062 * 100, metric = 10.25% * 100;
 Minibatch[1001-1100]: loss = 0.581581 * 100, metric = 9.06% * 100;
 Minibatch[1101-1200]: loss = 0.605587 * 100, metric = 10.16% * 100;
 Minibatch[1201-1300]: loss = 0.603091 * 100, metric = 9.98% * 100;
 Minibatch[1301-1400]: loss = 0.594149 * 100, metric = 9.61% * 100;
 Minibatch[1401-1500]: loss = 0.609085 * 100, metric = 10.22% * 100;
 Minibatch[1501-1600]: loss = 0.614933 * 100, metric = 10.06% * 100;
 Minibatch[1601-1700]: loss = 0.611959 * 100, metric = 10.12% * 100;
 Minibatch[1701-1800]: loss = 0.598910 * 100, metric = 9.62% * 100;
 Minibatch[1801-1900]: loss = 0.594238 * 100, metric = 9.70% * 100;
 Minibatch[1901-2000]: loss = 0.605956 * 100, metric = 9.96% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.606307 * 2000, metric = 9.93% * 2000 749.182s (  2.7 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 16.22% * 2000;
0.6624572900906205
 Minibatch[   1- 100]: loss = 0.624839 * 100, metric = 10.78% * 100;
 Minibatch[ 101- 200]: loss = 0.588539 * 100, metric = 9.71% * 100;
 Minibatch[ 201- 300]: loss = 0.598302 * 100, metric = 9.77% * 100;
 Minibatch[ 301- 400]: loss = 0.598623 * 100, metric = 9.89% * 100;
 Minibatch[ 401- 500]: loss = 0.619726 * 100, metric = 10.23% * 100;
 Minibatch[ 501- 600]: loss = 0.579049 * 100, metric = 9.27% * 100;
 Minibatch[ 601- 700]: loss = 0.579196 * 100, metric = 9.50% * 100;
 Minibatch[ 701- 800]: loss = 0.567692 * 100, metric = 8.74% * 100;
 Minibatch[ 801- 900]: loss = 0.592346 * 100, metric = 9.51% * 100;
 Minibatch[ 901-1000]: loss = 0.593734 * 100, metric = 9.81% * 100;
 Minibatch[1001-1100]: loss = 0.596530 * 100, metric = 10.07% * 100;
 Minibatch[1101-1200]: loss = 0.591213 * 100, metric = 9.43% * 100;
 Minibatch[1201-1300]: loss = 0.593295 * 100, metric = 9.83% * 100;
 Minibatch[1301-1400]: loss = 0.598410 * 100, metric = 9.78% * 100;
 Minibatch[1401-1500]: loss = 0.577565 * 100, metric = 9.17% * 100;
 Minibatch[1501-1600]: loss = 0.589592 * 100, metric = 9.83% * 100;
 Minibatch[1601-1700]: loss = 0.584099 * 100, metric = 9.24% * 100;
 Minibatch[1701-1800]: loss = 0.591457 * 100, metric = 9.79% * 100;
 Minibatch[1801-1900]: loss = 0.604015 * 100, metric = 10.02% * 100;
 Minibatch[1901-2000]: loss = 0.583623 * 100, metric = 9.73% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.592592 * 2000, metric = 9.70% * 2000 758.356s (  2.6 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 16.37% * 2000;
0.65858115106076
 Minibatch[   1- 100]: loss = 0.562310 * 100, metric = 8.90% * 100;
 Minibatch[ 101- 200]: loss = 0.583752 * 100, metric = 9.33% * 100;
 Minibatch[ 201- 300]: loss = 0.592001 * 100, metric = 9.42% * 100;
 Minibatch[ 301- 400]: loss = 0.582610 * 100, metric = 9.29% * 100;
 Minibatch[ 401- 500]: loss = 0.573097 * 100, metric = 9.16% * 100;
 Minibatch[ 501- 600]: loss = 0.588200 * 100, metric = 9.69% * 100;
 Minibatch[ 601- 700]: loss = 0.578594 * 100, metric = 9.16% * 100;
 Minibatch[ 701- 800]: loss = 0.587534 * 100, metric = 9.46% * 100;
 Minibatch[ 801- 900]: loss = 0.572927 * 100, metric = 9.12% * 100;
 Minibatch[ 901-1000]: loss = 0.586969 * 100, metric = 9.32% * 100;
 Minibatch[1001-1100]: loss = 0.574330 * 100, metric = 9.42% * 100;
 Minibatch[1101-1200]: loss = 0.590776 * 100, metric = 9.66% * 100;
 Minibatch[1201-1300]: loss = 0.573784 * 100, metric = 9.27% * 100;
 Minibatch[1301-1400]: loss = 0.552747 * 100, metric = 8.88% * 100;
 Minibatch[1401-1500]: loss = 0.585662 * 100, metric = 9.62% * 100;
 Minibatch[1501-1600]: loss = 0.561273 * 100, metric = 8.90% * 100;
 Minibatch[1601-1700]: loss = 0.571312 * 100, metric = 8.94% * 100;
 Minibatch[1701-1800]: loss = 0.587216 * 100, metric = 9.36% * 100;
 Minibatch[1801-1900]: loss = 0.568307 * 100, metric = 9.17% * 100;
 Minibatch[1901-2000]: loss = 0.570753 * 100, metric = 9.28% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.577208 * 2000, metric = 9.27% * 2000 758.558s (  2.6 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 16.31% * 2000;
 Minibatch[   1- 100]: loss = 0.551919 * 100, metric = 8.91% * 100;
 Minibatch[ 101- 200]: loss = 0.559798 * 100, metric = 8.65% * 100;
 Minibatch[ 201- 300]: loss = 0.555297 * 100, metric = 9.13% * 100;
 Minibatch[ 301- 400]: loss = 0.599490 * 100, metric = 9.62% * 100;
 Minibatch[ 401- 500]: loss = 0.558052 * 100, metric = 8.70% * 100;
 Minibatch[ 501- 600]: loss = 0.544024 * 100, metric = 8.31% * 100;
 Minibatch[ 601- 700]: loss = 0.556419 * 100, metric = 8.54% * 100;
 Minibatch[ 701- 800]: loss = 0.560560 * 100, metric = 8.72% * 100;
 Minibatch[ 801- 900]: loss = 0.550782 * 100, metric = 8.37% * 100;
 Minibatch[ 901-1000]: loss = 0.555921 * 100, metric = 9.00% * 100;
 Minibatch[1001-1100]: loss = 0.566419 * 100, metric = 9.19% * 100;
 Minibatch[1101-1200]: loss = 0.559085 * 100, metric = 8.98% * 100;
 Minibatch[1201-1300]: loss = 0.579467 * 100, metric = 9.29% * 100;
 Minibatch[1301-1400]: loss = 0.556718 * 100, metric = 8.91% * 100;
 Minibatch[1401-1500]: loss = 0.573582 * 100, metric = 9.34% * 100;
 Minibatch[1501-1600]: loss = 0.533591 * 100, metric = 8.50% * 100;
 Minibatch[1601-1700]: loss = 0.570832 * 100, metric = 9.05% * 100;
 Minibatch[1701-1800]: loss = 0.543619 * 100, metric = 8.45% * 100;
 Minibatch[1801-1900]: loss = 0.551316 * 100, metric = 8.71% * 100;
 Minibatch[1901-2000]: loss = 0.579513 * 100, metric = 9.04% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.560320 * 2000, metric = 8.87% * 2000 753.772s (  2.7 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 16.98% * 2000;
 Minibatch[   1- 100]: loss = 0.569829 * 100, metric = 9.14% * 100;
 Minibatch[ 101- 200]: loss = 0.562738 * 100, metric = 9.14% * 100;
 Minibatch[ 201- 300]: loss = 0.563307 * 100, metric = 8.97% * 100;
 Minibatch[ 301- 400]: loss = 0.568500 * 100, metric = 8.81% * 100;
 Minibatch[ 401- 500]: loss = 0.567945 * 100, metric = 9.49% * 100;
 Minibatch[ 501- 600]: loss = 0.572401 * 100, metric = 9.42% * 100;
 Minibatch[ 601- 700]: loss = 0.550419 * 100, metric = 8.46% * 100;
 Minibatch[ 701- 800]: loss = 0.551625 * 100, metric = 8.51% * 100;
 Minibatch[ 801- 900]: loss = 0.557081 * 100, metric = 8.75% * 100;
 Minibatch[ 901-1000]: loss = 0.559223 * 100, metric = 9.07% * 100;
 Minibatch[1001-1100]: loss = 0.569370 * 100, metric = 9.25% * 100;
 Minibatch[1101-1200]: loss = 0.554880 * 100, metric = 8.66% * 100;
 Minibatch[1201-1300]: loss = 0.561166 * 100, metric = 9.04% * 100;
 Minibatch[1301-1400]: loss = 0.549723 * 100, metric = 8.58% * 100;
 Minibatch[1401-1500]: loss = 0.545553 * 100, metric = 8.48% * 100;
 Minibatch[1501-1600]: loss = 0.542891 * 100, metric = 8.24% * 100;
 Minibatch[1601-1700]: loss = 0.535336 * 100, metric = 8.58% * 100;
 Minibatch[1701-1800]: loss = 0.546564 * 100, metric = 8.67% * 100;
 Minibatch[1801-1900]: loss = 0.547219 * 100, metric = 8.61% * 100;
 Minibatch[1901-2000]: loss = 0.554247 * 100, metric = 8.92% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.556501 * 2000, metric = 8.84% * 2000 744.687s (  2.7 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 17.72% * 2000;
 Minibatch[   1- 100]: loss = 0.548311 * 100, metric = 8.50% * 100;
 Minibatch[ 101- 200]: loss = 0.537999 * 100, metric = 8.28% * 100;
 Minibatch[ 201- 300]: loss = 0.559283 * 100, metric = 8.84% * 100;
 Minibatch[ 301- 400]: loss = 0.536452 * 100, metric = 8.28% * 100;
 Minibatch[ 401- 500]: loss = 0.544479 * 100, metric = 8.73% * 100;
 Minibatch[ 501- 600]: loss = 0.548947 * 100, metric = 8.54% * 100;
 Minibatch[ 601- 700]: loss = 0.541330 * 100, metric = 8.37% * 100;
 Minibatch[ 701- 800]: loss = 0.565677 * 100, metric = 9.15% * 100;
 Minibatch[ 801- 900]: loss = 0.558535 * 100, metric = 9.22% * 100;
 Minibatch[ 901-1000]: loss = 0.552922 * 100, metric = 8.74% * 100;
 Minibatch[1001-1100]: loss = 0.556398 * 100, metric = 9.03% * 100;
 Minibatch[1101-1200]: loss = 0.541693 * 100, metric = 8.63% * 100;
 Minibatch[1201-1300]: loss = 0.522151 * 100, metric = 8.09% * 100;
 Minibatch[1301-1400]: loss = 0.549736 * 100, metric = 9.00% * 100;
 Minibatch[1401-1500]: loss = 0.545536 * 100, metric = 8.71% * 100;
 Minibatch[1501-1600]: loss = 0.537846 * 100, metric = 8.62% * 100;
 Minibatch[1601-1700]: loss = 0.544338 * 100, metric = 8.48% * 100;
 Minibatch[1701-1800]: loss = 0.544119 * 100, metric = 8.40% * 100;
 Minibatch[1801-1900]: loss = 0.542538 * 100, metric = 8.46% * 100;
 Minibatch[1901-2000]: loss = 0.552052 * 100, metric = 8.48% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.546517 * 2000, metric = 8.63% * 2000 743.474s (  2.7 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 16.96% * 2000;
 Minibatch[   1- 100]: loss = 0.544855 * 100, metric = 8.52% * 100;
 Minibatch[ 101- 200]: loss = 0.545721 * 100, metric = 8.51% * 100;
 Minibatch[ 201- 300]: loss = 0.551964 * 100, metric = 8.84% * 100;
 Minibatch[ 301- 400]: loss = 0.522784 * 100, metric = 8.12% * 100;
 Minibatch[ 401- 500]: loss = 0.535961 * 100, metric = 8.33% * 100;
 Minibatch[ 501- 600]: loss = 0.529425 * 100, metric = 8.12% * 100;
 Minibatch[ 601- 700]: loss = 0.516670 * 100, metric = 8.04% * 100;
 Minibatch[ 701- 800]: loss = 0.553959 * 100, metric = 8.81% * 100;
 Minibatch[ 801- 900]: loss = 0.558584 * 100, metric = 9.21% * 100;
 Minibatch[ 901-1000]: loss = 0.545634 * 100, metric = 8.38% * 100;
 Minibatch[1001-1100]: loss = 0.551013 * 100, metric = 8.60% * 100;
 Minibatch[1101-1200]: loss = 0.533574 * 100, metric = 8.35% * 100;
 Minibatch[1201-1300]: loss = 0.529210 * 100, metric = 7.86% * 100;
 Minibatch[1301-1400]: loss = 0.557713 * 100, metric = 9.01% * 100;
 Minibatch[1401-1500]: loss = 0.517151 * 100, metric = 8.02% * 100;
 Minibatch[1501-1600]: loss = 0.527975 * 100, metric = 8.38% * 100;
 Minibatch[1601-1700]: loss = 0.534548 * 100, metric = 8.12% * 100;
 Minibatch[1701-1800]: loss = 0.517591 * 100, metric = 7.91% * 100;
 Minibatch[1801-1900]: loss = 0.522647 * 100, metric = 8.36% * 100;
 Minibatch[1901-2000]: loss = 0.528985 * 100, metric = 8.31% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.536298 * 2000, metric = 8.39% * 2000 740.524s (  2.7 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 15.21% * 2000;
0.6545260950103402
 Minibatch[   1- 100]: loss = 0.554592 * 100, metric = 8.93% * 100;
 Minibatch[ 101- 200]: loss = 0.547015 * 100, metric = 8.39% * 100;
 Minibatch[ 201- 300]: loss = 0.528100 * 100, metric = 8.19% * 100;
 Minibatch[ 301- 400]: loss = 0.540532 * 100, metric = 8.31% * 100;
 Minibatch[ 401- 500]: loss = 0.505939 * 100, metric = 7.48% * 100;
 Minibatch[ 501- 600]: loss = 0.529108 * 100, metric = 8.30% * 100;
 Minibatch[ 601- 700]: loss = 0.519948 * 100, metric = 8.02% * 100;
 Minibatch[ 701- 800]: loss = 0.514561 * 100, metric = 7.81% * 100;
 Minibatch[ 801- 900]: loss = 0.519980 * 100, metric = 7.73% * 100;
 Minibatch[ 901-1000]: loss = 0.529397 * 100, metric = 8.47% * 100;
 Minibatch[1001-1100]: loss = 0.514609 * 100, metric = 7.92% * 100;
 Minibatch[1101-1200]: loss = 0.521884 * 100, metric = 8.03% * 100;
 Minibatch[1201-1300]: loss = 0.523692 * 100, metric = 7.90% * 100;
 Minibatch[1301-1400]: loss = 0.518330 * 100, metric = 8.03% * 100;
 Minibatch[1401-1500]: loss = 0.512799 * 100, metric = 7.95% * 100;
 Minibatch[1501-1600]: loss = 0.520695 * 100, metric = 8.12% * 100;
 Minibatch[1601-1700]: loss = 0.522008 * 100, metric = 8.19% * 100;
 Minibatch[1701-1800]: loss = 0.553035 * 100, metric = 8.88% * 100;
 Minibatch[1801-1900]: loss = 0.535530 * 100, metric = 8.30% * 100;
 Minibatch[1901-2000]: loss = 0.513382 * 100, metric = 7.98% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.526257 * 2000, metric = 8.15% * 2000 743.606s (  2.7 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 15.53% * 2000;
 Minibatch[   1- 100]: loss = 0.511262 * 100, metric = 7.86% * 100;
 Minibatch[ 101- 200]: loss = 0.532340 * 100, metric = 8.31% * 100;
 Minibatch[ 201- 300]: loss = 0.530005 * 100, metric = 8.43% * 100;
 Minibatch[ 301- 400]: loss = 0.527048 * 100, metric = 8.06% * 100;
 Minibatch[ 401- 500]: loss = 0.537991 * 100, metric = 7.99% * 100;
 Minibatch[ 501- 600]: loss = 0.514264 * 100, metric = 7.89% * 100;
 Minibatch[ 601- 700]: loss = 0.504122 * 100, metric = 7.72% * 100;
 Minibatch[ 701- 800]: loss = 0.522454 * 100, metric = 7.96% * 100;
 Minibatch[ 801- 900]: loss = 0.520986 * 100, metric = 7.96% * 100;
 Minibatch[ 901-1000]: loss = 0.521190 * 100, metric = 8.04% * 100;
 Minibatch[1001-1100]: loss = 0.505585 * 100, metric = 7.82% * 100;
 Minibatch[1101-1200]: loss = 0.532183 * 100, metric = 8.21% * 100;
 Minibatch[1201-1300]: loss = 0.535422 * 100, metric = 8.11% * 100;
 Minibatch[1301-1400]: loss = 0.496217 * 100, metric = 7.72% * 100;
 Minibatch[1401-1500]: loss = 0.518574 * 100, metric = 8.12% * 100;
 Minibatch[1501-1600]: loss = 0.512568 * 100, metric = 7.81% * 100;
 Minibatch[1601-1700]: loss = 0.521398 * 100, metric = 7.78% * 100;
 Minibatch[1701-1800]: loss = 0.498820 * 100, metric = 7.67% * 100;
 Minibatch[1801-1900]: loss = 0.527222 * 100, metric = 8.42% * 100;
 Minibatch[1901-2000]: loss = 0.533678 * 100, metric = 8.51% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.520166 * 2000, metric = 8.02% * 2000 738.426s (  2.7 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 15.23% * 2000;
0.6491285799741745
 Minibatch[   1- 100]: loss = 0.496234 * 100, metric = 7.47% * 100;
 Minibatch[ 101- 200]: loss = 0.529051 * 100, metric = 8.13% * 100;
 Minibatch[ 201- 300]: loss = 0.496133 * 100, metric = 7.53% * 100;
 Minibatch[ 301- 400]: loss = 0.511301 * 100, metric = 7.83% * 100;
 Minibatch[ 401- 500]: loss = 0.499397 * 100, metric = 7.42% * 100;
 Minibatch[ 501- 600]: loss = 0.506806 * 100, metric = 7.77% * 100;
 Minibatch[ 601- 700]: loss = 0.515689 * 100, metric = 7.84% * 100;
 Minibatch[ 701- 800]: loss = 0.502755 * 100, metric = 7.66% * 100;
 Minibatch[ 801- 900]: loss = 0.511912 * 100, metric = 7.67% * 100;
 Minibatch[ 901-1000]: loss = 0.521069 * 100, metric = 7.79% * 100;
 Minibatch[1001-1100]: loss = 0.518071 * 100, metric = 8.03% * 100;
 Minibatch[1101-1200]: loss = 0.513867 * 100, metric = 7.82% * 100;
 Minibatch[1201-1300]: loss = 0.525804 * 100, metric = 8.25% * 100;
 Minibatch[1301-1400]: loss = 0.523622 * 100, metric = 7.94% * 100;
 Minibatch[1401-1500]: loss = 0.495494 * 100, metric = 7.26% * 100;
 Minibatch[1501-1600]: loss = 0.520604 * 100, metric = 7.88% * 100;
 Minibatch[1601-1700]: loss = 0.495338 * 100, metric = 7.42% * 100;
 Minibatch[1701-1800]: loss = 0.502111 * 100, metric = 7.60% * 100;
 Minibatch[1801-1900]: loss = 0.486246 * 100, metric = 7.52% * 100;
 Minibatch[1901-2000]: loss = 0.500103 * 100, metric = 7.54% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.508580 * 2000, metric = 7.72% * 2000 734.993s (  2.7 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.74% * 2000;
 Minibatch[   1- 100]: loss = 0.511500 * 100, metric = 7.94% * 100;
 Minibatch[ 101- 200]: loss = 0.524957 * 100, metric = 7.84% * 100;
 Minibatch[ 201- 300]: loss = 0.493274 * 100, metric = 7.34% * 100;
 Minibatch[ 301- 400]: loss = 0.518331 * 100, metric = 8.00% * 100;
 Minibatch[ 401- 500]: loss = 0.513252 * 100, metric = 7.70% * 100;
 Minibatch[ 501- 600]: loss = 0.495440 * 100, metric = 7.28% * 100;
 Minibatch[ 601- 700]: loss = 0.517245 * 100, metric = 8.02% * 100;
 Minibatch[ 701- 800]: loss = 0.491074 * 100, metric = 7.64% * 100;
 Minibatch[ 801- 900]: loss = 0.526638 * 100, metric = 8.14% * 100;
 Minibatch[ 901-1000]: loss = 0.491476 * 100, metric = 7.26% * 100;
 Minibatch[1001-1100]: loss = 0.519588 * 100, metric = 7.83% * 100;
 Minibatch[1101-1200]: loss = 0.507896 * 100, metric = 7.99% * 100;
 Minibatch[1201-1300]: loss = 0.507473 * 100, metric = 7.71% * 100;
 Minibatch[1301-1400]: loss = 0.503453 * 100, metric = 7.57% * 100;
 Minibatch[1401-1500]: loss = 0.519291 * 100, metric = 7.92% * 100;
 Minibatch[1501-1600]: loss = 0.522459 * 100, metric = 7.92% * 100;
 Minibatch[1601-1700]: loss = 0.503588 * 100, metric = 7.74% * 100;
 Minibatch[1701-1800]: loss = 0.488563 * 100, metric = 7.32% * 100;
 Minibatch[1801-1900]: loss = 0.500842 * 100, metric = 7.47% * 100;
 Minibatch[1901-2000]: loss = 0.489786 * 100, metric = 7.24% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.507306 * 2000, metric = 7.69% * 2000 733.960s (  2.7 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 15.12% * 2000;
 Minibatch[   1- 100]: loss = 0.496229 * 100, metric = 7.31% * 100;
 Minibatch[ 101- 200]: loss = 0.497310 * 100, metric = 7.29% * 100;
 Minibatch[ 201- 300]: loss = 0.493312 * 100, metric = 7.07% * 100;
 Minibatch[ 301- 400]: loss = 0.518942 * 100, metric = 7.67% * 100;
 Minibatch[ 401- 500]: loss = 0.501344 * 100, metric = 7.52% * 100;
 Minibatch[ 501- 600]: loss = 0.499628 * 100, metric = 7.59% * 100;
 Minibatch[ 601- 700]: loss = 0.511613 * 100, metric = 7.74% * 100;
 Minibatch[ 701- 800]: loss = 0.505085 * 100, metric = 7.79% * 100;
 Minibatch[ 801- 900]: loss = 0.520263 * 100, metric = 7.91% * 100;
 Minibatch[ 901-1000]: loss = 0.519853 * 100, metric = 7.52% * 100;
 Minibatch[1001-1100]: loss = 0.482821 * 100, metric = 7.10% * 100;
 Minibatch[1101-1200]: loss = 0.491136 * 100, metric = 7.22% * 100;
 Minibatch[1201-1300]: loss = 0.515405 * 100, metric = 7.62% * 100;
 Minibatch[1301-1400]: loss = 0.502890 * 100, metric = 7.81% * 100;
 Minibatch[1401-1500]: loss = 0.488336 * 100, metric = 7.59% * 100;
 Minibatch[1501-1600]: loss = 0.507516 * 100, metric = 7.46% * 100;
 Minibatch[1601-1700]: loss = 0.495042 * 100, metric = 7.50% * 100;
 Minibatch[1701-1800]: loss = 0.499517 * 100, metric = 7.49% * 100;
 Minibatch[1801-1900]: loss = 0.492961 * 100, metric = 7.44% * 100;
 Minibatch[1901-2000]: loss = 0.490796 * 100, metric = 7.41% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.501500 * 2000, metric = 7.50% * 2000 733.927s (  2.7 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 16.14% * 2000;
 Minibatch[   1- 100]: loss = 0.503708 * 100, metric = 7.72% * 100;
 Minibatch[ 101- 200]: loss = 0.505150 * 100, metric = 7.71% * 100;
 Minibatch[ 201- 300]: loss = 0.493682 * 100, metric = 7.49% * 100;
 Minibatch[ 301- 400]: loss = 0.511090 * 100, metric = 7.74% * 100;
 Minibatch[ 401- 500]: loss = 0.492905 * 100, metric = 7.55% * 100;
 Minibatch[ 501- 600]: loss = 0.490578 * 100, metric = 7.33% * 100;
 Minibatch[ 601- 700]: loss = 0.492021 * 100, metric = 7.20% * 100;
 Minibatch[ 701- 800]: loss = 0.464560 * 100, metric = 6.86% * 100;
 Minibatch[ 801- 900]: loss = 0.499225 * 100, metric = 7.48% * 100;
 Minibatch[ 901-1000]: loss = 0.486052 * 100, metric = 7.41% * 100;
 Minibatch[1001-1100]: loss = 0.497037 * 100, metric = 7.40% * 100;
 Minibatch[1101-1200]: loss = 0.486545 * 100, metric = 7.12% * 100;
 Minibatch[1201-1300]: loss = 0.491054 * 100, metric = 7.38% * 100;
 Minibatch[1301-1400]: loss = 0.492402 * 100, metric = 7.15% * 100;
 Minibatch[1401-1500]: loss = 0.494456 * 100, metric = 7.38% * 100;
 Minibatch[1501-1600]: loss = 0.509911 * 100, metric = 8.09% * 100;
 Minibatch[1601-1700]: loss = 0.490701 * 100, metric = 7.57% * 100;
 Minibatch[1701-1800]: loss = 0.482162 * 100, metric = 7.24% * 100;
 Minibatch[1801-1900]: loss = 0.506352 * 100, metric = 7.89% * 100;
 Minibatch[1901-2000]: loss = 0.468141 * 100, metric = 6.96% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.492887 * 2000, metric = 7.43% * 2000 734.669s (  2.7 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 14.53% * 2000;
0.6408612399473786
 Minibatch[   1- 100]: loss = 0.499200 * 100, metric = 7.67% * 100;
 Minibatch[ 101- 200]: loss = 0.487976 * 100, metric = 7.21% * 100;
 Minibatch[ 201- 300]: loss = 0.499102 * 100, metric = 7.66% * 100;
 Minibatch[ 301- 400]: loss = 0.481727 * 100, metric = 7.25% * 100;
 Minibatch[ 401- 500]: loss = 0.478201 * 100, metric = 7.27% * 100;
 Minibatch[ 501- 600]: loss = 0.490483 * 100, metric = 7.33% * 100;
 Minibatch[ 601- 700]: loss = 0.475879 * 100, metric = 7.05% * 100;
 Minibatch[ 701- 800]: loss = 0.482792 * 100, metric = 7.15% * 100;
 Minibatch[ 801- 900]: loss = 0.498116 * 100, metric = 7.66% * 100;
 Minibatch[ 901-1000]: loss = 0.502140 * 100, metric = 7.68% * 100;
 Minibatch[1001-1100]: loss = 0.479583 * 100, metric = 7.09% * 100;
 Minibatch[1101-1200]: loss = 0.469095 * 100, metric = 6.79% * 100;
 Minibatch[1201-1300]: loss = 0.485129 * 100, metric = 7.28% * 100;
 Minibatch[1301-1400]: loss = 0.490172 * 100, metric = 7.30% * 100;
 Minibatch[1401-1500]: loss = 0.480408 * 100, metric = 7.09% * 100;
 Minibatch[1501-1600]: loss = 0.472656 * 100, metric = 6.93% * 100;
 Minibatch[1601-1700]: loss = 0.483273 * 100, metric = 7.03% * 100;
 Minibatch[1701-1800]: loss = 0.481210 * 100, metric = 7.13% * 100;
 Minibatch[1801-1900]: loss = 0.489012 * 100, metric = 7.19% * 100;
 Minibatch[1901-2000]: loss = 0.481902 * 100, metric = 7.09% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.485403 * 2000, metric = 7.24% * 2000 726.620s (  2.8 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 15.29% * 2000;
 Minibatch[   1- 100]: loss = 0.492376 * 100, metric = 7.34% * 100;
 Minibatch[ 101- 200]: loss = 0.495256 * 100, metric = 7.70% * 100;
 Minibatch[ 201- 300]: loss = 0.480796 * 100, metric = 7.05% * 100;
 Minibatch[ 301- 400]: loss = 0.495050 * 100, metric = 7.36% * 100;
 Minibatch[ 401- 500]: loss = 0.493636 * 100, metric = 7.47% * 100;
 Minibatch[ 501- 600]: loss = 0.480250 * 100, metric = 7.16% * 100;
 Minibatch[ 601- 700]: loss = 0.491742 * 100, metric = 7.20% * 100;
 Minibatch[ 701- 800]: loss = 0.483476 * 100, metric = 6.98% * 100;
 Minibatch[ 801- 900]: loss = 0.462161 * 100, metric = 6.92% * 100;
 Minibatch[ 901-1000]: loss = 0.486758 * 100, metric = 7.30% * 100;
 Minibatch[1001-1100]: loss = 0.477295 * 100, metric = 7.03% * 100;
 Minibatch[1101-1200]: loss = 0.476393 * 100, metric = 7.07% * 100;
 Minibatch[1201-1300]: loss = 0.486114 * 100, metric = 7.12% * 100;
 Minibatch[1301-1400]: loss = 0.491702 * 100, metric = 7.42% * 100;
 Minibatch[1401-1500]: loss = 0.472965 * 100, metric = 7.01% * 100;
 Minibatch[1501-1600]: loss = 0.478635 * 100, metric = 6.98% * 100;
 Minibatch[1601-1700]: loss = 0.477470 * 100, metric = 7.23% * 100;
 Minibatch[1701-1800]: loss = 0.481609 * 100, metric = 7.23% * 100;
 Minibatch[1801-1900]: loss = 0.476669 * 100, metric = 7.30% * 100;
 Minibatch[1901-2000]: loss = 0.482369 * 100, metric = 6.99% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.483136 * 2000, metric = 7.19% * 2000 728.124s (  2.7 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 15.50% * 2000;
 Minibatch[   1- 100]: loss = 0.460410 * 100, metric = 6.93% * 100;
 Minibatch[ 101- 200]: loss = 0.482081 * 100, metric = 7.14% * 100;
 Minibatch[ 201- 300]: loss = 0.465447 * 100, metric = 7.05% * 100;
 Minibatch[ 301- 400]: loss = 0.478374 * 100, metric = 7.04% * 100;
 Minibatch[ 401- 500]: loss = 0.475330 * 100, metric = 6.97% * 100;
 Minibatch[ 501- 600]: loss = 0.462997 * 100, metric = 6.86% * 100;
 Minibatch[ 601- 700]: loss = 0.486698 * 100, metric = 7.26% * 100;
 Minibatch[ 701- 800]: loss = 0.476972 * 100, metric = 7.10% * 100;
 Minibatch[ 801- 900]: loss = 0.485367 * 100, metric = 7.41% * 100;
 Minibatch[ 901-1000]: loss = 0.475824 * 100, metric = 7.11% * 100;
 Minibatch[1001-1100]: loss = 0.481804 * 100, metric = 7.29% * 100;
 Minibatch[1101-1200]: loss = 0.492407 * 100, metric = 7.45% * 100;
 Minibatch[1201-1300]: loss = 0.489709 * 100, metric = 7.31% * 100;
 Minibatch[1301-1400]: loss = 0.477469 * 100, metric = 7.02% * 100;
 Minibatch[1401-1500]: loss = 0.466395 * 100, metric = 6.74% * 100;
 Minibatch[1501-1600]: loss = 0.481981 * 100, metric = 7.38% * 100;
 Minibatch[1601-1700]: loss = 0.470964 * 100, metric = 6.86% * 100;
 Minibatch[1701-1800]: loss = 0.466462 * 100, metric = 7.01% * 100;
 Minibatch[1801-1900]: loss = 0.483954 * 100, metric = 7.37% * 100;
 Minibatch[1901-2000]: loss = 0.490030 * 100, metric = 7.29% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.477534 * 2000, metric = 7.13% * 2000 726.744s (  2.8 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.32% * 2000;
 Minibatch[   1- 100]: loss = 0.483990 * 100, metric = 7.21% * 100;
 Minibatch[ 101- 200]: loss = 0.479694 * 100, metric = 7.37% * 100;
 Minibatch[ 201- 300]: loss = 0.477576 * 100, metric = 7.42% * 100;
 Minibatch[ 301- 400]: loss = 0.482635 * 100, metric = 7.24% * 100;
 Minibatch[ 401- 500]: loss = 0.488308 * 100, metric = 7.33% * 100;
 Minibatch[ 501- 600]: loss = 0.477183 * 100, metric = 7.03% * 100;
 Minibatch[ 601- 700]: loss = 0.486488 * 100, metric = 7.37% * 100;
 Minibatch[ 701- 800]: loss = 0.472039 * 100, metric = 6.88% * 100;
 Minibatch[ 801- 900]: loss = 0.471492 * 100, metric = 6.85% * 100;
 Minibatch[ 901-1000]: loss = 0.475621 * 100, metric = 7.15% * 100;
 Minibatch[1001-1100]: loss = 0.483992 * 100, metric = 7.30% * 100;
 Minibatch[1101-1200]: loss = 0.487975 * 100, metric = 7.41% * 100;
 Minibatch[1201-1300]: loss = 0.504457 * 100, metric = 7.73% * 100;
 Minibatch[1301-1400]: loss = 0.466749 * 100, metric = 6.67% * 100;
 Minibatch[1401-1500]: loss = 0.478026 * 100, metric = 6.76% * 100;
 Minibatch[1501-1600]: loss = 0.489085 * 100, metric = 7.48% * 100;
 Minibatch[1601-1700]: loss = 0.473727 * 100, metric = 7.02% * 100;
 Minibatch[1701-1800]: loss = 0.485480 * 100, metric = 7.27% * 100;
 Minibatch[1801-1900]: loss = 0.463552 * 100, metric = 6.80% * 100;
 Minibatch[1901-2000]: loss = 0.456559 * 100, metric = 6.79% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.479231 * 2000, metric = 7.16% * 2000 725.413s (  2.8 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.00% * 2000;
0.6407929641269148
 Minibatch[   1- 100]: loss = 0.483297 * 100, metric = 7.23% * 100;
 Minibatch[ 101- 200]: loss = 0.458333 * 100, metric = 6.69% * 100;
 Minibatch[ 201- 300]: loss = 0.474790 * 100, metric = 7.28% * 100;
 Minibatch[ 301- 400]: loss = 0.467497 * 100, metric = 6.92% * 100;
 Minibatch[ 401- 500]: loss = 0.466875 * 100, metric = 7.05% * 100;
 Minibatch[ 501- 600]: loss = 0.462374 * 100, metric = 6.66% * 100;
 Minibatch[ 601- 700]: loss = 0.479845 * 100, metric = 7.06% * 100;
 Minibatch[ 701- 800]: loss = 0.462487 * 100, metric = 7.09% * 100;
 Minibatch[ 801- 900]: loss = 0.463389 * 100, metric = 6.54% * 100;
 Minibatch[ 901-1000]: loss = 0.462008 * 100, metric = 6.57% * 100;
 Minibatch[1001-1100]: loss = 0.478154 * 100, metric = 7.56% * 100;
 Minibatch[1101-1200]: loss = 0.488546 * 100, metric = 7.45% * 100;
 Minibatch[1201-1300]: loss = 0.466423 * 100, metric = 7.03% * 100;
 Minibatch[1301-1400]: loss = 0.458381 * 100, metric = 6.67% * 100;
 Minibatch[1401-1500]: loss = 0.463069 * 100, metric = 6.83% * 100;
 Minibatch[1501-1600]: loss = 0.466963 * 100, metric = 6.52% * 100;
 Minibatch[1601-1700]: loss = 0.496923 * 100, metric = 7.60% * 100;
 Minibatch[1701-1800]: loss = 0.479165 * 100, metric = 7.25% * 100;
 Minibatch[1801-1900]: loss = 0.466573 * 100, metric = 6.88% * 100;
 Minibatch[1901-2000]: loss = 0.469206 * 100, metric = 6.92% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.470715 * 2000, metric = 6.99% * 2000 720.601s (  2.8 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.37% * 2000;
 Minibatch[   1- 100]: loss = 0.469477 * 100, metric = 6.97% * 100;
 Minibatch[ 101- 200]: loss = 0.483856 * 100, metric = 7.17% * 100;
 Minibatch[ 201- 300]: loss = 0.462729 * 100, metric = 6.95% * 100;
 Minibatch[ 301- 400]: loss = 0.461404 * 100, metric = 6.82% * 100;
 Minibatch[ 401- 500]: loss = 0.465125 * 100, metric = 6.65% * 100;
 Minibatch[ 501- 600]: loss = 0.456546 * 100, metric = 6.70% * 100;
 Minibatch[ 601- 700]: loss = 0.464565 * 100, metric = 6.74% * 100;
 Minibatch[ 701- 800]: loss = 0.469765 * 100, metric = 6.87% * 100;
 Minibatch[ 801- 900]: loss = 0.471384 * 100, metric = 6.96% * 100;
 Minibatch[ 901-1000]: loss = 0.466543 * 100, metric = 7.19% * 100;
 Minibatch[1001-1100]: loss = 0.462787 * 100, metric = 6.70% * 100;
 Minibatch[1101-1200]: loss = 0.484813 * 100, metric = 7.02% * 100;
 Minibatch[1201-1300]: loss = 0.464641 * 100, metric = 6.95% * 100;
 Minibatch[1301-1400]: loss = 0.474731 * 100, metric = 7.42% * 100;
 Minibatch[1401-1500]: loss = 0.464130 * 100, metric = 6.99% * 100;
 Minibatch[1501-1600]: loss = 0.469815 * 100, metric = 6.89% * 100;
 Minibatch[1601-1700]: loss = 0.446562 * 100, metric = 6.49% * 100;
 Minibatch[1701-1800]: loss = 0.457142 * 100, metric = 6.46% * 100;
 Minibatch[1801-1900]: loss = 0.459314 * 100, metric = 6.77% * 100;
 Minibatch[1901-2000]: loss = 0.474766 * 100, metric = 6.84% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.466505 * 2000, metric = 6.88% * 2000 724.244s (  2.8 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.75% * 2000;
0.6232784413546324
 Minibatch[   1- 100]: loss = 0.467807 * 100, metric = 6.99% * 100;
 Minibatch[ 101- 200]: loss = 0.455818 * 100, metric = 6.38% * 100;
 Minibatch[ 201- 300]: loss = 0.465450 * 100, metric = 6.77% * 100;
 Minibatch[ 301- 400]: loss = 0.469521 * 100, metric = 6.87% * 100;
 Minibatch[ 401- 500]: loss = 0.456223 * 100, metric = 6.65% * 100;
 Minibatch[ 501- 600]: loss = 0.480109 * 100, metric = 7.29% * 100;
 Minibatch[ 601- 700]: loss = 0.458483 * 100, metric = 6.55% * 100;
 Minibatch[ 701- 800]: loss = 0.449328 * 100, metric = 6.52% * 100;
 Minibatch[ 801- 900]: loss = 0.466195 * 100, metric = 6.95% * 100;
 Minibatch[ 901-1000]: loss = 0.472720 * 100, metric = 7.14% * 100;
 Minibatch[1001-1100]: loss = 0.465579 * 100, metric = 6.85% * 100;
 Minibatch[1101-1200]: loss = 0.459368 * 100, metric = 6.52% * 100;
 Minibatch[1201-1300]: loss = 0.464927 * 100, metric = 6.93% * 100;
 Minibatch[1301-1400]: loss = 0.452871 * 100, metric = 6.53% * 100;
 Minibatch[1401-1500]: loss = 0.477994 * 100, metric = 6.85% * 100;
 Minibatch[1501-1600]: loss = 0.457805 * 100, metric = 6.62% * 100;
 Minibatch[1601-1700]: loss = 0.455945 * 100, metric = 6.54% * 100;
 Minibatch[1701-1800]: loss = 0.459314 * 100, metric = 6.82% * 100;
 Minibatch[1801-1900]: loss = 0.458986 * 100, metric = 6.83% * 100;
 Minibatch[1901-2000]: loss = 0.460059 * 100, metric = 6.78% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.462725 * 2000, metric = 6.77% * 2000 722.630s (  2.8 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 12.90% * 2000;
0.6096752821430564
 Minibatch[   1- 100]: loss = 0.450988 * 100, metric = 6.57% * 100;
 Minibatch[ 101- 200]: loss = 0.454621 * 100, metric = 6.60% * 100;
 Minibatch[ 201- 300]: loss = 0.455493 * 100, metric = 6.73% * 100;
 Minibatch[ 301- 400]: loss = 0.481202 * 100, metric = 6.99% * 100;
 Minibatch[ 401- 500]: loss = 0.453271 * 100, metric = 6.24% * 100;
 Minibatch[ 501- 600]: loss = 0.457706 * 100, metric = 6.75% * 100;
 Minibatch[ 601- 700]: loss = 0.450545 * 100, metric = 6.67% * 100;
 Minibatch[ 701- 800]: loss = 0.465204 * 100, metric = 6.84% * 100;
 Minibatch[ 801- 900]: loss = 0.465278 * 100, metric = 6.92% * 100;
 Minibatch[ 901-1000]: loss = 0.457502 * 100, metric = 6.68% * 100;
 Minibatch[1001-1100]: loss = 0.456732 * 100, metric = 6.82% * 100;
 Minibatch[1101-1200]: loss = 0.439868 * 100, metric = 6.33% * 100;
 Minibatch[1201-1300]: loss = 0.456208 * 100, metric = 6.75% * 100;
 Minibatch[1301-1400]: loss = 0.447916 * 100, metric = 6.47% * 100;
 Minibatch[1401-1500]: loss = 0.478475 * 100, metric = 6.96% * 100;
 Minibatch[1501-1600]: loss = 0.439747 * 100, metric = 6.21% * 100;
 Minibatch[1601-1700]: loss = 0.467228 * 100, metric = 6.96% * 100;
 Minibatch[1701-1800]: loss = 0.444963 * 100, metric = 6.47% * 100;
 Minibatch[1801-1900]: loss = 0.474301 * 100, metric = 7.00% * 100;
 Minibatch[1901-2000]: loss = 0.460703 * 100, metric = 6.73% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.457898 * 2000, metric = 6.68% * 2000 720.747s (  2.8 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 15.06% * 2000;
 Minibatch[   1- 100]: loss = 0.482534 * 100, metric = 6.91% * 100;
 Minibatch[ 101- 200]: loss = 0.434012 * 100, metric = 5.95% * 100;
 Minibatch[ 201- 300]: loss = 0.445935 * 100, metric = 6.59% * 100;
 Minibatch[ 301- 400]: loss = 0.458960 * 100, metric = 6.85% * 100;
 Minibatch[ 401- 500]: loss = 0.458733 * 100, metric = 6.59% * 100;
 Minibatch[ 501- 600]: loss = 0.430932 * 100, metric = 5.98% * 100;
 Minibatch[ 601- 700]: loss = 0.459834 * 100, metric = 6.84% * 100;
 Minibatch[ 701- 800]: loss = 0.452486 * 100, metric = 6.41% * 100;
 Minibatch[ 801- 900]: loss = 0.467747 * 100, metric = 6.85% * 100;
 Minibatch[ 901-1000]: loss = 0.438371 * 100, metric = 6.43% * 100;
 Minibatch[1001-1100]: loss = 0.454266 * 100, metric = 6.56% * 100;
 Minibatch[1101-1200]: loss = 0.472159 * 100, metric = 6.93% * 100;
 Minibatch[1201-1300]: loss = 0.450002 * 100, metric = 6.63% * 100;
 Minibatch[1301-1400]: loss = 0.451770 * 100, metric = 6.37% * 100;
 Minibatch[1401-1500]: loss = 0.446585 * 100, metric = 6.45% * 100;
 Minibatch[1501-1600]: loss = 0.465475 * 100, metric = 6.77% * 100;
 Minibatch[1601-1700]: loss = 0.463052 * 100, metric = 6.74% * 100;
 Minibatch[1701-1800]: loss = 0.462733 * 100, metric = 6.63% * 100;
 Minibatch[1801-1900]: loss = 0.453826 * 100, metric = 6.39% * 100;
 Minibatch[1901-2000]: loss = 0.468022 * 100, metric = 7.08% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.455872 * 2000, metric = 6.60% * 2000 717.642s (  2.8 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.57% * 2000;
 Minibatch[   1- 100]: loss = 0.445277 * 100, metric = 6.27% * 100;
 Minibatch[ 101- 200]: loss = 0.463987 * 100, metric = 6.83% * 100;
 Minibatch[ 201- 300]: loss = 0.448061 * 100, metric = 6.59% * 100;
 Minibatch[ 301- 400]: loss = 0.443522 * 100, metric = 6.52% * 100;
 Minibatch[ 401- 500]: loss = 0.449260 * 100, metric = 6.69% * 100;
 Minibatch[ 501- 600]: loss = 0.451698 * 100, metric = 6.63% * 100;
 Minibatch[ 601- 700]: loss = 0.474988 * 100, metric = 7.06% * 100;
 Minibatch[ 701- 800]: loss = 0.470700 * 100, metric = 6.99% * 100;
 Minibatch[ 801- 900]: loss = 0.458835 * 100, metric = 6.78% * 100;
 Minibatch[ 901-1000]: loss = 0.447675 * 100, metric = 6.55% * 100;
 Minibatch[1001-1100]: loss = 0.443647 * 100, metric = 6.29% * 100;
 Minibatch[1101-1200]: loss = 0.462450 * 100, metric = 6.84% * 100;
 Minibatch[1201-1300]: loss = 0.459561 * 100, metric = 6.80% * 100;
 Minibatch[1301-1400]: loss = 0.450345 * 100, metric = 6.45% * 100;
 Minibatch[1401-1500]: loss = 0.457541 * 100, metric = 6.75% * 100;
 Minibatch[1501-1600]: loss = 0.440578 * 100, metric = 6.29% * 100;
 Minibatch[1601-1700]: loss = 0.456406 * 100, metric = 6.72% * 100;
 Minibatch[1701-1800]: loss = 0.451598 * 100, metric = 6.71% * 100;
 Minibatch[1801-1900]: loss = 0.460798 * 100, metric = 6.86% * 100;
 Minibatch[1901-2000]: loss = 0.453932 * 100, metric = 6.41% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.454543 * 2000, metric = 6.65% * 2000 719.372s (  2.8 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 13.61% * 2000;
 Minibatch[   1- 100]: loss = 0.452846 * 100, metric = 6.73% * 100;
 Minibatch[ 101- 200]: loss = 0.460780 * 100, metric = 6.54% * 100;
 Minibatch[ 201- 300]: loss = 0.462857 * 100, metric = 6.96% * 100;
 Minibatch[ 301- 400]: loss = 0.469754 * 100, metric = 6.85% * 100;
 Minibatch[ 401- 500]: loss = 0.461766 * 100, metric = 6.91% * 100;
 Minibatch[ 501- 600]: loss = 0.452566 * 100, metric = 6.78% * 100;
 Minibatch[ 601- 700]: loss = 0.444815 * 100, metric = 6.44% * 100;
 Minibatch[ 701- 800]: loss = 0.448310 * 100, metric = 6.61% * 100;
 Minibatch[ 801- 900]: loss = 0.444028 * 100, metric = 6.61% * 100;
 Minibatch[ 901-1000]: loss = 0.439494 * 100, metric = 6.28% * 100;
 Minibatch[1001-1100]: loss = 0.439125 * 100, metric = 6.19% * 100;
 Minibatch[1101-1200]: loss = 0.452109 * 100, metric = 6.70% * 100;
 Minibatch[1201-1300]: loss = 0.464554 * 100, metric = 6.85% * 100;
 Minibatch[1301-1400]: loss = 0.455153 * 100, metric = 6.84% * 100;
 Minibatch[1401-1500]: loss = 0.451553 * 100, metric = 6.75% * 100;
 Minibatch[1501-1600]: loss = 0.456790 * 100, metric = 6.61% * 100;
 Minibatch[1601-1700]: loss = 0.441174 * 100, metric = 6.32% * 100;
 Minibatch[1701-1800]: loss = 0.463109 * 100, metric = 6.87% * 100;
 Minibatch[1801-1900]: loss = 0.449164 * 100, metric = 6.50% * 100;
 Minibatch[1901-2000]: loss = 0.454931 * 100, metric = 6.89% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.453244 * 2000, metric = 6.66% * 2000 720.230s (  2.8 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.82% * 2000;
 Minibatch[   1- 100]: loss = 0.463358 * 100, metric = 6.89% * 100;
 Minibatch[ 101- 200]: loss = 0.444473 * 100, metric = 6.59% * 100;
 Minibatch[ 201- 300]: loss = 0.436165 * 100, metric = 6.43% * 100;
 Minibatch[ 301- 400]: loss = 0.451568 * 100, metric = 6.77% * 100;
 Minibatch[ 401- 500]: loss = 0.440515 * 100, metric = 6.51% * 100;
 Minibatch[ 501- 600]: loss = 0.447642 * 100, metric = 6.50% * 100;
 Minibatch[ 601- 700]: loss = 0.452301 * 100, metric = 6.74% * 100;
 Minibatch[ 701- 800]: loss = 0.451203 * 100, metric = 6.66% * 100;
 Minibatch[ 801- 900]: loss = 0.448559 * 100, metric = 6.53% * 100;
 Minibatch[ 901-1000]: loss = 0.431605 * 100, metric = 6.19% * 100;
 Minibatch[1001-1100]: loss = 0.440492 * 100, metric = 6.38% * 100;
 Minibatch[1101-1200]: loss = 0.428988 * 100, metric = 6.09% * 100;
 Minibatch[1201-1300]: loss = 0.455739 * 100, metric = 6.53% * 100;
 Minibatch[1301-1400]: loss = 0.435478 * 100, metric = 6.18% * 100;
 Minibatch[1401-1500]: loss = 0.465351 * 100, metric = 6.85% * 100;
 Minibatch[1501-1600]: loss = 0.461063 * 100, metric = 6.66% * 100;
 Minibatch[1601-1700]: loss = 0.451946 * 100, metric = 6.47% * 100;
 Minibatch[1701-1800]: loss = 0.443829 * 100, metric = 6.44% * 100;
 Minibatch[1801-1900]: loss = 0.443437 * 100, metric = 6.40% * 100;
 Minibatch[1901-2000]: loss = 0.469841 * 100, metric = 7.02% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.448178 * 2000, metric = 6.54% * 2000 716.412s (  2.8 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.39% * 2000;
 Minibatch[   1- 100]: loss = 0.454407 * 100, metric = 6.48% * 100;
 Minibatch[ 101- 200]: loss = 0.455421 * 100, metric = 6.66% * 100;
 Minibatch[ 201- 300]: loss = 0.442204 * 100, metric = 6.58% * 100;
 Minibatch[ 301- 400]: loss = 0.447992 * 100, metric = 6.64% * 100;
 Minibatch[ 401- 500]: loss = 0.439182 * 100, metric = 6.42% * 100;
 Minibatch[ 501- 600]: loss = 0.446160 * 100, metric = 6.46% * 100;
 Minibatch[ 601- 700]: loss = 0.459455 * 100, metric = 6.82% * 100;
 Minibatch[ 701- 800]: loss = 0.440843 * 100, metric = 6.33% * 100;
 Minibatch[ 801- 900]: loss = 0.430811 * 100, metric = 5.90% * 100;
 Minibatch[ 901-1000]: loss = 0.438493 * 100, metric = 6.57% * 100;
 Minibatch[1001-1100]: loss = 0.451967 * 100, metric = 6.77% * 100;
 Minibatch[1101-1200]: loss = 0.451339 * 100, metric = 6.72% * 100;
 Minibatch[1201-1300]: loss = 0.452474 * 100, metric = 6.64% * 100;
 Minibatch[1301-1400]: loss = 0.450522 * 100, metric = 6.64% * 100;
 Minibatch[1401-1500]: loss = 0.456890 * 100, metric = 6.80% * 100;
 Minibatch[1501-1600]: loss = 0.454590 * 100, metric = 6.44% * 100;
 Minibatch[1601-1700]: loss = 0.463842 * 100, metric = 7.01% * 100;
 Minibatch[1701-1800]: loss = 0.450742 * 100, metric = 6.55% * 100;
 Minibatch[1801-1900]: loss = 0.448643 * 100, metric = 6.67% * 100;
 Minibatch[1901-2000]: loss = 0.459817 * 100, metric = 6.57% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.449790 * 2000, metric = 6.58% * 2000 713.086s (  2.8 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.15% * 2000;
 Minibatch[   1- 100]: loss = 0.424274 * 100, metric = 6.07% * 100;
 Minibatch[ 101- 200]: loss = 0.444481 * 100, metric = 6.46% * 100;
 Minibatch[ 201- 300]: loss = 0.448948 * 100, metric = 6.67% * 100;
 Minibatch[ 301- 400]: loss = 0.429734 * 100, metric = 6.00% * 100;
 Minibatch[ 401- 500]: loss = 0.440677 * 100, metric = 6.40% * 100;
 Minibatch[ 501- 600]: loss = 0.418105 * 100, metric = 6.12% * 100;
 Minibatch[ 601- 700]: loss = 0.453497 * 100, metric = 6.57% * 100;
 Minibatch[ 701- 800]: loss = 0.420822 * 100, metric = 5.98% * 100;
 Minibatch[ 801- 900]: loss = 0.449004 * 100, metric = 6.47% * 100;
 Minibatch[ 901-1000]: loss = 0.427853 * 100, metric = 6.09% * 100;
 Minibatch[1001-1100]: loss = 0.453677 * 100, metric = 6.64% * 100;
 Minibatch[1101-1200]: loss = 0.440123 * 100, metric = 6.30% * 100;
 Minibatch[1201-1300]: loss = 0.452599 * 100, metric = 6.51% * 100;
 Minibatch[1301-1400]: loss = 0.447502 * 100, metric = 6.58% * 100;
 Minibatch[1401-1500]: loss = 0.437549 * 100, metric = 6.03% * 100;
 Minibatch[1501-1600]: loss = 0.444433 * 100, metric = 6.53% * 100;
 Minibatch[1601-1700]: loss = 0.447737 * 100, metric = 6.56% * 100;
 Minibatch[1701-1800]: loss = 0.433805 * 100, metric = 6.12% * 100;
 Minibatch[1801-1900]: loss = 0.447213 * 100, metric = 6.59% * 100;
 Minibatch[1901-2000]: loss = 0.427849 * 100, metric = 5.98% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.439494 * 2000, metric = 6.33% * 2000 712.431s (  2.8 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.67% * 2000;
 Minibatch[   1- 100]: loss = 0.430329 * 100, metric = 6.05% * 100;
 Minibatch[ 101- 200]: loss = 0.414628 * 100, metric = 5.86% * 100;
 Minibatch[ 201- 300]: loss = 0.452180 * 100, metric = 6.73% * 100;
 Minibatch[ 301- 400]: loss = 0.433490 * 100, metric = 6.29% * 100;
 Minibatch[ 401- 500]: loss = 0.434586 * 100, metric = 6.21% * 100;
 Minibatch[ 501- 600]: loss = 0.436701 * 100, metric = 6.19% * 100;
 Minibatch[ 601- 700]: loss = 0.448451 * 100, metric = 6.32% * 100;
 Minibatch[ 701- 800]: loss = 0.418638 * 100, metric = 6.01% * 100;
 Minibatch[ 801- 900]: loss = 0.432968 * 100, metric = 6.51% * 100;
 Minibatch[ 901-1000]: loss = 0.445065 * 100, metric = 6.67% * 100;
 Minibatch[1001-1100]: loss = 0.447004 * 100, metric = 6.88% * 100;
 Minibatch[1101-1200]: loss = 0.433014 * 100, metric = 6.45% * 100;
 Minibatch[1201-1300]: loss = 0.442783 * 100, metric = 6.53% * 100;
 Minibatch[1301-1400]: loss = 0.422734 * 100, metric = 5.98% * 100;
 Minibatch[1401-1500]: loss = 0.429274 * 100, metric = 6.27% * 100;
 Minibatch[1501-1600]: loss = 0.433877 * 100, metric = 6.18% * 100;
 Minibatch[1601-1700]: loss = 0.449946 * 100, metric = 6.62% * 100;
 Minibatch[1701-1800]: loss = 0.451166 * 100, metric = 6.24% * 100;
 Minibatch[1801-1900]: loss = 0.437204 * 100, metric = 6.34% * 100;
 Minibatch[1901-2000]: loss = 0.430535 * 100, metric = 6.04% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.436229 * 2000, metric = 6.32% * 2000 708.319s (  2.8 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.22% * 2000;
 Minibatch[   1- 100]: loss = 0.436536 * 100, metric = 6.41% * 100;
 Minibatch[ 101- 200]: loss = 0.444148 * 100, metric = 6.78% * 100;
 Minibatch[ 201- 300]: loss = 0.434764 * 100, metric = 6.36% * 100;
 Minibatch[ 301- 400]: loss = 0.434472 * 100, metric = 6.17% * 100;
 Minibatch[ 401- 500]: loss = 0.436971 * 100, metric = 6.44% * 100;
 Minibatch[ 501- 600]: loss = 0.427639 * 100, metric = 6.19% * 100;
 Minibatch[ 601- 700]: loss = 0.432869 * 100, metric = 6.21% * 100;
 Minibatch[ 701- 800]: loss = 0.442845 * 100, metric = 6.53% * 100;
 Minibatch[ 801- 900]: loss = 0.447829 * 100, metric = 6.44% * 100;
 Minibatch[ 901-1000]: loss = 0.433378 * 100, metric = 6.03% * 100;
 Minibatch[1001-1100]: loss = 0.430796 * 100, metric = 6.46% * 100;
 Minibatch[1101-1200]: loss = 0.452678 * 100, metric = 6.86% * 100;
 Minibatch[1201-1300]: loss = 0.451357 * 100, metric = 6.64% * 100;
 Minibatch[1301-1400]: loss = 0.439777 * 100, metric = 6.13% * 100;
 Minibatch[1401-1500]: loss = 0.437621 * 100, metric = 6.54% * 100;
 Minibatch[1501-1600]: loss = 0.423341 * 100, metric = 5.98% * 100;
 Minibatch[1601-1700]: loss = 0.437162 * 100, metric = 6.37% * 100;
 Minibatch[1701-1800]: loss = 0.432278 * 100, metric = 6.00% * 100;
 Minibatch[1801-1900]: loss = 0.441209 * 100, metric = 6.47% * 100;
 Minibatch[1901-2000]: loss = 0.435314 * 100, metric = 6.29% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.437649 * 2000, metric = 6.36% * 2000 710.588s (  2.8 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.77% * 2000;
 Minibatch[   1- 100]: loss = 0.437695 * 100, metric = 6.43% * 100;
 Minibatch[ 101- 200]: loss = 0.434588 * 100, metric = 6.40% * 100;
 Minibatch[ 201- 300]: loss = 0.416307 * 100, metric = 5.78% * 100;
 Minibatch[ 301- 400]: loss = 0.423394 * 100, metric = 6.18% * 100;
 Minibatch[ 401- 500]: loss = 0.434735 * 100, metric = 6.22% * 100;
 Minibatch[ 501- 600]: loss = 0.433094 * 100, metric = 6.08% * 100;
 Minibatch[ 601- 700]: loss = 0.432853 * 100, metric = 6.22% * 100;
 Minibatch[ 701- 800]: loss = 0.427316 * 100, metric = 6.13% * 100;
 Minibatch[ 801- 900]: loss = 0.437397 * 100, metric = 6.23% * 100;
 Minibatch[ 901-1000]: loss = 0.437986 * 100, metric = 6.28% * 100;
 Minibatch[1001-1100]: loss = 0.446160 * 100, metric = 6.46% * 100;
 Minibatch[1101-1200]: loss = 0.421624 * 100, metric = 6.11% * 100;
 Minibatch[1201-1300]: loss = 0.427758 * 100, metric = 6.45% * 100;
 Minibatch[1301-1400]: loss = 0.444994 * 100, metric = 6.34% * 100;
 Minibatch[1401-1500]: loss = 0.439085 * 100, metric = 6.33% * 100;
 Minibatch[1501-1600]: loss = 0.450922 * 100, metric = 6.54% * 100;
 Minibatch[1601-1700]: loss = 0.421945 * 100, metric = 6.07% * 100;
 Minibatch[1701-1800]: loss = 0.431534 * 100, metric = 6.38% * 100;
 Minibatch[1801-1900]: loss = 0.439302 * 100, metric = 6.35% * 100;
 Minibatch[1901-2000]: loss = 0.440596 * 100, metric = 6.16% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.433964 * 2000, metric = 6.26% * 2000 715.656s (  2.8 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 13.14% * 2000;
 Minibatch[   1- 100]: loss = 0.427199 * 100, metric = 6.10% * 100;
 Minibatch[ 101- 200]: loss = 0.440030 * 100, metric = 6.29% * 100;
 Minibatch[ 201- 300]: loss = 0.434114 * 100, metric = 6.27% * 100;
 Minibatch[ 301- 400]: loss = 0.427034 * 100, metric = 6.12% * 100;
 Minibatch[ 401- 500]: loss = 0.427567 * 100, metric = 6.31% * 100;
 Minibatch[ 501- 600]: loss = 0.438862 * 100, metric = 6.37% * 100;
 Minibatch[ 601- 700]: loss = 0.428326 * 100, metric = 6.40% * 100;
 Minibatch[ 701- 800]: loss = 0.436273 * 100, metric = 6.23% * 100;
 Minibatch[ 801- 900]: loss = 0.414883 * 100, metric = 5.77% * 100;
 Minibatch[ 901-1000]: loss = 0.422020 * 100, metric = 5.94% * 100;
 Minibatch[1001-1100]: loss = 0.434379 * 100, metric = 6.41% * 100;
 Minibatch[1101-1200]: loss = 0.437638 * 100, metric = 6.60% * 100;
 Minibatch[1201-1300]: loss = 0.440207 * 100, metric = 6.26% * 100;
 Minibatch[1301-1400]: loss = 0.442421 * 100, metric = 6.49% * 100;
 Minibatch[1401-1500]: loss = 0.440648 * 100, metric = 6.45% * 100;
 Minibatch[1501-1600]: loss = 0.439948 * 100, metric = 6.38% * 100;
 Minibatch[1601-1700]: loss = 0.437408 * 100, metric = 6.34% * 100;
 Minibatch[1701-1800]: loss = 0.439615 * 100, metric = 6.54% * 100;
 Minibatch[1801-1900]: loss = 0.425803 * 100, metric = 6.17% * 100;
 Minibatch[1901-2000]: loss = 0.426921 * 100, metric = 6.09% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.433065 * 2000, metric = 6.28% * 2000 711.058s (  2.8 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.24% * 2000;
 Minibatch[   1- 100]: loss = 0.422622 * 100, metric = 6.19% * 100;
 Minibatch[ 101- 200]: loss = 0.428440 * 100, metric = 6.21% * 100;
 Minibatch[ 201- 300]: loss = 0.434643 * 100, metric = 6.16% * 100;
 Minibatch[ 301- 400]: loss = 0.432956 * 100, metric = 6.37% * 100;
 Minibatch[ 401- 500]: loss = 0.432999 * 100, metric = 6.18% * 100;
 Minibatch[ 501- 600]: loss = 0.418925 * 100, metric = 6.18% * 100;
 Minibatch[ 601- 700]: loss = 0.449075 * 100, metric = 6.53% * 100;
 Minibatch[ 701- 800]: loss = 0.427094 * 100, metric = 5.94% * 100;
 Minibatch[ 801- 900]: loss = 0.432661 * 100, metric = 6.26% * 100;
 Minibatch[ 901-1000]: loss = 0.428790 * 100, metric = 6.08% * 100;
 Minibatch[1001-1100]: loss = 0.436848 * 100, metric = 6.38% * 100;
 Minibatch[1101-1200]: loss = 0.434101 * 100, metric = 6.16% * 100;
 Minibatch[1201-1300]: loss = 0.432711 * 100, metric = 6.19% * 100;
 Minibatch[1301-1400]: loss = 0.432042 * 100, metric = 6.24% * 100;
 Minibatch[1401-1500]: loss = 0.423011 * 100, metric = 6.14% * 100;
 Minibatch[1501-1600]: loss = 0.436442 * 100, metric = 6.29% * 100;
 Minibatch[1601-1700]: loss = 0.427133 * 100, metric = 5.98% * 100;
 Minibatch[1701-1800]: loss = 0.422606 * 100, metric = 5.99% * 100;
 Minibatch[1801-1900]: loss = 0.414858 * 100, metric = 5.72% * 100;
 Minibatch[1901-2000]: loss = 0.432399 * 100, metric = 6.23% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.430018 * 2000, metric = 6.17% * 2000 706.917s (  2.8 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 13.58% * 2000;
 Minibatch[   1- 100]: loss = 0.433730 * 100, metric = 6.32% * 100;
 Minibatch[ 101- 200]: loss = 0.429636 * 100, metric = 6.03% * 100;
 Minibatch[ 201- 300]: loss = 0.436045 * 100, metric = 6.29% * 100;
 Minibatch[ 301- 400]: loss = 0.438258 * 100, metric = 6.59% * 100;
 Minibatch[ 401- 500]: loss = 0.429401 * 100, metric = 6.28% * 100;
 Minibatch[ 501- 600]: loss = 0.424662 * 100, metric = 6.03% * 100;
 Minibatch[ 601- 700]: loss = 0.432125 * 100, metric = 6.35% * 100;
 Minibatch[ 701- 800]: loss = 0.424067 * 100, metric = 6.16% * 100;
 Minibatch[ 801- 900]: loss = 0.421664 * 100, metric = 6.19% * 100;
 Minibatch[ 901-1000]: loss = 0.418758 * 100, metric = 6.05% * 100;
 Minibatch[1001-1100]: loss = 0.426562 * 100, metric = 5.98% * 100;
 Minibatch[1101-1200]: loss = 0.450859 * 100, metric = 6.37% * 100;
 Minibatch[1201-1300]: loss = 0.430707 * 100, metric = 6.14% * 100;
 Minibatch[1301-1400]: loss = 0.409034 * 100, metric = 5.80% * 100;
 Minibatch[1401-1500]: loss = 0.424592 * 100, metric = 6.12% * 100;
 Minibatch[1501-1600]: loss = 0.425829 * 100, metric = 6.00% * 100;
 Minibatch[1601-1700]: loss = 0.433116 * 100, metric = 6.26% * 100;
 Minibatch[1701-1800]: loss = 0.433700 * 100, metric = 6.33% * 100;
 Minibatch[1801-1900]: loss = 0.431400 * 100, metric = 6.32% * 100;
 Minibatch[1901-2000]: loss = 0.420013 * 100, metric = 5.98% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.428708 * 2000, metric = 6.18% * 2000 715.011s (  2.8 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 13.61% * 2000;
 Minibatch[   1- 100]: loss = 0.421383 * 100, metric = 5.95% * 100;
 Minibatch[ 101- 200]: loss = 0.419770 * 100, metric = 6.22% * 100;
 Minibatch[ 201- 300]: loss = 0.422536 * 100, metric = 6.14% * 100;
 Minibatch[ 301- 400]: loss = 0.416412 * 100, metric = 5.87% * 100;
 Minibatch[ 401- 500]: loss = 0.416596 * 100, metric = 5.98% * 100;
 Minibatch[ 501- 600]: loss = 0.428248 * 100, metric = 6.03% * 100;
 Minibatch[ 601- 700]: loss = 0.421149 * 100, metric = 6.05% * 100;
 Minibatch[ 701- 800]: loss = 0.413730 * 100, metric = 5.94% * 100;
 Minibatch[ 801- 900]: loss = 0.409333 * 100, metric = 5.74% * 100;
 Minibatch[ 901-1000]: loss = 0.428142 * 100, metric = 6.21% * 100;
 Minibatch[1001-1100]: loss = 0.418212 * 100, metric = 6.22% * 100;
 Minibatch[1101-1200]: loss = 0.413801 * 100, metric = 5.89% * 100;
 Minibatch[1201-1300]: loss = 0.417903 * 100, metric = 5.90% * 100;
 Minibatch[1301-1400]: loss = 0.429014 * 100, metric = 6.18% * 100;
 Minibatch[1401-1500]: loss = 0.420972 * 100, metric = 5.88% * 100;
 Minibatch[1501-1600]: loss = 0.425984 * 100, metric = 5.75% * 100;
 Minibatch[1601-1700]: loss = 0.430720 * 100, metric = 6.28% * 100;
 Minibatch[1701-1800]: loss = 0.430409 * 100, metric = 6.32% * 100;
 Minibatch[1801-1900]: loss = 0.425711 * 100, metric = 6.12% * 100;
 Minibatch[1901-2000]: loss = 0.424542 * 100, metric = 6.09% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.421728 * 2000, metric = 6.04% * 2000 705.912s (  2.8 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 13.26% * 2000;
 Minibatch[   1- 100]: loss = 0.430595 * 100, metric = 6.26% * 100;
 Minibatch[ 101- 200]: loss = 0.409871 * 100, metric = 5.62% * 100;
 Minibatch[ 201- 300]: loss = 0.432229 * 100, metric = 6.10% * 100;
 Minibatch[ 301- 400]: loss = 0.424258 * 100, metric = 6.00% * 100;
 Minibatch[ 401- 500]: loss = 0.415219 * 100, metric = 5.81% * 100;
 Minibatch[ 501- 600]: loss = 0.411795 * 100, metric = 6.00% * 100;
 Minibatch[ 601- 700]: loss = 0.431823 * 100, metric = 6.35% * 100;
 Minibatch[ 701- 800]: loss = 0.415023 * 100, metric = 6.07% * 100;
 Minibatch[ 801- 900]: loss = 0.415319 * 100, metric = 5.85% * 100;
 Minibatch[ 901-1000]: loss = 0.426767 * 100, metric = 6.15% * 100;
 Minibatch[1001-1100]: loss = 0.424087 * 100, metric = 6.19% * 100;
 Minibatch[1101-1200]: loss = 0.411947 * 100, metric = 5.89% * 100;
 Minibatch[1201-1300]: loss = 0.435352 * 100, metric = 6.49% * 100;
 Minibatch[1301-1400]: loss = 0.428703 * 100, metric = 6.33% * 100;
 Minibatch[1401-1500]: loss = 0.415074 * 100, metric = 5.94% * 100;
 Minibatch[1501-1600]: loss = 0.429488 * 100, metric = 6.02% * 100;
 Minibatch[1601-1700]: loss = 0.425322 * 100, metric = 6.29% * 100;
 Minibatch[1701-1800]: loss = 0.419654 * 100, metric = 6.03% * 100;
 Minibatch[1801-1900]: loss = 0.430873 * 100, metric = 6.26% * 100;
 Minibatch[1901-2000]: loss = 0.416236 * 100, metric = 5.98% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.422482 * 2000, metric = 6.08% * 2000 707.456s (  2.8 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 13.36% * 2000;
 Minibatch[   1- 100]: loss = 0.420158 * 100, metric = 6.13% * 100;
 Minibatch[ 101- 200]: loss = 0.420947 * 100, metric = 6.12% * 100;
 Minibatch[ 201- 300]: loss = 0.417602 * 100, metric = 5.95% * 100;
 Minibatch[ 301- 400]: loss = 0.440419 * 100, metric = 6.28% * 100;
 Minibatch[ 401- 500]: loss = 0.437514 * 100, metric = 6.04% * 100;
 Minibatch[ 501- 600]: loss = 0.416772 * 100, metric = 5.89% * 100;
 Minibatch[ 601- 700]: loss = 0.434084 * 100, metric = 6.27% * 100;
 Minibatch[ 701- 800]: loss = 0.402863 * 100, metric = 5.43% * 100;
 Minibatch[ 801- 900]: loss = 0.415642 * 100, metric = 5.89% * 100;
 Minibatch[ 901-1000]: loss = 0.415044 * 100, metric = 5.76% * 100;
 Minibatch[1001-1100]: loss = 0.420724 * 100, metric = 5.72% * 100;
 Minibatch[1101-1200]: loss = 0.407030 * 100, metric = 5.58% * 100;
 Minibatch[1201-1300]: loss = 0.424991 * 100, metric = 5.86% * 100;
 Minibatch[1301-1400]: loss = 0.412820 * 100, metric = 5.63% * 100;
 Minibatch[1401-1500]: loss = 0.412938 * 100, metric = 5.75% * 100;
 Minibatch[1501-1600]: loss = 0.404907 * 100, metric = 5.71% * 100;
 Minibatch[1601-1700]: loss = 0.417278 * 100, metric = 5.84% * 100;
 Minibatch[1701-1800]: loss = 0.429084 * 100, metric = 6.38% * 100;
 Minibatch[1801-1900]: loss = 0.417317 * 100, metric = 5.74% * 100;
 Minibatch[1901-2000]: loss = 0.415101 * 100, metric = 5.90% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.419162 * 2000, metric = 5.89% * 2000 712.439s (  2.8 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 13.46% * 2000;
 Minibatch[   1- 100]: loss = 0.425897 * 100, metric = 5.96% * 100;
 Minibatch[ 101- 200]: loss = 0.419075 * 100, metric = 5.86% * 100;
 Minibatch[ 201- 300]: loss = 0.417960 * 100, metric = 5.97% * 100;
 Minibatch[ 301- 400]: loss = 0.426845 * 100, metric = 6.12% * 100;
 Minibatch[ 401- 500]: loss = 0.418159 * 100, metric = 6.01% * 100;
 Minibatch[ 501- 600]: loss = 0.404551 * 100, metric = 5.43% * 100;
 Minibatch[ 601- 700]: loss = 0.403079 * 100, metric = 5.55% * 100;
 Minibatch[ 701- 800]: loss = 0.406620 * 100, metric = 5.98% * 100;
 Minibatch[ 801- 900]: loss = 0.436830 * 100, metric = 6.43% * 100;
 Minibatch[ 901-1000]: loss = 0.414012 * 100, metric = 5.91% * 100;
 Minibatch[1001-1100]: loss = 0.404878 * 100, metric = 5.52% * 100;
 Minibatch[1101-1200]: loss = 0.428063 * 100, metric = 5.97% * 100;
 Minibatch[1201-1300]: loss = 0.416384 * 100, metric = 5.79% * 100;
 Minibatch[1301-1400]: loss = 0.418340 * 100, metric = 5.88% * 100;
 Minibatch[1401-1500]: loss = 0.419775 * 100, metric = 5.85% * 100;
 Minibatch[1501-1600]: loss = 0.416413 * 100, metric = 5.77% * 100;
 Minibatch[1601-1700]: loss = 0.404617 * 100, metric = 5.81% * 100;
 Minibatch[1701-1800]: loss = 0.417667 * 100, metric = 5.90% * 100;
 Minibatch[1801-1900]: loss = 0.427698 * 100, metric = 6.18% * 100;
 Minibatch[1901-2000]: loss = 0.413199 * 100, metric = 5.74% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.417003 * 2000, metric = 5.88% * 2000 712.688s (  2.8 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 13.57% * 2000;
 Minibatch[   1- 100]: loss = 0.403946 * 100, metric = 5.77% * 100;
 Minibatch[ 101- 200]: loss = 0.424314 * 100, metric = 6.06% * 100;
 Minibatch[ 201- 300]: loss = 0.411810 * 100, metric = 5.83% * 100;
 Minibatch[ 301- 400]: loss = 0.424738 * 100, metric = 6.15% * 100;
 Minibatch[ 401- 500]: loss = 0.412723 * 100, metric = 5.85% * 100;
 Minibatch[ 501- 600]: loss = 0.405465 * 100, metric = 5.79% * 100;
 Minibatch[ 601- 700]: loss = 0.402108 * 100, metric = 5.59% * 100;
 Minibatch[ 701- 800]: loss = 0.401129 * 100, metric = 5.43% * 100;
 Minibatch[ 801- 900]: loss = 0.410584 * 100, metric = 5.84% * 100;
 Minibatch[ 901-1000]: loss = 0.417293 * 100, metric = 5.75% * 100;
 Minibatch[1001-1100]: loss = 0.399213 * 100, metric = 5.52% * 100;
 Minibatch[1101-1200]: loss = 0.423072 * 100, metric = 6.12% * 100;
 Minibatch[1201-1300]: loss = 0.414700 * 100, metric = 5.67% * 100;
 Minibatch[1301-1400]: loss = 0.418441 * 100, metric = 5.94% * 100;
 Minibatch[1401-1500]: loss = 0.405277 * 100, metric = 5.74% * 100;
 Minibatch[1501-1600]: loss = 0.413458 * 100, metric = 5.90% * 100;
 Minibatch[1601-1700]: loss = 0.402653 * 100, metric = 5.56% * 100;
 Minibatch[1701-1800]: loss = 0.420399 * 100, metric = 6.08% * 100;
 Minibatch[1801-1900]: loss = 0.411110 * 100, metric = 5.53% * 100;
 Minibatch[1901-2000]: loss = 0.412982 * 100, metric = 5.72% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.411771 * 2000, metric = 5.79% * 2000 704.741s (  2.8 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 13.65% * 2000;
 Minibatch[   1- 100]: loss = 0.409754 * 100, metric = 5.74% * 100;
 Minibatch[ 101- 200]: loss = 0.401389 * 100, metric = 5.75% * 100;
 Minibatch[ 201- 300]: loss = 0.417959 * 100, metric = 6.01% * 100;
 Minibatch[ 301- 400]: loss = 0.407884 * 100, metric = 5.48% * 100;
 Minibatch[ 401- 500]: loss = 0.409062 * 100, metric = 5.75% * 100;
 Minibatch[ 501- 600]: loss = 0.404738 * 100, metric = 5.78% * 100;
 Minibatch[ 601- 700]: loss = 0.414829 * 100, metric = 5.85% * 100;
 Minibatch[ 701- 800]: loss = 0.415885 * 100, metric = 6.06% * 100;
 Minibatch[ 801- 900]: loss = 0.415303 * 100, metric = 5.64% * 100;
 Minibatch[ 901-1000]: loss = 0.411975 * 100, metric = 5.66% * 100;
 Minibatch[1001-1100]: loss = 0.424028 * 100, metric = 6.20% * 100;
 Minibatch[1101-1200]: loss = 0.410211 * 100, metric = 5.75% * 100;
 Minibatch[1201-1300]: loss = 0.396033 * 100, metric = 5.46% * 100;
 Minibatch[1301-1400]: loss = 0.406677 * 100, metric = 5.81% * 100;
 Minibatch[1401-1500]: loss = 0.427842 * 100, metric = 6.08% * 100;
 Minibatch[1501-1600]: loss = 0.417097 * 100, metric = 5.89% * 100;
 Minibatch[1601-1700]: loss = 0.414538 * 100, metric = 5.61% * 100;
 Minibatch[1701-1800]: loss = 0.427476 * 100, metric = 6.32% * 100;
 Minibatch[1801-1900]: loss = 0.418929 * 100, metric = 6.08% * 100;
 Minibatch[1901-2000]: loss = 0.426375 * 100, metric = 6.15% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.413899 * 2000, metric = 5.85% * 2000 697.124s (  2.9 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 12.39% * 2000;
 Minibatch[   1- 100]: loss = 0.414829 * 100, metric = 5.90% * 100;
 Minibatch[ 101- 200]: loss = 0.422943 * 100, metric = 5.97% * 100;
 Minibatch[ 201- 300]: loss = 0.399081 * 100, metric = 5.74% * 100;
 Minibatch[ 301- 400]: loss = 0.404917 * 100, metric = 5.71% * 100;
 Minibatch[ 401- 500]: loss = 0.414793 * 100, metric = 5.98% * 100;
 Minibatch[ 501- 600]: loss = 0.426195 * 100, metric = 6.28% * 100;
 Minibatch[ 601- 700]: loss = 0.428036 * 100, metric = 6.11% * 100;
 Minibatch[ 701- 800]: loss = 0.411122 * 100, metric = 5.79% * 100;
 Minibatch[ 801- 900]: loss = 0.404784 * 100, metric = 5.55% * 100;
 Minibatch[ 901-1000]: loss = 0.413316 * 100, metric = 6.01% * 100;
 Minibatch[1001-1100]: loss = 0.407389 * 100, metric = 5.93% * 100;
 Minibatch[1101-1200]: loss = 0.407430 * 100, metric = 5.85% * 100;
 Minibatch[1201-1300]: loss = 0.414805 * 100, metric = 5.86% * 100;
 Minibatch[1301-1400]: loss = 0.403101 * 100, metric = 5.78% * 100;
 Minibatch[1401-1500]: loss = 0.422469 * 100, metric = 6.15% * 100;
 Minibatch[1501-1600]: loss = 0.414724 * 100, metric = 5.98% * 100;
 Minibatch[1601-1700]: loss = 0.396192 * 100, metric = 5.40% * 100;
 Minibatch[1701-1800]: loss = 0.410388 * 100, metric = 5.75% * 100;
 Minibatch[1801-1900]: loss = 0.413997 * 100, metric = 5.84% * 100;
 Minibatch[1901-2000]: loss = 0.393788 * 100, metric = 5.40% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.411215 * 2000, metric = 5.85% * 2000 699.134s (  2.9 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 13.18% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
