Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.344656 * 100, metric = 26.21% * 100;
 Minibatch[ 101- 200]: loss = 1.106892 * 100, metric = 22.62% * 100;
 Minibatch[ 201- 300]: loss = 1.020316 * 100, metric = 21.70% * 100;
 Minibatch[ 301- 400]: loss = 0.999523 * 100, metric = 20.92% * 100;
 Minibatch[ 401- 500]: loss = 0.913191 * 100, metric = 18.73% * 100;
 Minibatch[ 501- 600]: loss = 0.891075 * 100, metric = 17.38% * 100;
 Minibatch[ 601- 700]: loss = 0.863603 * 100, metric = 17.10% * 100;
 Minibatch[ 701- 800]: loss = 0.820962 * 100, metric = 15.87% * 100;
 Minibatch[ 801- 900]: loss = 0.846981 * 100, metric = 16.35% * 100;
 Minibatch[ 901-1000]: loss = 0.849683 * 100, metric = 16.81% * 100;
 Minibatch[1001-1100]: loss = 0.827952 * 100, metric = 16.21% * 100;
 Minibatch[1101-1200]: loss = 0.827148 * 100, metric = 15.96% * 100;
 Minibatch[1201-1300]: loss = 0.821409 * 100, metric = 16.29% * 100;
 Minibatch[1301-1400]: loss = 0.795920 * 100, metric = 15.11% * 100;
 Minibatch[1401-1500]: loss = 0.799692 * 100, metric = 15.25% * 100;
 Minibatch[1501-1600]: loss = 0.783434 * 100, metric = 14.76% * 100;
 Minibatch[1601-1700]: loss = 0.779725 * 100, metric = 14.91% * 100;
 Minibatch[1701-1800]: loss = 0.776407 * 100, metric = 14.48% * 100;
 Minibatch[1801-1900]: loss = 0.783302 * 100, metric = 15.12% * 100;
 Minibatch[1901-2000]: loss = 0.758090 * 100, metric = 14.34% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.880498 * 2000, metric = 17.30% * 2000 1029.938s (  1.9 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 24.77% * 2000;
0.8554988794252276
 Minibatch[   1- 100]: loss = 0.769316 * 100, metric = 14.41% * 100;
 Minibatch[ 101- 200]: loss = 0.774441 * 100, metric = 14.54% * 100;
 Minibatch[ 201- 300]: loss = 0.774477 * 100, metric = 13.96% * 100;
 Minibatch[ 301- 400]: loss = 0.775785 * 100, metric = 14.15% * 100;
 Minibatch[ 401- 500]: loss = 0.775826 * 100, metric = 14.35% * 100;
 Minibatch[ 501- 600]: loss = 0.777665 * 100, metric = 13.85% * 100;
 Minibatch[ 601- 700]: loss = 0.721229 * 100, metric = 13.51% * 100;
 Minibatch[ 701- 800]: loss = 0.756864 * 100, metric = 14.27% * 100;
 Minibatch[ 801- 900]: loss = 0.735482 * 100, metric = 13.60% * 100;
 Minibatch[ 901-1000]: loss = 0.727511 * 100, metric = 13.30% * 100;
 Minibatch[1001-1100]: loss = 0.743761 * 100, metric = 13.93% * 100;
 Minibatch[1101-1200]: loss = 0.752740 * 100, metric = 13.63% * 100;
 Minibatch[1201-1300]: loss = 0.735049 * 100, metric = 13.56% * 100;
 Minibatch[1301-1400]: loss = 0.741635 * 100, metric = 13.64% * 100;
 Minibatch[1401-1500]: loss = 0.720070 * 100, metric = 12.88% * 100;
 Minibatch[1501-1600]: loss = 0.716188 * 100, metric = 12.96% * 100;
 Minibatch[1601-1700]: loss = 0.715251 * 100, metric = 13.03% * 100;
 Minibatch[1701-1800]: loss = 0.717921 * 100, metric = 13.38% * 100;
 Minibatch[1801-1900]: loss = 0.727778 * 100, metric = 13.08% * 100;
 Minibatch[1901-2000]: loss = 0.686686 * 100, metric = 12.46% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.742284 * 2000, metric = 13.62% * 2000 981.223s (  2.0 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 21.27% * 2000;
0.7692602514475584
 Minibatch[   1- 100]: loss = 0.719502 * 100, metric = 13.23% * 100;
 Minibatch[ 101- 200]: loss = 0.728272 * 100, metric = 13.37% * 100;
 Minibatch[ 201- 300]: loss = 0.707240 * 100, metric = 12.81% * 100;
 Minibatch[ 301- 400]: loss = 0.717881 * 100, metric = 13.37% * 100;
 Minibatch[ 401- 500]: loss = 0.718806 * 100, metric = 12.90% * 100;
 Minibatch[ 501- 600]: loss = 0.713606 * 100, metric = 12.77% * 100;
 Minibatch[ 601- 700]: loss = 0.719024 * 100, metric = 12.96% * 100;
 Minibatch[ 701- 800]: loss = 0.694444 * 100, metric = 12.11% * 100;
 Minibatch[ 801- 900]: loss = 0.718845 * 100, metric = 13.10% * 100;
 Minibatch[ 901-1000]: loss = 0.683433 * 100, metric = 12.63% * 100;
 Minibatch[1001-1100]: loss = 0.706307 * 100, metric = 12.93% * 100;
 Minibatch[1101-1200]: loss = 0.695411 * 100, metric = 12.43% * 100;
 Minibatch[1201-1300]: loss = 0.696425 * 100, metric = 12.61% * 100;
 Minibatch[1301-1400]: loss = 0.706992 * 100, metric = 13.04% * 100;
 Minibatch[1401-1500]: loss = 0.706884 * 100, metric = 12.83% * 100;
 Minibatch[1501-1600]: loss = 0.679849 * 100, metric = 12.05% * 100;
 Minibatch[1601-1700]: loss = 0.674453 * 100, metric = 11.90% * 100;
 Minibatch[1701-1800]: loss = 0.703840 * 100, metric = 12.99% * 100;
 Minibatch[1801-1900]: loss = 0.684413 * 100, metric = 12.06% * 100;
 Minibatch[1901-2000]: loss = 0.673981 * 100, metric = 12.04% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.702480 * 2000, metric = 12.71% * 2000 966.426s (  2.1 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 20.21% * 2000;
0.7394673167094589
 Minibatch[   1- 100]: loss = 0.697520 * 100, metric = 12.10% * 100;
 Minibatch[ 101- 200]: loss = 0.661714 * 100, metric = 11.89% * 100;
 Minibatch[ 201- 300]: loss = 0.696832 * 100, metric = 12.45% * 100;
 Minibatch[ 301- 400]: loss = 0.655039 * 100, metric = 11.54% * 100;
 Minibatch[ 401- 500]: loss = 0.681744 * 100, metric = 12.12% * 100;
 Minibatch[ 501- 600]: loss = 0.662895 * 100, metric = 11.54% * 100;
 Minibatch[ 601- 700]: loss = 0.658578 * 100, metric = 11.81% * 100;
 Minibatch[ 701- 800]: loss = 0.676275 * 100, metric = 12.03% * 100;
 Minibatch[ 801- 900]: loss = 0.671186 * 100, metric = 12.12% * 100;
 Minibatch[ 901-1000]: loss = 0.680549 * 100, metric = 12.22% * 100;
 Minibatch[1001-1100]: loss = 0.688793 * 100, metric = 12.38% * 100;
 Minibatch[1101-1200]: loss = 0.649909 * 100, metric = 11.75% * 100;
 Minibatch[1201-1300]: loss = 0.659587 * 100, metric = 11.65% * 100;
 Minibatch[1301-1400]: loss = 0.680291 * 100, metric = 12.19% * 100;
 Minibatch[1401-1500]: loss = 0.685568 * 100, metric = 12.52% * 100;
 Minibatch[1501-1600]: loss = 0.644843 * 100, metric = 11.21% * 100;
 Minibatch[1601-1700]: loss = 0.676637 * 100, metric = 12.21% * 100;
 Minibatch[1701-1800]: loss = 0.676178 * 100, metric = 12.27% * 100;
 Minibatch[1801-1900]: loss = 0.660763 * 100, metric = 11.89% * 100;
 Minibatch[1901-2000]: loss = 0.650178 * 100, metric = 11.46% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.670754 * 2000, metric = 11.97% * 2000 960.744s (  2.1 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 23.12% * 2000;
 Minibatch[   1- 100]: loss = 0.673232 * 100, metric = 12.00% * 100;
 Minibatch[ 101- 200]: loss = 0.660264 * 100, metric = 11.94% * 100;
 Minibatch[ 201- 300]: loss = 0.651619 * 100, metric = 11.65% * 100;
 Minibatch[ 301- 400]: loss = 0.676304 * 100, metric = 12.32% * 100;
 Minibatch[ 401- 500]: loss = 0.643581 * 100, metric = 11.14% * 100;
 Minibatch[ 501- 600]: loss = 0.635667 * 100, metric = 11.12% * 100;
 Minibatch[ 601- 700]: loss = 0.645779 * 100, metric = 11.29% * 100;
 Minibatch[ 701- 800]: loss = 0.656119 * 100, metric = 11.38% * 100;
 Minibatch[ 801- 900]: loss = 0.641877 * 100, metric = 11.02% * 100;
 Minibatch[ 901-1000]: loss = 0.644470 * 100, metric = 11.59% * 100;
 Minibatch[1001-1100]: loss = 0.664695 * 100, metric = 11.70% * 100;
 Minibatch[1101-1200]: loss = 0.638919 * 100, metric = 11.32% * 100;
 Minibatch[1201-1300]: loss = 0.657344 * 100, metric = 11.72% * 100;
 Minibatch[1301-1400]: loss = 0.680718 * 100, metric = 12.22% * 100;
 Minibatch[1401-1500]: loss = 0.651662 * 100, metric = 11.55% * 100;
 Minibatch[1501-1600]: loss = 0.658473 * 100, metric = 11.75% * 100;
 Minibatch[1601-1700]: loss = 0.668076 * 100, metric = 12.13% * 100;
 Minibatch[1701-1800]: loss = 0.679120 * 100, metric = 12.62% * 100;
 Minibatch[1801-1900]: loss = 0.664469 * 100, metric = 11.86% * 100;
 Minibatch[1901-2000]: loss = 0.643584 * 100, metric = 11.33% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.656799 * 2000, metric = 11.68% * 2000 960.856s (  2.1 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 19.94% * 2000;
0.7217755993902684
 Minibatch[   1- 100]: loss = 0.637973 * 100, metric = 11.48% * 100;
 Minibatch[ 101- 200]: loss = 0.626511 * 100, metric = 11.09% * 100;
 Minibatch[ 201- 300]: loss = 0.644803 * 100, metric = 11.36% * 100;
 Minibatch[ 301- 400]: loss = 0.646622 * 100, metric = 11.15% * 100;
 Minibatch[ 401- 500]: loss = 0.620886 * 100, metric = 11.06% * 100;
 Minibatch[ 501- 600]: loss = 0.636968 * 100, metric = 11.44% * 100;
 Minibatch[ 601- 700]: loss = 0.620840 * 100, metric = 11.08% * 100;
 Minibatch[ 701- 800]: loss = 0.632026 * 100, metric = 10.90% * 100;
 Minibatch[ 801- 900]: loss = 0.630452 * 100, metric = 11.15% * 100;
 Minibatch[ 901-1000]: loss = 0.624154 * 100, metric = 11.24% * 100;
 Minibatch[1001-1100]: loss = 0.619935 * 100, metric = 10.59% * 100;
 Minibatch[1101-1200]: loss = 0.636766 * 100, metric = 11.11% * 100;
 Minibatch[1201-1300]: loss = 0.639351 * 100, metric = 11.37% * 100;
 Minibatch[1301-1400]: loss = 0.620467 * 100, metric = 10.98% * 100;
 Minibatch[1401-1500]: loss = 0.623813 * 100, metric = 11.00% * 100;
 Minibatch[1501-1600]: loss = 0.612077 * 100, metric = 10.26% * 100;
 Minibatch[1601-1700]: loss = 0.622804 * 100, metric = 10.77% * 100;
 Minibatch[1701-1800]: loss = 0.615278 * 100, metric = 10.60% * 100;
 Minibatch[1801-1900]: loss = 0.630293 * 100, metric = 11.12% * 100;
 Minibatch[1901-2000]: loss = 0.621235 * 100, metric = 10.65% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.628163 * 2000, metric = 11.02% * 2000 956.730s (  2.1 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.66% * 2000;
 Minibatch[   1- 100]: loss = 0.619172 * 100, metric = 10.78% * 100;
 Minibatch[ 101- 200]: loss = 0.628429 * 100, metric = 11.01% * 100;
 Minibatch[ 201- 300]: loss = 0.635035 * 100, metric = 11.38% * 100;
 Minibatch[ 301- 400]: loss = 0.622588 * 100, metric = 10.77% * 100;
 Minibatch[ 401- 500]: loss = 0.631180 * 100, metric = 10.83% * 100;
 Minibatch[ 501- 600]: loss = 0.611277 * 100, metric = 10.57% * 100;
 Minibatch[ 601- 700]: loss = 0.633612 * 100, metric = 10.77% * 100;
 Minibatch[ 701- 800]: loss = 0.626150 * 100, metric = 10.63% * 100;
 Minibatch[ 801- 900]: loss = 0.637298 * 100, metric = 11.20% * 100;
 Minibatch[ 901-1000]: loss = 0.625262 * 100, metric = 10.88% * 100;
 Minibatch[1001-1100]: loss = 0.629354 * 100, metric = 10.86% * 100;
 Minibatch[1101-1200]: loss = 0.622961 * 100, metric = 10.86% * 100;
 Minibatch[1201-1300]: loss = 0.627383 * 100, metric = 11.23% * 100;
 Minibatch[1301-1400]: loss = 0.611881 * 100, metric = 10.42% * 100;
 Minibatch[1401-1500]: loss = 0.604070 * 100, metric = 10.35% * 100;
 Minibatch[1501-1600]: loss = 0.619991 * 100, metric = 10.82% * 100;
 Minibatch[1601-1700]: loss = 0.629036 * 100, metric = 10.94% * 100;
 Minibatch[1701-1800]: loss = 0.610105 * 100, metric = 10.65% * 100;
 Minibatch[1801-1900]: loss = 0.614169 * 100, metric = 10.61% * 100;
 Minibatch[1901-2000]: loss = 0.610760 * 100, metric = 10.67% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.622486 * 2000, metric = 10.81% * 2000 950.938s (  2.1 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 17.56% * 2000;
0.6705357548668981
 Minibatch[   1- 100]: loss = 0.616247 * 100, metric = 10.60% * 100;
 Minibatch[ 101- 200]: loss = 0.604810 * 100, metric = 10.52% * 100;
 Minibatch[ 201- 300]: loss = 0.595549 * 100, metric = 10.43% * 100;
 Minibatch[ 301- 400]: loss = 0.605864 * 100, metric = 10.79% * 100;
 Minibatch[ 401- 500]: loss = 0.604517 * 100, metric = 10.57% * 100;
 Minibatch[ 501- 600]: loss = 0.618939 * 100, metric = 10.88% * 100;
 Minibatch[ 601- 700]: loss = 0.586686 * 100, metric = 9.96% * 100;
 Minibatch[ 701- 800]: loss = 0.602223 * 100, metric = 10.24% * 100;
 Minibatch[ 801- 900]: loss = 0.582450 * 100, metric = 9.74% * 100;
 Minibatch[ 901-1000]: loss = 0.577344 * 100, metric = 9.66% * 100;
 Minibatch[1001-1100]: loss = 0.579686 * 100, metric = 9.92% * 100;
 Minibatch[1101-1200]: loss = 0.584161 * 100, metric = 10.11% * 100;
 Minibatch[1201-1300]: loss = 0.601688 * 100, metric = 10.48% * 100;
 Minibatch[1301-1400]: loss = 0.608655 * 100, metric = 10.71% * 100;
 Minibatch[1401-1500]: loss = 0.602883 * 100, metric = 10.37% * 100;
 Minibatch[1501-1600]: loss = 0.601762 * 100, metric = 10.70% * 100;
 Minibatch[1601-1700]: loss = 0.585108 * 100, metric = 9.85% * 100;
 Minibatch[1701-1800]: loss = 0.586482 * 100, metric = 9.94% * 100;
 Minibatch[1801-1900]: loss = 0.591664 * 100, metric = 10.11% * 100;
 Minibatch[1901-2000]: loss = 0.589524 * 100, metric = 9.88% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.596312 * 2000, metric = 10.27% * 2000 945.620s (  2.1 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 17.64% * 2000;
0.6619343716725707
 Minibatch[   1- 100]: loss = 0.563239 * 100, metric = 9.24% * 100;
 Minibatch[ 101- 200]: loss = 0.604030 * 100, metric = 10.29% * 100;
 Minibatch[ 201- 300]: loss = 0.591499 * 100, metric = 10.15% * 100;
 Minibatch[ 301- 400]: loss = 0.607517 * 100, metric = 10.37% * 100;
 Minibatch[ 401- 500]: loss = 0.590686 * 100, metric = 10.07% * 100;
 Minibatch[ 501- 600]: loss = 0.573895 * 100, metric = 9.60% * 100;
 Minibatch[ 601- 700]: loss = 0.572728 * 100, metric = 9.66% * 100;
 Minibatch[ 701- 800]: loss = 0.571378 * 100, metric = 9.47% * 100;
 Minibatch[ 801- 900]: loss = 0.568526 * 100, metric = 9.66% * 100;
 Minibatch[ 901-1000]: loss = 0.580419 * 100, metric = 9.80% * 100;
 Minibatch[1001-1100]: loss = 0.550438 * 100, metric = 8.95% * 100;
 Minibatch[1101-1200]: loss = 0.574734 * 100, metric = 9.75% * 100;
 Minibatch[1201-1300]: loss = 0.575392 * 100, metric = 9.83% * 100;
 Minibatch[1301-1400]: loss = 0.576152 * 100, metric = 9.57% * 100;
 Minibatch[1401-1500]: loss = 0.589885 * 100, metric = 10.02% * 100;
 Minibatch[1501-1600]: loss = 0.579686 * 100, metric = 9.65% * 100;
 Minibatch[1601-1700]: loss = 0.573871 * 100, metric = 9.66% * 100;
 Minibatch[1701-1800]: loss = 0.562720 * 100, metric = 9.37% * 100;
 Minibatch[1801-1900]: loss = 0.564108 * 100, metric = 9.39% * 100;
 Minibatch[1901-2000]: loss = 0.583384 * 100, metric = 9.96% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.577714 * 2000, metric = 9.72% * 2000 944.137s (  2.1 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 16.55% * 2000;
0.6484075545221567
 Minibatch[   1- 100]: loss = 0.602890 * 100, metric = 10.49% * 100;
 Minibatch[ 101- 200]: loss = 0.568584 * 100, metric = 9.80% * 100;
 Minibatch[ 201- 300]: loss = 0.573623 * 100, metric = 9.80% * 100;
 Minibatch[ 301- 400]: loss = 0.571794 * 100, metric = 9.71% * 100;
 Minibatch[ 401- 500]: loss = 0.582159 * 100, metric = 10.15% * 100;
 Minibatch[ 501- 600]: loss = 0.560119 * 100, metric = 9.21% * 100;
 Minibatch[ 601- 700]: loss = 0.563708 * 100, metric = 9.49% * 100;
 Minibatch[ 701- 800]: loss = 0.558397 * 100, metric = 9.13% * 100;
 Minibatch[ 801- 900]: loss = 0.572065 * 100, metric = 9.57% * 100;
 Minibatch[ 901-1000]: loss = 0.567135 * 100, metric = 9.44% * 100;
 Minibatch[1001-1100]: loss = 0.579897 * 100, metric = 9.85% * 100;
 Minibatch[1101-1200]: loss = 0.568615 * 100, metric = 9.67% * 100;
 Minibatch[1201-1300]: loss = 0.568832 * 100, metric = 9.81% * 100;
 Minibatch[1301-1400]: loss = 0.576934 * 100, metric = 9.89% * 100;
 Minibatch[1401-1500]: loss = 0.552225 * 100, metric = 9.36% * 100;
 Minibatch[1501-1600]: loss = 0.565358 * 100, metric = 9.56% * 100;
 Minibatch[1601-1700]: loss = 0.566656 * 100, metric = 9.24% * 100;
 Minibatch[1701-1800]: loss = 0.566606 * 100, metric = 9.44% * 100;
 Minibatch[1801-1900]: loss = 0.575575 * 100, metric = 9.58% * 100;
 Minibatch[1901-2000]: loss = 0.552861 * 100, metric = 9.36% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.569702 * 2000, metric = 9.63% * 2000 933.489s (  2.1 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 15.82% * 2000;
0.6299657531306148
 Minibatch[   1- 100]: loss = 0.541998 * 100, metric = 8.94% * 100;
 Minibatch[ 101- 200]: loss = 0.556855 * 100, metric = 9.14% * 100;
 Minibatch[ 201- 300]: loss = 0.563920 * 100, metric = 9.47% * 100;
 Minibatch[ 301- 400]: loss = 0.561390 * 100, metric = 9.34% * 100;
 Minibatch[ 401- 500]: loss = 0.553029 * 100, metric = 9.06% * 100;
 Minibatch[ 501- 600]: loss = 0.567765 * 100, metric = 9.52% * 100;
 Minibatch[ 601- 700]: loss = 0.562159 * 100, metric = 9.38% * 100;
 Minibatch[ 701- 800]: loss = 0.573093 * 100, metric = 9.78% * 100;
 Minibatch[ 801- 900]: loss = 0.561841 * 100, metric = 9.52% * 100;
 Minibatch[ 901-1000]: loss = 0.561156 * 100, metric = 9.47% * 100;
 Minibatch[1001-1100]: loss = 0.553605 * 100, metric = 9.07% * 100;
 Minibatch[1101-1200]: loss = 0.559480 * 100, metric = 9.45% * 100;
 Minibatch[1201-1300]: loss = 0.547369 * 100, metric = 9.01% * 100;
 Minibatch[1301-1400]: loss = 0.534091 * 100, metric = 8.77% * 100;
 Minibatch[1401-1500]: loss = 0.561215 * 100, metric = 9.25% * 100;
 Minibatch[1501-1600]: loss = 0.543891 * 100, metric = 9.03% * 100;
 Minibatch[1601-1700]: loss = 0.553875 * 100, metric = 9.16% * 100;
 Minibatch[1701-1800]: loss = 0.578028 * 100, metric = 9.79% * 100;
 Minibatch[1801-1900]: loss = 0.552668 * 100, metric = 9.10% * 100;
 Minibatch[1901-2000]: loss = 0.553506 * 100, metric = 9.42% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.557047 * 2000, metric = 9.28% * 2000 934.429s (  2.1 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 16.29% * 2000;
 Minibatch[   1- 100]: loss = 0.547317 * 100, metric = 9.02% * 100;
 Minibatch[ 101- 200]: loss = 0.553702 * 100, metric = 9.08% * 100;
 Minibatch[ 201- 300]: loss = 0.545764 * 100, metric = 9.11% * 100;
 Minibatch[ 301- 400]: loss = 0.581294 * 100, metric = 9.84% * 100;
 Minibatch[ 401- 500]: loss = 0.555454 * 100, metric = 9.03% * 100;
 Minibatch[ 501- 600]: loss = 0.541642 * 100, metric = 8.77% * 100;
 Minibatch[ 601- 700]: loss = 0.550310 * 100, metric = 8.90% * 100;
 Minibatch[ 701- 800]: loss = 0.556288 * 100, metric = 9.40% * 100;
 Minibatch[ 801- 900]: loss = 0.540124 * 100, metric = 9.01% * 100;
 Minibatch[ 901-1000]: loss = 0.553765 * 100, metric = 9.25% * 100;
 Minibatch[1001-1100]: loss = 0.562194 * 100, metric = 9.55% * 100;
 Minibatch[1101-1200]: loss = 0.551750 * 100, metric = 9.16% * 100;
 Minibatch[1201-1300]: loss = 0.568547 * 100, metric = 9.71% * 100;
 Minibatch[1301-1400]: loss = 0.537337 * 100, metric = 8.52% * 100;
 Minibatch[1401-1500]: loss = 0.565627 * 100, metric = 9.61% * 100;
 Minibatch[1501-1600]: loss = 0.524539 * 100, metric = 8.59% * 100;
 Minibatch[1601-1700]: loss = 0.552171 * 100, metric = 9.14% * 100;
 Minibatch[1701-1800]: loss = 0.531496 * 100, metric = 8.63% * 100;
 Minibatch[1801-1900]: loss = 0.545637 * 100, metric = 9.14% * 100;
 Minibatch[1901-2000]: loss = 0.554883 * 100, metric = 9.17% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.550992 * 2000, metric = 9.13% * 2000 925.538s (  2.2 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 17.72% * 2000;
 Minibatch[   1- 100]: loss = 0.536836 * 100, metric = 8.82% * 100;
 Minibatch[ 101- 200]: loss = 0.542123 * 100, metric = 9.03% * 100;
 Minibatch[ 201- 300]: loss = 0.545200 * 100, metric = 9.00% * 100;
 Minibatch[ 301- 400]: loss = 0.552240 * 100, metric = 9.22% * 100;
 Minibatch[ 401- 500]: loss = 0.543672 * 100, metric = 9.47% * 100;
 Minibatch[ 501- 600]: loss = 0.564874 * 100, metric = 9.58% * 100;
 Minibatch[ 601- 700]: loss = 0.530204 * 100, metric = 8.58% * 100;
 Minibatch[ 701- 800]: loss = 0.534968 * 100, metric = 8.63% * 100;
 Minibatch[ 801- 900]: loss = 0.531904 * 100, metric = 8.71% * 100;
 Minibatch[ 901-1000]: loss = 0.540017 * 100, metric = 8.83% * 100;
 Minibatch[1001-1100]: loss = 0.544955 * 100, metric = 9.20% * 100;
 Minibatch[1101-1200]: loss = 0.533321 * 100, metric = 8.82% * 100;
 Minibatch[1201-1300]: loss = 0.541363 * 100, metric = 8.96% * 100;
 Minibatch[1301-1400]: loss = 0.530975 * 100, metric = 8.73% * 100;
 Minibatch[1401-1500]: loss = 0.537039 * 100, metric = 8.85% * 100;
 Minibatch[1501-1600]: loss = 0.525756 * 100, metric = 8.47% * 100;
 Minibatch[1601-1700]: loss = 0.516972 * 100, metric = 8.59% * 100;
 Minibatch[1701-1800]: loss = 0.531069 * 100, metric = 8.71% * 100;
 Minibatch[1801-1900]: loss = 0.514596 * 100, metric = 8.36% * 100;
 Minibatch[1901-2000]: loss = 0.537727 * 100, metric = 9.00% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.536790 * 2000, metric = 8.88% * 2000 918.218s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 17.69% * 2000;
 Minibatch[   1- 100]: loss = 0.535671 * 100, metric = 8.87% * 100;
 Minibatch[ 101- 200]: loss = 0.519671 * 100, metric = 8.45% * 100;
 Minibatch[ 201- 300]: loss = 0.540367 * 100, metric = 8.89% * 100;
 Minibatch[ 301- 400]: loss = 0.536865 * 100, metric = 8.84% * 100;
 Minibatch[ 401- 500]: loss = 0.529581 * 100, metric = 8.82% * 100;
 Minibatch[ 501- 600]: loss = 0.537137 * 100, metric = 8.74% * 100;
 Minibatch[ 601- 700]: loss = 0.524814 * 100, metric = 8.57% * 100;
 Minibatch[ 701- 800]: loss = 0.552257 * 100, metric = 9.42% * 100;
 Minibatch[ 801- 900]: loss = 0.546684 * 100, metric = 9.29% * 100;
 Minibatch[ 901-1000]: loss = 0.534568 * 100, metric = 8.75% * 100;
 Minibatch[1001-1100]: loss = 0.527144 * 100, metric = 8.89% * 100;
 Minibatch[1101-1200]: loss = 0.528426 * 100, metric = 8.65% * 100;
 Minibatch[1201-1300]: loss = 0.515021 * 100, metric = 8.33% * 100;
 Minibatch[1301-1400]: loss = 0.544420 * 100, metric = 8.93% * 100;
 Minibatch[1401-1500]: loss = 0.530778 * 100, metric = 8.73% * 100;
 Minibatch[1501-1600]: loss = 0.517713 * 100, metric = 8.37% * 100;
 Minibatch[1601-1700]: loss = 0.532995 * 100, metric = 8.64% * 100;
 Minibatch[1701-1800]: loss = 0.518272 * 100, metric = 8.15% * 100;
 Minibatch[1801-1900]: loss = 0.524139 * 100, metric = 8.55% * 100;
 Minibatch[1901-2000]: loss = 0.530698 * 100, metric = 8.65% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.531361 * 2000, metric = 8.73% * 2000 920.439s (  2.2 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 17.08% * 2000;
 Minibatch[   1- 100]: loss = 0.526127 * 100, metric = 8.51% * 100;
 Minibatch[ 101- 200]: loss = 0.541179 * 100, metric = 8.95% * 100;
 Minibatch[ 201- 300]: loss = 0.527888 * 100, metric = 8.66% * 100;
 Minibatch[ 301- 400]: loss = 0.521035 * 100, metric = 8.51% * 100;
 Minibatch[ 401- 500]: loss = 0.516720 * 100, metric = 8.52% * 100;
 Minibatch[ 501- 600]: loss = 0.516880 * 100, metric = 8.04% * 100;
 Minibatch[ 601- 700]: loss = 0.502334 * 100, metric = 8.20% * 100;
 Minibatch[ 701- 800]: loss = 0.531626 * 100, metric = 9.00% * 100;
 Minibatch[ 801- 900]: loss = 0.530263 * 100, metric = 9.09% * 100;
 Minibatch[ 901-1000]: loss = 0.525757 * 100, metric = 8.62% * 100;
 Minibatch[1001-1100]: loss = 0.526651 * 100, metric = 8.68% * 100;
 Minibatch[1101-1200]: loss = 0.523253 * 100, metric = 8.55% * 100;
 Minibatch[1201-1300]: loss = 0.513079 * 100, metric = 8.14% * 100;
 Minibatch[1301-1400]: loss = 0.545920 * 100, metric = 9.07% * 100;
 Minibatch[1401-1500]: loss = 0.498105 * 100, metric = 7.98% * 100;
 Minibatch[1501-1600]: loss = 0.511002 * 100, metric = 8.25% * 100;
 Minibatch[1601-1700]: loss = 0.521517 * 100, metric = 8.49% * 100;
 Minibatch[1701-1800]: loss = 0.503629 * 100, metric = 7.98% * 100;
 Minibatch[1801-1900]: loss = 0.505415 * 100, metric = 8.29% * 100;
 Minibatch[1901-2000]: loss = 0.500198 * 100, metric = 8.02% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.519429 * 2000, metric = 8.48% * 2000 962.913s (  2.1 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 14.98% * 2000;
0.6287362460196019
 Minibatch[   1- 100]: loss = 0.523038 * 100, metric = 8.76% * 100;
 Minibatch[ 101- 200]: loss = 0.517998 * 100, metric = 8.14% * 100;
 Minibatch[ 201- 300]: loss = 0.512064 * 100, metric = 8.13% * 100;
 Minibatch[ 301- 400]: loss = 0.515442 * 100, metric = 8.31% * 100;
 Minibatch[ 401- 500]: loss = 0.490498 * 100, metric = 7.78% * 100;
 Minibatch[ 501- 600]: loss = 0.506749 * 100, metric = 8.17% * 100;
 Minibatch[ 601- 700]: loss = 0.505743 * 100, metric = 8.33% * 100;
 Minibatch[ 701- 800]: loss = 0.506088 * 100, metric = 8.20% * 100;
 Minibatch[ 801- 900]: loss = 0.495914 * 100, metric = 7.95% * 100;
 Minibatch[ 901-1000]: loss = 0.517399 * 100, metric = 8.42% * 100;
 Minibatch[1001-1100]: loss = 0.491171 * 100, metric = 8.14% * 100;
 Minibatch[1101-1200]: loss = 0.501799 * 100, metric = 8.09% * 100;
 Minibatch[1201-1300]: loss = 0.499678 * 100, metric = 8.00% * 100;
 Minibatch[1301-1400]: loss = 0.504202 * 100, metric = 8.23% * 100;
 Minibatch[1401-1500]: loss = 0.497303 * 100, metric = 8.20% * 100;
 Minibatch[1501-1600]: loss = 0.508922 * 100, metric = 8.31% * 100;
 Minibatch[1601-1700]: loss = 0.515629 * 100, metric = 8.42% * 100;
 Minibatch[1701-1800]: loss = 0.524137 * 100, metric = 8.54% * 100;
 Minibatch[1801-1900]: loss = 0.512656 * 100, metric = 8.60% * 100;
 Minibatch[1901-2000]: loss = 0.488768 * 100, metric = 7.84% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.506760 * 2000, metric = 8.23% * 2000 960.230s (  2.1 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.79% * 2000;
0.6213420303240419
 Minibatch[   1- 100]: loss = 0.496427 * 100, metric = 7.86% * 100;
 Minibatch[ 101- 200]: loss = 0.520679 * 100, metric = 8.52% * 100;
 Minibatch[ 201- 300]: loss = 0.513024 * 100, metric = 8.38% * 100;
 Minibatch[ 301- 400]: loss = 0.503925 * 100, metric = 8.22% * 100;
 Minibatch[ 401- 500]: loss = 0.523528 * 100, metric = 8.39% * 100;
 Minibatch[ 501- 600]: loss = 0.498538 * 100, metric = 7.89% * 100;
 Minibatch[ 601- 700]: loss = 0.489913 * 100, metric = 7.83% * 100;
 Minibatch[ 701- 800]: loss = 0.510872 * 100, metric = 8.17% * 100;
 Minibatch[ 801- 900]: loss = 0.510413 * 100, metric = 8.39% * 100;
 Minibatch[ 901-1000]: loss = 0.500373 * 100, metric = 7.91% * 100;
 Minibatch[1001-1100]: loss = 0.491962 * 100, metric = 8.01% * 100;
 Minibatch[1101-1200]: loss = 0.510109 * 100, metric = 8.31% * 100;
 Minibatch[1201-1300]: loss = 0.511031 * 100, metric = 8.38% * 100;
 Minibatch[1301-1400]: loss = 0.488223 * 100, metric = 7.92% * 100;
 Minibatch[1401-1500]: loss = 0.505334 * 100, metric = 8.42% * 100;
 Minibatch[1501-1600]: loss = 0.498695 * 100, metric = 8.01% * 100;
 Minibatch[1601-1700]: loss = 0.507572 * 100, metric = 7.99% * 100;
 Minibatch[1701-1800]: loss = 0.480192 * 100, metric = 7.56% * 100;
 Minibatch[1801-1900]: loss = 0.508699 * 100, metric = 8.30% * 100;
 Minibatch[1901-2000]: loss = 0.517261 * 100, metric = 8.56% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.504338 * 2000, metric = 8.15% * 2000 949.549s (  2.1 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.55% * 2000;
0.614992544785142
 Minibatch[   1- 100]: loss = 0.483706 * 100, metric = 7.69% * 100;
 Minibatch[ 101- 200]: loss = 0.508069 * 100, metric = 8.40% * 100;
 Minibatch[ 201- 300]: loss = 0.492281 * 100, metric = 7.96% * 100;
 Minibatch[ 301- 400]: loss = 0.491605 * 100, metric = 7.87% * 100;
 Minibatch[ 401- 500]: loss = 0.480979 * 100, metric = 7.58% * 100;
 Minibatch[ 501- 600]: loss = 0.487630 * 100, metric = 7.59% * 100;
 Minibatch[ 601- 700]: loss = 0.494631 * 100, metric = 7.86% * 100;
 Minibatch[ 701- 800]: loss = 0.483331 * 100, metric = 7.65% * 100;
 Minibatch[ 801- 900]: loss = 0.504199 * 100, metric = 8.13% * 100;
 Minibatch[ 901-1000]: loss = 0.502421 * 100, metric = 8.34% * 100;
 Minibatch[1001-1100]: loss = 0.503580 * 100, metric = 8.29% * 100;
 Minibatch[1101-1200]: loss = 0.500066 * 100, metric = 8.10% * 100;
 Minibatch[1201-1300]: loss = 0.499443 * 100, metric = 8.15% * 100;
 Minibatch[1301-1400]: loss = 0.501929 * 100, metric = 7.97% * 100;
 Minibatch[1401-1500]: loss = 0.475679 * 100, metric = 7.53% * 100;
 Minibatch[1501-1600]: loss = 0.489948 * 100, metric = 7.97% * 100;
 Minibatch[1601-1700]: loss = 0.466873 * 100, metric = 7.16% * 100;
 Minibatch[1701-1800]: loss = 0.484550 * 100, metric = 7.69% * 100;
 Minibatch[1801-1900]: loss = 0.483184 * 100, metric = 7.82% * 100;
 Minibatch[1901-2000]: loss = 0.480560 * 100, metric = 7.49% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.490733 * 2000, metric = 7.86% * 2000 946.165s (  2.1 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 16.63% * 2000;
 Minibatch[   1- 100]: loss = 0.498444 * 100, metric = 8.12% * 100;
 Minibatch[ 101- 200]: loss = 0.507738 * 100, metric = 8.15% * 100;
 Minibatch[ 201- 300]: loss = 0.472526 * 100, metric = 7.40% * 100;
 Minibatch[ 301- 400]: loss = 0.494392 * 100, metric = 7.89% * 100;
 Minibatch[ 401- 500]: loss = 0.499289 * 100, metric = 7.92% * 100;
 Minibatch[ 501- 600]: loss = 0.482820 * 100, metric = 7.53% * 100;
 Minibatch[ 601- 700]: loss = 0.494207 * 100, metric = 7.97% * 100;
 Minibatch[ 701- 800]: loss = 0.481208 * 100, metric = 7.62% * 100;
 Minibatch[ 801- 900]: loss = 0.503871 * 100, metric = 8.25% * 100;
 Minibatch[ 901-1000]: loss = 0.474661 * 100, metric = 7.44% * 100;
 Minibatch[1001-1100]: loss = 0.508495 * 100, metric = 8.09% * 100;
 Minibatch[1101-1200]: loss = 0.493256 * 100, metric = 7.96% * 100;
 Minibatch[1201-1300]: loss = 0.487384 * 100, metric = 7.67% * 100;
 Minibatch[1301-1400]: loss = 0.469263 * 100, metric = 7.36% * 100;
 Minibatch[1401-1500]: loss = 0.482120 * 100, metric = 7.72% * 100;
 Minibatch[1501-1600]: loss = 0.485711 * 100, metric = 7.68% * 100;
 Minibatch[1601-1700]: loss = 0.467529 * 100, metric = 7.67% * 100;
 Minibatch[1701-1800]: loss = 0.446040 * 100, metric = 6.93% * 100;
 Minibatch[1801-1900]: loss = 0.479055 * 100, metric = 7.54% * 100;
 Minibatch[1901-2000]: loss = 0.464696 * 100, metric = 7.15% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.484635 * 2000, metric = 7.70% * 2000 946.695s (  2.1 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 14.71% * 2000;
 Minibatch[   1- 100]: loss = 0.466459 * 100, metric = 7.30% * 100;
 Minibatch[ 101- 200]: loss = 0.476607 * 100, metric = 7.37% * 100;
 Minibatch[ 201- 300]: loss = 0.468054 * 100, metric = 7.13% * 100;
 Minibatch[ 301- 400]: loss = 0.473237 * 100, metric = 7.11% * 100;
 Minibatch[ 401- 500]: loss = 0.469989 * 100, metric = 7.25% * 100;
 Minibatch[ 501- 600]: loss = 0.476622 * 100, metric = 7.62% * 100;
 Minibatch[ 601- 700]: loss = 0.487413 * 100, metric = 7.74% * 100;
 Minibatch[ 701- 800]: loss = 0.472258 * 100, metric = 7.52% * 100;
 Minibatch[ 801- 900]: loss = 0.483119 * 100, metric = 7.64% * 100;
 Minibatch[ 901-1000]: loss = 0.495734 * 100, metric = 7.54% * 100;
 Minibatch[1001-1100]: loss = 0.457338 * 100, metric = 7.04% * 100;
 Minibatch[1101-1200]: loss = 0.462674 * 100, metric = 7.28% * 100;
 Minibatch[1201-1300]: loss = 0.460838 * 100, metric = 7.05% * 100;
 Minibatch[1301-1400]: loss = 0.470245 * 100, metric = 7.46% * 100;
 Minibatch[1401-1500]: loss = 0.459498 * 100, metric = 7.21% * 100;
 Minibatch[1501-1600]: loss = 0.471014 * 100, metric = 7.12% * 100;
 Minibatch[1601-1700]: loss = 0.462396 * 100, metric = 7.27% * 100;
 Minibatch[1701-1800]: loss = 0.474112 * 100, metric = 7.62% * 100;
 Minibatch[1801-1900]: loss = 0.460320 * 100, metric = 7.16% * 100;
 Minibatch[1901-2000]: loss = 0.456639 * 100, metric = 7.04% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.470228 * 2000, metric = 7.32% * 2000 943.927s (  2.1 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 16.07% * 2000;
 Minibatch[   1- 100]: loss = 0.465959 * 100, metric = 7.04% * 100;
 Minibatch[ 101- 200]: loss = 0.463072 * 100, metric = 7.13% * 100;
 Minibatch[ 201- 300]: loss = 0.457710 * 100, metric = 7.28% * 100;
 Minibatch[ 301- 400]: loss = 0.469738 * 100, metric = 7.35% * 100;
 Minibatch[ 401- 500]: loss = 0.450594 * 100, metric = 7.06% * 100;
 Minibatch[ 501- 600]: loss = 0.453925 * 100, metric = 6.93% * 100;
 Minibatch[ 601- 700]: loss = 0.456573 * 100, metric = 6.91% * 100;
 Minibatch[ 701- 800]: loss = 0.434813 * 100, metric = 6.60% * 100;
 Minibatch[ 801- 900]: loss = 0.468495 * 100, metric = 7.29% * 100;
 Minibatch[ 901-1000]: loss = 0.458558 * 100, metric = 6.96% * 100;
 Minibatch[1001-1100]: loss = 0.453202 * 100, metric = 6.90% * 100;
 Minibatch[1101-1200]: loss = 0.450892 * 100, metric = 6.92% * 100;
 Minibatch[1201-1300]: loss = 0.461909 * 100, metric = 7.13% * 100;
 Minibatch[1301-1400]: loss = 0.448966 * 100, metric = 6.71% * 100;
 Minibatch[1401-1500]: loss = 0.469746 * 100, metric = 7.25% * 100;
 Minibatch[1501-1600]: loss = 0.470646 * 100, metric = 7.69% * 100;
 Minibatch[1601-1700]: loss = 0.461227 * 100, metric = 7.21% * 100;
 Minibatch[1701-1800]: loss = 0.455308 * 100, metric = 6.89% * 100;
 Minibatch[1801-1900]: loss = 0.465894 * 100, metric = 7.32% * 100;
 Minibatch[1901-2000]: loss = 0.438599 * 100, metric = 6.63% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.457791 * 2000, metric = 7.06% * 2000 936.832s (  2.1 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 14.24% * 2000;
0.6039191095158458
 Minibatch[   1- 100]: loss = 0.476857 * 100, metric = 7.61% * 100;
 Minibatch[ 101- 200]: loss = 0.459863 * 100, metric = 7.09% * 100;
 Minibatch[ 201- 300]: loss = 0.470565 * 100, metric = 7.42% * 100;
 Minibatch[ 301- 400]: loss = 0.459015 * 100, metric = 7.09% * 100;
 Minibatch[ 401- 500]: loss = 0.448148 * 100, metric = 6.89% * 100;
 Minibatch[ 501- 600]: loss = 0.463161 * 100, metric = 7.17% * 100;
 Minibatch[ 601- 700]: loss = 0.453698 * 100, metric = 7.09% * 100;
 Minibatch[ 701- 800]: loss = 0.450739 * 100, metric = 6.90% * 100;
 Minibatch[ 801- 900]: loss = 0.457275 * 100, metric = 7.18% * 100;
 Minibatch[ 901-1000]: loss = 0.468661 * 100, metric = 7.24% * 100;
 Minibatch[1001-1100]: loss = 0.437685 * 100, metric = 6.78% * 100;
 Minibatch[1101-1200]: loss = 0.429857 * 100, metric = 6.24% * 100;
 Minibatch[1201-1300]: loss = 0.444965 * 100, metric = 6.80% * 100;
 Minibatch[1301-1400]: loss = 0.448773 * 100, metric = 6.84% * 100;
 Minibatch[1401-1500]: loss = 0.443629 * 100, metric = 6.80% * 100;
 Minibatch[1501-1600]: loss = 0.447639 * 100, metric = 6.81% * 100;
 Minibatch[1601-1700]: loss = 0.444022 * 100, metric = 6.85% * 100;
 Minibatch[1701-1800]: loss = 0.445349 * 100, metric = 6.71% * 100;
 Minibatch[1801-1900]: loss = 0.455180 * 100, metric = 7.14% * 100;
 Minibatch[1901-2000]: loss = 0.450798 * 100, metric = 6.87% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.452794 * 2000, metric = 6.98% * 2000 938.161s (  2.1 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 14.77% * 2000;
 Minibatch[   1- 100]: loss = 0.466875 * 100, metric = 7.15% * 100;
 Minibatch[ 101- 200]: loss = 0.466835 * 100, metric = 7.40% * 100;
 Minibatch[ 201- 300]: loss = 0.465774 * 100, metric = 7.18% * 100;
 Minibatch[ 301- 400]: loss = 0.469825 * 100, metric = 7.14% * 100;
 Minibatch[ 401- 500]: loss = 0.469972 * 100, metric = 7.59% * 100;
 Minibatch[ 501- 600]: loss = 0.456769 * 100, metric = 6.90% * 100;
 Minibatch[ 601- 700]: loss = 0.466395 * 100, metric = 6.89% * 100;
 Minibatch[ 701- 800]: loss = 0.450031 * 100, metric = 6.74% * 100;
 Minibatch[ 801- 900]: loss = 0.441312 * 100, metric = 6.89% * 100;
 Minibatch[ 901-1000]: loss = 0.464504 * 100, metric = 7.16% * 100;
 Minibatch[1001-1100]: loss = 0.440972 * 100, metric = 6.77% * 100;
 Minibatch[1101-1200]: loss = 0.460189 * 100, metric = 7.10% * 100;
 Minibatch[1201-1300]: loss = 0.457571 * 100, metric = 6.88% * 100;
 Minibatch[1301-1400]: loss = 0.457238 * 100, metric = 7.15% * 100;
 Minibatch[1401-1500]: loss = 0.442916 * 100, metric = 6.95% * 100;
 Minibatch[1501-1600]: loss = 0.454222 * 100, metric = 6.98% * 100;
 Minibatch[1601-1700]: loss = 0.443354 * 100, metric = 6.73% * 100;
 Minibatch[1701-1800]: loss = 0.453662 * 100, metric = 6.99% * 100;
 Minibatch[1801-1900]: loss = 0.455276 * 100, metric = 7.22% * 100;
 Minibatch[1901-2000]: loss = 0.457119 * 100, metric = 7.16% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.457041 * 2000, metric = 7.05% * 2000 931.219s (  2.1 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 15.49% * 2000;
 Minibatch[   1- 100]: loss = 0.438067 * 100, metric = 6.87% * 100;
 Minibatch[ 101- 200]: loss = 0.462074 * 100, metric = 7.34% * 100;
 Minibatch[ 201- 300]: loss = 0.439643 * 100, metric = 6.82% * 100;
 Minibatch[ 301- 400]: loss = 0.454619 * 100, metric = 7.04% * 100;
 Minibatch[ 401- 500]: loss = 0.447542 * 100, metric = 6.84% * 100;
 Minibatch[ 501- 600]: loss = 0.436837 * 100, metric = 6.63% * 100;
 Minibatch[ 601- 700]: loss = 0.461263 * 100, metric = 7.04% * 100;
 Minibatch[ 701- 800]: loss = 0.448050 * 100, metric = 6.92% * 100;
 Minibatch[ 801- 900]: loss = 0.473529 * 100, metric = 7.41% * 100;
 Minibatch[ 901-1000]: loss = 0.442587 * 100, metric = 6.66% * 100;
 Minibatch[1001-1100]: loss = 0.454890 * 100, metric = 7.05% * 100;
 Minibatch[1101-1200]: loss = 0.469082 * 100, metric = 7.33% * 100;
 Minibatch[1201-1300]: loss = 0.451415 * 100, metric = 6.79% * 100;
 Minibatch[1301-1400]: loss = 0.447244 * 100, metric = 6.65% * 100;
 Minibatch[1401-1500]: loss = 0.438328 * 100, metric = 6.65% * 100;
 Minibatch[1501-1600]: loss = 0.453301 * 100, metric = 7.00% * 100;
 Minibatch[1601-1700]: loss = 0.440033 * 100, metric = 6.68% * 100;
 Minibatch[1701-1800]: loss = 0.435915 * 100, metric = 6.70% * 100;
 Minibatch[1801-1900]: loss = 0.443270 * 100, metric = 6.74% * 100;
 Minibatch[1901-2000]: loss = 0.459398 * 100, metric = 7.31% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.449854 * 2000, metric = 6.92% * 2000 929.096s (  2.2 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.50% * 2000;
 Minibatch[   1- 100]: loss = 0.453105 * 100, metric = 6.82% * 100;
 Minibatch[ 101- 200]: loss = 0.439846 * 100, metric = 6.87% * 100;
 Minibatch[ 201- 300]: loss = 0.443373 * 100, metric = 6.96% * 100;
 Minibatch[ 301- 400]: loss = 0.449173 * 100, metric = 7.07% * 100;
 Minibatch[ 401- 500]: loss = 0.436411 * 100, metric = 6.82% * 100;
 Minibatch[ 501- 600]: loss = 0.433561 * 100, metric = 6.52% * 100;
 Minibatch[ 601- 700]: loss = 0.436157 * 100, metric = 6.54% * 100;
 Minibatch[ 701- 800]: loss = 0.431582 * 100, metric = 6.64% * 100;
 Minibatch[ 801- 900]: loss = 0.426740 * 100, metric = 6.47% * 100;
 Minibatch[ 901-1000]: loss = 0.433301 * 100, metric = 6.58% * 100;
 Minibatch[1001-1100]: loss = 0.440652 * 100, metric = 6.78% * 100;
 Minibatch[1101-1200]: loss = 0.450353 * 100, metric = 6.85% * 100;
 Minibatch[1201-1300]: loss = 0.454527 * 100, metric = 7.13% * 100;
 Minibatch[1301-1400]: loss = 0.446026 * 100, metric = 6.77% * 100;
 Minibatch[1401-1500]: loss = 0.430469 * 100, metric = 6.47% * 100;
 Minibatch[1501-1600]: loss = 0.451080 * 100, metric = 6.98% * 100;
 Minibatch[1601-1700]: loss = 0.437855 * 100, metric = 6.72% * 100;
 Minibatch[1701-1800]: loss = 0.445063 * 100, metric = 6.92% * 100;
 Minibatch[1801-1900]: loss = 0.428464 * 100, metric = 6.45% * 100;
 Minibatch[1901-2000]: loss = 0.423599 * 100, metric = 6.49% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.439567 * 2000, metric = 6.74% * 2000 922.960s (  2.2 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 13.90% * 2000;
 Minibatch[   1- 100]: loss = 0.437201 * 100, metric = 6.83% * 100;
 Minibatch[ 101- 200]: loss = 0.421339 * 100, metric = 6.20% * 100;
 Minibatch[ 201- 300]: loss = 0.437996 * 100, metric = 6.70% * 100;
 Minibatch[ 301- 400]: loss = 0.429559 * 100, metric = 6.40% * 100;
 Minibatch[ 401- 500]: loss = 0.439916 * 100, metric = 6.92% * 100;
 Minibatch[ 501- 600]: loss = 0.431205 * 100, metric = 6.63% * 100;
 Minibatch[ 601- 700]: loss = 0.434468 * 100, metric = 6.74% * 100;
 Minibatch[ 701- 800]: loss = 0.428027 * 100, metric = 6.71% * 100;
 Minibatch[ 801- 900]: loss = 0.427436 * 100, metric = 6.43% * 100;
 Minibatch[ 901-1000]: loss = 0.424051 * 100, metric = 6.45% * 100;
 Minibatch[1001-1100]: loss = 0.434864 * 100, metric = 6.75% * 100;
 Minibatch[1101-1200]: loss = 0.443568 * 100, metric = 6.78% * 100;
 Minibatch[1201-1300]: loss = 0.433239 * 100, metric = 6.58% * 100;
 Minibatch[1301-1400]: loss = 0.421404 * 100, metric = 6.25% * 100;
 Minibatch[1401-1500]: loss = 0.436439 * 100, metric = 6.69% * 100;
 Minibatch[1501-1600]: loss = 0.433809 * 100, metric = 6.48% * 100;
 Minibatch[1601-1700]: loss = 0.453810 * 100, metric = 6.99% * 100;
 Minibatch[1701-1800]: loss = 0.451915 * 100, metric = 7.09% * 100;
 Minibatch[1801-1900]: loss = 0.438432 * 100, metric = 6.66% * 100;
 Minibatch[1901-2000]: loss = 0.439954 * 100, metric = 6.69% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.434932 * 2000, metric = 6.65% * 2000 924.436s (  2.2 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 14.40% * 2000;
 Minibatch[   1- 100]: loss = 0.437502 * 100, metric = 6.53% * 100;
 Minibatch[ 101- 200]: loss = 0.431627 * 100, metric = 6.34% * 100;
 Minibatch[ 201- 300]: loss = 0.425571 * 100, metric = 6.49% * 100;
 Minibatch[ 301- 400]: loss = 0.431136 * 100, metric = 6.75% * 100;
 Minibatch[ 401- 500]: loss = 0.433434 * 100, metric = 6.60% * 100;
 Minibatch[ 501- 600]: loss = 0.423312 * 100, metric = 6.46% * 100;
 Minibatch[ 601- 700]: loss = 0.429077 * 100, metric = 6.43% * 100;
 Minibatch[ 701- 800]: loss = 0.446446 * 100, metric = 6.71% * 100;
 Minibatch[ 801- 900]: loss = 0.439968 * 100, metric = 6.75% * 100;
 Minibatch[ 901-1000]: loss = 0.444673 * 100, metric = 6.84% * 100;
 Minibatch[1001-1100]: loss = 0.426844 * 100, metric = 6.38% * 100;
 Minibatch[1101-1200]: loss = 0.439951 * 100, metric = 6.62% * 100;
 Minibatch[1201-1300]: loss = 0.431277 * 100, metric = 6.51% * 100;
 Minibatch[1301-1400]: loss = 0.447457 * 100, metric = 6.96% * 100;
 Minibatch[1401-1500]: loss = 0.423951 * 100, metric = 6.56% * 100;
 Minibatch[1501-1600]: loss = 0.424308 * 100, metric = 6.36% * 100;
 Minibatch[1601-1700]: loss = 0.405556 * 100, metric = 6.11% * 100;
 Minibatch[1701-1800]: loss = 0.430518 * 100, metric = 6.47% * 100;
 Minibatch[1801-1900]: loss = 0.430910 * 100, metric = 6.51% * 100;
 Minibatch[1901-2000]: loss = 0.438144 * 100, metric = 6.79% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.432083 * 2000, metric = 6.56% * 2000 926.567s (  2.2 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.71% * 2000;
 Minibatch[   1- 100]: loss = 0.439174 * 100, metric = 6.91% * 100;
 Minibatch[ 101- 200]: loss = 0.419639 * 100, metric = 6.26% * 100;
 Minibatch[ 201- 300]: loss = 0.432037 * 100, metric = 6.64% * 100;
 Minibatch[ 301- 400]: loss = 0.430577 * 100, metric = 6.36% * 100;
 Minibatch[ 401- 500]: loss = 0.420767 * 100, metric = 6.52% * 100;
 Minibatch[ 501- 600]: loss = 0.438305 * 100, metric = 6.78% * 100;
 Minibatch[ 601- 700]: loss = 0.434959 * 100, metric = 6.53% * 100;
 Minibatch[ 701- 800]: loss = 0.413406 * 100, metric = 6.15% * 100;
 Minibatch[ 801- 900]: loss = 0.424965 * 100, metric = 6.46% * 100;
 Minibatch[ 901-1000]: loss = 0.431217 * 100, metric = 6.72% * 100;
 Minibatch[1001-1100]: loss = 0.429884 * 100, metric = 6.53% * 100;
 Minibatch[1101-1200]: loss = 0.425707 * 100, metric = 6.21% * 100;
 Minibatch[1201-1300]: loss = 0.430701 * 100, metric = 6.60% * 100;
 Minibatch[1301-1400]: loss = 0.421189 * 100, metric = 6.52% * 100;
 Minibatch[1401-1500]: loss = 0.434970 * 100, metric = 6.64% * 100;
 Minibatch[1501-1600]: loss = 0.429530 * 100, metric = 6.55% * 100;
 Minibatch[1601-1700]: loss = 0.426776 * 100, metric = 6.34% * 100;
 Minibatch[1701-1800]: loss = 0.426607 * 100, metric = 6.50% * 100;
 Minibatch[1801-1900]: loss = 0.419928 * 100, metric = 6.29% * 100;
 Minibatch[1901-2000]: loss = 0.420162 * 100, metric = 6.12% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.427525 * 2000, metric = 6.48% * 2000 923.042s (  2.2 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.29% * 2000;
0.5965795127004385
 Minibatch[   1- 100]: loss = 0.407253 * 100, metric = 6.10% * 100;
 Minibatch[ 101- 200]: loss = 0.412841 * 100, metric = 6.15% * 100;
 Minibatch[ 201- 300]: loss = 0.425703 * 100, metric = 6.59% * 100;
 Minibatch[ 301- 400]: loss = 0.446674 * 100, metric = 6.88% * 100;
 Minibatch[ 401- 500]: loss = 0.419769 * 100, metric = 6.12% * 100;
 Minibatch[ 501- 600]: loss = 0.432381 * 100, metric = 6.55% * 100;
 Minibatch[ 601- 700]: loss = 0.418362 * 100, metric = 6.47% * 100;
 Minibatch[ 701- 800]: loss = 0.430795 * 100, metric = 6.83% * 100;
 Minibatch[ 801- 900]: loss = 0.422418 * 100, metric = 6.42% * 100;
 Minibatch[ 901-1000]: loss = 0.431797 * 100, metric = 6.67% * 100;
 Minibatch[1001-1100]: loss = 0.430755 * 100, metric = 6.68% * 100;
 Minibatch[1101-1200]: loss = 0.420956 * 100, metric = 6.40% * 100;
 Minibatch[1201-1300]: loss = 0.428484 * 100, metric = 6.40% * 100;
 Minibatch[1301-1400]: loss = 0.412741 * 100, metric = 6.34% * 100;
 Minibatch[1401-1500]: loss = 0.430844 * 100, metric = 6.62% * 100;
 Minibatch[1501-1600]: loss = 0.405485 * 100, metric = 6.17% * 100;
 Minibatch[1601-1700]: loss = 0.432360 * 100, metric = 6.58% * 100;
 Minibatch[1701-1800]: loss = 0.410209 * 100, metric = 6.22% * 100;
 Minibatch[1801-1900]: loss = 0.432902 * 100, metric = 6.41% * 100;
 Minibatch[1901-2000]: loss = 0.426038 * 100, metric = 6.49% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.423938 * 2000, metric = 6.45% * 2000 926.519s (  2.2 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 14.99% * 2000;
 Minibatch[   1- 100]: loss = 0.440177 * 100, metric = 6.77% * 100;
 Minibatch[ 101- 200]: loss = 0.402594 * 100, metric = 5.74% * 100;
 Minibatch[ 201- 300]: loss = 0.411614 * 100, metric = 6.09% * 100;
 Minibatch[ 301- 400]: loss = 0.428790 * 100, metric = 6.71% * 100;
 Minibatch[ 401- 500]: loss = 0.420566 * 100, metric = 6.29% * 100;
 Minibatch[ 501- 600]: loss = 0.400200 * 100, metric = 5.98% * 100;
 Minibatch[ 601- 700]: loss = 0.414853 * 100, metric = 6.49% * 100;
 Minibatch[ 701- 800]: loss = 0.412057 * 100, metric = 6.09% * 100;
 Minibatch[ 801- 900]: loss = 0.416681 * 100, metric = 6.19% * 100;
 Minibatch[ 901-1000]: loss = 0.395915 * 100, metric = 5.91% * 100;
 Minibatch[1001-1100]: loss = 0.418324 * 100, metric = 6.10% * 100;
 Minibatch[1101-1200]: loss = 0.423091 * 100, metric = 6.21% * 100;
 Minibatch[1201-1300]: loss = 0.409705 * 100, metric = 6.04% * 100;
 Minibatch[1301-1400]: loss = 0.420007 * 100, metric = 6.24% * 100;
 Minibatch[1401-1500]: loss = 0.420523 * 100, metric = 6.51% * 100;
 Minibatch[1501-1600]: loss = 0.433662 * 100, metric = 6.63% * 100;
 Minibatch[1601-1700]: loss = 0.428370 * 100, metric = 6.25% * 100;
 Minibatch[1701-1800]: loss = 0.434112 * 100, metric = 6.45% * 100;
 Minibatch[1801-1900]: loss = 0.424229 * 100, metric = 6.57% * 100;
 Minibatch[1901-2000]: loss = 0.439770 * 100, metric = 6.69% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.419762 * 2000, metric = 6.30% * 2000 920.462s (  2.2 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 13.98% * 2000;
 Minibatch[   1- 100]: loss = 0.421717 * 100, metric = 6.12% * 100;
 Minibatch[ 101- 200]: loss = 0.429762 * 100, metric = 6.76% * 100;
 Minibatch[ 201- 300]: loss = 0.414376 * 100, metric = 6.31% * 100;
 Minibatch[ 301- 400]: loss = 0.413830 * 100, metric = 6.16% * 100;
 Minibatch[ 401- 500]: loss = 0.413138 * 100, metric = 6.26% * 100;
 Minibatch[ 501- 600]: loss = 0.408162 * 100, metric = 6.22% * 100;
 Minibatch[ 601- 700]: loss = 0.434182 * 100, metric = 6.66% * 100;
 Minibatch[ 701- 800]: loss = 0.432475 * 100, metric = 6.79% * 100;
 Minibatch[ 801- 900]: loss = 0.423850 * 100, metric = 6.23% * 100;
 Minibatch[ 901-1000]: loss = 0.413687 * 100, metric = 6.15% * 100;
 Minibatch[1001-1100]: loss = 0.412791 * 100, metric = 6.24% * 100;
 Minibatch[1101-1200]: loss = 0.415466 * 100, metric = 6.38% * 100;
 Minibatch[1201-1300]: loss = 0.413502 * 100, metric = 6.29% * 100;
 Minibatch[1301-1400]: loss = 0.413513 * 100, metric = 6.24% * 100;
 Minibatch[1401-1500]: loss = 0.412780 * 100, metric = 6.15% * 100;
 Minibatch[1501-1600]: loss = 0.399184 * 100, metric = 6.02% * 100;
 Minibatch[1601-1700]: loss = 0.420220 * 100, metric = 6.28% * 100;
 Minibatch[1701-1800]: loss = 0.411597 * 100, metric = 6.22% * 100;
 Minibatch[1801-1900]: loss = 0.416540 * 100, metric = 6.31% * 100;
 Minibatch[1901-2000]: loss = 0.408004 * 100, metric = 6.18% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.416439 * 2000, metric = 6.30% * 2000 911.961s (  2.2 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 14.11% * 2000;
 Minibatch[   1- 100]: loss = 0.411512 * 100, metric = 6.24% * 100;
 Minibatch[ 101- 200]: loss = 0.415884 * 100, metric = 6.10% * 100;
 Minibatch[ 201- 300]: loss = 0.425280 * 100, metric = 6.58% * 100;
 Minibatch[ 301- 400]: loss = 0.426024 * 100, metric = 6.31% * 100;
 Minibatch[ 401- 500]: loss = 0.410591 * 100, metric = 6.22% * 100;
 Minibatch[ 501- 600]: loss = 0.401332 * 100, metric = 6.15% * 100;
 Minibatch[ 601- 700]: loss = 0.403853 * 100, metric = 5.92% * 100;
 Minibatch[ 701- 800]: loss = 0.399648 * 100, metric = 5.98% * 100;
 Minibatch[ 801- 900]: loss = 0.402878 * 100, metric = 6.07% * 100;
 Minibatch[ 901-1000]: loss = 0.399701 * 100, metric = 5.94% * 100;
 Minibatch[1001-1100]: loss = 0.411688 * 100, metric = 6.07% * 100;
 Minibatch[1101-1200]: loss = 0.417486 * 100, metric = 6.30% * 100;
 Minibatch[1201-1300]: loss = 0.417469 * 100, metric = 6.36% * 100;
 Minibatch[1301-1400]: loss = 0.417964 * 100, metric = 6.42% * 100;
 Minibatch[1401-1500]: loss = 0.405242 * 100, metric = 6.20% * 100;
 Minibatch[1501-1600]: loss = 0.408240 * 100, metric = 5.98% * 100;
 Minibatch[1601-1700]: loss = 0.391464 * 100, metric = 5.68% * 100;
 Minibatch[1701-1800]: loss = 0.418664 * 100, metric = 6.24% * 100;
 Minibatch[1801-1900]: loss = 0.395880 * 100, metric = 5.81% * 100;
 Minibatch[1901-2000]: loss = 0.407779 * 100, metric = 6.22% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.409429 * 2000, metric = 6.14% * 2000 917.950s (  2.2 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.81% * 2000;
 Minibatch[   1- 100]: loss = 0.421823 * 100, metric = 6.64% * 100;
 Minibatch[ 101- 200]: loss = 0.406505 * 100, metric = 6.13% * 100;
 Minibatch[ 201- 300]: loss = 0.397153 * 100, metric = 6.02% * 100;
 Minibatch[ 301- 400]: loss = 0.403905 * 100, metric = 6.19% * 100;
 Minibatch[ 401- 500]: loss = 0.407197 * 100, metric = 6.06% * 100;
 Minibatch[ 501- 600]: loss = 0.409239 * 100, metric = 6.02% * 100;
 Minibatch[ 601- 700]: loss = 0.413449 * 100, metric = 6.21% * 100;
 Minibatch[ 701- 800]: loss = 0.409718 * 100, metric = 6.07% * 100;
 Minibatch[ 801- 900]: loss = 0.397710 * 100, metric = 5.87% * 100;
 Minibatch[ 901-1000]: loss = 0.391974 * 100, metric = 5.67% * 100;
 Minibatch[1001-1100]: loss = 0.403260 * 100, metric = 5.98% * 100;
 Minibatch[1101-1200]: loss = 0.394449 * 100, metric = 5.82% * 100;
 Minibatch[1201-1300]: loss = 0.419904 * 100, metric = 6.16% * 100;
 Minibatch[1301-1400]: loss = 0.396478 * 100, metric = 5.80% * 100;
 Minibatch[1401-1500]: loss = 0.430862 * 100, metric = 6.39% * 100;
 Minibatch[1501-1600]: loss = 0.425873 * 100, metric = 6.28% * 100;
 Minibatch[1601-1700]: loss = 0.401266 * 100, metric = 5.49% * 100;
 Minibatch[1701-1800]: loss = 0.391423 * 100, metric = 5.85% * 100;
 Minibatch[1801-1900]: loss = 0.394395 * 100, metric = 5.84% * 100;
 Minibatch[1901-2000]: loss = 0.407560 * 100, metric = 6.19% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.406207 * 2000, metric = 6.03% * 2000 909.295s (  2.2 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.25% * 2000;
 Minibatch[   1- 100]: loss = 0.399982 * 100, metric = 5.98% * 100;
 Minibatch[ 101- 200]: loss = 0.414421 * 100, metric = 6.35% * 100;
 Minibatch[ 201- 300]: loss = 0.396762 * 100, metric = 5.81% * 100;
 Minibatch[ 301- 400]: loss = 0.406464 * 100, metric = 6.12% * 100;
 Minibatch[ 401- 500]: loss = 0.389845 * 100, metric = 5.74% * 100;
 Minibatch[ 501- 600]: loss = 0.400348 * 100, metric = 5.85% * 100;
 Minibatch[ 601- 700]: loss = 0.411449 * 100, metric = 6.30% * 100;
 Minibatch[ 701- 800]: loss = 0.397743 * 100, metric = 5.97% * 100;
 Minibatch[ 801- 900]: loss = 0.383080 * 100, metric = 5.36% * 100;
 Minibatch[ 901-1000]: loss = 0.397205 * 100, metric = 5.87% * 100;
 Minibatch[1001-1100]: loss = 0.408912 * 100, metric = 5.98% * 100;
 Minibatch[1101-1200]: loss = 0.405052 * 100, metric = 6.06% * 100;
 Minibatch[1201-1300]: loss = 0.395975 * 100, metric = 5.86% * 100;
 Minibatch[1301-1400]: loss = 0.396774 * 100, metric = 5.70% * 100;
 Minibatch[1401-1500]: loss = 0.416709 * 100, metric = 6.33% * 100;
 Minibatch[1501-1600]: loss = 0.408413 * 100, metric = 5.99% * 100;
 Minibatch[1601-1700]: loss = 0.420135 * 100, metric = 6.27% * 100;
 Minibatch[1701-1800]: loss = 0.400912 * 100, metric = 5.94% * 100;
 Minibatch[1801-1900]: loss = 0.400966 * 100, metric = 5.96% * 100;
 Minibatch[1901-2000]: loss = 0.400776 * 100, metric = 5.69% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.402596 * 2000, metric = 5.96% * 2000 918.744s (  2.2 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 15.04% * 2000;
 Minibatch[   1- 100]: loss = 0.385066 * 100, metric = 5.55% * 100;
 Minibatch[ 101- 200]: loss = 0.397392 * 100, metric = 6.01% * 100;
 Minibatch[ 201- 300]: loss = 0.409391 * 100, metric = 6.15% * 100;
 Minibatch[ 301- 400]: loss = 0.389743 * 100, metric = 5.60% * 100;
 Minibatch[ 401- 500]: loss = 0.396000 * 100, metric = 5.70% * 100;
 Minibatch[ 501- 600]: loss = 0.373103 * 100, metric = 5.24% * 100;
 Minibatch[ 601- 700]: loss = 0.408651 * 100, metric = 6.11% * 100;
 Minibatch[ 701- 800]: loss = 0.384567 * 100, metric = 5.54% * 100;
 Minibatch[ 801- 900]: loss = 0.405131 * 100, metric = 6.03% * 100;
 Minibatch[ 901-1000]: loss = 0.380494 * 100, metric = 5.64% * 100;
 Minibatch[1001-1100]: loss = 0.402172 * 100, metric = 5.86% * 100;
 Minibatch[1101-1200]: loss = 0.397261 * 100, metric = 5.75% * 100;
 Minibatch[1201-1300]: loss = 0.396942 * 100, metric = 5.97% * 100;
 Minibatch[1301-1400]: loss = 0.399044 * 100, metric = 5.85% * 100;
 Minibatch[1401-1500]: loss = 0.397700 * 100, metric = 5.72% * 100;
 Minibatch[1501-1600]: loss = 0.398697 * 100, metric = 5.83% * 100;
 Minibatch[1601-1700]: loss = 0.396927 * 100, metric = 5.90% * 100;
 Minibatch[1701-1800]: loss = 0.391219 * 100, metric = 5.72% * 100;
 Minibatch[1801-1900]: loss = 0.399737 * 100, metric = 5.88% * 100;
 Minibatch[1901-2000]: loss = 0.388909 * 100, metric = 5.75% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.394907 * 2000, metric = 5.79% * 2000 914.745s (  2.2 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.22% * 2000;
 Minibatch[   1- 100]: loss = 0.387030 * 100, metric = 5.45% * 100;
 Minibatch[ 101- 200]: loss = 0.373591 * 100, metric = 5.46% * 100;
 Minibatch[ 201- 300]: loss = 0.406143 * 100, metric = 6.07% * 100;
 Minibatch[ 301- 400]: loss = 0.380275 * 100, metric = 5.46% * 100;
 Minibatch[ 401- 500]: loss = 0.384837 * 100, metric = 5.54% * 100;
 Minibatch[ 501- 600]: loss = 0.388648 * 100, metric = 5.45% * 100;
 Minibatch[ 601- 700]: loss = 0.406745 * 100, metric = 5.75% * 100;
 Minibatch[ 701- 800]: loss = 0.391553 * 100, metric = 5.59% * 100;
 Minibatch[ 801- 900]: loss = 0.378796 * 100, metric = 5.45% * 100;
 Minibatch[ 901-1000]: loss = 0.399423 * 100, metric = 5.89% * 100;
 Minibatch[1001-1100]: loss = 0.397993 * 100, metric = 5.91% * 100;
 Minibatch[1101-1200]: loss = 0.384737 * 100, metric = 5.67% * 100;
 Minibatch[1201-1300]: loss = 0.388541 * 100, metric = 5.64% * 100;
 Minibatch[1301-1400]: loss = 0.365788 * 100, metric = 5.23% * 100;
 Minibatch[1401-1500]: loss = 0.380745 * 100, metric = 5.41% * 100;
 Minibatch[1501-1600]: loss = 0.376899 * 100, metric = 5.34% * 100;
 Minibatch[1601-1700]: loss = 0.394521 * 100, metric = 5.95% * 100;
 Minibatch[1701-1800]: loss = 0.388242 * 100, metric = 5.58% * 100;
 Minibatch[1801-1900]: loss = 0.385040 * 100, metric = 5.46% * 100;
 Minibatch[1901-2000]: loss = 0.387987 * 100, metric = 5.54% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.387377 * 2000, metric = 5.59% * 2000 906.276s (  2.2 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.04% * 2000;
 Minibatch[   1- 100]: loss = 0.386109 * 100, metric = 5.56% * 100;
 Minibatch[ 101- 200]: loss = 0.387312 * 100, metric = 5.61% * 100;
 Minibatch[ 201- 300]: loss = 0.385199 * 100, metric = 5.65% * 100;
 Minibatch[ 301- 400]: loss = 0.390677 * 100, metric = 5.58% * 100;
 Minibatch[ 401- 500]: loss = 0.382236 * 100, metric = 5.72% * 100;
 Minibatch[ 501- 600]: loss = 0.377668 * 100, metric = 5.55% * 100;
 Minibatch[ 601- 700]: loss = 0.385091 * 100, metric = 5.56% * 100;
 Minibatch[ 701- 800]: loss = 0.403126 * 100, metric = 6.03% * 100;
 Minibatch[ 801- 900]: loss = 0.382252 * 100, metric = 5.35% * 100;
 Minibatch[ 901-1000]: loss = 0.365486 * 100, metric = 5.11% * 100;
 Minibatch[1001-1100]: loss = 0.380965 * 100, metric = 5.43% * 100;
 Minibatch[1101-1200]: loss = 0.387397 * 100, metric = 5.72% * 100;
 Minibatch[1201-1300]: loss = 0.396690 * 100, metric = 5.89% * 100;
 Minibatch[1301-1400]: loss = 0.381989 * 100, metric = 5.52% * 100;
 Minibatch[1401-1500]: loss = 0.381462 * 100, metric = 5.57% * 100;
 Minibatch[1501-1600]: loss = 0.371951 * 100, metric = 5.27% * 100;
 Minibatch[1601-1700]: loss = 0.386728 * 100, metric = 5.74% * 100;
 Minibatch[1701-1800]: loss = 0.377637 * 100, metric = 5.38% * 100;
 Minibatch[1801-1900]: loss = 0.380599 * 100, metric = 5.60% * 100;
 Minibatch[1901-2000]: loss = 0.388631 * 100, metric = 5.66% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.383960 * 2000, metric = 5.58% * 2000 922.338s (  2.2 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.04% * 2000;
 Minibatch[   1- 100]: loss = 0.390234 * 100, metric = 5.75% * 100;
 Minibatch[ 101- 200]: loss = 0.383450 * 100, metric = 5.64% * 100;
 Minibatch[ 201- 300]: loss = 0.372234 * 100, metric = 5.33% * 100;
 Minibatch[ 301- 400]: loss = 0.375723 * 100, metric = 5.37% * 100;
 Minibatch[ 401- 500]: loss = 0.382104 * 100, metric = 5.46% * 100;
 Minibatch[ 501- 600]: loss = 0.380235 * 100, metric = 5.31% * 100;
 Minibatch[ 601- 700]: loss = 0.384328 * 100, metric = 5.56% * 100;
 Minibatch[ 701- 800]: loss = 0.375681 * 100, metric = 5.47% * 100;
 Minibatch[ 801- 900]: loss = 0.382245 * 100, metric = 5.51% * 100;
 Minibatch[ 901-1000]: loss = 0.384066 * 100, metric = 5.61% * 100;
 Minibatch[1001-1100]: loss = 0.388926 * 100, metric = 5.74% * 100;
 Minibatch[1101-1200]: loss = 0.373712 * 100, metric = 5.34% * 100;
 Minibatch[1201-1300]: loss = 0.380293 * 100, metric = 5.41% * 100;
 Minibatch[1301-1400]: loss = 0.385963 * 100, metric = 5.52% * 100;
 Minibatch[1401-1500]: loss = 0.382657 * 100, metric = 5.40% * 100;
 Minibatch[1501-1600]: loss = 0.391562 * 100, metric = 5.59% * 100;
 Minibatch[1601-1700]: loss = 0.371459 * 100, metric = 5.34% * 100;
 Minibatch[1701-1800]: loss = 0.387135 * 100, metric = 5.68% * 100;
 Minibatch[1801-1900]: loss = 0.390392 * 100, metric = 5.61% * 100;
 Minibatch[1901-2000]: loss = 0.385587 * 100, metric = 5.57% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.382399 * 2000, metric = 5.51% * 2000 907.440s (  2.2 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 12.87% * 2000;
 Minibatch[   1- 100]: loss = 0.370618 * 100, metric = 5.14% * 100;
 Minibatch[ 101- 200]: loss = 0.393350 * 100, metric = 5.71% * 100;
 Minibatch[ 201- 300]: loss = 0.376225 * 100, metric = 5.26% * 100;
 Minibatch[ 301- 400]: loss = 0.374395 * 100, metric = 5.29% * 100;
 Minibatch[ 401- 500]: loss = 0.383020 * 100, metric = 5.57% * 100;
 Minibatch[ 501- 600]: loss = 0.391414 * 100, metric = 5.57% * 100;
 Minibatch[ 601- 700]: loss = 0.377708 * 100, metric = 5.58% * 100;
 Minibatch[ 701- 800]: loss = 0.396660 * 100, metric = 5.71% * 100;
 Minibatch[ 801- 900]: loss = 0.374261 * 100, metric = 5.38% * 100;
 Minibatch[ 901-1000]: loss = 0.383584 * 100, metric = 5.39% * 100;
 Minibatch[1001-1100]: loss = 0.382563 * 100, metric = 5.70% * 100;
 Minibatch[1101-1200]: loss = 0.387065 * 100, metric = 5.84% * 100;
 Minibatch[1201-1300]: loss = 0.381467 * 100, metric = 5.38% * 100;
 Minibatch[1301-1400]: loss = 0.391518 * 100, metric = 5.71% * 100;
 Minibatch[1401-1500]: loss = 0.392739 * 100, metric = 5.82% * 100;
 Minibatch[1501-1600]: loss = 0.385559 * 100, metric = 5.73% * 100;
 Minibatch[1601-1700]: loss = 0.379502 * 100, metric = 5.39% * 100;
 Minibatch[1701-1800]: loss = 0.394037 * 100, metric = 5.61% * 100;
 Minibatch[1801-1900]: loss = 0.383890 * 100, metric = 5.39% * 100;
 Minibatch[1901-2000]: loss = 0.376883 * 100, metric = 5.44% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.383823 * 2000, metric = 5.53% * 2000 903.476s (  2.2 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.74% * 2000;
 Minibatch[   1- 100]: loss = 0.376611 * 100, metric = 5.44% * 100;
 Minibatch[ 101- 200]: loss = 0.363166 * 100, metric = 5.19% * 100;
 Minibatch[ 201- 300]: loss = 0.379690 * 100, metric = 5.41% * 100;
 Minibatch[ 301- 400]: loss = 0.375132 * 100, metric = 5.38% * 100;
 Minibatch[ 401- 500]: loss = 0.376086 * 100, metric = 5.44% * 100;
 Minibatch[ 501- 600]: loss = 0.370199 * 100, metric = 5.51% * 100;
 Minibatch[ 601- 700]: loss = 0.396709 * 100, metric = 5.63% * 100;
 Minibatch[ 701- 800]: loss = 0.373931 * 100, metric = 5.15% * 100;
 Minibatch[ 801- 900]: loss = 0.377338 * 100, metric = 5.29% * 100;
 Minibatch[ 901-1000]: loss = 0.376782 * 100, metric = 5.27% * 100;
 Minibatch[1001-1100]: loss = 0.383042 * 100, metric = 5.62% * 100;
 Minibatch[1101-1200]: loss = 0.382201 * 100, metric = 5.48% * 100;
 Minibatch[1201-1300]: loss = 0.380106 * 100, metric = 5.40% * 100;
 Minibatch[1301-1400]: loss = 0.375532 * 100, metric = 5.33% * 100;
 Minibatch[1401-1500]: loss = 0.369433 * 100, metric = 5.21% * 100;
 Minibatch[1501-1600]: loss = 0.388671 * 100, metric = 5.53% * 100;
 Minibatch[1601-1700]: loss = 0.379316 * 100, metric = 5.35% * 100;
 Minibatch[1701-1800]: loss = 0.372145 * 100, metric = 5.14% * 100;
 Minibatch[1801-1900]: loss = 0.375703 * 100, metric = 5.14% * 100;
 Minibatch[1901-2000]: loss = 0.382299 * 100, metric = 5.47% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.377705 * 2000, metric = 5.37% * 2000 902.509s (  2.2 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 12.98% * 2000;
 Minibatch[   1- 100]: loss = 0.375196 * 100, metric = 5.42% * 100;
 Minibatch[ 101- 200]: loss = 0.375669 * 100, metric = 5.36% * 100;
 Minibatch[ 201- 300]: loss = 0.378233 * 100, metric = 5.38% * 100;
 Minibatch[ 301- 400]: loss = 0.387169 * 100, metric = 5.69% * 100;
 Minibatch[ 401- 500]: loss = 0.380636 * 100, metric = 5.62% * 100;
 Minibatch[ 501- 600]: loss = 0.371242 * 100, metric = 5.21% * 100;
 Minibatch[ 601- 700]: loss = 0.375097 * 100, metric = 5.39% * 100;
 Minibatch[ 701- 800]: loss = 0.380762 * 100, metric = 5.46% * 100;
 Minibatch[ 801- 900]: loss = 0.368136 * 100, metric = 5.31% * 100;
 Minibatch[ 901-1000]: loss = 0.377169 * 100, metric = 5.48% * 100;
 Minibatch[1001-1100]: loss = 0.380153 * 100, metric = 5.28% * 100;
 Minibatch[1101-1200]: loss = 0.386496 * 100, metric = 5.55% * 100;
 Minibatch[1201-1300]: loss = 0.382874 * 100, metric = 5.44% * 100;
 Minibatch[1301-1400]: loss = 0.370223 * 100, metric = 5.21% * 100;
 Minibatch[1401-1500]: loss = 0.373569 * 100, metric = 5.25% * 100;
 Minibatch[1501-1600]: loss = 0.375009 * 100, metric = 5.22% * 100;
 Minibatch[1601-1700]: loss = 0.380222 * 100, metric = 5.31% * 100;
 Minibatch[1701-1800]: loss = 0.379944 * 100, metric = 5.34% * 100;
 Minibatch[1801-1900]: loss = 0.377344 * 100, metric = 5.29% * 100;
 Minibatch[1901-2000]: loss = 0.370941 * 100, metric = 5.02% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.377304 * 2000, metric = 5.36% * 2000 906.449s (  2.2 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 13.08% * 2000;
 Minibatch[   1- 100]: loss = 0.375161 * 100, metric = 5.24% * 100;
 Minibatch[ 101- 200]: loss = 0.373249 * 100, metric = 5.22% * 100;
 Minibatch[ 201- 300]: loss = 0.378731 * 100, metric = 5.22% * 100;
 Minibatch[ 301- 400]: loss = 0.374264 * 100, metric = 5.23% * 100;
 Minibatch[ 401- 500]: loss = 0.371798 * 100, metric = 5.12% * 100;
 Minibatch[ 501- 600]: loss = 0.375036 * 100, metric = 5.29% * 100;
 Minibatch[ 601- 700]: loss = 0.377437 * 100, metric = 5.36% * 100;
 Minibatch[ 701- 800]: loss = 0.363730 * 100, metric = 5.21% * 100;
 Minibatch[ 801- 900]: loss = 0.361585 * 100, metric = 5.12% * 100;
 Minibatch[ 901-1000]: loss = 0.391086 * 100, metric = 5.71% * 100;
 Minibatch[1001-1100]: loss = 0.363841 * 100, metric = 5.11% * 100;
 Minibatch[1101-1200]: loss = 0.360896 * 100, metric = 5.05% * 100;
 Minibatch[1201-1300]: loss = 0.368755 * 100, metric = 5.26% * 100;
 Minibatch[1301-1400]: loss = 0.374833 * 100, metric = 5.29% * 100;
 Minibatch[1401-1500]: loss = 0.370996 * 100, metric = 5.21% * 100;
 Minibatch[1501-1600]: loss = 0.372565 * 100, metric = 5.13% * 100;
 Minibatch[1601-1700]: loss = 0.378277 * 100, metric = 5.29% * 100;
 Minibatch[1701-1800]: loss = 0.373862 * 100, metric = 5.20% * 100;
 Minibatch[1801-1900]: loss = 0.375768 * 100, metric = 5.25% * 100;
 Minibatch[1901-2000]: loss = 0.369825 * 100, metric = 5.08% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.372585 * 2000, metric = 5.23% * 2000 898.906s (  2.2 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 12.35% * 2000;
0.5877788739800454
 Minibatch[   1- 100]: loss = 0.389533 * 100, metric = 5.71% * 100;
 Minibatch[ 101- 200]: loss = 0.372926 * 100, metric = 5.13% * 100;
 Minibatch[ 201- 300]: loss = 0.377423 * 100, metric = 5.19% * 100;
 Minibatch[ 301- 400]: loss = 0.374043 * 100, metric = 5.28% * 100;
 Minibatch[ 401- 500]: loss = 0.369958 * 100, metric = 5.05% * 100;
 Minibatch[ 501- 600]: loss = 0.370407 * 100, metric = 5.15% * 100;
 Minibatch[ 601- 700]: loss = 0.381827 * 100, metric = 5.44% * 100;
 Minibatch[ 701- 800]: loss = 0.356200 * 100, metric = 5.01% * 100;
 Minibatch[ 801- 900]: loss = 0.364079 * 100, metric = 4.97% * 100;
 Minibatch[ 901-1000]: loss = 0.370934 * 100, metric = 5.17% * 100;
 Minibatch[1001-1100]: loss = 0.381674 * 100, metric = 5.42% * 100;
 Minibatch[1101-1200]: loss = 0.374988 * 100, metric = 5.26% * 100;
 Minibatch[1201-1300]: loss = 0.377012 * 100, metric = 5.53% * 100;
 Minibatch[1301-1400]: loss = 0.374126 * 100, metric = 5.36% * 100;
 Minibatch[1401-1500]: loss = 0.357886 * 100, metric = 4.96% * 100;
 Minibatch[1501-1600]: loss = 0.381882 * 100, metric = 5.31% * 100;
 Minibatch[1601-1700]: loss = 0.363565 * 100, metric = 5.05% * 100;
 Minibatch[1701-1800]: loss = 0.377842 * 100, metric = 5.35% * 100;
 Minibatch[1801-1900]: loss = 0.372233 * 100, metric = 5.43% * 100;
 Minibatch[1901-2000]: loss = 0.371277 * 100, metric = 5.24% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.372991 * 2000, metric = 5.25% * 2000 905.395s (  2.2 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 13.07% * 2000;
 Minibatch[   1- 100]: loss = 0.368490 * 100, metric = 5.26% * 100;
 Minibatch[ 101- 200]: loss = 0.369408 * 100, metric = 5.18% * 100;
 Minibatch[ 201- 300]: loss = 0.367225 * 100, metric = 5.15% * 100;
 Minibatch[ 301- 400]: loss = 0.377307 * 100, metric = 5.22% * 100;
 Minibatch[ 401- 500]: loss = 0.370322 * 100, metric = 5.15% * 100;
 Minibatch[ 501- 600]: loss = 0.358098 * 100, metric = 5.06% * 100;
 Minibatch[ 601- 700]: loss = 0.370878 * 100, metric = 5.38% * 100;
 Minibatch[ 701- 800]: loss = 0.343950 * 100, metric = 4.67% * 100;
 Minibatch[ 801- 900]: loss = 0.357718 * 100, metric = 4.78% * 100;
 Minibatch[ 901-1000]: loss = 0.356443 * 100, metric = 4.92% * 100;
 Minibatch[1001-1100]: loss = 0.354032 * 100, metric = 4.71% * 100;
 Minibatch[1101-1200]: loss = 0.349692 * 100, metric = 4.57% * 100;
 Minibatch[1201-1300]: loss = 0.359137 * 100, metric = 5.06% * 100;
 Minibatch[1301-1400]: loss = 0.350345 * 100, metric = 4.88% * 100;
 Minibatch[1401-1500]: loss = 0.355010 * 100, metric = 4.83% * 100;
 Minibatch[1501-1600]: loss = 0.348127 * 100, metric = 4.85% * 100;
 Minibatch[1601-1700]: loss = 0.355990 * 100, metric = 4.83% * 100;
 Minibatch[1701-1800]: loss = 0.374261 * 100, metric = 5.36% * 100;
 Minibatch[1801-1900]: loss = 0.367750 * 100, metric = 5.11% * 100;
 Minibatch[1901-2000]: loss = 0.358042 * 100, metric = 4.90% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.360611 * 2000, metric = 4.99% * 2000 907.699s (  2.2 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 13.23% * 2000;
 Minibatch[   1- 100]: loss = 0.367604 * 100, metric = 4.97% * 100;
 Minibatch[ 101- 200]: loss = 0.358174 * 100, metric = 4.74% * 100;
 Minibatch[ 201- 300]: loss = 0.358900 * 100, metric = 4.84% * 100;
 Minibatch[ 301- 400]: loss = 0.368976 * 100, metric = 5.16% * 100;
 Minibatch[ 401- 500]: loss = 0.359059 * 100, metric = 5.03% * 100;
 Minibatch[ 501- 600]: loss = 0.356557 * 100, metric = 4.68% * 100;
 Minibatch[ 601- 700]: loss = 0.361862 * 100, metric = 5.05% * 100;
 Minibatch[ 701- 800]: loss = 0.345915 * 100, metric = 4.86% * 100;
 Minibatch[ 801- 900]: loss = 0.376116 * 100, metric = 5.30% * 100;
 Minibatch[ 901-1000]: loss = 0.360262 * 100, metric = 4.99% * 100;
 Minibatch[1001-1100]: loss = 0.356988 * 100, metric = 4.84% * 100;
 Minibatch[1101-1200]: loss = 0.369179 * 100, metric = 5.12% * 100;
 Minibatch[1201-1300]: loss = 0.362317 * 100, metric = 4.92% * 100;
 Minibatch[1301-1400]: loss = 0.351635 * 100, metric = 4.83% * 100;
 Minibatch[1401-1500]: loss = 0.365559 * 100, metric = 4.96% * 100;
 Minibatch[1501-1600]: loss = 0.361653 * 100, metric = 4.86% * 100;
 Minibatch[1601-1700]: loss = 0.348469 * 100, metric = 4.81% * 100;
 Minibatch[1701-1800]: loss = 0.368428 * 100, metric = 5.04% * 100;
 Minibatch[1801-1900]: loss = 0.356521 * 100, metric = 5.00% * 100;
 Minibatch[1901-2000]: loss = 0.357335 * 100, metric = 4.63% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.360576 * 2000, metric = 4.93% * 2000 903.619s (  2.2 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 13.21% * 2000;
 Minibatch[   1- 100]: loss = 0.353356 * 100, metric = 4.87% * 100;
 Minibatch[ 101- 200]: loss = 0.375099 * 100, metric = 5.34% * 100;
 Minibatch[ 201- 300]: loss = 0.368108 * 100, metric = 5.26% * 100;
 Minibatch[ 301- 400]: loss = 0.382771 * 100, metric = 5.34% * 100;
 Minibatch[ 401- 500]: loss = 0.367489 * 100, metric = 4.84% * 100;
 Minibatch[ 501- 600]: loss = 0.361243 * 100, metric = 4.96% * 100;
 Minibatch[ 601- 700]: loss = 0.347582 * 100, metric = 4.72% * 100;
 Minibatch[ 701- 800]: loss = 0.347773 * 100, metric = 4.75% * 100;
 Minibatch[ 801- 900]: loss = 0.360069 * 100, metric = 4.88% * 100;
 Minibatch[ 901-1000]: loss = 0.361377 * 100, metric = 5.00% * 100;
 Minibatch[1001-1100]: loss = 0.358817 * 100, metric = 4.91% * 100;
 Minibatch[1101-1200]: loss = 0.370269 * 100, metric = 5.17% * 100;
 Minibatch[1201-1300]: loss = 0.365895 * 100, metric = 5.17% * 100;
 Minibatch[1301-1400]: loss = 0.372824 * 100, metric = 5.13% * 100;
 Minibatch[1401-1500]: loss = 0.358799 * 100, metric = 5.05% * 100;
 Minibatch[1501-1600]: loss = 0.365967 * 100, metric = 5.04% * 100;
 Minibatch[1601-1700]: loss = 0.351024 * 100, metric = 4.62% * 100;
 Minibatch[1701-1800]: loss = 0.369328 * 100, metric = 5.12% * 100;
 Minibatch[1801-1900]: loss = 0.342216 * 100, metric = 4.48% * 100;
 Minibatch[1901-2000]: loss = 0.358890 * 100, metric = 4.92% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.361945 * 2000, metric = 4.98% * 2000 902.586s (  2.2 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 12.83% * 2000;
 Minibatch[   1- 100]: loss = 0.358999 * 100, metric = 4.92% * 100;
 Minibatch[ 101- 200]: loss = 0.355635 * 100, metric = 5.00% * 100;
 Minibatch[ 201- 300]: loss = 0.360892 * 100, metric = 4.77% * 100;
 Minibatch[ 301- 400]: loss = 0.363635 * 100, metric = 4.97% * 100;
 Minibatch[ 401- 500]: loss = 0.361194 * 100, metric = 4.91% * 100;
 Minibatch[ 501- 600]: loss = 0.349588 * 100, metric = 4.86% * 100;
 Minibatch[ 601- 700]: loss = 0.362214 * 100, metric = 5.09% * 100;
 Minibatch[ 701- 800]: loss = 0.366702 * 100, metric = 5.15% * 100;
 Minibatch[ 801- 900]: loss = 0.354694 * 100, metric = 4.80% * 100;
 Minibatch[ 901-1000]: loss = 0.364365 * 100, metric = 4.85% * 100;
 Minibatch[1001-1100]: loss = 0.365867 * 100, metric = 5.06% * 100;
 Minibatch[1101-1200]: loss = 0.353909 * 100, metric = 4.77% * 100;
 Minibatch[1201-1300]: loss = 0.343410 * 100, metric = 4.57% * 100;
 Minibatch[1301-1400]: loss = 0.338400 * 100, metric = 4.57% * 100;
 Minibatch[1401-1500]: loss = 0.364046 * 100, metric = 4.92% * 100;
 Minibatch[1501-1600]: loss = 0.366904 * 100, metric = 4.99% * 100;
 Minibatch[1601-1700]: loss = 0.356689 * 100, metric = 4.79% * 100;
 Minibatch[1701-1800]: loss = 0.377706 * 100, metric = 5.28% * 100;
 Minibatch[1801-1900]: loss = 0.366484 * 100, metric = 5.06% * 100;
 Minibatch[1901-2000]: loss = 0.375504 * 100, metric = 5.02% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.360342 * 2000, metric = 4.92% * 2000 903.125s (  2.2 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 12.18% * 2000;
 Minibatch[   1- 100]: loss = 0.364041 * 100, metric = 4.98% * 100;
 Minibatch[ 101- 200]: loss = 0.358511 * 100, metric = 4.86% * 100;
 Minibatch[ 201- 300]: loss = 0.348615 * 100, metric = 4.95% * 100;
 Minibatch[ 301- 400]: loss = 0.340507 * 100, metric = 4.73% * 100;
 Minibatch[ 401- 500]: loss = 0.358710 * 100, metric = 4.91% * 100;
 Minibatch[ 501- 600]: loss = 0.358695 * 100, metric = 4.99% * 100;
 Minibatch[ 601- 700]: loss = 0.378742 * 100, metric = 5.29% * 100;
 Minibatch[ 701- 800]: loss = 0.352865 * 100, metric = 4.75% * 100;
 Minibatch[ 801- 900]: loss = 0.349076 * 100, metric = 4.70% * 100;
 Minibatch[ 901-1000]: loss = 0.352006 * 100, metric = 4.91% * 100;
 Minibatch[1001-1100]: loss = 0.355369 * 100, metric = 4.99% * 100;
 Minibatch[1101-1200]: loss = 0.358213 * 100, metric = 4.88% * 100;
 Minibatch[1201-1300]: loss = 0.347436 * 100, metric = 4.79% * 100;
 Minibatch[1301-1400]: loss = 0.352860 * 100, metric = 4.85% * 100;
 Minibatch[1401-1500]: loss = 0.354403 * 100, metric = 5.05% * 100;
 Minibatch[1501-1600]: loss = 0.346990 * 100, metric = 4.92% * 100;
 Minibatch[1601-1700]: loss = 0.344524 * 100, metric = 4.51% * 100;
 Minibatch[1701-1800]: loss = 0.349476 * 100, metric = 4.75% * 100;
 Minibatch[1801-1900]: loss = 0.360314 * 100, metric = 4.91% * 100;
 Minibatch[1901-2000]: loss = 0.346830 * 100, metric = 4.59% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.353909 * 2000, metric = 4.87% * 2000 901.266s (  2.2 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 12.54% * 2000;
 Minibatch[   1- 100]: loss = 0.368959 * 100, metric = 5.02% * 100;
 Minibatch[ 101- 200]: loss = 0.351906 * 100, metric = 4.83% * 100;
 Minibatch[ 201- 300]: loss = 0.359809 * 100, metric = 4.86% * 100;
 Minibatch[ 301- 400]: loss = 0.341919 * 100, metric = 4.57% * 100;
 Minibatch[ 401- 500]: loss = 0.363603 * 100, metric = 5.02% * 100;
 Minibatch[ 501- 600]: loss = 0.357071 * 100, metric = 4.95% * 100;
 Minibatch[ 601- 700]: loss = 0.349623 * 100, metric = 4.71% * 100;
 Minibatch[ 701- 800]: loss = 0.341420 * 100, metric = 4.75% * 100;
 Minibatch[ 801- 900]: loss = 0.348662 * 100, metric = 4.75% * 100;
 Minibatch[ 901-1000]: loss = 0.354481 * 100, metric = 5.01% * 100;
 Minibatch[1001-1100]: loss = 0.361576 * 100, metric = 4.95% * 100;
 Minibatch[1101-1200]: loss = 0.351522 * 100, metric = 4.79% * 100;
 Minibatch[1201-1300]: loss = 0.329959 * 100, metric = 4.46% * 100;
 Minibatch[1301-1400]: loss = 0.355868 * 100, metric = 4.94% * 100;
 Minibatch[1401-1500]: loss = 0.351651 * 100, metric = 4.92% * 100;
 Minibatch[1501-1600]: loss = 0.334873 * 100, metric = 4.25% * 100;
 Minibatch[1601-1700]: loss = 0.358839 * 100, metric = 5.04% * 100;
 Minibatch[1701-1800]: loss = 0.361301 * 100, metric = 4.98% * 100;
 Minibatch[1801-1900]: loss = 0.356096 * 100, metric = 4.78% * 100;
 Minibatch[1901-2000]: loss = 0.350966 * 100, metric = 4.67% * 100;
Finished Epoch[49 of 200]: [Training] loss = 0.352505 * 2000, metric = 4.81% * 2000 894.160s (  2.2 samples/s);
Finished Evaluation [49]: Minibatch[1-2000]: metric = 11.78% * 2000;
 Minibatch[   1- 100]: loss = 0.350649 * 100, metric = 4.76% * 100;
 Minibatch[ 101- 200]: loss = 0.341882 * 100, metric = 4.63% * 100;
 Minibatch[ 201- 300]: loss = 0.338164 * 100, metric = 4.41% * 100;
 Minibatch[ 301- 400]: loss = 0.349947 * 100, metric = 4.52% * 100;
 Minibatch[ 401- 500]: loss = 0.356539 * 100, metric = 4.85% * 100;
 Minibatch[ 501- 600]: loss = 0.360268 * 100, metric = 4.94% * 100;
 Minibatch[ 601- 700]: loss = 0.338506 * 100, metric = 4.64% * 100;
 Minibatch[ 701- 800]: loss = 0.337247 * 100, metric = 4.53% * 100;
 Minibatch[ 801- 900]: loss = 0.358299 * 100, metric = 4.69% * 100;
 Minibatch[ 901-1000]: loss = 0.349292 * 100, metric = 4.60% * 100;
 Minibatch[1001-1100]: loss = 0.347744 * 100, metric = 4.80% * 100;
 Minibatch[1101-1200]: loss = 0.345529 * 100, metric = 4.84% * 100;
 Minibatch[1201-1300]: loss = 0.343657 * 100, metric = 4.74% * 100;
 Minibatch[1301-1400]: loss = 0.336422 * 100, metric = 4.56% * 100;
 Minibatch[1401-1500]: loss = 0.349680 * 100, metric = 4.77% * 100;
 Minibatch[1501-1600]: loss = 0.336081 * 100, metric = 4.45% * 100;
 Minibatch[1601-1700]: loss = 0.329357 * 100, metric = 4.23% * 100;
 Minibatch[1701-1800]: loss = 0.353221 * 100, metric = 4.87% * 100;
 Minibatch[1801-1900]: loss = 0.356262 * 100, metric = 4.79% * 100;
 Minibatch[1901-2000]: loss = 0.344843 * 100, metric = 4.58% * 100;
Finished Epoch[50 of 200]: [Training] loss = 0.346180 * 2000, metric = 4.66% * 2000 896.695s (  2.2 samples/s);
Finished Evaluation [50]: Minibatch[1-2000]: metric = 13.36% * 2000;
 Minibatch[   1- 100]: loss = 0.332857 * 100, metric = 4.44% * 100;
 Minibatch[ 101- 200]: loss = 0.352387 * 100, metric = 4.75% * 100;
 Minibatch[ 201- 300]: loss = 0.358585 * 100, metric = 4.66% * 100;
 Minibatch[ 301- 400]: loss = 0.347918 * 100, metric = 4.71% * 100;
 Minibatch[ 401- 500]: loss = 0.346411 * 100, metric = 4.55% * 100;
 Minibatch[ 501- 600]: loss = 0.341602 * 100, metric = 4.71% * 100;
 Minibatch[ 601- 700]: loss = 0.333916 * 100, metric = 4.54% * 100;
 Minibatch[ 701- 800]: loss = 0.344328 * 100, metric = 4.60% * 100;
 Minibatch[ 801- 900]: loss = 0.335314 * 100, metric = 4.48% * 100;
 Minibatch[ 901-1000]: loss = 0.339804 * 100, metric = 4.55% * 100;
 Minibatch[1001-1100]: loss = 0.334032 * 100, metric = 4.58% * 100;
 Minibatch[1101-1200]: loss = 0.358679 * 100, metric = 4.83% * 100;
 Minibatch[1201-1300]: loss = 0.356808 * 100, metric = 4.79% * 100;
 Minibatch[1301-1400]: loss = 0.351499 * 100, metric = 4.69% * 100;
 Minibatch[1401-1500]: loss = 0.333137 * 100, metric = 4.42% * 100;
 Minibatch[1501-1600]: loss = 0.351387 * 100, metric = 4.62% * 100;
 Minibatch[1601-1700]: loss = 0.332690 * 100, metric = 4.48% * 100;
 Minibatch[1701-1800]: loss = 0.338253 * 100, metric = 4.67% * 100;
 Minibatch[1801-1900]: loss = 0.322904 * 100, metric = 4.09% * 100;
 Minibatch[1901-2000]: loss = 0.336177 * 100, metric = 4.56% * 100;
Finished Epoch[51 of 200]: [Training] loss = 0.342434 * 2000, metric = 4.59% * 2000 897.767s (  2.2 samples/s);
Finished Evaluation [51]: Minibatch[1-2000]: metric = 12.39% * 2000;
 Minibatch[   1- 100]: loss = 0.329016 * 100, metric = 4.51% * 100;
 Minibatch[ 101- 200]: loss = 0.340559 * 100, metric = 4.53% * 100;
 Minibatch[ 201- 300]: loss = 0.350982 * 100, metric = 4.70% * 100;
 Minibatch[ 301- 400]: loss = 0.334648 * 100, metric = 4.52% * 100;
 Minibatch[ 401- 500]: loss = 0.341599 * 100, metric = 4.54% * 100;
 Minibatch[ 501- 600]: loss = 0.345149 * 100, metric = 4.67% * 100;
 Minibatch[ 601- 700]: loss = 0.330668 * 100, metric = 4.44% * 100;
 Minibatch[ 701- 800]: loss = 0.349661 * 100, metric = 4.76% * 100;
 Minibatch[ 801- 900]: loss = 0.343998 * 100, metric = 4.53% * 100;
 Minibatch[ 901-1000]: loss = 0.355122 * 100, metric = 4.76% * 100;
 Minibatch[1001-1100]: loss = 0.334913 * 100, metric = 4.53% * 100;
 Minibatch[1101-1200]: loss = 0.338657 * 100, metric = 4.30% * 100;
 Minibatch[1201-1300]: loss = 0.322167 * 100, metric = 4.12% * 100;
 Minibatch[1301-1400]: loss = 0.340467 * 100, metric = 4.29% * 100;
 Minibatch[1401-1500]: loss = 0.325317 * 100, metric = 4.27% * 100;
 Minibatch[1501-1600]: loss = 0.329920 * 100, metric = 4.29% * 100;
 Minibatch[1601-1700]: loss = 0.347729 * 100, metric = 4.62% * 100;
 Minibatch[1701-1800]: loss = 0.327033 * 100, metric = 4.48% * 100;
 Minibatch[1801-1900]: loss = 0.330158 * 100, metric = 4.15% * 100;
 Minibatch[1901-2000]: loss = 0.346073 * 100, metric = 4.66% * 100;
Finished Epoch[52 of 200]: [Training] loss = 0.338192 * 2000, metric = 4.48% * 2000 893.158s (  2.2 samples/s);
Finished Evaluation [52]: Minibatch[1-2000]: metric = 13.32% * 2000;
 Minibatch[   1- 100]: loss = 0.346568 * 100, metric = 4.60% * 100;
 Minibatch[ 101- 200]: loss = 0.324965 * 100, metric = 4.24% * 100;
 Minibatch[ 201- 300]: loss = 0.337305 * 100, metric = 4.51% * 100;
 Minibatch[ 301- 400]: loss = 0.335303 * 100, metric = 4.59% * 100;
 Minibatch[ 401- 500]: loss = 0.338132 * 100, metric = 4.59% * 100;
 Minibatch[ 501- 600]: loss = 0.343166 * 100, metric = 4.42% * 100;
 Minibatch[ 601- 700]: loss = 0.341982 * 100, metric = 4.47% * 100;
 Minibatch[ 701- 800]: loss = 0.346125 * 100, metric = 4.53% * 100;
 Minibatch[ 801- 900]: loss = 0.336367 * 100, metric = 4.46% * 100;
 Minibatch[ 901-1000]: loss = 0.338527 * 100, metric = 4.55% * 100;
 Minibatch[1001-1100]: loss = 0.336192 * 100, metric = 4.60% * 100;
 Minibatch[1101-1200]: loss = 0.331606 * 100, metric = 4.43% * 100;
 Minibatch[1201-1300]: loss = 0.326432 * 100, metric = 4.22% * 100;
 Minibatch[1301-1400]: loss = 0.337850 * 100, metric = 4.34% * 100;
 Minibatch[1401-1500]: loss = 0.333925 * 100, metric = 4.22% * 100;
 Minibatch[1501-1600]: loss = 0.349146 * 100, metric = 4.54% * 100;
 Minibatch[1601-1700]: loss = 0.335815 * 100, metric = 4.34% * 100;
 Minibatch[1701-1800]: loss = 0.342501 * 100, metric = 4.50% * 100;
 Minibatch[1801-1900]: loss = 0.358526 * 100, metric = 4.69% * 100;
 Minibatch[1901-2000]: loss = 0.330687 * 100, metric = 4.24% * 100;
Finished Epoch[53 of 200]: [Training] loss = 0.338556 * 2000, metric = 4.45% * 2000 905.094s (  2.2 samples/s);
Finished Evaluation [53]: Minibatch[1-2000]: metric = 12.30% * 2000;
 Minibatch[   1- 100]: loss = 0.349875 * 100, metric = 4.65% * 100;
 Minibatch[ 101- 200]: loss = 0.338963 * 100, metric = 4.42% * 100;
 Minibatch[ 201- 300]: loss = 0.335038 * 100, metric = 4.56% * 100;
 Minibatch[ 301- 400]: loss = 0.339673 * 100, metric = 4.37% * 100;
 Minibatch[ 401- 500]: loss = 0.344375 * 100, metric = 4.56% * 100;
 Minibatch[ 501- 600]: loss = 0.324601 * 100, metric = 4.29% * 100;
 Minibatch[ 601- 700]: loss = 0.350640 * 100, metric = 4.82% * 100;
 Minibatch[ 701- 800]: loss = 0.337738 * 100, metric = 4.35% * 100;
 Minibatch[ 801- 900]: loss = 0.329982 * 100, metric = 4.21% * 100;
 Minibatch[ 901-1000]: loss = 0.340359 * 100, metric = 4.46% * 100;
 Minibatch[1001-1100]: loss = 0.325760 * 100, metric = 4.26% * 100;
 Minibatch[1101-1200]: loss = 0.328181 * 100, metric = 4.47% * 100;
 Minibatch[1201-1300]: loss = 0.325664 * 100, metric = 4.22% * 100;
 Minibatch[1301-1400]: loss = 0.316281 * 100, metric = 4.23% * 100;
 Minibatch[1401-1500]: loss = 0.331837 * 100, metric = 4.28% * 100;
 Minibatch[1501-1600]: loss = 0.327491 * 100, metric = 4.34% * 100;
 Minibatch[1601-1700]: loss = 0.323856 * 100, metric = 4.27% * 100;
 Minibatch[1701-1800]: loss = 0.328354 * 100, metric = 4.28% * 100;
 Minibatch[1801-1900]: loss = 0.344929 * 100, metric = 4.72% * 100;
 Minibatch[1901-2000]: loss = 0.333644 * 100, metric = 4.47% * 100;
Finished Epoch[54 of 200]: [Training] loss = 0.333862 * 2000, metric = 4.41% * 2000 895.004s (  2.2 samples/s);
Finished Evaluation [54]: Minibatch[1-2000]: metric = 12.48% * 2000;
 Minibatch[   1- 100]: loss = 0.333577 * 100, metric = 4.28% * 100;
 Minibatch[ 101- 200]: loss = 0.330686 * 100, metric = 4.40% * 100;
 Minibatch[ 201- 300]: loss = 0.332332 * 100, metric = 4.39% * 100;
 Minibatch[ 301- 400]: loss = 0.328182 * 100, metric = 4.31% * 100;
 Minibatch[ 401- 500]: loss = 0.332180 * 100, metric = 4.37% * 100;
 Minibatch[ 501- 600]: loss = 0.333712 * 100, metric = 4.13% * 100;
 Minibatch[ 601- 700]: loss = 0.332722 * 100, metric = 4.49% * 100;
 Minibatch[ 701- 800]: loss = 0.350190 * 100, metric = 4.63% * 100;
 Minibatch[ 801- 900]: loss = 0.338788 * 100, metric = 4.57% * 100;
 Minibatch[ 901-1000]: loss = 0.336640 * 100, metric = 4.35% * 100;
 Minibatch[1001-1100]: loss = 0.337942 * 100, metric = 4.35% * 100;
 Minibatch[1101-1200]: loss = 0.342924 * 100, metric = 4.47% * 100;
 Minibatch[1201-1300]: loss = 0.339597 * 100, metric = 4.46% * 100;
 Minibatch[1301-1400]: loss = 0.321109 * 100, metric = 4.14% * 100;
 Minibatch[1401-1500]: loss = 0.329968 * 100, metric = 4.34% * 100;
 Minibatch[1501-1600]: loss = 0.343301 * 100, metric = 4.45% * 100;
 Minibatch[1601-1700]: loss = 0.330177 * 100, metric = 4.48% * 100;
 Minibatch[1701-1800]: loss = 0.334901 * 100, metric = 4.48% * 100;
 Minibatch[1801-1900]: loss = 0.325687 * 100, metric = 4.23% * 100;
 Minibatch[1901-2000]: loss = 0.333409 * 100, metric = 4.32% * 100;
Finished Epoch[55 of 200]: [Training] loss = 0.334401 * 2000, metric = 4.38% * 2000 891.621s (  2.2 samples/s);
Finished Evaluation [55]: Minibatch[1-2000]: metric = 12.61% * 2000;
 Minibatch[   1- 100]: loss = 0.348432 * 100, metric = 4.70% * 100;
 Minibatch[ 101- 200]: loss = 0.335895 * 100, metric = 4.34% * 100;
 Minibatch[ 201- 300]: loss = 0.333737 * 100, metric = 4.49% * 100;
 Minibatch[ 301- 400]: loss = 0.341328 * 100, metric = 4.60% * 100;
 Minibatch[ 401- 500]: loss = 0.345992 * 100, metric = 4.75% * 100;
 Minibatch[ 501- 600]: loss = 0.339044 * 100, metric = 4.51% * 100;
 Minibatch[ 601- 700]: loss = 0.334405 * 100, metric = 4.50% * 100;
 Minibatch[ 701- 800]: loss = 0.331127 * 100, metric = 4.28% * 100;
 Minibatch[ 801- 900]: loss = 0.334932 * 100, metric = 4.28% * 100;
 Minibatch[ 901-1000]: loss = 0.338905 * 100, metric = 4.58% * 100;
 Minibatch[1001-1100]: loss = 0.342917 * 100, metric = 4.61% * 100;
 Minibatch[1101-1200]: loss = 0.337351 * 100, metric = 4.40% * 100;
 Minibatch[1201-1300]: loss = 0.335917 * 100, metric = 4.17% * 100;
 Minibatch[1301-1400]: loss = 0.336234 * 100, metric = 4.37% * 100;
 Minibatch[1401-1500]: loss = 0.333876 * 100, metric = 4.32% * 100;
 Minibatch[1501-1600]: loss = 0.334787 * 100, metric = 4.39% * 100;
 Minibatch[1601-1700]: loss = 0.338814 * 100, metric = 4.15% * 100;
 Minibatch[1701-1800]: loss = 0.329971 * 100, metric = 4.31% * 100;
 Minibatch[1801-1900]: loss = 0.339186 * 100, metric = 4.37% * 100;
 Minibatch[1901-2000]: loss = 0.347651 * 100, metric = 4.63% * 100;
Finished Epoch[56 of 200]: [Training] loss = 0.338025 * 2000, metric = 4.44% * 2000 900.946s (  2.2 samples/s);
Finished Evaluation [56]: Minibatch[1-2000]: metric = 11.93% * 2000;
 Minibatch[   1- 100]: loss = 0.345547 * 100, metric = 4.35% * 100;
 Minibatch[ 101- 200]: loss = 0.333767 * 100, metric = 4.34% * 100;
 Minibatch[ 201- 300]: loss = 0.340232 * 100, metric = 4.39% * 100;
 Minibatch[ 301- 400]: loss = 0.332353 * 100, metric = 4.18% * 100;
 Minibatch[ 401- 500]: loss = 0.331510 * 100, metric = 4.16% * 100;
 Minibatch[ 501- 600]: loss = 0.334762 * 100, metric = 4.23% * 100;
 Minibatch[ 601- 700]: loss = 0.335494 * 100, metric = 4.34% * 100;
 Minibatch[ 701- 800]: loss = 0.327741 * 100, metric = 4.31% * 100;
 Minibatch[ 801- 900]: loss = 0.333029 * 100, metric = 4.37% * 100;
 Minibatch[ 901-1000]: loss = 0.327576 * 100, metric = 4.26% * 100;
 Minibatch[1001-1100]: loss = 0.346248 * 100, metric = 4.51% * 100;
 Minibatch[1101-1200]: loss = 0.328552 * 100, metric = 4.22% * 100;
 Minibatch[1201-1300]: loss = 0.326904 * 100, metric = 4.32% * 100;
 Minibatch[1301-1400]: loss = 0.316887 * 100, metric = 4.02% * 100;
 Minibatch[1401-1500]: loss = 0.335977 * 100, metric = 4.40% * 100;
 Minibatch[1501-1600]: loss = 0.331663 * 100, metric = 4.22% * 100;
 Minibatch[1601-1700]: loss = 0.328294 * 100, metric = 4.20% * 100;
 Minibatch[1701-1800]: loss = 0.328839 * 100, metric = 4.44% * 100;
 Minibatch[1801-1900]: loss = 0.340285 * 100, metric = 4.36% * 100;
 Minibatch[1901-2000]: loss = 0.342335 * 100, metric = 4.58% * 100;
Finished Epoch[57 of 200]: [Training] loss = 0.333400 * 2000, metric = 4.31% * 2000 896.810s (  2.2 samples/s);
Finished Evaluation [57]: Minibatch[1-2000]: metric = 12.39% * 2000;
 Minibatch[   1- 100]: loss = 0.326205 * 100, metric = 3.97% * 100;
 Minibatch[ 101- 200]: loss = 0.326020 * 100, metric = 4.24% * 100;
 Minibatch[ 201- 300]: loss = 0.335419 * 100, metric = 4.46% * 100;
 Minibatch[ 301- 400]: loss = 0.332035 * 100, metric = 4.24% * 100;
 Minibatch[ 401- 500]: loss = 0.351286 * 100, metric = 4.65% * 100;
 Minibatch[ 501- 600]: loss = 0.327743 * 100, metric = 4.30% * 100;
 Minibatch[ 601- 700]: loss = 0.329417 * 100, metric = 4.22% * 100;
 Minibatch[ 701- 800]: loss = 0.338566 * 100, metric = 4.58% * 100;
 Minibatch[ 801- 900]: loss = 0.335735 * 100, metric = 4.35% * 100;
 Minibatch[ 901-1000]: loss = 0.325676 * 100, metric = 4.35% * 100;
 Minibatch[1001-1100]: loss = 0.335093 * 100, metric = 4.46% * 100;
 Minibatch[1101-1200]: loss = 0.332492 * 100, metric = 4.23% * 100;
 Minibatch[1201-1300]: loss = 0.323963 * 100, metric = 4.27% * 100;
 Minibatch[1301-1400]: loss = 0.335835 * 100, metric = 4.55% * 100;
 Minibatch[1401-1500]: loss = 0.319633 * 100, metric = 4.07% * 100;
 Minibatch[1501-1600]: loss = 0.339188 * 100, metric = 4.58% * 100;
 Minibatch[1601-1700]: loss = 0.335907 * 100, metric = 4.44% * 100;
 Minibatch[1701-1800]: loss = 0.323298 * 100, metric = 4.19% * 100;
 Minibatch[1801-1900]: loss = 0.321299 * 100, metric = 4.17% * 100;
 Minibatch[1901-2000]: loss = 0.324854 * 100, metric = 4.20% * 100;
Finished Epoch[58 of 200]: [Training] loss = 0.330983 * 2000, metric = 4.33% * 2000 910.987s (  2.2 samples/s);
Finished Evaluation [58]: Minibatch[1-2000]: metric = 11.80% * 2000;
 Minibatch[   1- 100]: loss = 0.337576 * 100, metric = 4.48% * 100;
 Minibatch[ 101- 200]: loss = 0.336739 * 100, metric = 4.48% * 100;
 Minibatch[ 201- 300]: loss = 0.320169 * 100, metric = 3.95% * 100;
 Minibatch[ 301- 400]: loss = 0.316077 * 100, metric = 3.93% * 100;
 Minibatch[ 401- 500]: loss = 0.325146 * 100, metric = 4.23% * 100;
 Minibatch[ 501- 600]: loss = 0.320862 * 100, metric = 4.11% * 100;
 Minibatch[ 601- 700]: loss = 0.318984 * 100, metric = 4.16% * 100;
 Minibatch[ 701- 800]: loss = 0.322189 * 100, metric = 4.05% * 100;
 Minibatch[ 801- 900]: loss = 0.327552 * 100, metric = 4.24% * 100;
 Minibatch[ 901-1000]: loss = 0.324455 * 100, metric = 4.14% * 100;
 Minibatch[1001-1100]: loss = 0.320045 * 100, metric = 4.01% * 100;
 Minibatch[1101-1200]: loss = 0.335540 * 100, metric = 4.36% * 100;
 Minibatch[1201-1300]: loss = 0.324018 * 100, metric = 4.07% * 100;
 Minibatch[1301-1400]: loss = 0.322378 * 100, metric = 4.05% * 100;
 Minibatch[1401-1500]: loss = 0.325503 * 100, metric = 4.10% * 100;
 Minibatch[1501-1600]: loss = 0.315425 * 100, metric = 4.03% * 100;
 Minibatch[1601-1700]: loss = 0.325445 * 100, metric = 4.25% * 100;
 Minibatch[1701-1800]: loss = 0.324752 * 100, metric = 4.05% * 100;
 Minibatch[1801-1900]: loss = 0.329844 * 100, metric = 4.16% * 100;
 Minibatch[1901-2000]: loss = 0.337177 * 100, metric = 4.31% * 100;
Finished Epoch[59 of 200]: [Training] loss = 0.325494 * 2000, metric = 4.16% * 2000 891.075s (  2.2 samples/s);
Finished Evaluation [59]: Minibatch[1-2000]: metric = 13.01% * 2000;
 Minibatch[   1- 100]: loss = 0.327339 * 100, metric = 4.32% * 100;
 Minibatch[ 101- 200]: loss = 0.313818 * 100, metric = 4.10% * 100;
 Minibatch[ 201- 300]: loss = 0.308900 * 100, metric = 3.96% * 100;
 Minibatch[ 301- 400]: loss = 0.326116 * 100, metric = 4.06% * 100;
 Minibatch[ 401- 500]: loss = 0.334500 * 100, metric = 4.21% * 100;
 Minibatch[ 501- 600]: loss = 0.328342 * 100, metric = 4.35% * 100;
 Minibatch[ 601- 700]: loss = 0.316996 * 100, metric = 4.03% * 100;
 Minibatch[ 701- 800]: loss = 0.330085 * 100, metric = 4.19% * 100;
 Minibatch[ 801- 900]: loss = 0.323654 * 100, metric = 4.33% * 100;
 Minibatch[ 901-1000]: loss = 0.328826 * 100, metric = 4.37% * 100;
 Minibatch[1001-1100]: loss = 0.332465 * 100, metric = 4.42% * 100;
 Minibatch[1101-1200]: loss = 0.325849 * 100, metric = 4.20% * 100;
 Minibatch[1201-1300]: loss = 0.330463 * 100, metric = 4.37% * 100;
 Minibatch[1301-1400]: loss = 0.329208 * 100, metric = 4.31% * 100;
 Minibatch[1401-1500]: loss = 0.306989 * 100, metric = 3.84% * 100;
 Minibatch[1501-1600]: loss = 0.341308 * 100, metric = 4.37% * 100;
 Minibatch[1601-1700]: loss = 0.319263 * 100, metric = 3.97% * 100;
 Minibatch[1701-1800]: loss = 0.331337 * 100, metric = 4.18% * 100;
 Minibatch[1801-1900]: loss = 0.333525 * 100, metric = 4.29% * 100;
 Minibatch[1901-2000]: loss = 0.324600 * 100, metric = 4.25% * 100;
Finished Epoch[60 of 200]: [Training] loss = 0.325679 * 2000, metric = 4.21% * 2000 885.821s (  2.3 samples/s);
Finished Evaluation [60]: Minibatch[1-2000]: metric = 12.21% * 2000;
 Minibatch[   1- 100]: loss = 0.335052 * 100, metric = 4.10% * 100;
 Minibatch[ 101- 200]: loss = 0.309148 * 100, metric = 3.90% * 100;
 Minibatch[ 201- 300]: loss = 0.318743 * 100, metric = 4.13% * 100;
 Minibatch[ 301- 400]: loss = 0.327103 * 100, metric = 4.32% * 100;
 Minibatch[ 401- 500]: loss = 0.316675 * 100, metric = 4.00% * 100;
 Minibatch[ 501- 600]: loss = 0.302204 * 100, metric = 3.72% * 100;
 Minibatch[ 601- 700]: loss = 0.326133 * 100, metric = 4.01% * 100;
 Minibatch[ 701- 800]: loss = 0.318741 * 100, metric = 4.17% * 100;
 Minibatch[ 801- 900]: loss = 0.318843 * 100, metric = 3.88% * 100;
 Minibatch[ 901-1000]: loss = 0.317759 * 100, metric = 4.04% * 100;
 Minibatch[1001-1100]: loss = 0.320654 * 100, metric = 4.05% * 100;
 Minibatch[1101-1200]: loss = 0.328982 * 100, metric = 4.12% * 100;
 Minibatch[1201-1300]: loss = 0.301970 * 100, metric = 3.73% * 100;
 Minibatch[1301-1400]: loss = 0.300755 * 100, metric = 3.61% * 100;
 Minibatch[1401-1500]: loss = 0.323259 * 100, metric = 4.20% * 100;
 Minibatch[1501-1600]: loss = 0.324663 * 100, metric = 4.18% * 100;
 Minibatch[1601-1700]: loss = 0.317077 * 100, metric = 3.95% * 100;
 Minibatch[1701-1800]: loss = 0.313774 * 100, metric = 3.84% * 100;
 Minibatch[1801-1900]: loss = 0.316848 * 100, metric = 3.97% * 100;
 Minibatch[1901-2000]: loss = 0.314848 * 100, metric = 3.91% * 100;
Finished Epoch[61 of 200]: [Training] loss = 0.317661 * 2000, metric = 3.99% * 2000 904.540s (  2.2 samples/s);
Finished Evaluation [61]: Minibatch[1-2000]: metric = 12.06% * 2000;
 Minibatch[   1- 100]: loss = 0.310183 * 100, metric = 3.72% * 100;
 Minibatch[ 101- 200]: loss = 0.316167 * 100, metric = 3.93% * 100;
 Minibatch[ 201- 300]: loss = 0.323141 * 100, metric = 4.27% * 100;
 Minibatch[ 301- 400]: loss = 0.309227 * 100, metric = 4.03% * 100;
 Minibatch[ 401- 500]: loss = 0.314913 * 100, metric = 3.90% * 100;
 Minibatch[ 501- 600]: loss = 0.312537 * 100, metric = 3.92% * 100;
 Minibatch[ 601- 700]: loss = 0.325902 * 100, metric = 4.12% * 100;
 Minibatch[ 701- 800]: loss = 0.310163 * 100, metric = 3.75% * 100;
 Minibatch[ 801- 900]: loss = 0.317883 * 100, metric = 4.04% * 100;
 Minibatch[ 901-1000]: loss = 0.320670 * 100, metric = 4.00% * 100;
 Minibatch[1001-1100]: loss = 0.301338 * 100, metric = 3.79% * 100;
 Minibatch[1101-1200]: loss = 0.333240 * 100, metric = 4.41% * 100;
 Minibatch[1201-1300]: loss = 0.323067 * 100, metric = 4.03% * 100;
 Minibatch[1301-1400]: loss = 0.321399 * 100, metric = 4.18% * 100;
 Minibatch[1401-1500]: loss = 0.312057 * 100, metric = 3.98% * 100;
 Minibatch[1501-1600]: loss = 0.306227 * 100, metric = 3.67% * 100;
 Minibatch[1601-1700]: loss = 0.323192 * 100, metric = 3.95% * 100;
 Minibatch[1701-1800]: loss = 0.326618 * 100, metric = 4.11% * 100;
 Minibatch[1801-1900]: loss = 0.322296 * 100, metric = 4.29% * 100;
 Minibatch[1901-2000]: loss = 0.320729 * 100, metric = 4.15% * 100;
Finished Epoch[62 of 200]: [Training] loss = 0.317547 * 2000, metric = 4.01% * 2000 897.542s (  2.2 samples/s);
Finished Evaluation [62]: Minibatch[1-2000]: metric = 12.26% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
