Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.341387 * 100, metric = 24.55% * 100;
 Minibatch[ 101- 200]: loss = 1.115833 * 100, metric = 22.90% * 100;
 Minibatch[ 201- 300]: loss = 1.014879 * 100, metric = 21.84% * 100;
 Minibatch[ 301- 400]: loss = 0.987523 * 100, metric = 19.99% * 100;
 Minibatch[ 401- 500]: loss = 0.968714 * 100, metric = 20.18% * 100;
 Minibatch[ 501- 600]: loss = 0.933329 * 100, metric = 18.18% * 100;
 Minibatch[ 601- 700]: loss = 0.898864 * 100, metric = 17.21% * 100;
 Minibatch[ 701- 800]: loss = 0.841202 * 100, metric = 16.33% * 100;
 Minibatch[ 801- 900]: loss = 0.879985 * 100, metric = 16.76% * 100;
 Minibatch[ 901-1000]: loss = 0.880048 * 100, metric = 17.26% * 100;
 Minibatch[1001-1100]: loss = 0.857526 * 100, metric = 16.70% * 100;
 Minibatch[1101-1200]: loss = 0.836283 * 100, metric = 15.94% * 100;
 Minibatch[1201-1300]: loss = 0.849761 * 100, metric = 16.34% * 100;
 Minibatch[1301-1400]: loss = 0.819303 * 100, metric = 15.60% * 100;
 Minibatch[1401-1500]: loss = 0.826747 * 100, metric = 15.59% * 100;
 Minibatch[1501-1600]: loss = 0.809258 * 100, metric = 14.97% * 100;
 Minibatch[1601-1700]: loss = 0.791533 * 100, metric = 15.06% * 100;
 Minibatch[1701-1800]: loss = 0.810283 * 100, metric = 15.25% * 100;
 Minibatch[1801-1900]: loss = 0.794104 * 100, metric = 15.07% * 100;
 Minibatch[1901-2000]: loss = 0.770079 * 100, metric = 14.05% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.901332 * 2000, metric = 17.49% * 2000 969.619s (  2.1 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 25.23% * 2000;
0.8983813845217228
 Minibatch[   1- 100]: loss = 0.772141 * 100, metric = 14.20% * 100;
 Minibatch[ 101- 200]: loss = 0.787309 * 100, metric = 15.20% * 100;
 Minibatch[ 201- 300]: loss = 0.787391 * 100, metric = 14.04% * 100;
 Minibatch[ 301- 400]: loss = 0.779457 * 100, metric = 14.12% * 100;
 Minibatch[ 401- 500]: loss = 0.781658 * 100, metric = 14.10% * 100;
 Minibatch[ 501- 600]: loss = 0.784561 * 100, metric = 13.86% * 100;
 Minibatch[ 601- 700]: loss = 0.758743 * 100, metric = 13.89% * 100;
 Minibatch[ 701- 800]: loss = 0.776118 * 100, metric = 14.50% * 100;
 Minibatch[ 801- 900]: loss = 0.749608 * 100, metric = 13.49% * 100;
 Minibatch[ 901-1000]: loss = 0.746417 * 100, metric = 13.28% * 100;
 Minibatch[1001-1100]: loss = 0.753810 * 100, metric = 14.02% * 100;
 Minibatch[1101-1200]: loss = 0.762924 * 100, metric = 13.79% * 100;
 Minibatch[1201-1300]: loss = 0.746799 * 100, metric = 13.76% * 100;
 Minibatch[1301-1400]: loss = 0.772386 * 100, metric = 14.06% * 100;
 Minibatch[1401-1500]: loss = 0.738534 * 100, metric = 13.13% * 100;
 Minibatch[1501-1600]: loss = 0.731447 * 100, metric = 13.10% * 100;
 Minibatch[1601-1700]: loss = 0.752084 * 100, metric = 13.73% * 100;
 Minibatch[1701-1800]: loss = 0.744019 * 100, metric = 13.81% * 100;
 Minibatch[1801-1900]: loss = 0.750735 * 100, metric = 13.69% * 100;
 Minibatch[1901-2000]: loss = 0.722908 * 100, metric = 13.11% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.759952 * 2000, metric = 13.84% * 2000 902.917s (  2.2 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 21.48% * 2000;
0.7998206511288881
 Minibatch[   1- 100]: loss = 0.743027 * 100, metric = 13.65% * 100;
 Minibatch[ 101- 200]: loss = 0.747473 * 100, metric = 13.71% * 100;
 Minibatch[ 201- 300]: loss = 0.724947 * 100, metric = 13.22% * 100;
 Minibatch[ 301- 400]: loss = 0.756152 * 100, metric = 14.16% * 100;
 Minibatch[ 401- 500]: loss = 0.755611 * 100, metric = 13.91% * 100;
 Minibatch[ 501- 600]: loss = 0.750315 * 100, metric = 13.48% * 100;
 Minibatch[ 601- 700]: loss = 0.750657 * 100, metric = 13.51% * 100;
 Minibatch[ 701- 800]: loss = 0.722646 * 100, metric = 12.72% * 100;
 Minibatch[ 801- 900]: loss = 0.751862 * 100, metric = 13.82% * 100;
 Minibatch[ 901-1000]: loss = 0.708229 * 100, metric = 12.99% * 100;
 Minibatch[1001-1100]: loss = 0.731130 * 100, metric = 13.30% * 100;
 Minibatch[1101-1200]: loss = 0.710573 * 100, metric = 12.92% * 100;
 Minibatch[1201-1300]: loss = 0.709641 * 100, metric = 12.61% * 100;
 Minibatch[1301-1400]: loss = 0.720189 * 100, metric = 12.84% * 100;
 Minibatch[1401-1500]: loss = 0.718748 * 100, metric = 13.12% * 100;
 Minibatch[1501-1600]: loss = 0.720719 * 100, metric = 12.93% * 100;
 Minibatch[1601-1700]: loss = 0.705005 * 100, metric = 12.46% * 100;
 Minibatch[1701-1800]: loss = 0.732574 * 100, metric = 13.19% * 100;
 Minibatch[1801-1900]: loss = 0.709447 * 100, metric = 12.28% * 100;
 Minibatch[1901-2000]: loss = 0.715314 * 100, metric = 12.92% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.729213 * 2000, metric = 13.19% * 2000 886.674s (  2.3 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 22.17% * 2000;
0.7947700125277042
 Minibatch[   1- 100]: loss = 0.735399 * 100, metric = 12.68% * 100;
 Minibatch[ 101- 200]: loss = 0.698661 * 100, metric = 12.33% * 100;
 Minibatch[ 201- 300]: loss = 0.720824 * 100, metric = 13.04% * 100;
 Minibatch[ 301- 400]: loss = 0.676864 * 100, metric = 11.94% * 100;
 Minibatch[ 401- 500]: loss = 0.700446 * 100, metric = 12.18% * 100;
 Minibatch[ 501- 600]: loss = 0.687669 * 100, metric = 11.88% * 100;
 Minibatch[ 601- 700]: loss = 0.689590 * 100, metric = 12.24% * 100;
 Minibatch[ 701- 800]: loss = 0.707679 * 100, metric = 12.29% * 100;
 Minibatch[ 801- 900]: loss = 0.699706 * 100, metric = 12.63% * 100;
 Minibatch[ 901-1000]: loss = 0.694365 * 100, metric = 12.46% * 100;
 Minibatch[1001-1100]: loss = 0.707215 * 100, metric = 12.74% * 100;
 Minibatch[1101-1200]: loss = 0.680832 * 100, metric = 12.08% * 100;
 Minibatch[1201-1300]: loss = 0.685211 * 100, metric = 11.99% * 100;
 Minibatch[1301-1400]: loss = 0.703820 * 100, metric = 12.48% * 100;
 Minibatch[1401-1500]: loss = 0.705501 * 100, metric = 12.88% * 100;
 Minibatch[1501-1600]: loss = 0.671692 * 100, metric = 11.62% * 100;
 Minibatch[1601-1700]: loss = 0.694131 * 100, metric = 12.38% * 100;
 Minibatch[1701-1800]: loss = 0.705154 * 100, metric = 12.72% * 100;
 Minibatch[1801-1900]: loss = 0.687496 * 100, metric = 12.18% * 100;
 Minibatch[1901-2000]: loss = 0.680498 * 100, metric = 11.93% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.696638 * 2000, metric = 12.33% * 2000 884.510s (  2.3 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 22.53% * 2000;
 Minibatch[   1- 100]: loss = 0.706662 * 100, metric = 12.57% * 100;
 Minibatch[ 101- 200]: loss = 0.685483 * 100, metric = 12.13% * 100;
 Minibatch[ 201- 300]: loss = 0.662577 * 100, metric = 11.56% * 100;
 Minibatch[ 301- 400]: loss = 0.707504 * 100, metric = 12.80% * 100;
 Minibatch[ 401- 500]: loss = 0.663658 * 100, metric = 11.37% * 100;
 Minibatch[ 501- 600]: loss = 0.674919 * 100, metric = 11.69% * 100;
 Minibatch[ 601- 700]: loss = 0.669940 * 100, metric = 11.57% * 100;
 Minibatch[ 701- 800]: loss = 0.683269 * 100, metric = 12.04% * 100;
 Minibatch[ 801- 900]: loss = 0.669106 * 100, metric = 11.53% * 100;
 Minibatch[ 901-1000]: loss = 0.677498 * 100, metric = 12.18% * 100;
 Minibatch[1001-1100]: loss = 0.683625 * 100, metric = 11.90% * 100;
 Minibatch[1101-1200]: loss = 0.654869 * 100, metric = 11.27% * 100;
 Minibatch[1201-1300]: loss = 0.675634 * 100, metric = 11.73% * 100;
 Minibatch[1301-1400]: loss = 0.701552 * 100, metric = 12.60% * 100;
 Minibatch[1401-1500]: loss = 0.667192 * 100, metric = 12.03% * 100;
 Minibatch[1501-1600]: loss = 0.674373 * 100, metric = 11.71% * 100;
 Minibatch[1601-1700]: loss = 0.686592 * 100, metric = 12.34% * 100;
 Minibatch[1701-1800]: loss = 0.695168 * 100, metric = 12.50% * 100;
 Minibatch[1801-1900]: loss = 0.678616 * 100, metric = 11.98% * 100;
 Minibatch[1901-2000]: loss = 0.658411 * 100, metric = 11.64% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.678832 * 2000, metric = 11.96% * 2000 884.398s (  2.3 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.03% * 2000;
0.7435346061438322
 Minibatch[   1- 100]: loss = 0.665075 * 100, metric = 11.74% * 100;
 Minibatch[ 101- 200]: loss = 0.652013 * 100, metric = 11.33% * 100;
 Minibatch[ 201- 300]: loss = 0.667314 * 100, metric = 11.77% * 100;
 Minibatch[ 301- 400]: loss = 0.663957 * 100, metric = 11.30% * 100;
 Minibatch[ 401- 500]: loss = 0.634084 * 100, metric = 11.01% * 100;
 Minibatch[ 501- 600]: loss = 0.658210 * 100, metric = 11.50% * 100;
 Minibatch[ 601- 700]: loss = 0.640753 * 100, metric = 11.06% * 100;
 Minibatch[ 701- 800]: loss = 0.658891 * 100, metric = 11.44% * 100;
 Minibatch[ 801- 900]: loss = 0.654962 * 100, metric = 11.43% * 100;
 Minibatch[ 901-1000]: loss = 0.645272 * 100, metric = 11.04% * 100;
 Minibatch[1001-1100]: loss = 0.644417 * 100, metric = 11.02% * 100;
 Minibatch[1101-1200]: loss = 0.665027 * 100, metric = 11.49% * 100;
 Minibatch[1201-1300]: loss = 0.679449 * 100, metric = 11.91% * 100;
 Minibatch[1301-1400]: loss = 0.659924 * 100, metric = 11.37% * 100;
 Minibatch[1401-1500]: loss = 0.657181 * 100, metric = 11.57% * 100;
 Minibatch[1501-1600]: loss = 0.647404 * 100, metric = 11.02% * 100;
 Minibatch[1601-1700]: loss = 0.653241 * 100, metric = 11.27% * 100;
 Minibatch[1701-1800]: loss = 0.632629 * 100, metric = 10.99% * 100;
 Minibatch[1801-1900]: loss = 0.660139 * 100, metric = 11.25% * 100;
 Minibatch[1901-2000]: loss = 0.639771 * 100, metric = 10.99% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.653986 * 2000, metric = 11.33% * 2000 885.841s (  2.3 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.10% * 2000;
0.7426186387613416
 Minibatch[   1- 100]: loss = 0.651625 * 100, metric = 11.03% * 100;
 Minibatch[ 101- 200]: loss = 0.655375 * 100, metric = 10.90% * 100;
 Minibatch[ 201- 300]: loss = 0.651291 * 100, metric = 11.33% * 100;
 Minibatch[ 301- 400]: loss = 0.637074 * 100, metric = 10.67% * 100;
 Minibatch[ 401- 500]: loss = 0.654175 * 100, metric = 11.14% * 100;
 Minibatch[ 501- 600]: loss = 0.634443 * 100, metric = 10.59% * 100;
 Minibatch[ 601- 700]: loss = 0.646763 * 100, metric = 10.92% * 100;
 Minibatch[ 701- 800]: loss = 0.644479 * 100, metric = 10.75% * 100;
 Minibatch[ 801- 900]: loss = 0.644684 * 100, metric = 11.17% * 100;
 Minibatch[ 901-1000]: loss = 0.640298 * 100, metric = 11.05% * 100;
 Minibatch[1001-1100]: loss = 0.652440 * 100, metric = 11.52% * 100;
 Minibatch[1101-1200]: loss = 0.622896 * 100, metric = 10.26% * 100;
 Minibatch[1201-1300]: loss = 0.650367 * 100, metric = 11.29% * 100;
 Minibatch[1301-1400]: loss = 0.634593 * 100, metric = 10.83% * 100;
 Minibatch[1401-1500]: loss = 0.628551 * 100, metric = 10.66% * 100;
 Minibatch[1501-1600]: loss = 0.646683 * 100, metric = 11.13% * 100;
 Minibatch[1601-1700]: loss = 0.654709 * 100, metric = 11.30% * 100;
 Minibatch[1701-1800]: loss = 0.630820 * 100, metric = 10.93% * 100;
 Minibatch[1801-1900]: loss = 0.640424 * 100, metric = 11.03% * 100;
 Minibatch[1901-2000]: loss = 0.643176 * 100, metric = 11.01% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.643243 * 2000, metric = 10.98% * 2000 879.593s (  2.3 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.28% * 2000;
0.6977142188549041
 Minibatch[   1- 100]: loss = 0.647153 * 100, metric = 11.14% * 100;
 Minibatch[ 101- 200]: loss = 0.631852 * 100, metric = 10.80% * 100;
 Minibatch[ 201- 300]: loss = 0.619205 * 100, metric = 10.54% * 100;
 Minibatch[ 301- 400]: loss = 0.623533 * 100, metric = 10.71% * 100;
 Minibatch[ 401- 500]: loss = 0.635329 * 100, metric = 11.01% * 100;
 Minibatch[ 501- 600]: loss = 0.661316 * 100, metric = 11.53% * 100;
 Minibatch[ 601- 700]: loss = 0.612382 * 100, metric = 10.55% * 100;
 Minibatch[ 701- 800]: loss = 0.634553 * 100, metric = 10.79% * 100;
 Minibatch[ 801- 900]: loss = 0.611954 * 100, metric = 10.02% * 100;
 Minibatch[ 901-1000]: loss = 0.605425 * 100, metric = 10.15% * 100;
 Minibatch[1001-1100]: loss = 0.611071 * 100, metric = 10.20% * 100;
 Minibatch[1101-1200]: loss = 0.606604 * 100, metric = 10.18% * 100;
 Minibatch[1201-1300]: loss = 0.629411 * 100, metric = 10.80% * 100;
 Minibatch[1301-1400]: loss = 0.638967 * 100, metric = 11.36% * 100;
 Minibatch[1401-1500]: loss = 0.625812 * 100, metric = 10.67% * 100;
 Minibatch[1501-1600]: loss = 0.626349 * 100, metric = 10.73% * 100;
 Minibatch[1601-1700]: loss = 0.614726 * 100, metric = 10.40% * 100;
 Minibatch[1701-1800]: loss = 0.610990 * 100, metric = 10.23% * 100;
 Minibatch[1801-1900]: loss = 0.624800 * 100, metric = 10.51% * 100;
 Minibatch[1901-2000]: loss = 0.627988 * 100, metric = 10.37% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.624971 * 2000, metric = 10.63% * 2000 851.966s (  2.3 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 17.50% * 2000;
0.6816777193173766
 Minibatch[   1- 100]: loss = 0.596115 * 100, metric = 9.80% * 100;
 Minibatch[ 101- 200]: loss = 0.638340 * 100, metric = 10.95% * 100;
 Minibatch[ 201- 300]: loss = 0.618649 * 100, metric = 10.23% * 100;
 Minibatch[ 301- 400]: loss = 0.640401 * 100, metric = 10.93% * 100;
 Minibatch[ 401- 500]: loss = 0.626535 * 100, metric = 10.48% * 100;
 Minibatch[ 501- 600]: loss = 0.618804 * 100, metric = 10.47% * 100;
 Minibatch[ 601- 700]: loss = 0.617086 * 100, metric = 10.56% * 100;
 Minibatch[ 701- 800]: loss = 0.602438 * 100, metric = 9.83% * 100;
 Minibatch[ 801- 900]: loss = 0.600573 * 100, metric = 10.18% * 100;
 Minibatch[ 901-1000]: loss = 0.616660 * 100, metric = 10.51% * 100;
 Minibatch[1001-1100]: loss = 0.589834 * 100, metric = 9.67% * 100;
 Minibatch[1101-1200]: loss = 0.619698 * 100, metric = 10.52% * 100;
 Minibatch[1201-1300]: loss = 0.604545 * 100, metric = 10.03% * 100;
 Minibatch[1301-1400]: loss = 0.600135 * 100, metric = 9.76% * 100;
 Minibatch[1401-1500]: loss = 0.615635 * 100, metric = 10.71% * 100;
 Minibatch[1501-1600]: loss = 0.611849 * 100, metric = 10.25% * 100;
 Minibatch[1601-1700]: loss = 0.618173 * 100, metric = 10.43% * 100;
 Minibatch[1701-1800]: loss = 0.612401 * 100, metric = 10.06% * 100;
 Minibatch[1801-1900]: loss = 0.601332 * 100, metric = 10.13% * 100;
 Minibatch[1901-2000]: loss = 0.618381 * 100, metric = 10.55% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.613379 * 2000, metric = 10.30% * 2000 801.912s (  2.5 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 16.51% * 2000;
0.6737747239694
 Minibatch[   1- 100]: loss = 0.628920 * 100, metric = 10.98% * 100;
 Minibatch[ 101- 200]: loss = 0.598523 * 100, metric = 9.91% * 100;
 Minibatch[ 201- 300]: loss = 0.609481 * 100, metric = 10.12% * 100;
 Minibatch[ 301- 400]: loss = 0.607515 * 100, metric = 10.16% * 100;
 Minibatch[ 401- 500]: loss = 0.615329 * 100, metric = 10.55% * 100;
 Minibatch[ 501- 600]: loss = 0.598708 * 100, metric = 9.77% * 100;
 Minibatch[ 601- 700]: loss = 0.592892 * 100, metric = 9.98% * 100;
 Minibatch[ 701- 800]: loss = 0.582424 * 100, metric = 9.46% * 100;
 Minibatch[ 801- 900]: loss = 0.600579 * 100, metric = 10.07% * 100;
 Minibatch[ 901-1000]: loss = 0.605223 * 100, metric = 10.22% * 100;
 Minibatch[1001-1100]: loss = 0.605455 * 100, metric = 10.11% * 100;
 Minibatch[1101-1200]: loss = 0.606309 * 100, metric = 10.02% * 100;
 Minibatch[1201-1300]: loss = 0.599831 * 100, metric = 9.96% * 100;
 Minibatch[1301-1400]: loss = 0.603162 * 100, metric = 10.22% * 100;
 Minibatch[1401-1500]: loss = 0.585287 * 100, metric = 9.50% * 100;
 Minibatch[1501-1600]: loss = 0.599568 * 100, metric = 10.02% * 100;
 Minibatch[1601-1700]: loss = 0.590080 * 100, metric = 9.64% * 100;
 Minibatch[1701-1800]: loss = 0.600284 * 100, metric = 10.02% * 100;
 Minibatch[1801-1900]: loss = 0.607898 * 100, metric = 10.12% * 100;
 Minibatch[1901-2000]: loss = 0.589596 * 100, metric = 9.87% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.601353 * 2000, metric = 10.03% * 2000 799.416s (  2.5 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 16.25% * 2000;
0.6569291612952948
 Minibatch[   1- 100]: loss = 0.575938 * 100, metric = 9.31% * 100;
 Minibatch[ 101- 200]: loss = 0.586869 * 100, metric = 9.67% * 100;
 Minibatch[ 201- 300]: loss = 0.597713 * 100, metric = 10.05% * 100;
 Minibatch[ 301- 400]: loss = 0.591939 * 100, metric = 9.85% * 100;
 Minibatch[ 401- 500]: loss = 0.576037 * 100, metric = 9.54% * 100;
 Minibatch[ 501- 600]: loss = 0.598611 * 100, metric = 10.08% * 100;
 Minibatch[ 601- 700]: loss = 0.584854 * 100, metric = 9.54% * 100;
 Minibatch[ 701- 800]: loss = 0.588267 * 100, metric = 9.74% * 100;
 Minibatch[ 801- 900]: loss = 0.587872 * 100, metric = 9.71% * 100;
 Minibatch[ 901-1000]: loss = 0.597538 * 100, metric = 9.82% * 100;
 Minibatch[1001-1100]: loss = 0.579699 * 100, metric = 9.60% * 100;
 Minibatch[1101-1200]: loss = 0.590350 * 100, metric = 9.80% * 100;
 Minibatch[1201-1300]: loss = 0.576279 * 100, metric = 9.47% * 100;
 Minibatch[1301-1400]: loss = 0.565779 * 100, metric = 9.23% * 100;
 Minibatch[1401-1500]: loss = 0.588063 * 100, metric = 9.62% * 100;
 Minibatch[1501-1600]: loss = 0.568072 * 100, metric = 9.16% * 100;
 Minibatch[1601-1700]: loss = 0.584778 * 100, metric = 9.40% * 100;
 Minibatch[1701-1800]: loss = 0.588540 * 100, metric = 9.65% * 100;
 Minibatch[1801-1900]: loss = 0.583109 * 100, metric = 9.52% * 100;
 Minibatch[1901-2000]: loss = 0.582433 * 100, metric = 9.70% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.584637 * 2000, metric = 9.62% * 2000 799.034s (  2.5 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 16.84% * 2000;
 Minibatch[   1- 100]: loss = 0.558037 * 100, metric = 9.10% * 100;
 Minibatch[ 101- 200]: loss = 0.569787 * 100, metric = 9.11% * 100;
 Minibatch[ 201- 300]: loss = 0.569808 * 100, metric = 9.18% * 100;
 Minibatch[ 301- 400]: loss = 0.601778 * 100, metric = 10.19% * 100;
 Minibatch[ 401- 500]: loss = 0.571348 * 100, metric = 9.08% * 100;
 Minibatch[ 501- 600]: loss = 0.559755 * 100, metric = 8.90% * 100;
 Minibatch[ 601- 700]: loss = 0.560585 * 100, metric = 9.03% * 100;
 Minibatch[ 701- 800]: loss = 0.570969 * 100, metric = 9.29% * 100;
 Minibatch[ 801- 900]: loss = 0.563167 * 100, metric = 8.86% * 100;
 Minibatch[ 901-1000]: loss = 0.570832 * 100, metric = 9.38% * 100;
 Minibatch[1001-1100]: loss = 0.582095 * 100, metric = 9.56% * 100;
 Minibatch[1101-1200]: loss = 0.577275 * 100, metric = 9.44% * 100;
 Minibatch[1201-1300]: loss = 0.580872 * 100, metric = 9.53% * 100;
 Minibatch[1301-1400]: loss = 0.555238 * 100, metric = 9.04% * 100;
 Minibatch[1401-1500]: loss = 0.571973 * 100, metric = 9.31% * 100;
 Minibatch[1501-1600]: loss = 0.530909 * 100, metric = 8.48% * 100;
 Minibatch[1601-1700]: loss = 0.571950 * 100, metric = 9.26% * 100;
 Minibatch[1701-1800]: loss = 0.554692 * 100, metric = 8.79% * 100;
 Minibatch[1801-1900]: loss = 0.555304 * 100, metric = 8.97% * 100;
 Minibatch[1901-2000]: loss = 0.577893 * 100, metric = 9.55% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.567714 * 2000, metric = 9.20% * 2000 791.115s (  2.5 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 16.88% * 2000;
 Minibatch[   1- 100]: loss = 0.565751 * 100, metric = 9.04% * 100;
 Minibatch[ 101- 200]: loss = 0.564141 * 100, metric = 9.13% * 100;
 Minibatch[ 201- 300]: loss = 0.561168 * 100, metric = 8.94% * 100;
 Minibatch[ 301- 400]: loss = 0.570677 * 100, metric = 9.31% * 100;
 Minibatch[ 401- 500]: loss = 0.567818 * 100, metric = 9.63% * 100;
 Minibatch[ 501- 600]: loss = 0.578708 * 100, metric = 9.66% * 100;
 Minibatch[ 601- 700]: loss = 0.557869 * 100, metric = 8.80% * 100;
 Minibatch[ 701- 800]: loss = 0.558167 * 100, metric = 9.00% * 100;
 Minibatch[ 801- 900]: loss = 0.561659 * 100, metric = 9.12% * 100;
 Minibatch[ 901-1000]: loss = 0.571818 * 100, metric = 9.42% * 100;
 Minibatch[1001-1100]: loss = 0.569584 * 100, metric = 9.34% * 100;
 Minibatch[1101-1200]: loss = 0.559781 * 100, metric = 8.93% * 100;
 Minibatch[1201-1300]: loss = 0.566865 * 100, metric = 9.12% * 100;
 Minibatch[1301-1400]: loss = 0.553540 * 100, metric = 9.05% * 100;
 Minibatch[1401-1500]: loss = 0.557074 * 100, metric = 9.02% * 100;
 Minibatch[1501-1600]: loss = 0.553561 * 100, metric = 8.74% * 100;
 Minibatch[1601-1700]: loss = 0.537690 * 100, metric = 8.75% * 100;
 Minibatch[1701-1800]: loss = 0.556831 * 100, metric = 8.92% * 100;
 Minibatch[1801-1900]: loss = 0.552484 * 100, metric = 8.87% * 100;
 Minibatch[1901-2000]: loss = 0.561887 * 100, metric = 9.17% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.561354 * 2000, metric = 9.10% * 2000 787.248s (  2.5 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 18.38% * 2000;
 Minibatch[   1- 100]: loss = 0.562099 * 100, metric = 8.85% * 100;
 Minibatch[ 101- 200]: loss = 0.551898 * 100, metric = 8.81% * 100;
 Minibatch[ 201- 300]: loss = 0.572007 * 100, metric = 9.29% * 100;
 Minibatch[ 301- 400]: loss = 0.549265 * 100, metric = 8.67% * 100;
 Minibatch[ 401- 500]: loss = 0.555821 * 100, metric = 8.98% * 100;
 Minibatch[ 501- 600]: loss = 0.559607 * 100, metric = 9.28% * 100;
 Minibatch[ 601- 700]: loss = 0.555666 * 100, metric = 8.84% * 100;
 Minibatch[ 701- 800]: loss = 0.581779 * 100, metric = 9.61% * 100;
 Minibatch[ 801- 900]: loss = 0.568772 * 100, metric = 9.48% * 100;
 Minibatch[ 901-1000]: loss = 0.565737 * 100, metric = 9.23% * 100;
 Minibatch[1001-1100]: loss = 0.557255 * 100, metric = 9.10% * 100;
 Minibatch[1101-1200]: loss = 0.555203 * 100, metric = 8.92% * 100;
 Minibatch[1201-1300]: loss = 0.534757 * 100, metric = 8.27% * 100;
 Minibatch[1301-1400]: loss = 0.558151 * 100, metric = 9.29% * 100;
 Minibatch[1401-1500]: loss = 0.558397 * 100, metric = 8.97% * 100;
 Minibatch[1501-1600]: loss = 0.547925 * 100, metric = 8.84% * 100;
 Minibatch[1601-1700]: loss = 0.560927 * 100, metric = 9.00% * 100;
 Minibatch[1701-1800]: loss = 0.551964 * 100, metric = 8.69% * 100;
 Minibatch[1801-1900]: loss = 0.551749 * 100, metric = 8.75% * 100;
 Minibatch[1901-2000]: loss = 0.563002 * 100, metric = 8.92% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.558099 * 2000, metric = 8.99% * 2000 761.392s (  2.6 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 16.97% * 2000;
 Minibatch[   1- 100]: loss = 0.562873 * 100, metric = 8.90% * 100;
 Minibatch[ 101- 200]: loss = 0.559290 * 100, metric = 8.98% * 100;
 Minibatch[ 201- 300]: loss = 0.551218 * 100, metric = 8.99% * 100;
 Minibatch[ 301- 400]: loss = 0.543174 * 100, metric = 8.52% * 100;
 Minibatch[ 401- 500]: loss = 0.549356 * 100, metric = 8.82% * 100;
 Minibatch[ 501- 600]: loss = 0.542611 * 100, metric = 8.24% * 100;
 Minibatch[ 601- 700]: loss = 0.528063 * 100, metric = 8.31% * 100;
 Minibatch[ 701- 800]: loss = 0.555204 * 100, metric = 8.99% * 100;
 Minibatch[ 801- 900]: loss = 0.561747 * 100, metric = 9.25% * 100;
 Minibatch[ 901-1000]: loss = 0.551036 * 100, metric = 8.76% * 100;
 Minibatch[1001-1100]: loss = 0.559465 * 100, metric = 9.02% * 100;
 Minibatch[1101-1200]: loss = 0.537740 * 100, metric = 8.69% * 100;
 Minibatch[1201-1300]: loss = 0.537138 * 100, metric = 8.27% * 100;
 Minibatch[1301-1400]: loss = 0.559044 * 100, metric = 9.38% * 100;
 Minibatch[1401-1500]: loss = 0.525274 * 100, metric = 8.43% * 100;
 Minibatch[1501-1600]: loss = 0.542016 * 100, metric = 8.70% * 100;
 Minibatch[1601-1700]: loss = 0.552645 * 100, metric = 8.96% * 100;
 Minibatch[1701-1800]: loss = 0.535927 * 100, metric = 8.21% * 100;
 Minibatch[1801-1900]: loss = 0.534197 * 100, metric = 8.81% * 100;
 Minibatch[1901-2000]: loss = 0.534969 * 100, metric = 8.62% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.546149 * 2000, metric = 8.74% * 2000 759.329s (  2.6 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 15.35% * 2000;
0.6478613295406103
 Minibatch[   1- 100]: loss = 0.554475 * 100, metric = 9.27% * 100;
 Minibatch[ 101- 200]: loss = 0.551324 * 100, metric = 8.99% * 100;
 Minibatch[ 201- 300]: loss = 0.541433 * 100, metric = 8.62% * 100;
 Minibatch[ 301- 400]: loss = 0.538513 * 100, metric = 8.60% * 100;
 Minibatch[ 401- 500]: loss = 0.517556 * 100, metric = 8.10% * 100;
 Minibatch[ 501- 600]: loss = 0.530299 * 100, metric = 8.38% * 100;
 Minibatch[ 601- 700]: loss = 0.529756 * 100, metric = 8.26% * 100;
 Minibatch[ 701- 800]: loss = 0.519848 * 100, metric = 8.19% * 100;
 Minibatch[ 801- 900]: loss = 0.518082 * 100, metric = 8.08% * 100;
 Minibatch[ 901-1000]: loss = 0.527212 * 100, metric = 8.63% * 100;
 Minibatch[1001-1100]: loss = 0.515220 * 100, metric = 8.16% * 100;
 Minibatch[1101-1200]: loss = 0.519307 * 100, metric = 8.29% * 100;
 Minibatch[1201-1300]: loss = 0.518688 * 100, metric = 8.06% * 100;
 Minibatch[1301-1400]: loss = 0.521801 * 100, metric = 8.23% * 100;
 Minibatch[1401-1500]: loss = 0.517838 * 100, metric = 8.38% * 100;
 Minibatch[1501-1600]: loss = 0.528397 * 100, metric = 8.23% * 100;
 Minibatch[1601-1700]: loss = 0.524587 * 100, metric = 8.33% * 100;
 Minibatch[1701-1800]: loss = 0.546876 * 100, metric = 8.60% * 100;
 Minibatch[1801-1900]: loss = 0.529249 * 100, metric = 8.29% * 100;
 Minibatch[1901-2000]: loss = 0.516120 * 100, metric = 8.19% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.528329 * 2000, metric = 8.39% * 2000 753.617s (  2.7 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.92% * 2000;
0.644504556953907
 Minibatch[   1- 100]: loss = 0.508405 * 100, metric = 8.10% * 100;
 Minibatch[ 101- 200]: loss = 0.531120 * 100, metric = 8.31% * 100;
 Minibatch[ 201- 300]: loss = 0.536548 * 100, metric = 8.58% * 100;
 Minibatch[ 301- 400]: loss = 0.527903 * 100, metric = 8.42% * 100;
 Minibatch[ 401- 500]: loss = 0.535152 * 100, metric = 8.38% * 100;
 Minibatch[ 501- 600]: loss = 0.507976 * 100, metric = 7.88% * 100;
 Minibatch[ 601- 700]: loss = 0.492177 * 100, metric = 7.44% * 100;
 Minibatch[ 701- 800]: loss = 0.515645 * 100, metric = 7.96% * 100;
 Minibatch[ 801- 900]: loss = 0.524633 * 100, metric = 8.34% * 100;
 Minibatch[ 901-1000]: loss = 0.528266 * 100, metric = 8.26% * 100;
 Minibatch[1001-1100]: loss = 0.502221 * 100, metric = 7.80% * 100;
 Minibatch[1101-1200]: loss = 0.534778 * 100, metric = 8.46% * 100;
 Minibatch[1201-1300]: loss = 0.538195 * 100, metric = 8.37% * 100;
 Minibatch[1301-1400]: loss = 0.501601 * 100, metric = 7.63% * 100;
 Minibatch[1401-1500]: loss = 0.510886 * 100, metric = 8.10% * 100;
 Minibatch[1501-1600]: loss = 0.503752 * 100, metric = 7.89% * 100;
 Minibatch[1601-1700]: loss = 0.517244 * 100, metric = 7.79% * 100;
 Minibatch[1701-1800]: loss = 0.504618 * 100, metric = 7.72% * 100;
 Minibatch[1801-1900]: loss = 0.526878 * 100, metric = 8.51% * 100;
 Minibatch[1901-2000]: loss = 0.531542 * 100, metric = 8.68% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.518977 * 2000, metric = 8.13% * 2000 752.037s (  2.7 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.44% * 2000;
0.6350485392138362
 Minibatch[   1- 100]: loss = 0.503164 * 100, metric = 7.67% * 100;
 Minibatch[ 101- 200]: loss = 0.521856 * 100, metric = 8.08% * 100;
 Minibatch[ 201- 300]: loss = 0.506993 * 100, metric = 8.03% * 100;
 Minibatch[ 301- 400]: loss = 0.516447 * 100, metric = 8.03% * 100;
 Minibatch[ 401- 500]: loss = 0.493269 * 100, metric = 7.73% * 100;
 Minibatch[ 501- 600]: loss = 0.498271 * 100, metric = 7.62% * 100;
 Minibatch[ 601- 700]: loss = 0.510328 * 100, metric = 8.01% * 100;
 Minibatch[ 701- 800]: loss = 0.489139 * 100, metric = 7.52% * 100;
 Minibatch[ 801- 900]: loss = 0.506115 * 100, metric = 7.80% * 100;
 Minibatch[ 901-1000]: loss = 0.522190 * 100, metric = 8.06% * 100;
 Minibatch[1001-1100]: loss = 0.522877 * 100, metric = 8.08% * 100;
 Minibatch[1101-1200]: loss = 0.514009 * 100, metric = 8.10% * 100;
 Minibatch[1201-1300]: loss = 0.520300 * 100, metric = 8.28% * 100;
 Minibatch[1301-1400]: loss = 0.525339 * 100, metric = 8.25% * 100;
 Minibatch[1401-1500]: loss = 0.495151 * 100, metric = 7.57% * 100;
 Minibatch[1501-1600]: loss = 0.518336 * 100, metric = 7.76% * 100;
 Minibatch[1601-1700]: loss = 0.490267 * 100, metric = 7.56% * 100;
 Minibatch[1701-1800]: loss = 0.493661 * 100, metric = 7.57% * 100;
 Minibatch[1801-1900]: loss = 0.490272 * 100, metric = 7.65% * 100;
 Minibatch[1901-2000]: loss = 0.500117 * 100, metric = 7.51% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.506905 * 2000, metric = 7.84% * 2000 752.705s (  2.7 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.85% * 2000;
 Minibatch[   1- 100]: loss = 0.507930 * 100, metric = 7.94% * 100;
 Minibatch[ 101- 200]: loss = 0.529313 * 100, metric = 8.36% * 100;
 Minibatch[ 201- 300]: loss = 0.489023 * 100, metric = 7.38% * 100;
 Minibatch[ 301- 400]: loss = 0.507334 * 100, metric = 7.90% * 100;
 Minibatch[ 401- 500]: loss = 0.502823 * 100, metric = 7.73% * 100;
 Minibatch[ 501- 600]: loss = 0.493147 * 100, metric = 7.48% * 100;
 Minibatch[ 601- 700]: loss = 0.519905 * 100, metric = 8.20% * 100;
 Minibatch[ 701- 800]: loss = 0.485580 * 100, metric = 7.62% * 100;
 Minibatch[ 801- 900]: loss = 0.521371 * 100, metric = 8.11% * 100;
 Minibatch[ 901-1000]: loss = 0.491223 * 100, metric = 7.46% * 100;
 Minibatch[1001-1100]: loss = 0.510548 * 100, metric = 7.76% * 100;
 Minibatch[1101-1200]: loss = 0.501108 * 100, metric = 8.01% * 100;
 Minibatch[1201-1300]: loss = 0.487267 * 100, metric = 7.44% * 100;
 Minibatch[1301-1400]: loss = 0.484431 * 100, metric = 7.46% * 100;
 Minibatch[1401-1500]: loss = 0.519957 * 100, metric = 8.12% * 100;
 Minibatch[1501-1600]: loss = 0.518857 * 100, metric = 8.11% * 100;
 Minibatch[1601-1700]: loss = 0.495911 * 100, metric = 7.67% * 100;
 Minibatch[1701-1800]: loss = 0.484462 * 100, metric = 7.33% * 100;
 Minibatch[1801-1900]: loss = 0.500140 * 100, metric = 7.75% * 100;
 Minibatch[1901-2000]: loss = 0.483347 * 100, metric = 7.46% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.501684 * 2000, metric = 7.76% * 2000 739.170s (  2.7 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 15.30% * 2000;
 Minibatch[   1- 100]: loss = 0.495328 * 100, metric = 7.48% * 100;
 Minibatch[ 101- 200]: loss = 0.498827 * 100, metric = 7.65% * 100;
 Minibatch[ 201- 300]: loss = 0.498011 * 100, metric = 7.39% * 100;
 Minibatch[ 301- 400]: loss = 0.518729 * 100, metric = 7.88% * 100;
 Minibatch[ 401- 500]: loss = 0.503381 * 100, metric = 7.77% * 100;
 Minibatch[ 501- 600]: loss = 0.502982 * 100, metric = 7.84% * 100;
 Minibatch[ 601- 700]: loss = 0.511451 * 100, metric = 8.12% * 100;
 Minibatch[ 701- 800]: loss = 0.504274 * 100, metric = 7.90% * 100;
 Minibatch[ 801- 900]: loss = 0.519279 * 100, metric = 8.21% * 100;
 Minibatch[ 901-1000]: loss = 0.527636 * 100, metric = 8.18% * 100;
 Minibatch[1001-1100]: loss = 0.477930 * 100, metric = 7.23% * 100;
 Minibatch[1101-1200]: loss = 0.493012 * 100, metric = 7.49% * 100;
 Minibatch[1201-1300]: loss = 0.524105 * 100, metric = 8.07% * 100;
 Minibatch[1301-1400]: loss = 0.502401 * 100, metric = 7.92% * 100;
 Minibatch[1401-1500]: loss = 0.490043 * 100, metric = 7.71% * 100;
 Minibatch[1501-1600]: loss = 0.503361 * 100, metric = 7.66% * 100;
 Minibatch[1601-1700]: loss = 0.493526 * 100, metric = 7.59% * 100;
 Minibatch[1701-1800]: loss = 0.504429 * 100, metric = 7.94% * 100;
 Minibatch[1801-1900]: loss = 0.497979 * 100, metric = 7.68% * 100;
 Minibatch[1901-2000]: loss = 0.494068 * 100, metric = 7.76% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.503038 * 2000, metric = 7.77% * 2000 774.892s (  2.6 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 15.01% * 2000;
 Minibatch[   1- 100]: loss = 0.500843 * 100, metric = 7.88% * 100;
 Minibatch[ 101- 200]: loss = 0.501588 * 100, metric = 7.74% * 100;
 Minibatch[ 201- 300]: loss = 0.489107 * 100, metric = 7.50% * 100;
 Minibatch[ 301- 400]: loss = 0.500370 * 100, metric = 7.87% * 100;
 Minibatch[ 401- 500]: loss = 0.484728 * 100, metric = 7.34% * 100;
 Minibatch[ 501- 600]: loss = 0.496369 * 100, metric = 7.56% * 100;
 Minibatch[ 601- 700]: loss = 0.500514 * 100, metric = 7.65% * 100;
 Minibatch[ 701- 800]: loss = 0.461446 * 100, metric = 7.09% * 100;
 Minibatch[ 801- 900]: loss = 0.498105 * 100, metric = 7.46% * 100;
 Minibatch[ 901-1000]: loss = 0.480610 * 100, metric = 7.27% * 100;
 Minibatch[1001-1100]: loss = 0.490373 * 100, metric = 7.46% * 100;
 Minibatch[1101-1200]: loss = 0.482637 * 100, metric = 7.40% * 100;
 Minibatch[1201-1300]: loss = 0.495422 * 100, metric = 7.60% * 100;
 Minibatch[1301-1400]: loss = 0.483412 * 100, metric = 7.18% * 100;
 Minibatch[1401-1500]: loss = 0.495341 * 100, metric = 7.61% * 100;
 Minibatch[1501-1600]: loss = 0.495035 * 100, metric = 7.92% * 100;
 Minibatch[1601-1700]: loss = 0.480811 * 100, metric = 7.47% * 100;
 Minibatch[1701-1800]: loss = 0.475742 * 100, metric = 7.10% * 100;
 Minibatch[1801-1900]: loss = 0.503621 * 100, metric = 7.82% * 100;
 Minibatch[1901-2000]: loss = 0.462731 * 100, metric = 6.95% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.488940 * 2000, metric = 7.49% * 2000 787.253s (  2.5 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 14.10% * 2000;
0.6251265599764884
 Minibatch[   1- 100]: loss = 0.486821 * 100, metric = 7.62% * 100;
 Minibatch[ 101- 200]: loss = 0.482971 * 100, metric = 7.57% * 100;
 Minibatch[ 201- 300]: loss = 0.485290 * 100, metric = 7.34% * 100;
 Minibatch[ 301- 400]: loss = 0.478127 * 100, metric = 7.46% * 100;
 Minibatch[ 401- 500]: loss = 0.475180 * 100, metric = 7.06% * 100;
 Minibatch[ 501- 600]: loss = 0.487825 * 100, metric = 7.40% * 100;
 Minibatch[ 601- 700]: loss = 0.475705 * 100, metric = 7.23% * 100;
 Minibatch[ 701- 800]: loss = 0.475526 * 100, metric = 7.25% * 100;
 Minibatch[ 801- 900]: loss = 0.489777 * 100, metric = 7.47% * 100;
 Minibatch[ 901-1000]: loss = 0.495117 * 100, metric = 7.65% * 100;
 Minibatch[1001-1100]: loss = 0.460361 * 100, metric = 6.88% * 100;
 Minibatch[1101-1200]: loss = 0.462057 * 100, metric = 6.77% * 100;
 Minibatch[1201-1300]: loss = 0.474427 * 100, metric = 7.15% * 100;
 Minibatch[1301-1400]: loss = 0.487131 * 100, metric = 7.56% * 100;
 Minibatch[1401-1500]: loss = 0.474982 * 100, metric = 7.35% * 100;
 Minibatch[1501-1600]: loss = 0.468474 * 100, metric = 7.05% * 100;
 Minibatch[1601-1700]: loss = 0.470059 * 100, metric = 7.22% * 100;
 Minibatch[1701-1800]: loss = 0.481427 * 100, metric = 7.29% * 100;
 Minibatch[1801-1900]: loss = 0.471533 * 100, metric = 7.20% * 100;
 Minibatch[1901-2000]: loss = 0.473777 * 100, metric = 6.95% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.477828 * 2000, metric = 7.27% * 2000 757.723s (  2.6 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 14.37% * 2000;
 Minibatch[   1- 100]: loss = 0.494344 * 100, metric = 7.45% * 100;
 Minibatch[ 101- 200]: loss = 0.492678 * 100, metric = 7.55% * 100;
 Minibatch[ 201- 300]: loss = 0.486783 * 100, metric = 7.30% * 100;
 Minibatch[ 301- 400]: loss = 0.491083 * 100, metric = 7.39% * 100;
 Minibatch[ 401- 500]: loss = 0.498100 * 100, metric = 7.62% * 100;
 Minibatch[ 501- 600]: loss = 0.484700 * 100, metric = 7.25% * 100;
 Minibatch[ 601- 700]: loss = 0.487480 * 100, metric = 7.43% * 100;
 Minibatch[ 701- 800]: loss = 0.471349 * 100, metric = 6.95% * 100;
 Minibatch[ 801- 900]: loss = 0.464080 * 100, metric = 7.18% * 100;
 Minibatch[ 901-1000]: loss = 0.487923 * 100, metric = 7.53% * 100;
 Minibatch[1001-1100]: loss = 0.467747 * 100, metric = 7.00% * 100;
 Minibatch[1101-1200]: loss = 0.483046 * 100, metric = 7.47% * 100;
 Minibatch[1201-1300]: loss = 0.488234 * 100, metric = 7.44% * 100;
 Minibatch[1301-1400]: loss = 0.484645 * 100, metric = 7.65% * 100;
 Minibatch[1401-1500]: loss = 0.462346 * 100, metric = 7.02% * 100;
 Minibatch[1501-1600]: loss = 0.474731 * 100, metric = 7.19% * 100;
 Minibatch[1601-1700]: loss = 0.468055 * 100, metric = 7.03% * 100;
 Minibatch[1701-1800]: loss = 0.480232 * 100, metric = 7.27% * 100;
 Minibatch[1801-1900]: loss = 0.483138 * 100, metric = 7.50% * 100;
 Minibatch[1901-2000]: loss = 0.483671 * 100, metric = 7.33% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.481718 * 2000, metric = 7.33% * 2000 742.967s (  2.7 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 14.59% * 2000;
 Minibatch[   1- 100]: loss = 0.456939 * 100, metric = 7.07% * 100;
 Minibatch[ 101- 200]: loss = 0.483969 * 100, metric = 7.61% * 100;
 Minibatch[ 201- 300]: loss = 0.473835 * 100, metric = 7.25% * 100;
 Minibatch[ 301- 400]: loss = 0.479286 * 100, metric = 7.32% * 100;
 Minibatch[ 401- 500]: loss = 0.473467 * 100, metric = 7.24% * 100;
 Minibatch[ 501- 600]: loss = 0.464930 * 100, metric = 7.07% * 100;
 Minibatch[ 601- 700]: loss = 0.468490 * 100, metric = 7.12% * 100;
 Minibatch[ 701- 800]: loss = 0.475194 * 100, metric = 7.30% * 100;
 Minibatch[ 801- 900]: loss = 0.486134 * 100, metric = 7.46% * 100;
 Minibatch[ 901-1000]: loss = 0.473177 * 100, metric = 7.18% * 100;
 Minibatch[1001-1100]: loss = 0.480894 * 100, metric = 7.49% * 100;
 Minibatch[1101-1200]: loss = 0.492618 * 100, metric = 7.63% * 100;
 Minibatch[1201-1300]: loss = 0.483876 * 100, metric = 7.29% * 100;
 Minibatch[1301-1400]: loss = 0.474363 * 100, metric = 7.10% * 100;
 Minibatch[1401-1500]: loss = 0.464531 * 100, metric = 6.79% * 100;
 Minibatch[1501-1600]: loss = 0.481403 * 100, metric = 7.24% * 100;
 Minibatch[1601-1700]: loss = 0.454794 * 100, metric = 6.69% * 100;
 Minibatch[1701-1800]: loss = 0.462402 * 100, metric = 6.87% * 100;
 Minibatch[1801-1900]: loss = 0.469952 * 100, metric = 7.04% * 100;
 Minibatch[1901-2000]: loss = 0.474995 * 100, metric = 7.16% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.473762 * 2000, metric = 7.20% * 2000 741.606s (  2.7 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.15% * 2000;
 Minibatch[   1- 100]: loss = 0.470817 * 100, metric = 6.95% * 100;
 Minibatch[ 101- 200]: loss = 0.474031 * 100, metric = 7.20% * 100;
 Minibatch[ 201- 300]: loss = 0.462738 * 100, metric = 7.04% * 100;
 Minibatch[ 301- 400]: loss = 0.464916 * 100, metric = 7.17% * 100;
 Minibatch[ 401- 500]: loss = 0.472890 * 100, metric = 7.19% * 100;
 Minibatch[ 501- 600]: loss = 0.465872 * 100, metric = 7.06% * 100;
 Minibatch[ 601- 700]: loss = 0.473779 * 100, metric = 7.15% * 100;
 Minibatch[ 701- 800]: loss = 0.447311 * 100, metric = 6.50% * 100;
 Minibatch[ 801- 900]: loss = 0.453280 * 100, metric = 6.79% * 100;
 Minibatch[ 901-1000]: loss = 0.469817 * 100, metric = 7.12% * 100;
 Minibatch[1001-1100]: loss = 0.466467 * 100, metric = 7.11% * 100;
 Minibatch[1101-1200]: loss = 0.480731 * 100, metric = 7.45% * 100;
 Minibatch[1201-1300]: loss = 0.495270 * 100, metric = 7.60% * 100;
 Minibatch[1301-1400]: loss = 0.468295 * 100, metric = 7.09% * 100;
 Minibatch[1401-1500]: loss = 0.464666 * 100, metric = 6.76% * 100;
 Minibatch[1501-1600]: loss = 0.477817 * 100, metric = 7.37% * 100;
 Minibatch[1601-1700]: loss = 0.464703 * 100, metric = 7.04% * 100;
 Minibatch[1701-1800]: loss = 0.467078 * 100, metric = 6.94% * 100;
 Minibatch[1801-1900]: loss = 0.456616 * 100, metric = 6.72% * 100;
 Minibatch[1901-2000]: loss = 0.449037 * 100, metric = 6.49% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.467307 * 2000, metric = 7.04% * 2000 743.200s (  2.7 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.55% * 2000;
 Minibatch[   1- 100]: loss = 0.462221 * 100, metric = 6.78% * 100;
 Minibatch[ 101- 200]: loss = 0.449307 * 100, metric = 6.72% * 100;
 Minibatch[ 201- 300]: loss = 0.460237 * 100, metric = 6.84% * 100;
 Minibatch[ 301- 400]: loss = 0.450600 * 100, metric = 6.68% * 100;
 Minibatch[ 401- 500]: loss = 0.456809 * 100, metric = 6.74% * 100;
 Minibatch[ 501- 600]: loss = 0.448989 * 100, metric = 6.52% * 100;
 Minibatch[ 601- 700]: loss = 0.462653 * 100, metric = 6.94% * 100;
 Minibatch[ 701- 800]: loss = 0.453257 * 100, metric = 6.90% * 100;
 Minibatch[ 801- 900]: loss = 0.440992 * 100, metric = 6.31% * 100;
 Minibatch[ 901-1000]: loss = 0.443304 * 100, metric = 6.52% * 100;
 Minibatch[1001-1100]: loss = 0.464595 * 100, metric = 7.03% * 100;
 Minibatch[1101-1200]: loss = 0.471505 * 100, metric = 6.87% * 100;
 Minibatch[1201-1300]: loss = 0.451355 * 100, metric = 6.48% * 100;
 Minibatch[1301-1400]: loss = 0.444497 * 100, metric = 6.40% * 100;
 Minibatch[1401-1500]: loss = 0.460819 * 100, metric = 6.89% * 100;
 Minibatch[1501-1600]: loss = 0.453112 * 100, metric = 6.40% * 100;
 Minibatch[1601-1700]: loss = 0.482871 * 100, metric = 7.22% * 100;
 Minibatch[1701-1800]: loss = 0.462066 * 100, metric = 6.75% * 100;
 Minibatch[1801-1900]: loss = 0.458400 * 100, metric = 6.81% * 100;
 Minibatch[1901-2000]: loss = 0.453632 * 100, metric = 6.78% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.456561 * 2000, metric = 6.73% * 2000 738.429s (  2.7 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.33% * 2000;
 Minibatch[   1- 100]: loss = 0.456456 * 100, metric = 6.69% * 100;
 Minibatch[ 101- 200]: loss = 0.460929 * 100, metric = 6.84% * 100;
 Minibatch[ 201- 300]: loss = 0.451577 * 100, metric = 6.82% * 100;
 Minibatch[ 301- 400]: loss = 0.441254 * 100, metric = 6.43% * 100;
 Minibatch[ 401- 500]: loss = 0.463828 * 100, metric = 6.82% * 100;
 Minibatch[ 501- 600]: loss = 0.447838 * 100, metric = 6.56% * 100;
 Minibatch[ 601- 700]: loss = 0.440522 * 100, metric = 6.45% * 100;
 Minibatch[ 701- 800]: loss = 0.458416 * 100, metric = 6.73% * 100;
 Minibatch[ 801- 900]: loss = 0.463570 * 100, metric = 6.82% * 100;
 Minibatch[ 901-1000]: loss = 0.454844 * 100, metric = 7.01% * 100;
 Minibatch[1001-1100]: loss = 0.438749 * 100, metric = 6.26% * 100;
 Minibatch[1101-1200]: loss = 0.457802 * 100, metric = 6.64% * 100;
 Minibatch[1201-1300]: loss = 0.446542 * 100, metric = 6.46% * 100;
 Minibatch[1301-1400]: loss = 0.474521 * 100, metric = 7.05% * 100;
 Minibatch[1401-1500]: loss = 0.445351 * 100, metric = 6.81% * 100;
 Minibatch[1501-1600]: loss = 0.452586 * 100, metric = 6.62% * 100;
 Minibatch[1601-1700]: loss = 0.430399 * 100, metric = 6.14% * 100;
 Minibatch[1701-1800]: loss = 0.447803 * 100, metric = 6.38% * 100;
 Minibatch[1801-1900]: loss = 0.445910 * 100, metric = 6.46% * 100;
 Minibatch[1901-2000]: loss = 0.452383 * 100, metric = 6.75% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.451564 * 2000, metric = 6.64% * 2000 739.994s (  2.7 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.62% * 2000;
0.6244302011355758
 Minibatch[   1- 100]: loss = 0.452895 * 100, metric = 6.92% * 100;
 Minibatch[ 101- 200]: loss = 0.440293 * 100, metric = 6.38% * 100;
 Minibatch[ 201- 300]: loss = 0.458228 * 100, metric = 6.87% * 100;
 Minibatch[ 301- 400]: loss = 0.447187 * 100, metric = 6.50% * 100;
 Minibatch[ 401- 500]: loss = 0.442065 * 100, metric = 6.59% * 100;
 Minibatch[ 501- 600]: loss = 0.460651 * 100, metric = 7.09% * 100;
 Minibatch[ 601- 700]: loss = 0.446460 * 100, metric = 6.61% * 100;
 Minibatch[ 701- 800]: loss = 0.432878 * 100, metric = 6.35% * 100;
 Minibatch[ 801- 900]: loss = 0.449369 * 100, metric = 6.70% * 100;
 Minibatch[ 901-1000]: loss = 0.450041 * 100, metric = 6.81% * 100;
 Minibatch[1001-1100]: loss = 0.442142 * 100, metric = 6.54% * 100;
 Minibatch[1101-1200]: loss = 0.447261 * 100, metric = 6.62% * 100;
 Minibatch[1201-1300]: loss = 0.456870 * 100, metric = 6.79% * 100;
 Minibatch[1301-1400]: loss = 0.441871 * 100, metric = 6.49% * 100;
 Minibatch[1401-1500]: loss = 0.459721 * 100, metric = 6.67% * 100;
 Minibatch[1501-1600]: loss = 0.449689 * 100, metric = 6.65% * 100;
 Minibatch[1601-1700]: loss = 0.449559 * 100, metric = 6.40% * 100;
 Minibatch[1701-1800]: loss = 0.455317 * 100, metric = 6.66% * 100;
 Minibatch[1801-1900]: loss = 0.445480 * 100, metric = 6.69% * 100;
 Minibatch[1901-2000]: loss = 0.450221 * 100, metric = 6.66% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.448910 * 2000, metric = 6.65% * 2000 748.468s (  2.7 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 12.91% * 2000;
0.6156327459178865
 Minibatch[   1- 100]: loss = 0.436878 * 100, metric = 6.21% * 100;
 Minibatch[ 101- 200]: loss = 0.439719 * 100, metric = 6.60% * 100;
 Minibatch[ 201- 300]: loss = 0.450146 * 100, metric = 6.83% * 100;
 Minibatch[ 301- 400]: loss = 0.461342 * 100, metric = 6.89% * 100;
 Minibatch[ 401- 500]: loss = 0.438975 * 100, metric = 6.27% * 100;
 Minibatch[ 501- 600]: loss = 0.442633 * 100, metric = 6.40% * 100;
 Minibatch[ 601- 700]: loss = 0.437887 * 100, metric = 6.45% * 100;
 Minibatch[ 701- 800]: loss = 0.447534 * 100, metric = 6.79% * 100;
 Minibatch[ 801- 900]: loss = 0.444145 * 100, metric = 6.48% * 100;
 Minibatch[ 901-1000]: loss = 0.454688 * 100, metric = 6.68% * 100;
 Minibatch[1001-1100]: loss = 0.446573 * 100, metric = 6.54% * 100;
 Minibatch[1101-1200]: loss = 0.433092 * 100, metric = 6.31% * 100;
 Minibatch[1201-1300]: loss = 0.444059 * 100, metric = 6.40% * 100;
 Minibatch[1301-1400]: loss = 0.428484 * 100, metric = 6.14% * 100;
 Minibatch[1401-1500]: loss = 0.460091 * 100, metric = 6.69% * 100;
 Minibatch[1501-1600]: loss = 0.429124 * 100, metric = 6.20% * 100;
 Minibatch[1601-1700]: loss = 0.454637 * 100, metric = 6.85% * 100;
 Minibatch[1701-1800]: loss = 0.433278 * 100, metric = 6.30% * 100;
 Minibatch[1801-1900]: loss = 0.451024 * 100, metric = 6.61% * 100;
 Minibatch[1901-2000]: loss = 0.438740 * 100, metric = 6.38% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.443652 * 2000, metric = 6.50% * 2000 741.146s (  2.7 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 14.44% * 2000;
 Minibatch[   1- 100]: loss = 0.462983 * 100, metric = 6.85% * 100;
 Minibatch[ 101- 200]: loss = 0.418561 * 100, metric = 5.85% * 100;
 Minibatch[ 201- 300]: loss = 0.442373 * 100, metric = 6.39% * 100;
 Minibatch[ 301- 400]: loss = 0.446769 * 100, metric = 6.60% * 100;
 Minibatch[ 401- 500]: loss = 0.445427 * 100, metric = 6.32% * 100;
 Minibatch[ 501- 600]: loss = 0.416706 * 100, metric = 5.93% * 100;
 Minibatch[ 601- 700]: loss = 0.431681 * 100, metric = 6.33% * 100;
 Minibatch[ 701- 800]: loss = 0.440258 * 100, metric = 6.34% * 100;
 Minibatch[ 801- 900]: loss = 0.446228 * 100, metric = 6.52% * 100;
 Minibatch[ 901-1000]: loss = 0.416964 * 100, metric = 5.93% * 100;
 Minibatch[1001-1100]: loss = 0.434128 * 100, metric = 6.27% * 100;
 Minibatch[1101-1200]: loss = 0.454793 * 100, metric = 6.59% * 100;
 Minibatch[1201-1300]: loss = 0.422259 * 100, metric = 6.00% * 100;
 Minibatch[1301-1400]: loss = 0.443181 * 100, metric = 6.49% * 100;
 Minibatch[1401-1500]: loss = 0.429514 * 100, metric = 6.30% * 100;
 Minibatch[1501-1600]: loss = 0.452284 * 100, metric = 6.56% * 100;
 Minibatch[1601-1700]: loss = 0.445712 * 100, metric = 6.51% * 100;
 Minibatch[1701-1800]: loss = 0.450712 * 100, metric = 6.56% * 100;
 Minibatch[1801-1900]: loss = 0.440637 * 100, metric = 6.49% * 100;
 Minibatch[1901-2000]: loss = 0.453672 * 100, metric = 6.76% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.439742 * 2000, metric = 6.38% * 2000 741.565s (  2.7 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 13.96% * 2000;
 Minibatch[   1- 100]: loss = 0.445344 * 100, metric = 6.35% * 100;
 Minibatch[ 101- 200]: loss = 0.450173 * 100, metric = 6.70% * 100;
 Minibatch[ 201- 300]: loss = 0.435397 * 100, metric = 6.26% * 100;
 Minibatch[ 301- 400]: loss = 0.427983 * 100, metric = 6.25% * 100;
 Minibatch[ 401- 500]: loss = 0.431613 * 100, metric = 6.24% * 100;
 Minibatch[ 501- 600]: loss = 0.435410 * 100, metric = 6.27% * 100;
 Minibatch[ 601- 700]: loss = 0.453104 * 100, metric = 6.65% * 100;
 Minibatch[ 701- 800]: loss = 0.452887 * 100, metric = 6.77% * 100;
 Minibatch[ 801- 900]: loss = 0.446341 * 100, metric = 6.46% * 100;
 Minibatch[ 901-1000]: loss = 0.425902 * 100, metric = 6.24% * 100;
 Minibatch[1001-1100]: loss = 0.431639 * 100, metric = 6.25% * 100;
 Minibatch[1101-1200]: loss = 0.443798 * 100, metric = 6.70% * 100;
 Minibatch[1201-1300]: loss = 0.446718 * 100, metric = 6.70% * 100;
 Minibatch[1301-1400]: loss = 0.435839 * 100, metric = 6.43% * 100;
 Minibatch[1401-1500]: loss = 0.447336 * 100, metric = 6.57% * 100;
 Minibatch[1501-1600]: loss = 0.430361 * 100, metric = 6.48% * 100;
 Minibatch[1601-1700]: loss = 0.447808 * 100, metric = 6.39% * 100;
 Minibatch[1701-1800]: loss = 0.441652 * 100, metric = 6.58% * 100;
 Minibatch[1801-1900]: loss = 0.440950 * 100, metric = 6.51% * 100;
 Minibatch[1901-2000]: loss = 0.436791 * 100, metric = 6.34% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.440352 * 2000, metric = 6.46% * 2000 742.563s (  2.7 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 13.93% * 2000;
 Minibatch[   1- 100]: loss = 0.433615 * 100, metric = 6.26% * 100;
 Minibatch[ 101- 200]: loss = 0.438070 * 100, metric = 6.40% * 100;
 Minibatch[ 201- 300]: loss = 0.445951 * 100, metric = 6.68% * 100;
 Minibatch[ 301- 400]: loss = 0.447845 * 100, metric = 6.57% * 100;
 Minibatch[ 401- 500]: loss = 0.445727 * 100, metric = 6.76% * 100;
 Minibatch[ 501- 600]: loss = 0.446457 * 100, metric = 6.76% * 100;
 Minibatch[ 601- 700]: loss = 0.434210 * 100, metric = 6.28% * 100;
 Minibatch[ 701- 800]: loss = 0.428119 * 100, metric = 6.31% * 100;
 Minibatch[ 801- 900]: loss = 0.426902 * 100, metric = 6.15% * 100;
 Minibatch[ 901-1000]: loss = 0.430789 * 100, metric = 6.23% * 100;
 Minibatch[1001-1100]: loss = 0.421030 * 100, metric = 5.89% * 100;
 Minibatch[1101-1200]: loss = 0.441608 * 100, metric = 6.52% * 100;
 Minibatch[1201-1300]: loss = 0.444747 * 100, metric = 6.70% * 100;
 Minibatch[1301-1400]: loss = 0.434661 * 100, metric = 6.44% * 100;
 Minibatch[1401-1500]: loss = 0.438873 * 100, metric = 6.46% * 100;
 Minibatch[1501-1600]: loss = 0.440283 * 100, metric = 6.51% * 100;
 Minibatch[1601-1700]: loss = 0.424158 * 100, metric = 6.04% * 100;
 Minibatch[1701-1800]: loss = 0.444985 * 100, metric = 6.50% * 100;
 Minibatch[1801-1900]: loss = 0.426199 * 100, metric = 6.11% * 100;
 Minibatch[1901-2000]: loss = 0.442994 * 100, metric = 6.57% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.436861 * 2000, metric = 6.41% * 2000 721.818s (  2.8 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.88% * 2000;
 Minibatch[   1- 100]: loss = 0.451434 * 100, metric = 6.65% * 100;
 Minibatch[ 101- 200]: loss = 0.434428 * 100, metric = 6.63% * 100;
 Minibatch[ 201- 300]: loss = 0.425593 * 100, metric = 6.29% * 100;
 Minibatch[ 301- 400]: loss = 0.435204 * 100, metric = 6.54% * 100;
 Minibatch[ 401- 500]: loss = 0.423364 * 100, metric = 6.08% * 100;
 Minibatch[ 501- 600]: loss = 0.438279 * 100, metric = 6.46% * 100;
 Minibatch[ 601- 700]: loss = 0.442001 * 100, metric = 6.70% * 100;
 Minibatch[ 701- 800]: loss = 0.426423 * 100, metric = 6.22% * 100;
 Minibatch[ 801- 900]: loss = 0.428964 * 100, metric = 6.27% * 100;
 Minibatch[ 901-1000]: loss = 0.417612 * 100, metric = 5.90% * 100;
 Minibatch[1001-1100]: loss = 0.437841 * 100, metric = 6.45% * 100;
 Minibatch[1101-1200]: loss = 0.414467 * 100, metric = 6.00% * 100;
 Minibatch[1201-1300]: loss = 0.441728 * 100, metric = 6.46% * 100;
 Minibatch[1301-1400]: loss = 0.413403 * 100, metric = 5.90% * 100;
 Minibatch[1401-1500]: loss = 0.449193 * 100, metric = 6.43% * 100;
 Minibatch[1501-1600]: loss = 0.444704 * 100, metric = 6.58% * 100;
 Minibatch[1601-1700]: loss = 0.423400 * 100, metric = 5.97% * 100;
 Minibatch[1701-1800]: loss = 0.423279 * 100, metric = 6.14% * 100;
 Minibatch[1801-1900]: loss = 0.426049 * 100, metric = 6.15% * 100;
 Minibatch[1901-2000]: loss = 0.440570 * 100, metric = 6.66% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.431897 * 2000, metric = 6.32% * 2000 706.800s (  2.8 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.54% * 2000;
 Minibatch[   1- 100]: loss = 0.425532 * 100, metric = 6.13% * 100;
 Minibatch[ 101- 200]: loss = 0.439223 * 100, metric = 6.35% * 100;
 Minibatch[ 201- 300]: loss = 0.420255 * 100, metric = 6.12% * 100;
 Minibatch[ 301- 400]: loss = 0.431355 * 100, metric = 6.37% * 100;
 Minibatch[ 401- 500]: loss = 0.419887 * 100, metric = 6.21% * 100;
 Minibatch[ 501- 600]: loss = 0.432087 * 100, metric = 6.24% * 100;
 Minibatch[ 601- 700]: loss = 0.429801 * 100, metric = 6.31% * 100;
 Minibatch[ 701- 800]: loss = 0.420793 * 100, metric = 6.06% * 100;
 Minibatch[ 801- 900]: loss = 0.413712 * 100, metric = 5.80% * 100;
 Minibatch[ 901-1000]: loss = 0.414618 * 100, metric = 5.94% * 100;
 Minibatch[1001-1100]: loss = 0.435309 * 100, metric = 6.34% * 100;
 Minibatch[1101-1200]: loss = 0.423521 * 100, metric = 6.29% * 100;
 Minibatch[1201-1300]: loss = 0.422316 * 100, metric = 6.13% * 100;
 Minibatch[1301-1400]: loss = 0.424144 * 100, metric = 6.20% * 100;
 Minibatch[1401-1500]: loss = 0.437252 * 100, metric = 6.44% * 100;
 Minibatch[1501-1600]: loss = 0.429656 * 100, metric = 6.07% * 100;
 Minibatch[1601-1700]: loss = 0.440182 * 100, metric = 6.58% * 100;
 Minibatch[1701-1800]: loss = 0.427549 * 100, metric = 6.16% * 100;
 Minibatch[1801-1900]: loss = 0.426912 * 100, metric = 6.29% * 100;
 Minibatch[1901-2000]: loss = 0.433976 * 100, metric = 6.19% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.427404 * 2000, metric = 6.21% * 2000 706.043s (  2.8 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.20% * 2000;
 Minibatch[   1- 100]: loss = 0.404655 * 100, metric = 5.73% * 100;
 Minibatch[ 101- 200]: loss = 0.427197 * 100, metric = 6.20% * 100;
 Minibatch[ 201- 300]: loss = 0.420048 * 100, metric = 6.05% * 100;
 Minibatch[ 301- 400]: loss = 0.403809 * 100, metric = 5.68% * 100;
 Minibatch[ 401- 500]: loss = 0.416730 * 100, metric = 5.87% * 100;
 Minibatch[ 501- 600]: loss = 0.400643 * 100, metric = 5.70% * 100;
 Minibatch[ 601- 700]: loss = 0.437419 * 100, metric = 6.61% * 100;
 Minibatch[ 701- 800]: loss = 0.403547 * 100, metric = 5.65% * 100;
 Minibatch[ 801- 900]: loss = 0.422920 * 100, metric = 6.03% * 100;
 Minibatch[ 901-1000]: loss = 0.402502 * 100, metric = 5.71% * 100;
 Minibatch[1001-1100]: loss = 0.426952 * 100, metric = 6.18% * 100;
 Minibatch[1101-1200]: loss = 0.409067 * 100, metric = 5.78% * 100;
 Minibatch[1201-1300]: loss = 0.419737 * 100, metric = 6.26% * 100;
 Minibatch[1301-1400]: loss = 0.419813 * 100, metric = 6.28% * 100;
 Minibatch[1401-1500]: loss = 0.408962 * 100, metric = 5.75% * 100;
 Minibatch[1501-1600]: loss = 0.423405 * 100, metric = 6.10% * 100;
 Minibatch[1601-1700]: loss = 0.419684 * 100, metric = 6.14% * 100;
 Minibatch[1701-1800]: loss = 0.409000 * 100, metric = 5.87% * 100;
 Minibatch[1801-1900]: loss = 0.426038 * 100, metric = 6.12% * 100;
 Minibatch[1901-2000]: loss = 0.411683 * 100, metric = 5.86% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.415691 * 2000, metric = 5.98% * 2000 712.829s (  2.8 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.00% * 2000;
 Minibatch[   1- 100]: loss = 0.408184 * 100, metric = 5.71% * 100;
 Minibatch[ 101- 200]: loss = 0.398960 * 100, metric = 5.58% * 100;
 Minibatch[ 201- 300]: loss = 0.427722 * 100, metric = 6.47% * 100;
 Minibatch[ 301- 400]: loss = 0.415331 * 100, metric = 6.07% * 100;
 Minibatch[ 401- 500]: loss = 0.411833 * 100, metric = 5.77% * 100;
 Minibatch[ 501- 600]: loss = 0.417670 * 100, metric = 6.11% * 100;
 Minibatch[ 601- 700]: loss = 0.421563 * 100, metric = 5.86% * 100;
 Minibatch[ 701- 800]: loss = 0.395263 * 100, metric = 5.55% * 100;
 Minibatch[ 801- 900]: loss = 0.400804 * 100, metric = 5.82% * 100;
 Minibatch[ 901-1000]: loss = 0.422163 * 100, metric = 6.05% * 100;
 Minibatch[1001-1100]: loss = 0.425276 * 100, metric = 6.33% * 100;
 Minibatch[1101-1200]: loss = 0.414057 * 100, metric = 5.99% * 100;
 Minibatch[1201-1300]: loss = 0.422141 * 100, metric = 5.98% * 100;
 Minibatch[1301-1400]: loss = 0.392014 * 100, metric = 5.53% * 100;
 Minibatch[1401-1500]: loss = 0.409347 * 100, metric = 5.71% * 100;
 Minibatch[1501-1600]: loss = 0.406262 * 100, metric = 5.88% * 100;
 Minibatch[1601-1700]: loss = 0.428169 * 100, metric = 6.34% * 100;
 Minibatch[1701-1800]: loss = 0.435953 * 100, metric = 6.19% * 100;
 Minibatch[1801-1900]: loss = 0.418780 * 100, metric = 5.96% * 100;
 Minibatch[1901-2000]: loss = 0.412982 * 100, metric = 5.84% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.414224 * 2000, metric = 5.94% * 2000 714.194s (  2.8 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.38% * 2000;
 Minibatch[   1- 100]: loss = 0.420503 * 100, metric = 6.02% * 100;
 Minibatch[ 101- 200]: loss = 0.428089 * 100, metric = 6.26% * 100;
 Minibatch[ 201- 300]: loss = 0.418499 * 100, metric = 6.22% * 100;
 Minibatch[ 301- 400]: loss = 0.415433 * 100, metric = 6.04% * 100;
 Minibatch[ 401- 500]: loss = 0.410726 * 100, metric = 6.00% * 100;
 Minibatch[ 501- 600]: loss = 0.402367 * 100, metric = 5.86% * 100;
 Minibatch[ 601- 700]: loss = 0.413038 * 100, metric = 5.86% * 100;
 Minibatch[ 701- 800]: loss = 0.419261 * 100, metric = 5.89% * 100;
 Minibatch[ 801- 900]: loss = 0.419468 * 100, metric = 5.80% * 100;
 Minibatch[ 901-1000]: loss = 0.405366 * 100, metric = 5.45% * 100;
 Minibatch[1001-1100]: loss = 0.405168 * 100, metric = 5.77% * 100;
 Minibatch[1101-1200]: loss = 0.428413 * 100, metric = 6.40% * 100;
 Minibatch[1201-1300]: loss = 0.426953 * 100, metric = 6.10% * 100;
 Minibatch[1301-1400]: loss = 0.415980 * 100, metric = 5.83% * 100;
 Minibatch[1401-1500]: loss = 0.411526 * 100, metric = 5.82% * 100;
 Minibatch[1501-1600]: loss = 0.403928 * 100, metric = 5.57% * 100;
 Minibatch[1601-1700]: loss = 0.413354 * 100, metric = 6.02% * 100;
 Minibatch[1701-1800]: loss = 0.411693 * 100, metric = 5.73% * 100;
 Minibatch[1801-1900]: loss = 0.420885 * 100, metric = 6.19% * 100;
 Minibatch[1901-2000]: loss = 0.413031 * 100, metric = 5.75% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.415184 * 2000, metric = 5.93% * 2000 713.013s (  2.8 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.11% * 2000;
 Minibatch[   1- 100]: loss = 0.423236 * 100, metric = 6.14% * 100;
 Minibatch[ 101- 200]: loss = 0.413403 * 100, metric = 6.04% * 100;
 Minibatch[ 201- 300]: loss = 0.394296 * 100, metric = 5.42% * 100;
 Minibatch[ 301- 400]: loss = 0.393394 * 100, metric = 5.54% * 100;
 Minibatch[ 401- 500]: loss = 0.407249 * 100, metric = 5.69% * 100;
 Minibatch[ 501- 600]: loss = 0.408140 * 100, metric = 5.74% * 100;
 Minibatch[ 601- 700]: loss = 0.412557 * 100, metric = 6.01% * 100;
 Minibatch[ 701- 800]: loss = 0.409054 * 100, metric = 5.82% * 100;
 Minibatch[ 801- 900]: loss = 0.420723 * 100, metric = 6.03% * 100;
 Minibatch[ 901-1000]: loss = 0.412400 * 100, metric = 5.67% * 100;
 Minibatch[1001-1100]: loss = 0.420240 * 100, metric = 5.89% * 100;
 Minibatch[1101-1200]: loss = 0.398926 * 100, metric = 5.61% * 100;
 Minibatch[1201-1300]: loss = 0.411450 * 100, metric = 6.00% * 100;
 Minibatch[1301-1400]: loss = 0.420045 * 100, metric = 5.92% * 100;
 Minibatch[1401-1500]: loss = 0.425070 * 100, metric = 6.19% * 100;
 Minibatch[1501-1600]: loss = 0.422336 * 100, metric = 6.07% * 100;
 Minibatch[1601-1700]: loss = 0.407288 * 100, metric = 5.93% * 100;
 Minibatch[1701-1800]: loss = 0.405779 * 100, metric = 5.89% * 100;
 Minibatch[1801-1900]: loss = 0.421223 * 100, metric = 6.04% * 100;
 Minibatch[1901-2000]: loss = 0.423109 * 100, metric = 5.88% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.412496 * 2000, metric = 5.88% * 2000 708.024s (  2.8 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 12.86% * 2000;
 Minibatch[   1- 100]: loss = 0.401614 * 100, metric = 5.63% * 100;
 Minibatch[ 101- 200]: loss = 0.421396 * 100, metric = 6.14% * 100;
 Minibatch[ 201- 300]: loss = 0.407686 * 100, metric = 5.76% * 100;
 Minibatch[ 301- 400]: loss = 0.407568 * 100, metric = 5.81% * 100;
 Minibatch[ 401- 500]: loss = 0.410361 * 100, metric = 6.01% * 100;
 Minibatch[ 501- 600]: loss = 0.422328 * 100, metric = 5.86% * 100;
 Minibatch[ 601- 700]: loss = 0.417422 * 100, metric = 6.03% * 100;
 Minibatch[ 701- 800]: loss = 0.412334 * 100, metric = 5.98% * 100;
 Minibatch[ 801- 900]: loss = 0.401515 * 100, metric = 5.71% * 100;
 Minibatch[ 901-1000]: loss = 0.409623 * 100, metric = 5.85% * 100;
 Minibatch[1001-1100]: loss = 0.419861 * 100, metric = 6.28% * 100;
 Minibatch[1101-1200]: loss = 0.413643 * 100, metric = 6.05% * 100;
 Minibatch[1201-1300]: loss = 0.416804 * 100, metric = 5.82% * 100;
 Minibatch[1301-1400]: loss = 0.423851 * 100, metric = 6.19% * 100;
 Minibatch[1401-1500]: loss = 0.411396 * 100, metric = 5.91% * 100;
 Minibatch[1501-1600]: loss = 0.409230 * 100, metric = 5.76% * 100;
 Minibatch[1601-1700]: loss = 0.407352 * 100, metric = 5.69% * 100;
 Minibatch[1701-1800]: loss = 0.418121 * 100, metric = 6.16% * 100;
 Minibatch[1801-1900]: loss = 0.411061 * 100, metric = 6.06% * 100;
 Minibatch[1901-2000]: loss = 0.404425 * 100, metric = 5.64% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.412380 * 2000, metric = 5.92% * 2000 704.417s (  2.8 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.08% * 2000;
 Minibatch[   1- 100]: loss = 0.402499 * 100, metric = 5.88% * 100;
 Minibatch[ 101- 200]: loss = 0.396060 * 100, metric = 5.51% * 100;
 Minibatch[ 201- 300]: loss = 0.415434 * 100, metric = 5.87% * 100;
 Minibatch[ 301- 400]: loss = 0.409681 * 100, metric = 5.84% * 100;
 Minibatch[ 401- 500]: loss = 0.400225 * 100, metric = 5.54% * 100;
 Minibatch[ 501- 600]: loss = 0.396414 * 100, metric = 5.64% * 100;
 Minibatch[ 601- 700]: loss = 0.417545 * 100, metric = 5.88% * 100;
 Minibatch[ 701- 800]: loss = 0.398669 * 100, metric = 5.48% * 100;
 Minibatch[ 801- 900]: loss = 0.401565 * 100, metric = 5.67% * 100;
 Minibatch[ 901-1000]: loss = 0.400567 * 100, metric = 5.66% * 100;
 Minibatch[1001-1100]: loss = 0.405761 * 100, metric = 5.80% * 100;
 Minibatch[1101-1200]: loss = 0.410478 * 100, metric = 5.85% * 100;
 Minibatch[1201-1300]: loss = 0.402693 * 100, metric = 5.56% * 100;
 Minibatch[1301-1400]: loss = 0.401740 * 100, metric = 5.82% * 100;
 Minibatch[1401-1500]: loss = 0.399489 * 100, metric = 5.58% * 100;
 Minibatch[1501-1600]: loss = 0.414736 * 100, metric = 5.99% * 100;
 Minibatch[1601-1700]: loss = 0.413633 * 100, metric = 5.88% * 100;
 Minibatch[1701-1800]: loss = 0.409370 * 100, metric = 5.80% * 100;
 Minibatch[1801-1900]: loss = 0.408671 * 100, metric = 5.50% * 100;
 Minibatch[1901-2000]: loss = 0.410408 * 100, metric = 5.89% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.405782 * 2000, metric = 5.73% * 2000 701.841s (  2.8 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 12.69% * 2000;
 Minibatch[   1- 100]: loss = 0.407437 * 100, metric = 5.87% * 100;
 Minibatch[ 101- 200]: loss = 0.398269 * 100, metric = 5.53% * 100;
 Minibatch[ 201- 300]: loss = 0.398991 * 100, metric = 5.60% * 100;
 Minibatch[ 301- 400]: loss = 0.410733 * 100, metric = 5.91% * 100;
 Minibatch[ 401- 500]: loss = 0.402797 * 100, metric = 5.77% * 100;
 Minibatch[ 501- 600]: loss = 0.396630 * 100, metric = 5.55% * 100;
 Minibatch[ 601- 700]: loss = 0.410121 * 100, metric = 5.85% * 100;
 Minibatch[ 701- 800]: loss = 0.400564 * 100, metric = 5.64% * 100;
 Minibatch[ 801- 900]: loss = 0.397788 * 100, metric = 5.60% * 100;
 Minibatch[ 901-1000]: loss = 0.407928 * 100, metric = 5.98% * 100;
 Minibatch[1001-1100]: loss = 0.408577 * 100, metric = 5.61% * 100;
 Minibatch[1101-1200]: loss = 0.423440 * 100, metric = 5.99% * 100;
 Minibatch[1201-1300]: loss = 0.415814 * 100, metric = 5.90% * 100;
 Minibatch[1301-1400]: loss = 0.388006 * 100, metric = 5.25% * 100;
 Minibatch[1401-1500]: loss = 0.398315 * 100, metric = 5.55% * 100;
 Minibatch[1501-1600]: loss = 0.412787 * 100, metric = 5.77% * 100;
 Minibatch[1601-1700]: loss = 0.408099 * 100, metric = 5.83% * 100;
 Minibatch[1701-1800]: loss = 0.403660 * 100, metric = 5.73% * 100;
 Minibatch[1801-1900]: loss = 0.405790 * 100, metric = 5.96% * 100;
 Minibatch[1901-2000]: loss = 0.397612 * 100, metric = 5.39% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.404668 * 2000, metric = 5.71% * 2000 702.117s (  2.8 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 13.96% * 2000;
 Minibatch[   1- 100]: loss = 0.400819 * 100, metric = 5.54% * 100;
 Minibatch[ 101- 200]: loss = 0.399161 * 100, metric = 5.69% * 100;
 Minibatch[ 201- 300]: loss = 0.403730 * 100, metric = 5.69% * 100;
 Minibatch[ 301- 400]: loss = 0.395267 * 100, metric = 5.41% * 100;
 Minibatch[ 401- 500]: loss = 0.399847 * 100, metric = 5.40% * 100;
 Minibatch[ 501- 600]: loss = 0.412694 * 100, metric = 5.73% * 100;
 Minibatch[ 601- 700]: loss = 0.401913 * 100, metric = 5.80% * 100;
 Minibatch[ 701- 800]: loss = 0.391848 * 100, metric = 5.41% * 100;
 Minibatch[ 801- 900]: loss = 0.387437 * 100, metric = 5.55% * 100;
 Minibatch[ 901-1000]: loss = 0.409781 * 100, metric = 5.87% * 100;
 Minibatch[1001-1100]: loss = 0.397792 * 100, metric = 5.86% * 100;
 Minibatch[1101-1200]: loss = 0.395852 * 100, metric = 5.50% * 100;
 Minibatch[1201-1300]: loss = 0.396963 * 100, metric = 5.59% * 100;
 Minibatch[1301-1400]: loss = 0.401898 * 100, metric = 5.77% * 100;
 Minibatch[1401-1500]: loss = 0.393976 * 100, metric = 5.40% * 100;
 Minibatch[1501-1600]: loss = 0.402349 * 100, metric = 5.63% * 100;
 Minibatch[1601-1700]: loss = 0.401145 * 100, metric = 5.68% * 100;
 Minibatch[1701-1800]: loss = 0.401646 * 100, metric = 5.67% * 100;
 Minibatch[1801-1900]: loss = 0.399398 * 100, metric = 5.81% * 100;
 Minibatch[1901-2000]: loss = 0.394768 * 100, metric = 5.48% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.399414 * 2000, metric = 5.62% * 2000 691.518s (  2.9 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 13.40% * 2000;
 Minibatch[   1- 100]: loss = 0.406960 * 100, metric = 6.00% * 100;
 Minibatch[ 101- 200]: loss = 0.395714 * 100, metric = 5.48% * 100;
 Minibatch[ 201- 300]: loss = 0.398790 * 100, metric = 5.48% * 100;
 Minibatch[ 301- 400]: loss = 0.395764 * 100, metric = 5.64% * 100;
 Minibatch[ 401- 500]: loss = 0.391616 * 100, metric = 5.33% * 100;
 Minibatch[ 501- 600]: loss = 0.389837 * 100, metric = 5.46% * 100;
 Minibatch[ 601- 700]: loss = 0.402918 * 100, metric = 5.66% * 100;
 Minibatch[ 701- 800]: loss = 0.392413 * 100, metric = 5.83% * 100;
 Minibatch[ 801- 900]: loss = 0.390736 * 100, metric = 5.51% * 100;
 Minibatch[ 901-1000]: loss = 0.400578 * 100, metric = 5.39% * 100;
 Minibatch[1001-1100]: loss = 0.401638 * 100, metric = 5.72% * 100;
 Minibatch[1101-1200]: loss = 0.391213 * 100, metric = 5.59% * 100;
 Minibatch[1201-1300]: loss = 0.410690 * 100, metric = 5.87% * 100;
 Minibatch[1301-1400]: loss = 0.397231 * 100, metric = 5.82% * 100;
 Minibatch[1401-1500]: loss = 0.378982 * 100, metric = 4.98% * 100;
 Minibatch[1501-1600]: loss = 0.407824 * 100, metric = 5.85% * 100;
 Minibatch[1601-1700]: loss = 0.395320 * 100, metric = 5.70% * 100;
 Minibatch[1701-1800]: loss = 0.388852 * 100, metric = 5.57% * 100;
 Minibatch[1801-1900]: loss = 0.392653 * 100, metric = 5.64% * 100;
 Minibatch[1901-2000]: loss = 0.384706 * 100, metric = 5.24% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.395722 * 2000, metric = 5.59% * 2000 694.342s (  2.9 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 13.67% * 2000;
 Minibatch[   1- 100]: loss = 0.387422 * 100, metric = 5.29% * 100;
 Minibatch[ 101- 200]: loss = 0.396511 * 100, metric = 5.74% * 100;
 Minibatch[ 201- 300]: loss = 0.385309 * 100, metric = 5.37% * 100;
 Minibatch[ 301- 400]: loss = 0.405250 * 100, metric = 5.57% * 100;
 Minibatch[ 401- 500]: loss = 0.392763 * 100, metric = 5.37% * 100;
 Minibatch[ 501- 600]: loss = 0.388913 * 100, metric = 5.69% * 100;
 Minibatch[ 601- 700]: loss = 0.398706 * 100, metric = 5.88% * 100;
 Minibatch[ 701- 800]: loss = 0.367769 * 100, metric = 4.84% * 100;
 Minibatch[ 801- 900]: loss = 0.384760 * 100, metric = 5.15% * 100;
 Minibatch[ 901-1000]: loss = 0.378239 * 100, metric = 5.22% * 100;
 Minibatch[1001-1100]: loss = 0.376176 * 100, metric = 5.07% * 100;
 Minibatch[1101-1200]: loss = 0.371369 * 100, metric = 5.04% * 100;
 Minibatch[1201-1300]: loss = 0.384500 * 100, metric = 5.22% * 100;
 Minibatch[1301-1400]: loss = 0.372761 * 100, metric = 5.03% * 100;
 Minibatch[1401-1500]: loss = 0.383312 * 100, metric = 5.25% * 100;
 Minibatch[1501-1600]: loss = 0.377225 * 100, metric = 5.13% * 100;
 Minibatch[1601-1700]: loss = 0.377010 * 100, metric = 5.10% * 100;
 Minibatch[1701-1800]: loss = 0.391962 * 100, metric = 5.65% * 100;
 Minibatch[1801-1900]: loss = 0.384387 * 100, metric = 5.11% * 100;
 Minibatch[1901-2000]: loss = 0.368834 * 100, metric = 5.05% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.383659 * 2000, metric = 5.29% * 2000 700.656s (  2.9 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 13.67% * 2000;
 Minibatch[   1- 100]: loss = 0.391015 * 100, metric = 5.17% * 100;
 Minibatch[ 101- 200]: loss = 0.382986 * 100, metric = 5.24% * 100;
 Minibatch[ 201- 300]: loss = 0.379183 * 100, metric = 5.09% * 100;
 Minibatch[ 301- 400]: loss = 0.388541 * 100, metric = 5.37% * 100;
 Minibatch[ 401- 500]: loss = 0.383239 * 100, metric = 5.30% * 100;
 Minibatch[ 501- 600]: loss = 0.371313 * 100, metric = 4.95% * 100;
 Minibatch[ 601- 700]: loss = 0.374632 * 100, metric = 5.01% * 100;
 Minibatch[ 701- 800]: loss = 0.366985 * 100, metric = 4.98% * 100;
 Minibatch[ 801- 900]: loss = 0.398540 * 100, metric = 5.51% * 100;
 Minibatch[ 901-1000]: loss = 0.377878 * 100, metric = 5.03% * 100;
 Minibatch[1001-1100]: loss = 0.375063 * 100, metric = 4.99% * 100;
 Minibatch[1101-1200]: loss = 0.393591 * 100, metric = 5.42% * 100;
 Minibatch[1201-1300]: loss = 0.380610 * 100, metric = 5.32% * 100;
 Minibatch[1301-1400]: loss = 0.369709 * 100, metric = 4.98% * 100;
 Minibatch[1401-1500]: loss = 0.382098 * 100, metric = 5.24% * 100;
 Minibatch[1501-1600]: loss = 0.372281 * 100, metric = 4.92% * 100;
 Minibatch[1601-1700]: loss = 0.363162 * 100, metric = 4.93% * 100;
 Minibatch[1701-1800]: loss = 0.389576 * 100, metric = 5.32% * 100;
 Minibatch[1801-1900]: loss = 0.388815 * 100, metric = 5.51% * 100;
 Minibatch[1901-2000]: loss = 0.386812 * 100, metric = 5.34% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.380802 * 2000, metric = 5.18% * 2000 700.028s (  2.9 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 13.03% * 2000;
 Minibatch[   1- 100]: loss = 0.373254 * 100, metric = 5.22% * 100;
 Minibatch[ 101- 200]: loss = 0.387660 * 100, metric = 5.21% * 100;
 Minibatch[ 201- 300]: loss = 0.375352 * 100, metric = 5.02% * 100;
 Minibatch[ 301- 400]: loss = 0.394340 * 100, metric = 5.63% * 100;
 Minibatch[ 401- 500]: loss = 0.377351 * 100, metric = 4.98% * 100;
 Minibatch[ 501- 600]: loss = 0.377236 * 100, metric = 5.07% * 100;
 Minibatch[ 601- 700]: loss = 0.362173 * 100, metric = 4.84% * 100;
 Minibatch[ 701- 800]: loss = 0.371469 * 100, metric = 4.94% * 100;
 Minibatch[ 801- 900]: loss = 0.373925 * 100, metric = 5.15% * 100;
 Minibatch[ 901-1000]: loss = 0.382452 * 100, metric = 5.24% * 100;
 Minibatch[1001-1100]: loss = 0.376911 * 100, metric = 5.12% * 100;
 Minibatch[1101-1200]: loss = 0.392987 * 100, metric = 5.33% * 100;
 Minibatch[1201-1300]: loss = 0.383300 * 100, metric = 5.33% * 100;
 Minibatch[1301-1400]: loss = 0.381577 * 100, metric = 5.28% * 100;
 Minibatch[1401-1500]: loss = 0.371863 * 100, metric = 5.17% * 100;
 Minibatch[1501-1600]: loss = 0.389098 * 100, metric = 5.39% * 100;
 Minibatch[1601-1700]: loss = 0.373999 * 100, metric = 4.94% * 100;
 Minibatch[1701-1800]: loss = 0.387767 * 100, metric = 5.41% * 100;
 Minibatch[1801-1900]: loss = 0.367616 * 100, metric = 4.94% * 100;
 Minibatch[1901-2000]: loss = 0.366993 * 100, metric = 4.81% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.378366 * 2000, metric = 5.15% * 2000 701.665s (  2.9 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 12.67% * 2000;
 Minibatch[   1- 100]: loss = 0.378905 * 100, metric = 5.03% * 100;
 Minibatch[ 101- 200]: loss = 0.375400 * 100, metric = 5.04% * 100;
 Minibatch[ 201- 300]: loss = 0.379493 * 100, metric = 5.15% * 100;
 Minibatch[ 301- 400]: loss = 0.372302 * 100, metric = 4.97% * 100;
 Minibatch[ 401- 500]: loss = 0.365039 * 100, metric = 5.06% * 100;
 Minibatch[ 501- 600]: loss = 0.367512 * 100, metric = 5.20% * 100;
 Minibatch[ 601- 700]: loss = 0.378161 * 100, metric = 5.20% * 100;
 Minibatch[ 701- 800]: loss = 0.389558 * 100, metric = 5.58% * 100;
 Minibatch[ 801- 900]: loss = 0.372986 * 100, metric = 4.99% * 100;
 Minibatch[ 901-1000]: loss = 0.371248 * 100, metric = 5.15% * 100;
 Minibatch[1001-1100]: loss = 0.399235 * 100, metric = 5.70% * 100;
 Minibatch[1101-1200]: loss = 0.373333 * 100, metric = 5.12% * 100;
 Minibatch[1201-1300]: loss = 0.361889 * 100, metric = 4.98% * 100;
 Minibatch[1301-1400]: loss = 0.365881 * 100, metric = 5.01% * 100;
 Minibatch[1401-1500]: loss = 0.383730 * 100, metric = 5.34% * 100;
 Minibatch[1501-1600]: loss = 0.387271 * 100, metric = 5.25% * 100;
 Minibatch[1601-1700]: loss = 0.374106 * 100, metric = 5.20% * 100;
 Minibatch[1701-1800]: loss = 0.381716 * 100, metric = 5.13% * 100;
 Minibatch[1801-1900]: loss = 0.373824 * 100, metric = 5.17% * 100;
 Minibatch[1901-2000]: loss = 0.393308 * 100, metric = 5.34% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.377245 * 2000, metric = 5.18% * 2000 696.143s (  2.9 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 12.68% * 2000;
 Minibatch[   1- 100]: loss = 0.376755 * 100, metric = 5.01% * 100;
 Minibatch[ 101- 200]: loss = 0.379997 * 100, metric = 5.16% * 100;
 Minibatch[ 201- 300]: loss = 0.369317 * 100, metric = 5.06% * 100;
 Minibatch[ 301- 400]: loss = 0.370101 * 100, metric = 5.04% * 100;
 Minibatch[ 401- 500]: loss = 0.386850 * 100, metric = 5.31% * 100;
 Minibatch[ 501- 600]: loss = 0.391894 * 100, metric = 5.43% * 100;
 Minibatch[ 601- 700]: loss = 0.390133 * 100, metric = 5.30% * 100;
 Minibatch[ 701- 800]: loss = 0.369440 * 100, metric = 4.95% * 100;
 Minibatch[ 801- 900]: loss = 0.365731 * 100, metric = 4.95% * 100;
 Minibatch[ 901-1000]: loss = 0.380993 * 100, metric = 5.36% * 100;
 Minibatch[1001-1100]: loss = 0.370768 * 100, metric = 5.04% * 100;
 Minibatch[1101-1200]: loss = 0.376538 * 100, metric = 5.05% * 100;
 Minibatch[1201-1300]: loss = 0.370346 * 100, metric = 5.05% * 100;
 Minibatch[1301-1400]: loss = 0.366569 * 100, metric = 5.00% * 100;
 Minibatch[1401-1500]: loss = 0.368751 * 100, metric = 5.11% * 100;
 Minibatch[1501-1600]: loss = 0.375718 * 100, metric = 5.34% * 100;
 Minibatch[1601-1700]: loss = 0.365045 * 100, metric = 5.05% * 100;
 Minibatch[1701-1800]: loss = 0.377449 * 100, metric = 5.12% * 100;
 Minibatch[1801-1900]: loss = 0.378864 * 100, metric = 5.11% * 100;
 Minibatch[1901-2000]: loss = 0.355690 * 100, metric = 4.68% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.374347 * 2000, metric = 5.11% * 2000 693.447s (  2.9 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 12.79% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
