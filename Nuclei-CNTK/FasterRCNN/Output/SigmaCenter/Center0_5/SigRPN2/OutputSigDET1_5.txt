Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.270222 * 100, metric = 26.12% * 100;
 Minibatch[ 101- 200]: loss = 1.057063 * 100, metric = 23.22% * 100;
 Minibatch[ 201- 300]: loss = 0.901531 * 100, metric = 22.20% * 100;
 Minibatch[ 301- 400]: loss = 0.866024 * 100, metric = 20.86% * 100;
 Minibatch[ 401- 500]: loss = 0.808847 * 100, metric = 20.44% * 100;
 Minibatch[ 501- 600]: loss = 0.788971 * 100, metric = 19.45% * 100;
 Minibatch[ 601- 700]: loss = 0.770114 * 100, metric = 18.82% * 100;
 Minibatch[ 701- 800]: loss = 0.721230 * 100, metric = 17.51% * 100;
 Minibatch[ 801- 900]: loss = 0.734131 * 100, metric = 17.91% * 100;
 Minibatch[ 901-1000]: loss = 0.740069 * 100, metric = 18.07% * 100;
 Minibatch[1001-1100]: loss = 0.731415 * 100, metric = 17.60% * 100;
 Minibatch[1101-1200]: loss = 0.702267 * 100, metric = 16.89% * 100;
 Minibatch[1201-1300]: loss = 0.709896 * 100, metric = 17.30% * 100;
 Minibatch[1301-1400]: loss = 0.673096 * 100, metric = 16.03% * 100;
 Minibatch[1401-1500]: loss = 0.690367 * 100, metric = 16.58% * 100;
 Minibatch[1501-1600]: loss = 0.671635 * 100, metric = 16.28% * 100;
 Minibatch[1601-1700]: loss = 0.655249 * 100, metric = 15.61% * 100;
 Minibatch[1701-1800]: loss = 0.661912 * 100, metric = 15.88% * 100;
 Minibatch[1801-1900]: loss = 0.660883 * 100, metric = 15.96% * 100;
 Minibatch[1901-2000]: loss = 0.635509 * 100, metric = 15.21% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.772521 * 2000, metric = 18.40% * 2000 1036.135s (  1.9 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 27.50% * 2000;
0.7633775990381837
 Minibatch[   1- 100]: loss = 0.637417 * 100, metric = 15.07% * 100;
 Minibatch[ 101- 200]: loss = 0.650505 * 100, metric = 15.90% * 100;
 Minibatch[ 201- 300]: loss = 0.638440 * 100, metric = 14.55% * 100;
 Minibatch[ 301- 400]: loss = 0.643035 * 100, metric = 15.23% * 100;
 Minibatch[ 401- 500]: loss = 0.631149 * 100, metric = 14.88% * 100;
 Minibatch[ 501- 600]: loss = 0.639641 * 100, metric = 14.77% * 100;
 Minibatch[ 601- 700]: loss = 0.606745 * 100, metric = 14.30% * 100;
 Minibatch[ 701- 800]: loss = 0.623411 * 100, metric = 15.04% * 100;
 Minibatch[ 801- 900]: loss = 0.612500 * 100, metric = 14.46% * 100;
 Minibatch[ 901-1000]: loss = 0.594061 * 100, metric = 14.06% * 100;
 Minibatch[1001-1100]: loss = 0.613126 * 100, metric = 14.48% * 100;
 Minibatch[1101-1200]: loss = 0.617491 * 100, metric = 14.66% * 100;
 Minibatch[1201-1300]: loss = 0.602927 * 100, metric = 14.27% * 100;
 Minibatch[1301-1400]: loss = 0.605612 * 100, metric = 14.38% * 100;
 Minibatch[1401-1500]: loss = 0.585348 * 100, metric = 13.64% * 100;
 Minibatch[1501-1600]: loss = 0.584773 * 100, metric = 13.69% * 100;
 Minibatch[1601-1700]: loss = 0.599978 * 100, metric = 14.19% * 100;
 Minibatch[1701-1800]: loss = 0.599220 * 100, metric = 14.33% * 100;
 Minibatch[1801-1900]: loss = 0.599854 * 100, metric = 14.16% * 100;
 Minibatch[1901-2000]: loss = 0.575258 * 100, metric = 13.44% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.613025 * 2000, metric = 14.47% * 2000 970.008s (  2.1 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 20.78% * 2000;
0.6477613557726145
 Minibatch[   1- 100]: loss = 0.591238 * 100, metric = 14.03% * 100;
 Minibatch[ 101- 200]: loss = 0.592800 * 100, metric = 14.03% * 100;
 Minibatch[ 201- 300]: loss = 0.574343 * 100, metric = 13.55% * 100;
 Minibatch[ 301- 400]: loss = 0.577648 * 100, metric = 13.80% * 100;
 Minibatch[ 401- 500]: loss = 0.590858 * 100, metric = 14.14% * 100;
 Minibatch[ 501- 600]: loss = 0.579789 * 100, metric = 13.70% * 100;
 Minibatch[ 601- 700]: loss = 0.577939 * 100, metric = 13.57% * 100;
 Minibatch[ 701- 800]: loss = 0.555176 * 100, metric = 12.86% * 100;
 Minibatch[ 801- 900]: loss = 0.566132 * 100, metric = 13.65% * 100;
 Minibatch[ 901-1000]: loss = 0.541783 * 100, metric = 13.01% * 100;
 Minibatch[1001-1100]: loss = 0.558790 * 100, metric = 13.50% * 100;
 Minibatch[1101-1200]: loss = 0.539957 * 100, metric = 12.77% * 100;
 Minibatch[1201-1300]: loss = 0.538826 * 100, metric = 12.74% * 100;
 Minibatch[1301-1400]: loss = 0.546221 * 100, metric = 12.86% * 100;
 Minibatch[1401-1500]: loss = 0.546825 * 100, metric = 12.95% * 100;
 Minibatch[1501-1600]: loss = 0.529002 * 100, metric = 12.52% * 100;
 Minibatch[1601-1700]: loss = 0.523647 * 100, metric = 12.17% * 100;
 Minibatch[1701-1800]: loss = 0.540065 * 100, metric = 12.68% * 100;
 Minibatch[1801-1900]: loss = 0.526360 * 100, metric = 12.23% * 100;
 Minibatch[1901-2000]: loss = 0.526675 * 100, metric = 12.37% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.556204 * 2000, metric = 13.16% * 2000 972.057s (  2.1 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 21.29% * 2000;
0.6352049989253282
 Minibatch[   1- 100]: loss = 0.536745 * 100, metric = 12.30% * 100;
 Minibatch[ 101- 200]: loss = 0.506852 * 100, metric = 11.71% * 100;
 Minibatch[ 201- 300]: loss = 0.534118 * 100, metric = 12.67% * 100;
 Minibatch[ 301- 400]: loss = 0.498602 * 100, metric = 11.70% * 100;
 Minibatch[ 401- 500]: loss = 0.529556 * 100, metric = 12.45% * 100;
 Minibatch[ 501- 600]: loss = 0.500600 * 100, metric = 11.63% * 100;
 Minibatch[ 601- 700]: loss = 0.503164 * 100, metric = 11.88% * 100;
 Minibatch[ 701- 800]: loss = 0.514636 * 100, metric = 12.12% * 100;
 Minibatch[ 801- 900]: loss = 0.518973 * 100, metric = 12.07% * 100;
 Minibatch[ 901-1000]: loss = 0.515873 * 100, metric = 12.31% * 100;
 Minibatch[1001-1100]: loss = 0.523051 * 100, metric = 12.44% * 100;
 Minibatch[1101-1200]: loss = 0.502706 * 100, metric = 11.86% * 100;
 Minibatch[1201-1300]: loss = 0.504909 * 100, metric = 11.84% * 100;
 Minibatch[1301-1400]: loss = 0.523419 * 100, metric = 12.35% * 100;
 Minibatch[1401-1500]: loss = 0.531317 * 100, metric = 12.73% * 100;
 Minibatch[1501-1600]: loss = 0.500633 * 100, metric = 11.63% * 100;
 Minibatch[1601-1700]: loss = 0.518350 * 100, metric = 12.30% * 100;
 Minibatch[1701-1800]: loss = 0.528121 * 100, metric = 12.53% * 100;
 Minibatch[1801-1900]: loss = 0.510217 * 100, metric = 11.94% * 100;
 Minibatch[1901-2000]: loss = 0.494847 * 100, metric = 11.53% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.514834 * 2000, metric = 12.10% * 2000 967.709s (  2.1 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 22.16% * 2000;
 Minibatch[   1- 100]: loss = 0.513287 * 100, metric = 12.02% * 100;
 Minibatch[ 101- 200]: loss = 0.499874 * 100, metric = 11.75% * 100;
 Minibatch[ 201- 300]: loss = 0.496276 * 100, metric = 11.55% * 100;
 Minibatch[ 301- 400]: loss = 0.508507 * 100, metric = 12.14% * 100;
 Minibatch[ 401- 500]: loss = 0.471909 * 100, metric = 10.97% * 100;
 Minibatch[ 501- 600]: loss = 0.480968 * 100, metric = 10.91% * 100;
 Minibatch[ 601- 700]: loss = 0.485511 * 100, metric = 11.15% * 100;
 Minibatch[ 701- 800]: loss = 0.492484 * 100, metric = 11.56% * 100;
 Minibatch[ 801- 900]: loss = 0.474507 * 100, metric = 10.77% * 100;
 Minibatch[ 901-1000]: loss = 0.479437 * 100, metric = 11.12% * 100;
 Minibatch[1001-1100]: loss = 0.486586 * 100, metric = 11.42% * 100;
 Minibatch[1101-1200]: loss = 0.475121 * 100, metric = 11.06% * 100;
 Minibatch[1201-1300]: loss = 0.489041 * 100, metric = 11.30% * 100;
 Minibatch[1301-1400]: loss = 0.495437 * 100, metric = 11.49% * 100;
 Minibatch[1401-1500]: loss = 0.487899 * 100, metric = 11.55% * 100;
 Minibatch[1501-1600]: loss = 0.492063 * 100, metric = 11.59% * 100;
 Minibatch[1601-1700]: loss = 0.498264 * 100, metric = 12.03% * 100;
 Minibatch[1701-1800]: loss = 0.495419 * 100, metric = 11.76% * 100;
 Minibatch[1801-1900]: loss = 0.488160 * 100, metric = 11.53% * 100;
 Minibatch[1901-2000]: loss = 0.468133 * 100, metric = 10.99% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.488944 * 2000, metric = 11.43% * 2000 960.745s (  2.1 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.56% * 2000;
0.612588083513081
 Minibatch[   1- 100]: loss = 0.472649 * 100, metric = 11.09% * 100;
 Minibatch[ 101- 200]: loss = 0.466151 * 100, metric = 11.12% * 100;
 Minibatch[ 201- 300]: loss = 0.480510 * 100, metric = 11.17% * 100;
 Minibatch[ 301- 400]: loss = 0.472048 * 100, metric = 10.86% * 100;
 Minibatch[ 401- 500]: loss = 0.449351 * 100, metric = 10.46% * 100;
 Minibatch[ 501- 600]: loss = 0.455709 * 100, metric = 10.48% * 100;
 Minibatch[ 601- 700]: loss = 0.460305 * 100, metric = 10.78% * 100;
 Minibatch[ 701- 800]: loss = 0.467345 * 100, metric = 11.09% * 100;
 Minibatch[ 801- 900]: loss = 0.467663 * 100, metric = 10.79% * 100;
 Minibatch[ 901-1000]: loss = 0.460638 * 100, metric = 10.69% * 100;
 Minibatch[1001-1100]: loss = 0.467544 * 100, metric = 10.61% * 100;
 Minibatch[1101-1200]: loss = 0.473242 * 100, metric = 11.09% * 100;
 Minibatch[1201-1300]: loss = 0.474738 * 100, metric = 11.04% * 100;
 Minibatch[1301-1400]: loss = 0.461351 * 100, metric = 10.73% * 100;
 Minibatch[1401-1500]: loss = 0.469997 * 100, metric = 11.10% * 100;
 Minibatch[1501-1600]: loss = 0.451628 * 100, metric = 10.38% * 100;
 Minibatch[1601-1700]: loss = 0.455449 * 100, metric = 10.35% * 100;
 Minibatch[1701-1800]: loss = 0.449845 * 100, metric = 10.50% * 100;
 Minibatch[1801-1900]: loss = 0.473561 * 100, metric = 11.08% * 100;
 Minibatch[1901-2000]: loss = 0.459211 * 100, metric = 10.72% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.464447 * 2000, metric = 10.81% * 2000 956.758s (  2.1 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.83% * 2000;
 Minibatch[   1- 100]: loss = 0.459361 * 100, metric = 10.65% * 100;
 Minibatch[ 101- 200]: loss = 0.459674 * 100, metric = 10.30% * 100;
 Minibatch[ 201- 300]: loss = 0.471432 * 100, metric = 10.90% * 100;
 Minibatch[ 301- 400]: loss = 0.451330 * 100, metric = 10.40% * 100;
 Minibatch[ 401- 500]: loss = 0.467400 * 100, metric = 10.84% * 100;
 Minibatch[ 501- 600]: loss = 0.445921 * 100, metric = 10.37% * 100;
 Minibatch[ 601- 700]: loss = 0.455343 * 100, metric = 10.36% * 100;
 Minibatch[ 701- 800]: loss = 0.461519 * 100, metric = 10.47% * 100;
 Minibatch[ 801- 900]: loss = 0.470853 * 100, metric = 11.08% * 100;
 Minibatch[ 901-1000]: loss = 0.451996 * 100, metric = 10.30% * 100;
 Minibatch[1001-1100]: loss = 0.468175 * 100, metric = 11.03% * 100;
 Minibatch[1101-1200]: loss = 0.444622 * 100, metric = 10.17% * 100;
 Minibatch[1201-1300]: loss = 0.457394 * 100, metric = 10.59% * 100;
 Minibatch[1301-1400]: loss = 0.446665 * 100, metric = 10.45% * 100;
 Minibatch[1401-1500]: loss = 0.435405 * 100, metric = 10.10% * 100;
 Minibatch[1501-1600]: loss = 0.454875 * 100, metric = 10.58% * 100;
 Minibatch[1601-1700]: loss = 0.453193 * 100, metric = 10.51% * 100;
 Minibatch[1701-1800]: loss = 0.445412 * 100, metric = 10.12% * 100;
 Minibatch[1801-1900]: loss = 0.452552 * 100, metric = 10.71% * 100;
 Minibatch[1901-2000]: loss = 0.448096 * 100, metric = 10.51% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.455061 * 2000, metric = 10.52% * 2000 950.785s (  2.1 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 17.94% * 2000;
0.5585563604161143
 Minibatch[   1- 100]: loss = 0.454909 * 100, metric = 10.53% * 100;
 Minibatch[ 101- 200]: loss = 0.442446 * 100, metric = 10.45% * 100;
 Minibatch[ 201- 300]: loss = 0.431149 * 100, metric = 10.01% * 100;
 Minibatch[ 301- 400]: loss = 0.441999 * 100, metric = 10.52% * 100;
 Minibatch[ 401- 500]: loss = 0.451285 * 100, metric = 10.60% * 100;
 Minibatch[ 501- 600]: loss = 0.457304 * 100, metric = 11.02% * 100;
 Minibatch[ 601- 700]: loss = 0.427055 * 100, metric = 9.95% * 100;
 Minibatch[ 701- 800]: loss = 0.444246 * 100, metric = 10.04% * 100;
 Minibatch[ 801- 900]: loss = 0.422600 * 100, metric = 9.48% * 100;
 Minibatch[ 901-1000]: loss = 0.415973 * 100, metric = 9.32% * 100;
 Minibatch[1001-1100]: loss = 0.425005 * 100, metric = 9.71% * 100;
 Minibatch[1101-1200]: loss = 0.423270 * 100, metric = 9.74% * 100;
 Minibatch[1201-1300]: loss = 0.439865 * 100, metric = 10.12% * 100;
 Minibatch[1301-1400]: loss = 0.445210 * 100, metric = 10.18% * 100;
 Minibatch[1401-1500]: loss = 0.428937 * 100, metric = 9.82% * 100;
 Minibatch[1501-1600]: loss = 0.435087 * 100, metric = 10.04% * 100;
 Minibatch[1601-1700]: loss = 0.435864 * 100, metric = 9.89% * 100;
 Minibatch[1701-1800]: loss = 0.432438 * 100, metric = 9.76% * 100;
 Minibatch[1801-1900]: loss = 0.426253 * 100, metric = 9.52% * 100;
 Minibatch[1901-2000]: loss = 0.435874 * 100, metric = 10.02% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.435838 * 2000, metric = 10.03% * 2000 944.491s (  2.1 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 17.38% * 2000;
0.5401529670357704
 Minibatch[   1- 100]: loss = 0.412102 * 100, metric = 9.40% * 100;
 Minibatch[ 101- 200]: loss = 0.445851 * 100, metric = 10.38% * 100;
 Minibatch[ 201- 300]: loss = 0.436652 * 100, metric = 9.84% * 100;
 Minibatch[ 301- 400]: loss = 0.449973 * 100, metric = 10.30% * 100;
 Minibatch[ 401- 500]: loss = 0.439209 * 100, metric = 9.92% * 100;
 Minibatch[ 501- 600]: loss = 0.433840 * 100, metric = 10.02% * 100;
 Minibatch[ 601- 700]: loss = 0.434804 * 100, metric = 10.06% * 100;
 Minibatch[ 701- 800]: loss = 0.424390 * 100, metric = 9.72% * 100;
 Minibatch[ 801- 900]: loss = 0.421589 * 100, metric = 9.59% * 100;
 Minibatch[ 901-1000]: loss = 0.443624 * 100, metric = 10.38% * 100;
 Minibatch[1001-1100]: loss = 0.408390 * 100, metric = 9.17% * 100;
 Minibatch[1101-1200]: loss = 0.427618 * 100, metric = 9.87% * 100;
 Minibatch[1201-1300]: loss = 0.417462 * 100, metric = 9.61% * 100;
 Minibatch[1301-1400]: loss = 0.417904 * 100, metric = 9.42% * 100;
 Minibatch[1401-1500]: loss = 0.440109 * 100, metric = 10.27% * 100;
 Minibatch[1501-1600]: loss = 0.444794 * 100, metric = 10.07% * 100;
 Minibatch[1601-1700]: loss = 0.425901 * 100, metric = 9.86% * 100;
 Minibatch[1701-1800]: loss = 0.421929 * 100, metric = 9.36% * 100;
 Minibatch[1801-1900]: loss = 0.427760 * 100, metric = 9.82% * 100;
 Minibatch[1901-2000]: loss = 0.436393 * 100, metric = 10.06% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.430515 * 2000, metric = 9.86% * 2000 936.515s (  2.1 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 16.58% * 2000;
0.5372801412045956
 Minibatch[   1- 100]: loss = 0.448706 * 100, metric = 10.55% * 100;
 Minibatch[ 101- 200]: loss = 0.425568 * 100, metric = 9.73% * 100;
 Minibatch[ 201- 300]: loss = 0.429641 * 100, metric = 9.95% * 100;
 Minibatch[ 301- 400]: loss = 0.418510 * 100, metric = 9.47% * 100;
 Minibatch[ 401- 500]: loss = 0.438047 * 100, metric = 10.13% * 100;
 Minibatch[ 501- 600]: loss = 0.420963 * 100, metric = 9.67% * 100;
 Minibatch[ 601- 700]: loss = 0.415578 * 100, metric = 9.39% * 100;
 Minibatch[ 701- 800]: loss = 0.403562 * 100, metric = 8.74% * 100;
 Minibatch[ 801- 900]: loss = 0.419282 * 100, metric = 9.56% * 100;
 Minibatch[ 901-1000]: loss = 0.425792 * 100, metric = 9.71% * 100;
 Minibatch[1001-1100]: loss = 0.423141 * 100, metric = 9.79% * 100;
 Minibatch[1101-1200]: loss = 0.429190 * 100, metric = 9.66% * 100;
 Minibatch[1201-1300]: loss = 0.421813 * 100, metric = 9.72% * 100;
 Minibatch[1301-1400]: loss = 0.421044 * 100, metric = 9.48% * 100;
 Minibatch[1401-1500]: loss = 0.413433 * 100, metric = 9.28% * 100;
 Minibatch[1501-1600]: loss = 0.424928 * 100, metric = 9.70% * 100;
 Minibatch[1601-1700]: loss = 0.415613 * 100, metric = 9.18% * 100;
 Minibatch[1701-1800]: loss = 0.434172 * 100, metric = 9.75% * 100;
 Minibatch[1801-1900]: loss = 0.432780 * 100, metric = 9.95% * 100;
 Minibatch[1901-2000]: loss = 0.414139 * 100, metric = 9.49% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.423795 * 2000, metric = 9.65% * 2000 937.932s (  2.1 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 16.65% * 2000;
0.5351754441969097
 Minibatch[   1- 100]: loss = 0.406379 * 100, metric = 8.92% * 100;
 Minibatch[ 101- 200]: loss = 0.419888 * 100, metric = 9.46% * 100;
 Minibatch[ 201- 300]: loss = 0.423544 * 100, metric = 9.55% * 100;
 Minibatch[ 301- 400]: loss = 0.419431 * 100, metric = 9.48% * 100;
 Minibatch[ 401- 500]: loss = 0.408992 * 100, metric = 9.27% * 100;
 Minibatch[ 501- 600]: loss = 0.425048 * 100, metric = 9.67% * 100;
 Minibatch[ 601- 700]: loss = 0.415096 * 100, metric = 9.32% * 100;
 Minibatch[ 701- 800]: loss = 0.417939 * 100, metric = 9.67% * 100;
 Minibatch[ 801- 900]: loss = 0.418094 * 100, metric = 9.30% * 100;
 Minibatch[ 901-1000]: loss = 0.416424 * 100, metric = 9.38% * 100;
 Minibatch[1001-1100]: loss = 0.418408 * 100, metric = 9.43% * 100;
 Minibatch[1101-1200]: loss = 0.424238 * 100, metric = 9.69% * 100;
 Minibatch[1201-1300]: loss = 0.409998 * 100, metric = 9.18% * 100;
 Minibatch[1301-1400]: loss = 0.396527 * 100, metric = 9.02% * 100;
 Minibatch[1401-1500]: loss = 0.410643 * 100, metric = 9.38% * 100;
 Minibatch[1501-1600]: loss = 0.406265 * 100, metric = 9.22% * 100;
 Minibatch[1601-1700]: loss = 0.398767 * 100, metric = 8.91% * 100;
 Minibatch[1701-1800]: loss = 0.416397 * 100, metric = 9.49% * 100;
 Minibatch[1801-1900]: loss = 0.407773 * 100, metric = 9.13% * 100;
 Minibatch[1901-2000]: loss = 0.408973 * 100, metric = 9.42% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.413441 * 2000, metric = 9.34% * 2000 935.073s (  2.1 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 16.02% * 2000;
0.506570333853364
 Minibatch[   1- 100]: loss = 0.390674 * 100, metric = 8.88% * 100;
 Minibatch[ 101- 200]: loss = 0.389214 * 100, metric = 8.69% * 100;
 Minibatch[ 201- 300]: loss = 0.397117 * 100, metric = 9.05% * 100;
 Minibatch[ 301- 400]: loss = 0.428608 * 100, metric = 9.84% * 100;
 Minibatch[ 401- 500]: loss = 0.399069 * 100, metric = 8.67% * 100;
 Minibatch[ 501- 600]: loss = 0.389645 * 100, metric = 8.63% * 100;
 Minibatch[ 601- 700]: loss = 0.387621 * 100, metric = 8.74% * 100;
 Minibatch[ 701- 800]: loss = 0.399232 * 100, metric = 9.13% * 100;
 Minibatch[ 801- 900]: loss = 0.396698 * 100, metric = 8.92% * 100;
 Minibatch[ 901-1000]: loss = 0.406702 * 100, metric = 9.32% * 100;
 Minibatch[1001-1100]: loss = 0.409077 * 100, metric = 9.49% * 100;
 Minibatch[1101-1200]: loss = 0.402602 * 100, metric = 8.88% * 100;
 Minibatch[1201-1300]: loss = 0.407454 * 100, metric = 9.45% * 100;
 Minibatch[1301-1400]: loss = 0.388909 * 100, metric = 8.76% * 100;
 Minibatch[1401-1500]: loss = 0.404680 * 100, metric = 9.33% * 100;
 Minibatch[1501-1600]: loss = 0.376653 * 100, metric = 8.37% * 100;
 Minibatch[1601-1700]: loss = 0.396778 * 100, metric = 9.02% * 100;
 Minibatch[1701-1800]: loss = 0.383449 * 100, metric = 8.52% * 100;
 Minibatch[1801-1900]: loss = 0.392992 * 100, metric = 8.73% * 100;
 Minibatch[1901-2000]: loss = 0.397362 * 100, metric = 9.03% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.397227 * 2000, metric = 8.97% * 2000 928.645s (  2.2 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 16.50% * 2000;
 Minibatch[   1- 100]: loss = 0.397103 * 100, metric = 8.90% * 100;
 Minibatch[ 101- 200]: loss = 0.392185 * 100, metric = 8.85% * 100;
 Minibatch[ 201- 300]: loss = 0.390676 * 100, metric = 8.93% * 100;
 Minibatch[ 301- 400]: loss = 0.391001 * 100, metric = 8.80% * 100;
 Minibatch[ 401- 500]: loss = 0.390832 * 100, metric = 9.13% * 100;
 Minibatch[ 501- 600]: loss = 0.401492 * 100, metric = 9.15% * 100;
 Minibatch[ 601- 700]: loss = 0.381137 * 100, metric = 8.35% * 100;
 Minibatch[ 701- 800]: loss = 0.390173 * 100, metric = 8.66% * 100;
 Minibatch[ 801- 900]: loss = 0.389645 * 100, metric = 8.71% * 100;
 Minibatch[ 901-1000]: loss = 0.401313 * 100, metric = 9.06% * 100;
 Minibatch[1001-1100]: loss = 0.400030 * 100, metric = 9.02% * 100;
 Minibatch[1101-1200]: loss = 0.393289 * 100, metric = 8.90% * 100;
 Minibatch[1201-1300]: loss = 0.401249 * 100, metric = 9.12% * 100;
 Minibatch[1301-1400]: loss = 0.388595 * 100, metric = 8.89% * 100;
 Minibatch[1401-1500]: loss = 0.388282 * 100, metric = 8.81% * 100;
 Minibatch[1501-1600]: loss = 0.379783 * 100, metric = 8.41% * 100;
 Minibatch[1601-1700]: loss = 0.383949 * 100, metric = 8.59% * 100;
 Minibatch[1701-1800]: loss = 0.385177 * 100, metric = 8.46% * 100;
 Minibatch[1801-1900]: loss = 0.370167 * 100, metric = 8.42% * 100;
 Minibatch[1901-2000]: loss = 0.387462 * 100, metric = 8.85% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.390177 * 2000, metric = 8.80% * 2000 918.547s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 17.69% * 2000;
 Minibatch[   1- 100]: loss = 0.377685 * 100, metric = 8.38% * 100;
 Minibatch[ 101- 200]: loss = 0.380060 * 100, metric = 8.23% * 100;
 Minibatch[ 201- 300]: loss = 0.382517 * 100, metric = 8.58% * 100;
 Minibatch[ 301- 400]: loss = 0.386300 * 100, metric = 8.64% * 100;
 Minibatch[ 401- 500]: loss = 0.374816 * 100, metric = 8.36% * 100;
 Minibatch[ 501- 600]: loss = 0.383241 * 100, metric = 8.73% * 100;
 Minibatch[ 601- 700]: loss = 0.385989 * 100, metric = 8.62% * 100;
 Minibatch[ 701- 800]: loss = 0.402733 * 100, metric = 9.12% * 100;
 Minibatch[ 801- 900]: loss = 0.398714 * 100, metric = 9.01% * 100;
 Minibatch[ 901-1000]: loss = 0.397573 * 100, metric = 9.05% * 100;
 Minibatch[1001-1100]: loss = 0.394004 * 100, metric = 9.01% * 100;
 Minibatch[1101-1200]: loss = 0.388180 * 100, metric = 8.76% * 100;
 Minibatch[1201-1300]: loss = 0.372263 * 100, metric = 8.31% * 100;
 Minibatch[1301-1400]: loss = 0.386709 * 100, metric = 8.86% * 100;
 Minibatch[1401-1500]: loss = 0.380231 * 100, metric = 8.57% * 100;
 Minibatch[1501-1600]: loss = 0.369281 * 100, metric = 8.55% * 100;
 Minibatch[1601-1700]: loss = 0.382178 * 100, metric = 8.65% * 100;
 Minibatch[1701-1800]: loss = 0.381357 * 100, metric = 8.49% * 100;
 Minibatch[1801-1900]: loss = 0.379711 * 100, metric = 8.49% * 100;
 Minibatch[1901-2000]: loss = 0.381542 * 100, metric = 8.40% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.384254 * 2000, metric = 8.64% * 2000 921.830s (  2.2 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 16.63% * 2000;
 Minibatch[   1- 100]: loss = 0.373531 * 100, metric = 8.39% * 100;
 Minibatch[ 101- 200]: loss = 0.384161 * 100, metric = 8.65% * 100;
 Minibatch[ 201- 300]: loss = 0.378102 * 100, metric = 8.33% * 100;
 Minibatch[ 301- 400]: loss = 0.364304 * 100, metric = 8.09% * 100;
 Minibatch[ 401- 500]: loss = 0.374453 * 100, metric = 8.34% * 100;
 Minibatch[ 501- 600]: loss = 0.362584 * 100, metric = 7.92% * 100;
 Minibatch[ 601- 700]: loss = 0.354182 * 100, metric = 7.77% * 100;
 Minibatch[ 701- 800]: loss = 0.379051 * 100, metric = 8.64% * 100;
 Minibatch[ 801- 900]: loss = 0.379850 * 100, metric = 8.74% * 100;
 Minibatch[ 901-1000]: loss = 0.365842 * 100, metric = 8.08% * 100;
 Minibatch[1001-1100]: loss = 0.369745 * 100, metric = 8.26% * 100;
 Minibatch[1101-1200]: loss = 0.371865 * 100, metric = 8.24% * 100;
 Minibatch[1201-1300]: loss = 0.354927 * 100, metric = 7.69% * 100;
 Minibatch[1301-1400]: loss = 0.385083 * 100, metric = 8.79% * 100;
 Minibatch[1401-1500]: loss = 0.345014 * 100, metric = 7.54% * 100;
 Minibatch[1501-1600]: loss = 0.360073 * 100, metric = 7.95% * 100;
 Minibatch[1601-1700]: loss = 0.370154 * 100, metric = 8.30% * 100;
 Minibatch[1701-1800]: loss = 0.351738 * 100, metric = 7.73% * 100;
 Minibatch[1801-1900]: loss = 0.362227 * 100, metric = 8.08% * 100;
 Minibatch[1901-2000]: loss = 0.358414 * 100, metric = 8.06% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.367265 * 2000, metric = 8.18% * 2000 923.386s (  2.2 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 14.88% * 2000;
 Minibatch[   1- 100]: loss = 0.377359 * 100, metric = 8.57% * 100;
 Minibatch[ 101- 200]: loss = 0.369002 * 100, metric = 8.04% * 100;
 Minibatch[ 201- 300]: loss = 0.359500 * 100, metric = 8.04% * 100;
 Minibatch[ 301- 400]: loss = 0.362825 * 100, metric = 7.96% * 100;
 Minibatch[ 401- 500]: loss = 0.341146 * 100, metric = 7.46% * 100;
 Minibatch[ 501- 600]: loss = 0.360005 * 100, metric = 7.90% * 100;
 Minibatch[ 601- 700]: loss = 0.360427 * 100, metric = 7.98% * 100;
 Minibatch[ 701- 800]: loss = 0.348271 * 100, metric = 7.60% * 100;
 Minibatch[ 801- 900]: loss = 0.349875 * 100, metric = 7.78% * 100;
 Minibatch[ 901-1000]: loss = 0.364682 * 100, metric = 8.31% * 100;
 Minibatch[1001-1100]: loss = 0.344366 * 100, metric = 7.40% * 100;
 Minibatch[1101-1200]: loss = 0.349030 * 100, metric = 7.75% * 100;
 Minibatch[1201-1300]: loss = 0.341444 * 100, metric = 7.46% * 100;
 Minibatch[1301-1400]: loss = 0.349643 * 100, metric = 7.81% * 100;
 Minibatch[1401-1500]: loss = 0.352572 * 100, metric = 8.05% * 100;
 Minibatch[1501-1600]: loss = 0.355630 * 100, metric = 8.11% * 100;
 Minibatch[1601-1700]: loss = 0.359739 * 100, metric = 8.03% * 100;
 Minibatch[1701-1800]: loss = 0.363599 * 100, metric = 7.98% * 100;
 Minibatch[1801-1900]: loss = 0.360290 * 100, metric = 8.09% * 100;
 Minibatch[1901-2000]: loss = 0.352709 * 100, metric = 8.04% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.356106 * 2000, metric = 7.92% * 2000 917.673s (  2.2 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.68% * 2000;
0.49743111024424436
 Minibatch[   1- 100]: loss = 0.346716 * 100, metric = 7.66% * 100;
 Minibatch[ 101- 200]: loss = 0.361883 * 100, metric = 8.11% * 100;
 Minibatch[ 201- 300]: loss = 0.358300 * 100, metric = 8.03% * 100;
 Minibatch[ 301- 400]: loss = 0.354534 * 100, metric = 7.94% * 100;
 Minibatch[ 401- 500]: loss = 0.358434 * 100, metric = 7.87% * 100;
 Minibatch[ 501- 600]: loss = 0.351029 * 100, metric = 7.66% * 100;
 Minibatch[ 601- 700]: loss = 0.328672 * 100, metric = 7.08% * 100;
 Minibatch[ 701- 800]: loss = 0.347058 * 100, metric = 7.47% * 100;
 Minibatch[ 801- 900]: loss = 0.346982 * 100, metric = 7.50% * 100;
 Minibatch[ 901-1000]: loss = 0.346740 * 100, metric = 7.63% * 100;
 Minibatch[1001-1100]: loss = 0.337864 * 100, metric = 7.29% * 100;
 Minibatch[1101-1200]: loss = 0.353776 * 100, metric = 7.98% * 100;
 Minibatch[1201-1300]: loss = 0.350491 * 100, metric = 7.80% * 100;
 Minibatch[1301-1400]: loss = 0.335758 * 100, metric = 7.41% * 100;
 Minibatch[1401-1500]: loss = 0.350841 * 100, metric = 7.82% * 100;
 Minibatch[1501-1600]: loss = 0.340540 * 100, metric = 7.41% * 100;
 Minibatch[1601-1700]: loss = 0.342866 * 100, metric = 7.47% * 100;
 Minibatch[1701-1800]: loss = 0.336251 * 100, metric = 7.48% * 100;
 Minibatch[1801-1900]: loss = 0.356181 * 100, metric = 8.09% * 100;
 Minibatch[1901-2000]: loss = 0.364905 * 100, metric = 8.13% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.348491 * 2000, metric = 7.69% * 2000 914.013s (  2.2 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.65% * 2000;
 Minibatch[   1- 100]: loss = 0.335072 * 100, metric = 7.43% * 100;
 Minibatch[ 101- 200]: loss = 0.352571 * 100, metric = 7.78% * 100;
 Minibatch[ 201- 300]: loss = 0.330063 * 100, metric = 7.26% * 100;
 Minibatch[ 301- 400]: loss = 0.345057 * 100, metric = 7.53% * 100;
 Minibatch[ 401- 500]: loss = 0.330306 * 100, metric = 7.16% * 100;
 Minibatch[ 501- 600]: loss = 0.336971 * 100, metric = 7.35% * 100;
 Minibatch[ 601- 700]: loss = 0.342322 * 100, metric = 7.56% * 100;
 Minibatch[ 701- 800]: loss = 0.328946 * 100, metric = 7.29% * 100;
 Minibatch[ 801- 900]: loss = 0.338058 * 100, metric = 7.34% * 100;
 Minibatch[ 901-1000]: loss = 0.338737 * 100, metric = 7.52% * 100;
 Minibatch[1001-1100]: loss = 0.344352 * 100, metric = 7.64% * 100;
 Minibatch[1101-1200]: loss = 0.336279 * 100, metric = 7.39% * 100;
 Minibatch[1201-1300]: loss = 0.346840 * 100, metric = 7.76% * 100;
 Minibatch[1301-1400]: loss = 0.354682 * 100, metric = 7.87% * 100;
 Minibatch[1401-1500]: loss = 0.322882 * 100, metric = 6.98% * 100;
 Minibatch[1501-1600]: loss = 0.341008 * 100, metric = 7.38% * 100;
 Minibatch[1601-1700]: loss = 0.323579 * 100, metric = 6.99% * 100;
 Minibatch[1701-1800]: loss = 0.329674 * 100, metric = 7.09% * 100;
 Minibatch[1801-1900]: loss = 0.328228 * 100, metric = 7.40% * 100;
 Minibatch[1901-2000]: loss = 0.330070 * 100, metric = 7.08% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.336785 * 2000, metric = 7.39% * 2000 895.657s (  2.2 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.50% * 2000;
 Minibatch[   1- 100]: loss = 0.343020 * 100, metric = 7.74% * 100;
 Minibatch[ 101- 200]: loss = 0.348599 * 100, metric = 7.47% * 100;
 Minibatch[ 201- 300]: loss = 0.324231 * 100, metric = 7.11% * 100;
 Minibatch[ 301- 400]: loss = 0.339665 * 100, metric = 7.40% * 100;
 Minibatch[ 401- 500]: loss = 0.338938 * 100, metric = 7.30% * 100;
 Minibatch[ 501- 600]: loss = 0.327449 * 100, metric = 7.00% * 100;
 Minibatch[ 601- 700]: loss = 0.341913 * 100, metric = 7.53% * 100;
 Minibatch[ 701- 800]: loss = 0.323640 * 100, metric = 7.03% * 100;
 Minibatch[ 801- 900]: loss = 0.362549 * 100, metric = 8.09% * 100;
 Minibatch[ 901-1000]: loss = 0.328517 * 100, metric = 7.09% * 100;
 Minibatch[1001-1100]: loss = 0.346703 * 100, metric = 7.65% * 100;
 Minibatch[1101-1200]: loss = 0.341066 * 100, metric = 7.57% * 100;
 Minibatch[1201-1300]: loss = 0.338524 * 100, metric = 7.41% * 100;
 Minibatch[1301-1400]: loss = 0.332605 * 100, metric = 7.42% * 100;
 Minibatch[1401-1500]: loss = 0.339844 * 100, metric = 7.63% * 100;
 Minibatch[1501-1600]: loss = 0.341117 * 100, metric = 7.70% * 100;
 Minibatch[1601-1700]: loss = 0.335157 * 100, metric = 7.52% * 100;
 Minibatch[1701-1800]: loss = 0.325161 * 100, metric = 7.13% * 100;
 Minibatch[1801-1900]: loss = 0.324399 * 100, metric = 7.09% * 100;
 Minibatch[1901-2000]: loss = 0.326756 * 100, metric = 6.99% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.336493 * 2000, metric = 7.39% * 2000 905.684s (  2.2 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 14.86% * 2000;
 Minibatch[   1- 100]: loss = 0.328929 * 100, metric = 7.08% * 100;
 Minibatch[ 101- 200]: loss = 0.336015 * 100, metric = 7.22% * 100;
 Minibatch[ 201- 300]: loss = 0.326029 * 100, metric = 7.04% * 100;
 Minibatch[ 301- 400]: loss = 0.342463 * 100, metric = 7.28% * 100;
 Minibatch[ 401- 500]: loss = 0.325569 * 100, metric = 7.06% * 100;
 Minibatch[ 501- 600]: loss = 0.334639 * 100, metric = 7.57% * 100;
 Minibatch[ 601- 700]: loss = 0.341469 * 100, metric = 7.73% * 100;
 Minibatch[ 701- 800]: loss = 0.332359 * 100, metric = 7.33% * 100;
 Minibatch[ 801- 900]: loss = 0.337390 * 100, metric = 7.54% * 100;
 Minibatch[ 901-1000]: loss = 0.347599 * 100, metric = 7.45% * 100;
 Minibatch[1001-1100]: loss = 0.325361 * 100, metric = 6.98% * 100;
 Minibatch[1101-1200]: loss = 0.336159 * 100, metric = 7.45% * 100;
 Minibatch[1201-1300]: loss = 0.338897 * 100, metric = 7.47% * 100;
 Minibatch[1301-1400]: loss = 0.339122 * 100, metric = 7.56% * 100;
 Minibatch[1401-1500]: loss = 0.327084 * 100, metric = 7.44% * 100;
 Minibatch[1501-1600]: loss = 0.347896 * 100, metric = 7.53% * 100;
 Minibatch[1601-1700]: loss = 0.331359 * 100, metric = 7.34% * 100;
 Minibatch[1701-1800]: loss = 0.343204 * 100, metric = 7.64% * 100;
 Minibatch[1801-1900]: loss = 0.337848 * 100, metric = 7.48% * 100;
 Minibatch[1901-2000]: loss = 0.331813 * 100, metric = 7.43% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.335560 * 2000, metric = 7.38% * 2000 903.309s (  2.2 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 15.52% * 2000;
 Minibatch[   1- 100]: loss = 0.334203 * 100, metric = 7.26% * 100;
 Minibatch[ 101- 200]: loss = 0.333442 * 100, metric = 7.27% * 100;
 Minibatch[ 201- 300]: loss = 0.333260 * 100, metric = 7.32% * 100;
 Minibatch[ 301- 400]: loss = 0.336593 * 100, metric = 7.53% * 100;
 Minibatch[ 401- 500]: loss = 0.330194 * 100, metric = 7.36% * 100;
 Minibatch[ 501- 600]: loss = 0.326226 * 100, metric = 7.11% * 100;
 Minibatch[ 601- 700]: loss = 0.332022 * 100, metric = 7.35% * 100;
 Minibatch[ 701- 800]: loss = 0.304605 * 100, metric = 6.57% * 100;
 Minibatch[ 801- 900]: loss = 0.330268 * 100, metric = 7.25% * 100;
 Minibatch[ 901-1000]: loss = 0.318661 * 100, metric = 6.84% * 100;
 Minibatch[1001-1100]: loss = 0.323037 * 100, metric = 6.89% * 100;
 Minibatch[1101-1200]: loss = 0.318340 * 100, metric = 6.97% * 100;
 Minibatch[1201-1300]: loss = 0.325255 * 100, metric = 7.10% * 100;
 Minibatch[1301-1400]: loss = 0.312792 * 100, metric = 6.75% * 100;
 Minibatch[1401-1500]: loss = 0.326085 * 100, metric = 7.02% * 100;
 Minibatch[1501-1600]: loss = 0.335368 * 100, metric = 7.68% * 100;
 Minibatch[1601-1700]: loss = 0.318339 * 100, metric = 7.15% * 100;
 Minibatch[1701-1800]: loss = 0.319947 * 100, metric = 7.12% * 100;
 Minibatch[1801-1900]: loss = 0.335413 * 100, metric = 7.65% * 100;
 Minibatch[1901-2000]: loss = 0.315249 * 100, metric = 6.80% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.325465 * 2000, metric = 7.15% * 2000 900.723s (  2.2 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 14.23% * 2000;
 Minibatch[   1- 100]: loss = 0.329092 * 100, metric = 7.29% * 100;
 Minibatch[ 101- 200]: loss = 0.326157 * 100, metric = 7.21% * 100;
 Minibatch[ 201- 300]: loss = 0.329787 * 100, metric = 7.26% * 100;
 Minibatch[ 301- 400]: loss = 0.319880 * 100, metric = 7.25% * 100;
 Minibatch[ 401- 500]: loss = 0.316032 * 100, metric = 7.07% * 100;
 Minibatch[ 501- 600]: loss = 0.332116 * 100, metric = 7.16% * 100;
 Minibatch[ 601- 700]: loss = 0.319433 * 100, metric = 6.95% * 100;
 Minibatch[ 701- 800]: loss = 0.317328 * 100, metric = 7.00% * 100;
 Minibatch[ 801- 900]: loss = 0.329899 * 100, metric = 7.40% * 100;
 Minibatch[ 901-1000]: loss = 0.330883 * 100, metric = 7.23% * 100;
 Minibatch[1001-1100]: loss = 0.317136 * 100, metric = 6.79% * 100;
 Minibatch[1101-1200]: loss = 0.297599 * 100, metric = 6.51% * 100;
 Minibatch[1201-1300]: loss = 0.316677 * 100, metric = 6.72% * 100;
 Minibatch[1301-1400]: loss = 0.317950 * 100, metric = 7.04% * 100;
 Minibatch[1401-1500]: loss = 0.313329 * 100, metric = 7.02% * 100;
 Minibatch[1501-1600]: loss = 0.310216 * 100, metric = 7.04% * 100;
 Minibatch[1601-1700]: loss = 0.320544 * 100, metric = 7.04% * 100;
 Minibatch[1701-1800]: loss = 0.317458 * 100, metric = 6.92% * 100;
 Minibatch[1801-1900]: loss = 0.318304 * 100, metric = 7.06% * 100;
 Minibatch[1901-2000]: loss = 0.319581 * 100, metric = 6.82% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.319970 * 2000, metric = 7.04% * 2000 893.205s (  2.2 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 14.53% * 2000;
 Minibatch[   1- 100]: loss = 0.327732 * 100, metric = 7.14% * 100;
 Minibatch[ 101- 200]: loss = 0.325480 * 100, metric = 7.19% * 100;
 Minibatch[ 201- 300]: loss = 0.316483 * 100, metric = 6.76% * 100;
 Minibatch[ 301- 400]: loss = 0.323230 * 100, metric = 7.01% * 100;
 Minibatch[ 401- 500]: loss = 0.326698 * 100, metric = 7.28% * 100;
 Minibatch[ 501- 600]: loss = 0.330739 * 100, metric = 7.25% * 100;
 Minibatch[ 601- 700]: loss = 0.315873 * 100, metric = 6.97% * 100;
 Minibatch[ 701- 800]: loss = 0.308754 * 100, metric = 6.61% * 100;
 Minibatch[ 801- 900]: loss = 0.310531 * 100, metric = 6.94% * 100;
 Minibatch[ 901-1000]: loss = 0.319327 * 100, metric = 6.88% * 100;
 Minibatch[1001-1100]: loss = 0.312042 * 100, metric = 6.62% * 100;
 Minibatch[1101-1200]: loss = 0.314739 * 100, metric = 6.93% * 100;
 Minibatch[1201-1300]: loss = 0.315443 * 100, metric = 6.82% * 100;
 Minibatch[1301-1400]: loss = 0.320339 * 100, metric = 7.29% * 100;
 Minibatch[1401-1500]: loss = 0.304691 * 100, metric = 6.69% * 100;
 Minibatch[1501-1600]: loss = 0.310348 * 100, metric = 6.69% * 100;
 Minibatch[1601-1700]: loss = 0.305175 * 100, metric = 6.71% * 100;
 Minibatch[1701-1800]: loss = 0.313257 * 100, metric = 7.01% * 100;
 Minibatch[1801-1900]: loss = 0.321662 * 100, metric = 7.16% * 100;
 Minibatch[1901-2000]: loss = 0.323602 * 100, metric = 7.12% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.317307 * 2000, metric = 6.95% * 2000 909.681s (  2.2 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 14.70% * 2000;
 Minibatch[   1- 100]: loss = 0.299055 * 100, metric = 6.72% * 100;
 Minibatch[ 101- 200]: loss = 0.316288 * 100, metric = 6.87% * 100;
 Minibatch[ 201- 300]: loss = 0.306813 * 100, metric = 6.64% * 100;
 Minibatch[ 301- 400]: loss = 0.304471 * 100, metric = 6.70% * 100;
 Minibatch[ 401- 500]: loss = 0.305028 * 100, metric = 6.55% * 100;
 Minibatch[ 501- 600]: loss = 0.302933 * 100, metric = 6.68% * 100;
 Minibatch[ 601- 700]: loss = 0.316533 * 100, metric = 6.72% * 100;
 Minibatch[ 701- 800]: loss = 0.304913 * 100, metric = 6.79% * 100;
 Minibatch[ 801- 900]: loss = 0.318236 * 100, metric = 7.11% * 100;
 Minibatch[ 901-1000]: loss = 0.312594 * 100, metric = 6.83% * 100;
 Minibatch[1001-1100]: loss = 0.314604 * 100, metric = 6.74% * 100;
 Minibatch[1101-1200]: loss = 0.328948 * 100, metric = 7.37% * 100;
 Minibatch[1201-1300]: loss = 0.312265 * 100, metric = 6.70% * 100;
 Minibatch[1301-1400]: loss = 0.300129 * 100, metric = 6.44% * 100;
 Minibatch[1401-1500]: loss = 0.298614 * 100, metric = 6.30% * 100;
 Minibatch[1501-1600]: loss = 0.308729 * 100, metric = 6.82% * 100;
 Minibatch[1601-1700]: loss = 0.300590 * 100, metric = 6.48% * 100;
 Minibatch[1701-1800]: loss = 0.304647 * 100, metric = 6.67% * 100;
 Minibatch[1801-1900]: loss = 0.310355 * 100, metric = 7.03% * 100;
 Minibatch[1901-2000]: loss = 0.315204 * 100, metric = 6.94% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.309047 * 2000, metric = 6.75% * 2000 895.925s (  2.2 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.55% * 2000;
 Minibatch[   1- 100]: loss = 0.314201 * 100, metric = 6.80% * 100;
 Minibatch[ 101- 200]: loss = 0.313610 * 100, metric = 6.98% * 100;
 Minibatch[ 201- 300]: loss = 0.312311 * 100, metric = 7.04% * 100;
 Minibatch[ 301- 400]: loss = 0.313681 * 100, metric = 6.86% * 100;
 Minibatch[ 401- 500]: loss = 0.310564 * 100, metric = 6.74% * 100;
 Minibatch[ 501- 600]: loss = 0.310806 * 100, metric = 6.84% * 100;
 Minibatch[ 601- 700]: loss = 0.309820 * 100, metric = 6.81% * 100;
 Minibatch[ 701- 800]: loss = 0.295647 * 100, metric = 6.32% * 100;
 Minibatch[ 801- 900]: loss = 0.306076 * 100, metric = 6.75% * 100;
 Minibatch[ 901-1000]: loss = 0.309497 * 100, metric = 6.85% * 100;
 Minibatch[1001-1100]: loss = 0.313188 * 100, metric = 6.92% * 100;
 Minibatch[1101-1200]: loss = 0.315610 * 100, metric = 6.94% * 100;
 Minibatch[1201-1300]: loss = 0.324295 * 100, metric = 7.35% * 100;
 Minibatch[1301-1400]: loss = 0.309266 * 100, metric = 6.78% * 100;
 Minibatch[1401-1500]: loss = 0.295615 * 100, metric = 6.23% * 100;
 Minibatch[1501-1600]: loss = 0.311996 * 100, metric = 6.91% * 100;
 Minibatch[1601-1700]: loss = 0.301528 * 100, metric = 6.62% * 100;
 Minibatch[1701-1800]: loss = 0.305135 * 100, metric = 6.79% * 100;
 Minibatch[1801-1900]: loss = 0.298940 * 100, metric = 6.50% * 100;
 Minibatch[1901-2000]: loss = 0.291290 * 100, metric = 6.22% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.308154 * 2000, metric = 6.76% * 2000 897.221s (  2.2 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 13.93% * 2000;
 Minibatch[   1- 100]: loss = 0.301195 * 100, metric = 6.56% * 100;
 Minibatch[ 101- 200]: loss = 0.291492 * 100, metric = 6.21% * 100;
 Minibatch[ 201- 300]: loss = 0.301544 * 100, metric = 6.81% * 100;
 Minibatch[ 301- 400]: loss = 0.287727 * 100, metric = 6.29% * 100;
 Minibatch[ 401- 500]: loss = 0.300410 * 100, metric = 6.38% * 100;
 Minibatch[ 501- 600]: loss = 0.295584 * 100, metric = 6.31% * 100;
 Minibatch[ 601- 700]: loss = 0.306315 * 100, metric = 6.48% * 100;
 Minibatch[ 701- 800]: loss = 0.289485 * 100, metric = 6.39% * 100;
 Minibatch[ 801- 900]: loss = 0.289272 * 100, metric = 6.36% * 100;
 Minibatch[ 901-1000]: loss = 0.297748 * 100, metric = 6.42% * 100;
 Minibatch[1001-1100]: loss = 0.305928 * 100, metric = 6.80% * 100;
 Minibatch[1101-1200]: loss = 0.306023 * 100, metric = 6.59% * 100;
 Minibatch[1201-1300]: loss = 0.295084 * 100, metric = 6.40% * 100;
 Minibatch[1301-1400]: loss = 0.284633 * 100, metric = 6.06% * 100;
 Minibatch[1401-1500]: loss = 0.301143 * 100, metric = 6.54% * 100;
 Minibatch[1501-1600]: loss = 0.293052 * 100, metric = 6.13% * 100;
 Minibatch[1601-1700]: loss = 0.315330 * 100, metric = 6.83% * 100;
 Minibatch[1701-1800]: loss = 0.309321 * 100, metric = 6.70% * 100;
 Minibatch[1801-1900]: loss = 0.300373 * 100, metric = 6.44% * 100;
 Minibatch[1901-2000]: loss = 0.300555 * 100, metric = 6.51% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.298611 * 2000, metric = 6.46% * 2000 887.545s (  2.3 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 14.96% * 2000;
 Minibatch[   1- 100]: loss = 0.299174 * 100, metric = 6.29% * 100;
 Minibatch[ 101- 200]: loss = 0.307957 * 100, metric = 6.53% * 100;
 Minibatch[ 201- 300]: loss = 0.300715 * 100, metric = 6.61% * 100;
 Minibatch[ 301- 400]: loss = 0.297842 * 100, metric = 6.45% * 100;
 Minibatch[ 401- 500]: loss = 0.296139 * 100, metric = 6.26% * 100;
 Minibatch[ 501- 600]: loss = 0.294107 * 100, metric = 6.41% * 100;
 Minibatch[ 601- 700]: loss = 0.287772 * 100, metric = 6.26% * 100;
 Minibatch[ 701- 800]: loss = 0.291794 * 100, metric = 6.32% * 100;
 Minibatch[ 801- 900]: loss = 0.299609 * 100, metric = 6.43% * 100;
 Minibatch[ 901-1000]: loss = 0.299919 * 100, metric = 6.52% * 100;
 Minibatch[1001-1100]: loss = 0.295241 * 100, metric = 6.30% * 100;
 Minibatch[1101-1200]: loss = 0.302012 * 100, metric = 6.52% * 100;
 Minibatch[1201-1300]: loss = 0.297559 * 100, metric = 6.44% * 100;
 Minibatch[1301-1400]: loss = 0.302505 * 100, metric = 6.73% * 100;
 Minibatch[1401-1500]: loss = 0.290988 * 100, metric = 6.19% * 100;
 Minibatch[1501-1600]: loss = 0.298763 * 100, metric = 6.55% * 100;
 Minibatch[1601-1700]: loss = 0.278521 * 100, metric = 5.95% * 100;
 Minibatch[1701-1800]: loss = 0.282627 * 100, metric = 5.98% * 100;
 Minibatch[1801-1900]: loss = 0.287379 * 100, metric = 6.26% * 100;
 Minibatch[1901-2000]: loss = 0.296741 * 100, metric = 6.42% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.295368 * 2000, metric = 6.37% * 2000 888.603s (  2.3 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.87% * 2000;
 Minibatch[   1- 100]: loss = 0.297306 * 100, metric = 6.60% * 100;
 Minibatch[ 101- 200]: loss = 0.281527 * 100, metric = 5.93% * 100;
 Minibatch[ 201- 300]: loss = 0.297637 * 100, metric = 6.28% * 100;
 Minibatch[ 301- 400]: loss = 0.293579 * 100, metric = 6.23% * 100;
 Minibatch[ 401- 500]: loss = 0.292464 * 100, metric = 6.21% * 100;
 Minibatch[ 501- 600]: loss = 0.302942 * 100, metric = 6.76% * 100;
 Minibatch[ 601- 700]: loss = 0.286332 * 100, metric = 6.06% * 100;
 Minibatch[ 701- 800]: loss = 0.275264 * 100, metric = 5.98% * 100;
 Minibatch[ 801- 900]: loss = 0.295231 * 100, metric = 6.35% * 100;
 Minibatch[ 901-1000]: loss = 0.306147 * 100, metric = 6.71% * 100;
 Minibatch[1001-1100]: loss = 0.296857 * 100, metric = 6.46% * 100;
 Minibatch[1101-1200]: loss = 0.283066 * 100, metric = 5.92% * 100;
 Minibatch[1201-1300]: loss = 0.293687 * 100, metric = 6.38% * 100;
 Minibatch[1301-1400]: loss = 0.283412 * 100, metric = 6.11% * 100;
 Minibatch[1401-1500]: loss = 0.300209 * 100, metric = 6.50% * 100;
 Minibatch[1501-1600]: loss = 0.293095 * 100, metric = 6.31% * 100;
 Minibatch[1601-1700]: loss = 0.293709 * 100, metric = 6.11% * 100;
 Minibatch[1701-1800]: loss = 0.287532 * 100, metric = 6.19% * 100;
 Minibatch[1801-1900]: loss = 0.295141 * 100, metric = 6.50% * 100;
 Minibatch[1901-2000]: loss = 0.289630 * 100, metric = 6.25% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.292238 * 2000, metric = 6.29% * 2000 891.031s (  2.2 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.45% * 2000;
 Minibatch[   1- 100]: loss = 0.285453 * 100, metric = 6.13% * 100;
 Minibatch[ 101- 200]: loss = 0.288605 * 100, metric = 6.37% * 100;
 Minibatch[ 201- 300]: loss = 0.287185 * 100, metric = 6.45% * 100;
 Minibatch[ 301- 400]: loss = 0.304745 * 100, metric = 6.62% * 100;
 Minibatch[ 401- 500]: loss = 0.276810 * 100, metric = 5.92% * 100;
 Minibatch[ 501- 600]: loss = 0.292119 * 100, metric = 6.34% * 100;
 Minibatch[ 601- 700]: loss = 0.284221 * 100, metric = 6.31% * 100;
 Minibatch[ 701- 800]: loss = 0.291840 * 100, metric = 6.26% * 100;
 Minibatch[ 801- 900]: loss = 0.284838 * 100, metric = 6.27% * 100;
 Minibatch[ 901-1000]: loss = 0.295026 * 100, metric = 6.39% * 100;
 Minibatch[1001-1100]: loss = 0.282072 * 100, metric = 6.33% * 100;
 Minibatch[1101-1200]: loss = 0.276166 * 100, metric = 5.98% * 100;
 Minibatch[1201-1300]: loss = 0.284326 * 100, metric = 6.19% * 100;
 Minibatch[1301-1400]: loss = 0.273809 * 100, metric = 5.81% * 100;
 Minibatch[1401-1500]: loss = 0.290905 * 100, metric = 6.28% * 100;
 Minibatch[1501-1600]: loss = 0.277198 * 100, metric = 5.98% * 100;
 Minibatch[1601-1700]: loss = 0.290472 * 100, metric = 6.23% * 100;
 Minibatch[1701-1800]: loss = 0.272997 * 100, metric = 5.65% * 100;
 Minibatch[1801-1900]: loss = 0.295623 * 100, metric = 6.56% * 100;
 Minibatch[1901-2000]: loss = 0.282152 * 100, metric = 6.07% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.285828 * 2000, metric = 6.21% * 2000 892.844s (  2.2 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 15.02% * 2000;
 Minibatch[   1- 100]: loss = 0.293952 * 100, metric = 6.29% * 100;
 Minibatch[ 101- 200]: loss = 0.269460 * 100, metric = 5.55% * 100;
 Minibatch[ 201- 300]: loss = 0.276057 * 100, metric = 5.95% * 100;
 Minibatch[ 301- 400]: loss = 0.292189 * 100, metric = 6.41% * 100;
 Minibatch[ 401- 500]: loss = 0.284698 * 100, metric = 6.16% * 100;
 Minibatch[ 501- 600]: loss = 0.267422 * 100, metric = 5.68% * 100;
 Minibatch[ 601- 700]: loss = 0.282404 * 100, metric = 6.13% * 100;
 Minibatch[ 701- 800]: loss = 0.277522 * 100, metric = 5.79% * 100;
 Minibatch[ 801- 900]: loss = 0.287279 * 100, metric = 6.19% * 100;
 Minibatch[ 901-1000]: loss = 0.269090 * 100, metric = 5.83% * 100;
 Minibatch[1001-1100]: loss = 0.281212 * 100, metric = 5.87% * 100;
 Minibatch[1101-1200]: loss = 0.293734 * 100, metric = 6.38% * 100;
 Minibatch[1201-1300]: loss = 0.274657 * 100, metric = 5.90% * 100;
 Minibatch[1301-1400]: loss = 0.279799 * 100, metric = 6.01% * 100;
 Minibatch[1401-1500]: loss = 0.285522 * 100, metric = 6.17% * 100;
 Minibatch[1501-1600]: loss = 0.293564 * 100, metric = 6.46% * 100;
 Minibatch[1601-1700]: loss = 0.290533 * 100, metric = 6.24% * 100;
 Minibatch[1701-1800]: loss = 0.288817 * 100, metric = 6.35% * 100;
 Minibatch[1801-1900]: loss = 0.285081 * 100, metric = 6.24% * 100;
 Minibatch[1901-2000]: loss = 0.293193 * 100, metric = 6.38% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.283309 * 2000, metric = 6.10% * 2000 888.150s (  2.3 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.34% * 2000;
 Minibatch[   1- 100]: loss = 0.282697 * 100, metric = 6.08% * 100;
 Minibatch[ 101- 200]: loss = 0.292017 * 100, metric = 6.44% * 100;
 Minibatch[ 201- 300]: loss = 0.280396 * 100, metric = 6.00% * 100;
 Minibatch[ 301- 400]: loss = 0.281134 * 100, metric = 6.03% * 100;
 Minibatch[ 401- 500]: loss = 0.280938 * 100, metric = 6.05% * 100;
 Minibatch[ 501- 600]: loss = 0.278667 * 100, metric = 6.07% * 100;
 Minibatch[ 601- 700]: loss = 0.293166 * 100, metric = 6.40% * 100;
 Minibatch[ 701- 800]: loss = 0.284727 * 100, metric = 6.13% * 100;
 Minibatch[ 801- 900]: loss = 0.280295 * 100, metric = 6.10% * 100;
 Minibatch[ 901-1000]: loss = 0.274291 * 100, metric = 5.92% * 100;
 Minibatch[1001-1100]: loss = 0.274077 * 100, metric = 5.95% * 100;
 Minibatch[1101-1200]: loss = 0.277527 * 100, metric = 6.12% * 100;
 Minibatch[1201-1300]: loss = 0.279201 * 100, metric = 6.06% * 100;
 Minibatch[1301-1400]: loss = 0.281178 * 100, metric = 6.03% * 100;
 Minibatch[1401-1500]: loss = 0.285717 * 100, metric = 6.03% * 100;
 Minibatch[1501-1600]: loss = 0.269400 * 100, metric = 5.89% * 100;
 Minibatch[1601-1700]: loss = 0.276335 * 100, metric = 6.11% * 100;
 Minibatch[1701-1800]: loss = 0.268048 * 100, metric = 5.70% * 100;
 Minibatch[1801-1900]: loss = 0.284257 * 100, metric = 6.18% * 100;
 Minibatch[1901-2000]: loss = 0.278210 * 100, metric = 5.92% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.280114 * 2000, metric = 6.06% * 2000 895.301s (  2.2 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 13.79% * 2000;
 Minibatch[   1- 100]: loss = 0.276462 * 100, metric = 6.04% * 100;
 Minibatch[ 101- 200]: loss = 0.281939 * 100, metric = 5.98% * 100;
 Minibatch[ 201- 300]: loss = 0.284457 * 100, metric = 6.09% * 100;
 Minibatch[ 301- 400]: loss = 0.284640 * 100, metric = 6.11% * 100;
 Minibatch[ 401- 500]: loss = 0.279706 * 100, metric = 6.23% * 100;
 Minibatch[ 501- 600]: loss = 0.277341 * 100, metric = 6.05% * 100;
 Minibatch[ 601- 700]: loss = 0.270758 * 100, metric = 5.78% * 100;
 Minibatch[ 701- 800]: loss = 0.272730 * 100, metric = 5.84% * 100;
 Minibatch[ 801- 900]: loss = 0.269991 * 100, metric = 5.83% * 100;
 Minibatch[ 901-1000]: loss = 0.260332 * 100, metric = 5.51% * 100;
 Minibatch[1001-1100]: loss = 0.265544 * 100, metric = 5.57% * 100;
 Minibatch[1101-1200]: loss = 0.273650 * 100, metric = 5.87% * 100;
 Minibatch[1201-1300]: loss = 0.283961 * 100, metric = 6.34% * 100;
 Minibatch[1301-1400]: loss = 0.275083 * 100, metric = 6.06% * 100;
 Minibatch[1401-1500]: loss = 0.278683 * 100, metric = 6.32% * 100;
 Minibatch[1501-1600]: loss = 0.276892 * 100, metric = 6.17% * 100;
 Minibatch[1601-1700]: loss = 0.269152 * 100, metric = 5.67% * 100;
 Minibatch[1701-1800]: loss = 0.285796 * 100, metric = 6.28% * 100;
 Minibatch[1801-1900]: loss = 0.267623 * 100, metric = 5.75% * 100;
 Minibatch[1901-2000]: loss = 0.276436 * 100, metric = 6.24% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.275559 * 2000, metric = 5.99% * 2000 874.460s (  2.3 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.41% * 2000;
 Minibatch[   1- 100]: loss = 0.285549 * 100, metric = 6.35% * 100;
 Minibatch[ 101- 200]: loss = 0.272781 * 100, metric = 6.02% * 100;
 Minibatch[ 201- 300]: loss = 0.266629 * 100, metric = 5.71% * 100;
 Minibatch[ 301- 400]: loss = 0.282203 * 100, metric = 6.12% * 100;
 Minibatch[ 401- 500]: loss = 0.269789 * 100, metric = 5.82% * 100;
 Minibatch[ 501- 600]: loss = 0.277016 * 100, metric = 6.04% * 100;
 Minibatch[ 601- 700]: loss = 0.281220 * 100, metric = 6.22% * 100;
 Minibatch[ 701- 800]: loss = 0.275047 * 100, metric = 6.01% * 100;
 Minibatch[ 801- 900]: loss = 0.272515 * 100, metric = 5.81% * 100;
 Minibatch[ 901-1000]: loss = 0.262776 * 100, metric = 5.68% * 100;
 Minibatch[1001-1100]: loss = 0.267554 * 100, metric = 5.78% * 100;
 Minibatch[1101-1200]: loss = 0.257146 * 100, metric = 5.57% * 100;
 Minibatch[1201-1300]: loss = 0.281431 * 100, metric = 5.97% * 100;
 Minibatch[1301-1400]: loss = 0.263560 * 100, metric = 5.63% * 100;
 Minibatch[1401-1500]: loss = 0.286920 * 100, metric = 6.08% * 100;
 Minibatch[1501-1600]: loss = 0.278092 * 100, metric = 6.02% * 100;
 Minibatch[1601-1700]: loss = 0.270545 * 100, metric = 5.74% * 100;
 Minibatch[1701-1800]: loss = 0.264259 * 100, metric = 5.63% * 100;
 Minibatch[1801-1900]: loss = 0.259073 * 100, metric = 5.51% * 100;
 Minibatch[1901-2000]: loss = 0.280610 * 100, metric = 6.24% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.272736 * 2000, metric = 5.90% * 2000 875.314s (  2.3 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.06% * 2000;
0.4899970542229712
 Minibatch[   1- 100]: loss = 0.263769 * 100, metric = 5.53% * 100;
 Minibatch[ 101- 200]: loss = 0.274065 * 100, metric = 6.09% * 100;
 Minibatch[ 201- 300]: loss = 0.268102 * 100, metric = 5.88% * 100;
 Minibatch[ 301- 400]: loss = 0.274835 * 100, metric = 6.10% * 100;
 Minibatch[ 401- 500]: loss = 0.263820 * 100, metric = 5.71% * 100;
 Minibatch[ 501- 600]: loss = 0.264077 * 100, metric = 5.64% * 100;
 Minibatch[ 601- 700]: loss = 0.271433 * 100, metric = 5.91% * 100;
 Minibatch[ 701- 800]: loss = 0.270962 * 100, metric = 5.87% * 100;
 Minibatch[ 801- 900]: loss = 0.260004 * 100, metric = 5.42% * 100;
 Minibatch[ 901-1000]: loss = 0.259774 * 100, metric = 5.78% * 100;
 Minibatch[1001-1100]: loss = 0.271686 * 100, metric = 5.94% * 100;
 Minibatch[1101-1200]: loss = 0.263850 * 100, metric = 5.79% * 100;
 Minibatch[1201-1300]: loss = 0.270127 * 100, metric = 5.88% * 100;
 Minibatch[1301-1400]: loss = 0.271818 * 100, metric = 5.97% * 100;
 Minibatch[1401-1500]: loss = 0.276434 * 100, metric = 6.06% * 100;
 Minibatch[1501-1600]: loss = 0.271719 * 100, metric = 5.89% * 100;
 Minibatch[1601-1700]: loss = 0.281072 * 100, metric = 6.35% * 100;
 Minibatch[1701-1800]: loss = 0.268862 * 100, metric = 5.85% * 100;
 Minibatch[1801-1900]: loss = 0.269889 * 100, metric = 6.01% * 100;
 Minibatch[1901-2000]: loss = 0.269485 * 100, metric = 5.79% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.269289 * 2000, metric = 5.87% * 2000 889.724s (  2.2 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.42% * 2000;
 Minibatch[   1- 100]: loss = 0.254294 * 100, metric = 5.45% * 100;
 Minibatch[ 101- 200]: loss = 0.268167 * 100, metric = 5.92% * 100;
 Minibatch[ 201- 300]: loss = 0.266885 * 100, metric = 5.67% * 100;
 Minibatch[ 301- 400]: loss = 0.256440 * 100, metric = 5.50% * 100;
 Minibatch[ 401- 500]: loss = 0.266485 * 100, metric = 5.89% * 100;
 Minibatch[ 501- 600]: loss = 0.251645 * 100, metric = 5.38% * 100;
 Minibatch[ 601- 700]: loss = 0.268319 * 100, metric = 5.80% * 100;
 Minibatch[ 701- 800]: loss = 0.252754 * 100, metric = 5.41% * 100;
 Minibatch[ 801- 900]: loss = 0.265702 * 100, metric = 5.69% * 100;
 Minibatch[ 901-1000]: loss = 0.255567 * 100, metric = 5.49% * 100;
 Minibatch[1001-1100]: loss = 0.272322 * 100, metric = 5.87% * 100;
 Minibatch[1101-1200]: loss = 0.262214 * 100, metric = 5.60% * 100;
 Minibatch[1201-1300]: loss = 0.261332 * 100, metric = 5.71% * 100;
 Minibatch[1301-1400]: loss = 0.266590 * 100, metric = 5.88% * 100;
 Minibatch[1401-1500]: loss = 0.262712 * 100, metric = 5.55% * 100;
 Minibatch[1501-1600]: loss = 0.269744 * 100, metric = 6.06% * 100;
 Minibatch[1601-1700]: loss = 0.262141 * 100, metric = 5.80% * 100;
 Minibatch[1701-1800]: loss = 0.260066 * 100, metric = 5.62% * 100;
 Minibatch[1801-1900]: loss = 0.268497 * 100, metric = 5.70% * 100;
 Minibatch[1901-2000]: loss = 0.254793 * 100, metric = 5.36% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.262333 * 2000, metric = 5.67% * 2000 882.310s (  2.3 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.38% * 2000;
 Minibatch[   1- 100]: loss = 0.257264 * 100, metric = 5.47% * 100;
 Minibatch[ 101- 200]: loss = 0.250702 * 100, metric = 5.46% * 100;
 Minibatch[ 201- 300]: loss = 0.278344 * 100, metric = 6.16% * 100;
 Minibatch[ 301- 400]: loss = 0.257036 * 100, metric = 5.64% * 100;
 Minibatch[ 401- 500]: loss = 0.253632 * 100, metric = 5.39% * 100;
 Minibatch[ 501- 600]: loss = 0.263572 * 100, metric = 5.70% * 100;
 Minibatch[ 601- 700]: loss = 0.275136 * 100, metric = 5.72% * 100;
 Minibatch[ 701- 800]: loss = 0.245289 * 100, metric = 5.17% * 100;
 Minibatch[ 801- 900]: loss = 0.254405 * 100, metric = 5.48% * 100;
 Minibatch[ 901-1000]: loss = 0.268614 * 100, metric = 5.99% * 100;
 Minibatch[1001-1100]: loss = 0.272185 * 100, metric = 5.83% * 100;
 Minibatch[1101-1200]: loss = 0.252874 * 100, metric = 5.57% * 100;
 Minibatch[1201-1300]: loss = 0.263898 * 100, metric = 5.72% * 100;
 Minibatch[1301-1400]: loss = 0.243161 * 100, metric = 5.26% * 100;
 Minibatch[1401-1500]: loss = 0.251420 * 100, metric = 5.22% * 100;
 Minibatch[1501-1600]: loss = 0.251820 * 100, metric = 5.44% * 100;
 Minibatch[1601-1700]: loss = 0.265664 * 100, metric = 5.74% * 100;
 Minibatch[1701-1800]: loss = 0.256822 * 100, metric = 5.56% * 100;
 Minibatch[1801-1900]: loss = 0.251462 * 100, metric = 5.21% * 100;
 Minibatch[1901-2000]: loss = 0.253170 * 100, metric = 5.26% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.258324 * 2000, metric = 5.55% * 2000 876.063s (  2.3 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.64% * 2000;
 Minibatch[   1- 100]: loss = 0.253333 * 100, metric = 5.52% * 100;
 Minibatch[ 101- 200]: loss = 0.262335 * 100, metric = 5.63% * 100;
 Minibatch[ 201- 300]: loss = 0.256669 * 100, metric = 5.55% * 100;
 Minibatch[ 301- 400]: loss = 0.257058 * 100, metric = 5.42% * 100;
 Minibatch[ 401- 500]: loss = 0.253062 * 100, metric = 5.57% * 100;
 Minibatch[ 501- 600]: loss = 0.245647 * 100, metric = 5.34% * 100;
 Minibatch[ 601- 700]: loss = 0.252507 * 100, metric = 5.37% * 100;
 Minibatch[ 701- 800]: loss = 0.265955 * 100, metric = 5.88% * 100;
 Minibatch[ 801- 900]: loss = 0.258883 * 100, metric = 5.61% * 100;
 Minibatch[ 901-1000]: loss = 0.246219 * 100, metric = 5.22% * 100;
 Minibatch[1001-1100]: loss = 0.252340 * 100, metric = 5.39% * 100;
 Minibatch[1101-1200]: loss = 0.270441 * 100, metric = 6.00% * 100;
 Minibatch[1201-1300]: loss = 0.268144 * 100, metric = 5.76% * 100;
 Minibatch[1301-1400]: loss = 0.256173 * 100, metric = 5.36% * 100;
 Minibatch[1401-1500]: loss = 0.254224 * 100, metric = 5.43% * 100;
 Minibatch[1501-1600]: loss = 0.255533 * 100, metric = 5.37% * 100;
 Minibatch[1601-1700]: loss = 0.259685 * 100, metric = 5.69% * 100;
 Minibatch[1701-1800]: loss = 0.251683 * 100, metric = 5.24% * 100;
 Minibatch[1801-1900]: loss = 0.256847 * 100, metric = 5.68% * 100;
 Minibatch[1901-2000]: loss = 0.256696 * 100, metric = 5.54% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.256672 * 2000, metric = 5.53% * 2000 886.635s (  2.3 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.95% * 2000;
 Minibatch[   1- 100]: loss = 0.266422 * 100, metric = 5.83% * 100;
 Minibatch[ 101- 200]: loss = 0.261456 * 100, metric = 5.74% * 100;
 Minibatch[ 201- 300]: loss = 0.240909 * 100, metric = 4.97% * 100;
 Minibatch[ 301- 400]: loss = 0.244329 * 100, metric = 5.22% * 100;
 Minibatch[ 401- 500]: loss = 0.256739 * 100, metric = 5.42% * 100;
 Minibatch[ 501- 600]: loss = 0.250131 * 100, metric = 5.24% * 100;
 Minibatch[ 601- 700]: loss = 0.259629 * 100, metric = 5.71% * 100;
 Minibatch[ 701- 800]: loss = 0.256536 * 100, metric = 5.48% * 100;
 Minibatch[ 801- 900]: loss = 0.258288 * 100, metric = 5.55% * 100;
 Minibatch[ 901-1000]: loss = 0.255567 * 100, metric = 5.24% * 100;
 Minibatch[1001-1100]: loss = 0.262895 * 100, metric = 5.62% * 100;
 Minibatch[1101-1200]: loss = 0.243947 * 100, metric = 5.16% * 100;
 Minibatch[1201-1300]: loss = 0.249725 * 100, metric = 5.33% * 100;
 Minibatch[1301-1400]: loss = 0.264516 * 100, metric = 5.71% * 100;
 Minibatch[1401-1500]: loss = 0.259948 * 100, metric = 5.54% * 100;
 Minibatch[1501-1600]: loss = 0.255509 * 100, metric = 5.49% * 100;
 Minibatch[1601-1700]: loss = 0.246041 * 100, metric = 5.24% * 100;
 Minibatch[1701-1800]: loss = 0.255923 * 100, metric = 5.54% * 100;
 Minibatch[1801-1900]: loss = 0.253388 * 100, metric = 5.45% * 100;
 Minibatch[1901-2000]: loss = 0.249477 * 100, metric = 5.38% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.254569 * 2000, metric = 5.44% * 2000 884.360s (  2.3 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 12.80% * 2000;
 Minibatch[   1- 100]: loss = 0.247990 * 100, metric = 5.38% * 100;
 Minibatch[ 101- 200]: loss = 0.256270 * 100, metric = 5.46% * 100;
 Minibatch[ 201- 300]: loss = 0.246649 * 100, metric = 5.15% * 100;
 Minibatch[ 301- 400]: loss = 0.243866 * 100, metric = 5.19% * 100;
 Minibatch[ 401- 500]: loss = 0.253949 * 100, metric = 5.57% * 100;
 Minibatch[ 501- 600]: loss = 0.257881 * 100, metric = 5.43% * 100;
 Minibatch[ 601- 700]: loss = 0.251485 * 100, metric = 5.46% * 100;
 Minibatch[ 701- 800]: loss = 0.252267 * 100, metric = 5.49% * 100;
 Minibatch[ 801- 900]: loss = 0.241582 * 100, metric = 5.13% * 100;
 Minibatch[ 901-1000]: loss = 0.248413 * 100, metric = 5.15% * 100;
 Minibatch[1001-1100]: loss = 0.261233 * 100, metric = 5.77% * 100;
 Minibatch[1101-1200]: loss = 0.257628 * 100, metric = 5.54% * 100;
 Minibatch[1201-1300]: loss = 0.254020 * 100, metric = 5.39% * 100;
 Minibatch[1301-1400]: loss = 0.261270 * 100, metric = 5.59% * 100;
 Minibatch[1401-1500]: loss = 0.257120 * 100, metric = 5.70% * 100;
 Minibatch[1501-1600]: loss = 0.252287 * 100, metric = 5.37% * 100;
 Minibatch[1601-1700]: loss = 0.251516 * 100, metric = 5.37% * 100;
 Minibatch[1701-1800]: loss = 0.258447 * 100, metric = 5.58% * 100;
 Minibatch[1801-1900]: loss = 0.250324 * 100, metric = 5.34% * 100;
 Minibatch[1901-2000]: loss = 0.251946 * 100, metric = 5.28% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.252807 * 2000, metric = 5.42% * 2000 889.928s (  2.2 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.17% * 2000;
 Minibatch[   1- 100]: loss = 0.249580 * 100, metric = 5.40% * 100;
 Minibatch[ 101- 200]: loss = 0.241852 * 100, metric = 5.10% * 100;
 Minibatch[ 201- 300]: loss = 0.256791 * 100, metric = 5.44% * 100;
 Minibatch[ 301- 400]: loss = 0.251889 * 100, metric = 5.40% * 100;
 Minibatch[ 401- 500]: loss = 0.256512 * 100, metric = 5.53% * 100;
 Minibatch[ 501- 600]: loss = 0.252786 * 100, metric = 5.47% * 100;
 Minibatch[ 601- 700]: loss = 0.264133 * 100, metric = 5.63% * 100;
 Minibatch[ 701- 800]: loss = 0.246415 * 100, metric = 5.27% * 100;
 Minibatch[ 801- 900]: loss = 0.248086 * 100, metric = 5.36% * 100;
 Minibatch[ 901-1000]: loss = 0.252393 * 100, metric = 5.34% * 100;
 Minibatch[1001-1100]: loss = 0.265131 * 100, metric = 5.83% * 100;
 Minibatch[1101-1200]: loss = 0.254009 * 100, metric = 5.40% * 100;
 Minibatch[1201-1300]: loss = 0.249680 * 100, metric = 5.40% * 100;
 Minibatch[1301-1400]: loss = 0.247242 * 100, metric = 5.28% * 100;
 Minibatch[1401-1500]: loss = 0.249544 * 100, metric = 5.38% * 100;
 Minibatch[1501-1600]: loss = 0.256079 * 100, metric = 5.54% * 100;
 Minibatch[1601-1700]: loss = 0.250694 * 100, metric = 5.26% * 100;
 Minibatch[1701-1800]: loss = 0.243768 * 100, metric = 5.25% * 100;
 Minibatch[1801-1900]: loss = 0.247392 * 100, metric = 5.21% * 100;
 Minibatch[1901-2000]: loss = 0.255406 * 100, metric = 5.54% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.251969 * 2000, metric = 5.40% * 2000 884.034s (  2.3 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 13.30% * 2000;
 Minibatch[   1- 100]: loss = 0.249102 * 100, metric = 5.33% * 100;
 Minibatch[ 101- 200]: loss = 0.251464 * 100, metric = 5.37% * 100;
 Minibatch[ 201- 300]: loss = 0.257253 * 100, metric = 5.65% * 100;
 Minibatch[ 301- 400]: loss = 0.254937 * 100, metric = 5.50% * 100;
 Minibatch[ 401- 500]: loss = 0.247056 * 100, metric = 5.45% * 100;
 Minibatch[ 501- 600]: loss = 0.241970 * 100, metric = 5.05% * 100;
 Minibatch[ 601- 700]: loss = 0.247650 * 100, metric = 5.22% * 100;
 Minibatch[ 701- 800]: loss = 0.248164 * 100, metric = 5.36% * 100;
 Minibatch[ 801- 900]: loss = 0.249317 * 100, metric = 5.44% * 100;
 Minibatch[ 901-1000]: loss = 0.251729 * 100, metric = 5.48% * 100;
 Minibatch[1001-1100]: loss = 0.250649 * 100, metric = 5.31% * 100;
 Minibatch[1101-1200]: loss = 0.259729 * 100, metric = 5.55% * 100;
 Minibatch[1201-1300]: loss = 0.251726 * 100, metric = 5.17% * 100;
 Minibatch[1301-1400]: loss = 0.239643 * 100, metric = 5.12% * 100;
 Minibatch[1401-1500]: loss = 0.242890 * 100, metric = 5.11% * 100;
 Minibatch[1501-1600]: loss = 0.253454 * 100, metric = 5.30% * 100;
 Minibatch[1601-1700]: loss = 0.253254 * 100, metric = 5.41% * 100;
 Minibatch[1701-1800]: loss = 0.248813 * 100, metric = 5.40% * 100;
 Minibatch[1801-1900]: loss = 0.240125 * 100, metric = 5.08% * 100;
 Minibatch[1901-2000]: loss = 0.236578 * 100, metric = 4.96% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.248775 * 2000, metric = 5.31% * 2000 887.868s (  2.3 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 13.75% * 2000;
 Minibatch[   1- 100]: loss = 0.243765 * 100, metric = 5.09% * 100;
 Minibatch[ 101- 200]: loss = 0.250500 * 100, metric = 5.44% * 100;
 Minibatch[ 201- 300]: loss = 0.251651 * 100, metric = 5.32% * 100;
 Minibatch[ 301- 400]: loss = 0.243287 * 100, metric = 5.11% * 100;
 Minibatch[ 401- 500]: loss = 0.248013 * 100, metric = 5.11% * 100;
 Minibatch[ 501- 600]: loss = 0.245018 * 100, metric = 5.10% * 100;
 Minibatch[ 601- 700]: loss = 0.247833 * 100, metric = 5.40% * 100;
 Minibatch[ 701- 800]: loss = 0.243614 * 100, metric = 5.04% * 100;
 Minibatch[ 801- 900]: loss = 0.235829 * 100, metric = 5.10% * 100;
 Minibatch[ 901-1000]: loss = 0.252870 * 100, metric = 5.53% * 100;
 Minibatch[1001-1100]: loss = 0.245873 * 100, metric = 5.27% * 100;
 Minibatch[1101-1200]: loss = 0.245344 * 100, metric = 5.16% * 100;
 Minibatch[1201-1300]: loss = 0.248274 * 100, metric = 5.29% * 100;
 Minibatch[1301-1400]: loss = 0.248480 * 100, metric = 5.26% * 100;
 Minibatch[1401-1500]: loss = 0.234979 * 100, metric = 4.92% * 100;
 Minibatch[1501-1600]: loss = 0.245114 * 100, metric = 5.03% * 100;
 Minibatch[1601-1700]: loss = 0.245462 * 100, metric = 5.14% * 100;
 Minibatch[1701-1800]: loss = 0.245945 * 100, metric = 5.22% * 100;
 Minibatch[1801-1900]: loss = 0.246129 * 100, metric = 5.35% * 100;
 Minibatch[1901-2000]: loss = 0.241011 * 100, metric = 5.13% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.245450 * 2000, metric = 5.20% * 2000 869.266s (  2.3 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 12.81% * 2000;
 Minibatch[   1- 100]: loss = 0.253783 * 100, metric = 5.48% * 100;
 Minibatch[ 101- 200]: loss = 0.236926 * 100, metric = 4.81% * 100;
 Minibatch[ 201- 300]: loss = 0.245667 * 100, metric = 5.11% * 100;
 Minibatch[ 301- 400]: loss = 0.246682 * 100, metric = 5.24% * 100;
 Minibatch[ 401- 500]: loss = 0.240527 * 100, metric = 5.18% * 100;
 Minibatch[ 501- 600]: loss = 0.238230 * 100, metric = 5.05% * 100;
 Minibatch[ 601- 700]: loss = 0.246775 * 100, metric = 5.36% * 100;
 Minibatch[ 701- 800]: loss = 0.233717 * 100, metric = 5.05% * 100;
 Minibatch[ 801- 900]: loss = 0.242266 * 100, metric = 5.15% * 100;
 Minibatch[ 901-1000]: loss = 0.240623 * 100, metric = 5.20% * 100;
 Minibatch[1001-1100]: loss = 0.239282 * 100, metric = 5.14% * 100;
 Minibatch[1101-1200]: loss = 0.234658 * 100, metric = 5.08% * 100;
 Minibatch[1201-1300]: loss = 0.250777 * 100, metric = 5.60% * 100;
 Minibatch[1301-1400]: loss = 0.242950 * 100, metric = 5.35% * 100;
 Minibatch[1401-1500]: loss = 0.231107 * 100, metric = 4.72% * 100;
 Minibatch[1501-1600]: loss = 0.247212 * 100, metric = 5.23% * 100;
 Minibatch[1601-1700]: loss = 0.243233 * 100, metric = 5.20% * 100;
 Minibatch[1701-1800]: loss = 0.241297 * 100, metric = 5.20% * 100;
 Minibatch[1801-1900]: loss = 0.250931 * 100, metric = 5.54% * 100;
 Minibatch[1901-2000]: loss = 0.236442 * 100, metric = 5.01% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.242154 * 2000, metric = 5.19% * 2000 878.577s (  2.3 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 13.66% * 2000;
 Minibatch[   1- 100]: loss = 0.237816 * 100, metric = 5.03% * 100;
 Minibatch[ 101- 200]: loss = 0.239783 * 100, metric = 5.02% * 100;
 Minibatch[ 201- 300]: loss = 0.248027 * 100, metric = 5.30% * 100;
 Minibatch[ 301- 400]: loss = 0.247144 * 100, metric = 5.28% * 100;
 Minibatch[ 401- 500]: loss = 0.236093 * 100, metric = 4.93% * 100;
 Minibatch[ 501- 600]: loss = 0.238495 * 100, metric = 5.24% * 100;
 Minibatch[ 601- 700]: loss = 0.244559 * 100, metric = 5.33% * 100;
 Minibatch[ 701- 800]: loss = 0.219870 * 100, metric = 4.53% * 100;
 Minibatch[ 801- 900]: loss = 0.233636 * 100, metric = 4.80% * 100;
 Minibatch[ 901-1000]: loss = 0.233664 * 100, metric = 4.84% * 100;
 Minibatch[1001-1100]: loss = 0.232601 * 100, metric = 4.75% * 100;
 Minibatch[1101-1200]: loss = 0.229989 * 100, metric = 4.77% * 100;
 Minibatch[1201-1300]: loss = 0.236562 * 100, metric = 5.03% * 100;
 Minibatch[1301-1400]: loss = 0.231483 * 100, metric = 4.98% * 100;
 Minibatch[1401-1500]: loss = 0.228299 * 100, metric = 4.82% * 100;
 Minibatch[1501-1600]: loss = 0.226596 * 100, metric = 4.78% * 100;
 Minibatch[1601-1700]: loss = 0.238683 * 100, metric = 5.10% * 100;
 Minibatch[1701-1800]: loss = 0.238549 * 100, metric = 5.26% * 100;
 Minibatch[1801-1900]: loss = 0.239973 * 100, metric = 4.99% * 100;
 Minibatch[1901-2000]: loss = 0.226942 * 100, metric = 4.79% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.235438 * 2000, metric = 4.98% * 2000 873.974s (  2.3 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 13.09% * 2000;
 Minibatch[   1- 100]: loss = 0.239612 * 100, metric = 5.08% * 100;
 Minibatch[ 101- 200]: loss = 0.236413 * 100, metric = 4.76% * 100;
 Minibatch[ 201- 300]: loss = 0.234944 * 100, metric = 4.93% * 100;
 Minibatch[ 301- 400]: loss = 0.241842 * 100, metric = 5.12% * 100;
 Minibatch[ 401- 500]: loss = 0.236608 * 100, metric = 5.12% * 100;
 Minibatch[ 501- 600]: loss = 0.223951 * 100, metric = 4.62% * 100;
 Minibatch[ 601- 700]: loss = 0.227878 * 100, metric = 4.79% * 100;
 Minibatch[ 701- 800]: loss = 0.228560 * 100, metric = 5.02% * 100;
 Minibatch[ 801- 900]: loss = 0.241213 * 100, metric = 5.36% * 100;
 Minibatch[ 901-1000]: loss = 0.230339 * 100, metric = 4.94% * 100;
 Minibatch[1001-1100]: loss = 0.225943 * 100, metric = 4.78% * 100;
 Minibatch[1101-1200]: loss = 0.241119 * 100, metric = 4.98% * 100;
 Minibatch[1201-1300]: loss = 0.235904 * 100, metric = 5.04% * 100;
 Minibatch[1301-1400]: loss = 0.231682 * 100, metric = 4.88% * 100;
 Minibatch[1401-1500]: loss = 0.242778 * 100, metric = 5.14% * 100;
 Minibatch[1501-1600]: loss = 0.232310 * 100, metric = 4.90% * 100;
 Minibatch[1601-1700]: loss = 0.229532 * 100, metric = 4.96% * 100;
 Minibatch[1701-1800]: loss = 0.237712 * 100, metric = 5.07% * 100;
 Minibatch[1801-1900]: loss = 0.238781 * 100, metric = 5.12% * 100;
 Minibatch[1901-2000]: loss = 0.239199 * 100, metric = 4.96% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.234816 * 2000, metric = 4.98% * 2000 882.163s (  2.3 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 13.09% * 2000;
 Minibatch[   1- 100]: loss = 0.233244 * 100, metric = 4.96% * 100;
 Minibatch[ 101- 200]: loss = 0.246040 * 100, metric = 5.27% * 100;
 Minibatch[ 201- 300]: loss = 0.240716 * 100, metric = 5.08% * 100;
 Minibatch[ 301- 400]: loss = 0.245130 * 100, metric = 5.25% * 100;
 Minibatch[ 401- 500]: loss = 0.238090 * 100, metric = 4.93% * 100;
 Minibatch[ 501- 600]: loss = 0.235237 * 100, metric = 4.96% * 100;
 Minibatch[ 601- 700]: loss = 0.227533 * 100, metric = 4.77% * 100;
 Minibatch[ 701- 800]: loss = 0.228207 * 100, metric = 4.75% * 100;
 Minibatch[ 801- 900]: loss = 0.231512 * 100, metric = 4.91% * 100;
 Minibatch[ 901-1000]: loss = 0.238306 * 100, metric = 5.00% * 100;
 Minibatch[1001-1100]: loss = 0.232225 * 100, metric = 4.90% * 100;
 Minibatch[1101-1200]: loss = 0.246740 * 100, metric = 5.22% * 100;
 Minibatch[1201-1300]: loss = 0.237201 * 100, metric = 4.90% * 100;
 Minibatch[1301-1400]: loss = 0.233687 * 100, metric = 4.88% * 100;
 Minibatch[1401-1500]: loss = 0.228275 * 100, metric = 4.97% * 100;
 Minibatch[1501-1600]: loss = 0.240886 * 100, metric = 4.94% * 100;
 Minibatch[1601-1700]: loss = 0.230347 * 100, metric = 4.80% * 100;
 Minibatch[1701-1800]: loss = 0.242063 * 100, metric = 5.02% * 100;
 Minibatch[1801-1900]: loss = 0.215082 * 100, metric = 4.36% * 100;
 Minibatch[1901-2000]: loss = 0.227925 * 100, metric = 4.66% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.234922 * 2000, metric = 4.93% * 2000 877.300s (  2.3 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 13.19% * 2000;
 Minibatch[   1- 100]: loss = 0.233301 * 100, metric = 5.01% * 100;
 Minibatch[ 101- 200]: loss = 0.223928 * 100, metric = 4.62% * 100;
 Minibatch[ 201- 300]: loss = 0.233591 * 100, metric = 4.86% * 100;
 Minibatch[ 301- 400]: loss = 0.227056 * 100, metric = 4.67% * 100;
 Minibatch[ 401- 500]: loss = 0.220064 * 100, metric = 4.52% * 100;
 Minibatch[ 501- 600]: loss = 0.226510 * 100, metric = 4.92% * 100;
 Minibatch[ 601- 700]: loss = 0.233728 * 100, metric = 4.83% * 100;
 Minibatch[ 701- 800]: loss = 0.237701 * 100, metric = 5.12% * 100;
 Minibatch[ 801- 900]: loss = 0.227559 * 100, metric = 4.65% * 100;
 Minibatch[ 901-1000]: loss = 0.230080 * 100, metric = 4.74% * 100;
 Minibatch[1001-1100]: loss = 0.234888 * 100, metric = 4.90% * 100;
 Minibatch[1101-1200]: loss = 0.236207 * 100, metric = 5.00% * 100;
 Minibatch[1201-1300]: loss = 0.212410 * 100, metric = 4.42% * 100;
 Minibatch[1301-1400]: loss = 0.226621 * 100, metric = 4.82% * 100;
 Minibatch[1401-1500]: loss = 0.235169 * 100, metric = 5.05% * 100;
 Minibatch[1501-1600]: loss = 0.237622 * 100, metric = 4.96% * 100;
 Minibatch[1601-1700]: loss = 0.228584 * 100, metric = 4.67% * 100;
 Minibatch[1701-1800]: loss = 0.236437 * 100, metric = 5.05% * 100;
 Minibatch[1801-1900]: loss = 0.227167 * 100, metric = 4.82% * 100;
 Minibatch[1901-2000]: loss = 0.238447 * 100, metric = 5.06% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.230354 * 2000, metric = 4.83% * 2000 876.828s (  2.3 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 12.35% * 2000;
 Minibatch[   1- 100]: loss = 0.228736 * 100, metric = 4.78% * 100;
 Minibatch[ 101- 200]: loss = 0.229775 * 100, metric = 4.84% * 100;
 Minibatch[ 201- 300]: loss = 0.228553 * 100, metric = 4.85% * 100;
 Minibatch[ 301- 400]: loss = 0.222361 * 100, metric = 4.60% * 100;
 Minibatch[ 401- 500]: loss = 0.236999 * 100, metric = 5.17% * 100;
 Minibatch[ 501- 600]: loss = 0.241728 * 100, metric = 5.15% * 100;
 Minibatch[ 601- 700]: loss = 0.242112 * 100, metric = 5.12% * 100;
 Minibatch[ 701- 800]: loss = 0.234171 * 100, metric = 4.86% * 100;
 Minibatch[ 801- 900]: loss = 0.228009 * 100, metric = 4.78% * 100;
 Minibatch[ 901-1000]: loss = 0.236528 * 100, metric = 5.15% * 100;
 Minibatch[1001-1100]: loss = 0.227144 * 100, metric = 4.76% * 100;
 Minibatch[1101-1200]: loss = 0.228136 * 100, metric = 4.71% * 100;
 Minibatch[1201-1300]: loss = 0.229232 * 100, metric = 4.94% * 100;
 Minibatch[1301-1400]: loss = 0.225714 * 100, metric = 4.73% * 100;
 Minibatch[1401-1500]: loss = 0.226033 * 100, metric = 4.85% * 100;
 Minibatch[1501-1600]: loss = 0.226946 * 100, metric = 4.87% * 100;
 Minibatch[1601-1700]: loss = 0.227813 * 100, metric = 4.93% * 100;
 Minibatch[1701-1800]: loss = 0.224349 * 100, metric = 4.75% * 100;
 Minibatch[1801-1900]: loss = 0.235714 * 100, metric = 5.00% * 100;
 Minibatch[1901-2000]: loss = 0.220247 * 100, metric = 4.52% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.230015 * 2000, metric = 4.87% * 2000 876.570s (  2.3 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 13.21% * 2000;
 Minibatch[   1- 100]: loss = 0.234204 * 100, metric = 4.95% * 100;
 Minibatch[ 101- 200]: loss = 0.224032 * 100, metric = 4.76% * 100;
 Minibatch[ 201- 300]: loss = 0.235739 * 100, metric = 5.28% * 100;
 Minibatch[ 301- 400]: loss = 0.226968 * 100, metric = 4.80% * 100;
 Minibatch[ 401- 500]: loss = 0.238296 * 100, metric = 5.12% * 100;
 Minibatch[ 501- 600]: loss = 0.228941 * 100, metric = 4.88% * 100;
 Minibatch[ 601- 700]: loss = 0.223171 * 100, metric = 4.72% * 100;
 Minibatch[ 701- 800]: loss = 0.227342 * 100, metric = 4.87% * 100;
 Minibatch[ 801- 900]: loss = 0.224854 * 100, metric = 4.80% * 100;
 Minibatch[ 901-1000]: loss = 0.235299 * 100, metric = 5.14% * 100;
 Minibatch[1001-1100]: loss = 0.227572 * 100, metric = 4.98% * 100;
 Minibatch[1101-1200]: loss = 0.236819 * 100, metric = 5.11% * 100;
 Minibatch[1201-1300]: loss = 0.212960 * 100, metric = 4.43% * 100;
 Minibatch[1301-1400]: loss = 0.230349 * 100, metric = 4.93% * 100;
 Minibatch[1401-1500]: loss = 0.227995 * 100, metric = 4.99% * 100;
 Minibatch[1501-1600]: loss = 0.214824 * 100, metric = 4.38% * 100;
 Minibatch[1601-1700]: loss = 0.239510 * 100, metric = 5.12% * 100;
 Minibatch[1701-1800]: loss = 0.229510 * 100, metric = 4.94% * 100;
 Minibatch[1801-1900]: loss = 0.232241 * 100, metric = 4.95% * 100;
 Minibatch[1901-2000]: loss = 0.224045 * 100, metric = 4.72% * 100;
Finished Epoch[49 of 200]: [Training] loss = 0.228734 * 2000, metric = 4.89% * 2000 880.989s (  2.3 samples/s);
Finished Evaluation [49]: Minibatch[1-2000]: metric = 12.34% * 2000;
 Minibatch[   1- 100]: loss = 0.232624 * 100, metric = 4.88% * 100;
 Minibatch[ 101- 200]: loss = 0.222699 * 100, metric = 4.73% * 100;
 Minibatch[ 201- 300]: loss = 0.222572 * 100, metric = 4.63% * 100;
 Minibatch[ 301- 400]: loss = 0.222591 * 100, metric = 4.62% * 100;
 Minibatch[ 401- 500]: loss = 0.229286 * 100, metric = 5.02% * 100;
 Minibatch[ 501- 600]: loss = 0.234487 * 100, metric = 5.06% * 100;
 Minibatch[ 601- 700]: loss = 0.222963 * 100, metric = 4.76% * 100;
 Minibatch[ 701- 800]: loss = 0.223062 * 100, metric = 4.70% * 100;
 Minibatch[ 801- 900]: loss = 0.223451 * 100, metric = 4.65% * 100;
 Minibatch[ 901-1000]: loss = 0.225072 * 100, metric = 4.71% * 100;
 Minibatch[1001-1100]: loss = 0.217845 * 100, metric = 4.62% * 100;
 Minibatch[1101-1200]: loss = 0.219420 * 100, metric = 4.75% * 100;
 Minibatch[1201-1300]: loss = 0.226296 * 100, metric = 4.89% * 100;
 Minibatch[1301-1400]: loss = 0.217850 * 100, metric = 4.74% * 100;
 Minibatch[1401-1500]: loss = 0.228200 * 100, metric = 5.10% * 100;
 Minibatch[1501-1600]: loss = 0.216947 * 100, metric = 4.52% * 100;
 Minibatch[1601-1700]: loss = 0.216564 * 100, metric = 4.51% * 100;
 Minibatch[1701-1800]: loss = 0.226849 * 100, metric = 4.88% * 100;
 Minibatch[1801-1900]: loss = 0.230638 * 100, metric = 4.87% * 100;
 Minibatch[1901-2000]: loss = 0.222462 * 100, metric = 4.75% * 100;
Finished Epoch[50 of 200]: [Training] loss = 0.224094 * 2000, metric = 4.77% * 2000 881.883s (  2.3 samples/s);
Finished Evaluation [50]: Minibatch[1-2000]: metric = 13.02% * 2000;
 Minibatch[   1- 100]: loss = 0.214324 * 100, metric = 4.54% * 100;
 Minibatch[ 101- 200]: loss = 0.223683 * 100, metric = 4.67% * 100;
 Minibatch[ 201- 300]: loss = 0.218611 * 100, metric = 4.51% * 100;
 Minibatch[ 301- 400]: loss = 0.218393 * 100, metric = 4.67% * 100;
 Minibatch[ 401- 500]: loss = 0.216272 * 100, metric = 4.52% * 100;
 Minibatch[ 501- 600]: loss = 0.231666 * 100, metric = 5.06% * 100;
 Minibatch[ 601- 700]: loss = 0.214072 * 100, metric = 4.48% * 100;
 Minibatch[ 701- 800]: loss = 0.215425 * 100, metric = 4.57% * 100;
 Minibatch[ 801- 900]: loss = 0.224281 * 100, metric = 4.71% * 100;
 Minibatch[ 901-1000]: loss = 0.216688 * 100, metric = 4.66% * 100;
 Minibatch[1001-1100]: loss = 0.219911 * 100, metric = 4.76% * 100;
 Minibatch[1101-1200]: loss = 0.225147 * 100, metric = 4.73% * 100;
 Minibatch[1201-1300]: loss = 0.227551 * 100, metric = 4.68% * 100;
 Minibatch[1301-1400]: loss = 0.220819 * 100, metric = 4.53% * 100;
 Minibatch[1401-1500]: loss = 0.215095 * 100, metric = 4.59% * 100;
 Minibatch[1501-1600]: loss = 0.222982 * 100, metric = 4.61% * 100;
 Minibatch[1601-1700]: loss = 0.206829 * 100, metric = 4.31% * 100;
 Minibatch[1701-1800]: loss = 0.222874 * 100, metric = 4.61% * 100;
 Minibatch[1801-1900]: loss = 0.210130 * 100, metric = 4.54% * 100;
 Minibatch[1901-2000]: loss = 0.222699 * 100, metric = 4.69% * 100;
Finished Epoch[51 of 200]: [Training] loss = 0.219373 * 2000, metric = 4.62% * 2000 882.577s (  2.3 samples/s);
Finished Evaluation [51]: Minibatch[1-2000]: metric = 12.45% * 2000;
 Minibatch[   1- 100]: loss = 0.210479 * 100, metric = 4.36% * 100;
 Minibatch[ 101- 200]: loss = 0.214646 * 100, metric = 4.41% * 100;
 Minibatch[ 201- 300]: loss = 0.226980 * 100, metric = 4.88% * 100;
 Minibatch[ 301- 400]: loss = 0.207806 * 100, metric = 4.38% * 100;
 Minibatch[ 401- 500]: loss = 0.218724 * 100, metric = 4.54% * 100;
 Minibatch[ 501- 600]: loss = 0.215480 * 100, metric = 4.54% * 100;
 Minibatch[ 601- 700]: loss = 0.214165 * 100, metric = 4.44% * 100;
 Minibatch[ 701- 800]: loss = 0.224194 * 100, metric = 4.59% * 100;
 Minibatch[ 801- 900]: loss = 0.224324 * 100, metric = 4.89% * 100;
 Minibatch[ 901-1000]: loss = 0.222691 * 100, metric = 4.67% * 100;
 Minibatch[1001-1100]: loss = 0.216944 * 100, metric = 4.50% * 100;
 Minibatch[1101-1200]: loss = 0.214706 * 100, metric = 4.30% * 100;
 Minibatch[1201-1300]: loss = 0.214434 * 100, metric = 4.43% * 100;
 Minibatch[1301-1400]: loss = 0.211530 * 100, metric = 4.22% * 100;
 Minibatch[1401-1500]: loss = 0.204456 * 100, metric = 4.09% * 100;
 Minibatch[1501-1600]: loss = 0.207401 * 100, metric = 4.41% * 100;
 Minibatch[1601-1700]: loss = 0.216634 * 100, metric = 4.54% * 100;
 Minibatch[1701-1800]: loss = 0.208853 * 100, metric = 4.41% * 100;
 Minibatch[1801-1900]: loss = 0.207007 * 100, metric = 4.21% * 100;
 Minibatch[1901-2000]: loss = 0.224616 * 100, metric = 4.80% * 100;
Finished Epoch[52 of 200]: [Training] loss = 0.215303 * 2000, metric = 4.48% * 2000 871.649s (  2.3 samples/s);
Finished Evaluation [52]: Minibatch[1-2000]: metric = 13.30% * 2000;
 Minibatch[   1- 100]: loss = 0.213056 * 100, metric = 4.35% * 100;
 Minibatch[ 101- 200]: loss = 0.211447 * 100, metric = 4.36% * 100;
 Minibatch[ 201- 300]: loss = 0.218426 * 100, metric = 4.59% * 100;
 Minibatch[ 301- 400]: loss = 0.217850 * 100, metric = 4.56% * 100;
 Minibatch[ 401- 500]: loss = 0.216381 * 100, metric = 4.51% * 100;
 Minibatch[ 501- 600]: loss = 0.211284 * 100, metric = 4.40% * 100;
 Minibatch[ 601- 700]: loss = 0.207148 * 100, metric = 4.16% * 100;
 Minibatch[ 701- 800]: loss = 0.212652 * 100, metric = 4.35% * 100;
 Minibatch[ 801- 900]: loss = 0.212884 * 100, metric = 4.45% * 100;
 Minibatch[ 901-1000]: loss = 0.215625 * 100, metric = 4.61% * 100;
 Minibatch[1001-1100]: loss = 0.217984 * 100, metric = 4.58% * 100;
 Minibatch[1101-1200]: loss = 0.208207 * 100, metric = 4.38% * 100;
 Minibatch[1201-1300]: loss = 0.208204 * 100, metric = 4.36% * 100;
 Minibatch[1301-1400]: loss = 0.212569 * 100, metric = 4.25% * 100;
 Minibatch[1401-1500]: loss = 0.209522 * 100, metric = 4.36% * 100;
 Minibatch[1501-1600]: loss = 0.220954 * 100, metric = 4.78% * 100;
 Minibatch[1601-1700]: loss = 0.212389 * 100, metric = 4.47% * 100;
 Minibatch[1701-1800]: loss = 0.218318 * 100, metric = 4.68% * 100;
 Minibatch[1801-1900]: loss = 0.223122 * 100, metric = 4.71% * 100;
 Minibatch[1901-2000]: loss = 0.205208 * 100, metric = 4.30% * 100;
Finished Epoch[53 of 200]: [Training] loss = 0.213661 * 2000, metric = 4.46% * 2000 878.308s (  2.3 samples/s);
Finished Evaluation [53]: Minibatch[1-2000]: metric = 12.36% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
