Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.271548 * 100, metric = 24.67% * 100;
 Minibatch[ 101- 200]: loss = 1.038989 * 100, metric = 23.36% * 100;
 Minibatch[ 201- 300]: loss = 0.930542 * 100, metric = 21.71% * 100;
 Minibatch[ 301- 400]: loss = 0.913477 * 100, metric = 20.88% * 100;
 Minibatch[ 401- 500]: loss = 0.847905 * 100, metric = 18.75% * 100;
 Minibatch[ 501- 600]: loss = 0.816877 * 100, metric = 17.67% * 100;
 Minibatch[ 601- 700]: loss = 0.804529 * 100, metric = 17.71% * 100;
 Minibatch[ 701- 800]: loss = 0.756253 * 100, metric = 16.25% * 100;
 Minibatch[ 801- 900]: loss = 0.768832 * 100, metric = 16.54% * 100;
 Minibatch[ 901-1000]: loss = 0.777418 * 100, metric = 17.17% * 100;
 Minibatch[1001-1100]: loss = 0.763447 * 100, metric = 16.96% * 100;
 Minibatch[1101-1200]: loss = 0.756647 * 100, metric = 16.34% * 100;
 Minibatch[1201-1300]: loss = 0.750225 * 100, metric = 16.61% * 100;
 Minibatch[1301-1400]: loss = 0.736410 * 100, metric = 15.79% * 100;
 Minibatch[1401-1500]: loss = 0.739597 * 100, metric = 15.82% * 100;
 Minibatch[1501-1600]: loss = 0.722252 * 100, metric = 15.61% * 100;
 Minibatch[1601-1700]: loss = 0.704460 * 100, metric = 15.14% * 100;
 Minibatch[1701-1800]: loss = 0.713307 * 100, metric = 15.43% * 100;
 Minibatch[1801-1900]: loss = 0.708374 * 100, metric = 15.42% * 100;
 Minibatch[1901-2000]: loss = 0.686862 * 100, metric = 14.55% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.810398 * 2000, metric = 17.62% * 2000 1025.981s (  1.9 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 24.32% * 2000;
0.7547138993889093
 Minibatch[   1- 100]: loss = 0.681450 * 100, metric = 14.48% * 100;
 Minibatch[ 101- 200]: loss = 0.702421 * 100, metric = 15.77% * 100;
 Minibatch[ 201- 300]: loss = 0.697071 * 100, metric = 14.55% * 100;
 Minibatch[ 301- 400]: loss = 0.697625 * 100, metric = 14.59% * 100;
 Minibatch[ 401- 500]: loss = 0.690011 * 100, metric = 14.82% * 100;
 Minibatch[ 501- 600]: loss = 0.691235 * 100, metric = 14.43% * 100;
 Minibatch[ 601- 700]: loss = 0.662499 * 100, metric = 14.28% * 100;
 Minibatch[ 701- 800]: loss = 0.674819 * 100, metric = 14.73% * 100;
 Minibatch[ 801- 900]: loss = 0.665566 * 100, metric = 14.30% * 100;
 Minibatch[ 901-1000]: loss = 0.649966 * 100, metric = 13.63% * 100;
 Minibatch[1001-1100]: loss = 0.666539 * 100, metric = 14.20% * 100;
 Minibatch[1101-1200]: loss = 0.662837 * 100, metric = 14.01% * 100;
 Minibatch[1201-1300]: loss = 0.653209 * 100, metric = 13.65% * 100;
 Minibatch[1301-1400]: loss = 0.663666 * 100, metric = 14.07% * 100;
 Minibatch[1401-1500]: loss = 0.639495 * 100, metric = 13.38% * 100;
 Minibatch[1501-1600]: loss = 0.630446 * 100, metric = 13.42% * 100;
 Minibatch[1601-1700]: loss = 0.647892 * 100, metric = 13.41% * 100;
 Minibatch[1701-1800]: loss = 0.654122 * 100, metric = 14.06% * 100;
 Minibatch[1801-1900]: loss = 0.653679 * 100, metric = 13.71% * 100;
 Minibatch[1901-2000]: loss = 0.627493 * 100, metric = 13.33% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.665602 * 2000, metric = 14.14% * 2000 960.309s (  2.1 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 20.76% * 2000;
0.6920913029387593
 Minibatch[   1- 100]: loss = 0.647443 * 100, metric = 13.63% * 100;
 Minibatch[ 101- 200]: loss = 0.636966 * 100, metric = 13.35% * 100;
 Minibatch[ 201- 300]: loss = 0.621820 * 100, metric = 13.28% * 100;
 Minibatch[ 301- 400]: loss = 0.635176 * 100, metric = 13.45% * 100;
 Minibatch[ 401- 500]: loss = 0.640359 * 100, metric = 13.73% * 100;
 Minibatch[ 501- 600]: loss = 0.637017 * 100, metric = 13.37% * 100;
 Minibatch[ 601- 700]: loss = 0.643291 * 100, metric = 13.65% * 100;
 Minibatch[ 701- 800]: loss = 0.617497 * 100, metric = 12.74% * 100;
 Minibatch[ 801- 900]: loss = 0.639885 * 100, metric = 13.64% * 100;
 Minibatch[ 901-1000]: loss = 0.613560 * 100, metric = 13.07% * 100;
 Minibatch[1001-1100]: loss = 0.622281 * 100, metric = 13.17% * 100;
 Minibatch[1101-1200]: loss = 0.607526 * 100, metric = 12.62% * 100;
 Minibatch[1201-1300]: loss = 0.613406 * 100, metric = 12.89% * 100;
 Minibatch[1301-1400]: loss = 0.617703 * 100, metric = 13.00% * 100;
 Minibatch[1401-1500]: loss = 0.624711 * 100, metric = 13.39% * 100;
 Minibatch[1501-1600]: loss = 0.607188 * 100, metric = 12.70% * 100;
 Minibatch[1601-1700]: loss = 0.602235 * 100, metric = 12.53% * 100;
 Minibatch[1701-1800]: loss = 0.618124 * 100, metric = 12.91% * 100;
 Minibatch[1801-1900]: loss = 0.602534 * 100, metric = 12.54% * 100;
 Minibatch[1901-2000]: loss = 0.601877 * 100, metric = 12.89% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.622530 * 2000, metric = 13.13% * 2000 955.756s (  2.1 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 21.25% * 2000;
0.6729091753959656
 Minibatch[   1- 100]: loss = 0.623232 * 100, metric = 12.79% * 100;
 Minibatch[ 101- 200]: loss = 0.597535 * 100, metric = 12.36% * 100;
 Minibatch[ 201- 300]: loss = 0.611962 * 100, metric = 12.78% * 100;
 Minibatch[ 301- 400]: loss = 0.581410 * 100, metric = 12.00% * 100;
 Minibatch[ 401- 500]: loss = 0.612699 * 100, metric = 12.92% * 100;
 Minibatch[ 501- 600]: loss = 0.585798 * 100, metric = 11.81% * 100;
 Minibatch[ 601- 700]: loss = 0.587402 * 100, metric = 12.11% * 100;
 Minibatch[ 701- 800]: loss = 0.596543 * 100, metric = 12.39% * 100;
 Minibatch[ 801- 900]: loss = 0.602164 * 100, metric = 12.56% * 100;
 Minibatch[ 901-1000]: loss = 0.601924 * 100, metric = 12.81% * 100;
 Minibatch[1001-1100]: loss = 0.608695 * 100, metric = 12.77% * 100;
 Minibatch[1101-1200]: loss = 0.580047 * 100, metric = 12.24% * 100;
 Minibatch[1201-1300]: loss = 0.593940 * 100, metric = 12.46% * 100;
 Minibatch[1301-1400]: loss = 0.609374 * 100, metric = 12.77% * 100;
 Minibatch[1401-1500]: loss = 0.610898 * 100, metric = 12.82% * 100;
 Minibatch[1501-1600]: loss = 0.578297 * 100, metric = 11.96% * 100;
 Minibatch[1601-1700]: loss = 0.598486 * 100, metric = 12.71% * 100;
 Minibatch[1701-1800]: loss = 0.601035 * 100, metric = 12.86% * 100;
 Minibatch[1801-1900]: loss = 0.595662 * 100, metric = 12.38% * 100;
 Minibatch[1901-2000]: loss = 0.576719 * 100, metric = 12.08% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.597691 * 2000, metric = 12.48% * 2000 954.113s (  2.1 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 21.33% * 2000;
 Minibatch[   1- 100]: loss = 0.601946 * 100, metric = 12.39% * 100;
 Minibatch[ 101- 200]: loss = 0.586046 * 100, metric = 12.07% * 100;
 Minibatch[ 201- 300]: loss = 0.578795 * 100, metric = 11.94% * 100;
 Minibatch[ 301- 400]: loss = 0.607945 * 100, metric = 12.84% * 100;
 Minibatch[ 401- 500]: loss = 0.571692 * 100, metric = 11.55% * 100;
 Minibatch[ 501- 600]: loss = 0.571443 * 100, metric = 11.78% * 100;
 Minibatch[ 601- 700]: loss = 0.575703 * 100, metric = 11.63% * 100;
 Minibatch[ 701- 800]: loss = 0.579691 * 100, metric = 11.88% * 100;
 Minibatch[ 801- 900]: loss = 0.573689 * 100, metric = 11.74% * 100;
 Minibatch[ 901-1000]: loss = 0.569462 * 100, metric = 11.83% * 100;
 Minibatch[1001-1100]: loss = 0.589824 * 100, metric = 12.16% * 100;
 Minibatch[1101-1200]: loss = 0.561810 * 100, metric = 11.57% * 100;
 Minibatch[1201-1300]: loss = 0.583347 * 100, metric = 12.08% * 100;
 Minibatch[1301-1400]: loss = 0.594811 * 100, metric = 12.76% * 100;
 Minibatch[1401-1500]: loss = 0.576668 * 100, metric = 12.12% * 100;
 Minibatch[1501-1600]: loss = 0.583805 * 100, metric = 12.20% * 100;
 Minibatch[1601-1700]: loss = 0.589695 * 100, metric = 12.54% * 100;
 Minibatch[1701-1800]: loss = 0.598179 * 100, metric = 12.68% * 100;
 Minibatch[1801-1900]: loss = 0.581533 * 100, metric = 12.21% * 100;
 Minibatch[1901-2000]: loss = 0.565870 * 100, metric = 11.75% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.582098 * 2000, metric = 12.09% * 2000 958.638s (  2.1 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 19.07% * 2000;
0.6201237790063023
 Minibatch[   1- 100]: loss = 0.563056 * 100, metric = 11.70% * 100;
 Minibatch[ 101- 200]: loss = 0.553781 * 100, metric = 11.73% * 100;
 Minibatch[ 201- 300]: loss = 0.571844 * 100, metric = 11.90% * 100;
 Minibatch[ 301- 400]: loss = 0.564986 * 100, metric = 11.41% * 100;
 Minibatch[ 401- 500]: loss = 0.536952 * 100, metric = 11.13% * 100;
 Minibatch[ 501- 600]: loss = 0.561924 * 100, metric = 11.78% * 100;
 Minibatch[ 601- 700]: loss = 0.549832 * 100, metric = 11.56% * 100;
 Minibatch[ 701- 800]: loss = 0.568023 * 100, metric = 11.77% * 100;
 Minibatch[ 801- 900]: loss = 0.568293 * 100, metric = 11.84% * 100;
 Minibatch[ 901-1000]: loss = 0.550752 * 100, metric = 11.51% * 100;
 Minibatch[1001-1100]: loss = 0.557083 * 100, metric = 11.39% * 100;
 Minibatch[1101-1200]: loss = 0.562156 * 100, metric = 11.46% * 100;
 Minibatch[1201-1300]: loss = 0.578489 * 100, metric = 11.92% * 100;
 Minibatch[1301-1400]: loss = 0.555876 * 100, metric = 11.58% * 100;
 Minibatch[1401-1500]: loss = 0.568223 * 100, metric = 12.24% * 100;
 Minibatch[1501-1600]: loss = 0.547181 * 100, metric = 11.22% * 100;
 Minibatch[1601-1700]: loss = 0.554731 * 100, metric = 11.41% * 100;
 Minibatch[1701-1800]: loss = 0.548408 * 100, metric = 11.30% * 100;
 Minibatch[1801-1900]: loss = 0.561945 * 100, metric = 11.75% * 100;
 Minibatch[1901-2000]: loss = 0.544966 * 100, metric = 11.20% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.558425 * 2000, metric = 11.59% * 2000 958.021s (  2.1 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.55% * 2000;
 Minibatch[   1- 100]: loss = 0.544797 * 100, metric = 11.33% * 100;
 Minibatch[ 101- 200]: loss = 0.553420 * 100, metric = 11.18% * 100;
 Minibatch[ 201- 300]: loss = 0.561248 * 100, metric = 11.69% * 100;
 Minibatch[ 301- 400]: loss = 0.543298 * 100, metric = 11.06% * 100;
 Minibatch[ 401- 500]: loss = 0.552534 * 100, metric = 11.41% * 100;
 Minibatch[ 501- 600]: loss = 0.536938 * 100, metric = 10.90% * 100;
 Minibatch[ 601- 700]: loss = 0.553830 * 100, metric = 11.22% * 100;
 Minibatch[ 701- 800]: loss = 0.552483 * 100, metric = 11.22% * 100;
 Minibatch[ 801- 900]: loss = 0.556413 * 100, metric = 11.72% * 100;
 Minibatch[ 901-1000]: loss = 0.543174 * 100, metric = 11.31% * 100;
 Minibatch[1001-1100]: loss = 0.550431 * 100, metric = 11.51% * 100;
 Minibatch[1101-1200]: loss = 0.534056 * 100, metric = 11.06% * 100;
 Minibatch[1201-1300]: loss = 0.546149 * 100, metric = 11.54% * 100;
 Minibatch[1301-1400]: loss = 0.538832 * 100, metric = 11.33% * 100;
 Minibatch[1401-1500]: loss = 0.528659 * 100, metric = 10.60% * 100;
 Minibatch[1501-1600]: loss = 0.543046 * 100, metric = 11.22% * 100;
 Minibatch[1601-1700]: loss = 0.544303 * 100, metric = 11.37% * 100;
 Minibatch[1701-1800]: loss = 0.532909 * 100, metric = 10.91% * 100;
 Minibatch[1801-1900]: loss = 0.544239 * 100, metric = 11.48% * 100;
 Minibatch[1901-2000]: loss = 0.547369 * 100, metric = 11.37% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.545406 * 2000, metric = 11.27% * 2000 950.623s (  2.1 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.67% * 2000;
0.6187772289440036
 Minibatch[   1- 100]: loss = 0.543591 * 100, metric = 11.30% * 100;
 Minibatch[ 101- 200]: loss = 0.532723 * 100, metric = 10.93% * 100;
 Minibatch[ 201- 300]: loss = 0.513905 * 100, metric = 10.76% * 100;
 Minibatch[ 301- 400]: loss = 0.523279 * 100, metric = 10.86% * 100;
 Minibatch[ 401- 500]: loss = 0.534636 * 100, metric = 11.19% * 100;
 Minibatch[ 501- 600]: loss = 0.547725 * 100, metric = 11.47% * 100;
 Minibatch[ 601- 700]: loss = 0.521100 * 100, metric = 11.08% * 100;
 Minibatch[ 701- 800]: loss = 0.523721 * 100, metric = 10.75% * 100;
 Minibatch[ 801- 900]: loss = 0.511359 * 100, metric = 10.32% * 100;
 Minibatch[ 901-1000]: loss = 0.500882 * 100, metric = 10.31% * 100;
 Minibatch[1001-1100]: loss = 0.515175 * 100, metric = 10.46% * 100;
 Minibatch[1101-1200]: loss = 0.512523 * 100, metric = 10.50% * 100;
 Minibatch[1201-1300]: loss = 0.519245 * 100, metric = 10.82% * 100;
 Minibatch[1301-1400]: loss = 0.526711 * 100, metric = 11.08% * 100;
 Minibatch[1401-1500]: loss = 0.517675 * 100, metric = 10.37% * 100;
 Minibatch[1501-1600]: loss = 0.519979 * 100, metric = 10.55% * 100;
 Minibatch[1601-1700]: loss = 0.520032 * 100, metric = 10.41% * 100;
 Minibatch[1701-1800]: loss = 0.519227 * 100, metric = 10.32% * 100;
 Minibatch[1801-1900]: loss = 0.519714 * 100, metric = 10.57% * 100;
 Minibatch[1901-2000]: loss = 0.518347 * 100, metric = 10.67% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.522078 * 2000, metric = 10.74% * 2000 943.390s (  2.1 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 18.07% * 2000;
0.5875214470773935
 Minibatch[   1- 100]: loss = 0.502154 * 100, metric = 10.05% * 100;
 Minibatch[ 101- 200]: loss = 0.533472 * 100, metric = 11.04% * 100;
 Minibatch[ 201- 300]: loss = 0.522024 * 100, metric = 10.69% * 100;
 Minibatch[ 301- 400]: loss = 0.532891 * 100, metric = 10.86% * 100;
 Minibatch[ 401- 500]: loss = 0.516186 * 100, metric = 10.47% * 100;
 Minibatch[ 501- 600]: loss = 0.502524 * 100, metric = 10.37% * 100;
 Minibatch[ 601- 700]: loss = 0.505410 * 100, metric = 10.35% * 100;
 Minibatch[ 701- 800]: loss = 0.498602 * 100, metric = 10.12% * 100;
 Minibatch[ 801- 900]: loss = 0.497697 * 100, metric = 10.33% * 100;
 Minibatch[ 901-1000]: loss = 0.509114 * 100, metric = 10.44% * 100;
 Minibatch[1001-1100]: loss = 0.493291 * 100, metric = 9.74% * 100;
 Minibatch[1101-1200]: loss = 0.509687 * 100, metric = 10.20% * 100;
 Minibatch[1201-1300]: loss = 0.502365 * 100, metric = 10.22% * 100;
 Minibatch[1301-1400]: loss = 0.502174 * 100, metric = 9.97% * 100;
 Minibatch[1401-1500]: loss = 0.518610 * 100, metric = 10.80% * 100;
 Minibatch[1501-1600]: loss = 0.522429 * 100, metric = 10.69% * 100;
 Minibatch[1601-1700]: loss = 0.512341 * 100, metric = 10.46% * 100;
 Minibatch[1701-1800]: loss = 0.499854 * 100, metric = 9.96% * 100;
 Minibatch[1801-1900]: loss = 0.499111 * 100, metric = 10.10% * 100;
 Minibatch[1901-2000]: loss = 0.515413 * 100, metric = 10.40% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.509767 * 2000, metric = 10.36% * 2000 941.128s (  2.1 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 16.32% * 2000;
0.5573645474016666
 Minibatch[   1- 100]: loss = 0.523054 * 100, metric = 11.19% * 100;
 Minibatch[ 101- 200]: loss = 0.496717 * 100, metric = 10.10% * 100;
 Minibatch[ 201- 300]: loss = 0.503878 * 100, metric = 10.38% * 100;
 Minibatch[ 301- 400]: loss = 0.495622 * 100, metric = 9.97% * 100;
 Minibatch[ 401- 500]: loss = 0.506234 * 100, metric = 10.49% * 100;
 Minibatch[ 501- 600]: loss = 0.487466 * 100, metric = 10.14% * 100;
 Minibatch[ 601- 700]: loss = 0.488662 * 100, metric = 9.91% * 100;
 Minibatch[ 701- 800]: loss = 0.482868 * 100, metric = 9.47% * 100;
 Minibatch[ 801- 900]: loss = 0.500067 * 100, metric = 10.13% * 100;
 Minibatch[ 901-1000]: loss = 0.496537 * 100, metric = 10.32% * 100;
 Minibatch[1001-1100]: loss = 0.497425 * 100, metric = 10.32% * 100;
 Minibatch[1101-1200]: loss = 0.496753 * 100, metric = 10.02% * 100;
 Minibatch[1201-1300]: loss = 0.502347 * 100, metric = 10.37% * 100;
 Minibatch[1301-1400]: loss = 0.489294 * 100, metric = 9.89% * 100;
 Minibatch[1401-1500]: loss = 0.487156 * 100, metric = 9.64% * 100;
 Minibatch[1501-1600]: loss = 0.496150 * 100, metric = 10.26% * 100;
 Minibatch[1601-1700]: loss = 0.487564 * 100, metric = 9.78% * 100;
 Minibatch[1701-1800]: loss = 0.499031 * 100, metric = 10.09% * 100;
 Minibatch[1801-1900]: loss = 0.504846 * 100, metric = 10.23% * 100;
 Minibatch[1901-2000]: loss = 0.475845 * 100, metric = 9.71% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.495876 * 2000, metric = 10.12% * 2000 938.642s (  2.1 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 15.73% * 2000;
0.544132451467216
 Minibatch[   1- 100]: loss = 0.475267 * 100, metric = 9.40% * 100;
 Minibatch[ 101- 200]: loss = 0.494051 * 100, metric = 9.92% * 100;
 Minibatch[ 201- 300]: loss = 0.500685 * 100, metric = 10.09% * 100;
 Minibatch[ 301- 400]: loss = 0.489070 * 100, metric = 9.73% * 100;
 Minibatch[ 401- 500]: loss = 0.481477 * 100, metric = 9.66% * 100;
 Minibatch[ 501- 600]: loss = 0.486233 * 100, metric = 9.90% * 100;
 Minibatch[ 601- 700]: loss = 0.485499 * 100, metric = 9.62% * 100;
 Minibatch[ 701- 800]: loss = 0.492211 * 100, metric = 9.94% * 100;
 Minibatch[ 801- 900]: loss = 0.483848 * 100, metric = 9.68% * 100;
 Minibatch[ 901-1000]: loss = 0.488894 * 100, metric = 9.86% * 100;
 Minibatch[1001-1100]: loss = 0.482273 * 100, metric = 9.71% * 100;
 Minibatch[1101-1200]: loss = 0.485269 * 100, metric = 9.68% * 100;
 Minibatch[1201-1300]: loss = 0.467432 * 100, metric = 9.22% * 100;
 Minibatch[1301-1400]: loss = 0.458408 * 100, metric = 9.12% * 100;
 Minibatch[1401-1500]: loss = 0.484078 * 100, metric = 9.76% * 100;
 Minibatch[1501-1600]: loss = 0.467670 * 100, metric = 9.35% * 100;
 Minibatch[1601-1700]: loss = 0.475686 * 100, metric = 9.20% * 100;
 Minibatch[1701-1800]: loss = 0.488737 * 100, metric = 9.72% * 100;
 Minibatch[1801-1900]: loss = 0.467245 * 100, metric = 9.35% * 100;
 Minibatch[1901-2000]: loss = 0.474766 * 100, metric = 9.95% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.481440 * 2000, metric = 9.64% * 2000 942.322s (  2.1 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 16.68% * 2000;
 Minibatch[   1- 100]: loss = 0.455164 * 100, metric = 9.06% * 100;
 Minibatch[ 101- 200]: loss = 0.462188 * 100, metric = 8.97% * 100;
 Minibatch[ 201- 300]: loss = 0.465733 * 100, metric = 9.46% * 100;
 Minibatch[ 301- 400]: loss = 0.497562 * 100, metric = 10.13% * 100;
 Minibatch[ 401- 500]: loss = 0.460542 * 100, metric = 8.94% * 100;
 Minibatch[ 501- 600]: loss = 0.457761 * 100, metric = 8.98% * 100;
 Minibatch[ 601- 700]: loss = 0.460717 * 100, metric = 9.18% * 100;
 Minibatch[ 701- 800]: loss = 0.477010 * 100, metric = 9.68% * 100;
 Minibatch[ 801- 900]: loss = 0.466621 * 100, metric = 9.19% * 100;
 Minibatch[ 901-1000]: loss = 0.478498 * 100, metric = 9.67% * 100;
 Minibatch[1001-1100]: loss = 0.475334 * 100, metric = 9.74% * 100;
 Minibatch[1101-1200]: loss = 0.468475 * 100, metric = 9.19% * 100;
 Minibatch[1201-1300]: loss = 0.468724 * 100, metric = 9.51% * 100;
 Minibatch[1301-1400]: loss = 0.461564 * 100, metric = 9.18% * 100;
 Minibatch[1401-1500]: loss = 0.470986 * 100, metric = 9.47% * 100;
 Minibatch[1501-1600]: loss = 0.449242 * 100, metric = 8.82% * 100;
 Minibatch[1601-1700]: loss = 0.470916 * 100, metric = 9.35% * 100;
 Minibatch[1701-1800]: loss = 0.461182 * 100, metric = 9.14% * 100;
 Minibatch[1801-1900]: loss = 0.457773 * 100, metric = 9.05% * 100;
 Minibatch[1901-2000]: loss = 0.470885 * 100, metric = 9.39% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.466844 * 2000, metric = 9.31% * 2000 923.969s (  2.2 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 17.10% * 2000;
 Minibatch[   1- 100]: loss = 0.467628 * 100, metric = 9.30% * 100;
 Minibatch[ 101- 200]: loss = 0.469476 * 100, metric = 9.49% * 100;
 Minibatch[ 201- 300]: loss = 0.466259 * 100, metric = 9.60% * 100;
 Minibatch[ 301- 400]: loss = 0.469492 * 100, metric = 9.36% * 100;
 Minibatch[ 401- 500]: loss = 0.474169 * 100, metric = 9.85% * 100;
 Minibatch[ 501- 600]: loss = 0.478778 * 100, metric = 9.94% * 100;
 Minibatch[ 601- 700]: loss = 0.456558 * 100, metric = 8.92% * 100;
 Minibatch[ 701- 800]: loss = 0.454711 * 100, metric = 9.06% * 100;
 Minibatch[ 801- 900]: loss = 0.461053 * 100, metric = 9.27% * 100;
 Minibatch[ 901-1000]: loss = 0.467952 * 100, metric = 9.25% * 100;
 Minibatch[1001-1100]: loss = 0.473026 * 100, metric = 9.52% * 100;
 Minibatch[1101-1200]: loss = 0.458459 * 100, metric = 9.04% * 100;
 Minibatch[1201-1300]: loss = 0.459698 * 100, metric = 9.38% * 100;
 Minibatch[1301-1400]: loss = 0.462177 * 100, metric = 9.33% * 100;
 Minibatch[1401-1500]: loss = 0.454781 * 100, metric = 9.04% * 100;
 Minibatch[1501-1600]: loss = 0.446948 * 100, metric = 8.83% * 100;
 Minibatch[1601-1700]: loss = 0.443156 * 100, metric = 8.77% * 100;
 Minibatch[1701-1800]: loss = 0.453464 * 100, metric = 8.81% * 100;
 Minibatch[1801-1900]: loss = 0.443369 * 100, metric = 8.62% * 100;
 Minibatch[1901-2000]: loss = 0.453604 * 100, metric = 9.15% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.460738 * 2000, metric = 9.23% * 2000 921.037s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 17.75% * 2000;
 Minibatch[   1- 100]: loss = 0.444102 * 100, metric = 8.46% * 100;
 Minibatch[ 101- 200]: loss = 0.442022 * 100, metric = 8.75% * 100;
 Minibatch[ 201- 300]: loss = 0.455741 * 100, metric = 9.14% * 100;
 Minibatch[ 301- 400]: loss = 0.452349 * 100, metric = 9.00% * 100;
 Minibatch[ 401- 500]: loss = 0.451360 * 100, metric = 8.72% * 100;
 Minibatch[ 501- 600]: loss = 0.454690 * 100, metric = 9.04% * 100;
 Minibatch[ 601- 700]: loss = 0.448018 * 100, metric = 8.78% * 100;
 Minibatch[ 701- 800]: loss = 0.469186 * 100, metric = 9.44% * 100;
 Minibatch[ 801- 900]: loss = 0.461423 * 100, metric = 9.53% * 100;
 Minibatch[ 901-1000]: loss = 0.456080 * 100, metric = 9.25% * 100;
 Minibatch[1001-1100]: loss = 0.450959 * 100, metric = 9.07% * 100;
 Minibatch[1101-1200]: loss = 0.445113 * 100, metric = 8.72% * 100;
 Minibatch[1201-1300]: loss = 0.434700 * 100, metric = 8.41% * 100;
 Minibatch[1301-1400]: loss = 0.451382 * 100, metric = 9.10% * 100;
 Minibatch[1401-1500]: loss = 0.453741 * 100, metric = 9.01% * 100;
 Minibatch[1501-1600]: loss = 0.438036 * 100, metric = 8.84% * 100;
 Minibatch[1601-1700]: loss = 0.449566 * 100, metric = 8.86% * 100;
 Minibatch[1701-1800]: loss = 0.448480 * 100, metric = 8.73% * 100;
 Minibatch[1801-1900]: loss = 0.438947 * 100, metric = 8.65% * 100;
 Minibatch[1901-2000]: loss = 0.448580 * 100, metric = 8.90% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.449724 * 2000, metric = 8.92% * 2000 934.862s (  2.1 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 17.87% * 2000;
 Minibatch[   1- 100]: loss = 0.439949 * 100, metric = 8.66% * 100;
 Minibatch[ 101- 200]: loss = 0.446771 * 100, metric = 8.81% * 100;
 Minibatch[ 201- 300]: loss = 0.443317 * 100, metric = 8.67% * 100;
 Minibatch[ 301- 400]: loss = 0.434666 * 100, metric = 8.58% * 100;
 Minibatch[ 401- 500]: loss = 0.441700 * 100, metric = 8.81% * 100;
 Minibatch[ 501- 600]: loss = 0.431921 * 100, metric = 8.25% * 100;
 Minibatch[ 601- 700]: loss = 0.425140 * 100, metric = 8.24% * 100;
 Minibatch[ 701- 800]: loss = 0.447174 * 100, metric = 8.67% * 100;
 Minibatch[ 801- 900]: loss = 0.453177 * 100, metric = 9.17% * 100;
 Minibatch[ 901-1000]: loss = 0.442696 * 100, metric = 8.85% * 100;
 Minibatch[1001-1100]: loss = 0.445986 * 100, metric = 8.95% * 100;
 Minibatch[1101-1200]: loss = 0.440412 * 100, metric = 8.69% * 100;
 Minibatch[1201-1300]: loss = 0.431058 * 100, metric = 8.26% * 100;
 Minibatch[1301-1400]: loss = 0.450399 * 100, metric = 9.13% * 100;
 Minibatch[1401-1500]: loss = 0.411316 * 100, metric = 7.86% * 100;
 Minibatch[1501-1600]: loss = 0.432258 * 100, metric = 8.53% * 100;
 Minibatch[1601-1700]: loss = 0.438799 * 100, metric = 8.62% * 100;
 Minibatch[1701-1800]: loss = 0.426262 * 100, metric = 8.30% * 100;
 Minibatch[1801-1900]: loss = 0.434449 * 100, metric = 8.53% * 100;
 Minibatch[1901-2000]: loss = 0.433401 * 100, metric = 8.62% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.437543 * 2000, metric = 8.61% * 2000 930.156s (  2.2 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 15.14% * 2000;
 Minibatch[   1- 100]: loss = 0.446419 * 100, metric = 9.08% * 100;
 Minibatch[ 101- 200]: loss = 0.438169 * 100, metric = 8.51% * 100;
 Minibatch[ 201- 300]: loss = 0.437365 * 100, metric = 8.42% * 100;
 Minibatch[ 301- 400]: loss = 0.435997 * 100, metric = 8.53% * 100;
 Minibatch[ 401- 500]: loss = 0.414254 * 100, metric = 7.80% * 100;
 Minibatch[ 501- 600]: loss = 0.429133 * 100, metric = 8.49% * 100;
 Minibatch[ 601- 700]: loss = 0.427108 * 100, metric = 8.22% * 100;
 Minibatch[ 701- 800]: loss = 0.419835 * 100, metric = 7.97% * 100;
 Minibatch[ 801- 900]: loss = 0.420075 * 100, metric = 8.30% * 100;
 Minibatch[ 901-1000]: loss = 0.431501 * 100, metric = 8.57% * 100;
 Minibatch[1001-1100]: loss = 0.416564 * 100, metric = 8.21% * 100;
 Minibatch[1101-1200]: loss = 0.420765 * 100, metric = 8.12% * 100;
 Minibatch[1201-1300]: loss = 0.416426 * 100, metric = 8.04% * 100;
 Minibatch[1301-1400]: loss = 0.416569 * 100, metric = 7.97% * 100;
 Minibatch[1401-1500]: loss = 0.431278 * 100, metric = 8.72% * 100;
 Minibatch[1501-1600]: loss = 0.426255 * 100, metric = 8.32% * 100;
 Minibatch[1601-1700]: loss = 0.427479 * 100, metric = 8.55% * 100;
 Minibatch[1701-1800]: loss = 0.441999 * 100, metric = 8.58% * 100;
 Minibatch[1801-1900]: loss = 0.437642 * 100, metric = 8.62% * 100;
 Minibatch[1901-2000]: loss = 0.424315 * 100, metric = 8.49% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.427957 * 2000, metric = 8.38% * 2000 919.109s (  2.2 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.96% * 2000;
 Minibatch[   1- 100]: loss = 0.418014 * 100, metric = 8.15% * 100;
 Minibatch[ 101- 200]: loss = 0.439434 * 100, metric = 8.71% * 100;
 Minibatch[ 201- 300]: loss = 0.437906 * 100, metric = 8.59% * 100;
 Minibatch[ 301- 400]: loss = 0.425883 * 100, metric = 8.23% * 100;
 Minibatch[ 401- 500]: loss = 0.439886 * 100, metric = 8.56% * 100;
 Minibatch[ 501- 600]: loss = 0.423354 * 100, metric = 8.14% * 100;
 Minibatch[ 601- 700]: loss = 0.415298 * 100, metric = 7.95% * 100;
 Minibatch[ 701- 800]: loss = 0.423340 * 100, metric = 8.06% * 100;
 Minibatch[ 801- 900]: loss = 0.423497 * 100, metric = 8.39% * 100;
 Minibatch[ 901-1000]: loss = 0.421859 * 100, metric = 8.39% * 100;
 Minibatch[1001-1100]: loss = 0.422245 * 100, metric = 8.21% * 100;
 Minibatch[1101-1200]: loss = 0.436272 * 100, metric = 8.68% * 100;
 Minibatch[1201-1300]: loss = 0.444907 * 100, metric = 8.63% * 100;
 Minibatch[1301-1400]: loss = 0.412097 * 100, metric = 8.04% * 100;
 Minibatch[1401-1500]: loss = 0.423722 * 100, metric = 8.40% * 100;
 Minibatch[1501-1600]: loss = 0.421135 * 100, metric = 8.17% * 100;
 Minibatch[1601-1700]: loss = 0.425110 * 100, metric = 8.34% * 100;
 Minibatch[1701-1800]: loss = 0.413264 * 100, metric = 7.95% * 100;
 Minibatch[1801-1900]: loss = 0.428801 * 100, metric = 8.50% * 100;
 Minibatch[1901-2000]: loss = 0.436122 * 100, metric = 8.72% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.426607 * 2000, metric = 8.34% * 2000 911.215s (  2.2 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.27% * 2000;
0.5359728653505444
 Minibatch[   1- 100]: loss = 0.411603 * 100, metric = 7.78% * 100;
 Minibatch[ 101- 200]: loss = 0.435348 * 100, metric = 8.43% * 100;
 Minibatch[ 201- 300]: loss = 0.411515 * 100, metric = 7.93% * 100;
 Minibatch[ 301- 400]: loss = 0.427907 * 100, metric = 8.37% * 100;
 Minibatch[ 401- 500]: loss = 0.415357 * 100, metric = 7.93% * 100;
 Minibatch[ 501- 600]: loss = 0.415150 * 100, metric = 7.88% * 100;
 Minibatch[ 601- 700]: loss = 0.427012 * 100, metric = 8.35% * 100;
 Minibatch[ 701- 800]: loss = 0.399536 * 100, metric = 7.68% * 100;
 Minibatch[ 801- 900]: loss = 0.418136 * 100, metric = 8.03% * 100;
 Minibatch[ 901-1000]: loss = 0.419105 * 100, metric = 8.13% * 100;
 Minibatch[1001-1100]: loss = 0.430474 * 100, metric = 8.55% * 100;
 Minibatch[1101-1200]: loss = 0.425307 * 100, metric = 8.32% * 100;
 Minibatch[1201-1300]: loss = 0.425666 * 100, metric = 8.47% * 100;
 Minibatch[1301-1400]: loss = 0.424438 * 100, metric = 8.22% * 100;
 Minibatch[1401-1500]: loss = 0.401862 * 100, metric = 7.67% * 100;
 Minibatch[1501-1600]: loss = 0.409737 * 100, metric = 7.77% * 100;
 Minibatch[1601-1700]: loss = 0.395424 * 100, metric = 7.50% * 100;
 Minibatch[1701-1800]: loss = 0.408446 * 100, metric = 7.74% * 100;
 Minibatch[1801-1900]: loss = 0.398115 * 100, metric = 7.68% * 100;
 Minibatch[1901-2000]: loss = 0.405456 * 100, metric = 7.72% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.415280 * 2000, metric = 8.01% * 2000 898.856s (  2.2 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.55% * 2000;
 Minibatch[   1- 100]: loss = 0.416560 * 100, metric = 8.10% * 100;
 Minibatch[ 101- 200]: loss = 0.430331 * 100, metric = 8.20% * 100;
 Minibatch[ 201- 300]: loss = 0.401549 * 100, metric = 7.56% * 100;
 Minibatch[ 301- 400]: loss = 0.413493 * 100, metric = 7.86% * 100;
 Minibatch[ 401- 500]: loss = 0.412996 * 100, metric = 7.89% * 100;
 Minibatch[ 501- 600]: loss = 0.409800 * 100, metric = 7.70% * 100;
 Minibatch[ 601- 700]: loss = 0.413526 * 100, metric = 7.98% * 100;
 Minibatch[ 701- 800]: loss = 0.410561 * 100, metric = 7.96% * 100;
 Minibatch[ 801- 900]: loss = 0.428721 * 100, metric = 8.41% * 100;
 Minibatch[ 901-1000]: loss = 0.403561 * 100, metric = 7.71% * 100;
 Minibatch[1001-1100]: loss = 0.422298 * 100, metric = 8.13% * 100;
 Minibatch[1101-1200]: loss = 0.405728 * 100, metric = 7.98% * 100;
 Minibatch[1201-1300]: loss = 0.412797 * 100, metric = 8.02% * 100;
 Minibatch[1301-1400]: loss = 0.406621 * 100, metric = 7.79% * 100;
 Minibatch[1401-1500]: loss = 0.420535 * 100, metric = 8.31% * 100;
 Minibatch[1501-1600]: loss = 0.421804 * 100, metric = 8.23% * 100;
 Minibatch[1601-1700]: loss = 0.413852 * 100, metric = 8.16% * 100;
 Minibatch[1701-1800]: loss = 0.398174 * 100, metric = 7.70% * 100;
 Minibatch[1801-1900]: loss = 0.406308 * 100, metric = 7.82% * 100;
 Minibatch[1901-2000]: loss = 0.396474 * 100, metric = 7.48% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.412284 * 2000, metric = 7.95% * 2000 905.206s (  2.2 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 14.86% * 2000;
 Minibatch[   1- 100]: loss = 0.416484 * 100, metric = 7.89% * 100;
 Minibatch[ 101- 200]: loss = 0.403630 * 100, metric = 7.76% * 100;
 Minibatch[ 201- 300]: loss = 0.405044 * 100, metric = 7.54% * 100;
 Minibatch[ 301- 400]: loss = 0.416512 * 100, metric = 7.87% * 100;
 Minibatch[ 401- 500]: loss = 0.407452 * 100, metric = 7.72% * 100;
 Minibatch[ 501- 600]: loss = 0.414324 * 100, metric = 8.10% * 100;
 Minibatch[ 601- 700]: loss = 0.413661 * 100, metric = 8.12% * 100;
 Minibatch[ 701- 800]: loss = 0.405126 * 100, metric = 7.76% * 100;
 Minibatch[ 801- 900]: loss = 0.420825 * 100, metric = 8.17% * 100;
 Minibatch[ 901-1000]: loss = 0.427978 * 100, metric = 8.31% * 100;
 Minibatch[1001-1100]: loss = 0.395335 * 100, metric = 7.52% * 100;
 Minibatch[1101-1200]: loss = 0.409305 * 100, metric = 7.78% * 100;
 Minibatch[1201-1300]: loss = 0.414753 * 100, metric = 8.10% * 100;
 Minibatch[1301-1400]: loss = 0.414474 * 100, metric = 8.08% * 100;
 Minibatch[1401-1500]: loss = 0.404435 * 100, metric = 8.03% * 100;
 Minibatch[1501-1600]: loss = 0.420480 * 100, metric = 7.95% * 100;
 Minibatch[1601-1700]: loss = 0.404592 * 100, metric = 7.76% * 100;
 Minibatch[1701-1800]: loss = 0.420241 * 100, metric = 8.25% * 100;
 Minibatch[1801-1900]: loss = 0.409177 * 100, metric = 7.92% * 100;
 Minibatch[1901-2000]: loss = 0.404993 * 100, metric = 7.90% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.411441 * 2000, metric = 7.93% * 2000 902.366s (  2.2 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 14.61% * 2000;
 Minibatch[   1- 100]: loss = 0.416703 * 100, metric = 7.87% * 100;
 Minibatch[ 101- 200]: loss = 0.410027 * 100, metric = 7.86% * 100;
 Minibatch[ 201- 300]: loss = 0.405680 * 100, metric = 8.04% * 100;
 Minibatch[ 301- 400]: loss = 0.410333 * 100, metric = 8.01% * 100;
 Minibatch[ 401- 500]: loss = 0.394390 * 100, metric = 7.74% * 100;
 Minibatch[ 501- 600]: loss = 0.397138 * 100, metric = 7.66% * 100;
 Minibatch[ 601- 700]: loss = 0.401886 * 100, metric = 7.63% * 100;
 Minibatch[ 701- 800]: loss = 0.377083 * 100, metric = 7.05% * 100;
 Minibatch[ 801- 900]: loss = 0.408606 * 100, metric = 8.00% * 100;
 Minibatch[ 901-1000]: loss = 0.392745 * 100, metric = 7.53% * 100;
 Minibatch[1001-1100]: loss = 0.394625 * 100, metric = 7.58% * 100;
 Minibatch[1101-1200]: loss = 0.392258 * 100, metric = 7.35% * 100;
 Minibatch[1201-1300]: loss = 0.408319 * 100, metric = 7.62% * 100;
 Minibatch[1301-1400]: loss = 0.394814 * 100, metric = 7.43% * 100;
 Minibatch[1401-1500]: loss = 0.407517 * 100, metric = 7.65% * 100;
 Minibatch[1501-1600]: loss = 0.409734 * 100, metric = 8.13% * 100;
 Minibatch[1601-1700]: loss = 0.400609 * 100, metric = 7.85% * 100;
 Minibatch[1701-1800]: loss = 0.404355 * 100, metric = 7.65% * 100;
 Minibatch[1801-1900]: loss = 0.412360 * 100, metric = 8.03% * 100;
 Minibatch[1901-2000]: loss = 0.391788 * 100, metric = 7.47% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.401549 * 2000, metric = 7.71% * 2000 901.242s (  2.2 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 13.93% * 2000;
0.5304887567721307
 Minibatch[   1- 100]: loss = 0.406938 * 100, metric = 7.72% * 100;
 Minibatch[ 101- 200]: loss = 0.403402 * 100, metric = 7.77% * 100;
 Minibatch[ 201- 300]: loss = 0.407638 * 100, metric = 7.90% * 100;
 Minibatch[ 301- 400]: loss = 0.393955 * 100, metric = 7.58% * 100;
 Minibatch[ 401- 500]: loss = 0.390874 * 100, metric = 7.31% * 100;
 Minibatch[ 501- 600]: loss = 0.404904 * 100, metric = 7.78% * 100;
 Minibatch[ 601- 700]: loss = 0.389315 * 100, metric = 7.44% * 100;
 Minibatch[ 701- 800]: loss = 0.391928 * 100, metric = 7.46% * 100;
 Minibatch[ 801- 900]: loss = 0.395606 * 100, metric = 7.56% * 100;
 Minibatch[ 901-1000]: loss = 0.396386 * 100, metric = 7.46% * 100;
 Minibatch[1001-1100]: loss = 0.380630 * 100, metric = 7.12% * 100;
 Minibatch[1101-1200]: loss = 0.373794 * 100, metric = 6.99% * 100;
 Minibatch[1201-1300]: loss = 0.385987 * 100, metric = 7.48% * 100;
 Minibatch[1301-1400]: loss = 0.388676 * 100, metric = 7.44% * 100;
 Minibatch[1401-1500]: loss = 0.384205 * 100, metric = 7.39% * 100;
 Minibatch[1501-1600]: loss = 0.381026 * 100, metric = 7.21% * 100;
 Minibatch[1601-1700]: loss = 0.385223 * 100, metric = 7.36% * 100;
 Minibatch[1701-1800]: loss = 0.389102 * 100, metric = 7.38% * 100;
 Minibatch[1801-1900]: loss = 0.392875 * 100, metric = 7.65% * 100;
 Minibatch[1901-2000]: loss = 0.385164 * 100, metric = 7.19% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.391381 * 2000, metric = 7.46% * 2000 897.124s (  2.2 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 14.80% * 2000;
 Minibatch[   1- 100]: loss = 0.400671 * 100, metric = 7.56% * 100;
 Minibatch[ 101- 200]: loss = 0.400920 * 100, metric = 7.77% * 100;
 Minibatch[ 201- 300]: loss = 0.390890 * 100, metric = 7.51% * 100;
 Minibatch[ 301- 400]: loss = 0.396342 * 100, metric = 7.75% * 100;
 Minibatch[ 401- 500]: loss = 0.398638 * 100, metric = 7.71% * 100;
 Minibatch[ 501- 600]: loss = 0.390638 * 100, metric = 7.29% * 100;
 Minibatch[ 601- 700]: loss = 0.402104 * 100, metric = 7.55% * 100;
 Minibatch[ 701- 800]: loss = 0.376099 * 100, metric = 7.15% * 100;
 Minibatch[ 801- 900]: loss = 0.374774 * 100, metric = 7.19% * 100;
 Minibatch[ 901-1000]: loss = 0.396678 * 100, metric = 7.53% * 100;
 Minibatch[1001-1100]: loss = 0.385188 * 100, metric = 7.32% * 100;
 Minibatch[1101-1200]: loss = 0.382825 * 100, metric = 7.47% * 100;
 Minibatch[1201-1300]: loss = 0.392758 * 100, metric = 7.47% * 100;
 Minibatch[1301-1400]: loss = 0.388938 * 100, metric = 7.36% * 100;
 Minibatch[1401-1500]: loss = 0.375346 * 100, metric = 7.08% * 100;
 Minibatch[1501-1600]: loss = 0.389094 * 100, metric = 7.35% * 100;
 Minibatch[1601-1700]: loss = 0.389254 * 100, metric = 7.52% * 100;
 Minibatch[1701-1800]: loss = 0.380668 * 100, metric = 7.16% * 100;
 Minibatch[1801-1900]: loss = 0.382251 * 100, metric = 7.46% * 100;
 Minibatch[1901-2000]: loss = 0.391851 * 100, metric = 7.38% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.389296 * 2000, metric = 7.43% * 2000 890.594s (  2.2 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 14.98% * 2000;
 Minibatch[   1- 100]: loss = 0.370991 * 100, metric = 7.04% * 100;
 Minibatch[ 101- 200]: loss = 0.386486 * 100, metric = 7.24% * 100;
 Minibatch[ 201- 300]: loss = 0.380891 * 100, metric = 7.19% * 100;
 Minibatch[ 301- 400]: loss = 0.378801 * 100, metric = 7.20% * 100;
 Minibatch[ 401- 500]: loss = 0.382522 * 100, metric = 7.28% * 100;
 Minibatch[ 501- 600]: loss = 0.371676 * 100, metric = 7.18% * 100;
 Minibatch[ 601- 700]: loss = 0.390110 * 100, metric = 7.14% * 100;
 Minibatch[ 701- 800]: loss = 0.378741 * 100, metric = 7.37% * 100;
 Minibatch[ 801- 900]: loss = 0.396124 * 100, metric = 7.56% * 100;
 Minibatch[ 901-1000]: loss = 0.380495 * 100, metric = 7.20% * 100;
 Minibatch[1001-1100]: loss = 0.376718 * 100, metric = 7.19% * 100;
 Minibatch[1101-1200]: loss = 0.396170 * 100, metric = 7.59% * 100;
 Minibatch[1201-1300]: loss = 0.387258 * 100, metric = 7.20% * 100;
 Minibatch[1301-1400]: loss = 0.385787 * 100, metric = 7.28% * 100;
 Minibatch[1401-1500]: loss = 0.379373 * 100, metric = 7.30% * 100;
 Minibatch[1501-1600]: loss = 0.392368 * 100, metric = 7.52% * 100;
 Minibatch[1601-1700]: loss = 0.372874 * 100, metric = 6.80% * 100;
 Minibatch[1701-1800]: loss = 0.374042 * 100, metric = 6.86% * 100;
 Minibatch[1801-1900]: loss = 0.384783 * 100, metric = 7.24% * 100;
 Minibatch[1901-2000]: loss = 0.387756 * 100, metric = 7.40% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.382698 * 2000, metric = 7.24% * 2000 887.796s (  2.3 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.12% * 2000;
 Minibatch[   1- 100]: loss = 0.385419 * 100, metric = 7.33% * 100;
 Minibatch[ 101- 200]: loss = 0.379507 * 100, metric = 7.35% * 100;
 Minibatch[ 201- 300]: loss = 0.382898 * 100, metric = 7.39% * 100;
 Minibatch[ 301- 400]: loss = 0.385409 * 100, metric = 7.35% * 100;
 Minibatch[ 401- 500]: loss = 0.383986 * 100, metric = 7.20% * 100;
 Minibatch[ 501- 600]: loss = 0.375417 * 100, metric = 7.14% * 100;
 Minibatch[ 601- 700]: loss = 0.385151 * 100, metric = 7.31% * 100;
 Minibatch[ 701- 800]: loss = 0.371161 * 100, metric = 7.02% * 100;
 Minibatch[ 801- 900]: loss = 0.375012 * 100, metric = 7.12% * 100;
 Minibatch[ 901-1000]: loss = 0.378760 * 100, metric = 7.33% * 100;
 Minibatch[1001-1100]: loss = 0.382300 * 100, metric = 7.32% * 100;
 Minibatch[1101-1200]: loss = 0.386573 * 100, metric = 7.44% * 100;
 Minibatch[1201-1300]: loss = 0.396765 * 100, metric = 7.73% * 100;
 Minibatch[1301-1400]: loss = 0.382180 * 100, metric = 7.23% * 100;
 Minibatch[1401-1500]: loss = 0.372969 * 100, metric = 6.97% * 100;
 Minibatch[1501-1600]: loss = 0.397444 * 100, metric = 7.73% * 100;
 Minibatch[1601-1700]: loss = 0.378769 * 100, metric = 7.22% * 100;
 Minibatch[1701-1800]: loss = 0.381562 * 100, metric = 7.39% * 100;
 Minibatch[1801-1900]: loss = 0.374805 * 100, metric = 7.01% * 100;
 Minibatch[1901-2000]: loss = 0.370353 * 100, metric = 6.85% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.381322 * 2000, metric = 7.27% * 2000 891.254s (  2.2 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.29% * 2000;
 Minibatch[   1- 100]: loss = 0.375344 * 100, metric = 7.18% * 100;
 Minibatch[ 101- 200]: loss = 0.364478 * 100, metric = 6.93% * 100;
 Minibatch[ 201- 300]: loss = 0.386582 * 100, metric = 7.57% * 100;
 Minibatch[ 301- 400]: loss = 0.368172 * 100, metric = 6.90% * 100;
 Minibatch[ 401- 500]: loss = 0.376677 * 100, metric = 7.26% * 100;
 Minibatch[ 501- 600]: loss = 0.369252 * 100, metric = 6.76% * 100;
 Minibatch[ 601- 700]: loss = 0.378552 * 100, metric = 7.27% * 100;
 Minibatch[ 701- 800]: loss = 0.369726 * 100, metric = 7.17% * 100;
 Minibatch[ 801- 900]: loss = 0.358732 * 100, metric = 6.71% * 100;
 Minibatch[ 901-1000]: loss = 0.362245 * 100, metric = 6.80% * 100;
 Minibatch[1001-1100]: loss = 0.379580 * 100, metric = 7.27% * 100;
 Minibatch[1101-1200]: loss = 0.382334 * 100, metric = 7.22% * 100;
 Minibatch[1201-1300]: loss = 0.376468 * 100, metric = 7.19% * 100;
 Minibatch[1301-1400]: loss = 0.357730 * 100, metric = 6.61% * 100;
 Minibatch[1401-1500]: loss = 0.370264 * 100, metric = 7.07% * 100;
 Minibatch[1501-1600]: loss = 0.372003 * 100, metric = 7.02% * 100;
 Minibatch[1601-1700]: loss = 0.385139 * 100, metric = 7.44% * 100;
 Minibatch[1701-1800]: loss = 0.376401 * 100, metric = 7.10% * 100;
 Minibatch[1801-1900]: loss = 0.366011 * 100, metric = 6.70% * 100;
 Minibatch[1901-2000]: loss = 0.370444 * 100, metric = 6.98% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.372307 * 2000, metric = 7.06% * 2000 880.989s (  2.3 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 14.36% * 2000;
 Minibatch[   1- 100]: loss = 0.361941 * 100, metric = 6.69% * 100;
 Minibatch[ 101- 200]: loss = 0.380336 * 100, metric = 7.26% * 100;
 Minibatch[ 201- 300]: loss = 0.367540 * 100, metric = 6.78% * 100;
 Minibatch[ 301- 400]: loss = 0.364296 * 100, metric = 6.82% * 100;
 Minibatch[ 401- 500]: loss = 0.363524 * 100, metric = 6.86% * 100;
 Minibatch[ 501- 600]: loss = 0.364188 * 100, metric = 6.82% * 100;
 Minibatch[ 601- 700]: loss = 0.361729 * 100, metric = 6.71% * 100;
 Minibatch[ 701- 800]: loss = 0.368744 * 100, metric = 6.86% * 100;
 Minibatch[ 801- 900]: loss = 0.375982 * 100, metric = 6.97% * 100;
 Minibatch[ 901-1000]: loss = 0.370129 * 100, metric = 7.09% * 100;
 Minibatch[1001-1100]: loss = 0.364242 * 100, metric = 6.80% * 100;
 Minibatch[1101-1200]: loss = 0.375811 * 100, metric = 7.04% * 100;
 Minibatch[1201-1300]: loss = 0.370531 * 100, metric = 6.97% * 100;
 Minibatch[1301-1400]: loss = 0.378460 * 100, metric = 7.21% * 100;
 Minibatch[1401-1500]: loss = 0.363636 * 100, metric = 6.81% * 100;
 Minibatch[1501-1600]: loss = 0.366986 * 100, metric = 6.70% * 100;
 Minibatch[1601-1700]: loss = 0.352949 * 100, metric = 6.64% * 100;
 Minibatch[1701-1800]: loss = 0.365220 * 100, metric = 6.73% * 100;
 Minibatch[1801-1900]: loss = 0.362988 * 100, metric = 6.95% * 100;
 Minibatch[1901-2000]: loss = 0.369150 * 100, metric = 6.95% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.367419 * 2000, metric = 6.88% * 2000 885.603s (  2.3 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.31% * 2000;
 Minibatch[   1- 100]: loss = 0.373387 * 100, metric = 7.14% * 100;
 Minibatch[ 101- 200]: loss = 0.354759 * 100, metric = 6.47% * 100;
 Minibatch[ 201- 300]: loss = 0.366261 * 100, metric = 6.81% * 100;
 Minibatch[ 301- 400]: loss = 0.361219 * 100, metric = 6.72% * 100;
 Minibatch[ 401- 500]: loss = 0.362452 * 100, metric = 6.90% * 100;
 Minibatch[ 501- 600]: loss = 0.380638 * 100, metric = 7.42% * 100;
 Minibatch[ 601- 700]: loss = 0.358923 * 100, metric = 6.61% * 100;
 Minibatch[ 701- 800]: loss = 0.354659 * 100, metric = 6.62% * 100;
 Minibatch[ 801- 900]: loss = 0.366044 * 100, metric = 6.98% * 100;
 Minibatch[ 901-1000]: loss = 0.370283 * 100, metric = 7.13% * 100;
 Minibatch[1001-1100]: loss = 0.362552 * 100, metric = 6.79% * 100;
 Minibatch[1101-1200]: loss = 0.356143 * 100, metric = 6.71% * 100;
 Minibatch[1201-1300]: loss = 0.363698 * 100, metric = 6.79% * 100;
 Minibatch[1301-1400]: loss = 0.363847 * 100, metric = 6.74% * 100;
 Minibatch[1401-1500]: loss = 0.375177 * 100, metric = 6.87% * 100;
 Minibatch[1501-1600]: loss = 0.362507 * 100, metric = 6.70% * 100;
 Minibatch[1601-1700]: loss = 0.363861 * 100, metric = 6.64% * 100;
 Minibatch[1701-1800]: loss = 0.355688 * 100, metric = 6.58% * 100;
 Minibatch[1801-1900]: loss = 0.361182 * 100, metric = 6.84% * 100;
 Minibatch[1901-2000]: loss = 0.368342 * 100, metric = 6.90% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.364081 * 2000, metric = 6.82% * 2000 877.257s (  2.3 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.33% * 2000;
0.5237505037412047
 Minibatch[   1- 100]: loss = 0.354258 * 100, metric = 6.62% * 100;
 Minibatch[ 101- 200]: loss = 0.353270 * 100, metric = 6.60% * 100;
 Minibatch[ 201- 300]: loss = 0.367573 * 100, metric = 6.94% * 100;
 Minibatch[ 301- 400]: loss = 0.381552 * 100, metric = 7.14% * 100;
 Minibatch[ 401- 500]: loss = 0.357003 * 100, metric = 6.61% * 100;
 Minibatch[ 501- 600]: loss = 0.362811 * 100, metric = 6.79% * 100;
 Minibatch[ 601- 700]: loss = 0.365026 * 100, metric = 6.91% * 100;
 Minibatch[ 701- 800]: loss = 0.369661 * 100, metric = 7.04% * 100;
 Minibatch[ 801- 900]: loss = 0.364304 * 100, metric = 6.94% * 100;
 Minibatch[ 901-1000]: loss = 0.367395 * 100, metric = 6.97% * 100;
 Minibatch[1001-1100]: loss = 0.366406 * 100, metric = 6.99% * 100;
 Minibatch[1101-1200]: loss = 0.352196 * 100, metric = 6.59% * 100;
 Minibatch[1201-1300]: loss = 0.360999 * 100, metric = 6.61% * 100;
 Minibatch[1301-1400]: loss = 0.360698 * 100, metric = 6.95% * 100;
 Minibatch[1401-1500]: loss = 0.371236 * 100, metric = 7.03% * 100;
 Minibatch[1501-1600]: loss = 0.348755 * 100, metric = 6.42% * 100;
 Minibatch[1601-1700]: loss = 0.366368 * 100, metric = 6.90% * 100;
 Minibatch[1701-1800]: loss = 0.355074 * 100, metric = 6.57% * 100;
 Minibatch[1801-1900]: loss = 0.371288 * 100, metric = 7.08% * 100;
 Minibatch[1901-2000]: loss = 0.365206 * 100, metric = 6.84% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.363054 * 2000, metric = 6.83% * 2000 883.507s (  2.3 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 15.26% * 2000;
 Minibatch[   1- 100]: loss = 0.374416 * 100, metric = 7.00% * 100;
 Minibatch[ 101- 200]: loss = 0.344021 * 100, metric = 6.26% * 100;
 Minibatch[ 201- 300]: loss = 0.358233 * 100, metric = 6.63% * 100;
 Minibatch[ 301- 400]: loss = 0.362488 * 100, metric = 7.10% * 100;
 Minibatch[ 401- 500]: loss = 0.358074 * 100, metric = 6.58% * 100;
 Minibatch[ 501- 600]: loss = 0.341521 * 100, metric = 6.22% * 100;
 Minibatch[ 601- 700]: loss = 0.363548 * 100, metric = 6.97% * 100;
 Minibatch[ 701- 800]: loss = 0.353456 * 100, metric = 6.58% * 100;
 Minibatch[ 801- 900]: loss = 0.362498 * 100, metric = 6.79% * 100;
 Minibatch[ 901-1000]: loss = 0.339482 * 100, metric = 6.45% * 100;
 Minibatch[1001-1100]: loss = 0.354594 * 100, metric = 6.48% * 100;
 Minibatch[1101-1200]: loss = 0.359210 * 100, metric = 6.69% * 100;
 Minibatch[1201-1300]: loss = 0.350077 * 100, metric = 6.38% * 100;
 Minibatch[1301-1400]: loss = 0.350952 * 100, metric = 6.50% * 100;
 Minibatch[1401-1500]: loss = 0.356924 * 100, metric = 6.64% * 100;
 Minibatch[1501-1600]: loss = 0.374761 * 100, metric = 6.92% * 100;
 Minibatch[1601-1700]: loss = 0.360499 * 100, metric = 6.82% * 100;
 Minibatch[1701-1800]: loss = 0.366827 * 100, metric = 6.92% * 100;
 Minibatch[1801-1900]: loss = 0.356925 * 100, metric = 6.77% * 100;
 Minibatch[1901-2000]: loss = 0.373206 * 100, metric = 6.95% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.358086 * 2000, metric = 6.68% * 2000 884.785s (  2.3 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.38% * 2000;
 Minibatch[   1- 100]: loss = 0.354623 * 100, metric = 6.56% * 100;
 Minibatch[ 101- 200]: loss = 0.362685 * 100, metric = 6.97% * 100;
 Minibatch[ 201- 300]: loss = 0.358002 * 100, metric = 6.95% * 100;
 Minibatch[ 301- 400]: loss = 0.354351 * 100, metric = 6.48% * 100;
 Minibatch[ 401- 500]: loss = 0.357442 * 100, metric = 6.66% * 100;
 Minibatch[ 501- 600]: loss = 0.361633 * 100, metric = 6.84% * 100;
 Minibatch[ 601- 700]: loss = 0.377643 * 100, metric = 7.24% * 100;
 Minibatch[ 701- 800]: loss = 0.370739 * 100, metric = 6.96% * 100;
 Minibatch[ 801- 900]: loss = 0.363028 * 100, metric = 6.76% * 100;
 Minibatch[ 901-1000]: loss = 0.354828 * 100, metric = 6.62% * 100;
 Minibatch[1001-1100]: loss = 0.356712 * 100, metric = 6.56% * 100;
 Minibatch[1101-1200]: loss = 0.361816 * 100, metric = 7.03% * 100;
 Minibatch[1201-1300]: loss = 0.361762 * 100, metric = 6.76% * 100;
 Minibatch[1301-1400]: loss = 0.360169 * 100, metric = 6.84% * 100;
 Minibatch[1401-1500]: loss = 0.367300 * 100, metric = 6.76% * 100;
 Minibatch[1501-1600]: loss = 0.345291 * 100, metric = 6.43% * 100;
 Minibatch[1601-1700]: loss = 0.353999 * 100, metric = 6.40% * 100;
 Minibatch[1701-1800]: loss = 0.352668 * 100, metric = 6.62% * 100;
 Minibatch[1801-1900]: loss = 0.359897 * 100, metric = 6.71% * 100;
 Minibatch[1901-2000]: loss = 0.352996 * 100, metric = 6.62% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.359379 * 2000, metric = 6.74% * 2000 874.088s (  2.3 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 13.83% * 2000;
 Minibatch[   1- 100]: loss = 0.353371 * 100, metric = 6.61% * 100;
 Minibatch[ 101- 200]: loss = 0.360666 * 100, metric = 6.62% * 100;
 Minibatch[ 201- 300]: loss = 0.370435 * 100, metric = 7.07% * 100;
 Minibatch[ 301- 400]: loss = 0.371928 * 100, metric = 7.04% * 100;
 Minibatch[ 401- 500]: loss = 0.361694 * 100, metric = 6.89% * 100;
 Minibatch[ 501- 600]: loss = 0.355524 * 100, metric = 6.88% * 100;
 Minibatch[ 601- 700]: loss = 0.350820 * 100, metric = 6.55% * 100;
 Minibatch[ 701- 800]: loss = 0.353479 * 100, metric = 6.73% * 100;
 Minibatch[ 801- 900]: loss = 0.358041 * 100, metric = 6.60% * 100;
 Minibatch[ 901-1000]: loss = 0.342572 * 100, metric = 6.38% * 100;
 Minibatch[1001-1100]: loss = 0.351373 * 100, metric = 6.46% * 100;
 Minibatch[1101-1200]: loss = 0.350992 * 100, metric = 6.50% * 100;
 Minibatch[1201-1300]: loss = 0.360812 * 100, metric = 6.68% * 100;
 Minibatch[1301-1400]: loss = 0.345105 * 100, metric = 6.40% * 100;
 Minibatch[1401-1500]: loss = 0.349405 * 100, metric = 6.65% * 100;
 Minibatch[1501-1600]: loss = 0.347333 * 100, metric = 6.27% * 100;
 Minibatch[1601-1700]: loss = 0.343046 * 100, metric = 6.39% * 100;
 Minibatch[1701-1800]: loss = 0.365505 * 100, metric = 6.78% * 100;
 Minibatch[1801-1900]: loss = 0.344533 * 100, metric = 6.52% * 100;
 Minibatch[1901-2000]: loss = 0.348777 * 100, metric = 6.59% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.354271 * 2000, metric = 6.63% * 2000 883.992s (  2.3 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.72% * 2000;
 Minibatch[   1- 100]: loss = 0.365482 * 100, metric = 6.93% * 100;
 Minibatch[ 101- 200]: loss = 0.352818 * 100, metric = 6.73% * 100;
 Minibatch[ 201- 300]: loss = 0.342402 * 100, metric = 6.49% * 100;
 Minibatch[ 301- 400]: loss = 0.352574 * 100, metric = 6.76% * 100;
 Minibatch[ 401- 500]: loss = 0.343964 * 100, metric = 6.61% * 100;
 Minibatch[ 501- 600]: loss = 0.353702 * 100, metric = 6.62% * 100;
 Minibatch[ 601- 700]: loss = 0.361408 * 100, metric = 6.88% * 100;
 Minibatch[ 701- 800]: loss = 0.353272 * 100, metric = 6.58% * 100;
 Minibatch[ 801- 900]: loss = 0.349252 * 100, metric = 6.46% * 100;
 Minibatch[ 901-1000]: loss = 0.332948 * 100, metric = 6.10% * 100;
 Minibatch[1001-1100]: loss = 0.341591 * 100, metric = 6.40% * 100;
 Minibatch[1101-1200]: loss = 0.335473 * 100, metric = 6.12% * 100;
 Minibatch[1201-1300]: loss = 0.363643 * 100, metric = 6.52% * 100;
 Minibatch[1301-1400]: loss = 0.337265 * 100, metric = 6.12% * 100;
 Minibatch[1401-1500]: loss = 0.361456 * 100, metric = 6.70% * 100;
 Minibatch[1501-1600]: loss = 0.360446 * 100, metric = 6.60% * 100;
 Minibatch[1601-1700]: loss = 0.344371 * 100, metric = 6.08% * 100;
 Minibatch[1701-1800]: loss = 0.340568 * 100, metric = 6.36% * 100;
 Minibatch[1801-1900]: loss = 0.340911 * 100, metric = 6.28% * 100;
 Minibatch[1901-2000]: loss = 0.355013 * 100, metric = 6.90% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.349428 * 2000, metric = 6.51% * 2000 873.807s (  2.3 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.00% * 2000;
 Minibatch[   1- 100]: loss = 0.338821 * 100, metric = 6.06% * 100;
 Minibatch[ 101- 200]: loss = 0.351186 * 100, metric = 6.45% * 100;
 Minibatch[ 201- 300]: loss = 0.337076 * 100, metric = 6.17% * 100;
 Minibatch[ 301- 400]: loss = 0.347274 * 100, metric = 6.48% * 100;
 Minibatch[ 401- 500]: loss = 0.340826 * 100, metric = 6.28% * 100;
 Minibatch[ 501- 600]: loss = 0.352290 * 100, metric = 6.54% * 100;
 Minibatch[ 601- 700]: loss = 0.352367 * 100, metric = 6.74% * 100;
 Minibatch[ 701- 800]: loss = 0.340673 * 100, metric = 6.37% * 100;
 Minibatch[ 801- 900]: loss = 0.331776 * 100, metric = 6.03% * 100;
 Minibatch[ 901-1000]: loss = 0.339466 * 100, metric = 6.32% * 100;
 Minibatch[1001-1100]: loss = 0.350252 * 100, metric = 6.67% * 100;
 Minibatch[1101-1200]: loss = 0.339299 * 100, metric = 6.38% * 100;
 Minibatch[1201-1300]: loss = 0.348067 * 100, metric = 6.45% * 100;
 Minibatch[1301-1400]: loss = 0.348665 * 100, metric = 6.42% * 100;
 Minibatch[1401-1500]: loss = 0.353851 * 100, metric = 6.57% * 100;
 Minibatch[1501-1600]: loss = 0.345488 * 100, metric = 6.32% * 100;
 Minibatch[1601-1700]: loss = 0.361251 * 100, metric = 6.88% * 100;
 Minibatch[1701-1800]: loss = 0.352251 * 100, metric = 6.60% * 100;
 Minibatch[1801-1900]: loss = 0.339972 * 100, metric = 6.25% * 100;
 Minibatch[1901-2000]: loss = 0.342546 * 100, metric = 6.41% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.345670 * 2000, metric = 6.42% * 2000 878.952s (  2.3 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 13.76% * 2000;
 Minibatch[   1- 100]: loss = 0.328535 * 100, metric = 5.94% * 100;
 Minibatch[ 101- 200]: loss = 0.339739 * 100, metric = 6.42% * 100;
 Minibatch[ 201- 300]: loss = 0.339669 * 100, metric = 6.12% * 100;
 Minibatch[ 301- 400]: loss = 0.326083 * 100, metric = 5.81% * 100;
 Minibatch[ 401- 500]: loss = 0.336957 * 100, metric = 6.24% * 100;
 Minibatch[ 501- 600]: loss = 0.322473 * 100, metric = 5.84% * 100;
 Minibatch[ 601- 700]: loss = 0.347983 * 100, metric = 6.34% * 100;
 Minibatch[ 701- 800]: loss = 0.322460 * 100, metric = 5.82% * 100;
 Minibatch[ 801- 900]: loss = 0.337581 * 100, metric = 6.13% * 100;
 Minibatch[ 901-1000]: loss = 0.327421 * 100, metric = 5.96% * 100;
 Minibatch[1001-1100]: loss = 0.352744 * 100, metric = 6.35% * 100;
 Minibatch[1101-1200]: loss = 0.341425 * 100, metric = 6.30% * 100;
 Minibatch[1201-1300]: loss = 0.336677 * 100, metric = 6.31% * 100;
 Minibatch[1301-1400]: loss = 0.346221 * 100, metric = 6.51% * 100;
 Minibatch[1401-1500]: loss = 0.344380 * 100, metric = 6.33% * 100;
 Minibatch[1501-1600]: loss = 0.344922 * 100, metric = 6.29% * 100;
 Minibatch[1601-1700]: loss = 0.341705 * 100, metric = 6.27% * 100;
 Minibatch[1701-1800]: loss = 0.325638 * 100, metric = 6.07% * 100;
 Minibatch[1801-1900]: loss = 0.345265 * 100, metric = 6.49% * 100;
 Minibatch[1901-2000]: loss = 0.331255 * 100, metric = 6.07% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.336957 * 2000, metric = 6.18% * 2000 874.826s (  2.3 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.45% * 2000;
 Minibatch[   1- 100]: loss = 0.325485 * 100, metric = 5.86% * 100;
 Minibatch[ 101- 200]: loss = 0.318849 * 100, metric = 5.79% * 100;
 Minibatch[ 201- 300]: loss = 0.346034 * 100, metric = 6.56% * 100;
 Minibatch[ 301- 400]: loss = 0.330794 * 100, metric = 6.13% * 100;
 Minibatch[ 401- 500]: loss = 0.329554 * 100, metric = 5.92% * 100;
 Minibatch[ 501- 600]: loss = 0.332325 * 100, metric = 6.17% * 100;
 Minibatch[ 601- 700]: loss = 0.340447 * 100, metric = 6.11% * 100;
 Minibatch[ 701- 800]: loss = 0.320420 * 100, metric = 5.96% * 100;
 Minibatch[ 801- 900]: loss = 0.326021 * 100, metric = 6.16% * 100;
 Minibatch[ 901-1000]: loss = 0.349150 * 100, metric = 6.52% * 100;
 Minibatch[1001-1100]: loss = 0.344988 * 100, metric = 6.54% * 100;
 Minibatch[1101-1200]: loss = 0.332453 * 100, metric = 6.12% * 100;
 Minibatch[1201-1300]: loss = 0.333175 * 100, metric = 6.30% * 100;
 Minibatch[1301-1400]: loss = 0.316573 * 100, metric = 5.72% * 100;
 Minibatch[1401-1500]: loss = 0.332764 * 100, metric = 6.19% * 100;
 Minibatch[1501-1600]: loss = 0.330697 * 100, metric = 6.06% * 100;
 Minibatch[1601-1700]: loss = 0.338303 * 100, metric = 6.28% * 100;
 Minibatch[1701-1800]: loss = 0.332621 * 100, metric = 6.18% * 100;
 Minibatch[1801-1900]: loss = 0.333589 * 100, metric = 6.11% * 100;
 Minibatch[1901-2000]: loss = 0.326132 * 100, metric = 5.94% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.332019 * 2000, metric = 6.13% * 2000 873.055s (  2.3 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.28% * 2000;
 Minibatch[   1- 100]: loss = 0.337578 * 100, metric = 6.47% * 100;
 Minibatch[ 101- 200]: loss = 0.337445 * 100, metric = 6.41% * 100;
 Minibatch[ 201- 300]: loss = 0.333844 * 100, metric = 6.18% * 100;
 Minibatch[ 301- 400]: loss = 0.339271 * 100, metric = 6.28% * 100;
 Minibatch[ 401- 500]: loss = 0.332627 * 100, metric = 6.31% * 100;
 Minibatch[ 501- 600]: loss = 0.316950 * 100, metric = 5.96% * 100;
 Minibatch[ 601- 700]: loss = 0.323183 * 100, metric = 5.91% * 100;
 Minibatch[ 701- 800]: loss = 0.330580 * 100, metric = 6.17% * 100;
 Minibatch[ 801- 900]: loss = 0.329807 * 100, metric = 6.03% * 100;
 Minibatch[ 901-1000]: loss = 0.313757 * 100, metric = 5.45% * 100;
 Minibatch[1001-1100]: loss = 0.320039 * 100, metric = 5.76% * 100;
 Minibatch[1101-1200]: loss = 0.341250 * 100, metric = 6.29% * 100;
 Minibatch[1201-1300]: loss = 0.344283 * 100, metric = 6.31% * 100;
 Minibatch[1301-1400]: loss = 0.330574 * 100, metric = 5.82% * 100;
 Minibatch[1401-1500]: loss = 0.327674 * 100, metric = 5.98% * 100;
 Minibatch[1501-1600]: loss = 0.322623 * 100, metric = 5.75% * 100;
 Minibatch[1601-1700]: loss = 0.326927 * 100, metric = 6.15% * 100;
 Minibatch[1701-1800]: loss = 0.331204 * 100, metric = 5.91% * 100;
 Minibatch[1801-1900]: loss = 0.336907 * 100, metric = 6.25% * 100;
 Minibatch[1901-2000]: loss = 0.329280 * 100, metric = 5.98% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.330290 * 2000, metric = 6.07% * 2000 877.058s (  2.3 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.39% * 2000;
 Minibatch[   1- 100]: loss = 0.338265 * 100, metric = 6.21% * 100;
 Minibatch[ 101- 200]: loss = 0.324951 * 100, metric = 5.87% * 100;
 Minibatch[ 201- 300]: loss = 0.310463 * 100, metric = 5.39% * 100;
 Minibatch[ 301- 400]: loss = 0.316152 * 100, metric = 5.64% * 100;
 Minibatch[ 401- 500]: loss = 0.324692 * 100, metric = 5.86% * 100;
 Minibatch[ 501- 600]: loss = 0.337198 * 100, metric = 6.01% * 100;
 Minibatch[ 601- 700]: loss = 0.326013 * 100, metric = 6.07% * 100;
 Minibatch[ 701- 800]: loss = 0.323175 * 100, metric = 5.87% * 100;
 Minibatch[ 801- 900]: loss = 0.335461 * 100, metric = 5.98% * 100;
 Minibatch[ 901-1000]: loss = 0.332735 * 100, metric = 5.87% * 100;
 Minibatch[1001-1100]: loss = 0.332160 * 100, metric = 6.07% * 100;
 Minibatch[1101-1200]: loss = 0.320554 * 100, metric = 6.11% * 100;
 Minibatch[1201-1300]: loss = 0.330971 * 100, metric = 6.19% * 100;
 Minibatch[1301-1400]: loss = 0.333382 * 100, metric = 6.03% * 100;
 Minibatch[1401-1500]: loss = 0.332538 * 100, metric = 6.07% * 100;
 Minibatch[1501-1600]: loss = 0.331272 * 100, metric = 6.15% * 100;
 Minibatch[1601-1700]: loss = 0.318878 * 100, metric = 5.70% * 100;
 Minibatch[1701-1800]: loss = 0.331487 * 100, metric = 6.03% * 100;
 Minibatch[1801-1900]: loss = 0.333840 * 100, metric = 6.01% * 100;
 Minibatch[1901-2000]: loss = 0.331885 * 100, metric = 5.94% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.328304 * 2000, metric = 5.95% * 2000 884.698s (  2.3 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 12.78% * 2000;
 Minibatch[   1- 100]: loss = 0.319420 * 100, metric = 5.80% * 100;
 Minibatch[ 101- 200]: loss = 0.333747 * 100, metric = 6.10% * 100;
 Minibatch[ 201- 300]: loss = 0.322030 * 100, metric = 5.73% * 100;
 Minibatch[ 301- 400]: loss = 0.324311 * 100, metric = 5.98% * 100;
 Minibatch[ 401- 500]: loss = 0.327768 * 100, metric = 6.11% * 100;
 Minibatch[ 501- 600]: loss = 0.327698 * 100, metric = 5.92% * 100;
 Minibatch[ 601- 700]: loss = 0.331277 * 100, metric = 6.14% * 100;
 Minibatch[ 701- 800]: loss = 0.330503 * 100, metric = 6.19% * 100;
 Minibatch[ 801- 900]: loss = 0.312095 * 100, metric = 5.62% * 100;
 Minibatch[ 901-1000]: loss = 0.323993 * 100, metric = 5.91% * 100;
 Minibatch[1001-1100]: loss = 0.330317 * 100, metric = 6.21% * 100;
 Minibatch[1101-1200]: loss = 0.331320 * 100, metric = 6.24% * 100;
 Minibatch[1201-1300]: loss = 0.330244 * 100, metric = 5.82% * 100;
 Minibatch[1301-1400]: loss = 0.340769 * 100, metric = 6.17% * 100;
 Minibatch[1401-1500]: loss = 0.330237 * 100, metric = 5.85% * 100;
 Minibatch[1501-1600]: loss = 0.328045 * 100, metric = 5.92% * 100;
 Minibatch[1601-1700]: loss = 0.326157 * 100, metric = 5.96% * 100;
 Minibatch[1701-1800]: loss = 0.330900 * 100, metric = 6.16% * 100;
 Minibatch[1801-1900]: loss = 0.328038 * 100, metric = 5.95% * 100;
 Minibatch[1901-2000]: loss = 0.323159 * 100, metric = 5.81% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.327601 * 2000, metric = 5.98% * 2000 872.683s (  2.3 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.05% * 2000;
 Minibatch[   1- 100]: loss = 0.324881 * 100, metric = 5.99% * 100;
 Minibatch[ 101- 200]: loss = 0.316384 * 100, metric = 5.92% * 100;
 Minibatch[ 201- 300]: loss = 0.331921 * 100, metric = 6.07% * 100;
 Minibatch[ 301- 400]: loss = 0.330430 * 100, metric = 6.02% * 100;
 Minibatch[ 401- 500]: loss = 0.324992 * 100, metric = 5.69% * 100;
 Minibatch[ 501- 600]: loss = 0.321125 * 100, metric = 5.94% * 100;
 Minibatch[ 601- 700]: loss = 0.336656 * 100, metric = 6.12% * 100;
 Minibatch[ 701- 800]: loss = 0.317692 * 100, metric = 5.67% * 100;
 Minibatch[ 801- 900]: loss = 0.323564 * 100, metric = 5.86% * 100;
 Minibatch[ 901-1000]: loss = 0.318988 * 100, metric = 5.70% * 100;
 Minibatch[1001-1100]: loss = 0.332615 * 100, metric = 6.16% * 100;
 Minibatch[1101-1200]: loss = 0.339149 * 100, metric = 6.12% * 100;
 Minibatch[1201-1300]: loss = 0.323438 * 100, metric = 5.80% * 100;
 Minibatch[1301-1400]: loss = 0.318164 * 100, metric = 5.75% * 100;
 Minibatch[1401-1500]: loss = 0.308488 * 100, metric = 5.42% * 100;
 Minibatch[1501-1600]: loss = 0.333357 * 100, metric = 6.03% * 100;
 Minibatch[1601-1700]: loss = 0.319080 * 100, metric = 5.76% * 100;
 Minibatch[1701-1800]: loss = 0.310602 * 100, metric = 5.60% * 100;
 Minibatch[1801-1900]: loss = 0.311292 * 100, metric = 5.47% * 100;
 Minibatch[1901-2000]: loss = 0.317305 * 100, metric = 5.64% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.323006 * 2000, metric = 5.84% * 2000 866.671s (  2.3 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 13.36% * 2000;
 Minibatch[   1- 100]: loss = 0.317100 * 100, metric = 5.64% * 100;
 Minibatch[ 101- 200]: loss = 0.320910 * 100, metric = 5.62% * 100;
 Minibatch[ 201- 300]: loss = 0.327930 * 100, metric = 5.85% * 100;
 Minibatch[ 301- 400]: loss = 0.328481 * 100, metric = 6.05% * 100;
 Minibatch[ 401- 500]: loss = 0.325703 * 100, metric = 5.94% * 100;
 Minibatch[ 501- 600]: loss = 0.317255 * 100, metric = 5.34% * 100;
 Minibatch[ 601- 700]: loss = 0.324059 * 100, metric = 5.75% * 100;
 Minibatch[ 701- 800]: loss = 0.320686 * 100, metric = 5.80% * 100;
 Minibatch[ 801- 900]: loss = 0.317941 * 100, metric = 5.79% * 100;
 Minibatch[ 901-1000]: loss = 0.324784 * 100, metric = 5.86% * 100;
 Minibatch[1001-1100]: loss = 0.322278 * 100, metric = 5.83% * 100;
 Minibatch[1101-1200]: loss = 0.326311 * 100, metric = 5.84% * 100;
 Minibatch[1201-1300]: loss = 0.327134 * 100, metric = 5.90% * 100;
 Minibatch[1301-1400]: loss = 0.304569 * 100, metric = 5.52% * 100;
 Minibatch[1401-1500]: loss = 0.308393 * 100, metric = 5.59% * 100;
 Minibatch[1501-1600]: loss = 0.315994 * 100, metric = 5.63% * 100;
 Minibatch[1601-1700]: loss = 0.321064 * 100, metric = 5.83% * 100;
 Minibatch[1701-1800]: loss = 0.322325 * 100, metric = 6.10% * 100;
 Minibatch[1801-1900]: loss = 0.318857 * 100, metric = 5.92% * 100;
 Minibatch[1901-2000]: loss = 0.313923 * 100, metric = 5.62% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.320285 * 2000, metric = 5.77% * 2000 881.575s (  2.3 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 13.05% * 2000;
 Minibatch[   1- 100]: loss = 0.316772 * 100, metric = 5.59% * 100;
 Minibatch[ 101- 200]: loss = 0.324481 * 100, metric = 5.96% * 100;
 Minibatch[ 201- 300]: loss = 0.319113 * 100, metric = 5.63% * 100;
 Minibatch[ 301- 400]: loss = 0.319017 * 100, metric = 5.52% * 100;
 Minibatch[ 401- 500]: loss = 0.313411 * 100, metric = 5.65% * 100;
 Minibatch[ 501- 600]: loss = 0.321534 * 100, metric = 5.90% * 100;
 Minibatch[ 601- 700]: loss = 0.322347 * 100, metric = 5.96% * 100;
 Minibatch[ 701- 800]: loss = 0.315385 * 100, metric = 5.75% * 100;
 Minibatch[ 801- 900]: loss = 0.313539 * 100, metric = 5.81% * 100;
 Minibatch[ 901-1000]: loss = 0.330799 * 100, metric = 6.21% * 100;
 Minibatch[1001-1100]: loss = 0.316102 * 100, metric = 5.84% * 100;
 Minibatch[1101-1200]: loss = 0.314293 * 100, metric = 5.65% * 100;
 Minibatch[1201-1300]: loss = 0.323105 * 100, metric = 5.96% * 100;
 Minibatch[1301-1400]: loss = 0.325971 * 100, metric = 5.98% * 100;
 Minibatch[1401-1500]: loss = 0.317693 * 100, metric = 5.69% * 100;
 Minibatch[1501-1600]: loss = 0.323544 * 100, metric = 5.76% * 100;
 Minibatch[1601-1700]: loss = 0.332383 * 100, metric = 5.92% * 100;
 Minibatch[1701-1800]: loss = 0.325563 * 100, metric = 5.81% * 100;
 Minibatch[1801-1900]: loss = 0.320198 * 100, metric = 5.82% * 100;
 Minibatch[1901-2000]: loss = 0.322234 * 100, metric = 5.82% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.320874 * 2000, metric = 5.81% * 2000 869.463s (  2.3 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 12.23% * 2000;
 Minibatch[   1- 100]: loss = 0.326326 * 100, metric = 6.10% * 100;
 Minibatch[ 101- 200]: loss = 0.311443 * 100, metric = 5.40% * 100;
 Minibatch[ 201- 300]: loss = 0.320496 * 100, metric = 5.68% * 100;
 Minibatch[ 301- 400]: loss = 0.319371 * 100, metric = 5.70% * 100;
 Minibatch[ 401- 500]: loss = 0.307593 * 100, metric = 5.54% * 100;
 Minibatch[ 501- 600]: loss = 0.310920 * 100, metric = 5.58% * 100;
 Minibatch[ 601- 700]: loss = 0.324238 * 100, metric = 5.93% * 100;
 Minibatch[ 701- 800]: loss = 0.320775 * 100, metric = 6.05% * 100;
 Minibatch[ 801- 900]: loss = 0.317283 * 100, metric = 5.95% * 100;
 Minibatch[ 901-1000]: loss = 0.320942 * 100, metric = 5.92% * 100;
 Minibatch[1001-1100]: loss = 0.315958 * 100, metric = 5.66% * 100;
 Minibatch[1101-1200]: loss = 0.312291 * 100, metric = 5.63% * 100;
 Minibatch[1201-1300]: loss = 0.322963 * 100, metric = 5.99% * 100;
 Minibatch[1301-1400]: loss = 0.324190 * 100, metric = 5.87% * 100;
 Minibatch[1401-1500]: loss = 0.308357 * 100, metric = 5.44% * 100;
 Minibatch[1501-1600]: loss = 0.322936 * 100, metric = 5.88% * 100;
 Minibatch[1601-1700]: loss = 0.315497 * 100, metric = 5.83% * 100;
 Minibatch[1701-1800]: loss = 0.311226 * 100, metric = 5.74% * 100;
 Minibatch[1801-1900]: loss = 0.315104 * 100, metric = 6.03% * 100;
 Minibatch[1901-2000]: loss = 0.309294 * 100, metric = 5.52% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.316860 * 2000, metric = 5.77% * 2000 871.551s (  2.3 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 13.03% * 2000;
 Minibatch[   1- 100]: loss = 0.304002 * 100, metric = 5.66% * 100;
 Minibatch[ 101- 200]: loss = 0.310476 * 100, metric = 5.73% * 100;
 Minibatch[ 201- 300]: loss = 0.317142 * 100, metric = 5.83% * 100;
 Minibatch[ 301- 400]: loss = 0.330698 * 100, metric = 5.84% * 100;
 Minibatch[ 401- 500]: loss = 0.317111 * 100, metric = 5.58% * 100;
 Minibatch[ 501- 600]: loss = 0.307081 * 100, metric = 5.72% * 100;
 Minibatch[ 601- 700]: loss = 0.319779 * 100, metric = 6.04% * 100;
 Minibatch[ 701- 800]: loss = 0.295366 * 100, metric = 5.23% * 100;
 Minibatch[ 801- 900]: loss = 0.304743 * 100, metric = 5.32% * 100;
 Minibatch[ 901-1000]: loss = 0.304061 * 100, metric = 5.36% * 100;
 Minibatch[1001-1100]: loss = 0.302453 * 100, metric = 5.20% * 100;
 Minibatch[1101-1200]: loss = 0.299007 * 100, metric = 5.16% * 100;
 Minibatch[1201-1300]: loss = 0.312881 * 100, metric = 5.55% * 100;
 Minibatch[1301-1400]: loss = 0.308487 * 100, metric = 5.55% * 100;
 Minibatch[1401-1500]: loss = 0.309577 * 100, metric = 5.33% * 100;
 Minibatch[1501-1600]: loss = 0.302527 * 100, metric = 5.19% * 100;
 Minibatch[1601-1700]: loss = 0.314596 * 100, metric = 5.52% * 100;
 Minibatch[1701-1800]: loss = 0.325637 * 100, metric = 6.03% * 100;
 Minibatch[1801-1900]: loss = 0.313458 * 100, metric = 5.44% * 100;
 Minibatch[1901-2000]: loss = 0.309950 * 100, metric = 5.53% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.310452 * 2000, metric = 5.54% * 2000 865.603s (  2.3 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 13.23% * 2000;
 Minibatch[   1- 100]: loss = 0.314456 * 100, metric = 5.62% * 100;
 Minibatch[ 101- 200]: loss = 0.307502 * 100, metric = 5.37% * 100;
 Minibatch[ 201- 300]: loss = 0.311780 * 100, metric = 5.41% * 100;
 Minibatch[ 301- 400]: loss = 0.311227 * 100, metric = 5.68% * 100;
 Minibatch[ 401- 500]: loss = 0.306771 * 100, metric = 5.57% * 100;
 Minibatch[ 501- 600]: loss = 0.305935 * 100, metric = 5.37% * 100;
 Minibatch[ 601- 700]: loss = 0.301858 * 100, metric = 5.29% * 100;
 Minibatch[ 701- 800]: loss = 0.298175 * 100, metric = 5.23% * 100;
 Minibatch[ 801- 900]: loss = 0.319390 * 100, metric = 5.76% * 100;
 Minibatch[ 901-1000]: loss = 0.303909 * 100, metric = 5.39% * 100;
 Minibatch[1001-1100]: loss = 0.296977 * 100, metric = 5.12% * 100;
 Minibatch[1101-1200]: loss = 0.319882 * 100, metric = 5.51% * 100;
 Minibatch[1201-1300]: loss = 0.311330 * 100, metric = 5.44% * 100;
 Minibatch[1301-1400]: loss = 0.313741 * 100, metric = 5.45% * 100;
 Minibatch[1401-1500]: loss = 0.314580 * 100, metric = 5.53% * 100;
 Minibatch[1501-1600]: loss = 0.301849 * 100, metric = 5.42% * 100;
 Minibatch[1601-1700]: loss = 0.295346 * 100, metric = 5.27% * 100;
 Minibatch[1701-1800]: loss = 0.306873 * 100, metric = 5.39% * 100;
 Minibatch[1801-1900]: loss = 0.309785 * 100, metric = 5.64% * 100;
 Minibatch[1901-2000]: loss = 0.299590 * 100, metric = 5.41% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.307548 * 2000, metric = 5.44% * 2000 878.601s (  2.3 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 12.57% * 2000;
 Minibatch[   1- 100]: loss = 0.299557 * 100, metric = 5.41% * 100;
 Minibatch[ 101- 200]: loss = 0.311273 * 100, metric = 5.50% * 100;
 Minibatch[ 201- 300]: loss = 0.306242 * 100, metric = 5.37% * 100;
 Minibatch[ 301- 400]: loss = 0.322417 * 100, metric = 5.80% * 100;
 Minibatch[ 401- 500]: loss = 0.312664 * 100, metric = 5.23% * 100;
 Minibatch[ 501- 600]: loss = 0.303025 * 100, metric = 5.26% * 100;
 Minibatch[ 601- 700]: loss = 0.303937 * 100, metric = 5.37% * 100;
 Minibatch[ 701- 800]: loss = 0.296619 * 100, metric = 5.07% * 100;
 Minibatch[ 801- 900]: loss = 0.301758 * 100, metric = 5.34% * 100;
 Minibatch[ 901-1000]: loss = 0.300086 * 100, metric = 5.33% * 100;
 Minibatch[1001-1100]: loss = 0.300363 * 100, metric = 5.15% * 100;
 Minibatch[1101-1200]: loss = 0.313303 * 100, metric = 5.58% * 100;
 Minibatch[1201-1300]: loss = 0.316632 * 100, metric = 5.62% * 100;
 Minibatch[1301-1400]: loss = 0.322668 * 100, metric = 5.58% * 100;
 Minibatch[1401-1500]: loss = 0.301850 * 100, metric = 5.26% * 100;
 Minibatch[1501-1600]: loss = 0.308482 * 100, metric = 5.41% * 100;
 Minibatch[1601-1700]: loss = 0.302410 * 100, metric = 5.19% * 100;
 Minibatch[1701-1800]: loss = 0.314728 * 100, metric = 5.61% * 100;
 Minibatch[1801-1900]: loss = 0.295742 * 100, metric = 5.19% * 100;
 Minibatch[1901-2000]: loss = 0.297875 * 100, metric = 5.24% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.306582 * 2000, metric = 5.38% * 2000 869.787s (  2.3 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 13.07% * 2000;
 Minibatch[   1- 100]: loss = 0.300435 * 100, metric = 5.27% * 100;
 Minibatch[ 101- 200]: loss = 0.295805 * 100, metric = 5.09% * 100;
 Minibatch[ 201- 300]: loss = 0.299014 * 100, metric = 5.19% * 100;
 Minibatch[ 301- 400]: loss = 0.301564 * 100, metric = 5.38% * 100;
 Minibatch[ 401- 500]: loss = 0.297676 * 100, metric = 5.31% * 100;
 Minibatch[ 501- 600]: loss = 0.295409 * 100, metric = 5.22% * 100;
 Minibatch[ 601- 700]: loss = 0.307678 * 100, metric = 5.42% * 100;
 Minibatch[ 701- 800]: loss = 0.299691 * 100, metric = 5.36% * 100;
 Minibatch[ 801- 900]: loss = 0.298077 * 100, metric = 5.32% * 100;
 Minibatch[ 901-1000]: loss = 0.309122 * 100, metric = 5.50% * 100;
 Minibatch[1001-1100]: loss = 0.313253 * 100, metric = 5.70% * 100;
 Minibatch[1101-1200]: loss = 0.301839 * 100, metric = 5.26% * 100;
 Minibatch[1201-1300]: loss = 0.294857 * 100, metric = 5.09% * 100;
 Minibatch[1301-1400]: loss = 0.298825 * 100, metric = 5.44% * 100;
 Minibatch[1401-1500]: loss = 0.312957 * 100, metric = 5.70% * 100;
 Minibatch[1501-1600]: loss = 0.306241 * 100, metric = 5.33% * 100;
 Minibatch[1601-1700]: loss = 0.301396 * 100, metric = 5.22% * 100;
 Minibatch[1701-1800]: loss = 0.317582 * 100, metric = 5.64% * 100;
 Minibatch[1801-1900]: loss = 0.299621 * 100, metric = 5.32% * 100;
 Minibatch[1901-2000]: loss = 0.311391 * 100, metric = 5.56% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.303122 * 2000, metric = 5.37% * 2000 866.259s (  2.3 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 12.17% * 2000;
 Minibatch[   1- 100]: loss = 0.296643 * 100, metric = 5.20% * 100;
 Minibatch[ 101- 200]: loss = 0.298887 * 100, metric = 5.19% * 100;
 Minibatch[ 201- 300]: loss = 0.304173 * 100, metric = 5.49% * 100;
 Minibatch[ 301- 400]: loss = 0.284864 * 100, metric = 5.07% * 100;
 Minibatch[ 401- 500]: loss = 0.311589 * 100, metric = 5.74% * 100;
 Minibatch[ 501- 600]: loss = 0.307718 * 100, metric = 5.65% * 100;
 Minibatch[ 601- 700]: loss = 0.315014 * 100, metric = 5.55% * 100;
 Minibatch[ 701- 800]: loss = 0.300367 * 100, metric = 5.25% * 100;
 Minibatch[ 801- 900]: loss = 0.299037 * 100, metric = 5.13% * 100;
 Minibatch[ 901-1000]: loss = 0.300910 * 100, metric = 5.46% * 100;
 Minibatch[1001-1100]: loss = 0.300786 * 100, metric = 5.45% * 100;
 Minibatch[1101-1200]: loss = 0.293897 * 100, metric = 5.24% * 100;
 Minibatch[1201-1300]: loss = 0.293491 * 100, metric = 5.16% * 100;
 Minibatch[1301-1400]: loss = 0.295475 * 100, metric = 5.24% * 100;
 Minibatch[1401-1500]: loss = 0.294900 * 100, metric = 5.40% * 100;
 Minibatch[1501-1600]: loss = 0.292314 * 100, metric = 5.34% * 100;
 Minibatch[1601-1700]: loss = 0.291425 * 100, metric = 5.11% * 100;
 Minibatch[1701-1800]: loss = 0.294284 * 100, metric = 5.31% * 100;
 Minibatch[1801-1900]: loss = 0.304305 * 100, metric = 5.49% * 100;
 Minibatch[1901-2000]: loss = 0.285760 * 100, metric = 4.94% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.298292 * 2000, metric = 5.32% * 2000 867.151s (  2.3 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 13.34% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
