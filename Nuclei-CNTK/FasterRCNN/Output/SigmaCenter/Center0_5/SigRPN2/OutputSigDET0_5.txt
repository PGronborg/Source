Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 0.893527 * 100, metric = 24.98% * 100;
 Minibatch[ 101- 200]: loss = 0.710176 * 100, metric = 24.04% * 100;
 Minibatch[ 201- 300]: loss = 0.594483 * 100, metric = 22.09% * 100;
 Minibatch[ 301- 400]: loss = 0.570962 * 100, metric = 20.73% * 100;
 Minibatch[ 401- 500]: loss = 0.522740 * 100, metric = 20.02% * 100;
 Minibatch[ 501- 600]: loss = 0.492146 * 100, metric = 18.39% * 100;
 Minibatch[ 601- 700]: loss = 0.462985 * 100, metric = 17.46% * 100;
 Minibatch[ 701- 800]: loss = 0.435345 * 100, metric = 16.37% * 100;
 Minibatch[ 801- 900]: loss = 0.443465 * 100, metric = 17.06% * 100;
 Minibatch[ 901-1000]: loss = 0.452546 * 100, metric = 17.37% * 100;
 Minibatch[1001-1100]: loss = 0.441700 * 100, metric = 17.11% * 100;
 Minibatch[1101-1200]: loss = 0.426421 * 100, metric = 16.38% * 100;
 Minibatch[1201-1300]: loss = 0.426477 * 100, metric = 16.66% * 100;
 Minibatch[1301-1400]: loss = 0.409073 * 100, metric = 15.64% * 100;
 Minibatch[1401-1500]: loss = 0.417084 * 100, metric = 15.97% * 100;
 Minibatch[1501-1600]: loss = 0.395263 * 100, metric = 15.58% * 100;
 Minibatch[1601-1700]: loss = 0.398710 * 100, metric = 15.44% * 100;
 Minibatch[1701-1800]: loss = 0.409128 * 100, metric = 15.90% * 100;
 Minibatch[1801-1900]: loss = 0.404299 * 100, metric = 15.48% * 100;
 Minibatch[1901-2000]: loss = 0.387078 * 100, metric = 14.66% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.484680 * 2000, metric = 17.87% * 2000 1117.129s (  1.8 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 26.30% * 2000;
0.5799611233621835
 Minibatch[   1- 100]: loss = 0.388261 * 100, metric = 14.89% * 100;
 Minibatch[ 101- 200]: loss = 0.407216 * 100, metric = 15.70% * 100;
 Minibatch[ 201- 300]: loss = 0.388055 * 100, metric = 14.42% * 100;
 Minibatch[ 301- 400]: loss = 0.396020 * 100, metric = 14.97% * 100;
 Minibatch[ 401- 500]: loss = 0.381000 * 100, metric = 14.48% * 100;
 Minibatch[ 501- 600]: loss = 0.398471 * 100, metric = 14.62% * 100;
 Minibatch[ 601- 700]: loss = 0.373448 * 100, metric = 13.88% * 100;
 Minibatch[ 701- 800]: loss = 0.383285 * 100, metric = 14.74% * 100;
 Minibatch[ 801- 900]: loss = 0.363404 * 100, metric = 14.17% * 100;
 Minibatch[ 901-1000]: loss = 0.354689 * 100, metric = 13.35% * 100;
 Minibatch[1001-1100]: loss = 0.367906 * 100, metric = 14.06% * 100;
 Minibatch[1101-1200]: loss = 0.364148 * 100, metric = 13.76% * 100;
 Minibatch[1201-1300]: loss = 0.357261 * 100, metric = 14.06% * 100;
 Minibatch[1301-1400]: loss = 0.375310 * 100, metric = 14.12% * 100;
 Minibatch[1401-1500]: loss = 0.355386 * 100, metric = 13.12% * 100;
 Minibatch[1501-1600]: loss = 0.346392 * 100, metric = 13.24% * 100;
 Minibatch[1601-1700]: loss = 0.367094 * 100, metric = 13.59% * 100;
 Minibatch[1701-1800]: loss = 0.374739 * 100, metric = 13.89% * 100;
 Minibatch[1801-1900]: loss = 0.358083 * 100, metric = 13.47% * 100;
 Minibatch[1901-2000]: loss = 0.342302 * 100, metric = 13.02% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.372123 * 2000, metric = 14.08% * 2000 1034.978s (  1.9 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 22.19% * 2000;
0.5005027769058943
 Minibatch[   1- 100]: loss = 0.355098 * 100, metric = 13.30% * 100;
 Minibatch[ 101- 200]: loss = 0.360133 * 100, metric = 13.61% * 100;
 Minibatch[ 201- 300]: loss = 0.341753 * 100, metric = 12.98% * 100;
 Minibatch[ 301- 400]: loss = 0.363011 * 100, metric = 13.88% * 100;
 Minibatch[ 401- 500]: loss = 0.361000 * 100, metric = 13.38% * 100;
 Minibatch[ 501- 600]: loss = 0.355201 * 100, metric = 13.55% * 100;
 Minibatch[ 601- 700]: loss = 0.361960 * 100, metric = 13.52% * 100;
 Minibatch[ 701- 800]: loss = 0.332535 * 100, metric = 12.55% * 100;
 Minibatch[ 801- 900]: loss = 0.356493 * 100, metric = 13.45% * 100;
 Minibatch[ 901-1000]: loss = 0.337019 * 100, metric = 12.99% * 100;
 Minibatch[1001-1100]: loss = 0.355353 * 100, metric = 13.78% * 100;
 Minibatch[1101-1200]: loss = 0.334360 * 100, metric = 12.74% * 100;
 Minibatch[1201-1300]: loss = 0.336780 * 100, metric = 12.83% * 100;
 Minibatch[1301-1400]: loss = 0.347303 * 100, metric = 13.06% * 100;
 Minibatch[1401-1500]: loss = 0.349724 * 100, metric = 13.17% * 100;
 Minibatch[1501-1600]: loss = 0.335481 * 100, metric = 12.79% * 100;
 Minibatch[1601-1700]: loss = 0.328040 * 100, metric = 12.33% * 100;
 Minibatch[1701-1800]: loss = 0.352981 * 100, metric = 13.34% * 100;
 Minibatch[1801-1900]: loss = 0.333546 * 100, metric = 12.68% * 100;
 Minibatch[1901-2000]: loss = 0.333551 * 100, metric = 12.58% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.346566 * 2000, metric = 13.13% * 2000 1019.151s (  2.0 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 19.40% * 2000;
0.46606690490245817
 Minibatch[   1- 100]: loss = 0.349626 * 100, metric = 12.71% * 100;
 Minibatch[ 101- 200]: loss = 0.326963 * 100, metric = 12.25% * 100;
 Minibatch[ 201- 300]: loss = 0.338212 * 100, metric = 12.81% * 100;
 Minibatch[ 301- 400]: loss = 0.312859 * 100, metric = 12.07% * 100;
 Minibatch[ 401- 500]: loss = 0.341949 * 100, metric = 12.88% * 100;
 Minibatch[ 501- 600]: loss = 0.315195 * 100, metric = 11.86% * 100;
 Minibatch[ 601- 700]: loss = 0.323133 * 100, metric = 12.31% * 100;
 Minibatch[ 701- 800]: loss = 0.326726 * 100, metric = 12.25% * 100;
 Minibatch[ 801- 900]: loss = 0.328176 * 100, metric = 12.15% * 100;
 Minibatch[ 901-1000]: loss = 0.328159 * 100, metric = 12.47% * 100;
 Minibatch[1001-1100]: loss = 0.337482 * 100, metric = 12.82% * 100;
 Minibatch[1101-1200]: loss = 0.318623 * 100, metric = 12.18% * 100;
 Minibatch[1201-1300]: loss = 0.323149 * 100, metric = 12.38% * 100;
 Minibatch[1301-1400]: loss = 0.331419 * 100, metric = 12.46% * 100;
 Minibatch[1401-1500]: loss = 0.333437 * 100, metric = 12.63% * 100;
 Minibatch[1501-1600]: loss = 0.307392 * 100, metric = 11.65% * 100;
 Minibatch[1601-1700]: loss = 0.329537 * 100, metric = 12.72% * 100;
 Minibatch[1701-1800]: loss = 0.331176 * 100, metric = 12.67% * 100;
 Minibatch[1801-1900]: loss = 0.322489 * 100, metric = 12.26% * 100;
 Minibatch[1901-2000]: loss = 0.313199 * 100, metric = 11.80% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.326945 * 2000, metric = 12.37% * 2000 971.519s (  2.1 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 20.84% * 2000;
 Minibatch[   1- 100]: loss = 0.329995 * 100, metric = 12.33% * 100;
 Minibatch[ 101- 200]: loss = 0.318671 * 100, metric = 12.26% * 100;
 Minibatch[ 201- 300]: loss = 0.311886 * 100, metric = 11.64% * 100;
 Minibatch[ 301- 400]: loss = 0.337413 * 100, metric = 12.77% * 100;
 Minibatch[ 401- 500]: loss = 0.305567 * 100, metric = 11.43% * 100;
 Minibatch[ 501- 600]: loss = 0.305866 * 100, metric = 11.36% * 100;
 Minibatch[ 601- 700]: loss = 0.315465 * 100, metric = 11.53% * 100;
 Minibatch[ 701- 800]: loss = 0.319980 * 100, metric = 12.01% * 100;
 Minibatch[ 801- 900]: loss = 0.301068 * 100, metric = 11.26% * 100;
 Minibatch[ 901-1000]: loss = 0.303461 * 100, metric = 11.60% * 100;
 Minibatch[1001-1100]: loss = 0.316319 * 100, metric = 11.68% * 100;
 Minibatch[1101-1200]: loss = 0.302285 * 100, metric = 11.35% * 100;
 Minibatch[1201-1300]: loss = 0.314907 * 100, metric = 11.61% * 100;
 Minibatch[1301-1400]: loss = 0.322782 * 100, metric = 12.21% * 100;
 Minibatch[1401-1500]: loss = 0.314598 * 100, metric = 11.80% * 100;
 Minibatch[1501-1600]: loss = 0.313959 * 100, metric = 11.88% * 100;
 Minibatch[1601-1700]: loss = 0.317419 * 100, metric = 12.14% * 100;
 Minibatch[1701-1800]: loss = 0.318794 * 100, metric = 11.90% * 100;
 Minibatch[1801-1900]: loss = 0.322892 * 100, metric = 12.06% * 100;
 Minibatch[1901-2000]: loss = 0.310168 * 100, metric = 11.66% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.315175 * 2000, metric = 11.82% * 2000 977.398s (  2.0 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.11% * 2000;
 Minibatch[   1- 100]: loss = 0.304865 * 100, metric = 11.65% * 100;
 Minibatch[ 101- 200]: loss = 0.304406 * 100, metric = 11.55% * 100;
 Minibatch[ 201- 300]: loss = 0.307118 * 100, metric = 11.46% * 100;
 Minibatch[ 301- 400]: loss = 0.309802 * 100, metric = 11.47% * 100;
 Minibatch[ 401- 500]: loss = 0.297785 * 100, metric = 11.14% * 100;
 Minibatch[ 501- 600]: loss = 0.310326 * 100, metric = 11.67% * 100;
 Minibatch[ 601- 700]: loss = 0.302121 * 100, metric = 11.64% * 100;
 Minibatch[ 701- 800]: loss = 0.308331 * 100, metric = 11.81% * 100;
 Minibatch[ 801- 900]: loss = 0.308209 * 100, metric = 11.60% * 100;
 Minibatch[ 901-1000]: loss = 0.305686 * 100, metric = 11.37% * 100;
 Minibatch[1001-1100]: loss = 0.301900 * 100, metric = 11.06% * 100;
 Minibatch[1101-1200]: loss = 0.316467 * 100, metric = 11.67% * 100;
 Minibatch[1201-1300]: loss = 0.317745 * 100, metric = 11.85% * 100;
 Minibatch[1301-1400]: loss = 0.302401 * 100, metric = 11.46% * 100;
 Minibatch[1401-1500]: loss = 0.304996 * 100, metric = 11.73% * 100;
 Minibatch[1501-1600]: loss = 0.294218 * 100, metric = 10.98% * 100;
 Minibatch[1601-1700]: loss = 0.300528 * 100, metric = 11.21% * 100;
 Minibatch[1701-1800]: loss = 0.290820 * 100, metric = 10.86% * 100;
 Minibatch[1801-1900]: loss = 0.305826 * 100, metric = 11.76% * 100;
 Minibatch[1901-2000]: loss = 0.291450 * 100, metric = 10.94% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.304250 * 2000, metric = 11.44% * 2000 960.688s (  2.1 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.37% * 2000;
 Minibatch[   1- 100]: loss = 0.293342 * 100, metric = 11.26% * 100;
 Minibatch[ 101- 200]: loss = 0.303151 * 100, metric = 11.12% * 100;
 Minibatch[ 201- 300]: loss = 0.315602 * 100, metric = 11.53% * 100;
 Minibatch[ 301- 400]: loss = 0.295091 * 100, metric = 10.91% * 100;
 Minibatch[ 401- 500]: loss = 0.304464 * 100, metric = 11.29% * 100;
 Minibatch[ 501- 600]: loss = 0.286428 * 100, metric = 10.74% * 100;
 Minibatch[ 601- 700]: loss = 0.294298 * 100, metric = 10.85% * 100;
 Minibatch[ 701- 800]: loss = 0.298813 * 100, metric = 11.10% * 100;
 Minibatch[ 801- 900]: loss = 0.307744 * 100, metric = 11.63% * 100;
 Minibatch[ 901-1000]: loss = 0.297691 * 100, metric = 11.05% * 100;
 Minibatch[1001-1100]: loss = 0.303137 * 100, metric = 11.30% * 100;
 Minibatch[1101-1200]: loss = 0.293506 * 100, metric = 11.08% * 100;
 Minibatch[1201-1300]: loss = 0.303830 * 100, metric = 11.60% * 100;
 Minibatch[1301-1400]: loss = 0.289739 * 100, metric = 11.04% * 100;
 Minibatch[1401-1500]: loss = 0.290021 * 100, metric = 10.82% * 100;
 Minibatch[1501-1600]: loss = 0.293608 * 100, metric = 11.07% * 100;
 Minibatch[1601-1700]: loss = 0.299019 * 100, metric = 11.10% * 100;
 Minibatch[1701-1800]: loss = 0.298186 * 100, metric = 11.00% * 100;
 Minibatch[1801-1900]: loss = 0.297427 * 100, metric = 11.33% * 100;
 Minibatch[1901-2000]: loss = 0.303678 * 100, metric = 11.48% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.298439 * 2000, metric = 11.17% * 2000 959.607s (  2.1 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.35% * 2000;
0.44674017052352427
 Minibatch[   1- 100]: loss = 0.298888 * 100, metric = 11.20% * 100;
 Minibatch[ 101- 200]: loss = 0.294554 * 100, metric = 11.16% * 100;
 Minibatch[ 201- 300]: loss = 0.284705 * 100, metric = 10.80% * 100;
 Minibatch[ 301- 400]: loss = 0.287379 * 100, metric = 10.90% * 100;
 Minibatch[ 401- 500]: loss = 0.297663 * 100, metric = 11.26% * 100;
 Minibatch[ 501- 600]: loss = 0.307012 * 100, metric = 11.65% * 100;
 Minibatch[ 601- 700]: loss = 0.281189 * 100, metric = 10.89% * 100;
 Minibatch[ 701- 800]: loss = 0.294955 * 100, metric = 10.96% * 100;
 Minibatch[ 801- 900]: loss = 0.275674 * 100, metric = 10.17% * 100;
 Minibatch[ 901-1000]: loss = 0.266494 * 100, metric = 10.10% * 100;
 Minibatch[1001-1100]: loss = 0.278200 * 100, metric = 10.42% * 100;
 Minibatch[1101-1200]: loss = 0.276968 * 100, metric = 10.32% * 100;
 Minibatch[1201-1300]: loss = 0.288456 * 100, metric = 10.87% * 100;
 Minibatch[1301-1400]: loss = 0.294939 * 100, metric = 11.31% * 100;
 Minibatch[1401-1500]: loss = 0.285426 * 100, metric = 10.68% * 100;
 Minibatch[1501-1600]: loss = 0.288852 * 100, metric = 10.81% * 100;
 Minibatch[1601-1700]: loss = 0.282185 * 100, metric = 10.55% * 100;
 Minibatch[1701-1800]: loss = 0.280643 * 100, metric = 10.23% * 100;
 Minibatch[1801-1900]: loss = 0.282996 * 100, metric = 10.70% * 100;
 Minibatch[1901-2000]: loss = 0.279043 * 100, metric = 10.62% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.286311 * 2000, metric = 10.78% * 2000 964.768s (  2.1 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 17.51% * 2000;
0.4331208501197398
 Minibatch[   1- 100]: loss = 0.268211 * 100, metric = 10.07% * 100;
 Minibatch[ 101- 200]: loss = 0.297170 * 100, metric = 11.11% * 100;
 Minibatch[ 201- 300]: loss = 0.279161 * 100, metric = 10.53% * 100;
 Minibatch[ 301- 400]: loss = 0.298193 * 100, metric = 11.18% * 100;
 Minibatch[ 401- 500]: loss = 0.286031 * 100, metric = 10.42% * 100;
 Minibatch[ 501- 600]: loss = 0.278862 * 100, metric = 10.47% * 100;
 Minibatch[ 601- 700]: loss = 0.280771 * 100, metric = 10.33% * 100;
 Minibatch[ 701- 800]: loss = 0.262826 * 100, metric = 10.04% * 100;
 Minibatch[ 801- 900]: loss = 0.270829 * 100, metric = 10.12% * 100;
 Minibatch[ 901-1000]: loss = 0.284753 * 100, metric = 10.67% * 100;
 Minibatch[1001-1100]: loss = 0.259312 * 100, metric = 9.65% * 100;
 Minibatch[1101-1200]: loss = 0.276898 * 100, metric = 10.51% * 100;
 Minibatch[1201-1300]: loss = 0.273748 * 100, metric = 10.27% * 100;
 Minibatch[1301-1400]: loss = 0.270560 * 100, metric = 10.03% * 100;
 Minibatch[1401-1500]: loss = 0.284087 * 100, metric = 10.71% * 100;
 Minibatch[1501-1600]: loss = 0.280356 * 100, metric = 10.47% * 100;
 Minibatch[1601-1700]: loss = 0.280285 * 100, metric = 10.41% * 100;
 Minibatch[1701-1800]: loss = 0.271335 * 100, metric = 10.00% * 100;
 Minibatch[1801-1900]: loss = 0.270130 * 100, metric = 10.03% * 100;
 Minibatch[1901-2000]: loss = 0.274196 * 100, metric = 10.21% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.277386 * 2000, metric = 10.36% * 2000 953.125s (  2.1 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 16.76% * 2000;
0.42102588759362697
 Minibatch[   1- 100]: loss = 0.286350 * 100, metric = 10.80% * 100;
 Minibatch[ 101- 200]: loss = 0.272233 * 100, metric = 10.13% * 100;
 Minibatch[ 201- 300]: loss = 0.274662 * 100, metric = 10.21% * 100;
 Minibatch[ 301- 400]: loss = 0.269438 * 100, metric = 10.10% * 100;
 Minibatch[ 401- 500]: loss = 0.278941 * 100, metric = 10.43% * 100;
 Minibatch[ 501- 600]: loss = 0.259999 * 100, metric = 9.63% * 100;
 Minibatch[ 601- 700]: loss = 0.259962 * 100, metric = 9.71% * 100;
 Minibatch[ 701- 800]: loss = 0.250813 * 100, metric = 9.16% * 100;
 Minibatch[ 801- 900]: loss = 0.265795 * 100, metric = 10.08% * 100;
 Minibatch[ 901-1000]: loss = 0.276582 * 100, metric = 10.38% * 100;
 Minibatch[1001-1100]: loss = 0.278920 * 100, metric = 10.25% * 100;
 Minibatch[1101-1200]: loss = 0.271567 * 100, metric = 10.07% * 100;
 Minibatch[1201-1300]: loss = 0.272310 * 100, metric = 10.24% * 100;
 Minibatch[1301-1400]: loss = 0.271801 * 100, metric = 10.05% * 100;
 Minibatch[1401-1500]: loss = 0.259371 * 100, metric = 9.67% * 100;
 Minibatch[1501-1600]: loss = 0.263721 * 100, metric = 9.86% * 100;
 Minibatch[1601-1700]: loss = 0.266826 * 100, metric = 9.62% * 100;
 Minibatch[1701-1800]: loss = 0.273533 * 100, metric = 9.95% * 100;
 Minibatch[1801-1900]: loss = 0.274568 * 100, metric = 10.37% * 100;
 Minibatch[1901-2000]: loss = 0.262132 * 100, metric = 9.81% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.269476 * 2000, metric = 10.03% * 2000 925.341s (  2.2 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 16.79% * 2000;
 Minibatch[   1- 100]: loss = 0.248262 * 100, metric = 9.10% * 100;
 Minibatch[ 101- 200]: loss = 0.259082 * 100, metric = 9.56% * 100;
 Minibatch[ 201- 300]: loss = 0.267556 * 100, metric = 10.05% * 100;
 Minibatch[ 301- 400]: loss = 0.264318 * 100, metric = 9.79% * 100;
 Minibatch[ 401- 500]: loss = 0.258356 * 100, metric = 9.78% * 100;
 Minibatch[ 501- 600]: loss = 0.270035 * 100, metric = 10.14% * 100;
 Minibatch[ 601- 700]: loss = 0.256548 * 100, metric = 9.36% * 100;
 Minibatch[ 701- 800]: loss = 0.265377 * 100, metric = 9.74% * 100;
 Minibatch[ 801- 900]: loss = 0.261380 * 100, metric = 9.61% * 100;
 Minibatch[ 901-1000]: loss = 0.270441 * 100, metric = 9.79% * 100;
 Minibatch[1001-1100]: loss = 0.260014 * 100, metric = 9.66% * 100;
 Minibatch[1101-1200]: loss = 0.267610 * 100, metric = 9.90% * 100;
 Minibatch[1201-1300]: loss = 0.255284 * 100, metric = 9.44% * 100;
 Minibatch[1301-1400]: loss = 0.247900 * 100, metric = 9.26% * 100;
 Minibatch[1401-1500]: loss = 0.264293 * 100, metric = 9.82% * 100;
 Minibatch[1501-1600]: loss = 0.256880 * 100, metric = 9.64% * 100;
 Minibatch[1601-1700]: loss = 0.257629 * 100, metric = 9.59% * 100;
 Minibatch[1701-1800]: loss = 0.270900 * 100, metric = 9.96% * 100;
 Minibatch[1801-1900]: loss = 0.261800 * 100, metric = 9.65% * 100;
 Minibatch[1901-2000]: loss = 0.258920 * 100, metric = 9.49% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.261129 * 2000, metric = 9.67% * 2000 937.661s (  2.1 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 17.00% * 2000;
 Minibatch[   1- 100]: loss = 0.244243 * 100, metric = 8.85% * 100;
 Minibatch[ 101- 200]: loss = 0.246175 * 100, metric = 9.13% * 100;
 Minibatch[ 201- 300]: loss = 0.251222 * 100, metric = 9.44% * 100;
 Minibatch[ 301- 400]: loss = 0.273754 * 100, metric = 10.23% * 100;
 Minibatch[ 401- 500]: loss = 0.251210 * 100, metric = 9.33% * 100;
 Minibatch[ 501- 600]: loss = 0.242802 * 100, metric = 8.90% * 100;
 Minibatch[ 601- 700]: loss = 0.241160 * 100, metric = 8.87% * 100;
 Minibatch[ 701- 800]: loss = 0.253803 * 100, metric = 9.25% * 100;
 Minibatch[ 801- 900]: loss = 0.250553 * 100, metric = 9.10% * 100;
 Minibatch[ 901-1000]: loss = 0.255290 * 100, metric = 9.53% * 100;
 Minibatch[1001-1100]: loss = 0.260245 * 100, metric = 9.75% * 100;
 Minibatch[1101-1200]: loss = 0.258588 * 100, metric = 9.60% * 100;
 Minibatch[1201-1300]: loss = 0.262828 * 100, metric = 9.78% * 100;
 Minibatch[1301-1400]: loss = 0.249223 * 100, metric = 9.24% * 100;
 Minibatch[1401-1500]: loss = 0.262163 * 100, metric = 9.89% * 100;
 Minibatch[1501-1600]: loss = 0.242846 * 100, metric = 8.86% * 100;
 Minibatch[1601-1700]: loss = 0.258785 * 100, metric = 9.74% * 100;
 Minibatch[1701-1800]: loss = 0.240060 * 100, metric = 8.88% * 100;
 Minibatch[1801-1900]: loss = 0.245406 * 100, metric = 8.96% * 100;
 Minibatch[1901-2000]: loss = 0.255117 * 100, metric = 9.18% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.252274 * 2000, metric = 9.33% * 2000 944.258s (  2.1 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 17.61% * 2000;
 Minibatch[   1- 100]: loss = 0.255209 * 100, metric = 9.46% * 100;
 Minibatch[ 101- 200]: loss = 0.256835 * 100, metric = 9.68% * 100;
 Minibatch[ 201- 300]: loss = 0.247709 * 100, metric = 9.09% * 100;
 Minibatch[ 301- 400]: loss = 0.256556 * 100, metric = 9.53% * 100;
 Minibatch[ 401- 500]: loss = 0.263544 * 100, metric = 9.87% * 100;
 Minibatch[ 501- 600]: loss = 0.267051 * 100, metric = 9.87% * 100;
 Minibatch[ 601- 700]: loss = 0.247471 * 100, metric = 8.73% * 100;
 Minibatch[ 701- 800]: loss = 0.242843 * 100, metric = 9.00% * 100;
 Minibatch[ 801- 900]: loss = 0.246797 * 100, metric = 9.09% * 100;
 Minibatch[ 901-1000]: loss = 0.258721 * 100, metric = 9.60% * 100;
 Minibatch[1001-1100]: loss = 0.260882 * 100, metric = 9.70% * 100;
 Minibatch[1101-1200]: loss = 0.245351 * 100, metric = 9.02% * 100;
 Minibatch[1201-1300]: loss = 0.249460 * 100, metric = 9.44% * 100;
 Minibatch[1301-1400]: loss = 0.248041 * 100, metric = 9.05% * 100;
 Minibatch[1401-1500]: loss = 0.243263 * 100, metric = 8.98% * 100;
 Minibatch[1501-1600]: loss = 0.239045 * 100, metric = 8.77% * 100;
 Minibatch[1601-1700]: loss = 0.241506 * 100, metric = 8.87% * 100;
 Minibatch[1701-1800]: loss = 0.245750 * 100, metric = 8.86% * 100;
 Minibatch[1801-1900]: loss = 0.236706 * 100, metric = 8.64% * 100;
 Minibatch[1901-2000]: loss = 0.256993 * 100, metric = 9.56% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.250487 * 2000, metric = 9.24% * 2000 913.871s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 18.76% * 2000;
 Minibatch[   1- 100]: loss = 0.245115 * 100, metric = 8.88% * 100;
 Minibatch[ 101- 200]: loss = 0.242312 * 100, metric = 8.95% * 100;
 Minibatch[ 201- 300]: loss = 0.252355 * 100, metric = 9.42% * 100;
 Minibatch[ 301- 400]: loss = 0.243658 * 100, metric = 9.01% * 100;
 Minibatch[ 401- 500]: loss = 0.245667 * 100, metric = 8.98% * 100;
 Minibatch[ 501- 600]: loss = 0.244129 * 100, metric = 9.11% * 100;
 Minibatch[ 601- 700]: loss = 0.244182 * 100, metric = 8.76% * 100;
 Minibatch[ 701- 800]: loss = 0.258544 * 100, metric = 9.54% * 100;
 Minibatch[ 801- 900]: loss = 0.256557 * 100, metric = 9.40% * 100;
 Minibatch[ 901-1000]: loss = 0.246727 * 100, metric = 9.16% * 100;
 Minibatch[1001-1100]: loss = 0.249941 * 100, metric = 9.01% * 100;
 Minibatch[1101-1200]: loss = 0.244767 * 100, metric = 8.90% * 100;
 Minibatch[1201-1300]: loss = 0.231634 * 100, metric = 8.61% * 100;
 Minibatch[1301-1400]: loss = 0.245761 * 100, metric = 9.21% * 100;
 Minibatch[1401-1500]: loss = 0.246292 * 100, metric = 9.14% * 100;
 Minibatch[1501-1600]: loss = 0.237044 * 100, metric = 8.94% * 100;
 Minibatch[1601-1700]: loss = 0.243370 * 100, metric = 9.07% * 100;
 Minibatch[1701-1800]: loss = 0.233473 * 100, metric = 8.51% * 100;
 Minibatch[1801-1900]: loss = 0.237729 * 100, metric = 8.84% * 100;
 Minibatch[1901-2000]: loss = 0.248193 * 100, metric = 9.14% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.244873 * 2000, metric = 9.03% * 2000 908.293s (  2.2 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 18.20% * 2000;
 Minibatch[   1- 100]: loss = 0.234820 * 100, metric = 8.62% * 100;
 Minibatch[ 101- 200]: loss = 0.240906 * 100, metric = 8.95% * 100;
 Minibatch[ 201- 300]: loss = 0.241728 * 100, metric = 9.05% * 100;
 Minibatch[ 301- 400]: loss = 0.234270 * 100, metric = 8.63% * 100;
 Minibatch[ 401- 500]: loss = 0.239638 * 100, metric = 9.01% * 100;
 Minibatch[ 501- 600]: loss = 0.228245 * 100, metric = 8.23% * 100;
 Minibatch[ 601- 700]: loss = 0.227044 * 100, metric = 8.38% * 100;
 Minibatch[ 701- 800]: loss = 0.247484 * 100, metric = 9.11% * 100;
 Minibatch[ 801- 900]: loss = 0.261172 * 100, metric = 9.56% * 100;
 Minibatch[ 901-1000]: loss = 0.237956 * 100, metric = 8.96% * 100;
 Minibatch[1001-1100]: loss = 0.245892 * 100, metric = 9.20% * 100;
 Minibatch[1101-1200]: loss = 0.239676 * 100, metric = 8.82% * 100;
 Minibatch[1201-1300]: loss = 0.227101 * 100, metric = 8.38% * 100;
 Minibatch[1301-1400]: loss = 0.255946 * 100, metric = 9.37% * 100;
 Minibatch[1401-1500]: loss = 0.217518 * 100, metric = 7.99% * 100;
 Minibatch[1501-1600]: loss = 0.233726 * 100, metric = 8.72% * 100;
 Minibatch[1601-1700]: loss = 0.240311 * 100, metric = 8.81% * 100;
 Minibatch[1701-1800]: loss = 0.226731 * 100, metric = 8.13% * 100;
 Minibatch[1801-1900]: loss = 0.234331 * 100, metric = 8.57% * 100;
 Minibatch[1901-2000]: loss = 0.231471 * 100, metric = 8.70% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.237298 * 2000, metric = 8.76% * 2000 902.078s (  2.2 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 15.71% * 2000;
 Minibatch[   1- 100]: loss = 0.243715 * 100, metric = 9.17% * 100;
 Minibatch[ 101- 200]: loss = 0.232584 * 100, metric = 8.42% * 100;
 Minibatch[ 201- 300]: loss = 0.235848 * 100, metric = 8.73% * 100;
 Minibatch[ 301- 400]: loss = 0.239793 * 100, metric = 8.91% * 100;
 Minibatch[ 401- 500]: loss = 0.222645 * 100, metric = 8.13% * 100;
 Minibatch[ 501- 600]: loss = 0.234801 * 100, metric = 8.28% * 100;
 Minibatch[ 601- 700]: loss = 0.228870 * 100, metric = 8.55% * 100;
 Minibatch[ 701- 800]: loss = 0.230951 * 100, metric = 8.57% * 100;
 Minibatch[ 801- 900]: loss = 0.222259 * 100, metric = 8.17% * 100;
 Minibatch[ 901-1000]: loss = 0.233284 * 100, metric = 8.60% * 100;
 Minibatch[1001-1100]: loss = 0.224706 * 100, metric = 8.42% * 100;
 Minibatch[1101-1200]: loss = 0.229391 * 100, metric = 8.45% * 100;
 Minibatch[1201-1300]: loss = 0.217817 * 100, metric = 7.99% * 100;
 Minibatch[1301-1400]: loss = 0.220736 * 100, metric = 8.00% * 100;
 Minibatch[1401-1500]: loss = 0.225114 * 100, metric = 8.45% * 100;
 Minibatch[1501-1600]: loss = 0.223792 * 100, metric = 8.31% * 100;
 Minibatch[1601-1700]: loss = 0.227056 * 100, metric = 8.43% * 100;
 Minibatch[1701-1800]: loss = 0.238000 * 100, metric = 8.63% * 100;
 Minibatch[1801-1900]: loss = 0.239066 * 100, metric = 8.86% * 100;
 Minibatch[1901-2000]: loss = 0.219400 * 100, metric = 8.29% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.229491 * 2000, metric = 8.47% * 2000 920.400s (  2.2 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 15.49% * 2000;
0.417937622923404
 Minibatch[   1- 100]: loss = 0.217680 * 100, metric = 8.19% * 100;
 Minibatch[ 101- 200]: loss = 0.235348 * 100, metric = 8.66% * 100;
 Minibatch[ 201- 300]: loss = 0.236786 * 100, metric = 8.62% * 100;
 Minibatch[ 301- 400]: loss = 0.224378 * 100, metric = 8.44% * 100;
 Minibatch[ 401- 500]: loss = 0.226792 * 100, metric = 8.37% * 100;
 Minibatch[ 501- 600]: loss = 0.219489 * 100, metric = 7.96% * 100;
 Minibatch[ 601- 700]: loss = 0.211314 * 100, metric = 7.72% * 100;
 Minibatch[ 701- 800]: loss = 0.228443 * 100, metric = 8.36% * 100;
 Minibatch[ 801- 900]: loss = 0.227898 * 100, metric = 8.28% * 100;
 Minibatch[ 901-1000]: loss = 0.224303 * 100, metric = 8.20% * 100;
 Minibatch[1001-1100]: loss = 0.217045 * 100, metric = 7.89% * 100;
 Minibatch[1101-1200]: loss = 0.233857 * 100, metric = 8.71% * 100;
 Minibatch[1201-1300]: loss = 0.232235 * 100, metric = 8.59% * 100;
 Minibatch[1301-1400]: loss = 0.215401 * 100, metric = 8.15% * 100;
 Minibatch[1401-1500]: loss = 0.227067 * 100, metric = 8.41% * 100;
 Minibatch[1501-1600]: loss = 0.226078 * 100, metric = 8.47% * 100;
 Minibatch[1601-1700]: loss = 0.225501 * 100, metric = 8.30% * 100;
 Minibatch[1701-1800]: loss = 0.218363 * 100, metric = 7.91% * 100;
 Minibatch[1801-1900]: loss = 0.236435 * 100, metric = 8.77% * 100;
 Minibatch[1901-2000]: loss = 0.237795 * 100, metric = 8.87% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.226111 * 2000, metric = 8.34% * 2000 939.795s (  2.1 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 15.11% * 2000;
 Minibatch[   1- 100]: loss = 0.211156 * 100, metric = 7.69% * 100;
 Minibatch[ 101- 200]: loss = 0.227291 * 100, metric = 8.47% * 100;
 Minibatch[ 201- 300]: loss = 0.220249 * 100, metric = 8.29% * 100;
 Minibatch[ 301- 400]: loss = 0.220254 * 100, metric = 8.05% * 100;
 Minibatch[ 401- 500]: loss = 0.212219 * 100, metric = 7.75% * 100;
 Minibatch[ 501- 600]: loss = 0.216362 * 100, metric = 7.84% * 100;
 Minibatch[ 601- 700]: loss = 0.222626 * 100, metric = 8.11% * 100;
 Minibatch[ 701- 800]: loss = 0.218956 * 100, metric = 8.08% * 100;
 Minibatch[ 801- 900]: loss = 0.220958 * 100, metric = 7.99% * 100;
 Minibatch[ 901-1000]: loss = 0.228463 * 100, metric = 8.53% * 100;
 Minibatch[1001-1100]: loss = 0.229321 * 100, metric = 8.39% * 100;
 Minibatch[1101-1200]: loss = 0.220086 * 100, metric = 8.09% * 100;
 Minibatch[1201-1300]: loss = 0.232096 * 100, metric = 8.54% * 100;
 Minibatch[1301-1400]: loss = 0.229749 * 100, metric = 8.22% * 100;
 Minibatch[1401-1500]: loss = 0.209970 * 100, metric = 7.65% * 100;
 Minibatch[1501-1600]: loss = 0.221821 * 100, metric = 8.05% * 100;
 Minibatch[1601-1700]: loss = 0.212765 * 100, metric = 7.77% * 100;
 Minibatch[1701-1800]: loss = 0.214307 * 100, metric = 7.96% * 100;
 Minibatch[1801-1900]: loss = 0.210353 * 100, metric = 7.71% * 100;
 Minibatch[1901-2000]: loss = 0.212479 * 100, metric = 7.62% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.219574 * 2000, metric = 8.04% * 2000 899.882s (  2.2 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.84% * 2000;
 Minibatch[   1- 100]: loss = 0.227643 * 100, metric = 8.32% * 100;
 Minibatch[ 101- 200]: loss = 0.233278 * 100, metric = 8.45% * 100;
 Minibatch[ 201- 300]: loss = 0.208710 * 100, metric = 7.59% * 100;
 Minibatch[ 301- 400]: loss = 0.216543 * 100, metric = 7.81% * 100;
 Minibatch[ 401- 500]: loss = 0.218901 * 100, metric = 7.92% * 100;
 Minibatch[ 501- 600]: loss = 0.211027 * 100, metric = 7.74% * 100;
 Minibatch[ 601- 700]: loss = 0.222617 * 100, metric = 8.25% * 100;
 Minibatch[ 701- 800]: loss = 0.210465 * 100, metric = 7.76% * 100;
 Minibatch[ 801- 900]: loss = 0.235315 * 100, metric = 8.51% * 100;
 Minibatch[ 901-1000]: loss = 0.208001 * 100, metric = 7.66% * 100;
 Minibatch[1001-1100]: loss = 0.221508 * 100, metric = 8.26% * 100;
 Minibatch[1101-1200]: loss = 0.219278 * 100, metric = 8.41% * 100;
 Minibatch[1201-1300]: loss = 0.209940 * 100, metric = 7.94% * 100;
 Minibatch[1301-1400]: loss = 0.207800 * 100, metric = 7.67% * 100;
 Minibatch[1401-1500]: loss = 0.221234 * 100, metric = 8.33% * 100;
 Minibatch[1501-1600]: loss = 0.221151 * 100, metric = 8.09% * 100;
 Minibatch[1601-1700]: loss = 0.214055 * 100, metric = 7.92% * 100;
 Minibatch[1701-1800]: loss = 0.204909 * 100, metric = 7.64% * 100;
 Minibatch[1801-1900]: loss = 0.211063 * 100, metric = 7.82% * 100;
 Minibatch[1901-2000]: loss = 0.205424 * 100, metric = 7.52% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.216443 * 2000, metric = 7.98% * 2000 894.082s (  2.2 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 15.95% * 2000;
 Minibatch[   1- 100]: loss = 0.206303 * 100, metric = 7.37% * 100;
 Minibatch[ 101- 200]: loss = 0.210063 * 100, metric = 7.65% * 100;
 Minibatch[ 201- 300]: loss = 0.201040 * 100, metric = 7.36% * 100;
 Minibatch[ 301- 400]: loss = 0.219129 * 100, metric = 7.74% * 100;
 Minibatch[ 401- 500]: loss = 0.212580 * 100, metric = 8.09% * 100;
 Minibatch[ 501- 600]: loss = 0.214864 * 100, metric = 7.86% * 100;
 Minibatch[ 601- 700]: loss = 0.221350 * 100, metric = 8.32% * 100;
 Minibatch[ 701- 800]: loss = 0.212811 * 100, metric = 7.77% * 100;
 Minibatch[ 801- 900]: loss = 0.220719 * 100, metric = 8.14% * 100;
 Minibatch[ 901-1000]: loss = 0.219208 * 100, metric = 8.07% * 100;
 Minibatch[1001-1100]: loss = 0.198764 * 100, metric = 7.41% * 100;
 Minibatch[1101-1200]: loss = 0.207798 * 100, metric = 7.64% * 100;
 Minibatch[1201-1300]: loss = 0.217674 * 100, metric = 7.74% * 100;
 Minibatch[1301-1400]: loss = 0.218388 * 100, metric = 7.98% * 100;
 Minibatch[1401-1500]: loss = 0.211590 * 100, metric = 7.92% * 100;
 Minibatch[1501-1600]: loss = 0.220926 * 100, metric = 7.98% * 100;
 Minibatch[1601-1700]: loss = 0.212935 * 100, metric = 7.69% * 100;
 Minibatch[1701-1800]: loss = 0.214764 * 100, metric = 7.99% * 100;
 Minibatch[1801-1900]: loss = 0.210093 * 100, metric = 7.72% * 100;
 Minibatch[1901-2000]: loss = 0.207878 * 100, metric = 7.61% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.212944 * 2000, metric = 7.80% * 2000 893.053s (  2.2 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 16.48% * 2000;
 Minibatch[   1- 100]: loss = 0.214237 * 100, metric = 7.94% * 100;
 Minibatch[ 101- 200]: loss = 0.212562 * 100, metric = 7.82% * 100;
 Minibatch[ 201- 300]: loss = 0.213532 * 100, metric = 7.92% * 100;
 Minibatch[ 301- 400]: loss = 0.217673 * 100, metric = 8.23% * 100;
 Minibatch[ 401- 500]: loss = 0.207225 * 100, metric = 7.61% * 100;
 Minibatch[ 501- 600]: loss = 0.202332 * 100, metric = 7.61% * 100;
 Minibatch[ 601- 700]: loss = 0.209934 * 100, metric = 7.71% * 100;
 Minibatch[ 701- 800]: loss = 0.193149 * 100, metric = 7.18% * 100;
 Minibatch[ 801- 900]: loss = 0.209435 * 100, metric = 7.69% * 100;
 Minibatch[ 901-1000]: loss = 0.207735 * 100, metric = 7.72% * 100;
 Minibatch[1001-1100]: loss = 0.206848 * 100, metric = 7.46% * 100;
 Minibatch[1101-1200]: loss = 0.206383 * 100, metric = 7.33% * 100;
 Minibatch[1201-1300]: loss = 0.208429 * 100, metric = 7.44% * 100;
 Minibatch[1301-1400]: loss = 0.201308 * 100, metric = 7.29% * 100;
 Minibatch[1401-1500]: loss = 0.206645 * 100, metric = 7.56% * 100;
 Minibatch[1501-1600]: loss = 0.220132 * 100, metric = 8.43% * 100;
 Minibatch[1601-1700]: loss = 0.203029 * 100, metric = 7.42% * 100;
 Minibatch[1701-1800]: loss = 0.200961 * 100, metric = 7.34% * 100;
 Minibatch[1801-1900]: loss = 0.221449 * 100, metric = 8.20% * 100;
 Minibatch[1901-2000]: loss = 0.203169 * 100, metric = 7.25% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.208308 * 2000, metric = 7.66% * 2000 907.251s (  2.2 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 14.49% * 2000;
 Minibatch[   1- 100]: loss = 0.217686 * 100, metric = 8.10% * 100;
 Minibatch[ 101- 200]: loss = 0.210523 * 100, metric = 7.69% * 100;
 Minibatch[ 201- 300]: loss = 0.213869 * 100, metric = 8.05% * 100;
 Minibatch[ 301- 400]: loss = 0.205802 * 100, metric = 7.51% * 100;
 Minibatch[ 401- 500]: loss = 0.204892 * 100, metric = 7.34% * 100;
 Minibatch[ 501- 600]: loss = 0.211151 * 100, metric = 7.72% * 100;
 Minibatch[ 601- 700]: loss = 0.199736 * 100, metric = 7.42% * 100;
 Minibatch[ 701- 800]: loss = 0.208576 * 100, metric = 7.86% * 100;
 Minibatch[ 801- 900]: loss = 0.209857 * 100, metric = 7.93% * 100;
 Minibatch[ 901-1000]: loss = 0.215167 * 100, metric = 8.13% * 100;
 Minibatch[1001-1100]: loss = 0.204007 * 100, metric = 7.32% * 100;
 Minibatch[1101-1200]: loss = 0.189713 * 100, metric = 7.07% * 100;
 Minibatch[1201-1300]: loss = 0.206507 * 100, metric = 7.73% * 100;
 Minibatch[1301-1400]: loss = 0.207278 * 100, metric = 7.57% * 100;
 Minibatch[1401-1500]: loss = 0.205347 * 100, metric = 7.67% * 100;
 Minibatch[1501-1600]: loss = 0.198553 * 100, metric = 7.32% * 100;
 Minibatch[1601-1700]: loss = 0.202635 * 100, metric = 7.44% * 100;
 Minibatch[1701-1800]: loss = 0.203796 * 100, metric = 7.37% * 100;
 Minibatch[1801-1900]: loss = 0.201418 * 100, metric = 7.32% * 100;
 Minibatch[1901-2000]: loss = 0.201152 * 100, metric = 7.13% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.205883 * 2000, metric = 7.58% * 2000 899.340s (  2.2 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 15.85% * 2000;
 Minibatch[   1- 100]: loss = 0.206606 * 100, metric = 7.56% * 100;
 Minibatch[ 101- 200]: loss = 0.212058 * 100, metric = 7.87% * 100;
 Minibatch[ 201- 300]: loss = 0.200949 * 100, metric = 7.55% * 100;
 Minibatch[ 301- 400]: loss = 0.207829 * 100, metric = 7.59% * 100;
 Minibatch[ 401- 500]: loss = 0.209204 * 100, metric = 7.76% * 100;
 Minibatch[ 501- 600]: loss = 0.202340 * 100, metric = 7.43% * 100;
 Minibatch[ 601- 700]: loss = 0.205046 * 100, metric = 7.43% * 100;
 Minibatch[ 701- 800]: loss = 0.187604 * 100, metric = 6.86% * 100;
 Minibatch[ 801- 900]: loss = 0.195396 * 100, metric = 7.30% * 100;
 Minibatch[ 901-1000]: loss = 0.205906 * 100, metric = 7.50% * 100;
 Minibatch[1001-1100]: loss = 0.194843 * 100, metric = 6.98% * 100;
 Minibatch[1101-1200]: loss = 0.198230 * 100, metric = 7.40% * 100;
 Minibatch[1201-1300]: loss = 0.203119 * 100, metric = 7.66% * 100;
 Minibatch[1301-1400]: loss = 0.206458 * 100, metric = 7.72% * 100;
 Minibatch[1401-1500]: loss = 0.198624 * 100, metric = 7.44% * 100;
 Minibatch[1501-1600]: loss = 0.199447 * 100, metric = 7.30% * 100;
 Minibatch[1601-1700]: loss = 0.198114 * 100, metric = 7.41% * 100;
 Minibatch[1701-1800]: loss = 0.207089 * 100, metric = 7.76% * 100;
 Minibatch[1801-1900]: loss = 0.206931 * 100, metric = 7.74% * 100;
 Minibatch[1901-2000]: loss = 0.201902 * 100, metric = 7.48% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.202385 * 2000, metric = 7.49% * 2000 884.484s (  2.3 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 15.44% * 2000;
 Minibatch[   1- 100]: loss = 0.192714 * 100, metric = 7.23% * 100;
 Minibatch[ 101- 200]: loss = 0.204522 * 100, metric = 7.77% * 100;
 Minibatch[ 201- 300]: loss = 0.202022 * 100, metric = 7.54% * 100;
 Minibatch[ 301- 400]: loss = 0.198786 * 100, metric = 7.35% * 100;
 Minibatch[ 401- 500]: loss = 0.202108 * 100, metric = 7.55% * 100;
 Minibatch[ 501- 600]: loss = 0.197151 * 100, metric = 7.53% * 100;
 Minibatch[ 601- 700]: loss = 0.203759 * 100, metric = 7.31% * 100;
 Minibatch[ 701- 800]: loss = 0.199820 * 100, metric = 7.54% * 100;
 Minibatch[ 801- 900]: loss = 0.208982 * 100, metric = 7.96% * 100;
 Minibatch[ 901-1000]: loss = 0.202825 * 100, metric = 7.46% * 100;
 Minibatch[1001-1100]: loss = 0.201418 * 100, metric = 7.62% * 100;
 Minibatch[1101-1200]: loss = 0.213702 * 100, metric = 7.83% * 100;
 Minibatch[1201-1300]: loss = 0.208781 * 100, metric = 7.87% * 100;
 Minibatch[1301-1400]: loss = 0.196026 * 100, metric = 7.23% * 100;
 Minibatch[1401-1500]: loss = 0.195699 * 100, metric = 7.25% * 100;
 Minibatch[1501-1600]: loss = 0.204392 * 100, metric = 7.56% * 100;
 Minibatch[1601-1700]: loss = 0.196341 * 100, metric = 7.18% * 100;
 Minibatch[1701-1800]: loss = 0.191529 * 100, metric = 6.97% * 100;
 Minibatch[1801-1900]: loss = 0.207470 * 100, metric = 7.59% * 100;
 Minibatch[1901-2000]: loss = 0.202613 * 100, metric = 7.53% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.201533 * 2000, metric = 7.49% * 2000 879.261s (  2.3 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.33% * 2000;
0.4169684827402234
 Minibatch[   1- 100]: loss = 0.202118 * 100, metric = 7.34% * 100;
 Minibatch[ 101- 200]: loss = 0.202379 * 100, metric = 7.47% * 100;
 Minibatch[ 201- 300]: loss = 0.199994 * 100, metric = 7.42% * 100;
 Minibatch[ 301- 400]: loss = 0.195928 * 100, metric = 7.39% * 100;
 Minibatch[ 401- 500]: loss = 0.201828 * 100, metric = 7.33% * 100;
 Minibatch[ 501- 600]: loss = 0.203612 * 100, metric = 7.63% * 100;
 Minibatch[ 601- 700]: loss = 0.201695 * 100, metric = 7.45% * 100;
 Minibatch[ 701- 800]: loss = 0.190457 * 100, metric = 6.94% * 100;
 Minibatch[ 801- 900]: loss = 0.195081 * 100, metric = 7.25% * 100;
 Minibatch[ 901-1000]: loss = 0.199319 * 100, metric = 7.50% * 100;
 Minibatch[1001-1100]: loss = 0.199780 * 100, metric = 7.53% * 100;
 Minibatch[1101-1200]: loss = 0.206334 * 100, metric = 7.55% * 100;
 Minibatch[1201-1300]: loss = 0.213868 * 100, metric = 7.88% * 100;
 Minibatch[1301-1400]: loss = 0.194211 * 100, metric = 7.28% * 100;
 Minibatch[1401-1500]: loss = 0.186612 * 100, metric = 6.71% * 100;
 Minibatch[1501-1600]: loss = 0.206619 * 100, metric = 7.71% * 100;
 Minibatch[1601-1700]: loss = 0.199193 * 100, metric = 7.52% * 100;
 Minibatch[1701-1800]: loss = 0.199258 * 100, metric = 7.49% * 100;
 Minibatch[1801-1900]: loss = 0.191121 * 100, metric = 7.11% * 100;
 Minibatch[1901-2000]: loss = 0.185931 * 100, metric = 6.79% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.198767 * 2000, metric = 7.36% * 2000 888.657s (  2.3 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.69% * 2000;
 Minibatch[   1- 100]: loss = 0.196381 * 100, metric = 7.23% * 100;
 Minibatch[ 101- 200]: loss = 0.186321 * 100, metric = 6.86% * 100;
 Minibatch[ 201- 300]: loss = 0.191770 * 100, metric = 7.06% * 100;
 Minibatch[ 301- 400]: loss = 0.184006 * 100, metric = 6.73% * 100;
 Minibatch[ 401- 500]: loss = 0.196841 * 100, metric = 7.26% * 100;
 Minibatch[ 501- 600]: loss = 0.187993 * 100, metric = 6.64% * 100;
 Minibatch[ 601- 700]: loss = 0.204108 * 100, metric = 7.34% * 100;
 Minibatch[ 701- 800]: loss = 0.190565 * 100, metric = 7.19% * 100;
 Minibatch[ 801- 900]: loss = 0.180054 * 100, metric = 6.71% * 100;
 Minibatch[ 901-1000]: loss = 0.183275 * 100, metric = 6.81% * 100;
 Minibatch[1001-1100]: loss = 0.199582 * 100, metric = 7.50% * 100;
 Minibatch[1101-1200]: loss = 0.198733 * 100, metric = 7.24% * 100;
 Minibatch[1201-1300]: loss = 0.191112 * 100, metric = 7.04% * 100;
 Minibatch[1301-1400]: loss = 0.181895 * 100, metric = 6.61% * 100;
 Minibatch[1401-1500]: loss = 0.188381 * 100, metric = 6.96% * 100;
 Minibatch[1501-1600]: loss = 0.179607 * 100, metric = 6.51% * 100;
 Minibatch[1601-1700]: loss = 0.200587 * 100, metric = 7.31% * 100;
 Minibatch[1701-1800]: loss = 0.197018 * 100, metric = 7.21% * 100;
 Minibatch[1801-1900]: loss = 0.187807 * 100, metric = 6.72% * 100;
 Minibatch[1901-2000]: loss = 0.192049 * 100, metric = 7.08% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.190904 * 2000, metric = 7.00% * 2000 894.319s (  2.2 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.67% * 2000;
 Minibatch[   1- 100]: loss = 0.188815 * 100, metric = 6.70% * 100;
 Minibatch[ 101- 200]: loss = 0.196722 * 100, metric = 7.20% * 100;
 Minibatch[ 201- 300]: loss = 0.187775 * 100, metric = 6.84% * 100;
 Minibatch[ 301- 400]: loss = 0.187215 * 100, metric = 6.82% * 100;
 Minibatch[ 401- 500]: loss = 0.193687 * 100, metric = 7.20% * 100;
 Minibatch[ 501- 600]: loss = 0.186723 * 100, metric = 6.82% * 100;
 Minibatch[ 601- 700]: loss = 0.185241 * 100, metric = 6.85% * 100;
 Minibatch[ 701- 800]: loss = 0.186711 * 100, metric = 6.76% * 100;
 Minibatch[ 801- 900]: loss = 0.192431 * 100, metric = 6.82% * 100;
 Minibatch[ 901-1000]: loss = 0.190316 * 100, metric = 6.95% * 100;
 Minibatch[1001-1100]: loss = 0.181032 * 100, metric = 6.52% * 100;
 Minibatch[1101-1200]: loss = 0.192469 * 100, metric = 7.04% * 100;
 Minibatch[1201-1300]: loss = 0.186962 * 100, metric = 6.91% * 100;
 Minibatch[1301-1400]: loss = 0.193215 * 100, metric = 7.17% * 100;
 Minibatch[1401-1500]: loss = 0.188453 * 100, metric = 6.96% * 100;
 Minibatch[1501-1600]: loss = 0.186333 * 100, metric = 6.64% * 100;
 Minibatch[1601-1700]: loss = 0.176635 * 100, metric = 6.32% * 100;
 Minibatch[1701-1800]: loss = 0.187258 * 100, metric = 6.70% * 100;
 Minibatch[1801-1900]: loss = 0.189513 * 100, metric = 6.83% * 100;
 Minibatch[1901-2000]: loss = 0.188484 * 100, metric = 6.72% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.188299 * 2000, metric = 6.84% * 2000 906.628s (  2.2 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 14.20% * 2000;
 Minibatch[   1- 100]: loss = 0.193813 * 100, metric = 7.15% * 100;
 Minibatch[ 101- 200]: loss = 0.180700 * 100, metric = 6.50% * 100;
 Minibatch[ 201- 300]: loss = 0.190527 * 100, metric = 6.90% * 100;
 Minibatch[ 301- 400]: loss = 0.183829 * 100, metric = 6.41% * 100;
 Minibatch[ 401- 500]: loss = 0.180204 * 100, metric = 6.57% * 100;
 Minibatch[ 501- 600]: loss = 0.196419 * 100, metric = 7.19% * 100;
 Minibatch[ 601- 700]: loss = 0.176966 * 100, metric = 6.57% * 100;
 Minibatch[ 701- 800]: loss = 0.176443 * 100, metric = 6.43% * 100;
 Minibatch[ 801- 900]: loss = 0.188889 * 100, metric = 6.71% * 100;
 Minibatch[ 901-1000]: loss = 0.196253 * 100, metric = 7.11% * 100;
 Minibatch[1001-1100]: loss = 0.185279 * 100, metric = 6.67% * 100;
 Minibatch[1101-1200]: loss = 0.179431 * 100, metric = 6.57% * 100;
 Minibatch[1201-1300]: loss = 0.191082 * 100, metric = 7.18% * 100;
 Minibatch[1301-1400]: loss = 0.182628 * 100, metric = 6.70% * 100;
 Minibatch[1401-1500]: loss = 0.187756 * 100, metric = 6.86% * 100;
 Minibatch[1501-1600]: loss = 0.179650 * 100, metric = 6.51% * 100;
 Minibatch[1601-1700]: loss = 0.182461 * 100, metric = 6.66% * 100;
 Minibatch[1701-1800]: loss = 0.179427 * 100, metric = 6.59% * 100;
 Minibatch[1801-1900]: loss = 0.184868 * 100, metric = 6.71% * 100;
 Minibatch[1901-2000]: loss = 0.190839 * 100, metric = 7.01% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.185373 * 2000, metric = 6.75% * 2000 893.124s (  2.2 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 14.16% * 2000;
 Minibatch[   1- 100]: loss = 0.178872 * 100, metric = 6.45% * 100;
 Minibatch[ 101- 200]: loss = 0.183605 * 100, metric = 6.72% * 100;
 Minibatch[ 201- 300]: loss = 0.191632 * 100, metric = 7.24% * 100;
 Minibatch[ 301- 400]: loss = 0.197563 * 100, metric = 7.38% * 100;
 Minibatch[ 401- 500]: loss = 0.175259 * 100, metric = 6.40% * 100;
 Minibatch[ 501- 600]: loss = 0.187650 * 100, metric = 6.98% * 100;
 Minibatch[ 601- 700]: loss = 0.180578 * 100, metric = 6.63% * 100;
 Minibatch[ 701- 800]: loss = 0.192026 * 100, metric = 6.99% * 100;
 Minibatch[ 801- 900]: loss = 0.184251 * 100, metric = 6.78% * 100;
 Minibatch[ 901-1000]: loss = 0.186948 * 100, metric = 7.00% * 100;
 Minibatch[1001-1100]: loss = 0.185287 * 100, metric = 6.80% * 100;
 Minibatch[1101-1200]: loss = 0.175402 * 100, metric = 6.40% * 100;
 Minibatch[1201-1300]: loss = 0.181007 * 100, metric = 6.74% * 100;
 Minibatch[1301-1400]: loss = 0.173279 * 100, metric = 6.31% * 100;
 Minibatch[1401-1500]: loss = 0.194528 * 100, metric = 7.07% * 100;
 Minibatch[1501-1600]: loss = 0.173890 * 100, metric = 6.33% * 100;
 Minibatch[1601-1700]: loss = 0.185244 * 100, metric = 6.89% * 100;
 Minibatch[1701-1800]: loss = 0.174332 * 100, metric = 6.44% * 100;
 Minibatch[1801-1900]: loss = 0.192833 * 100, metric = 7.06% * 100;
 Minibatch[1901-2000]: loss = 0.182073 * 100, metric = 6.67% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.183813 * 2000, metric = 6.76% * 2000 882.346s (  2.3 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 16.34% * 2000;
 Minibatch[   1- 100]: loss = 0.186740 * 100, metric = 6.84% * 100;
 Minibatch[ 101- 200]: loss = 0.170938 * 100, metric = 6.30% * 100;
 Minibatch[ 201- 300]: loss = 0.177630 * 100, metric = 6.59% * 100;
 Minibatch[ 301- 400]: loss = 0.182429 * 100, metric = 6.79% * 100;
 Minibatch[ 401- 500]: loss = 0.181117 * 100, metric = 6.72% * 100;
 Minibatch[ 501- 600]: loss = 0.165262 * 100, metric = 6.07% * 100;
 Minibatch[ 601- 700]: loss = 0.181839 * 100, metric = 6.76% * 100;
 Minibatch[ 701- 800]: loss = 0.173363 * 100, metric = 6.43% * 100;
 Minibatch[ 801- 900]: loss = 0.187175 * 100, metric = 6.83% * 100;
 Minibatch[ 901-1000]: loss = 0.166853 * 100, metric = 6.07% * 100;
 Minibatch[1001-1100]: loss = 0.179171 * 100, metric = 6.38% * 100;
 Minibatch[1101-1200]: loss = 0.182759 * 100, metric = 6.62% * 100;
 Minibatch[1201-1300]: loss = 0.175806 * 100, metric = 6.39% * 100;
 Minibatch[1301-1400]: loss = 0.177372 * 100, metric = 6.63% * 100;
 Minibatch[1401-1500]: loss = 0.177423 * 100, metric = 6.43% * 100;
 Minibatch[1501-1600]: loss = 0.181268 * 100, metric = 6.70% * 100;
 Minibatch[1601-1700]: loss = 0.179579 * 100, metric = 6.57% * 100;
 Minibatch[1701-1800]: loss = 0.187722 * 100, metric = 6.97% * 100;
 Minibatch[1801-1900]: loss = 0.183019 * 100, metric = 6.84% * 100;
 Minibatch[1901-2000]: loss = 0.195949 * 100, metric = 7.27% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.179671 * 2000, metric = 6.61% * 2000 875.464s (  2.3 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.76% * 2000;
 Minibatch[   1- 100]: loss = 0.175715 * 100, metric = 6.44% * 100;
 Minibatch[ 101- 200]: loss = 0.187400 * 100, metric = 6.91% * 100;
 Minibatch[ 201- 300]: loss = 0.179774 * 100, metric = 6.57% * 100;
 Minibatch[ 301- 400]: loss = 0.170392 * 100, metric = 6.14% * 100;
 Minibatch[ 401- 500]: loss = 0.181040 * 100, metric = 6.65% * 100;
 Minibatch[ 501- 600]: loss = 0.175704 * 100, metric = 6.36% * 100;
 Minibatch[ 601- 700]: loss = 0.181855 * 100, metric = 6.78% * 100;
 Minibatch[ 701- 800]: loss = 0.182755 * 100, metric = 6.70% * 100;
 Minibatch[ 801- 900]: loss = 0.175578 * 100, metric = 6.36% * 100;
 Minibatch[ 901-1000]: loss = 0.169336 * 100, metric = 6.19% * 100;
 Minibatch[1001-1100]: loss = 0.172419 * 100, metric = 6.21% * 100;
 Minibatch[1101-1200]: loss = 0.179174 * 100, metric = 6.66% * 100;
 Minibatch[1201-1300]: loss = 0.176962 * 100, metric = 6.59% * 100;
 Minibatch[1301-1400]: loss = 0.179514 * 100, metric = 6.53% * 100;
 Minibatch[1401-1500]: loss = 0.180764 * 100, metric = 6.53% * 100;
 Minibatch[1501-1600]: loss = 0.173187 * 100, metric = 6.39% * 100;
 Minibatch[1601-1700]: loss = 0.179826 * 100, metric = 6.65% * 100;
 Minibatch[1701-1800]: loss = 0.177057 * 100, metric = 6.52% * 100;
 Minibatch[1801-1900]: loss = 0.178326 * 100, metric = 6.46% * 100;
 Minibatch[1901-2000]: loss = 0.174482 * 100, metric = 6.40% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.177563 * 2000, metric = 6.50% * 2000 881.394s (  2.3 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 13.95% * 2000;
 Minibatch[   1- 100]: loss = 0.174121 * 100, metric = 6.30% * 100;
 Minibatch[ 101- 200]: loss = 0.176692 * 100, metric = 6.53% * 100;
 Minibatch[ 201- 300]: loss = 0.183033 * 100, metric = 6.63% * 100;
 Minibatch[ 301- 400]: loss = 0.179458 * 100, metric = 6.38% * 100;
 Minibatch[ 401- 500]: loss = 0.181319 * 100, metric = 6.73% * 100;
 Minibatch[ 501- 600]: loss = 0.177758 * 100, metric = 6.49% * 100;
 Minibatch[ 601- 700]: loss = 0.167150 * 100, metric = 6.04% * 100;
 Minibatch[ 701- 800]: loss = 0.169665 * 100, metric = 6.21% * 100;
 Minibatch[ 801- 900]: loss = 0.173811 * 100, metric = 6.29% * 100;
 Minibatch[ 901-1000]: loss = 0.164322 * 100, metric = 6.01% * 100;
 Minibatch[1001-1100]: loss = 0.164068 * 100, metric = 5.89% * 100;
 Minibatch[1101-1200]: loss = 0.174731 * 100, metric = 6.27% * 100;
 Minibatch[1201-1300]: loss = 0.179711 * 100, metric = 6.54% * 100;
 Minibatch[1301-1400]: loss = 0.174357 * 100, metric = 6.29% * 100;
 Minibatch[1401-1500]: loss = 0.171877 * 100, metric = 6.38% * 100;
 Minibatch[1501-1600]: loss = 0.174255 * 100, metric = 6.21% * 100;
 Minibatch[1601-1700]: loss = 0.167959 * 100, metric = 6.18% * 100;
 Minibatch[1701-1800]: loss = 0.179913 * 100, metric = 6.58% * 100;
 Minibatch[1801-1900]: loss = 0.163037 * 100, metric = 5.98% * 100;
 Minibatch[1901-2000]: loss = 0.181140 * 100, metric = 6.76% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.173919 * 2000, metric = 6.33% * 2000 919.366s (  2.2 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.68% * 2000;
 Minibatch[   1- 100]: loss = 0.185515 * 100, metric = 6.68% * 100;
 Minibatch[ 101- 200]: loss = 0.171294 * 100, metric = 6.27% * 100;
 Minibatch[ 201- 300]: loss = 0.169762 * 100, metric = 6.07% * 100;
 Minibatch[ 301- 400]: loss = 0.178759 * 100, metric = 6.64% * 100;
 Minibatch[ 401- 500]: loss = 0.171418 * 100, metric = 6.34% * 100;
 Minibatch[ 501- 600]: loss = 0.174325 * 100, metric = 6.36% * 100;
 Minibatch[ 601- 700]: loss = 0.174389 * 100, metric = 6.32% * 100;
 Minibatch[ 701- 800]: loss = 0.168529 * 100, metric = 6.09% * 100;
 Minibatch[ 801- 900]: loss = 0.166923 * 100, metric = 6.05% * 100;
 Minibatch[ 901-1000]: loss = 0.163376 * 100, metric = 6.03% * 100;
 Minibatch[1001-1100]: loss = 0.170155 * 100, metric = 6.34% * 100;
 Minibatch[1101-1200]: loss = 0.163030 * 100, metric = 5.98% * 100;
 Minibatch[1201-1300]: loss = 0.176422 * 100, metric = 6.28% * 100;
 Minibatch[1301-1400]: loss = 0.161807 * 100, metric = 5.92% * 100;
 Minibatch[1401-1500]: loss = 0.181365 * 100, metric = 6.29% * 100;
 Minibatch[1501-1600]: loss = 0.174404 * 100, metric = 6.39% * 100;
 Minibatch[1601-1700]: loss = 0.167824 * 100, metric = 6.09% * 100;
 Minibatch[1701-1800]: loss = 0.164937 * 100, metric = 6.07% * 100;
 Minibatch[1801-1900]: loss = 0.169851 * 100, metric = 6.26% * 100;
 Minibatch[1901-2000]: loss = 0.184326 * 100, metric = 6.80% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.171920 * 2000, metric = 6.26% * 2000 946.336s (  2.1 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 14.51% * 2000;
 Minibatch[   1- 100]: loss = 0.161624 * 100, metric = 5.86% * 100;
 Minibatch[ 101- 200]: loss = 0.172102 * 100, metric = 6.33% * 100;
 Minibatch[ 201- 300]: loss = 0.165841 * 100, metric = 6.17% * 100;
 Minibatch[ 301- 400]: loss = 0.174656 * 100, metric = 6.32% * 100;
 Minibatch[ 401- 500]: loss = 0.167942 * 100, metric = 6.02% * 100;
 Minibatch[ 501- 600]: loss = 0.172118 * 100, metric = 6.24% * 100;
 Minibatch[ 601- 700]: loss = 0.173020 * 100, metric = 6.48% * 100;
 Minibatch[ 701- 800]: loss = 0.165701 * 100, metric = 6.04% * 100;
 Minibatch[ 801- 900]: loss = 0.163575 * 100, metric = 5.86% * 100;
 Minibatch[ 901-1000]: loss = 0.169792 * 100, metric = 6.31% * 100;
 Minibatch[1001-1100]: loss = 0.170322 * 100, metric = 6.13% * 100;
 Minibatch[1101-1200]: loss = 0.166096 * 100, metric = 6.16% * 100;
 Minibatch[1201-1300]: loss = 0.168662 * 100, metric = 6.10% * 100;
 Minibatch[1301-1400]: loss = 0.167492 * 100, metric = 5.97% * 100;
 Minibatch[1401-1500]: loss = 0.172566 * 100, metric = 6.23% * 100;
 Minibatch[1501-1600]: loss = 0.169252 * 100, metric = 6.25% * 100;
 Minibatch[1601-1700]: loss = 0.178144 * 100, metric = 6.52% * 100;
 Minibatch[1701-1800]: loss = 0.168826 * 100, metric = 6.24% * 100;
 Minibatch[1801-1900]: loss = 0.167361 * 100, metric = 6.08% * 100;
 Minibatch[1901-2000]: loss = 0.169532 * 100, metric = 6.12% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.169231 * 2000, metric = 6.17% * 2000 941.001s (  2.1 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 15.46% * 2000;
 Minibatch[   1- 100]: loss = 0.160152 * 100, metric = 5.68% * 100;
 Minibatch[ 101- 200]: loss = 0.168773 * 100, metric = 6.14% * 100;
 Minibatch[ 201- 300]: loss = 0.168014 * 100, metric = 6.11% * 100;
 Minibatch[ 301- 400]: loss = 0.157307 * 100, metric = 5.84% * 100;
 Minibatch[ 401- 500]: loss = 0.164432 * 100, metric = 6.02% * 100;
 Minibatch[ 501- 600]: loss = 0.156383 * 100, metric = 5.70% * 100;
 Minibatch[ 601- 700]: loss = 0.173250 * 100, metric = 6.42% * 100;
 Minibatch[ 701- 800]: loss = 0.157813 * 100, metric = 5.73% * 100;
 Minibatch[ 801- 900]: loss = 0.170385 * 100, metric = 6.21% * 100;
 Minibatch[ 901-1000]: loss = 0.161609 * 100, metric = 5.75% * 100;
 Minibatch[1001-1100]: loss = 0.169243 * 100, metric = 6.06% * 100;
 Minibatch[1101-1200]: loss = 0.162770 * 100, metric = 5.98% * 100;
 Minibatch[1201-1300]: loss = 0.166408 * 100, metric = 6.03% * 100;
 Minibatch[1301-1400]: loss = 0.176178 * 100, metric = 6.54% * 100;
 Minibatch[1401-1500]: loss = 0.160347 * 100, metric = 5.87% * 100;
 Minibatch[1501-1600]: loss = 0.166904 * 100, metric = 6.03% * 100;
 Minibatch[1601-1700]: loss = 0.165554 * 100, metric = 5.96% * 100;
 Minibatch[1701-1800]: loss = 0.162326 * 100, metric = 5.98% * 100;
 Minibatch[1801-1900]: loss = 0.173645 * 100, metric = 6.40% * 100;
 Minibatch[1901-2000]: loss = 0.159691 * 100, metric = 5.87% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.165059 * 2000, metric = 6.02% * 2000 939.080s (  2.1 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 14.58% * 2000;
 Minibatch[   1- 100]: loss = 0.159476 * 100, metric = 5.95% * 100;
 Minibatch[ 101- 200]: loss = 0.154427 * 100, metric = 5.63% * 100;
 Minibatch[ 201- 300]: loss = 0.175490 * 100, metric = 6.42% * 100;
 Minibatch[ 301- 400]: loss = 0.159845 * 100, metric = 5.76% * 100;
 Minibatch[ 401- 500]: loss = 0.159153 * 100, metric = 5.76% * 100;
 Minibatch[ 501- 600]: loss = 0.161335 * 100, metric = 5.87% * 100;
 Minibatch[ 601- 700]: loss = 0.168359 * 100, metric = 6.01% * 100;
 Minibatch[ 701- 800]: loss = 0.154887 * 100, metric = 5.62% * 100;
 Minibatch[ 801- 900]: loss = 0.162356 * 100, metric = 5.79% * 100;
 Minibatch[ 901-1000]: loss = 0.166933 * 100, metric = 6.10% * 100;
 Minibatch[1001-1100]: loss = 0.174309 * 100, metric = 6.42% * 100;
 Minibatch[1101-1200]: loss = 0.161828 * 100, metric = 5.85% * 100;
 Minibatch[1201-1300]: loss = 0.167297 * 100, metric = 6.00% * 100;
 Minibatch[1301-1400]: loss = 0.148686 * 100, metric = 5.42% * 100;
 Minibatch[1401-1500]: loss = 0.157903 * 100, metric = 5.59% * 100;
 Minibatch[1501-1600]: loss = 0.161740 * 100, metric = 5.94% * 100;
 Minibatch[1601-1700]: loss = 0.172510 * 100, metric = 6.28% * 100;
 Minibatch[1701-1800]: loss = 0.163676 * 100, metric = 5.93% * 100;
 Minibatch[1801-1900]: loss = 0.159620 * 100, metric = 5.76% * 100;
 Minibatch[1901-2000]: loss = 0.160648 * 100, metric = 5.80% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.162524 * 2000, metric = 5.89% * 2000 955.607s (  2.1 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 15.14% * 2000;
 Minibatch[   1- 100]: loss = 0.162689 * 100, metric = 5.91% * 100;
 Minibatch[ 101- 200]: loss = 0.169580 * 100, metric = 6.23% * 100;
 Minibatch[ 201- 300]: loss = 0.164826 * 100, metric = 5.96% * 100;
 Minibatch[ 301- 400]: loss = 0.161254 * 100, metric = 6.02% * 100;
 Minibatch[ 401- 500]: loss = 0.165139 * 100, metric = 6.17% * 100;
 Minibatch[ 501- 600]: loss = 0.158468 * 100, metric = 5.90% * 100;
 Minibatch[ 601- 700]: loss = 0.161800 * 100, metric = 5.91% * 100;
 Minibatch[ 701- 800]: loss = 0.173674 * 100, metric = 6.37% * 100;
 Minibatch[ 801- 900]: loss = 0.160568 * 100, metric = 5.93% * 100;
 Minibatch[ 901-1000]: loss = 0.157179 * 100, metric = 5.64% * 100;
 Minibatch[1001-1100]: loss = 0.158910 * 100, metric = 5.86% * 100;
 Minibatch[1101-1200]: loss = 0.174779 * 100, metric = 6.54% * 100;
 Minibatch[1201-1300]: loss = 0.173857 * 100, metric = 6.30% * 100;
 Minibatch[1301-1400]: loss = 0.160581 * 100, metric = 6.00% * 100;
 Minibatch[1401-1500]: loss = 0.168142 * 100, metric = 6.15% * 100;
 Minibatch[1501-1600]: loss = 0.156411 * 100, metric = 5.62% * 100;
 Minibatch[1601-1700]: loss = 0.164568 * 100, metric = 6.09% * 100;
 Minibatch[1701-1800]: loss = 0.158192 * 100, metric = 5.66% * 100;
 Minibatch[1801-1900]: loss = 0.167667 * 100, metric = 6.27% * 100;
 Minibatch[1901-2000]: loss = 0.157667 * 100, metric = 5.65% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.163798 * 2000, metric = 6.01% * 2000 933.989s (  2.1 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 15.28% * 2000;
 Minibatch[   1- 100]: loss = 0.163708 * 100, metric = 6.10% * 100;
 Minibatch[ 101- 200]: loss = 0.161984 * 100, metric = 5.83% * 100;
 Minibatch[ 201- 300]: loss = 0.149874 * 100, metric = 5.43% * 100;
 Minibatch[ 301- 400]: loss = 0.150987 * 100, metric = 5.43% * 100;
 Minibatch[ 401- 500]: loss = 0.158879 * 100, metric = 5.81% * 100;
 Minibatch[ 501- 600]: loss = 0.159229 * 100, metric = 5.77% * 100;
 Minibatch[ 601- 700]: loss = 0.161798 * 100, metric = 6.02% * 100;
 Minibatch[ 701- 800]: loss = 0.160864 * 100, metric = 5.83% * 100;
 Minibatch[ 801- 900]: loss = 0.159562 * 100, metric = 5.76% * 100;
 Minibatch[ 901-1000]: loss = 0.157297 * 100, metric = 5.65% * 100;
 Minibatch[1001-1100]: loss = 0.165161 * 100, metric = 6.09% * 100;
 Minibatch[1101-1200]: loss = 0.153335 * 100, metric = 5.52% * 100;
 Minibatch[1201-1300]: loss = 0.160899 * 100, metric = 5.98% * 100;
 Minibatch[1301-1400]: loss = 0.164333 * 100, metric = 5.97% * 100;
 Minibatch[1401-1500]: loss = 0.160367 * 100, metric = 5.75% * 100;
 Minibatch[1501-1600]: loss = 0.163377 * 100, metric = 6.11% * 100;
 Minibatch[1601-1700]: loss = 0.155724 * 100, metric = 5.68% * 100;
 Minibatch[1701-1800]: loss = 0.157892 * 100, metric = 5.83% * 100;
 Minibatch[1801-1900]: loss = 0.163743 * 100, metric = 6.03% * 100;
 Minibatch[1901-2000]: loss = 0.158846 * 100, metric = 5.67% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.159393 * 2000, metric = 5.81% * 2000 946.838s (  2.1 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 14.13% * 2000;
 Minibatch[   1- 100]: loss = 0.157312 * 100, metric = 5.80% * 100;
 Minibatch[ 101- 200]: loss = 0.160882 * 100, metric = 5.71% * 100;
 Minibatch[ 201- 300]: loss = 0.155092 * 100, metric = 5.51% * 100;
 Minibatch[ 301- 400]: loss = 0.153345 * 100, metric = 5.60% * 100;
 Minibatch[ 401- 500]: loss = 0.158251 * 100, metric = 5.93% * 100;
 Minibatch[ 501- 600]: loss = 0.158341 * 100, metric = 5.69% * 100;
 Minibatch[ 601- 700]: loss = 0.164984 * 100, metric = 6.05% * 100;
 Minibatch[ 701- 800]: loss = 0.154597 * 100, metric = 5.67% * 100;
 Minibatch[ 801- 900]: loss = 0.143258 * 100, metric = 5.39% * 100;
 Minibatch[ 901-1000]: loss = 0.153234 * 100, metric = 5.51% * 100;
 Minibatch[1001-1100]: loss = 0.163758 * 100, metric = 5.90% * 100;
 Minibatch[1101-1200]: loss = 0.161559 * 100, metric = 5.95% * 100;
 Minibatch[1201-1300]: loss = 0.158337 * 100, metric = 5.69% * 100;
 Minibatch[1301-1400]: loss = 0.168933 * 100, metric = 6.09% * 100;
 Minibatch[1401-1500]: loss = 0.161296 * 100, metric = 6.00% * 100;
 Minibatch[1501-1600]: loss = 0.157140 * 100, metric = 5.51% * 100;
 Minibatch[1601-1700]: loss = 0.149817 * 100, metric = 5.40% * 100;
 Minibatch[1701-1800]: loss = 0.160858 * 100, metric = 5.78% * 100;
 Minibatch[1801-1900]: loss = 0.153195 * 100, metric = 5.63% * 100;
 Minibatch[1901-2000]: loss = 0.156178 * 100, metric = 5.61% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.157518 * 2000, metric = 5.72% * 2000 937.373s (  2.1 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 14.86% * 2000;
 Minibatch[   1- 100]: loss = 0.155302 * 100, metric = 5.71% * 100;
 Minibatch[ 101- 200]: loss = 0.151883 * 100, metric = 5.57% * 100;
 Minibatch[ 201- 300]: loss = 0.159018 * 100, metric = 5.76% * 100;
 Minibatch[ 301- 400]: loss = 0.163857 * 100, metric = 5.92% * 100;
 Minibatch[ 401- 500]: loss = 0.158998 * 100, metric = 5.86% * 100;
 Minibatch[ 501- 600]: loss = 0.155376 * 100, metric = 5.46% * 100;
 Minibatch[ 601- 700]: loss = 0.160673 * 100, metric = 5.90% * 100;
 Minibatch[ 701- 800]: loss = 0.155440 * 100, metric = 5.52% * 100;
 Minibatch[ 801- 900]: loss = 0.157034 * 100, metric = 5.74% * 100;
 Minibatch[ 901-1000]: loss = 0.158378 * 100, metric = 5.68% * 100;
 Minibatch[1001-1100]: loss = 0.165602 * 100, metric = 5.99% * 100;
 Minibatch[1101-1200]: loss = 0.160482 * 100, metric = 5.74% * 100;
 Minibatch[1201-1300]: loss = 0.153256 * 100, metric = 5.52% * 100;
 Minibatch[1301-1400]: loss = 0.161674 * 100, metric = 6.02% * 100;
 Minibatch[1401-1500]: loss = 0.156112 * 100, metric = 5.78% * 100;
 Minibatch[1501-1600]: loss = 0.158846 * 100, metric = 5.76% * 100;
 Minibatch[1601-1700]: loss = 0.157842 * 100, metric = 5.73% * 100;
 Minibatch[1701-1800]: loss = 0.151906 * 100, metric = 5.50% * 100;
 Minibatch[1801-1900]: loss = 0.149068 * 100, metric = 5.28% * 100;
 Minibatch[1901-2000]: loss = 0.161639 * 100, metric = 5.79% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.157619 * 2000, metric = 5.71% * 2000 938.629s (  2.1 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 14.39% * 2000;
 Minibatch[   1- 100]: loss = 0.159558 * 100, metric = 5.89% * 100;
 Minibatch[ 101- 200]: loss = 0.157922 * 100, metric = 5.72% * 100;
 Minibatch[ 201- 300]: loss = 0.159244 * 100, metric = 5.78% * 100;
 Minibatch[ 301- 400]: loss = 0.163576 * 100, metric = 6.03% * 100;
 Minibatch[ 401- 500]: loss = 0.156862 * 100, metric = 5.87% * 100;
 Minibatch[ 501- 600]: loss = 0.158556 * 100, metric = 5.82% * 100;
 Minibatch[ 601- 700]: loss = 0.157378 * 100, metric = 5.68% * 100;
 Minibatch[ 701- 800]: loss = 0.156005 * 100, metric = 5.61% * 100;
 Minibatch[ 801- 900]: loss = 0.150664 * 100, metric = 5.65% * 100;
 Minibatch[ 901-1000]: loss = 0.160442 * 100, metric = 5.93% * 100;
 Minibatch[1001-1100]: loss = 0.153463 * 100, metric = 5.55% * 100;
 Minibatch[1101-1200]: loss = 0.162852 * 100, metric = 5.85% * 100;
 Minibatch[1201-1300]: loss = 0.161031 * 100, metric = 5.83% * 100;
 Minibatch[1301-1400]: loss = 0.146589 * 100, metric = 5.26% * 100;
 Minibatch[1401-1500]: loss = 0.152510 * 100, metric = 5.44% * 100;
 Minibatch[1501-1600]: loss = 0.151748 * 100, metric = 5.56% * 100;
 Minibatch[1601-1700]: loss = 0.156283 * 100, metric = 5.58% * 100;
 Minibatch[1701-1800]: loss = 0.150148 * 100, metric = 5.55% * 100;
 Minibatch[1801-1900]: loss = 0.151362 * 100, metric = 5.63% * 100;
 Minibatch[1901-2000]: loss = 0.145609 * 100, metric = 5.27% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.155590 * 2000, metric = 5.68% * 2000 938.973s (  2.1 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 15.84% * 2000;
 Minibatch[   1- 100]: loss = 0.148412 * 100, metric = 5.32% * 100;
 Minibatch[ 101- 200]: loss = 0.153550 * 100, metric = 5.54% * 100;
 Minibatch[ 201- 300]: loss = 0.150460 * 100, metric = 5.47% * 100;
 Minibatch[ 301- 400]: loss = 0.148554 * 100, metric = 5.28% * 100;
 Minibatch[ 401- 500]: loss = 0.149863 * 100, metric = 5.44% * 100;
 Minibatch[ 501- 600]: loss = 0.149268 * 100, metric = 5.39% * 100;
 Minibatch[ 601- 700]: loss = 0.148877 * 100, metric = 5.42% * 100;
 Minibatch[ 701- 800]: loss = 0.149986 * 100, metric = 5.55% * 100;
 Minibatch[ 801- 900]: loss = 0.151511 * 100, metric = 5.50% * 100;
 Minibatch[ 901-1000]: loss = 0.157474 * 100, metric = 5.93% * 100;
 Minibatch[1001-1100]: loss = 0.151722 * 100, metric = 5.61% * 100;
 Minibatch[1101-1200]: loss = 0.149497 * 100, metric = 5.16% * 100;
 Minibatch[1201-1300]: loss = 0.142152 * 100, metric = 5.11% * 100;
 Minibatch[1301-1400]: loss = 0.154306 * 100, metric = 5.70% * 100;
 Minibatch[1401-1500]: loss = 0.144848 * 100, metric = 5.03% * 100;
 Minibatch[1501-1600]: loss = 0.146208 * 100, metric = 5.21% * 100;
 Minibatch[1601-1700]: loss = 0.149601 * 100, metric = 5.23% * 100;
 Minibatch[1701-1800]: loss = 0.147645 * 100, metric = 5.30% * 100;
 Minibatch[1801-1900]: loss = 0.151392 * 100, metric = 5.61% * 100;
 Minibatch[1901-2000]: loss = 0.145225 * 100, metric = 5.24% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.149528 * 2000, metric = 5.40% * 2000 934.052s (  2.1 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 14.68% * 2000;
 Minibatch[   1- 100]: loss = 0.162724 * 100, metric = 5.97% * 100;
 Minibatch[ 101- 200]: loss = 0.140692 * 100, metric = 5.01% * 100;
 Minibatch[ 201- 300]: loss = 0.155853 * 100, metric = 5.60% * 100;
 Minibatch[ 301- 400]: loss = 0.153544 * 100, metric = 5.53% * 100;
 Minibatch[ 401- 500]: loss = 0.147353 * 100, metric = 5.35% * 100;
 Minibatch[ 501- 600]: loss = 0.149286 * 100, metric = 5.45% * 100;
 Minibatch[ 601- 700]: loss = 0.157236 * 100, metric = 5.71% * 100;
 Minibatch[ 701- 800]: loss = 0.146765 * 100, metric = 5.19% * 100;
 Minibatch[ 801- 900]: loss = 0.147912 * 100, metric = 5.32% * 100;
 Minibatch[ 901-1000]: loss = 0.148546 * 100, metric = 5.34% * 100;
 Minibatch[1001-1100]: loss = 0.149616 * 100, metric = 5.42% * 100;
 Minibatch[1101-1200]: loss = 0.144377 * 100, metric = 5.33% * 100;
 Minibatch[1201-1300]: loss = 0.156339 * 100, metric = 5.83% * 100;
 Minibatch[1301-1400]: loss = 0.148575 * 100, metric = 5.42% * 100;
 Minibatch[1401-1500]: loss = 0.139410 * 100, metric = 5.00% * 100;
 Minibatch[1501-1600]: loss = 0.151945 * 100, metric = 5.47% * 100;
 Minibatch[1601-1700]: loss = 0.149082 * 100, metric = 5.41% * 100;
 Minibatch[1701-1800]: loss = 0.148934 * 100, metric = 5.44% * 100;
 Minibatch[1801-1900]: loss = 0.145875 * 100, metric = 5.24% * 100;
 Minibatch[1901-2000]: loss = 0.141632 * 100, metric = 5.17% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.149285 * 2000, metric = 5.41% * 2000 934.001s (  2.1 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 14.62% * 2000;
 Minibatch[   1- 100]: loss = 0.147538 * 100, metric = 5.31% * 100;
 Minibatch[ 101- 200]: loss = 0.145297 * 100, metric = 5.29% * 100;
 Minibatch[ 201- 300]: loss = 0.152091 * 100, metric = 5.34% * 100;
 Minibatch[ 301- 400]: loss = 0.147398 * 100, metric = 5.32% * 100;
 Minibatch[ 401- 500]: loss = 0.144018 * 100, metric = 5.14% * 100;
 Minibatch[ 501- 600]: loss = 0.145144 * 100, metric = 5.21% * 100;
 Minibatch[ 601- 700]: loss = 0.155866 * 100, metric = 5.54% * 100;
 Minibatch[ 701- 800]: loss = 0.129636 * 100, metric = 4.63% * 100;
 Minibatch[ 801- 900]: loss = 0.139709 * 100, metric = 4.96% * 100;
 Minibatch[ 901-1000]: loss = 0.139133 * 100, metric = 4.96% * 100;
 Minibatch[1001-1100]: loss = 0.142917 * 100, metric = 5.01% * 100;
 Minibatch[1101-1200]: loss = 0.136687 * 100, metric = 4.80% * 100;
 Minibatch[1201-1300]: loss = 0.142598 * 100, metric = 5.10% * 100;
 Minibatch[1301-1400]: loss = 0.136134 * 100, metric = 4.93% * 100;
 Minibatch[1401-1500]: loss = 0.139779 * 100, metric = 4.96% * 100;
 Minibatch[1501-1600]: loss = 0.135228 * 100, metric = 4.84% * 100;
 Minibatch[1601-1700]: loss = 0.142932 * 100, metric = 5.10% * 100;
 Minibatch[1701-1800]: loss = 0.153462 * 100, metric = 5.70% * 100;
 Minibatch[1801-1900]: loss = 0.144102 * 100, metric = 5.16% * 100;
 Minibatch[1901-2000]: loss = 0.137716 * 100, metric = 4.98% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.142869 * 2000, metric = 5.11% * 2000 933.195s (  2.1 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 15.05% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
