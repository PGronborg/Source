Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.320554 * 100, metric = 25.33% * 100;
 Minibatch[ 101- 200]: loss = 1.136658 * 100, metric = 23.45% * 100;
 Minibatch[ 201- 300]: loss = 1.018774 * 100, metric = 21.40% * 100;
 Minibatch[ 301- 400]: loss = 1.006447 * 100, metric = 19.96% * 100;
 Minibatch[ 401- 500]: loss = 0.967809 * 100, metric = 19.63% * 100;
 Minibatch[ 501- 600]: loss = 0.918905 * 100, metric = 18.07% * 100;
 Minibatch[ 601- 700]: loss = 0.887852 * 100, metric = 17.05% * 100;
 Minibatch[ 701- 800]: loss = 0.849193 * 100, metric = 16.54% * 100;
 Minibatch[ 801- 900]: loss = 0.872367 * 100, metric = 16.89% * 100;
 Minibatch[ 901-1000]: loss = 0.881829 * 100, metric = 17.10% * 100;
 Minibatch[1001-1100]: loss = 0.870248 * 100, metric = 17.03% * 100;
 Minibatch[1101-1200]: loss = 0.851488 * 100, metric = 16.54% * 100;
 Minibatch[1201-1300]: loss = 0.848845 * 100, metric = 16.56% * 100;
 Minibatch[1301-1400]: loss = 0.829995 * 100, metric = 15.49% * 100;
 Minibatch[1401-1500]: loss = 0.840941 * 100, metric = 15.97% * 100;
 Minibatch[1501-1600]: loss = 0.806523 * 100, metric = 15.42% * 100;
 Minibatch[1601-1700]: loss = 0.810720 * 100, metric = 15.41% * 100;
 Minibatch[1701-1800]: loss = 0.826812 * 100, metric = 15.55% * 100;
 Minibatch[1801-1900]: loss = 0.815291 * 100, metric = 15.38% * 100;
 Minibatch[1901-2000]: loss = 0.802059 * 100, metric = 14.91% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.908165 * 2000, metric = 17.68% * 2000 1030.654s (  1.9 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 25.14% * 2000;
0.8639539824277163
 Minibatch[   1- 100]: loss = 0.791313 * 100, metric = 14.61% * 100;
 Minibatch[ 101- 200]: loss = 0.812938 * 100, metric = 15.73% * 100;
 Minibatch[ 201- 300]: loss = 0.805653 * 100, metric = 14.51% * 100;
 Minibatch[ 301- 400]: loss = 0.800084 * 100, metric = 14.94% * 100;
 Minibatch[ 401- 500]: loss = 0.789044 * 100, metric = 14.59% * 100;
 Minibatch[ 501- 600]: loss = 0.805958 * 100, metric = 14.48% * 100;
 Minibatch[ 601- 700]: loss = 0.752553 * 100, metric = 13.88% * 100;
 Minibatch[ 701- 800]: loss = 0.784806 * 100, metric = 14.66% * 100;
 Minibatch[ 801- 900]: loss = 0.761464 * 100, metric = 13.88% * 100;
 Minibatch[ 901-1000]: loss = 0.745936 * 100, metric = 13.39% * 100;
 Minibatch[1001-1100]: loss = 0.758882 * 100, metric = 14.31% * 100;
 Minibatch[1101-1200]: loss = 0.762206 * 100, metric = 13.86% * 100;
 Minibatch[1201-1300]: loss = 0.753016 * 100, metric = 13.61% * 100;
 Minibatch[1301-1400]: loss = 0.756445 * 100, metric = 13.63% * 100;
 Minibatch[1401-1500]: loss = 0.737711 * 100, metric = 12.99% * 100;
 Minibatch[1501-1600]: loss = 0.731195 * 100, metric = 13.25% * 100;
 Minibatch[1601-1700]: loss = 0.751746 * 100, metric = 13.81% * 100;
 Minibatch[1701-1800]: loss = 0.747275 * 100, metric = 13.87% * 100;
 Minibatch[1801-1900]: loss = 0.751823 * 100, metric = 13.62% * 100;
 Minibatch[1901-2000]: loss = 0.723217 * 100, metric = 13.20% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.766163 * 2000, metric = 14.04% * 2000 959.975s (  2.1 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 22.21% * 2000;
0.7931305800899863
 Minibatch[   1- 100]: loss = 0.737238 * 100, metric = 13.47% * 100;
 Minibatch[ 101- 200]: loss = 0.736457 * 100, metric = 13.63% * 100;
 Minibatch[ 201- 300]: loss = 0.719521 * 100, metric = 12.97% * 100;
 Minibatch[ 301- 400]: loss = 0.743343 * 100, metric = 13.56% * 100;
 Minibatch[ 401- 500]: loss = 0.748013 * 100, metric = 14.00% * 100;
 Minibatch[ 501- 600]: loss = 0.736837 * 100, metric = 13.12% * 100;
 Minibatch[ 601- 700]: loss = 0.749337 * 100, metric = 13.68% * 100;
 Minibatch[ 701- 800]: loss = 0.718389 * 100, metric = 12.38% * 100;
 Minibatch[ 801- 900]: loss = 0.738745 * 100, metric = 13.50% * 100;
 Minibatch[ 901-1000]: loss = 0.709952 * 100, metric = 13.07% * 100;
 Minibatch[1001-1100]: loss = 0.735836 * 100, metric = 13.65% * 100;
 Minibatch[1101-1200]: loss = 0.724387 * 100, metric = 13.39% * 100;
 Minibatch[1201-1300]: loss = 0.719854 * 100, metric = 12.91% * 100;
 Minibatch[1301-1400]: loss = 0.725360 * 100, metric = 13.30% * 100;
 Minibatch[1401-1500]: loss = 0.728925 * 100, metric = 13.23% * 100;
 Minibatch[1501-1600]: loss = 0.719271 * 100, metric = 13.12% * 100;
 Minibatch[1601-1700]: loss = 0.700148 * 100, metric = 12.49% * 100;
 Minibatch[1701-1800]: loss = 0.719675 * 100, metric = 13.20% * 100;
 Minibatch[1801-1900]: loss = 0.705992 * 100, metric = 12.54% * 100;
 Minibatch[1901-2000]: loss = 0.710463 * 100, metric = 12.81% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.726387 * 2000, metric = 13.20% * 2000 956.803s (  2.1 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 20.69% * 2000;
0.7591443644762039
 Minibatch[   1- 100]: loss = 0.724192 * 100, metric = 12.76% * 100;
 Minibatch[ 101- 200]: loss = 0.694503 * 100, metric = 12.32% * 100;
 Minibatch[ 201- 300]: loss = 0.712447 * 100, metric = 12.92% * 100;
 Minibatch[ 301- 400]: loss = 0.677573 * 100, metric = 11.98% * 100;
 Minibatch[ 401- 500]: loss = 0.703254 * 100, metric = 12.66% * 100;
 Minibatch[ 501- 600]: loss = 0.680155 * 100, metric = 11.92% * 100;
 Minibatch[ 601- 700]: loss = 0.683044 * 100, metric = 12.41% * 100;
 Minibatch[ 701- 800]: loss = 0.703792 * 100, metric = 12.81% * 100;
 Minibatch[ 801- 900]: loss = 0.693967 * 100, metric = 12.73% * 100;
 Minibatch[ 901-1000]: loss = 0.699618 * 100, metric = 12.82% * 100;
 Minibatch[1001-1100]: loss = 0.711359 * 100, metric = 13.07% * 100;
 Minibatch[1101-1200]: loss = 0.684198 * 100, metric = 12.45% * 100;
 Minibatch[1201-1300]: loss = 0.679481 * 100, metric = 12.08% * 100;
 Minibatch[1301-1400]: loss = 0.699536 * 100, metric = 12.43% * 100;
 Minibatch[1401-1500]: loss = 0.701392 * 100, metric = 12.68% * 100;
 Minibatch[1501-1600]: loss = 0.660947 * 100, metric = 11.75% * 100;
 Minibatch[1601-1700]: loss = 0.695999 * 100, metric = 12.39% * 100;
 Minibatch[1701-1800]: loss = 0.697814 * 100, metric = 12.70% * 100;
 Minibatch[1801-1900]: loss = 0.678282 * 100, metric = 12.12% * 100;
 Minibatch[1901-2000]: loss = 0.667155 * 100, metric = 11.89% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.692435 * 2000, metric = 12.45% * 2000 952.106s (  2.1 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 21.66% * 2000;
 Minibatch[   1- 100]: loss = 0.697116 * 100, metric = 12.32% * 100;
 Minibatch[ 101- 200]: loss = 0.674714 * 100, metric = 11.92% * 100;
 Minibatch[ 201- 300]: loss = 0.662439 * 100, metric = 11.76% * 100;
 Minibatch[ 301- 400]: loss = 0.697424 * 100, metric = 12.50% * 100;
 Minibatch[ 401- 500]: loss = 0.662343 * 100, metric = 11.27% * 100;
 Minibatch[ 501- 600]: loss = 0.665417 * 100, metric = 11.38% * 100;
 Minibatch[ 601- 700]: loss = 0.665447 * 100, metric = 11.63% * 100;
 Minibatch[ 701- 800]: loss = 0.676136 * 100, metric = 12.13% * 100;
 Minibatch[ 801- 900]: loss = 0.656637 * 100, metric = 11.33% * 100;
 Minibatch[ 901-1000]: loss = 0.659574 * 100, metric = 11.73% * 100;
 Minibatch[1001-1100]: loss = 0.673724 * 100, metric = 11.80% * 100;
 Minibatch[1101-1200]: loss = 0.647452 * 100, metric = 11.46% * 100;
 Minibatch[1201-1300]: loss = 0.672935 * 100, metric = 11.66% * 100;
 Minibatch[1301-1400]: loss = 0.687062 * 100, metric = 12.01% * 100;
 Minibatch[1401-1500]: loss = 0.668898 * 100, metric = 11.82% * 100;
 Minibatch[1501-1600]: loss = 0.667119 * 100, metric = 11.91% * 100;
 Minibatch[1601-1700]: loss = 0.672537 * 100, metric = 12.17% * 100;
 Minibatch[1701-1800]: loss = 0.671095 * 100, metric = 11.97% * 100;
 Minibatch[1801-1900]: loss = 0.662677 * 100, metric = 11.77% * 100;
 Minibatch[1901-2000]: loss = 0.650316 * 100, metric = 11.64% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.669553 * 2000, metric = 11.81% * 2000 949.857s (  2.1 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.07% * 2000;
0.7290465637966991
 Minibatch[   1- 100]: loss = 0.655598 * 100, metric = 11.48% * 100;
 Minibatch[ 101- 200]: loss = 0.636877 * 100, metric = 11.33% * 100;
 Minibatch[ 201- 300]: loss = 0.648813 * 100, metric = 11.38% * 100;
 Minibatch[ 301- 400]: loss = 0.657590 * 100, metric = 11.17% * 100;
 Minibatch[ 401- 500]: loss = 0.630944 * 100, metric = 10.84% * 100;
 Minibatch[ 501- 600]: loss = 0.642775 * 100, metric = 11.34% * 100;
 Minibatch[ 601- 700]: loss = 0.641807 * 100, metric = 11.10% * 100;
 Minibatch[ 701- 800]: loss = 0.649523 * 100, metric = 11.13% * 100;
 Minibatch[ 801- 900]: loss = 0.648164 * 100, metric = 11.42% * 100;
 Minibatch[ 901-1000]: loss = 0.644134 * 100, metric = 11.25% * 100;
 Minibatch[1001-1100]: loss = 0.638149 * 100, metric = 10.64% * 100;
 Minibatch[1101-1200]: loss = 0.650487 * 100, metric = 11.36% * 100;
 Minibatch[1201-1300]: loss = 0.660396 * 100, metric = 11.36% * 100;
 Minibatch[1301-1400]: loss = 0.637657 * 100, metric = 11.15% * 100;
 Minibatch[1401-1500]: loss = 0.652159 * 100, metric = 11.75% * 100;
 Minibatch[1501-1600]: loss = 0.628706 * 100, metric = 10.65% * 100;
 Minibatch[1601-1700]: loss = 0.624979 * 100, metric = 10.73% * 100;
 Minibatch[1701-1800]: loss = 0.625996 * 100, metric = 10.81% * 100;
 Minibatch[1801-1900]: loss = 0.646028 * 100, metric = 11.08% * 100;
 Minibatch[1901-2000]: loss = 0.632539 * 100, metric = 10.95% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.642666 * 2000, metric = 11.15% * 2000 954.836s (  2.1 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.70% * 2000;
 Minibatch[   1- 100]: loss = 0.634231 * 100, metric = 10.92% * 100;
 Minibatch[ 101- 200]: loss = 0.646748 * 100, metric = 11.03% * 100;
 Minibatch[ 201- 300]: loss = 0.644734 * 100, metric = 11.21% * 100;
 Minibatch[ 301- 400]: loss = 0.621796 * 100, metric = 10.46% * 100;
 Minibatch[ 401- 500]: loss = 0.643642 * 100, metric = 11.04% * 100;
 Minibatch[ 501- 600]: loss = 0.625486 * 100, metric = 10.71% * 100;
 Minibatch[ 601- 700]: loss = 0.632788 * 100, metric = 10.72% * 100;
 Minibatch[ 701- 800]: loss = 0.645423 * 100, metric = 11.04% * 100;
 Minibatch[ 801- 900]: loss = 0.644012 * 100, metric = 11.30% * 100;
 Minibatch[ 901-1000]: loss = 0.638694 * 100, metric = 11.09% * 100;
 Minibatch[1001-1100]: loss = 0.640200 * 100, metric = 11.37% * 100;
 Minibatch[1101-1200]: loss = 0.630610 * 100, metric = 10.86% * 100;
 Minibatch[1201-1300]: loss = 0.644270 * 100, metric = 11.27% * 100;
 Minibatch[1301-1400]: loss = 0.630460 * 100, metric = 10.76% * 100;
 Minibatch[1401-1500]: loss = 0.619512 * 100, metric = 10.48% * 100;
 Minibatch[1501-1600]: loss = 0.629203 * 100, metric = 10.68% * 100;
 Minibatch[1601-1700]: loss = 0.630661 * 100, metric = 10.87% * 100;
 Minibatch[1701-1800]: loss = 0.622944 * 100, metric = 10.60% * 100;
 Minibatch[1801-1900]: loss = 0.628110 * 100, metric = 10.91% * 100;
 Minibatch[1901-2000]: loss = 0.629520 * 100, metric = 11.05% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.634152 * 2000, metric = 10.92% * 2000 961.727s (  2.1 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.32% * 2000;
0.692744466483593
 Minibatch[   1- 100]: loss = 0.629864 * 100, metric = 10.79% * 100;
 Minibatch[ 101- 200]: loss = 0.618611 * 100, metric = 10.90% * 100;
 Minibatch[ 201- 300]: loss = 0.603766 * 100, metric = 10.35% * 100;
 Minibatch[ 301- 400]: loss = 0.607753 * 100, metric = 10.57% * 100;
 Minibatch[ 401- 500]: loss = 0.625345 * 100, metric = 10.99% * 100;
 Minibatch[ 501- 600]: loss = 0.634173 * 100, metric = 11.25% * 100;
 Minibatch[ 601- 700]: loss = 0.594970 * 100, metric = 10.06% * 100;
 Minibatch[ 701- 800]: loss = 0.618438 * 100, metric = 10.42% * 100;
 Minibatch[ 801- 900]: loss = 0.592185 * 100, metric = 9.67% * 100;
 Minibatch[ 901-1000]: loss = 0.584869 * 100, metric = 9.66% * 100;
 Minibatch[1001-1100]: loss = 0.593266 * 100, metric = 10.03% * 100;
 Minibatch[1101-1200]: loss = 0.590347 * 100, metric = 9.84% * 100;
 Minibatch[1201-1300]: loss = 0.608461 * 100, metric = 10.65% * 100;
 Minibatch[1301-1400]: loss = 0.613257 * 100, metric = 10.46% * 100;
 Minibatch[1401-1500]: loss = 0.602687 * 100, metric = 10.01% * 100;
 Minibatch[1501-1600]: loss = 0.610294 * 100, metric = 10.51% * 100;
 Minibatch[1601-1700]: loss = 0.600603 * 100, metric = 9.91% * 100;
 Minibatch[1701-1800]: loss = 0.601370 * 100, metric = 10.17% * 100;
 Minibatch[1801-1900]: loss = 0.606735 * 100, metric = 10.34% * 100;
 Minibatch[1901-2000]: loss = 0.602968 * 100, metric = 9.98% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.606998 * 2000, metric = 10.33% * 2000 961.337s (  2.1 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 17.49% * 2000;
0.6786964135020971
 Minibatch[   1- 100]: loss = 0.573554 * 100, metric = 9.45% * 100;
 Minibatch[ 101- 200]: loss = 0.607572 * 100, metric = 10.43% * 100;
 Minibatch[ 201- 300]: loss = 0.594886 * 100, metric = 9.86% * 100;
 Minibatch[ 301- 400]: loss = 0.609085 * 100, metric = 10.27% * 100;
 Minibatch[ 401- 500]: loss = 0.592956 * 100, metric = 9.98% * 100;
 Minibatch[ 501- 600]: loss = 0.582723 * 100, metric = 9.84% * 100;
 Minibatch[ 601- 700]: loss = 0.583085 * 100, metric = 9.77% * 100;
 Minibatch[ 701- 800]: loss = 0.570195 * 100, metric = 9.43% * 100;
 Minibatch[ 801- 900]: loss = 0.579964 * 100, metric = 9.79% * 100;
 Minibatch[ 901-1000]: loss = 0.588306 * 100, metric = 10.17% * 100;
 Minibatch[1001-1100]: loss = 0.557800 * 100, metric = 8.99% * 100;
 Minibatch[1101-1200]: loss = 0.587859 * 100, metric = 9.81% * 100;
 Minibatch[1201-1300]: loss = 0.587142 * 100, metric = 9.76% * 100;
 Minibatch[1301-1400]: loss = 0.568638 * 100, metric = 9.09% * 100;
 Minibatch[1401-1500]: loss = 0.584624 * 100, metric = 9.99% * 100;
 Minibatch[1501-1600]: loss = 0.588628 * 100, metric = 9.71% * 100;
 Minibatch[1601-1700]: loss = 0.590760 * 100, metric = 10.15% * 100;
 Minibatch[1701-1800]: loss = 0.578637 * 100, metric = 9.51% * 100;
 Minibatch[1801-1900]: loss = 0.576597 * 100, metric = 9.63% * 100;
 Minibatch[1901-2000]: loss = 0.590500 * 100, metric = 9.88% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.584676 * 2000, metric = 9.78% * 2000 953.212s (  2.1 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 16.81% * 2000;
0.6725078873187303
 Minibatch[   1- 100]: loss = 0.601595 * 100, metric = 10.41% * 100;
 Minibatch[ 101- 200]: loss = 0.569927 * 100, metric = 9.56% * 100;
 Minibatch[ 201- 300]: loss = 0.586091 * 100, metric = 9.70% * 100;
 Minibatch[ 301- 400]: loss = 0.572440 * 100, metric = 9.22% * 100;
 Minibatch[ 401- 500]: loss = 0.585804 * 100, metric = 9.86% * 100;
 Minibatch[ 501- 600]: loss = 0.556734 * 100, metric = 9.15% * 100;
 Minibatch[ 601- 700]: loss = 0.559442 * 100, metric = 9.11% * 100;
 Minibatch[ 701- 800]: loss = 0.548501 * 100, metric = 8.72% * 100;
 Minibatch[ 801- 900]: loss = 0.563863 * 100, metric = 9.14% * 100;
 Minibatch[ 901-1000]: loss = 0.572721 * 100, metric = 9.62% * 100;
 Minibatch[1001-1100]: loss = 0.571142 * 100, metric = 9.68% * 100;
 Minibatch[1101-1200]: loss = 0.562980 * 100, metric = 9.16% * 100;
 Minibatch[1201-1300]: loss = 0.571610 * 100, metric = 9.57% * 100;
 Minibatch[1301-1400]: loss = 0.574994 * 100, metric = 9.56% * 100;
 Minibatch[1401-1500]: loss = 0.555696 * 100, metric = 8.86% * 100;
 Minibatch[1501-1600]: loss = 0.563393 * 100, metric = 9.49% * 100;
 Minibatch[1601-1700]: loss = 0.561595 * 100, metric = 8.92% * 100;
 Minibatch[1701-1800]: loss = 0.559368 * 100, metric = 8.98% * 100;
 Minibatch[1801-1900]: loss = 0.568669 * 100, metric = 9.26% * 100;
 Minibatch[1901-2000]: loss = 0.555645 * 100, metric = 8.92% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.568111 * 2000, metric = 9.34% * 2000 951.964s (  2.1 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 16.05% * 2000;
0.6459524751082063
 Minibatch[   1- 100]: loss = 0.534994 * 100, metric = 8.51% * 100;
 Minibatch[ 101- 200]: loss = 0.553075 * 100, metric = 8.62% * 100;
 Minibatch[ 201- 300]: loss = 0.570702 * 100, metric = 9.64% * 100;
 Minibatch[ 301- 400]: loss = 0.555432 * 100, metric = 8.76% * 100;
 Minibatch[ 401- 500]: loss = 0.554863 * 100, metric = 9.01% * 100;
 Minibatch[ 501- 600]: loss = 0.564726 * 100, metric = 9.31% * 100;
 Minibatch[ 601- 700]: loss = 0.551125 * 100, metric = 8.82% * 100;
 Minibatch[ 701- 800]: loss = 0.556356 * 100, metric = 9.27% * 100;
 Minibatch[ 801- 900]: loss = 0.554104 * 100, metric = 8.98% * 100;
 Minibatch[ 901-1000]: loss = 0.567532 * 100, metric = 9.33% * 100;
 Minibatch[1001-1100]: loss = 0.560182 * 100, metric = 9.01% * 100;
 Minibatch[1101-1200]: loss = 0.566200 * 100, metric = 9.31% * 100;
 Minibatch[1201-1300]: loss = 0.545576 * 100, metric = 8.87% * 100;
 Minibatch[1301-1400]: loss = 0.529713 * 100, metric = 8.53% * 100;
 Minibatch[1401-1500]: loss = 0.558011 * 100, metric = 9.31% * 100;
 Minibatch[1501-1600]: loss = 0.540135 * 100, metric = 8.80% * 100;
 Minibatch[1601-1700]: loss = 0.551494 * 100, metric = 8.93% * 100;
 Minibatch[1701-1800]: loss = 0.570377 * 100, metric = 9.06% * 100;
 Minibatch[1801-1900]: loss = 0.549636 * 100, metric = 9.00% * 100;
 Minibatch[1901-2000]: loss = 0.551846 * 100, metric = 9.25% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.554304 * 2000, metric = 9.02% * 2000 946.474s (  2.1 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 16.23% * 2000;
 Minibatch[   1- 100]: loss = 0.528076 * 100, metric = 8.38% * 100;
 Minibatch[ 101- 200]: loss = 0.534001 * 100, metric = 8.23% * 100;
 Minibatch[ 201- 300]: loss = 0.534965 * 100, metric = 8.75% * 100;
 Minibatch[ 301- 400]: loss = 0.579673 * 100, metric = 9.66% * 100;
 Minibatch[ 401- 500]: loss = 0.546777 * 100, metric = 8.51% * 100;
 Minibatch[ 501- 600]: loss = 0.528842 * 100, metric = 8.16% * 100;
 Minibatch[ 601- 700]: loss = 0.530140 * 100, metric = 8.33% * 100;
 Minibatch[ 701- 800]: loss = 0.546291 * 100, metric = 8.63% * 100;
 Minibatch[ 801- 900]: loss = 0.539699 * 100, metric = 8.38% * 100;
 Minibatch[ 901-1000]: loss = 0.547445 * 100, metric = 9.07% * 100;
 Minibatch[1001-1100]: loss = 0.557627 * 100, metric = 9.12% * 100;
 Minibatch[1101-1200]: loss = 0.557722 * 100, metric = 8.86% * 100;
 Minibatch[1201-1300]: loss = 0.562632 * 100, metric = 9.40% * 100;
 Minibatch[1301-1400]: loss = 0.539655 * 100, metric = 8.53% * 100;
 Minibatch[1401-1500]: loss = 0.552091 * 100, metric = 8.97% * 100;
 Minibatch[1501-1600]: loss = 0.515018 * 100, metric = 8.41% * 100;
 Minibatch[1601-1700]: loss = 0.552941 * 100, metric = 9.18% * 100;
 Minibatch[1701-1800]: loss = 0.530084 * 100, metric = 8.49% * 100;
 Minibatch[1801-1900]: loss = 0.534484 * 100, metric = 8.50% * 100;
 Minibatch[1901-2000]: loss = 0.553613 * 100, metric = 9.03% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.543589 * 2000, metric = 8.73% * 2000 941.871s (  2.1 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 16.78% * 2000;
 Minibatch[   1- 100]: loss = 0.550238 * 100, metric = 9.00% * 100;
 Minibatch[ 101- 200]: loss = 0.542677 * 100, metric = 8.76% * 100;
 Minibatch[ 201- 300]: loss = 0.543583 * 100, metric = 8.83% * 100;
 Minibatch[ 301- 400]: loss = 0.557900 * 100, metric = 8.92% * 100;
 Minibatch[ 401- 500]: loss = 0.550161 * 100, metric = 9.21% * 100;
 Minibatch[ 501- 600]: loss = 0.559496 * 100, metric = 9.17% * 100;
 Minibatch[ 601- 700]: loss = 0.539055 * 100, metric = 8.47% * 100;
 Minibatch[ 701- 800]: loss = 0.540484 * 100, metric = 8.69% * 100;
 Minibatch[ 801- 900]: loss = 0.534073 * 100, metric = 8.59% * 100;
 Minibatch[ 901-1000]: loss = 0.550705 * 100, metric = 9.10% * 100;
 Minibatch[1001-1100]: loss = 0.557589 * 100, metric = 9.19% * 100;
 Minibatch[1101-1200]: loss = 0.547123 * 100, metric = 8.79% * 100;
 Minibatch[1201-1300]: loss = 0.549797 * 100, metric = 8.96% * 100;
 Minibatch[1301-1400]: loss = 0.537666 * 100, metric = 8.46% * 100;
 Minibatch[1401-1500]: loss = 0.541606 * 100, metric = 8.76% * 100;
 Minibatch[1501-1600]: loss = 0.530385 * 100, metric = 8.41% * 100;
 Minibatch[1601-1700]: loss = 0.520582 * 100, metric = 8.49% * 100;
 Minibatch[1701-1800]: loss = 0.533701 * 100, metric = 8.49% * 100;
 Minibatch[1801-1900]: loss = 0.525517 * 100, metric = 8.47% * 100;
 Minibatch[1901-2000]: loss = 0.541432 * 100, metric = 8.85% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.542689 * 2000, metric = 8.78% * 2000 921.976s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 17.68% * 2000;
 Minibatch[   1- 100]: loss = 0.524124 * 100, metric = 8.25% * 100;
 Minibatch[ 101- 200]: loss = 0.518152 * 100, metric = 8.10% * 100;
 Minibatch[ 201- 300]: loss = 0.542693 * 100, metric = 8.86% * 100;
 Minibatch[ 301- 400]: loss = 0.528123 * 100, metric = 8.47% * 100;
 Minibatch[ 401- 500]: loss = 0.524632 * 100, metric = 8.53% * 100;
 Minibatch[ 501- 600]: loss = 0.529577 * 100, metric = 8.56% * 100;
 Minibatch[ 601- 700]: loss = 0.521888 * 100, metric = 8.48% * 100;
 Minibatch[ 701- 800]: loss = 0.553097 * 100, metric = 9.01% * 100;
 Minibatch[ 801- 900]: loss = 0.538423 * 100, metric = 8.75% * 100;
 Minibatch[ 901-1000]: loss = 0.536315 * 100, metric = 8.64% * 100;
 Minibatch[1001-1100]: loss = 0.522275 * 100, metric = 8.24% * 100;
 Minibatch[1101-1200]: loss = 0.519601 * 100, metric = 8.42% * 100;
 Minibatch[1201-1300]: loss = 0.502899 * 100, metric = 7.80% * 100;
 Minibatch[1301-1400]: loss = 0.524764 * 100, metric = 8.41% * 100;
 Minibatch[1401-1500]: loss = 0.529617 * 100, metric = 8.60% * 100;
 Minibatch[1501-1600]: loss = 0.512304 * 100, metric = 8.32% * 100;
 Minibatch[1601-1700]: loss = 0.517484 * 100, metric = 8.08% * 100;
 Minibatch[1701-1800]: loss = 0.518415 * 100, metric = 8.25% * 100;
 Minibatch[1801-1900]: loss = 0.524240 * 100, metric = 8.32% * 100;
 Minibatch[1901-2000]: loss = 0.533436 * 100, metric = 8.54% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.526103 * 2000, metric = 8.43% * 2000 921.991s (  2.2 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 16.38% * 2000;
 Minibatch[   1- 100]: loss = 0.511112 * 100, metric = 8.08% * 100;
 Minibatch[ 101- 200]: loss = 0.533055 * 100, metric = 8.33% * 100;
 Minibatch[ 201- 300]: loss = 0.528994 * 100, metric = 8.31% * 100;
 Minibatch[ 301- 400]: loss = 0.515954 * 100, metric = 8.29% * 100;
 Minibatch[ 401- 500]: loss = 0.519379 * 100, metric = 8.36% * 100;
 Minibatch[ 501- 600]: loss = 0.511869 * 100, metric = 7.95% * 100;
 Minibatch[ 601- 700]: loss = 0.500503 * 100, metric = 7.88% * 100;
 Minibatch[ 701- 800]: loss = 0.528363 * 100, metric = 8.54% * 100;
 Minibatch[ 801- 900]: loss = 0.541787 * 100, metric = 9.17% * 100;
 Minibatch[ 901-1000]: loss = 0.531419 * 100, metric = 8.54% * 100;
 Minibatch[1001-1100]: loss = 0.529064 * 100, metric = 8.61% * 100;
 Minibatch[1101-1200]: loss = 0.511490 * 100, metric = 8.12% * 100;
 Minibatch[1201-1300]: loss = 0.512787 * 100, metric = 7.81% * 100;
 Minibatch[1301-1400]: loss = 0.531831 * 100, metric = 8.79% * 100;
 Minibatch[1401-1500]: loss = 0.496792 * 100, metric = 7.76% * 100;
 Minibatch[1501-1600]: loss = 0.502860 * 100, metric = 8.09% * 100;
 Minibatch[1601-1700]: loss = 0.518616 * 100, metric = 8.13% * 100;
 Minibatch[1701-1800]: loss = 0.496232 * 100, metric = 7.60% * 100;
 Minibatch[1801-1900]: loss = 0.503137 * 100, metric = 8.04% * 100;
 Minibatch[1901-2000]: loss = 0.504059 * 100, metric = 8.17% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.516465 * 2000, metric = 8.23% * 2000 923.068s (  2.2 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 15.34% * 2000;
0.6440210463330149
 Minibatch[   1- 100]: loss = 0.526118 * 100, metric = 8.61% * 100;
 Minibatch[ 101- 200]: loss = 0.518982 * 100, metric = 8.10% * 100;
 Minibatch[ 201- 300]: loss = 0.511792 * 100, metric = 8.05% * 100;
 Minibatch[ 301- 400]: loss = 0.515564 * 100, metric = 8.13% * 100;
 Minibatch[ 401- 500]: loss = 0.496100 * 100, metric = 7.52% * 100;
 Minibatch[ 501- 600]: loss = 0.505184 * 100, metric = 7.96% * 100;
 Minibatch[ 601- 700]: loss = 0.512538 * 100, metric = 8.03% * 100;
 Minibatch[ 701- 800]: loss = 0.499408 * 100, metric = 7.81% * 100;
 Minibatch[ 801- 900]: loss = 0.496368 * 100, metric = 7.62% * 100;
 Minibatch[ 901-1000]: loss = 0.511474 * 100, metric = 8.24% * 100;
 Minibatch[1001-1100]: loss = 0.487189 * 100, metric = 7.69% * 100;
 Minibatch[1101-1200]: loss = 0.499614 * 100, metric = 7.74% * 100;
 Minibatch[1201-1300]: loss = 0.493452 * 100, metric = 7.59% * 100;
 Minibatch[1301-1400]: loss = 0.497894 * 100, metric = 7.54% * 100;
 Minibatch[1401-1500]: loss = 0.494980 * 100, metric = 7.68% * 100;
 Minibatch[1501-1600]: loss = 0.509462 * 100, metric = 8.16% * 100;
 Minibatch[1601-1700]: loss = 0.499116 * 100, metric = 7.84% * 100;
 Minibatch[1701-1800]: loss = 0.520375 * 100, metric = 8.27% * 100;
 Minibatch[1801-1900]: loss = 0.512944 * 100, metric = 8.14% * 100;
 Minibatch[1901-2000]: loss = 0.489868 * 100, metric = 7.78% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.504921 * 2000, metric = 7.92% * 2000 923.826s (  2.2 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.62% * 2000;
0.6260133402124047
 Minibatch[   1- 100]: loss = 0.496246 * 100, metric = 7.72% * 100;
 Minibatch[ 101- 200]: loss = 0.513164 * 100, metric = 8.22% * 100;
 Minibatch[ 201- 300]: loss = 0.513084 * 100, metric = 8.14% * 100;
 Minibatch[ 301- 400]: loss = 0.507696 * 100, metric = 7.96% * 100;
 Minibatch[ 401- 500]: loss = 0.511142 * 100, metric = 7.90% * 100;
 Minibatch[ 501- 600]: loss = 0.495700 * 100, metric = 7.64% * 100;
 Minibatch[ 601- 700]: loss = 0.474026 * 100, metric = 7.20% * 100;
 Minibatch[ 701- 800]: loss = 0.494218 * 100, metric = 7.71% * 100;
 Minibatch[ 801- 900]: loss = 0.502829 * 100, metric = 7.98% * 100;
 Minibatch[ 901-1000]: loss = 0.496929 * 100, metric = 7.83% * 100;
 Minibatch[1001-1100]: loss = 0.483113 * 100, metric = 7.45% * 100;
 Minibatch[1101-1200]: loss = 0.515565 * 100, metric = 8.32% * 100;
 Minibatch[1201-1300]: loss = 0.524047 * 100, metric = 8.15% * 100;
 Minibatch[1301-1400]: loss = 0.474068 * 100, metric = 7.24% * 100;
 Minibatch[1401-1500]: loss = 0.506796 * 100, metric = 7.95% * 100;
 Minibatch[1501-1600]: loss = 0.500365 * 100, metric = 7.89% * 100;
 Minibatch[1601-1700]: loss = 0.498991 * 100, metric = 7.64% * 100;
 Minibatch[1701-1800]: loss = 0.482039 * 100, metric = 7.57% * 100;
 Minibatch[1801-1900]: loss = 0.507606 * 100, metric = 8.31% * 100;
 Minibatch[1901-2000]: loss = 0.517302 * 100, metric = 8.14% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.500746 * 2000, metric = 7.85% * 2000 911.516s (  2.2 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.84% * 2000;
 Minibatch[   1- 100]: loss = 0.483785 * 100, metric = 7.49% * 100;
 Minibatch[ 101- 200]: loss = 0.506215 * 100, metric = 7.78% * 100;
 Minibatch[ 201- 300]: loss = 0.487678 * 100, metric = 7.50% * 100;
 Minibatch[ 301- 400]: loss = 0.496428 * 100, metric = 7.64% * 100;
 Minibatch[ 401- 500]: loss = 0.474494 * 100, metric = 7.33% * 100;
 Minibatch[ 501- 600]: loss = 0.483367 * 100, metric = 7.29% * 100;
 Minibatch[ 601- 700]: loss = 0.495807 * 100, metric = 7.79% * 100;
 Minibatch[ 701- 800]: loss = 0.474513 * 100, metric = 7.35% * 100;
 Minibatch[ 801- 900]: loss = 0.489460 * 100, metric = 7.66% * 100;
 Minibatch[ 901-1000]: loss = 0.492251 * 100, metric = 7.51% * 100;
 Minibatch[1001-1100]: loss = 0.504083 * 100, metric = 7.76% * 100;
 Minibatch[1101-1200]: loss = 0.498663 * 100, metric = 7.82% * 100;
 Minibatch[1201-1300]: loss = 0.514340 * 100, metric = 8.18% * 100;
 Minibatch[1301-1400]: loss = 0.508552 * 100, metric = 7.98% * 100;
 Minibatch[1401-1500]: loss = 0.486317 * 100, metric = 7.22% * 100;
 Minibatch[1501-1600]: loss = 0.500563 * 100, metric = 7.82% * 100;
 Minibatch[1601-1700]: loss = 0.460751 * 100, metric = 6.80% * 100;
 Minibatch[1701-1800]: loss = 0.480866 * 100, metric = 7.34% * 100;
 Minibatch[1801-1900]: loss = 0.475785 * 100, metric = 7.37% * 100;
 Minibatch[1901-2000]: loss = 0.486768 * 100, metric = 7.44% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.490034 * 2000, metric = 7.55% * 2000 910.071s (  2.2 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.71% * 2000;
 Minibatch[   1- 100]: loss = 0.499932 * 100, metric = 7.69% * 100;
 Minibatch[ 101- 200]: loss = 0.499613 * 100, metric = 7.71% * 100;
 Minibatch[ 201- 300]: loss = 0.476505 * 100, metric = 6.93% * 100;
 Minibatch[ 301- 400]: loss = 0.495868 * 100, metric = 7.60% * 100;
 Minibatch[ 401- 500]: loss = 0.494898 * 100, metric = 7.45% * 100;
 Minibatch[ 501- 600]: loss = 0.480968 * 100, metric = 7.33% * 100;
 Minibatch[ 601- 700]: loss = 0.492402 * 100, metric = 7.65% * 100;
 Minibatch[ 701- 800]: loss = 0.475412 * 100, metric = 7.41% * 100;
 Minibatch[ 801- 900]: loss = 0.505876 * 100, metric = 7.98% * 100;
 Minibatch[ 901-1000]: loss = 0.482354 * 100, metric = 7.20% * 100;
 Minibatch[1001-1100]: loss = 0.511073 * 100, metric = 7.75% * 100;
 Minibatch[1101-1200]: loss = 0.495111 * 100, metric = 7.66% * 100;
 Minibatch[1201-1300]: loss = 0.486094 * 100, metric = 7.47% * 100;
 Minibatch[1301-1400]: loss = 0.485310 * 100, metric = 7.55% * 100;
 Minibatch[1401-1500]: loss = 0.506450 * 100, metric = 7.92% * 100;
 Minibatch[1501-1600]: loss = 0.503015 * 100, metric = 7.79% * 100;
 Minibatch[1601-1700]: loss = 0.475204 * 100, metric = 7.36% * 100;
 Minibatch[1701-1800]: loss = 0.465784 * 100, metric = 7.18% * 100;
 Minibatch[1801-1900]: loss = 0.479520 * 100, metric = 7.35% * 100;
 Minibatch[1901-2000]: loss = 0.467037 * 100, metric = 6.92% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.488921 * 2000, metric = 7.49% * 2000 912.048s (  2.2 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 14.58% * 2000;
 Minibatch[   1- 100]: loss = 0.483363 * 100, metric = 7.32% * 100;
 Minibatch[ 101- 200]: loss = 0.485716 * 100, metric = 7.33% * 100;
 Minibatch[ 201- 300]: loss = 0.479125 * 100, metric = 7.29% * 100;
 Minibatch[ 301- 400]: loss = 0.498286 * 100, metric = 7.53% * 100;
 Minibatch[ 401- 500]: loss = 0.474233 * 100, metric = 7.18% * 100;
 Minibatch[ 501- 600]: loss = 0.484335 * 100, metric = 7.73% * 100;
 Minibatch[ 601- 700]: loss = 0.493700 * 100, metric = 7.83% * 100;
 Minibatch[ 701- 800]: loss = 0.480218 * 100, metric = 7.48% * 100;
 Minibatch[ 801- 900]: loss = 0.491733 * 100, metric = 7.67% * 100;
 Minibatch[ 901-1000]: loss = 0.489563 * 100, metric = 7.41% * 100;
 Minibatch[1001-1100]: loss = 0.453225 * 100, metric = 6.83% * 100;
 Minibatch[1101-1200]: loss = 0.474898 * 100, metric = 7.32% * 100;
 Minibatch[1201-1300]: loss = 0.492355 * 100, metric = 7.60% * 100;
 Minibatch[1301-1400]: loss = 0.488661 * 100, metric = 7.55% * 100;
 Minibatch[1401-1500]: loss = 0.485552 * 100, metric = 7.54% * 100;
 Minibatch[1501-1600]: loss = 0.483972 * 100, metric = 7.29% * 100;
 Minibatch[1601-1700]: loss = 0.472035 * 100, metric = 7.15% * 100;
 Minibatch[1701-1800]: loss = 0.487169 * 100, metric = 7.70% * 100;
 Minibatch[1801-1900]: loss = 0.467997 * 100, metric = 7.06% * 100;
 Minibatch[1901-2000]: loss = 0.473594 * 100, metric = 7.31% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.481987 * 2000, metric = 7.41% * 2000 899.256s (  2.2 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 15.37% * 2000;
 Minibatch[   1- 100]: loss = 0.483452 * 100, metric = 7.32% * 100;
 Minibatch[ 101- 200]: loss = 0.479043 * 100, metric = 7.29% * 100;
 Minibatch[ 201- 300]: loss = 0.475211 * 100, metric = 7.42% * 100;
 Minibatch[ 301- 400]: loss = 0.487757 * 100, metric = 7.60% * 100;
 Minibatch[ 401- 500]: loss = 0.465096 * 100, metric = 6.99% * 100;
 Minibatch[ 501- 600]: loss = 0.464934 * 100, metric = 6.91% * 100;
 Minibatch[ 601- 700]: loss = 0.466821 * 100, metric = 7.12% * 100;
 Minibatch[ 701- 800]: loss = 0.439104 * 100, metric = 6.78% * 100;
 Minibatch[ 801- 900]: loss = 0.478036 * 100, metric = 7.16% * 100;
 Minibatch[ 901-1000]: loss = 0.465381 * 100, metric = 7.06% * 100;
 Minibatch[1001-1100]: loss = 0.466716 * 100, metric = 7.11% * 100;
 Minibatch[1101-1200]: loss = 0.465179 * 100, metric = 6.93% * 100;
 Minibatch[1201-1300]: loss = 0.475402 * 100, metric = 7.34% * 100;
 Minibatch[1301-1400]: loss = 0.462914 * 100, metric = 6.85% * 100;
 Minibatch[1401-1500]: loss = 0.480806 * 100, metric = 7.41% * 100;
 Minibatch[1501-1600]: loss = 0.484158 * 100, metric = 7.63% * 100;
 Minibatch[1601-1700]: loss = 0.464831 * 100, metric = 6.88% * 100;
 Minibatch[1701-1800]: loss = 0.472502 * 100, metric = 7.27% * 100;
 Minibatch[1801-1900]: loss = 0.486794 * 100, metric = 7.54% * 100;
 Minibatch[1901-2000]: loss = 0.458310 * 100, metric = 6.88% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.471122 * 2000, metric = 7.17% * 2000 901.488s (  2.2 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 13.88% * 2000;
0.6138274531438946
 Minibatch[   1- 100]: loss = 0.485387 * 100, metric = 7.63% * 100;
 Minibatch[ 101- 200]: loss = 0.471382 * 100, metric = 7.16% * 100;
 Minibatch[ 201- 300]: loss = 0.479576 * 100, metric = 7.41% * 100;
 Minibatch[ 301- 400]: loss = 0.469637 * 100, metric = 7.28% * 100;
 Minibatch[ 401- 500]: loss = 0.465546 * 100, metric = 7.01% * 100;
 Minibatch[ 501- 600]: loss = 0.480793 * 100, metric = 7.19% * 100;
 Minibatch[ 601- 700]: loss = 0.474290 * 100, metric = 7.11% * 100;
 Minibatch[ 701- 800]: loss = 0.463492 * 100, metric = 7.06% * 100;
 Minibatch[ 801- 900]: loss = 0.476133 * 100, metric = 7.43% * 100;
 Minibatch[ 901-1000]: loss = 0.478875 * 100, metric = 7.17% * 100;
 Minibatch[1001-1100]: loss = 0.444470 * 100, metric = 6.52% * 100;
 Minibatch[1101-1200]: loss = 0.439230 * 100, metric = 6.53% * 100;
 Minibatch[1201-1300]: loss = 0.457347 * 100, metric = 6.90% * 100;
 Minibatch[1301-1400]: loss = 0.465211 * 100, metric = 7.06% * 100;
 Minibatch[1401-1500]: loss = 0.454307 * 100, metric = 6.95% * 100;
 Minibatch[1501-1600]: loss = 0.445587 * 100, metric = 6.57% * 100;
 Minibatch[1601-1700]: loss = 0.454567 * 100, metric = 6.84% * 100;
 Minibatch[1701-1800]: loss = 0.457459 * 100, metric = 6.77% * 100;
 Minibatch[1801-1900]: loss = 0.450947 * 100, metric = 6.88% * 100;
 Minibatch[1901-2000]: loss = 0.461332 * 100, metric = 6.90% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.463778 * 2000, metric = 7.02% * 2000 900.735s (  2.2 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 14.08% * 2000;
 Minibatch[   1- 100]: loss = 0.468958 * 100, metric = 7.01% * 100;
 Minibatch[ 101- 200]: loss = 0.472546 * 100, metric = 7.25% * 100;
 Minibatch[ 201- 300]: loss = 0.458201 * 100, metric = 6.66% * 100;
 Minibatch[ 301- 400]: loss = 0.479547 * 100, metric = 7.30% * 100;
 Minibatch[ 401- 500]: loss = 0.474354 * 100, metric = 7.18% * 100;
 Minibatch[ 501- 600]: loss = 0.472918 * 100, metric = 7.02% * 100;
 Minibatch[ 601- 700]: loss = 0.477061 * 100, metric = 7.10% * 100;
 Minibatch[ 701- 800]: loss = 0.443448 * 100, metric = 6.44% * 100;
 Minibatch[ 801- 900]: loss = 0.451139 * 100, metric = 6.78% * 100;
 Minibatch[ 901-1000]: loss = 0.468361 * 100, metric = 7.02% * 100;
 Minibatch[1001-1100]: loss = 0.456060 * 100, metric = 6.66% * 100;
 Minibatch[1101-1200]: loss = 0.464132 * 100, metric = 6.88% * 100;
 Minibatch[1201-1300]: loss = 0.471432 * 100, metric = 7.05% * 100;
 Minibatch[1301-1400]: loss = 0.475287 * 100, metric = 7.21% * 100;
 Minibatch[1401-1500]: loss = 0.456727 * 100, metric = 6.90% * 100;
 Minibatch[1501-1600]: loss = 0.463768 * 100, metric = 7.09% * 100;
 Minibatch[1601-1700]: loss = 0.456010 * 100, metric = 6.99% * 100;
 Minibatch[1701-1800]: loss = 0.469799 * 100, metric = 7.17% * 100;
 Minibatch[1801-1900]: loss = 0.466440 * 100, metric = 7.36% * 100;
 Minibatch[1901-2000]: loss = 0.465137 * 100, metric = 6.83% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.465566 * 2000, metric = 7.00% * 2000 893.071s (  2.2 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 15.48% * 2000;
 Minibatch[   1- 100]: loss = 0.447513 * 100, metric = 6.75% * 100;
 Minibatch[ 101- 200]: loss = 0.467491 * 100, metric = 7.12% * 100;
 Minibatch[ 201- 300]: loss = 0.456576 * 100, metric = 7.02% * 100;
 Minibatch[ 301- 400]: loss = 0.466791 * 100, metric = 7.07% * 100;
 Minibatch[ 401- 500]: loss = 0.460654 * 100, metric = 7.00% * 100;
 Minibatch[ 501- 600]: loss = 0.462415 * 100, metric = 7.14% * 100;
 Minibatch[ 601- 700]: loss = 0.472650 * 100, metric = 7.25% * 100;
 Minibatch[ 701- 800]: loss = 0.460738 * 100, metric = 7.01% * 100;
 Minibatch[ 801- 900]: loss = 0.474253 * 100, metric = 7.27% * 100;
 Minibatch[ 901-1000]: loss = 0.468871 * 100, metric = 7.08% * 100;
 Minibatch[1001-1100]: loss = 0.470743 * 100, metric = 6.80% * 100;
 Minibatch[1101-1200]: loss = 0.474645 * 100, metric = 7.20% * 100;
 Minibatch[1201-1300]: loss = 0.470458 * 100, metric = 6.97% * 100;
 Minibatch[1301-1400]: loss = 0.461257 * 100, metric = 6.72% * 100;
 Minibatch[1401-1500]: loss = 0.455988 * 100, metric = 6.76% * 100;
 Minibatch[1501-1600]: loss = 0.472352 * 100, metric = 7.18% * 100;
 Minibatch[1601-1700]: loss = 0.447626 * 100, metric = 6.67% * 100;
 Minibatch[1701-1800]: loss = 0.445959 * 100, metric = 6.57% * 100;
 Minibatch[1801-1900]: loss = 0.459562 * 100, metric = 6.85% * 100;
 Minibatch[1901-2000]: loss = 0.467028 * 100, metric = 7.12% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.463179 * 2000, metric = 6.98% * 2000 890.429s (  2.2 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.01% * 2000;
0.6135872926265001
 Minibatch[   1- 100]: loss = 0.455156 * 100, metric = 6.83% * 100;
 Minibatch[ 101- 200]: loss = 0.459490 * 100, metric = 7.10% * 100;
 Minibatch[ 201- 300]: loss = 0.456941 * 100, metric = 7.20% * 100;
 Minibatch[ 301- 400]: loss = 0.456296 * 100, metric = 6.90% * 100;
 Minibatch[ 401- 500]: loss = 0.446900 * 100, metric = 6.59% * 100;
 Minibatch[ 501- 600]: loss = 0.463381 * 100, metric = 6.90% * 100;
 Minibatch[ 601- 700]: loss = 0.458874 * 100, metric = 6.81% * 100;
 Minibatch[ 701- 800]: loss = 0.448188 * 100, metric = 6.46% * 100;
 Minibatch[ 801- 900]: loss = 0.453263 * 100, metric = 6.77% * 100;
 Minibatch[ 901-1000]: loss = 0.451463 * 100, metric = 6.80% * 100;
 Minibatch[1001-1100]: loss = 0.450995 * 100, metric = 6.76% * 100;
 Minibatch[1101-1200]: loss = 0.463605 * 100, metric = 7.00% * 100;
 Minibatch[1201-1300]: loss = 0.471523 * 100, metric = 7.17% * 100;
 Minibatch[1301-1400]: loss = 0.450764 * 100, metric = 6.57% * 100;
 Minibatch[1401-1500]: loss = 0.446017 * 100, metric = 6.48% * 100;
 Minibatch[1501-1600]: loss = 0.459539 * 100, metric = 6.92% * 100;
 Minibatch[1601-1700]: loss = 0.454337 * 100, metric = 7.05% * 100;
 Minibatch[1701-1800]: loss = 0.457076 * 100, metric = 6.98% * 100;
 Minibatch[1801-1900]: loss = 0.440062 * 100, metric = 6.40% * 100;
 Minibatch[1901-2000]: loss = 0.442736 * 100, metric = 6.60% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.454330 * 2000, metric = 6.81% * 2000 887.760s (  2.3 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 13.73% * 2000;
 Minibatch[   1- 100]: loss = 0.452135 * 100, metric = 6.71% * 100;
 Minibatch[ 101- 200]: loss = 0.435993 * 100, metric = 6.32% * 100;
 Minibatch[ 201- 300]: loss = 0.459625 * 100, metric = 7.03% * 100;
 Minibatch[ 301- 400]: loss = 0.438390 * 100, metric = 6.37% * 100;
 Minibatch[ 401- 500]: loss = 0.448773 * 100, metric = 6.64% * 100;
 Minibatch[ 501- 600]: loss = 0.448920 * 100, metric = 6.53% * 100;
 Minibatch[ 601- 700]: loss = 0.461749 * 100, metric = 7.07% * 100;
 Minibatch[ 701- 800]: loss = 0.441918 * 100, metric = 6.81% * 100;
 Minibatch[ 801- 900]: loss = 0.436772 * 100, metric = 6.29% * 100;
 Minibatch[ 901-1000]: loss = 0.437502 * 100, metric = 6.29% * 100;
 Minibatch[1001-1100]: loss = 0.460810 * 100, metric = 7.10% * 100;
 Minibatch[1101-1200]: loss = 0.463078 * 100, metric = 6.93% * 100;
 Minibatch[1201-1300]: loss = 0.443416 * 100, metric = 6.51% * 100;
 Minibatch[1301-1400]: loss = 0.440611 * 100, metric = 6.45% * 100;
 Minibatch[1401-1500]: loss = 0.451370 * 100, metric = 6.74% * 100;
 Minibatch[1501-1600]: loss = 0.448195 * 100, metric = 6.43% * 100;
 Minibatch[1601-1700]: loss = 0.476691 * 100, metric = 7.05% * 100;
 Minibatch[1701-1800]: loss = 0.461957 * 100, metric = 6.91% * 100;
 Minibatch[1801-1900]: loss = 0.452842 * 100, metric = 6.74% * 100;
 Minibatch[1901-2000]: loss = 0.453759 * 100, metric = 6.61% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.450725 * 2000, metric = 6.68% * 2000 880.888s (  2.3 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 14.10% * 2000;
 Minibatch[   1- 100]: loss = 0.446043 * 100, metric = 6.39% * 100;
 Minibatch[ 101- 200]: loss = 0.461861 * 100, metric = 6.74% * 100;
 Minibatch[ 201- 300]: loss = 0.438631 * 100, metric = 6.51% * 100;
 Minibatch[ 301- 400]: loss = 0.440970 * 100, metric = 6.54% * 100;
 Minibatch[ 401- 500]: loss = 0.449354 * 100, metric = 6.64% * 100;
 Minibatch[ 501- 600]: loss = 0.429108 * 100, metric = 6.33% * 100;
 Minibatch[ 601- 700]: loss = 0.429592 * 100, metric = 6.30% * 100;
 Minibatch[ 701- 800]: loss = 0.449297 * 100, metric = 6.55% * 100;
 Minibatch[ 801- 900]: loss = 0.465883 * 100, metric = 7.03% * 100;
 Minibatch[ 901-1000]: loss = 0.456770 * 100, metric = 7.15% * 100;
 Minibatch[1001-1100]: loss = 0.454281 * 100, metric = 6.53% * 100;
 Minibatch[1101-1200]: loss = 0.457287 * 100, metric = 6.78% * 100;
 Minibatch[1201-1300]: loss = 0.446854 * 100, metric = 6.63% * 100;
 Minibatch[1301-1400]: loss = 0.457440 * 100, metric = 6.95% * 100;
 Minibatch[1401-1500]: loss = 0.434535 * 100, metric = 6.35% * 100;
 Minibatch[1501-1600]: loss = 0.440104 * 100, metric = 6.53% * 100;
 Minibatch[1601-1700]: loss = 0.424327 * 100, metric = 6.09% * 100;
 Minibatch[1701-1800]: loss = 0.440935 * 100, metric = 6.42% * 100;
 Minibatch[1801-1900]: loss = 0.447098 * 100, metric = 6.50% * 100;
 Minibatch[1901-2000]: loss = 0.458229 * 100, metric = 6.80% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.446430 * 2000, metric = 6.59% * 2000 880.574s (  2.3 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.60% * 2000;
 Minibatch[   1- 100]: loss = 0.453870 * 100, metric = 6.85% * 100;
 Minibatch[ 101- 200]: loss = 0.428266 * 100, metric = 6.27% * 100;
 Minibatch[ 201- 300]: loss = 0.442650 * 100, metric = 6.56% * 100;
 Minibatch[ 301- 400]: loss = 0.444815 * 100, metric = 6.50% * 100;
 Minibatch[ 401- 500]: loss = 0.443331 * 100, metric = 6.49% * 100;
 Minibatch[ 501- 600]: loss = 0.457163 * 100, metric = 6.91% * 100;
 Minibatch[ 601- 700]: loss = 0.442717 * 100, metric = 6.49% * 100;
 Minibatch[ 701- 800]: loss = 0.436613 * 100, metric = 6.43% * 100;
 Minibatch[ 801- 900]: loss = 0.442477 * 100, metric = 6.71% * 100;
 Minibatch[ 901-1000]: loss = 0.453582 * 100, metric = 6.97% * 100;
 Minibatch[1001-1100]: loss = 0.434363 * 100, metric = 6.26% * 100;
 Minibatch[1101-1200]: loss = 0.437155 * 100, metric = 6.18% * 100;
 Minibatch[1201-1300]: loss = 0.453201 * 100, metric = 6.69% * 100;
 Minibatch[1301-1400]: loss = 0.435429 * 100, metric = 6.57% * 100;
 Minibatch[1401-1500]: loss = 0.454528 * 100, metric = 6.71% * 100;
 Minibatch[1501-1600]: loss = 0.431970 * 100, metric = 6.14% * 100;
 Minibatch[1601-1700]: loss = 0.438512 * 100, metric = 6.30% * 100;
 Minibatch[1701-1800]: loss = 0.440425 * 100, metric = 6.40% * 100;
 Minibatch[1801-1900]: loss = 0.439598 * 100, metric = 6.49% * 100;
 Minibatch[1901-2000]: loss = 0.445336 * 100, metric = 6.54% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.442800 * 2000, metric = 6.52% * 2000 881.144s (  2.3 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.15% * 2000;
0.6017991775795818
 Minibatch[   1- 100]: loss = 0.430277 * 100, metric = 6.33% * 100;
 Minibatch[ 101- 200]: loss = 0.438458 * 100, metric = 6.59% * 100;
 Minibatch[ 201- 300]: loss = 0.453509 * 100, metric = 6.71% * 100;
 Minibatch[ 301- 400]: loss = 0.463376 * 100, metric = 6.90% * 100;
 Minibatch[ 401- 500]: loss = 0.433101 * 100, metric = 6.09% * 100;
 Minibatch[ 501- 600]: loss = 0.437110 * 100, metric = 6.42% * 100;
 Minibatch[ 601- 700]: loss = 0.431313 * 100, metric = 6.35% * 100;
 Minibatch[ 701- 800]: loss = 0.448156 * 100, metric = 6.87% * 100;
 Minibatch[ 801- 900]: loss = 0.446265 * 100, metric = 6.61% * 100;
 Minibatch[ 901-1000]: loss = 0.448938 * 100, metric = 6.68% * 100;
 Minibatch[1001-1100]: loss = 0.448346 * 100, metric = 6.62% * 100;
 Minibatch[1101-1200]: loss = 0.432403 * 100, metric = 6.14% * 100;
 Minibatch[1201-1300]: loss = 0.442139 * 100, metric = 6.44% * 100;
 Minibatch[1301-1400]: loss = 0.437374 * 100, metric = 6.35% * 100;
 Minibatch[1401-1500]: loss = 0.451763 * 100, metric = 6.48% * 100;
 Minibatch[1501-1600]: loss = 0.425682 * 100, metric = 6.24% * 100;
 Minibatch[1601-1700]: loss = 0.447272 * 100, metric = 6.71% * 100;
 Minibatch[1701-1800]: loss = 0.434766 * 100, metric = 6.19% * 100;
 Minibatch[1801-1900]: loss = 0.455231 * 100, metric = 6.57% * 100;
 Minibatch[1901-2000]: loss = 0.448744 * 100, metric = 6.47% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.442711 * 2000, metric = 6.49% * 2000 885.082s (  2.3 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 14.53% * 2000;
 Minibatch[   1- 100]: loss = 0.453405 * 100, metric = 6.49% * 100;
 Minibatch[ 101- 200]: loss = 0.420419 * 100, metric = 5.99% * 100;
 Minibatch[ 201- 300]: loss = 0.428626 * 100, metric = 6.10% * 100;
 Minibatch[ 301- 400]: loss = 0.455440 * 100, metric = 6.87% * 100;
 Minibatch[ 401- 500]: loss = 0.441197 * 100, metric = 6.41% * 100;
 Minibatch[ 501- 600]: loss = 0.414955 * 100, metric = 5.88% * 100;
 Minibatch[ 601- 700]: loss = 0.439676 * 100, metric = 6.54% * 100;
 Minibatch[ 701- 800]: loss = 0.423872 * 100, metric = 6.07% * 100;
 Minibatch[ 801- 900]: loss = 0.447077 * 100, metric = 6.58% * 100;
 Minibatch[ 901-1000]: loss = 0.416555 * 100, metric = 5.95% * 100;
 Minibatch[1001-1100]: loss = 0.436700 * 100, metric = 6.34% * 100;
 Minibatch[1101-1200]: loss = 0.445100 * 100, metric = 6.55% * 100;
 Minibatch[1201-1300]: loss = 0.431675 * 100, metric = 6.28% * 100;
 Minibatch[1301-1400]: loss = 0.445879 * 100, metric = 6.54% * 100;
 Minibatch[1401-1500]: loss = 0.438368 * 100, metric = 6.47% * 100;
 Minibatch[1501-1600]: loss = 0.455748 * 100, metric = 6.66% * 100;
 Minibatch[1601-1700]: loss = 0.434808 * 100, metric = 6.47% * 100;
 Minibatch[1701-1800]: loss = 0.438090 * 100, metric = 6.48% * 100;
 Minibatch[1801-1900]: loss = 0.435605 * 100, metric = 6.54% * 100;
 Minibatch[1901-2000]: loss = 0.455220 * 100, metric = 6.77% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.437921 * 2000, metric = 6.40% * 2000 890.423s (  2.2 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.21% * 2000;
 Minibatch[   1- 100]: loss = 0.436405 * 100, metric = 6.24% * 100;
 Minibatch[ 101- 200]: loss = 0.445991 * 100, metric = 6.74% * 100;
 Minibatch[ 201- 300]: loss = 0.432406 * 100, metric = 6.42% * 100;
 Minibatch[ 301- 400]: loss = 0.432024 * 100, metric = 6.33% * 100;
 Minibatch[ 401- 500]: loss = 0.429425 * 100, metric = 6.31% * 100;
 Minibatch[ 501- 600]: loss = 0.434842 * 100, metric = 6.10% * 100;
 Minibatch[ 601- 700]: loss = 0.449622 * 100, metric = 6.72% * 100;
 Minibatch[ 701- 800]: loss = 0.444572 * 100, metric = 6.70% * 100;
 Minibatch[ 801- 900]: loss = 0.439834 * 100, metric = 6.32% * 100;
 Minibatch[ 901-1000]: loss = 0.426041 * 100, metric = 6.33% * 100;
 Minibatch[1001-1100]: loss = 0.424283 * 100, metric = 5.96% * 100;
 Minibatch[1101-1200]: loss = 0.444437 * 100, metric = 6.54% * 100;
 Minibatch[1201-1300]: loss = 0.435188 * 100, metric = 6.23% * 100;
 Minibatch[1301-1400]: loss = 0.430178 * 100, metric = 6.40% * 100;
 Minibatch[1401-1500]: loss = 0.440103 * 100, metric = 6.43% * 100;
 Minibatch[1501-1600]: loss = 0.419008 * 100, metric = 6.16% * 100;
 Minibatch[1601-1700]: loss = 0.428459 * 100, metric = 6.19% * 100;
 Minibatch[1701-1800]: loss = 0.423322 * 100, metric = 6.17% * 100;
 Minibatch[1801-1900]: loss = 0.440185 * 100, metric = 6.46% * 100;
 Minibatch[1901-2000]: loss = 0.426721 * 100, metric = 6.18% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.434152 * 2000, metric = 6.35% * 2000 882.695s (  2.3 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 13.28% * 2000;
 Minibatch[   1- 100]: loss = 0.431315 * 100, metric = 6.46% * 100;
 Minibatch[ 101- 200]: loss = 0.447154 * 100, metric = 6.36% * 100;
 Minibatch[ 201- 300]: loss = 0.441437 * 100, metric = 6.47% * 100;
 Minibatch[ 301- 400]: loss = 0.451295 * 100, metric = 6.58% * 100;
 Minibatch[ 401- 500]: loss = 0.435231 * 100, metric = 6.62% * 100;
 Minibatch[ 501- 600]: loss = 0.439906 * 100, metric = 6.61% * 100;
 Minibatch[ 601- 700]: loss = 0.425022 * 100, metric = 6.08% * 100;
 Minibatch[ 701- 800]: loss = 0.424416 * 100, metric = 6.06% * 100;
 Minibatch[ 801- 900]: loss = 0.435691 * 100, metric = 6.40% * 100;
 Minibatch[ 901-1000]: loss = 0.417755 * 100, metric = 5.98% * 100;
 Minibatch[1001-1100]: loss = 0.422993 * 100, metric = 5.88% * 100;
 Minibatch[1101-1200]: loss = 0.440424 * 100, metric = 6.50% * 100;
 Minibatch[1201-1300]: loss = 0.450383 * 100, metric = 6.77% * 100;
 Minibatch[1301-1400]: loss = 0.431233 * 100, metric = 6.26% * 100;
 Minibatch[1401-1500]: loss = 0.430858 * 100, metric = 6.48% * 100;
 Minibatch[1501-1600]: loss = 0.440538 * 100, metric = 6.50% * 100;
 Minibatch[1601-1700]: loss = 0.421698 * 100, metric = 6.19% * 100;
 Minibatch[1701-1800]: loss = 0.450065 * 100, metric = 6.58% * 100;
 Minibatch[1801-1900]: loss = 0.427006 * 100, metric = 6.13% * 100;
 Minibatch[1901-2000]: loss = 0.437501 * 100, metric = 6.45% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.435096 * 2000, metric = 6.37% * 2000 885.890s (  2.3 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.34% * 2000;
 Minibatch[   1- 100]: loss = 0.453522 * 100, metric = 6.78% * 100;
 Minibatch[ 101- 200]: loss = 0.433578 * 100, metric = 6.55% * 100;
 Minibatch[ 201- 300]: loss = 0.422683 * 100, metric = 6.29% * 100;
 Minibatch[ 301- 400]: loss = 0.439271 * 100, metric = 6.57% * 100;
 Minibatch[ 401- 500]: loss = 0.428684 * 100, metric = 6.26% * 100;
 Minibatch[ 501- 600]: loss = 0.437649 * 100, metric = 6.34% * 100;
 Minibatch[ 601- 700]: loss = 0.440930 * 100, metric = 6.59% * 100;
 Minibatch[ 701- 800]: loss = 0.425168 * 100, metric = 6.20% * 100;
 Minibatch[ 801- 900]: loss = 0.435511 * 100, metric = 6.24% * 100;
 Minibatch[ 901-1000]: loss = 0.418350 * 100, metric = 5.91% * 100;
 Minibatch[1001-1100]: loss = 0.424450 * 100, metric = 6.22% * 100;
 Minibatch[1101-1200]: loss = 0.410799 * 100, metric = 5.93% * 100;
 Minibatch[1201-1300]: loss = 0.443071 * 100, metric = 6.38% * 100;
 Minibatch[1301-1400]: loss = 0.425451 * 100, metric = 6.04% * 100;
 Minibatch[1401-1500]: loss = 0.441501 * 100, metric = 6.58% * 100;
 Minibatch[1501-1600]: loss = 0.434412 * 100, metric = 6.38% * 100;
 Minibatch[1601-1700]: loss = 0.420366 * 100, metric = 5.93% * 100;
 Minibatch[1701-1800]: loss = 0.418034 * 100, metric = 5.96% * 100;
 Minibatch[1801-1900]: loss = 0.422361 * 100, metric = 6.12% * 100;
 Minibatch[1901-2000]: loss = 0.442751 * 100, metric = 6.79% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.430927 * 2000, metric = 6.30% * 2000 874.413s (  2.3 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.41% * 2000;
 Minibatch[   1- 100]: loss = 0.422512 * 100, metric = 6.14% * 100;
 Minibatch[ 101- 200]: loss = 0.431968 * 100, metric = 6.31% * 100;
 Minibatch[ 201- 300]: loss = 0.410781 * 100, metric = 5.94% * 100;
 Minibatch[ 301- 400]: loss = 0.427451 * 100, metric = 6.35% * 100;
 Minibatch[ 401- 500]: loss = 0.410179 * 100, metric = 5.86% * 100;
 Minibatch[ 501- 600]: loss = 0.426428 * 100, metric = 6.06% * 100;
 Minibatch[ 601- 700]: loss = 0.428104 * 100, metric = 6.23% * 100;
 Minibatch[ 701- 800]: loss = 0.417604 * 100, metric = 5.94% * 100;
 Minibatch[ 801- 900]: loss = 0.405504 * 100, metric = 5.48% * 100;
 Minibatch[ 901-1000]: loss = 0.416385 * 100, metric = 6.04% * 100;
 Minibatch[1001-1100]: loss = 0.425190 * 100, metric = 6.28% * 100;
 Minibatch[1101-1200]: loss = 0.421416 * 100, metric = 6.21% * 100;
 Minibatch[1201-1300]: loss = 0.426646 * 100, metric = 6.33% * 100;
 Minibatch[1301-1400]: loss = 0.417203 * 100, metric = 6.17% * 100;
 Minibatch[1401-1500]: loss = 0.435994 * 100, metric = 6.41% * 100;
 Minibatch[1501-1600]: loss = 0.440192 * 100, metric = 6.38% * 100;
 Minibatch[1601-1700]: loss = 0.444487 * 100, metric = 6.55% * 100;
 Minibatch[1701-1800]: loss = 0.424276 * 100, metric = 6.16% * 100;
 Minibatch[1801-1900]: loss = 0.430481 * 100, metric = 6.08% * 100;
 Minibatch[1901-2000]: loss = 0.428287 * 100, metric = 6.23% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.424554 * 2000, metric = 6.16% * 2000 878.438s (  2.3 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 13.64% * 2000;
 Minibatch[   1- 100]: loss = 0.404254 * 100, metric = 5.74% * 100;
 Minibatch[ 101- 200]: loss = 0.432275 * 100, metric = 6.44% * 100;
 Minibatch[ 201- 300]: loss = 0.428330 * 100, metric = 6.34% * 100;
 Minibatch[ 301- 400]: loss = 0.410233 * 100, metric = 5.76% * 100;
 Minibatch[ 401- 500]: loss = 0.423652 * 100, metric = 5.98% * 100;
 Minibatch[ 501- 600]: loss = 0.402515 * 100, metric = 5.84% * 100;
 Minibatch[ 601- 700]: loss = 0.435919 * 100, metric = 6.36% * 100;
 Minibatch[ 701- 800]: loss = 0.400717 * 100, metric = 5.70% * 100;
 Minibatch[ 801- 900]: loss = 0.427221 * 100, metric = 6.27% * 100;
 Minibatch[ 901-1000]: loss = 0.407926 * 100, metric = 5.90% * 100;
 Minibatch[1001-1100]: loss = 0.440581 * 100, metric = 6.52% * 100;
 Minibatch[1101-1200]: loss = 0.416691 * 100, metric = 5.89% * 100;
 Minibatch[1201-1300]: loss = 0.419687 * 100, metric = 5.97% * 100;
 Minibatch[1301-1400]: loss = 0.420811 * 100, metric = 6.16% * 100;
 Minibatch[1401-1500]: loss = 0.410513 * 100, metric = 5.53% * 100;
 Minibatch[1501-1600]: loss = 0.415724 * 100, metric = 6.18% * 100;
 Minibatch[1601-1700]: loss = 0.418692 * 100, metric = 6.19% * 100;
 Minibatch[1701-1800]: loss = 0.409545 * 100, metric = 5.79% * 100;
 Minibatch[1801-1900]: loss = 0.431396 * 100, metric = 6.38% * 100;
 Minibatch[1901-2000]: loss = 0.410850 * 100, metric = 5.94% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.418377 * 2000, metric = 6.04% * 2000 874.674s (  2.3 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 12.83% * 2000;
 Minibatch[   1- 100]: loss = 0.414577 * 100, metric = 5.87% * 100;
 Minibatch[ 101- 200]: loss = 0.400569 * 100, metric = 5.55% * 100;
 Minibatch[ 201- 300]: loss = 0.426531 * 100, metric = 6.32% * 100;
 Minibatch[ 301- 400]: loss = 0.414365 * 100, metric = 5.96% * 100;
 Minibatch[ 401- 500]: loss = 0.410191 * 100, metric = 5.77% * 100;
 Minibatch[ 501- 600]: loss = 0.413609 * 100, metric = 5.95% * 100;
 Minibatch[ 601- 700]: loss = 0.418514 * 100, metric = 5.68% * 100;
 Minibatch[ 701- 800]: loss = 0.395929 * 100, metric = 5.74% * 100;
 Minibatch[ 801- 900]: loss = 0.395522 * 100, metric = 5.73% * 100;
 Minibatch[ 901-1000]: loss = 0.422144 * 100, metric = 6.12% * 100;
 Minibatch[1001-1100]: loss = 0.427831 * 100, metric = 6.40% * 100;
 Minibatch[1101-1200]: loss = 0.413032 * 100, metric = 5.96% * 100;
 Minibatch[1201-1300]: loss = 0.417453 * 100, metric = 6.17% * 100;
 Minibatch[1301-1400]: loss = 0.391097 * 100, metric = 5.48% * 100;
 Minibatch[1401-1500]: loss = 0.406859 * 100, metric = 5.81% * 100;
 Minibatch[1501-1600]: loss = 0.411215 * 100, metric = 5.86% * 100;
 Minibatch[1601-1700]: loss = 0.423470 * 100, metric = 6.29% * 100;
 Minibatch[1701-1800]: loss = 0.417075 * 100, metric = 5.97% * 100;
 Minibatch[1801-1900]: loss = 0.410988 * 100, metric = 5.81% * 100;
 Minibatch[1901-2000]: loss = 0.402009 * 100, metric = 5.59% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.411649 * 2000, metric = 5.90% * 2000 902.559s (  2.2 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.09% * 2000;
 Minibatch[   1- 100]: loss = 0.400600 * 100, metric = 5.73% * 100;
 Minibatch[ 101- 200]: loss = 0.417688 * 100, metric = 6.12% * 100;
 Minibatch[ 201- 300]: loss = 0.403279 * 100, metric = 5.72% * 100;
 Minibatch[ 301- 400]: loss = 0.409662 * 100, metric = 5.69% * 100;
 Minibatch[ 401- 500]: loss = 0.409891 * 100, metric = 6.10% * 100;
 Minibatch[ 501- 600]: loss = 0.401127 * 100, metric = 5.75% * 100;
 Minibatch[ 601- 700]: loss = 0.411375 * 100, metric = 5.96% * 100;
 Minibatch[ 701- 800]: loss = 0.427534 * 100, metric = 6.19% * 100;
 Minibatch[ 801- 900]: loss = 0.417206 * 100, metric = 5.95% * 100;
 Minibatch[ 901-1000]: loss = 0.396722 * 100, metric = 5.45% * 100;
 Minibatch[1001-1100]: loss = 0.407936 * 100, metric = 5.81% * 100;
 Minibatch[1101-1200]: loss = 0.428589 * 100, metric = 6.27% * 100;
 Minibatch[1201-1300]: loss = 0.424945 * 100, metric = 6.08% * 100;
 Minibatch[1301-1400]: loss = 0.409863 * 100, metric = 5.71% * 100;
 Minibatch[1401-1500]: loss = 0.407345 * 100, metric = 5.87% * 100;
 Minibatch[1501-1600]: loss = 0.411066 * 100, metric = 5.87% * 100;
 Minibatch[1601-1700]: loss = 0.414238 * 100, metric = 5.94% * 100;
 Minibatch[1701-1800]: loss = 0.405059 * 100, metric = 5.56% * 100;
 Minibatch[1801-1900]: loss = 0.417986 * 100, metric = 6.21% * 100;
 Minibatch[1901-2000]: loss = 0.407645 * 100, metric = 5.74% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.411488 * 2000, metric = 5.89% * 2000 911.745s (  2.2 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 12.74% * 2000;
 Minibatch[   1- 100]: loss = 0.415020 * 100, metric = 6.11% * 100;
 Minibatch[ 101- 200]: loss = 0.415076 * 100, metric = 6.16% * 100;
 Minibatch[ 201- 300]: loss = 0.394144 * 100, metric = 5.46% * 100;
 Minibatch[ 301- 400]: loss = 0.395843 * 100, metric = 5.47% * 100;
 Minibatch[ 401- 500]: loss = 0.411664 * 100, metric = 5.66% * 100;
 Minibatch[ 501- 600]: loss = 0.410304 * 100, metric = 5.63% * 100;
 Minibatch[ 601- 700]: loss = 0.406731 * 100, metric = 5.90% * 100;
 Minibatch[ 701- 800]: loss = 0.401985 * 100, metric = 5.64% * 100;
 Minibatch[ 801- 900]: loss = 0.422477 * 100, metric = 5.99% * 100;
 Minibatch[ 901-1000]: loss = 0.414621 * 100, metric = 5.62% * 100;
 Minibatch[1001-1100]: loss = 0.413632 * 100, metric = 5.96% * 100;
 Minibatch[1101-1200]: loss = 0.403244 * 100, metric = 5.77% * 100;
 Minibatch[1201-1300]: loss = 0.404872 * 100, metric = 5.75% * 100;
 Minibatch[1301-1400]: loss = 0.419772 * 100, metric = 5.94% * 100;
 Minibatch[1401-1500]: loss = 0.415422 * 100, metric = 6.12% * 100;
 Minibatch[1501-1600]: loss = 0.424326 * 100, metric = 6.01% * 100;
 Minibatch[1601-1700]: loss = 0.395614 * 100, metric = 5.60% * 100;
 Minibatch[1701-1800]: loss = 0.398156 * 100, metric = 5.74% * 100;
 Minibatch[1801-1900]: loss = 0.410693 * 100, metric = 5.88% * 100;
 Minibatch[1901-2000]: loss = 0.418370 * 100, metric = 5.90% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.409598 * 2000, metric = 5.82% * 2000 919.224s (  2.2 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 12.55% * 2000;
 Minibatch[   1- 100]: loss = 0.399301 * 100, metric = 5.67% * 100;
 Minibatch[ 101- 200]: loss = 0.406290 * 100, metric = 5.78% * 100;
 Minibatch[ 201- 300]: loss = 0.397985 * 100, metric = 5.47% * 100;
 Minibatch[ 301- 400]: loss = 0.397001 * 100, metric = 5.58% * 100;
 Minibatch[ 401- 500]: loss = 0.399007 * 100, metric = 5.71% * 100;
 Minibatch[ 501- 600]: loss = 0.406962 * 100, metric = 5.64% * 100;
 Minibatch[ 601- 700]: loss = 0.401548 * 100, metric = 5.74% * 100;
 Minibatch[ 701- 800]: loss = 0.404752 * 100, metric = 5.72% * 100;
 Minibatch[ 801- 900]: loss = 0.390444 * 100, metric = 5.41% * 100;
 Minibatch[ 901-1000]: loss = 0.393364 * 100, metric = 5.34% * 100;
 Minibatch[1001-1100]: loss = 0.404727 * 100, metric = 6.00% * 100;
 Minibatch[1101-1200]: loss = 0.406408 * 100, metric = 5.90% * 100;
 Minibatch[1201-1300]: loss = 0.401651 * 100, metric = 5.40% * 100;
 Minibatch[1301-1400]: loss = 0.425646 * 100, metric = 6.19% * 100;
 Minibatch[1401-1500]: loss = 0.411019 * 100, metric = 5.88% * 100;
 Minibatch[1501-1600]: loss = 0.403864 * 100, metric = 5.66% * 100;
 Minibatch[1601-1700]: loss = 0.403793 * 100, metric = 5.59% * 100;
 Minibatch[1701-1800]: loss = 0.410107 * 100, metric = 5.78% * 100;
 Minibatch[1801-1900]: loss = 0.406548 * 100, metric = 5.94% * 100;
 Minibatch[1901-2000]: loss = 0.396289 * 100, metric = 5.47% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.403335 * 2000, metric = 5.69% * 2000 911.839s (  2.2 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 12.72% * 2000;
 Minibatch[   1- 100]: loss = 0.403935 * 100, metric = 5.86% * 100;
 Minibatch[ 101- 200]: loss = 0.387320 * 100, metric = 5.47% * 100;
 Minibatch[ 201- 300]: loss = 0.401961 * 100, metric = 5.69% * 100;
 Minibatch[ 301- 400]: loss = 0.403563 * 100, metric = 5.74% * 100;
 Minibatch[ 401- 500]: loss = 0.405084 * 100, metric = 5.71% * 100;
 Minibatch[ 501- 600]: loss = 0.391825 * 100, metric = 5.61% * 100;
 Minibatch[ 601- 700]: loss = 0.411357 * 100, metric = 5.76% * 100;
 Minibatch[ 701- 800]: loss = 0.394409 * 100, metric = 5.51% * 100;
 Minibatch[ 801- 900]: loss = 0.403138 * 100, metric = 5.62% * 100;
 Minibatch[ 901-1000]: loss = 0.397478 * 100, metric = 5.54% * 100;
 Minibatch[1001-1100]: loss = 0.408354 * 100, metric = 5.85% * 100;
 Minibatch[1101-1200]: loss = 0.412842 * 100, metric = 5.79% * 100;
 Minibatch[1201-1300]: loss = 0.406013 * 100, metric = 5.70% * 100;
 Minibatch[1301-1400]: loss = 0.396188 * 100, metric = 5.51% * 100;
 Minibatch[1401-1500]: loss = 0.395452 * 100, metric = 5.62% * 100;
 Minibatch[1501-1600]: loss = 0.407358 * 100, metric = 5.82% * 100;
 Minibatch[1601-1700]: loss = 0.396498 * 100, metric = 5.59% * 100;
 Minibatch[1701-1800]: loss = 0.385428 * 100, metric = 5.26% * 100;
 Minibatch[1801-1900]: loss = 0.396582 * 100, metric = 5.63% * 100;
 Minibatch[1901-2000]: loss = 0.402750 * 100, metric = 5.75% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.400377 * 2000, metric = 5.65% * 2000 916.116s (  2.2 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 12.74% * 2000;
 Minibatch[   1- 100]: loss = 0.398338 * 100, metric = 5.76% * 100;
 Minibatch[ 101- 200]: loss = 0.386199 * 100, metric = 5.29% * 100;
 Minibatch[ 201- 300]: loss = 0.410269 * 100, metric = 5.61% * 100;
 Minibatch[ 301- 400]: loss = 0.407580 * 100, metric = 5.76% * 100;
 Minibatch[ 401- 500]: loss = 0.396866 * 100, metric = 5.59% * 100;
 Minibatch[ 501- 600]: loss = 0.397926 * 100, metric = 5.47% * 100;
 Minibatch[ 601- 700]: loss = 0.403264 * 100, metric = 5.79% * 100;
 Minibatch[ 701- 800]: loss = 0.397539 * 100, metric = 5.57% * 100;
 Minibatch[ 801- 900]: loss = 0.390718 * 100, metric = 5.54% * 100;
 Minibatch[ 901-1000]: loss = 0.409003 * 100, metric = 6.00% * 100;
 Minibatch[1001-1100]: loss = 0.404717 * 100, metric = 5.76% * 100;
 Minibatch[1101-1200]: loss = 0.410064 * 100, metric = 5.69% * 100;
 Minibatch[1201-1300]: loss = 0.404543 * 100, metric = 5.57% * 100;
 Minibatch[1301-1400]: loss = 0.381003 * 100, metric = 5.15% * 100;
 Minibatch[1401-1500]: loss = 0.401334 * 100, metric = 5.44% * 100;
 Minibatch[1501-1600]: loss = 0.407598 * 100, metric = 5.62% * 100;
 Minibatch[1601-1700]: loss = 0.402858 * 100, metric = 5.71% * 100;
 Minibatch[1701-1800]: loss = 0.395138 * 100, metric = 5.60% * 100;
 Minibatch[1801-1900]: loss = 0.401129 * 100, metric = 5.61% * 100;
 Minibatch[1901-2000]: loss = 0.394489 * 100, metric = 5.51% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.400029 * 2000, metric = 5.60% * 2000 916.216s (  2.2 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 13.49% * 2000;
 Minibatch[   1- 100]: loss = 0.388486 * 100, metric = 5.30% * 100;
 Minibatch[ 101- 200]: loss = 0.389580 * 100, metric = 5.59% * 100;
 Minibatch[ 201- 300]: loss = 0.399876 * 100, metric = 5.48% * 100;
 Minibatch[ 301- 400]: loss = 0.384566 * 100, metric = 5.32% * 100;
 Minibatch[ 401- 500]: loss = 0.385608 * 100, metric = 5.31% * 100;
 Minibatch[ 501- 600]: loss = 0.392956 * 100, metric = 5.43% * 100;
 Minibatch[ 601- 700]: loss = 0.395643 * 100, metric = 5.52% * 100;
 Minibatch[ 701- 800]: loss = 0.388160 * 100, metric = 5.42% * 100;
 Minibatch[ 801- 900]: loss = 0.381759 * 100, metric = 5.48% * 100;
 Minibatch[ 901-1000]: loss = 0.401926 * 100, metric = 5.71% * 100;
 Minibatch[1001-1100]: loss = 0.397836 * 100, metric = 5.73% * 100;
 Minibatch[1101-1200]: loss = 0.393562 * 100, metric = 5.42% * 100;
 Minibatch[1201-1300]: loss = 0.396217 * 100, metric = 5.66% * 100;
 Minibatch[1301-1400]: loss = 0.401455 * 100, metric = 5.76% * 100;
 Minibatch[1401-1500]: loss = 0.395266 * 100, metric = 5.46% * 100;
 Minibatch[1501-1600]: loss = 0.398960 * 100, metric = 5.32% * 100;
 Minibatch[1601-1700]: loss = 0.405467 * 100, metric = 5.70% * 100;
 Minibatch[1701-1800]: loss = 0.398798 * 100, metric = 5.60% * 100;
 Minibatch[1801-1900]: loss = 0.394034 * 100, metric = 5.52% * 100;
 Minibatch[1901-2000]: loss = 0.389695 * 100, metric = 5.37% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.393992 * 2000, metric = 5.51% * 2000 906.697s (  2.2 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 12.69% * 2000;
 Minibatch[   1- 100]: loss = 0.399179 * 100, metric = 5.79% * 100;
 Minibatch[ 101- 200]: loss = 0.390835 * 100, metric = 5.13% * 100;
 Minibatch[ 201- 300]: loss = 0.402838 * 100, metric = 5.62% * 100;
 Minibatch[ 301- 400]: loss = 0.395483 * 100, metric = 5.40% * 100;
 Minibatch[ 401- 500]: loss = 0.389327 * 100, metric = 5.34% * 100;
 Minibatch[ 501- 600]: loss = 0.379644 * 100, metric = 5.14% * 100;
 Minibatch[ 601- 700]: loss = 0.397078 * 100, metric = 5.50% * 100;
 Minibatch[ 701- 800]: loss = 0.379362 * 100, metric = 5.26% * 100;
 Minibatch[ 801- 900]: loss = 0.381226 * 100, metric = 5.23% * 100;
 Minibatch[ 901-1000]: loss = 0.395022 * 100, metric = 5.41% * 100;
 Minibatch[1001-1100]: loss = 0.392404 * 100, metric = 5.40% * 100;
 Minibatch[1101-1200]: loss = 0.388048 * 100, metric = 5.32% * 100;
 Minibatch[1201-1300]: loss = 0.397032 * 100, metric = 5.71% * 100;
 Minibatch[1301-1400]: loss = 0.393222 * 100, metric = 5.44% * 100;
 Minibatch[1401-1500]: loss = 0.380206 * 100, metric = 5.07% * 100;
 Minibatch[1501-1600]: loss = 0.400762 * 100, metric = 5.66% * 100;
 Minibatch[1601-1700]: loss = 0.387018 * 100, metric = 5.50% * 100;
 Minibatch[1701-1800]: loss = 0.393309 * 100, metric = 5.70% * 100;
 Minibatch[1801-1900]: loss = 0.392224 * 100, metric = 5.61% * 100;
 Minibatch[1901-2000]: loss = 0.390618 * 100, metric = 5.39% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.391242 * 2000, metric = 5.43% * 2000 914.832s (  2.2 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 12.79% * 2000;
 Minibatch[   1- 100]: loss = 0.381008 * 100, metric = 5.26% * 100;
 Minibatch[ 101- 200]: loss = 0.386640 * 100, metric = 5.40% * 100;
 Minibatch[ 201- 300]: loss = 0.390998 * 100, metric = 5.39% * 100;
 Minibatch[ 301- 400]: loss = 0.405972 * 100, metric = 5.56% * 100;
 Minibatch[ 401- 500]: loss = 0.389221 * 100, metric = 5.18% * 100;
 Minibatch[ 501- 600]: loss = 0.385552 * 100, metric = 5.30% * 100;
 Minibatch[ 601- 700]: loss = 0.400758 * 100, metric = 5.75% * 100;
 Minibatch[ 701- 800]: loss = 0.370748 * 100, metric = 5.04% * 100;
 Minibatch[ 801- 900]: loss = 0.379089 * 100, metric = 5.14% * 100;
 Minibatch[ 901-1000]: loss = 0.386400 * 100, metric = 5.19% * 100;
 Minibatch[1001-1100]: loss = 0.381579 * 100, metric = 5.21% * 100;
 Minibatch[1101-1200]: loss = 0.381315 * 100, metric = 5.08% * 100;
 Minibatch[1201-1300]: loss = 0.381428 * 100, metric = 5.04% * 100;
 Minibatch[1301-1400]: loss = 0.382859 * 100, metric = 5.27% * 100;
 Minibatch[1401-1500]: loss = 0.378765 * 100, metric = 5.03% * 100;
 Minibatch[1501-1600]: loss = 0.375658 * 100, metric = 5.19% * 100;
 Minibatch[1601-1700]: loss = 0.383609 * 100, metric = 5.17% * 100;
 Minibatch[1701-1800]: loss = 0.397148 * 100, metric = 5.71% * 100;
 Minibatch[1801-1900]: loss = 0.390279 * 100, metric = 5.12% * 100;
 Minibatch[1901-2000]: loss = 0.369163 * 100, metric = 5.00% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.384909 * 2000, metric = 5.25% * 2000 912.625s (  2.2 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 13.17% * 2000;
 Minibatch[   1- 100]: loss = 0.389601 * 100, metric = 5.29% * 100;
 Minibatch[ 101- 200]: loss = 0.382639 * 100, metric = 5.00% * 100;
 Minibatch[ 201- 300]: loss = 0.374822 * 100, metric = 5.08% * 100;
 Minibatch[ 301- 400]: loss = 0.396885 * 100, metric = 5.53% * 100;
 Minibatch[ 401- 500]: loss = 0.384010 * 100, metric = 5.21% * 100;
 Minibatch[ 501- 600]: loss = 0.375335 * 100, metric = 4.87% * 100;
 Minibatch[ 601- 700]: loss = 0.369903 * 100, metric = 5.02% * 100;
 Minibatch[ 701- 800]: loss = 0.372146 * 100, metric = 5.18% * 100;
 Minibatch[ 801- 900]: loss = 0.404524 * 100, metric = 5.69% * 100;
 Minibatch[ 901-1000]: loss = 0.378147 * 100, metric = 5.20% * 100;
 Minibatch[1001-1100]: loss = 0.374234 * 100, metric = 5.10% * 100;
 Minibatch[1101-1200]: loss = 0.395624 * 100, metric = 5.38% * 100;
 Minibatch[1201-1300]: loss = 0.390267 * 100, metric = 5.33% * 100;
 Minibatch[1301-1400]: loss = 0.385797 * 100, metric = 5.18% * 100;
 Minibatch[1401-1500]: loss = 0.397976 * 100, metric = 5.32% * 100;
 Minibatch[1501-1600]: loss = 0.384647 * 100, metric = 5.27% * 100;
 Minibatch[1601-1700]: loss = 0.386286 * 100, metric = 5.46% * 100;
 Minibatch[1701-1800]: loss = 0.386304 * 100, metric = 5.36% * 100;
 Minibatch[1801-1900]: loss = 0.392161 * 100, metric = 5.61% * 100;
 Minibatch[1901-2000]: loss = 0.380036 * 100, metric = 4.91% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.385067 * 2000, metric = 5.25% * 2000 910.832s (  2.2 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 12.76% * 2000;
 Minibatch[   1- 100]: loss = 0.374418 * 100, metric = 5.19% * 100;
 Minibatch[ 101- 200]: loss = 0.398757 * 100, metric = 5.40% * 100;
 Minibatch[ 201- 300]: loss = 0.385767 * 100, metric = 5.20% * 100;
 Minibatch[ 301- 400]: loss = 0.399081 * 100, metric = 5.51% * 100;
 Minibatch[ 401- 500]: loss = 0.378372 * 100, metric = 5.00% * 100;
 Minibatch[ 501- 600]: loss = 0.377586 * 100, metric = 5.08% * 100;
 Minibatch[ 601- 700]: loss = 0.363263 * 100, metric = 4.73% * 100;
 Minibatch[ 701- 800]: loss = 0.364907 * 100, metric = 5.00% * 100;
 Minibatch[ 801- 900]: loss = 0.374086 * 100, metric = 5.02% * 100;
 Minibatch[ 901-1000]: loss = 0.376060 * 100, metric = 5.01% * 100;
 Minibatch[1001-1100]: loss = 0.375180 * 100, metric = 5.06% * 100;
 Minibatch[1101-1200]: loss = 0.383780 * 100, metric = 5.29% * 100;
 Minibatch[1201-1300]: loss = 0.393842 * 100, metric = 5.34% * 100;
 Minibatch[1301-1400]: loss = 0.390771 * 100, metric = 5.41% * 100;
 Minibatch[1401-1500]: loss = 0.372043 * 100, metric = 5.01% * 100;
 Minibatch[1501-1600]: loss = 0.384338 * 100, metric = 5.05% * 100;
 Minibatch[1601-1700]: loss = 0.369322 * 100, metric = 4.98% * 100;
 Minibatch[1701-1800]: loss = 0.384744 * 100, metric = 5.40% * 100;
 Minibatch[1801-1900]: loss = 0.369213 * 100, metric = 4.83% * 100;
 Minibatch[1901-2000]: loss = 0.370039 * 100, metric = 4.85% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.379278 * 2000, metric = 5.12% * 2000 903.560s (  2.2 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 12.65% * 2000;
 Minibatch[   1- 100]: loss = 0.375670 * 100, metric = 5.01% * 100;
 Minibatch[ 101- 200]: loss = 0.367470 * 100, metric = 4.93% * 100;
 Minibatch[ 201- 300]: loss = 0.374921 * 100, metric = 5.08% * 100;
 Minibatch[ 301- 400]: loss = 0.372227 * 100, metric = 4.93% * 100;
 Minibatch[ 401- 500]: loss = 0.366439 * 100, metric = 5.12% * 100;
 Minibatch[ 501- 600]: loss = 0.367143 * 100, metric = 5.12% * 100;
 Minibatch[ 601- 700]: loss = 0.386018 * 100, metric = 5.28% * 100;
 Minibatch[ 701- 800]: loss = 0.388317 * 100, metric = 5.41% * 100;
 Minibatch[ 801- 900]: loss = 0.376993 * 100, metric = 5.02% * 100;
 Minibatch[ 901-1000]: loss = 0.373762 * 100, metric = 5.08% * 100;
 Minibatch[1001-1100]: loss = 0.384206 * 100, metric = 5.32% * 100;
 Minibatch[1101-1200]: loss = 0.374775 * 100, metric = 5.07% * 100;
 Minibatch[1201-1300]: loss = 0.361119 * 100, metric = 4.89% * 100;
 Minibatch[1301-1400]: loss = 0.367911 * 100, metric = 5.07% * 100;
 Minibatch[1401-1500]: loss = 0.385367 * 100, metric = 5.42% * 100;
 Minibatch[1501-1600]: loss = 0.384868 * 100, metric = 5.20% * 100;
 Minibatch[1601-1700]: loss = 0.384677 * 100, metric = 5.26% * 100;
 Minibatch[1701-1800]: loss = 0.392328 * 100, metric = 5.48% * 100;
 Minibatch[1801-1900]: loss = 0.382623 * 100, metric = 5.53% * 100;
 Minibatch[1901-2000]: loss = 0.397766 * 100, metric = 5.53% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.378230 * 2000, metric = 5.19% * 2000 903.399s (  2.2 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 12.24% * 2000;
 Minibatch[   1- 100]: loss = 0.381374 * 100, metric = 5.13% * 100;
 Minibatch[ 101- 200]: loss = 0.382695 * 100, metric = 5.07% * 100;
 Minibatch[ 201- 300]: loss = 0.380158 * 100, metric = 5.45% * 100;
 Minibatch[ 301- 400]: loss = 0.372141 * 100, metric = 5.10% * 100;
 Minibatch[ 401- 500]: loss = 0.385223 * 100, metric = 5.41% * 100;
 Minibatch[ 501- 600]: loss = 0.395655 * 100, metric = 5.64% * 100;
 Minibatch[ 601- 700]: loss = 0.404404 * 100, metric = 5.58% * 100;
 Minibatch[ 701- 800]: loss = 0.377394 * 100, metric = 5.15% * 100;
 Minibatch[ 801- 900]: loss = 0.372562 * 100, metric = 4.93% * 100;
 Minibatch[ 901-1000]: loss = 0.386905 * 100, metric = 5.54% * 100;
 Minibatch[1001-1100]: loss = 0.384962 * 100, metric = 5.36% * 100;
 Minibatch[1101-1200]: loss = 0.376157 * 100, metric = 5.04% * 100;
 Minibatch[1201-1300]: loss = 0.370658 * 100, metric = 5.06% * 100;
 Minibatch[1301-1400]: loss = 0.371875 * 100, metric = 5.24% * 100;
 Minibatch[1401-1500]: loss = 0.373431 * 100, metric = 5.17% * 100;
 Minibatch[1501-1600]: loss = 0.380909 * 100, metric = 5.23% * 100;
 Minibatch[1601-1700]: loss = 0.370894 * 100, metric = 5.17% * 100;
 Minibatch[1701-1800]: loss = 0.375774 * 100, metric = 4.98% * 100;
 Minibatch[1801-1900]: loss = 0.380341 * 100, metric = 5.07% * 100;
 Minibatch[1901-2000]: loss = 0.361224 * 100, metric = 4.96% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.379237 * 2000, metric = 5.21% * 2000 908.611s (  2.2 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 12.53% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
