Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.015633 * 100, metric = 24.84% * 100;
 Minibatch[ 101- 200]: loss = 0.862409 * 100, metric = 23.98% * 100;
 Minibatch[ 201- 300]: loss = 0.745195 * 100, metric = 22.51% * 100;
 Minibatch[ 301- 400]: loss = 0.695369 * 100, metric = 20.88% * 100;
 Minibatch[ 401- 500]: loss = 0.624543 * 100, metric = 19.20% * 100;
 Minibatch[ 501- 600]: loss = 0.613447 * 100, metric = 18.53% * 100;
 Minibatch[ 601- 700]: loss = 0.577130 * 100, metric = 17.72% * 100;
 Minibatch[ 701- 800]: loss = 0.545976 * 100, metric = 16.97% * 100;
 Minibatch[ 801- 900]: loss = 0.557439 * 100, metric = 17.32% * 100;
 Minibatch[ 901-1000]: loss = 0.557260 * 100, metric = 17.28% * 100;
 Minibatch[1001-1100]: loss = 0.550485 * 100, metric = 17.09% * 100;
 Minibatch[1101-1200]: loss = 0.530504 * 100, metric = 16.42% * 100;
 Minibatch[1201-1300]: loss = 0.538954 * 100, metric = 17.18% * 100;
 Minibatch[1301-1400]: loss = 0.508527 * 100, metric = 16.02% * 100;
 Minibatch[1401-1500]: loss = 0.521700 * 100, metric = 16.13% * 100;
 Minibatch[1501-1600]: loss = 0.507922 * 100, metric = 16.05% * 100;
 Minibatch[1601-1700]: loss = 0.500057 * 100, metric = 15.75% * 100;
 Minibatch[1701-1800]: loss = 0.504382 * 100, metric = 15.93% * 100;
 Minibatch[1801-1900]: loss = 0.506881 * 100, metric = 15.96% * 100;
 Minibatch[1901-2000]: loss = 0.483923 * 100, metric = 15.17% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.597387 * 2000, metric = 18.05% * 2000 1110.363s (  1.8 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 25.79% * 2000;
0.616199040569365
 Minibatch[   1- 100]: loss = 0.491091 * 100, metric = 15.23% * 100;
 Minibatch[ 101- 200]: loss = 0.492122 * 100, metric = 15.48% * 100;
 Minibatch[ 201- 300]: loss = 0.492180 * 100, metric = 14.58% * 100;
 Minibatch[ 301- 400]: loss = 0.486904 * 100, metric = 15.00% * 100;
 Minibatch[ 401- 500]: loss = 0.477452 * 100, metric = 15.05% * 100;
 Minibatch[ 501- 600]: loss = 0.490749 * 100, metric = 14.67% * 100;
 Minibatch[ 601- 700]: loss = 0.453228 * 100, metric = 14.04% * 100;
 Minibatch[ 701- 800]: loss = 0.474629 * 100, metric = 15.17% * 100;
 Minibatch[ 801- 900]: loss = 0.446972 * 100, metric = 14.18% * 100;
 Minibatch[ 901-1000]: loss = 0.440579 * 100, metric = 13.67% * 100;
 Minibatch[1001-1100]: loss = 0.452231 * 100, metric = 14.27% * 100;
 Minibatch[1101-1200]: loss = 0.463030 * 100, metric = 14.48% * 100;
 Minibatch[1201-1300]: loss = 0.448104 * 100, metric = 14.10% * 100;
 Minibatch[1301-1400]: loss = 0.462277 * 100, metric = 14.43% * 100;
 Minibatch[1401-1500]: loss = 0.443164 * 100, metric = 13.61% * 100;
 Minibatch[1501-1600]: loss = 0.435174 * 100, metric = 13.69% * 100;
 Minibatch[1601-1700]: loss = 0.451279 * 100, metric = 13.84% * 100;
 Minibatch[1701-1800]: loss = 0.444520 * 100, metric = 13.92% * 100;
 Minibatch[1801-1900]: loss = 0.437504 * 100, metric = 13.73% * 100;
 Minibatch[1901-2000]: loss = 0.420828 * 100, metric = 13.15% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.460201 * 2000, metric = 14.31% * 2000 1051.492s (  1.9 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 22.41% * 2000;
0.5530241803005338
 Minibatch[   1- 100]: loss = 0.433562 * 100, metric = 13.76% * 100;
 Minibatch[ 101- 200]: loss = 0.442055 * 100, metric = 13.73% * 100;
 Minibatch[ 201- 300]: loss = 0.426664 * 100, metric = 13.40% * 100;
 Minibatch[ 301- 400]: loss = 0.441691 * 100, metric = 14.05% * 100;
 Minibatch[ 401- 500]: loss = 0.447292 * 100, metric = 14.19% * 100;
 Minibatch[ 501- 600]: loss = 0.441364 * 100, metric = 13.91% * 100;
 Minibatch[ 601- 700]: loss = 0.439131 * 100, metric = 13.67% * 100;
 Minibatch[ 701- 800]: loss = 0.418734 * 100, metric = 13.15% * 100;
 Minibatch[ 801- 900]: loss = 0.438121 * 100, metric = 14.04% * 100;
 Minibatch[ 901-1000]: loss = 0.417282 * 100, metric = 13.33% * 100;
 Minibatch[1001-1100]: loss = 0.429990 * 100, metric = 13.92% * 100;
 Minibatch[1101-1200]: loss = 0.412594 * 100, metric = 13.07% * 100;
 Minibatch[1201-1300]: loss = 0.413597 * 100, metric = 13.00% * 100;
 Minibatch[1301-1400]: loss = 0.424702 * 100, metric = 13.53% * 100;
 Minibatch[1401-1500]: loss = 0.425647 * 100, metric = 13.51% * 100;
 Minibatch[1501-1600]: loss = 0.410328 * 100, metric = 12.87% * 100;
 Minibatch[1601-1700]: loss = 0.404575 * 100, metric = 12.41% * 100;
 Minibatch[1701-1800]: loss = 0.419528 * 100, metric = 13.09% * 100;
 Minibatch[1801-1900]: loss = 0.415862 * 100, metric = 13.01% * 100;
 Minibatch[1901-2000]: loss = 0.415210 * 100, metric = 13.09% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.425896 * 2000, metric = 13.44% * 2000 1016.826s (  2.0 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 21.56% * 2000;
0.5355344827845693
 Minibatch[   1- 100]: loss = 0.427493 * 100, metric = 13.08% * 100;
 Minibatch[ 101- 200]: loss = 0.401961 * 100, metric = 12.57% * 100;
 Minibatch[ 201- 300]: loss = 0.414097 * 100, metric = 13.19% * 100;
 Minibatch[ 301- 400]: loss = 0.388090 * 100, metric = 12.20% * 100;
 Minibatch[ 401- 500]: loss = 0.418055 * 100, metric = 12.93% * 100;
 Minibatch[ 501- 600]: loss = 0.399654 * 100, metric = 12.52% * 100;
 Minibatch[ 601- 700]: loss = 0.402370 * 100, metric = 12.86% * 100;
 Minibatch[ 701- 800]: loss = 0.405576 * 100, metric = 12.78% * 100;
 Minibatch[ 801- 900]: loss = 0.404591 * 100, metric = 12.79% * 100;
 Minibatch[ 901-1000]: loss = 0.406801 * 100, metric = 13.01% * 100;
 Minibatch[1001-1100]: loss = 0.415746 * 100, metric = 13.18% * 100;
 Minibatch[1101-1200]: loss = 0.390029 * 100, metric = 12.20% * 100;
 Minibatch[1201-1300]: loss = 0.389939 * 100, metric = 12.22% * 100;
 Minibatch[1301-1400]: loss = 0.408765 * 100, metric = 13.26% * 100;
 Minibatch[1401-1500]: loss = 0.404639 * 100, metric = 12.87% * 100;
 Minibatch[1501-1600]: loss = 0.381826 * 100, metric = 11.98% * 100;
 Minibatch[1601-1700]: loss = 0.397166 * 100, metric = 12.69% * 100;
 Minibatch[1701-1800]: loss = 0.406041 * 100, metric = 12.95% * 100;
 Minibatch[1801-1900]: loss = 0.394731 * 100, metric = 12.41% * 100;
 Minibatch[1901-2000]: loss = 0.383715 * 100, metric = 12.05% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.402064 * 2000, metric = 12.69% * 2000 924.804s (  2.2 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 22.27% * 2000;
 Minibatch[   1- 100]: loss = 0.404432 * 100, metric = 12.85% * 100;
 Minibatch[ 101- 200]: loss = 0.391203 * 100, metric = 12.50% * 100;
 Minibatch[ 201- 300]: loss = 0.379952 * 100, metric = 11.93% * 100;
 Minibatch[ 301- 400]: loss = 0.410788 * 100, metric = 13.16% * 100;
 Minibatch[ 401- 500]: loss = 0.372140 * 100, metric = 11.43% * 100;
 Minibatch[ 501- 600]: loss = 0.377487 * 100, metric = 11.71% * 100;
 Minibatch[ 601- 700]: loss = 0.383372 * 100, metric = 11.80% * 100;
 Minibatch[ 701- 800]: loss = 0.392911 * 100, metric = 12.46% * 100;
 Minibatch[ 801- 900]: loss = 0.379591 * 100, metric = 11.85% * 100;
 Minibatch[ 901-1000]: loss = 0.384891 * 100, metric = 12.25% * 100;
 Minibatch[1001-1100]: loss = 0.393986 * 100, metric = 12.29% * 100;
 Minibatch[1101-1200]: loss = 0.379840 * 100, metric = 11.99% * 100;
 Minibatch[1201-1300]: loss = 0.387982 * 100, metric = 12.15% * 100;
 Minibatch[1301-1400]: loss = 0.401288 * 100, metric = 12.70% * 100;
 Minibatch[1401-1500]: loss = 0.385925 * 100, metric = 12.22% * 100;
 Minibatch[1501-1600]: loss = 0.381929 * 100, metric = 12.03% * 100;
 Minibatch[1601-1700]: loss = 0.388495 * 100, metric = 12.33% * 100;
 Minibatch[1701-1800]: loss = 0.393415 * 100, metric = 12.32% * 100;
 Minibatch[1801-1900]: loss = 0.384420 * 100, metric = 12.15% * 100;
 Minibatch[1901-2000]: loss = 0.373444 * 100, metric = 11.52% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.387375 * 2000, metric = 12.18% * 2000 915.049s (  2.2 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.44% * 2000;
0.5118632750958204
 Minibatch[   1- 100]: loss = 0.368725 * 100, metric = 11.62% * 100;
 Minibatch[ 101- 200]: loss = 0.362210 * 100, metric = 11.60% * 100;
 Minibatch[ 201- 300]: loss = 0.375627 * 100, metric = 11.53% * 100;
 Minibatch[ 301- 400]: loss = 0.375807 * 100, metric = 11.61% * 100;
 Minibatch[ 401- 500]: loss = 0.357487 * 100, metric = 11.16% * 100;
 Minibatch[ 501- 600]: loss = 0.367356 * 100, metric = 11.60% * 100;
 Minibatch[ 601- 700]: loss = 0.368153 * 100, metric = 11.73% * 100;
 Minibatch[ 701- 800]: loss = 0.370404 * 100, metric = 11.68% * 100;
 Minibatch[ 801- 900]: loss = 0.371673 * 100, metric = 11.77% * 100;
 Minibatch[ 901-1000]: loss = 0.365461 * 100, metric = 11.42% * 100;
 Minibatch[1001-1100]: loss = 0.371165 * 100, metric = 11.34% * 100;
 Minibatch[1101-1200]: loss = 0.379103 * 100, metric = 11.93% * 100;
 Minibatch[1201-1300]: loss = 0.386334 * 100, metric = 12.23% * 100;
 Minibatch[1301-1400]: loss = 0.362725 * 100, metric = 11.31% * 100;
 Minibatch[1401-1500]: loss = 0.368113 * 100, metric = 11.85% * 100;
 Minibatch[1501-1600]: loss = 0.357108 * 100, metric = 11.18% * 100;
 Minibatch[1601-1700]: loss = 0.362209 * 100, metric = 11.34% * 100;
 Minibatch[1701-1800]: loss = 0.356578 * 100, metric = 11.07% * 100;
 Minibatch[1801-1900]: loss = 0.372881 * 100, metric = 11.97% * 100;
 Minibatch[1901-2000]: loss = 0.354708 * 100, metric = 11.36% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.367691 * 2000, metric = 11.57% * 2000 909.859s (  2.2 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 21.43% * 2000;
 Minibatch[   1- 100]: loss = 0.357728 * 100, metric = 11.27% * 100;
 Minibatch[ 101- 200]: loss = 0.363818 * 100, metric = 11.21% * 100;
 Minibatch[ 201- 300]: loss = 0.367283 * 100, metric = 11.47% * 100;
 Minibatch[ 301- 400]: loss = 0.348184 * 100, metric = 10.76% * 100;
 Minibatch[ 401- 500]: loss = 0.371045 * 100, metric = 11.47% * 100;
 Minibatch[ 501- 600]: loss = 0.342841 * 100, metric = 10.74% * 100;
 Minibatch[ 601- 700]: loss = 0.354299 * 100, metric = 10.92% * 100;
 Minibatch[ 701- 800]: loss = 0.358697 * 100, metric = 10.95% * 100;
 Minibatch[ 801- 900]: loss = 0.362721 * 100, metric = 11.49% * 100;
 Minibatch[ 901-1000]: loss = 0.360706 * 100, metric = 11.26% * 100;
 Minibatch[1001-1100]: loss = 0.365204 * 100, metric = 11.43% * 100;
 Minibatch[1101-1200]: loss = 0.346561 * 100, metric = 10.83% * 100;
 Minibatch[1201-1300]: loss = 0.360141 * 100, metric = 11.53% * 100;
 Minibatch[1301-1400]: loss = 0.349589 * 100, metric = 10.95% * 100;
 Minibatch[1401-1500]: loss = 0.350920 * 100, metric = 10.99% * 100;
 Minibatch[1501-1600]: loss = 0.358434 * 100, metric = 11.27% * 100;
 Minibatch[1601-1700]: loss = 0.361883 * 100, metric = 11.53% * 100;
 Minibatch[1701-1800]: loss = 0.358736 * 100, metric = 11.15% * 100;
 Minibatch[1801-1900]: loss = 0.359872 * 100, metric = 11.25% * 100;
 Minibatch[1901-2000]: loss = 0.360907 * 100, metric = 11.38% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.357979 * 2000, metric = 11.19% * 2000 911.281s (  2.2 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.54% * 2000;
0.4784208514094353
 Minibatch[   1- 100]: loss = 0.363560 * 100, metric = 11.54% * 100;
 Minibatch[ 101- 200]: loss = 0.356895 * 100, metric = 11.31% * 100;
 Minibatch[ 201- 300]: loss = 0.347012 * 100, metric = 11.07% * 100;
 Minibatch[ 301- 400]: loss = 0.345615 * 100, metric = 10.83% * 100;
 Minibatch[ 401- 500]: loss = 0.353326 * 100, metric = 11.26% * 100;
 Minibatch[ 501- 600]: loss = 0.365136 * 100, metric = 11.77% * 100;
 Minibatch[ 601- 700]: loss = 0.339283 * 100, metric = 10.80% * 100;
 Minibatch[ 701- 800]: loss = 0.353488 * 100, metric = 10.80% * 100;
 Minibatch[ 801- 900]: loss = 0.330388 * 100, metric = 10.05% * 100;
 Minibatch[ 901-1000]: loss = 0.322585 * 100, metric = 10.04% * 100;
 Minibatch[1001-1100]: loss = 0.333488 * 100, metric = 10.43% * 100;
 Minibatch[1101-1200]: loss = 0.334342 * 100, metric = 10.53% * 100;
 Minibatch[1201-1300]: loss = 0.347775 * 100, metric = 11.01% * 100;
 Minibatch[1301-1400]: loss = 0.352129 * 100, metric = 11.18% * 100;
 Minibatch[1401-1500]: loss = 0.340276 * 100, metric = 10.65% * 100;
 Minibatch[1501-1600]: loss = 0.341766 * 100, metric = 10.69% * 100;
 Minibatch[1601-1700]: loss = 0.342652 * 100, metric = 10.66% * 100;
 Minibatch[1701-1800]: loss = 0.339856 * 100, metric = 10.34% * 100;
 Minibatch[1801-1900]: loss = 0.345401 * 100, metric = 10.79% * 100;
 Minibatch[1901-2000]: loss = 0.332047 * 100, metric = 10.47% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.344351 * 2000, metric = 10.81% * 2000 908.550s (  2.2 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 17.78% * 2000;
0.4579152281433344
 Minibatch[   1- 100]: loss = 0.317973 * 100, metric = 9.90% * 100;
 Minibatch[ 101- 200]: loss = 0.346745 * 100, metric = 10.96% * 100;
 Minibatch[ 201- 300]: loss = 0.333985 * 100, metric = 10.49% * 100;
 Minibatch[ 301- 400]: loss = 0.349078 * 100, metric = 10.93% * 100;
 Minibatch[ 401- 500]: loss = 0.332197 * 100, metric = 10.21% * 100;
 Minibatch[ 501- 600]: loss = 0.324527 * 100, metric = 9.98% * 100;
 Minibatch[ 601- 700]: loss = 0.330868 * 100, metric = 10.37% * 100;
 Minibatch[ 701- 800]: loss = 0.313417 * 100, metric = 9.75% * 100;
 Minibatch[ 801- 900]: loss = 0.320395 * 100, metric = 10.09% * 100;
 Minibatch[ 901-1000]: loss = 0.337047 * 100, metric = 10.86% * 100;
 Minibatch[1001-1100]: loss = 0.305753 * 100, metric = 9.34% * 100;
 Minibatch[1101-1200]: loss = 0.328304 * 100, metric = 10.17% * 100;
 Minibatch[1201-1300]: loss = 0.318080 * 100, metric = 9.82% * 100;
 Minibatch[1301-1400]: loss = 0.323556 * 100, metric = 9.93% * 100;
 Minibatch[1401-1500]: loss = 0.337933 * 100, metric = 10.39% * 100;
 Minibatch[1501-1600]: loss = 0.327333 * 100, metric = 10.05% * 100;
 Minibatch[1601-1700]: loss = 0.334418 * 100, metric = 10.31% * 100;
 Minibatch[1701-1800]: loss = 0.313961 * 100, metric = 9.46% * 100;
 Minibatch[1801-1900]: loss = 0.319140 * 100, metric = 9.89% * 100;
 Minibatch[1901-2000]: loss = 0.329478 * 100, metric = 10.38% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.327209 * 2000, metric = 10.16% * 2000 907.705s (  2.2 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 17.44% * 2000;
0.44923194726929067
 Minibatch[   1- 100]: loss = 0.343117 * 100, metric = 10.91% * 100;
 Minibatch[ 101- 200]: loss = 0.321020 * 100, metric = 9.96% * 100;
 Minibatch[ 201- 300]: loss = 0.333990 * 100, metric = 10.34% * 100;
 Minibatch[ 301- 400]: loss = 0.324655 * 100, metric = 10.13% * 100;
 Minibatch[ 401- 500]: loss = 0.335362 * 100, metric = 10.44% * 100;
 Minibatch[ 501- 600]: loss = 0.317129 * 100, metric = 9.81% * 100;
 Minibatch[ 601- 700]: loss = 0.311781 * 100, metric = 9.56% * 100;
 Minibatch[ 701- 800]: loss = 0.306232 * 100, metric = 9.21% * 100;
 Minibatch[ 801- 900]: loss = 0.322989 * 100, metric = 9.99% * 100;
 Minibatch[ 901-1000]: loss = 0.330884 * 100, metric = 10.22% * 100;
 Minibatch[1001-1100]: loss = 0.329450 * 100, metric = 10.16% * 100;
 Minibatch[1101-1200]: loss = 0.326648 * 100, metric = 10.11% * 100;
 Minibatch[1201-1300]: loss = 0.328475 * 100, metric = 10.24% * 100;
 Minibatch[1301-1400]: loss = 0.323322 * 100, metric = 9.94% * 100;
 Minibatch[1401-1500]: loss = 0.308181 * 100, metric = 9.48% * 100;
 Minibatch[1501-1600]: loss = 0.320560 * 100, metric = 10.26% * 100;
 Minibatch[1601-1700]: loss = 0.315771 * 100, metric = 9.61% * 100;
 Minibatch[1701-1800]: loss = 0.333333 * 100, metric = 10.25% * 100;
 Minibatch[1801-1900]: loss = 0.324453 * 100, metric = 10.25% * 100;
 Minibatch[1901-2000]: loss = 0.319378 * 100, metric = 9.87% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.323836 * 2000, metric = 10.04% * 2000 904.138s (  2.2 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 15.95% * 2000;
0.4253729929625988
 Minibatch[   1- 100]: loss = 0.303977 * 100, metric = 9.27% * 100;
 Minibatch[ 101- 200]: loss = 0.318357 * 100, metric = 9.90% * 100;
 Minibatch[ 201- 300]: loss = 0.330098 * 100, metric = 10.29% * 100;
 Minibatch[ 301- 400]: loss = 0.315029 * 100, metric = 9.67% * 100;
 Minibatch[ 401- 500]: loss = 0.309762 * 100, metric = 9.59% * 100;
 Minibatch[ 501- 600]: loss = 0.322305 * 100, metric = 9.94% * 100;
 Minibatch[ 601- 700]: loss = 0.311436 * 100, metric = 9.36% * 100;
 Minibatch[ 701- 800]: loss = 0.321278 * 100, metric = 9.98% * 100;
 Minibatch[ 801- 900]: loss = 0.313807 * 100, metric = 9.45% * 100;
 Minibatch[ 901-1000]: loss = 0.325980 * 100, metric = 10.10% * 100;
 Minibatch[1001-1100]: loss = 0.315557 * 100, metric = 9.57% * 100;
 Minibatch[1101-1200]: loss = 0.318712 * 100, metric = 9.70% * 100;
 Minibatch[1201-1300]: loss = 0.308416 * 100, metric = 9.63% * 100;
 Minibatch[1301-1400]: loss = 0.301021 * 100, metric = 9.40% * 100;
 Minibatch[1401-1500]: loss = 0.320081 * 100, metric = 9.97% * 100;
 Minibatch[1501-1600]: loss = 0.304366 * 100, metric = 9.26% * 100;
 Minibatch[1601-1700]: loss = 0.306999 * 100, metric = 9.53% * 100;
 Minibatch[1701-1800]: loss = 0.324606 * 100, metric = 9.98% * 100;
 Minibatch[1801-1900]: loss = 0.313233 * 100, metric = 9.54% * 100;
 Minibatch[1901-2000]: loss = 0.314670 * 100, metric = 9.72% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.314984 * 2000, metric = 9.69% * 2000 896.870s (  2.2 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 16.60% * 2000;
 Minibatch[   1- 100]: loss = 0.297432 * 100, metric = 8.94% * 100;
 Minibatch[ 101- 200]: loss = 0.295548 * 100, metric = 8.94% * 100;
 Minibatch[ 201- 300]: loss = 0.308851 * 100, metric = 9.57% * 100;
 Minibatch[ 301- 400]: loss = 0.327467 * 100, metric = 10.32% * 100;
 Minibatch[ 401- 500]: loss = 0.300932 * 100, metric = 9.10% * 100;
 Minibatch[ 501- 600]: loss = 0.287778 * 100, metric = 8.73% * 100;
 Minibatch[ 601- 700]: loss = 0.293319 * 100, metric = 9.03% * 100;
 Minibatch[ 701- 800]: loss = 0.302561 * 100, metric = 9.43% * 100;
 Minibatch[ 801- 900]: loss = 0.293554 * 100, metric = 8.82% * 100;
 Minibatch[ 901-1000]: loss = 0.309172 * 100, metric = 9.65% * 100;
 Minibatch[1001-1100]: loss = 0.305061 * 100, metric = 9.59% * 100;
 Minibatch[1101-1200]: loss = 0.309818 * 100, metric = 9.37% * 100;
 Minibatch[1201-1300]: loss = 0.314093 * 100, metric = 9.97% * 100;
 Minibatch[1301-1400]: loss = 0.302444 * 100, metric = 9.34% * 100;
 Minibatch[1401-1500]: loss = 0.313081 * 100, metric = 9.77% * 100;
 Minibatch[1501-1600]: loss = 0.284952 * 100, metric = 8.74% * 100;
 Minibatch[1601-1700]: loss = 0.307108 * 100, metric = 9.68% * 100;
 Minibatch[1701-1800]: loss = 0.293499 * 100, metric = 8.91% * 100;
 Minibatch[1801-1900]: loss = 0.297647 * 100, metric = 9.24% * 100;
 Minibatch[1901-2000]: loss = 0.312141 * 100, metric = 9.60% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.302823 * 2000, metric = 9.34% * 2000 890.671s (  2.2 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 17.50% * 2000;
 Minibatch[   1- 100]: loss = 0.305129 * 100, metric = 9.53% * 100;
 Minibatch[ 101- 200]: loss = 0.302002 * 100, metric = 9.60% * 100;
 Minibatch[ 201- 300]: loss = 0.300915 * 100, metric = 9.29% * 100;
 Minibatch[ 301- 400]: loss = 0.309671 * 100, metric = 9.75% * 100;
 Minibatch[ 401- 500]: loss = 0.314630 * 100, metric = 9.91% * 100;
 Minibatch[ 501- 600]: loss = 0.315608 * 100, metric = 10.04% * 100;
 Minibatch[ 601- 700]: loss = 0.301116 * 100, metric = 9.24% * 100;
 Minibatch[ 701- 800]: loss = 0.293064 * 100, metric = 9.02% * 100;
 Minibatch[ 801- 900]: loss = 0.298681 * 100, metric = 9.40% * 100;
 Minibatch[ 901-1000]: loss = 0.309225 * 100, metric = 9.65% * 100;
 Minibatch[1001-1100]: loss = 0.307529 * 100, metric = 9.60% * 100;
 Minibatch[1101-1200]: loss = 0.295987 * 100, metric = 9.05% * 100;
 Minibatch[1201-1300]: loss = 0.304340 * 100, metric = 9.50% * 100;
 Minibatch[1301-1400]: loss = 0.297953 * 100, metric = 9.22% * 100;
 Minibatch[1401-1500]: loss = 0.295464 * 100, metric = 9.16% * 100;
 Minibatch[1501-1600]: loss = 0.289508 * 100, metric = 8.95% * 100;
 Minibatch[1601-1700]: loss = 0.289070 * 100, metric = 8.91% * 100;
 Minibatch[1701-1800]: loss = 0.299785 * 100, metric = 9.03% * 100;
 Minibatch[1801-1900]: loss = 0.287894 * 100, metric = 9.02% * 100;
 Minibatch[1901-2000]: loss = 0.300853 * 100, metric = 9.46% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.300921 * 2000, metric = 9.37% * 2000 889.509s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 17.60% * 2000;
 Minibatch[   1- 100]: loss = 0.292634 * 100, metric = 9.12% * 100;
 Minibatch[ 101- 200]: loss = 0.283044 * 100, metric = 8.82% * 100;
 Minibatch[ 201- 300]: loss = 0.300999 * 100, metric = 9.27% * 100;
 Minibatch[ 301- 400]: loss = 0.294816 * 100, metric = 9.29% * 100;
 Minibatch[ 401- 500]: loss = 0.289798 * 100, metric = 8.96% * 100;
 Minibatch[ 501- 600]: loss = 0.294732 * 100, metric = 9.24% * 100;
 Minibatch[ 601- 700]: loss = 0.293082 * 100, metric = 9.13% * 100;
 Minibatch[ 701- 800]: loss = 0.308955 * 100, metric = 9.55% * 100;
 Minibatch[ 801- 900]: loss = 0.307330 * 100, metric = 9.87% * 100;
 Minibatch[ 901-1000]: loss = 0.298784 * 100, metric = 9.63% * 100;
 Minibatch[1001-1100]: loss = 0.301746 * 100, metric = 9.33% * 100;
 Minibatch[1101-1200]: loss = 0.292309 * 100, metric = 9.13% * 100;
 Minibatch[1201-1300]: loss = 0.273564 * 100, metric = 8.29% * 100;
 Minibatch[1301-1400]: loss = 0.298860 * 100, metric = 9.43% * 100;
 Minibatch[1401-1500]: loss = 0.298482 * 100, metric = 9.36% * 100;
 Minibatch[1501-1600]: loss = 0.282999 * 100, metric = 8.76% * 100;
 Minibatch[1601-1700]: loss = 0.285416 * 100, metric = 8.94% * 100;
 Minibatch[1701-1800]: loss = 0.278091 * 100, metric = 8.40% * 100;
 Minibatch[1801-1900]: loss = 0.286901 * 100, metric = 8.75% * 100;
 Minibatch[1901-2000]: loss = 0.290045 * 100, metric = 8.73% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.292629 * 2000, metric = 9.10% * 2000 890.029s (  2.2 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 16.75% * 2000;
 Minibatch[   1- 100]: loss = 0.281032 * 100, metric = 8.66% * 100;
 Minibatch[ 101- 200]: loss = 0.294332 * 100, metric = 9.32% * 100;
 Minibatch[ 201- 300]: loss = 0.291735 * 100, metric = 8.96% * 100;
 Minibatch[ 301- 400]: loss = 0.280976 * 100, metric = 8.64% * 100;
 Minibatch[ 401- 500]: loss = 0.282764 * 100, metric = 8.74% * 100;
 Minibatch[ 501- 600]: loss = 0.269183 * 100, metric = 8.10% * 100;
 Minibatch[ 601- 700]: loss = 0.271639 * 100, metric = 8.55% * 100;
 Minibatch[ 701- 800]: loss = 0.290847 * 100, metric = 9.12% * 100;
 Minibatch[ 801- 900]: loss = 0.306171 * 100, metric = 9.40% * 100;
 Minibatch[ 901-1000]: loss = 0.282639 * 100, metric = 8.90% * 100;
 Minibatch[1001-1100]: loss = 0.293778 * 100, metric = 9.03% * 100;
 Minibatch[1101-1200]: loss = 0.288467 * 100, metric = 8.98% * 100;
 Minibatch[1201-1300]: loss = 0.278040 * 100, metric = 8.57% * 100;
 Minibatch[1301-1400]: loss = 0.301785 * 100, metric = 9.48% * 100;
 Minibatch[1401-1500]: loss = 0.267527 * 100, metric = 8.21% * 100;
 Minibatch[1501-1600]: loss = 0.283322 * 100, metric = 8.83% * 100;
 Minibatch[1601-1700]: loss = 0.287715 * 100, metric = 8.88% * 100;
 Minibatch[1701-1800]: loss = 0.270610 * 100, metric = 8.09% * 100;
 Minibatch[1801-1900]: loss = 0.285817 * 100, metric = 8.89% * 100;
 Minibatch[1901-2000]: loss = 0.280641 * 100, metric = 8.69% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.284451 * 2000, metric = 8.80% * 2000 885.783s (  2.3 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 14.78% * 2000;
0.4216661356538534
 Minibatch[   1- 100]: loss = 0.291982 * 100, metric = 9.17% * 100;
 Minibatch[ 101- 200]: loss = 0.285915 * 100, metric = 8.80% * 100;
 Minibatch[ 201- 300]: loss = 0.283555 * 100, metric = 8.79% * 100;
 Minibatch[ 301- 400]: loss = 0.288539 * 100, metric = 8.76% * 100;
 Minibatch[ 401- 500]: loss = 0.272197 * 100, metric = 8.32% * 100;
 Minibatch[ 501- 600]: loss = 0.282316 * 100, metric = 8.75% * 100;
 Minibatch[ 601- 700]: loss = 0.277673 * 100, metric = 8.58% * 100;
 Minibatch[ 701- 800]: loss = 0.272729 * 100, metric = 8.34% * 100;
 Minibatch[ 801- 900]: loss = 0.271536 * 100, metric = 8.42% * 100;
 Minibatch[ 901-1000]: loss = 0.281610 * 100, metric = 9.01% * 100;
 Minibatch[1001-1100]: loss = 0.272285 * 100, metric = 8.51% * 100;
 Minibatch[1101-1200]: loss = 0.277353 * 100, metric = 8.83% * 100;
 Minibatch[1201-1300]: loss = 0.261382 * 100, metric = 8.02% * 100;
 Minibatch[1301-1400]: loss = 0.270724 * 100, metric = 8.45% * 100;
 Minibatch[1401-1500]: loss = 0.271325 * 100, metric = 8.47% * 100;
 Minibatch[1501-1600]: loss = 0.274431 * 100, metric = 8.64% * 100;
 Minibatch[1601-1700]: loss = 0.280379 * 100, metric = 8.71% * 100;
 Minibatch[1701-1800]: loss = 0.285499 * 100, metric = 8.81% * 100;
 Minibatch[1801-1900]: loss = 0.289518 * 100, metric = 8.93% * 100;
 Minibatch[1901-2000]: loss = 0.272435 * 100, metric = 8.53% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.278169 * 2000, metric = 8.64% * 2000 886.423s (  2.3 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.65% * 2000;
 Minibatch[   1- 100]: loss = 0.265595 * 100, metric = 8.30% * 100;
 Minibatch[ 101- 200]: loss = 0.281370 * 100, metric = 8.67% * 100;
 Minibatch[ 201- 300]: loss = 0.283857 * 100, metric = 8.90% * 100;
 Minibatch[ 301- 400]: loss = 0.270178 * 100, metric = 8.44% * 100;
 Minibatch[ 401- 500]: loss = 0.276751 * 100, metric = 8.46% * 100;
 Minibatch[ 501- 600]: loss = 0.266915 * 100, metric = 8.18% * 100;
 Minibatch[ 601- 700]: loss = 0.254738 * 100, metric = 7.86% * 100;
 Minibatch[ 701- 800]: loss = 0.269278 * 100, metric = 8.27% * 100;
 Minibatch[ 801- 900]: loss = 0.277044 * 100, metric = 8.72% * 100;
 Minibatch[ 901-1000]: loss = 0.265600 * 100, metric = 8.12% * 100;
 Minibatch[1001-1100]: loss = 0.265658 * 100, metric = 8.20% * 100;
 Minibatch[1101-1200]: loss = 0.281823 * 100, metric = 8.78% * 100;
 Minibatch[1201-1300]: loss = 0.276953 * 100, metric = 8.61% * 100;
 Minibatch[1301-1400]: loss = 0.258422 * 100, metric = 7.77% * 100;
 Minibatch[1401-1500]: loss = 0.274983 * 100, metric = 8.61% * 100;
 Minibatch[1501-1600]: loss = 0.271008 * 100, metric = 8.34% * 100;
 Minibatch[1601-1700]: loss = 0.273155 * 100, metric = 8.40% * 100;
 Minibatch[1701-1800]: loss = 0.261287 * 100, metric = 8.09% * 100;
 Minibatch[1801-1900]: loss = 0.280589 * 100, metric = 8.95% * 100;
 Minibatch[1901-2000]: loss = 0.279101 * 100, metric = 8.63% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.271715 * 2000, metric = 8.42% * 2000 886.407s (  2.3 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.12% * 2000;
0.4158943615742028
 Minibatch[   1- 100]: loss = 0.255083 * 100, metric = 7.96% * 100;
 Minibatch[ 101- 200]: loss = 0.276541 * 100, metric = 8.66% * 100;
 Minibatch[ 201- 300]: loss = 0.264662 * 100, metric = 8.36% * 100;
 Minibatch[ 301- 400]: loss = 0.268614 * 100, metric = 8.34% * 100;
 Minibatch[ 401- 500]: loss = 0.255353 * 100, metric = 7.88% * 100;
 Minibatch[ 501- 600]: loss = 0.260974 * 100, metric = 8.05% * 100;
 Minibatch[ 601- 700]: loss = 0.271167 * 100, metric = 8.34% * 100;
 Minibatch[ 701- 800]: loss = 0.259096 * 100, metric = 8.19% * 100;
 Minibatch[ 801- 900]: loss = 0.266578 * 100, metric = 8.12% * 100;
 Minibatch[ 901-1000]: loss = 0.266029 * 100, metric = 8.16% * 100;
 Minibatch[1001-1100]: loss = 0.273784 * 100, metric = 8.62% * 100;
 Minibatch[1101-1200]: loss = 0.271063 * 100, metric = 8.44% * 100;
 Minibatch[1201-1300]: loss = 0.277706 * 100, metric = 8.58% * 100;
 Minibatch[1301-1400]: loss = 0.278588 * 100, metric = 8.46% * 100;
 Minibatch[1401-1500]: loss = 0.254231 * 100, metric = 7.78% * 100;
 Minibatch[1501-1600]: loss = 0.265516 * 100, metric = 8.12% * 100;
 Minibatch[1601-1700]: loss = 0.252455 * 100, metric = 7.77% * 100;
 Minibatch[1701-1800]: loss = 0.260007 * 100, metric = 7.93% * 100;
 Minibatch[1801-1900]: loss = 0.252773 * 100, metric = 7.88% * 100;
 Minibatch[1901-2000]: loss = 0.257300 * 100, metric = 7.80% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.264376 * 2000, metric = 8.17% * 2000 878.788s (  2.3 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.27% * 2000;
 Minibatch[   1- 100]: loss = 0.271824 * 100, metric = 8.63% * 100;
 Minibatch[ 101- 200]: loss = 0.278453 * 100, metric = 8.66% * 100;
 Minibatch[ 201- 300]: loss = 0.252304 * 100, metric = 7.80% * 100;
 Minibatch[ 301- 400]: loss = 0.269536 * 100, metric = 8.20% * 100;
 Minibatch[ 401- 500]: loss = 0.263805 * 100, metric = 8.00% * 100;
 Minibatch[ 501- 600]: loss = 0.256346 * 100, metric = 7.79% * 100;
 Minibatch[ 601- 700]: loss = 0.263053 * 100, metric = 8.17% * 100;
 Minibatch[ 701- 800]: loss = 0.254843 * 100, metric = 7.91% * 100;
 Minibatch[ 801- 900]: loss = 0.277010 * 100, metric = 8.50% * 100;
 Minibatch[ 901-1000]: loss = 0.251534 * 100, metric = 7.80% * 100;
 Minibatch[1001-1100]: loss = 0.262170 * 100, metric = 8.22% * 100;
 Minibatch[1101-1200]: loss = 0.259020 * 100, metric = 8.30% * 100;
 Minibatch[1201-1300]: loss = 0.256570 * 100, metric = 7.94% * 100;
 Minibatch[1301-1400]: loss = 0.252928 * 100, metric = 7.78% * 100;
 Minibatch[1401-1500]: loss = 0.268448 * 100, metric = 8.45% * 100;
 Minibatch[1501-1600]: loss = 0.265762 * 100, metric = 8.43% * 100;
 Minibatch[1601-1700]: loss = 0.256774 * 100, metric = 7.96% * 100;
 Minibatch[1701-1800]: loss = 0.247167 * 100, metric = 7.69% * 100;
 Minibatch[1801-1900]: loss = 0.254688 * 100, metric = 7.99% * 100;
 Minibatch[1901-2000]: loss = 0.245409 * 100, metric = 7.55% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.260382 * 2000, metric = 8.09% * 2000 890.475s (  2.2 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 15.45% * 2000;
 Minibatch[   1- 100]: loss = 0.253776 * 100, metric = 7.79% * 100;
 Minibatch[ 101- 200]: loss = 0.256472 * 100, metric = 7.77% * 100;
 Minibatch[ 201- 300]: loss = 0.251088 * 100, metric = 7.53% * 100;
 Minibatch[ 301- 400]: loss = 0.270021 * 100, metric = 7.91% * 100;
 Minibatch[ 401- 500]: loss = 0.256703 * 100, metric = 8.08% * 100;
 Minibatch[ 501- 600]: loss = 0.259872 * 100, metric = 8.17% * 100;
 Minibatch[ 601- 700]: loss = 0.266224 * 100, metric = 8.41% * 100;
 Minibatch[ 701- 800]: loss = 0.254633 * 100, metric = 8.04% * 100;
 Minibatch[ 801- 900]: loss = 0.259207 * 100, metric = 8.09% * 100;
 Minibatch[ 901-1000]: loss = 0.264203 * 100, metric = 8.18% * 100;
 Minibatch[1001-1100]: loss = 0.240662 * 100, metric = 7.28% * 100;
 Minibatch[1101-1200]: loss = 0.257189 * 100, metric = 7.89% * 100;
 Minibatch[1201-1300]: loss = 0.264413 * 100, metric = 8.07% * 100;
 Minibatch[1301-1400]: loss = 0.265183 * 100, metric = 8.44% * 100;
 Minibatch[1401-1500]: loss = 0.253306 * 100, metric = 7.91% * 100;
 Minibatch[1501-1600]: loss = 0.265988 * 100, metric = 8.15% * 100;
 Minibatch[1601-1700]: loss = 0.254463 * 100, metric = 7.92% * 100;
 Minibatch[1701-1800]: loss = 0.262662 * 100, metric = 8.15% * 100;
 Minibatch[1801-1900]: loss = 0.250412 * 100, metric = 7.74% * 100;
 Minibatch[1901-2000]: loss = 0.249475 * 100, metric = 7.67% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.257798 * 2000, metric = 7.96% * 2000 895.151s (  2.2 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 15.49% * 2000;
 Minibatch[   1- 100]: loss = 0.256227 * 100, metric = 7.92% * 100;
 Minibatch[ 101- 200]: loss = 0.245997 * 100, metric = 7.61% * 100;
 Minibatch[ 201- 300]: loss = 0.251888 * 100, metric = 7.88% * 100;
 Minibatch[ 301- 400]: loss = 0.258399 * 100, metric = 8.14% * 100;
 Minibatch[ 401- 500]: loss = 0.248713 * 100, metric = 7.82% * 100;
 Minibatch[ 501- 600]: loss = 0.243348 * 100, metric = 7.53% * 100;
 Minibatch[ 601- 700]: loss = 0.248832 * 100, metric = 7.60% * 100;
 Minibatch[ 701- 800]: loss = 0.231279 * 100, metric = 7.12% * 100;
 Minibatch[ 801- 900]: loss = 0.253972 * 100, metric = 7.87% * 100;
 Minibatch[ 901-1000]: loss = 0.246139 * 100, metric = 7.75% * 100;
 Minibatch[1001-1100]: loss = 0.244860 * 100, metric = 7.62% * 100;
 Minibatch[1101-1200]: loss = 0.244768 * 100, metric = 7.36% * 100;
 Minibatch[1201-1300]: loss = 0.247413 * 100, metric = 7.51% * 100;
 Minibatch[1301-1400]: loss = 0.239672 * 100, metric = 7.48% * 100;
 Minibatch[1401-1500]: loss = 0.247622 * 100, metric = 7.77% * 100;
 Minibatch[1501-1600]: loss = 0.262600 * 100, metric = 8.20% * 100;
 Minibatch[1601-1700]: loss = 0.251927 * 100, metric = 7.71% * 100;
 Minibatch[1701-1800]: loss = 0.243884 * 100, metric = 7.49% * 100;
 Minibatch[1801-1900]: loss = 0.260417 * 100, metric = 7.98% * 100;
 Minibatch[1901-2000]: loss = 0.246292 * 100, metric = 7.36% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.248713 * 2000, metric = 7.69% * 2000 879.099s (  2.3 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 13.97% * 2000;
 Minibatch[   1- 100]: loss = 0.257734 * 100, metric = 8.09% * 100;
 Minibatch[ 101- 200]: loss = 0.248264 * 100, metric = 7.60% * 100;
 Minibatch[ 201- 300]: loss = 0.258503 * 100, metric = 7.92% * 100;
 Minibatch[ 301- 400]: loss = 0.244258 * 100, metric = 7.70% * 100;
 Minibatch[ 401- 500]: loss = 0.247620 * 100, metric = 7.63% * 100;
 Minibatch[ 501- 600]: loss = 0.247516 * 100, metric = 7.73% * 100;
 Minibatch[ 601- 700]: loss = 0.238372 * 100, metric = 7.46% * 100;
 Minibatch[ 701- 800]: loss = 0.244887 * 100, metric = 7.74% * 100;
 Minibatch[ 801- 900]: loss = 0.252857 * 100, metric = 7.97% * 100;
 Minibatch[ 901-1000]: loss = 0.254536 * 100, metric = 7.87% * 100;
 Minibatch[1001-1100]: loss = 0.237903 * 100, metric = 7.21% * 100;
 Minibatch[1101-1200]: loss = 0.224240 * 100, metric = 6.79% * 100;
 Minibatch[1201-1300]: loss = 0.246146 * 100, metric = 7.70% * 100;
 Minibatch[1301-1400]: loss = 0.245599 * 100, metric = 7.55% * 100;
 Minibatch[1401-1500]: loss = 0.237920 * 100, metric = 7.46% * 100;
 Minibatch[1501-1600]: loss = 0.236936 * 100, metric = 7.35% * 100;
 Minibatch[1601-1700]: loss = 0.242759 * 100, metric = 7.29% * 100;
 Minibatch[1701-1800]: loss = 0.238502 * 100, metric = 7.34% * 100;
 Minibatch[1801-1900]: loss = 0.240461 * 100, metric = 7.46% * 100;
 Minibatch[1901-2000]: loss = 0.242387 * 100, metric = 7.37% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.244370 * 2000, metric = 7.56% * 2000 870.761s (  2.3 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 14.67% * 2000;
 Minibatch[   1- 100]: loss = 0.249819 * 100, metric = 7.55% * 100;
 Minibatch[ 101- 200]: loss = 0.253566 * 100, metric = 7.97% * 100;
 Minibatch[ 201- 300]: loss = 0.240173 * 100, metric = 7.33% * 100;
 Minibatch[ 301- 400]: loss = 0.247769 * 100, metric = 7.62% * 100;
 Minibatch[ 401- 500]: loss = 0.252022 * 100, metric = 7.89% * 100;
 Minibatch[ 501- 600]: loss = 0.242739 * 100, metric = 7.45% * 100;
 Minibatch[ 601- 700]: loss = 0.244092 * 100, metric = 7.47% * 100;
 Minibatch[ 701- 800]: loss = 0.232691 * 100, metric = 7.20% * 100;
 Minibatch[ 801- 900]: loss = 0.233735 * 100, metric = 7.41% * 100;
 Minibatch[ 901-1000]: loss = 0.252160 * 100, metric = 8.01% * 100;
 Minibatch[1001-1100]: loss = 0.238960 * 100, metric = 7.26% * 100;
 Minibatch[1101-1200]: loss = 0.243698 * 100, metric = 7.73% * 100;
 Minibatch[1201-1300]: loss = 0.244345 * 100, metric = 7.54% * 100;
 Minibatch[1301-1400]: loss = 0.245439 * 100, metric = 7.62% * 100;
 Minibatch[1401-1500]: loss = 0.232288 * 100, metric = 7.11% * 100;
 Minibatch[1501-1600]: loss = 0.232710 * 100, metric = 7.12% * 100;
 Minibatch[1601-1700]: loss = 0.236167 * 100, metric = 7.29% * 100;
 Minibatch[1701-1800]: loss = 0.241845 * 100, metric = 7.64% * 100;
 Minibatch[1801-1900]: loss = 0.244738 * 100, metric = 7.85% * 100;
 Minibatch[1901-2000]: loss = 0.240804 * 100, metric = 7.48% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.242488 * 2000, metric = 7.53% * 2000 868.353s (  2.3 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 14.71% * 2000;
 Minibatch[   1- 100]: loss = 0.231389 * 100, metric = 7.31% * 100;
 Minibatch[ 101- 200]: loss = 0.241251 * 100, metric = 7.61% * 100;
 Minibatch[ 201- 300]: loss = 0.233178 * 100, metric = 7.25% * 100;
 Minibatch[ 301- 400]: loss = 0.239576 * 100, metric = 7.38% * 100;
 Minibatch[ 401- 500]: loss = 0.234967 * 100, metric = 7.22% * 100;
 Minibatch[ 501- 600]: loss = 0.227010 * 100, metric = 7.23% * 100;
 Minibatch[ 601- 700]: loss = 0.235687 * 100, metric = 7.18% * 100;
 Minibatch[ 701- 800]: loss = 0.236673 * 100, metric = 7.46% * 100;
 Minibatch[ 801- 900]: loss = 0.239931 * 100, metric = 7.63% * 100;
 Minibatch[ 901-1000]: loss = 0.236704 * 100, metric = 7.40% * 100;
 Minibatch[1001-1100]: loss = 0.238783 * 100, metric = 7.46% * 100;
 Minibatch[1101-1200]: loss = 0.246519 * 100, metric = 7.57% * 100;
 Minibatch[1201-1300]: loss = 0.235615 * 100, metric = 7.37% * 100;
 Minibatch[1301-1400]: loss = 0.227661 * 100, metric = 7.01% * 100;
 Minibatch[1401-1500]: loss = 0.226100 * 100, metric = 6.92% * 100;
 Minibatch[1501-1600]: loss = 0.235479 * 100, metric = 7.30% * 100;
 Minibatch[1601-1700]: loss = 0.222845 * 100, metric = 6.83% * 100;
 Minibatch[1701-1800]: loss = 0.225732 * 100, metric = 6.89% * 100;
 Minibatch[1801-1900]: loss = 0.236852 * 100, metric = 7.34% * 100;
 Minibatch[1901-2000]: loss = 0.240774 * 100, metric = 7.52% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.234636 * 2000, metric = 7.29% * 2000 866.154s (  2.3 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.16% * 2000;
 Minibatch[   1- 100]: loss = 0.234574 * 100, metric = 7.15% * 100;
 Minibatch[ 101- 200]: loss = 0.238402 * 100, metric = 7.33% * 100;
 Minibatch[ 201- 300]: loss = 0.235803 * 100, metric = 7.49% * 100;
 Minibatch[ 301- 400]: loss = 0.232823 * 100, metric = 7.25% * 100;
 Minibatch[ 401- 500]: loss = 0.234858 * 100, metric = 7.29% * 100;
 Minibatch[ 501- 600]: loss = 0.230841 * 100, metric = 7.23% * 100;
 Minibatch[ 601- 700]: loss = 0.232214 * 100, metric = 7.11% * 100;
 Minibatch[ 701- 800]: loss = 0.222819 * 100, metric = 6.90% * 100;
 Minibatch[ 801- 900]: loss = 0.225551 * 100, metric = 7.03% * 100;
 Minibatch[ 901-1000]: loss = 0.233676 * 100, metric = 7.38% * 100;
 Minibatch[1001-1100]: loss = 0.232548 * 100, metric = 7.34% * 100;
 Minibatch[1101-1200]: loss = 0.239388 * 100, metric = 7.41% * 100;
 Minibatch[1201-1300]: loss = 0.249152 * 100, metric = 7.73% * 100;
 Minibatch[1301-1400]: loss = 0.231498 * 100, metric = 7.16% * 100;
 Minibatch[1401-1500]: loss = 0.224573 * 100, metric = 6.80% * 100;
 Minibatch[1501-1600]: loss = 0.234340 * 100, metric = 7.37% * 100;
 Minibatch[1601-1700]: loss = 0.231121 * 100, metric = 7.24% * 100;
 Minibatch[1701-1800]: loss = 0.231109 * 100, metric = 7.25% * 100;
 Minibatch[1801-1900]: loss = 0.224320 * 100, metric = 6.96% * 100;
 Minibatch[1901-2000]: loss = 0.218814 * 100, metric = 6.78% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.231921 * 2000, metric = 7.21% * 2000 860.648s (  2.3 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 13.79% * 2000;
 Minibatch[   1- 100]: loss = 0.234497 * 100, metric = 7.40% * 100;
 Minibatch[ 101- 200]: loss = 0.216058 * 100, metric = 6.63% * 100;
 Minibatch[ 201- 300]: loss = 0.230950 * 100, metric = 7.22% * 100;
 Minibatch[ 301- 400]: loss = 0.220124 * 100, metric = 6.78% * 100;
 Minibatch[ 401- 500]: loss = 0.229909 * 100, metric = 7.21% * 100;
 Minibatch[ 501- 600]: loss = 0.220305 * 100, metric = 6.70% * 100;
 Minibatch[ 601- 700]: loss = 0.235381 * 100, metric = 7.19% * 100;
 Minibatch[ 701- 800]: loss = 0.225586 * 100, metric = 7.12% * 100;
 Minibatch[ 801- 900]: loss = 0.212740 * 100, metric = 6.49% * 100;
 Minibatch[ 901-1000]: loss = 0.222556 * 100, metric = 6.82% * 100;
 Minibatch[1001-1100]: loss = 0.235398 * 100, metric = 7.59% * 100;
 Minibatch[1101-1200]: loss = 0.236335 * 100, metric = 7.37% * 100;
 Minibatch[1201-1300]: loss = 0.229420 * 100, metric = 7.01% * 100;
 Minibatch[1301-1400]: loss = 0.212984 * 100, metric = 6.38% * 100;
 Minibatch[1401-1500]: loss = 0.229476 * 100, metric = 7.20% * 100;
 Minibatch[1501-1600]: loss = 0.220169 * 100, metric = 6.62% * 100;
 Minibatch[1601-1700]: loss = 0.240560 * 100, metric = 7.48% * 100;
 Minibatch[1701-1800]: loss = 0.235574 * 100, metric = 7.35% * 100;
 Minibatch[1801-1900]: loss = 0.223146 * 100, metric = 6.93% * 100;
 Minibatch[1901-2000]: loss = 0.230843 * 100, metric = 7.16% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.227101 * 2000, metric = 7.03% * 2000 857.648s (  2.3 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 13.97% * 2000;
 Minibatch[   1- 100]: loss = 0.227096 * 100, metric = 7.00% * 100;
 Minibatch[ 101- 200]: loss = 0.238663 * 100, metric = 7.27% * 100;
 Minibatch[ 201- 300]: loss = 0.226966 * 100, metric = 7.07% * 100;
 Minibatch[ 301- 400]: loss = 0.220611 * 100, metric = 6.80% * 100;
 Minibatch[ 401- 500]: loss = 0.231933 * 100, metric = 7.32% * 100;
 Minibatch[ 501- 600]: loss = 0.220468 * 100, metric = 6.73% * 100;
 Minibatch[ 601- 700]: loss = 0.216146 * 100, metric = 6.58% * 100;
 Minibatch[ 701- 800]: loss = 0.224568 * 100, metric = 6.96% * 100;
 Minibatch[ 801- 900]: loss = 0.235505 * 100, metric = 7.11% * 100;
 Minibatch[ 901-1000]: loss = 0.226120 * 100, metric = 7.10% * 100;
 Minibatch[1001-1100]: loss = 0.212310 * 100, metric = 6.57% * 100;
 Minibatch[1101-1200]: loss = 0.230257 * 100, metric = 7.14% * 100;
 Minibatch[1201-1300]: loss = 0.222045 * 100, metric = 6.82% * 100;
 Minibatch[1301-1400]: loss = 0.230379 * 100, metric = 7.30% * 100;
 Minibatch[1401-1500]: loss = 0.220304 * 100, metric = 6.79% * 100;
 Minibatch[1501-1600]: loss = 0.225215 * 100, metric = 6.84% * 100;
 Minibatch[1601-1700]: loss = 0.210968 * 100, metric = 6.52% * 100;
 Minibatch[1701-1800]: loss = 0.223410 * 100, metric = 6.90% * 100;
 Minibatch[1801-1900]: loss = 0.221442 * 100, metric = 6.83% * 100;
 Minibatch[1901-2000]: loss = 0.229468 * 100, metric = 7.09% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.224694 * 2000, metric = 6.94% * 2000 868.847s (  2.3 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.85% * 2000;
 Minibatch[   1- 100]: loss = 0.226568 * 100, metric = 6.97% * 100;
 Minibatch[ 101- 200]: loss = 0.212093 * 100, metric = 6.42% * 100;
 Minibatch[ 201- 300]: loss = 0.224106 * 100, metric = 6.91% * 100;
 Minibatch[ 301- 400]: loss = 0.226385 * 100, metric = 6.90% * 100;
 Minibatch[ 401- 500]: loss = 0.222424 * 100, metric = 6.94% * 100;
 Minibatch[ 501- 600]: loss = 0.237370 * 100, metric = 7.52% * 100;
 Minibatch[ 601- 700]: loss = 0.217496 * 100, metric = 6.82% * 100;
 Minibatch[ 701- 800]: loss = 0.212517 * 100, metric = 6.57% * 100;
 Minibatch[ 801- 900]: loss = 0.225792 * 100, metric = 7.02% * 100;
 Minibatch[ 901-1000]: loss = 0.233308 * 100, metric = 7.25% * 100;
 Minibatch[1001-1100]: loss = 0.221908 * 100, metric = 6.86% * 100;
 Minibatch[1101-1200]: loss = 0.222293 * 100, metric = 6.98% * 100;
 Minibatch[1201-1300]: loss = 0.227415 * 100, metric = 7.10% * 100;
 Minibatch[1301-1400]: loss = 0.223450 * 100, metric = 6.96% * 100;
 Minibatch[1401-1500]: loss = 0.226622 * 100, metric = 6.93% * 100;
 Minibatch[1501-1600]: loss = 0.218394 * 100, metric = 6.80% * 100;
 Minibatch[1601-1700]: loss = 0.219036 * 100, metric = 6.59% * 100;
 Minibatch[1701-1800]: loss = 0.219749 * 100, metric = 6.83% * 100;
 Minibatch[1801-1900]: loss = 0.218751 * 100, metric = 6.83% * 100;
 Minibatch[1901-2000]: loss = 0.222471 * 100, metric = 6.75% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.222907 * 2000, metric = 6.90% * 2000 860.505s (  2.3 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.20% * 2000;
 Minibatch[   1- 100]: loss = 0.219661 * 100, metric = 6.69% * 100;
 Minibatch[ 101- 200]: loss = 0.227056 * 100, metric = 7.15% * 100;
 Minibatch[ 201- 300]: loss = 0.226218 * 100, metric = 7.11% * 100;
 Minibatch[ 301- 400]: loss = 0.237832 * 100, metric = 7.36% * 100;
 Minibatch[ 401- 500]: loss = 0.209050 * 100, metric = 6.47% * 100;
 Minibatch[ 501- 600]: loss = 0.221421 * 100, metric = 6.92% * 100;
 Minibatch[ 601- 700]: loss = 0.215628 * 100, metric = 6.82% * 100;
 Minibatch[ 701- 800]: loss = 0.229300 * 100, metric = 7.25% * 100;
 Minibatch[ 801- 900]: loss = 0.222883 * 100, metric = 7.05% * 100;
 Minibatch[ 901-1000]: loss = 0.224438 * 100, metric = 7.11% * 100;
 Minibatch[1001-1100]: loss = 0.220475 * 100, metric = 6.93% * 100;
 Minibatch[1101-1200]: loss = 0.211786 * 100, metric = 6.57% * 100;
 Minibatch[1201-1300]: loss = 0.219446 * 100, metric = 6.87% * 100;
 Minibatch[1301-1400]: loss = 0.211229 * 100, metric = 6.59% * 100;
 Minibatch[1401-1500]: loss = 0.225597 * 100, metric = 6.97% * 100;
 Minibatch[1501-1600]: loss = 0.209758 * 100, metric = 6.57% * 100;
 Minibatch[1601-1700]: loss = 0.226279 * 100, metric = 7.16% * 100;
 Minibatch[1701-1800]: loss = 0.208203 * 100, metric = 6.48% * 100;
 Minibatch[1801-1900]: loss = 0.225482 * 100, metric = 6.97% * 100;
 Minibatch[1901-2000]: loss = 0.217052 * 100, metric = 6.81% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.220440 * 2000, metric = 6.89% * 2000 859.492s (  2.3 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 15.19% * 2000;
 Minibatch[   1- 100]: loss = 0.227787 * 100, metric = 6.97% * 100;
 Minibatch[ 101- 200]: loss = 0.201456 * 100, metric = 6.21% * 100;
 Minibatch[ 201- 300]: loss = 0.210723 * 100, metric = 6.57% * 100;
 Minibatch[ 301- 400]: loss = 0.219457 * 100, metric = 6.99% * 100;
 Minibatch[ 401- 500]: loss = 0.219991 * 100, metric = 6.80% * 100;
 Minibatch[ 501- 600]: loss = 0.203017 * 100, metric = 6.27% * 100;
 Minibatch[ 601- 700]: loss = 0.223728 * 100, metric = 7.04% * 100;
 Minibatch[ 701- 800]: loss = 0.212227 * 100, metric = 6.65% * 100;
 Minibatch[ 801- 900]: loss = 0.220286 * 100, metric = 6.75% * 100;
 Minibatch[ 901-1000]: loss = 0.205666 * 100, metric = 6.33% * 100;
 Minibatch[1001-1100]: loss = 0.216033 * 100, metric = 6.48% * 100;
 Minibatch[1101-1200]: loss = 0.222360 * 100, metric = 6.95% * 100;
 Minibatch[1201-1300]: loss = 0.210114 * 100, metric = 6.51% * 100;
 Minibatch[1301-1400]: loss = 0.216404 * 100, metric = 6.75% * 100;
 Minibatch[1401-1500]: loss = 0.212652 * 100, metric = 6.55% * 100;
 Minibatch[1501-1600]: loss = 0.213135 * 100, metric = 6.65% * 100;
 Minibatch[1601-1700]: loss = 0.219177 * 100, metric = 6.91% * 100;
 Minibatch[1701-1800]: loss = 0.218209 * 100, metric = 6.82% * 100;
 Minibatch[1801-1900]: loss = 0.213496 * 100, metric = 6.79% * 100;
 Minibatch[1901-2000]: loss = 0.226662 * 100, metric = 7.04% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.215629 * 2000, metric = 6.70% * 2000 855.460s (  2.3 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 13.65% * 2000;
 Minibatch[   1- 100]: loss = 0.210817 * 100, metric = 6.52% * 100;
 Minibatch[ 101- 200]: loss = 0.223446 * 100, metric = 6.95% * 100;
 Minibatch[ 201- 300]: loss = 0.215570 * 100, metric = 6.68% * 100;
 Minibatch[ 301- 400]: loss = 0.213092 * 100, metric = 6.62% * 100;
 Minibatch[ 401- 500]: loss = 0.214831 * 100, metric = 6.61% * 100;
 Minibatch[ 501- 600]: loss = 0.212861 * 100, metric = 6.69% * 100;
 Minibatch[ 601- 700]: loss = 0.223575 * 100, metric = 7.00% * 100;
 Minibatch[ 701- 800]: loss = 0.217670 * 100, metric = 6.73% * 100;
 Minibatch[ 801- 900]: loss = 0.216527 * 100, metric = 6.61% * 100;
 Minibatch[ 901-1000]: loss = 0.217680 * 100, metric = 6.95% * 100;
 Minibatch[1001-1100]: loss = 0.209608 * 100, metric = 6.46% * 100;
 Minibatch[1101-1200]: loss = 0.215726 * 100, metric = 6.71% * 100;
 Minibatch[1201-1300]: loss = 0.213904 * 100, metric = 6.74% * 100;
 Minibatch[1301-1400]: loss = 0.210862 * 100, metric = 6.46% * 100;
 Minibatch[1401-1500]: loss = 0.216476 * 100, metric = 6.66% * 100;
 Minibatch[1501-1600]: loss = 0.212077 * 100, metric = 6.74% * 100;
 Minibatch[1601-1700]: loss = 0.213600 * 100, metric = 6.59% * 100;
 Minibatch[1701-1800]: loss = 0.213755 * 100, metric = 6.84% * 100;
 Minibatch[1801-1900]: loss = 0.213562 * 100, metric = 6.67% * 100;
 Minibatch[1901-2000]: loss = 0.211927 * 100, metric = 6.67% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.214878 * 2000, metric = 6.70% * 2000 857.130s (  2.3 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 14.54% * 2000;
 Minibatch[   1- 100]: loss = 0.213404 * 100, metric = 6.69% * 100;
 Minibatch[ 101- 200]: loss = 0.212834 * 100, metric = 6.58% * 100;
 Minibatch[ 201- 300]: loss = 0.224140 * 100, metric = 7.01% * 100;
 Minibatch[ 301- 400]: loss = 0.224379 * 100, metric = 6.96% * 100;
 Minibatch[ 401- 500]: loss = 0.216484 * 100, metric = 6.75% * 100;
 Minibatch[ 501- 600]: loss = 0.215534 * 100, metric = 6.80% * 100;
 Minibatch[ 601- 700]: loss = 0.209203 * 100, metric = 6.46% * 100;
 Minibatch[ 701- 800]: loss = 0.205278 * 100, metric = 6.38% * 100;
 Minibatch[ 801- 900]: loss = 0.213573 * 100, metric = 6.51% * 100;
 Minibatch[ 901-1000]: loss = 0.197967 * 100, metric = 6.06% * 100;
 Minibatch[1001-1100]: loss = 0.197934 * 100, metric = 5.96% * 100;
 Minibatch[1101-1200]: loss = 0.208874 * 100, metric = 6.45% * 100;
 Minibatch[1201-1300]: loss = 0.215559 * 100, metric = 6.73% * 100;
 Minibatch[1301-1400]: loss = 0.212560 * 100, metric = 6.54% * 100;
 Minibatch[1401-1500]: loss = 0.211642 * 100, metric = 6.57% * 100;
 Minibatch[1501-1600]: loss = 0.211398 * 100, metric = 6.44% * 100;
 Minibatch[1601-1700]: loss = 0.201924 * 100, metric = 6.18% * 100;
 Minibatch[1701-1800]: loss = 0.218608 * 100, metric = 6.78% * 100;
 Minibatch[1801-1900]: loss = 0.204160 * 100, metric = 6.27% * 100;
 Minibatch[1901-2000]: loss = 0.215870 * 100, metric = 6.87% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.211566 * 2000, metric = 6.55% * 2000 851.202s (  2.3 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.16% * 2000;
 Minibatch[   1- 100]: loss = 0.224639 * 100, metric = 6.96% * 100;
 Minibatch[ 101- 200]: loss = 0.209377 * 100, metric = 6.58% * 100;
 Minibatch[ 201- 300]: loss = 0.207909 * 100, metric = 6.40% * 100;
 Minibatch[ 301- 400]: loss = 0.215187 * 100, metric = 6.71% * 100;
 Minibatch[ 401- 500]: loss = 0.207492 * 100, metric = 6.42% * 100;
 Minibatch[ 501- 600]: loss = 0.212237 * 100, metric = 6.65% * 100;
 Minibatch[ 601- 700]: loss = 0.218753 * 100, metric = 6.95% * 100;
 Minibatch[ 701- 800]: loss = 0.214059 * 100, metric = 6.70% * 100;
 Minibatch[ 801- 900]: loss = 0.206629 * 100, metric = 6.43% * 100;
 Minibatch[ 901-1000]: loss = 0.197854 * 100, metric = 6.26% * 100;
 Minibatch[1001-1100]: loss = 0.206633 * 100, metric = 6.58% * 100;
 Minibatch[1101-1200]: loss = 0.199150 * 100, metric = 6.23% * 100;
 Minibatch[1201-1300]: loss = 0.214205 * 100, metric = 6.44% * 100;
 Minibatch[1301-1400]: loss = 0.197068 * 100, metric = 6.12% * 100;
 Minibatch[1401-1500]: loss = 0.224173 * 100, metric = 6.85% * 100;
 Minibatch[1501-1600]: loss = 0.214854 * 100, metric = 6.59% * 100;
 Minibatch[1601-1700]: loss = 0.200910 * 100, metric = 6.00% * 100;
 Minibatch[1701-1800]: loss = 0.200204 * 100, metric = 6.08% * 100;
 Minibatch[1801-1900]: loss = 0.195556 * 100, metric = 5.98% * 100;
 Minibatch[1901-2000]: loss = 0.217571 * 100, metric = 6.83% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.209223 * 2000, metric = 6.49% * 2000 849.617s (  2.4 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 14.22% * 2000;
 Minibatch[   1- 100]: loss = 0.203839 * 100, metric = 6.32% * 100;
 Minibatch[ 101- 200]: loss = 0.209675 * 100, metric = 6.54% * 100;
 Minibatch[ 201- 300]: loss = 0.202832 * 100, metric = 6.33% * 100;
 Minibatch[ 301- 400]: loss = 0.211380 * 100, metric = 6.53% * 100;
 Minibatch[ 401- 500]: loss = 0.204735 * 100, metric = 6.33% * 100;
 Minibatch[ 501- 600]: loss = 0.204698 * 100, metric = 6.32% * 100;
 Minibatch[ 601- 700]: loss = 0.205544 * 100, metric = 6.48% * 100;
 Minibatch[ 701- 800]: loss = 0.203025 * 100, metric = 6.23% * 100;
 Minibatch[ 801- 900]: loss = 0.193941 * 100, metric = 5.88% * 100;
 Minibatch[ 901-1000]: loss = 0.202203 * 100, metric = 6.32% * 100;
 Minibatch[1001-1100]: loss = 0.210995 * 100, metric = 6.63% * 100;
 Minibatch[1101-1200]: loss = 0.204790 * 100, metric = 6.41% * 100;
 Minibatch[1201-1300]: loss = 0.205698 * 100, metric = 6.38% * 100;
 Minibatch[1301-1400]: loss = 0.205403 * 100, metric = 6.50% * 100;
 Minibatch[1401-1500]: loss = 0.209725 * 100, metric = 6.54% * 100;
 Minibatch[1501-1600]: loss = 0.207443 * 100, metric = 6.54% * 100;
 Minibatch[1601-1700]: loss = 0.213833 * 100, metric = 6.73% * 100;
 Minibatch[1701-1800]: loss = 0.205131 * 100, metric = 6.50% * 100;
 Minibatch[1801-1900]: loss = 0.207209 * 100, metric = 6.32% * 100;
 Minibatch[1901-2000]: loss = 0.203424 * 100, metric = 6.38% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.205776 * 2000, metric = 6.41% * 2000 852.983s (  2.3 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.13% * 2000;
 Minibatch[   1- 100]: loss = 0.191920 * 100, metric = 5.89% * 100;
 Minibatch[ 101- 200]: loss = 0.200868 * 100, metric = 6.19% * 100;
 Minibatch[ 201- 300]: loss = 0.202914 * 100, metric = 6.24% * 100;
 Minibatch[ 301- 400]: loss = 0.193662 * 100, metric = 5.89% * 100;
 Minibatch[ 401- 500]: loss = 0.204366 * 100, metric = 6.18% * 100;
 Minibatch[ 501- 600]: loss = 0.184670 * 100, metric = 5.61% * 100;
 Minibatch[ 601- 700]: loss = 0.207554 * 100, metric = 6.43% * 100;
 Minibatch[ 701- 800]: loss = 0.190735 * 100, metric = 5.88% * 100;
 Minibatch[ 801- 900]: loss = 0.204874 * 100, metric = 6.34% * 100;
 Minibatch[ 901-1000]: loss = 0.195479 * 100, metric = 5.88% * 100;
 Minibatch[1001-1100]: loss = 0.207144 * 100, metric = 6.44% * 100;
 Minibatch[1101-1200]: loss = 0.198737 * 100, metric = 6.11% * 100;
 Minibatch[1201-1300]: loss = 0.199879 * 100, metric = 6.17% * 100;
 Minibatch[1301-1400]: loss = 0.207171 * 100, metric = 6.54% * 100;
 Minibatch[1401-1500]: loss = 0.192793 * 100, metric = 5.90% * 100;
 Minibatch[1501-1600]: loss = 0.201399 * 100, metric = 6.18% * 100;
 Minibatch[1601-1700]: loss = 0.200276 * 100, metric = 6.38% * 100;
 Minibatch[1701-1800]: loss = 0.191450 * 100, metric = 5.90% * 100;
 Minibatch[1801-1900]: loss = 0.205688 * 100, metric = 6.35% * 100;
 Minibatch[1901-2000]: loss = 0.191097 * 100, metric = 5.98% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.198634 * 2000, metric = 6.12% * 2000 857.330s (  2.3 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 12.69% * 2000;
 Minibatch[   1- 100]: loss = 0.192862 * 100, metric = 5.96% * 100;
 Minibatch[ 101- 200]: loss = 0.184327 * 100, metric = 5.71% * 100;
 Minibatch[ 201- 300]: loss = 0.211216 * 100, metric = 6.75% * 100;
 Minibatch[ 301- 400]: loss = 0.198219 * 100, metric = 6.14% * 100;
 Minibatch[ 401- 500]: loss = 0.192650 * 100, metric = 5.86% * 100;
 Minibatch[ 501- 600]: loss = 0.196372 * 100, metric = 6.08% * 100;
 Minibatch[ 601- 700]: loss = 0.194118 * 100, metric = 5.86% * 100;
 Minibatch[ 701- 800]: loss = 0.185140 * 100, metric = 5.72% * 100;
 Minibatch[ 801- 900]: loss = 0.191530 * 100, metric = 5.85% * 100;
 Minibatch[ 901-1000]: loss = 0.203945 * 100, metric = 6.48% * 100;
 Minibatch[1001-1100]: loss = 0.204185 * 100, metric = 6.20% * 100;
 Minibatch[1101-1200]: loss = 0.196172 * 100, metric = 6.19% * 100;
 Minibatch[1201-1300]: loss = 0.201874 * 100, metric = 6.14% * 100;
 Minibatch[1301-1400]: loss = 0.184679 * 100, metric = 5.69% * 100;
 Minibatch[1401-1500]: loss = 0.190471 * 100, metric = 5.87% * 100;
 Minibatch[1501-1600]: loss = 0.193970 * 100, metric = 5.98% * 100;
 Minibatch[1601-1700]: loss = 0.207367 * 100, metric = 6.47% * 100;
 Minibatch[1701-1800]: loss = 0.200854 * 100, metric = 6.31% * 100;
 Minibatch[1801-1900]: loss = 0.197769 * 100, metric = 6.18% * 100;
 Minibatch[1901-2000]: loss = 0.192865 * 100, metric = 5.84% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.196029 * 2000, metric = 6.06% * 2000 841.460s (  2.4 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 12.94% * 2000;
 Minibatch[   1- 100]: loss = 0.193397 * 100, metric = 5.99% * 100;
 Minibatch[ 101- 200]: loss = 0.204431 * 100, metric = 6.34% * 100;
 Minibatch[ 201- 300]: loss = 0.198359 * 100, metric = 6.25% * 100;
 Minibatch[ 301- 400]: loss = 0.196790 * 100, metric = 6.12% * 100;
 Minibatch[ 401- 500]: loss = 0.194069 * 100, metric = 6.00% * 100;
 Minibatch[ 501- 600]: loss = 0.191752 * 100, metric = 5.91% * 100;
 Minibatch[ 601- 700]: loss = 0.195190 * 100, metric = 6.14% * 100;
 Minibatch[ 701- 800]: loss = 0.203540 * 100, metric = 6.39% * 100;
 Minibatch[ 801- 900]: loss = 0.196044 * 100, metric = 6.10% * 100;
 Minibatch[ 901-1000]: loss = 0.182894 * 100, metric = 5.56% * 100;
 Minibatch[1001-1100]: loss = 0.189712 * 100, metric = 5.95% * 100;
 Minibatch[1101-1200]: loss = 0.207184 * 100, metric = 6.37% * 100;
 Minibatch[1201-1300]: loss = 0.206006 * 100, metric = 6.43% * 100;
 Minibatch[1301-1400]: loss = 0.196180 * 100, metric = 6.11% * 100;
 Minibatch[1401-1500]: loss = 0.197547 * 100, metric = 6.01% * 100;
 Minibatch[1501-1600]: loss = 0.193536 * 100, metric = 5.96% * 100;
 Minibatch[1601-1700]: loss = 0.198589 * 100, metric = 6.31% * 100;
 Minibatch[1701-1800]: loss = 0.187362 * 100, metric = 5.75% * 100;
 Minibatch[1801-1900]: loss = 0.198530 * 100, metric = 6.31% * 100;
 Minibatch[1901-2000]: loss = 0.194973 * 100, metric = 6.02% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.196304 * 2000, metric = 6.10% * 2000 873.240s (  2.3 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.29% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
