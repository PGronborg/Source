Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.213014 * 100, metric = 25.22% * 100;
 Minibatch[ 101- 200]: loss = 1.000837 * 100, metric = 23.62% * 100;
 Minibatch[ 201- 300]: loss = 0.921032 * 100, metric = 22.51% * 100;
 Minibatch[ 301- 400]: loss = 0.912710 * 100, metric = 21.98% * 100;
 Minibatch[ 401- 500]: loss = 0.833575 * 100, metric = 20.50% * 100;
 Minibatch[ 501- 600]: loss = 0.815391 * 100, metric = 19.41% * 100;
 Minibatch[ 601- 700]: loss = 0.792264 * 100, metric = 18.78% * 100;
 Minibatch[ 701- 800]: loss = 0.746248 * 100, metric = 17.38% * 100;
 Minibatch[ 801- 900]: loss = 0.779844 * 100, metric = 18.16% * 100;
 Minibatch[ 901-1000]: loss = 0.784712 * 100, metric = 18.36% * 100;
 Minibatch[1001-1100]: loss = 0.765156 * 100, metric = 18.24% * 100;
 Minibatch[1101-1200]: loss = 0.735289 * 100, metric = 16.84% * 100;
 Minibatch[1201-1300]: loss = 0.740156 * 100, metric = 17.53% * 100;
 Minibatch[1301-1400]: loss = 0.711083 * 100, metric = 16.54% * 100;
 Minibatch[1401-1500]: loss = 0.731227 * 100, metric = 17.23% * 100;
 Minibatch[1501-1600]: loss = 0.699349 * 100, metric = 16.55% * 100;
 Minibatch[1601-1700]: loss = 0.690205 * 100, metric = 15.92% * 100;
 Minibatch[1701-1800]: loss = 0.704661 * 100, metric = 16.78% * 100;
 Minibatch[1801-1900]: loss = 0.697655 * 100, metric = 16.35% * 100;
 Minibatch[1901-2000]: loss = 0.674707 * 100, metric = 15.56% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.797456 * 2000, metric = 18.67% * 2000 870.320s (  2.3 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 24.30% * 2000;
0.7384174218028784
 Minibatch[   1- 100]: loss = 0.669727 * 100, metric = 15.43% * 100;
 Minibatch[ 101- 200]: loss = 0.675640 * 100, metric = 16.06% * 100;
 Minibatch[ 201- 300]: loss = 0.670556 * 100, metric = 15.15% * 100;
 Minibatch[ 301- 400]: loss = 0.676154 * 100, metric = 15.63% * 100;
 Minibatch[ 401- 500]: loss = 0.658682 * 100, metric = 15.26% * 100;
 Minibatch[ 501- 600]: loss = 0.682046 * 100, metric = 15.46% * 100;
 Minibatch[ 601- 700]: loss = 0.638481 * 100, metric = 15.04% * 100;
 Minibatch[ 701- 800]: loss = 0.660067 * 100, metric = 15.45% * 100;
 Minibatch[ 801- 900]: loss = 0.637798 * 100, metric = 14.86% * 100;
 Minibatch[ 901-1000]: loss = 0.622933 * 100, metric = 14.34% * 100;
 Minibatch[1001-1100]: loss = 0.641021 * 100, metric = 14.93% * 100;
 Minibatch[1101-1200]: loss = 0.644606 * 100, metric = 14.93% * 100;
 Minibatch[1201-1300]: loss = 0.631645 * 100, metric = 14.57% * 100;
 Minibatch[1301-1400]: loss = 0.640857 * 100, metric = 14.58% * 100;
 Minibatch[1401-1500]: loss = 0.618389 * 100, metric = 14.37% * 100;
 Minibatch[1501-1600]: loss = 0.622499 * 100, metric = 14.60% * 100;
 Minibatch[1601-1700]: loss = 0.623275 * 100, metric = 14.49% * 100;
 Minibatch[1701-1800]: loss = 0.628522 * 100, metric = 14.82% * 100;
 Minibatch[1801-1900]: loss = 0.634244 * 100, metric = 14.83% * 100;
 Minibatch[1901-2000]: loss = 0.598032 * 100, metric = 14.02% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.643759 * 2000, metric = 14.94% * 2000 821.403s (  2.4 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 20.60% * 2000;
0.6423408747538925
 Minibatch[   1- 100]: loss = 0.621607 * 100, metric = 14.38% * 100;
 Minibatch[ 101- 200]: loss = 0.624311 * 100, metric = 14.70% * 100;
 Minibatch[ 201- 300]: loss = 0.609220 * 100, metric = 14.05% * 100;
 Minibatch[ 301- 400]: loss = 0.619526 * 100, metric = 14.59% * 100;
 Minibatch[ 401- 500]: loss = 0.620581 * 100, metric = 14.75% * 100;
 Minibatch[ 501- 600]: loss = 0.614095 * 100, metric = 14.06% * 100;
 Minibatch[ 601- 700]: loss = 0.624213 * 100, metric = 14.47% * 100;
 Minibatch[ 701- 800]: loss = 0.600190 * 100, metric = 13.68% * 100;
 Minibatch[ 801- 900]: loss = 0.619191 * 100, metric = 14.59% * 100;
 Minibatch[ 901-1000]: loss = 0.594017 * 100, metric = 14.16% * 100;
 Minibatch[1001-1100]: loss = 0.608784 * 100, metric = 14.46% * 100;
 Minibatch[1101-1200]: loss = 0.592606 * 100, metric = 13.63% * 100;
 Minibatch[1201-1300]: loss = 0.592648 * 100, metric = 13.83% * 100;
 Minibatch[1301-1400]: loss = 0.604095 * 100, metric = 13.91% * 100;
 Minibatch[1401-1500]: loss = 0.603325 * 100, metric = 13.99% * 100;
 Minibatch[1501-1600]: loss = 0.585914 * 100, metric = 13.59% * 100;
 Minibatch[1601-1700]: loss = 0.576854 * 100, metric = 13.43% * 100;
 Minibatch[1701-1800]: loss = 0.602288 * 100, metric = 14.13% * 100;
 Minibatch[1801-1900]: loss = 0.578820 * 100, metric = 13.21% * 100;
 Minibatch[1901-2000]: loss = 0.577458 * 100, metric = 13.52% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.603487 * 2000, metric = 14.06% * 2000 818.680s (  2.4 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 19.36% * 2000;
0.6209403267651796
 Minibatch[   1- 100]: loss = 0.601729 * 100, metric = 13.55% * 100;
 Minibatch[ 101- 200]: loss = 0.570318 * 100, metric = 13.05% * 100;
 Minibatch[ 201- 300]: loss = 0.585139 * 100, metric = 13.40% * 100;
 Minibatch[ 301- 400]: loss = 0.549664 * 100, metric = 12.56% * 100;
 Minibatch[ 401- 500]: loss = 0.579240 * 100, metric = 13.11% * 100;
 Minibatch[ 501- 600]: loss = 0.558172 * 100, metric = 12.51% * 100;
 Minibatch[ 601- 700]: loss = 0.558490 * 100, metric = 13.09% * 100;
 Minibatch[ 701- 800]: loss = 0.573874 * 100, metric = 13.07% * 100;
 Minibatch[ 801- 900]: loss = 0.574372 * 100, metric = 13.29% * 100;
 Minibatch[ 901-1000]: loss = 0.570511 * 100, metric = 13.17% * 100;
 Minibatch[1001-1100]: loss = 0.585062 * 100, metric = 13.67% * 100;
 Minibatch[1101-1200]: loss = 0.557725 * 100, metric = 12.98% * 100;
 Minibatch[1201-1300]: loss = 0.555041 * 100, metric = 12.75% * 100;
 Minibatch[1301-1400]: loss = 0.579839 * 100, metric = 13.42% * 100;
 Minibatch[1401-1500]: loss = 0.580953 * 100, metric = 13.53% * 100;
 Minibatch[1501-1600]: loss = 0.544115 * 100, metric = 12.48% * 100;
 Minibatch[1601-1700]: loss = 0.561855 * 100, metric = 13.07% * 100;
 Minibatch[1701-1800]: loss = 0.566114 * 100, metric = 13.22% * 100;
 Minibatch[1801-1900]: loss = 0.557963 * 100, metric = 12.88% * 100;
 Minibatch[1901-2000]: loss = 0.553049 * 100, metric = 12.67% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.568161 * 2000, metric = 13.07% * 2000 819.404s (  2.4 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 21.93% * 2000;
 Minibatch[   1- 100]: loss = 0.567298 * 100, metric = 13.19% * 100;
 Minibatch[ 101- 200]: loss = 0.550746 * 100, metric = 12.48% * 100;
 Minibatch[ 201- 300]: loss = 0.541699 * 100, metric = 12.31% * 100;
 Minibatch[ 301- 400]: loss = 0.577155 * 100, metric = 13.64% * 100;
 Minibatch[ 401- 500]: loss = 0.528626 * 100, metric = 11.68% * 100;
 Minibatch[ 501- 600]: loss = 0.544403 * 100, metric = 12.17% * 100;
 Minibatch[ 601- 700]: loss = 0.538106 * 100, metric = 12.15% * 100;
 Minibatch[ 701- 800]: loss = 0.547888 * 100, metric = 12.29% * 100;
 Minibatch[ 801- 900]: loss = 0.531389 * 100, metric = 12.05% * 100;
 Minibatch[ 901-1000]: loss = 0.539401 * 100, metric = 12.40% * 100;
 Minibatch[1001-1100]: loss = 0.541163 * 100, metric = 12.29% * 100;
 Minibatch[1101-1200]: loss = 0.532232 * 100, metric = 12.33% * 100;
 Minibatch[1201-1300]: loss = 0.543612 * 100, metric = 12.52% * 100;
 Minibatch[1301-1400]: loss = 0.556846 * 100, metric = 13.10% * 100;
 Minibatch[1401-1500]: loss = 0.535792 * 100, metric = 12.40% * 100;
 Minibatch[1501-1600]: loss = 0.538884 * 100, metric = 12.43% * 100;
 Minibatch[1601-1700]: loss = 0.550396 * 100, metric = 12.79% * 100;
 Minibatch[1701-1800]: loss = 0.548060 * 100, metric = 12.75% * 100;
 Minibatch[1801-1900]: loss = 0.539714 * 100, metric = 12.58% * 100;
 Minibatch[1901-2000]: loss = 0.524020 * 100, metric = 11.79% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.543871 * 2000, metric = 12.47% * 2000 821.712s (  2.4 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.39% * 2000;
0.6201978480890393
 Minibatch[   1- 100]: loss = 0.515340 * 100, metric = 11.86% * 100;
 Minibatch[ 101- 200]: loss = 0.510624 * 100, metric = 11.51% * 100;
 Minibatch[ 201- 300]: loss = 0.525450 * 100, metric = 11.97% * 100;
 Minibatch[ 301- 400]: loss = 0.529508 * 100, metric = 11.87% * 100;
 Minibatch[ 401- 500]: loss = 0.502820 * 100, metric = 11.42% * 100;
 Minibatch[ 501- 600]: loss = 0.522721 * 100, metric = 12.06% * 100;
 Minibatch[ 601- 700]: loss = 0.517616 * 100, metric = 12.08% * 100;
 Minibatch[ 701- 800]: loss = 0.524089 * 100, metric = 11.84% * 100;
 Minibatch[ 801- 900]: loss = 0.527768 * 100, metric = 11.98% * 100;
 Minibatch[ 901-1000]: loss = 0.524412 * 100, metric = 12.36% * 100;
 Minibatch[1001-1100]: loss = 0.530525 * 100, metric = 11.98% * 100;
 Minibatch[1101-1200]: loss = 0.530873 * 100, metric = 12.13% * 100;
 Minibatch[1201-1300]: loss = 0.545192 * 100, metric = 12.68% * 100;
 Minibatch[1301-1400]: loss = 0.522001 * 100, metric = 12.30% * 100;
 Minibatch[1401-1500]: loss = 0.529939 * 100, metric = 12.29% * 100;
 Minibatch[1501-1600]: loss = 0.506827 * 100, metric = 11.48% * 100;
 Minibatch[1601-1700]: loss = 0.516501 * 100, metric = 11.70% * 100;
 Minibatch[1701-1800]: loss = 0.505340 * 100, metric = 11.58% * 100;
 Minibatch[1801-1900]: loss = 0.518807 * 100, metric = 11.92% * 100;
 Minibatch[1901-2000]: loss = 0.501593 * 100, metric = 11.51% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.520397 * 2000, metric = 11.93% * 2000 821.249s (  2.4 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 21.87% * 2000;
 Minibatch[   1- 100]: loss = 0.511513 * 100, metric = 11.85% * 100;
 Minibatch[ 101- 200]: loss = 0.521817 * 100, metric = 11.67% * 100;
 Minibatch[ 201- 300]: loss = 0.512965 * 100, metric = 11.52% * 100;
 Minibatch[ 301- 400]: loss = 0.502151 * 100, metric = 11.35% * 100;
 Minibatch[ 401- 500]: loss = 0.513971 * 100, metric = 11.69% * 100;
 Minibatch[ 501- 600]: loss = 0.491334 * 100, metric = 11.01% * 100;
 Minibatch[ 601- 700]: loss = 0.509637 * 100, metric = 11.57% * 100;
 Minibatch[ 701- 800]: loss = 0.512660 * 100, metric = 11.39% * 100;
 Minibatch[ 801- 900]: loss = 0.512187 * 100, metric = 11.89% * 100;
 Minibatch[ 901-1000]: loss = 0.503347 * 100, metric = 11.83% * 100;
 Minibatch[1001-1100]: loss = 0.509743 * 100, metric = 11.60% * 100;
 Minibatch[1101-1200]: loss = 0.489652 * 100, metric = 11.08% * 100;
 Minibatch[1201-1300]: loss = 0.510834 * 100, metric = 11.99% * 100;
 Minibatch[1301-1400]: loss = 0.496247 * 100, metric = 11.31% * 100;
 Minibatch[1401-1500]: loss = 0.485189 * 100, metric = 11.04% * 100;
 Minibatch[1501-1600]: loss = 0.504286 * 100, metric = 11.50% * 100;
 Minibatch[1601-1700]: loss = 0.511633 * 100, metric = 11.80% * 100;
 Minibatch[1701-1800]: loss = 0.499996 * 100, metric = 11.51% * 100;
 Minibatch[1801-1900]: loss = 0.508421 * 100, metric = 11.91% * 100;
 Minibatch[1901-2000]: loss = 0.510504 * 100, metric = 11.86% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.505904 * 2000, metric = 11.57% * 2000 814.386s (  2.5 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 19.19% * 2000;
0.5865343699231744
 Minibatch[   1- 100]: loss = 0.510327 * 100, metric = 11.94% * 100;
 Minibatch[ 101- 200]: loss = 0.496165 * 100, metric = 11.61% * 100;
 Minibatch[ 201- 300]: loss = 0.492085 * 100, metric = 11.69% * 100;
 Minibatch[ 301- 400]: loss = 0.499489 * 100, metric = 11.63% * 100;
 Minibatch[ 401- 500]: loss = 0.499511 * 100, metric = 11.63% * 100;
 Minibatch[ 501- 600]: loss = 0.512946 * 100, metric = 12.12% * 100;
 Minibatch[ 601- 700]: loss = 0.485898 * 100, metric = 11.21% * 100;
 Minibatch[ 701- 800]: loss = 0.502690 * 100, metric = 11.57% * 100;
 Minibatch[ 801- 900]: loss = 0.481191 * 100, metric = 10.70% * 100;
 Minibatch[ 901-1000]: loss = 0.472780 * 100, metric = 10.55% * 100;
 Minibatch[1001-1100]: loss = 0.473047 * 100, metric = 10.88% * 100;
 Minibatch[1101-1200]: loss = 0.469382 * 100, metric = 10.71% * 100;
 Minibatch[1201-1300]: loss = 0.497433 * 100, metric = 11.66% * 100;
 Minibatch[1301-1400]: loss = 0.502950 * 100, metric = 11.74% * 100;
 Minibatch[1401-1500]: loss = 0.489418 * 100, metric = 11.18% * 100;
 Minibatch[1501-1600]: loss = 0.487366 * 100, metric = 11.26% * 100;
 Minibatch[1601-1700]: loss = 0.479782 * 100, metric = 10.83% * 100;
 Minibatch[1701-1800]: loss = 0.487620 * 100, metric = 10.90% * 100;
 Minibatch[1801-1900]: loss = 0.483177 * 100, metric = 11.20% * 100;
 Minibatch[1901-2000]: loss = 0.484200 * 100, metric = 11.10% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.490373 * 2000, metric = 11.31% * 2000 813.774s (  2.5 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 18.83% * 2000;
0.5707473528534174
 Minibatch[   1- 100]: loss = 0.462643 * 100, metric = 10.30% * 100;
 Minibatch[ 101- 200]: loss = 0.500620 * 100, metric = 11.48% * 100;
 Minibatch[ 201- 300]: loss = 0.488778 * 100, metric = 11.21% * 100;
 Minibatch[ 301- 400]: loss = 0.497102 * 100, metric = 11.59% * 100;
 Minibatch[ 401- 500]: loss = 0.481443 * 100, metric = 10.92% * 100;
 Minibatch[ 501- 600]: loss = 0.470796 * 100, metric = 10.70% * 100;
 Minibatch[ 601- 700]: loss = 0.478579 * 100, metric = 10.90% * 100;
 Minibatch[ 701- 800]: loss = 0.463864 * 100, metric = 10.41% * 100;
 Minibatch[ 801- 900]: loss = 0.468408 * 100, metric = 10.86% * 100;
 Minibatch[ 901-1000]: loss = 0.476400 * 100, metric = 10.96% * 100;
 Minibatch[1001-1100]: loss = 0.455043 * 100, metric = 10.40% * 100;
 Minibatch[1101-1200]: loss = 0.476501 * 100, metric = 10.86% * 100;
 Minibatch[1201-1300]: loss = 0.468818 * 100, metric = 10.73% * 100;
 Minibatch[1301-1400]: loss = 0.463784 * 100, metric = 10.55% * 100;
 Minibatch[1401-1500]: loss = 0.481160 * 100, metric = 10.90% * 100;
 Minibatch[1501-1600]: loss = 0.476436 * 100, metric = 10.92% * 100;
 Minibatch[1601-1700]: loss = 0.474928 * 100, metric = 11.08% * 100;
 Minibatch[1701-1800]: loss = 0.464824 * 100, metric = 10.42% * 100;
 Minibatch[1801-1900]: loss = 0.472552 * 100, metric = 10.71% * 100;
 Minibatch[1901-2000]: loss = 0.475141 * 100, metric = 10.81% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.474891 * 2000, metric = 10.84% * 2000 816.916s (  2.4 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 17.55% * 2000;
0.5439395604729652
 Minibatch[   1- 100]: loss = 0.482890 * 100, metric = 11.59% * 100;
 Minibatch[ 101- 200]: loss = 0.464614 * 100, metric = 10.89% * 100;
 Minibatch[ 201- 300]: loss = 0.476333 * 100, metric = 11.07% * 100;
 Minibatch[ 301- 400]: loss = 0.463472 * 100, metric = 10.45% * 100;
 Minibatch[ 401- 500]: loss = 0.478699 * 100, metric = 11.04% * 100;
 Minibatch[ 501- 600]: loss = 0.448747 * 100, metric = 10.23% * 100;
 Minibatch[ 601- 700]: loss = 0.454820 * 100, metric = 10.05% * 100;
 Minibatch[ 701- 800]: loss = 0.441731 * 100, metric = 9.74% * 100;
 Minibatch[ 801- 900]: loss = 0.465592 * 100, metric = 10.61% * 100;
 Minibatch[ 901-1000]: loss = 0.465428 * 100, metric = 10.71% * 100;
 Minibatch[1001-1100]: loss = 0.465856 * 100, metric = 10.66% * 100;
 Minibatch[1101-1200]: loss = 0.464985 * 100, metric = 10.31% * 100;
 Minibatch[1201-1300]: loss = 0.459363 * 100, metric = 10.60% * 100;
 Minibatch[1301-1400]: loss = 0.461914 * 100, metric = 10.46% * 100;
 Minibatch[1401-1500]: loss = 0.449673 * 100, metric = 10.11% * 100;
 Minibatch[1501-1600]: loss = 0.458236 * 100, metric = 10.43% * 100;
 Minibatch[1601-1700]: loss = 0.446431 * 100, metric = 10.03% * 100;
 Minibatch[1701-1800]: loss = 0.468753 * 100, metric = 10.47% * 100;
 Minibatch[1801-1900]: loss = 0.467249 * 100, metric = 10.65% * 100;
 Minibatch[1901-2000]: loss = 0.449863 * 100, metric = 10.41% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.461732 * 2000, metric = 10.53% * 2000 816.986s (  2.4 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 17.23% * 2000;
0.5416848496794701
 Minibatch[   1- 100]: loss = 0.436561 * 100, metric = 9.91% * 100;
 Minibatch[ 101- 200]: loss = 0.456410 * 100, metric = 10.18% * 100;
 Minibatch[ 201- 300]: loss = 0.463508 * 100, metric = 10.80% * 100;
 Minibatch[ 301- 400]: loss = 0.451108 * 100, metric = 10.35% * 100;
 Minibatch[ 401- 500]: loss = 0.450899 * 100, metric = 10.37% * 100;
 Minibatch[ 501- 600]: loss = 0.455063 * 100, metric = 10.51% * 100;
 Minibatch[ 601- 700]: loss = 0.439915 * 100, metric = 9.91% * 100;
 Minibatch[ 701- 800]: loss = 0.459049 * 100, metric = 10.63% * 100;
 Minibatch[ 801- 900]: loss = 0.447698 * 100, metric = 9.93% * 100;
 Minibatch[ 901-1000]: loss = 0.453449 * 100, metric = 10.36% * 100;
 Minibatch[1001-1100]: loss = 0.449967 * 100, metric = 10.24% * 100;
 Minibatch[1101-1200]: loss = 0.456378 * 100, metric = 10.56% * 100;
 Minibatch[1201-1300]: loss = 0.440190 * 100, metric = 9.91% * 100;
 Minibatch[1301-1400]: loss = 0.429520 * 100, metric = 9.86% * 100;
 Minibatch[1401-1500]: loss = 0.446379 * 100, metric = 10.26% * 100;
 Minibatch[1501-1600]: loss = 0.427628 * 100, metric = 9.74% * 100;
 Minibatch[1601-1700]: loss = 0.436450 * 100, metric = 9.81% * 100;
 Minibatch[1701-1800]: loss = 0.456564 * 100, metric = 10.55% * 100;
 Minibatch[1801-1900]: loss = 0.446351 * 100, metric = 10.12% * 100;
 Minibatch[1901-2000]: loss = 0.444706 * 100, metric = 10.55% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.447390 * 2000, metric = 10.23% * 2000 810.061s (  2.5 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 17.54% * 2000;
 Minibatch[   1- 100]: loss = 0.422009 * 100, metric = 9.63% * 100;
 Minibatch[ 101- 200]: loss = 0.430133 * 100, metric = 9.56% * 100;
 Minibatch[ 201- 300]: loss = 0.433113 * 100, metric = 9.91% * 100;
 Minibatch[ 301- 400]: loss = 0.456102 * 100, metric = 10.54% * 100;
 Minibatch[ 401- 500]: loss = 0.427384 * 100, metric = 9.44% * 100;
 Minibatch[ 501- 600]: loss = 0.413524 * 100, metric = 9.03% * 100;
 Minibatch[ 601- 700]: loss = 0.428538 * 100, metric = 9.53% * 100;
 Minibatch[ 701- 800]: loss = 0.436524 * 100, metric = 9.94% * 100;
 Minibatch[ 801- 900]: loss = 0.426886 * 100, metric = 9.43% * 100;
 Minibatch[ 901-1000]: loss = 0.437510 * 100, metric = 10.05% * 100;
 Minibatch[1001-1100]: loss = 0.439541 * 100, metric = 10.30% * 100;
 Minibatch[1101-1200]: loss = 0.443898 * 100, metric = 10.02% * 100;
 Minibatch[1201-1300]: loss = 0.446324 * 100, metric = 10.24% * 100;
 Minibatch[1301-1400]: loss = 0.427820 * 100, metric = 9.68% * 100;
 Minibatch[1401-1500]: loss = 0.442479 * 100, metric = 10.31% * 100;
 Minibatch[1501-1600]: loss = 0.416535 * 100, metric = 9.52% * 100;
 Minibatch[1601-1700]: loss = 0.441127 * 100, metric = 9.96% * 100;
 Minibatch[1701-1800]: loss = 0.424739 * 100, metric = 9.54% * 100;
 Minibatch[1801-1900]: loss = 0.426732 * 100, metric = 9.83% * 100;
 Minibatch[1901-2000]: loss = 0.441259 * 100, metric = 10.19% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.433109 * 2000, metric = 9.83% * 2000 812.242s (  2.5 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 18.53% * 2000;
 Minibatch[   1- 100]: loss = 0.428176 * 100, metric = 9.72% * 100;
 Minibatch[ 101- 200]: loss = 0.433315 * 100, metric = 9.93% * 100;
 Minibatch[ 201- 300]: loss = 0.431825 * 100, metric = 9.84% * 100;
 Minibatch[ 301- 400]: loss = 0.433683 * 100, metric = 10.03% * 100;
 Minibatch[ 401- 500]: loss = 0.437386 * 100, metric = 10.21% * 100;
 Minibatch[ 501- 600]: loss = 0.446236 * 100, metric = 10.48% * 100;
 Minibatch[ 601- 700]: loss = 0.416332 * 100, metric = 9.09% * 100;
 Minibatch[ 701- 800]: loss = 0.418456 * 100, metric = 9.49% * 100;
 Minibatch[ 801- 900]: loss = 0.419293 * 100, metric = 9.64% * 100;
 Minibatch[ 901-1000]: loss = 0.430193 * 100, metric = 9.74% * 100;
 Minibatch[1001-1100]: loss = 0.434558 * 100, metric = 9.77% * 100;
 Minibatch[1101-1200]: loss = 0.422998 * 100, metric = 9.60% * 100;
 Minibatch[1201-1300]: loss = 0.427203 * 100, metric = 9.98% * 100;
 Minibatch[1301-1400]: loss = 0.418875 * 100, metric = 9.62% * 100;
 Minibatch[1401-1500]: loss = 0.419393 * 100, metric = 9.72% * 100;
 Minibatch[1501-1600]: loss = 0.409338 * 100, metric = 9.16% * 100;
 Minibatch[1601-1700]: loss = 0.406238 * 100, metric = 9.28% * 100;
 Minibatch[1701-1800]: loss = 0.420134 * 100, metric = 9.44% * 100;
 Minibatch[1801-1900]: loss = 0.410700 * 100, metric = 9.32% * 100;
 Minibatch[1901-2000]: loss = 0.422527 * 100, metric = 9.70% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.424343 * 2000, metric = 9.69% * 2000 805.077s (  2.5 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 20.09% * 2000;
 Minibatch[   1- 100]: loss = 0.416943 * 100, metric = 9.47% * 100;
 Minibatch[ 101- 200]: loss = 0.407556 * 100, metric = 9.22% * 100;
 Minibatch[ 201- 300]: loss = 0.420760 * 100, metric = 9.69% * 100;
 Minibatch[ 301- 400]: loss = 0.412908 * 100, metric = 9.40% * 100;
 Minibatch[ 401- 500]: loss = 0.416884 * 100, metric = 9.57% * 100;
 Minibatch[ 501- 600]: loss = 0.410844 * 100, metric = 9.23% * 100;
 Minibatch[ 601- 700]: loss = 0.412930 * 100, metric = 9.21% * 100;
 Minibatch[ 701- 800]: loss = 0.433738 * 100, metric = 10.07% * 100;
 Minibatch[ 801- 900]: loss = 0.431258 * 100, metric = 9.97% * 100;
 Minibatch[ 901-1000]: loss = 0.422056 * 100, metric = 9.81% * 100;
 Minibatch[1001-1100]: loss = 0.417511 * 100, metric = 9.71% * 100;
 Minibatch[1101-1200]: loss = 0.410374 * 100, metric = 9.35% * 100;
 Minibatch[1201-1300]: loss = 0.394080 * 100, metric = 8.84% * 100;
 Minibatch[1301-1400]: loss = 0.424069 * 100, metric = 9.85% * 100;
 Minibatch[1401-1500]: loss = 0.417715 * 100, metric = 9.55% * 100;
 Minibatch[1501-1600]: loss = 0.400071 * 100, metric = 9.21% * 100;
 Minibatch[1601-1700]: loss = 0.417130 * 100, metric = 9.61% * 100;
 Minibatch[1701-1800]: loss = 0.409104 * 100, metric = 9.07% * 100;
 Minibatch[1801-1900]: loss = 0.417590 * 100, metric = 9.51% * 100;
 Minibatch[1901-2000]: loss = 0.419733 * 100, metric = 9.48% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.415663 * 2000, metric = 9.49% * 2000 806.186s (  2.5 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 19.26% * 2000;
 Minibatch[   1- 100]: loss = 0.405890 * 100, metric = 9.18% * 100;
 Minibatch[ 101- 200]: loss = 0.412783 * 100, metric = 9.41% * 100;
 Minibatch[ 201- 300]: loss = 0.411601 * 100, metric = 9.33% * 100;
 Minibatch[ 301- 400]: loss = 0.394222 * 100, metric = 9.03% * 100;
 Minibatch[ 401- 500]: loss = 0.400427 * 100, metric = 9.03% * 100;
 Minibatch[ 501- 600]: loss = 0.392249 * 100, metric = 8.64% * 100;
 Minibatch[ 601- 700]: loss = 0.387502 * 100, metric = 8.75% * 100;
 Minibatch[ 701- 800]: loss = 0.401556 * 100, metric = 8.92% * 100;
 Minibatch[ 801- 900]: loss = 0.419233 * 100, metric = 9.64% * 100;
 Minibatch[ 901-1000]: loss = 0.408835 * 100, metric = 9.46% * 100;
 Minibatch[1001-1100]: loss = 0.410090 * 100, metric = 9.45% * 100;
 Minibatch[1101-1200]: loss = 0.400224 * 100, metric = 9.09% * 100;
 Minibatch[1201-1300]: loss = 0.388063 * 100, metric = 8.54% * 100;
 Minibatch[1301-1400]: loss = 0.415450 * 100, metric = 9.55% * 100;
 Minibatch[1401-1500]: loss = 0.381905 * 100, metric = 8.63% * 100;
 Minibatch[1501-1600]: loss = 0.394781 * 100, metric = 8.98% * 100;
 Minibatch[1601-1700]: loss = 0.399012 * 100, metric = 9.16% * 100;
 Minibatch[1701-1800]: loss = 0.381927 * 100, metric = 8.59% * 100;
 Minibatch[1801-1900]: loss = 0.392518 * 100, metric = 8.96% * 100;
 Minibatch[1901-2000]: loss = 0.398414 * 100, metric = 8.96% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.399834 * 2000, metric = 9.07% * 2000 833.650s (  2.4 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 16.30% * 2000;
0.5306432352140545
 Minibatch[   1- 100]: loss = 0.412309 * 100, metric = 9.57% * 100;
 Minibatch[ 101- 200]: loss = 0.400282 * 100, metric = 9.09% * 100;
 Minibatch[ 201- 300]: loss = 0.398904 * 100, metric = 8.97% * 100;
 Minibatch[ 301- 400]: loss = 0.401957 * 100, metric = 8.89% * 100;
 Minibatch[ 401- 500]: loss = 0.383575 * 100, metric = 8.59% * 100;
 Minibatch[ 501- 600]: loss = 0.396807 * 100, metric = 8.96% * 100;
 Minibatch[ 601- 700]: loss = 0.392891 * 100, metric = 8.98% * 100;
 Minibatch[ 701- 800]: loss = 0.390027 * 100, metric = 8.88% * 100;
 Minibatch[ 801- 900]: loss = 0.380821 * 100, metric = 8.54% * 100;
 Minibatch[ 901-1000]: loss = 0.397534 * 100, metric = 9.30% * 100;
 Minibatch[1001-1100]: loss = 0.379687 * 100, metric = 8.53% * 100;
 Minibatch[1101-1200]: loss = 0.381564 * 100, metric = 8.49% * 100;
 Minibatch[1201-1300]: loss = 0.373269 * 100, metric = 8.26% * 100;
 Minibatch[1301-1400]: loss = 0.385569 * 100, metric = 8.71% * 100;
 Minibatch[1401-1500]: loss = 0.379669 * 100, metric = 8.75% * 100;
 Minibatch[1501-1600]: loss = 0.385446 * 100, metric = 8.78% * 100;
 Minibatch[1601-1700]: loss = 0.388412 * 100, metric = 8.73% * 100;
 Minibatch[1701-1800]: loss = 0.401442 * 100, metric = 8.85% * 100;
 Minibatch[1801-1900]: loss = 0.388123 * 100, metric = 8.84% * 100;
 Minibatch[1901-2000]: loss = 0.383553 * 100, metric = 8.71% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.390092 * 2000, metric = 8.82% * 2000 821.985s (  2.4 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 16.15% * 2000;
0.5304895526021719
 Minibatch[   1- 100]: loss = 0.372123 * 100, metric = 8.30% * 100;
 Minibatch[ 101- 200]: loss = 0.394723 * 100, metric = 8.82% * 100;
 Minibatch[ 201- 300]: loss = 0.385199 * 100, metric = 8.56% * 100;
 Minibatch[ 301- 400]: loss = 0.383675 * 100, metric = 8.86% * 100;
 Minibatch[ 401- 500]: loss = 0.392450 * 100, metric = 8.63% * 100;
 Minibatch[ 501- 600]: loss = 0.378052 * 100, metric = 8.38% * 100;
 Minibatch[ 601- 700]: loss = 0.359020 * 100, metric = 7.89% * 100;
 Minibatch[ 701- 800]: loss = 0.370695 * 100, metric = 8.21% * 100;
 Minibatch[ 801- 900]: loss = 0.382443 * 100, metric = 8.48% * 100;
 Minibatch[ 901-1000]: loss = 0.369228 * 100, metric = 8.27% * 100;
 Minibatch[1001-1100]: loss = 0.370101 * 100, metric = 8.19% * 100;
 Minibatch[1101-1200]: loss = 0.384424 * 100, metric = 8.74% * 100;
 Minibatch[1201-1300]: loss = 0.381001 * 100, metric = 8.58% * 100;
 Minibatch[1301-1400]: loss = 0.362111 * 100, metric = 7.96% * 100;
 Minibatch[1401-1500]: loss = 0.373822 * 100, metric = 8.32% * 100;
 Minibatch[1501-1600]: loss = 0.372872 * 100, metric = 8.36% * 100;
 Minibatch[1601-1700]: loss = 0.376091 * 100, metric = 8.29% * 100;
 Minibatch[1701-1800]: loss = 0.365560 * 100, metric = 8.20% * 100;
 Minibatch[1801-1900]: loss = 0.388113 * 100, metric = 8.82% * 100;
 Minibatch[1901-2000]: loss = 0.388003 * 100, metric = 8.83% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.377485 * 2000, metric = 8.43% * 2000 818.185s (  2.4 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 15.80% * 2000;
0.5156662974134087
 Minibatch[   1- 100]: loss = 0.358572 * 100, metric = 7.88% * 100;
 Minibatch[ 101- 200]: loss = 0.388776 * 100, metric = 8.58% * 100;
 Minibatch[ 201- 300]: loss = 0.370516 * 100, metric = 8.43% * 100;
 Minibatch[ 301- 400]: loss = 0.374619 * 100, metric = 8.45% * 100;
 Minibatch[ 401- 500]: loss = 0.360023 * 100, metric = 7.92% * 100;
 Minibatch[ 501- 600]: loss = 0.362524 * 100, metric = 7.92% * 100;
 Minibatch[ 601- 700]: loss = 0.378933 * 100, metric = 8.60% * 100;
 Minibatch[ 701- 800]: loss = 0.366647 * 100, metric = 8.36% * 100;
 Minibatch[ 801- 900]: loss = 0.377381 * 100, metric = 8.39% * 100;
 Minibatch[ 901-1000]: loss = 0.377084 * 100, metric = 8.49% * 100;
 Minibatch[1001-1100]: loss = 0.382858 * 100, metric = 8.82% * 100;
 Minibatch[1101-1200]: loss = 0.377479 * 100, metric = 8.43% * 100;
 Minibatch[1201-1300]: loss = 0.388993 * 100, metric = 8.77% * 100;
 Minibatch[1301-1400]: loss = 0.380097 * 100, metric = 8.57% * 100;
 Minibatch[1401-1500]: loss = 0.358798 * 100, metric = 7.95% * 100;
 Minibatch[1501-1600]: loss = 0.370388 * 100, metric = 8.15% * 100;
 Minibatch[1601-1700]: loss = 0.357566 * 100, metric = 7.76% * 100;
 Minibatch[1701-1800]: loss = 0.361864 * 100, metric = 8.02% * 100;
 Minibatch[1801-1900]: loss = 0.360594 * 100, metric = 8.05% * 100;
 Minibatch[1901-2000]: loss = 0.358333 * 100, metric = 8.04% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.370602 * 2000, metric = 8.28% * 2000 809.939s (  2.5 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 16.38% * 2000;
 Minibatch[   1- 100]: loss = 0.375536 * 100, metric = 8.51% * 100;
 Minibatch[ 101- 200]: loss = 0.379198 * 100, metric = 8.51% * 100;
 Minibatch[ 201- 300]: loss = 0.349255 * 100, metric = 7.58% * 100;
 Minibatch[ 301- 400]: loss = 0.369107 * 100, metric = 8.17% * 100;
 Minibatch[ 401- 500]: loss = 0.364887 * 100, metric = 8.04% * 100;
 Minibatch[ 501- 600]: loss = 0.355438 * 100, metric = 7.76% * 100;
 Minibatch[ 601- 700]: loss = 0.367613 * 100, metric = 8.11% * 100;
 Minibatch[ 701- 800]: loss = 0.351109 * 100, metric = 7.69% * 100;
 Minibatch[ 801- 900]: loss = 0.381608 * 100, metric = 8.33% * 100;
 Minibatch[ 901-1000]: loss = 0.357246 * 100, metric = 7.83% * 100;
 Minibatch[1001-1100]: loss = 0.371712 * 100, metric = 8.27% * 100;
 Minibatch[1101-1200]: loss = 0.363826 * 100, metric = 8.31% * 100;
 Minibatch[1201-1300]: loss = 0.357014 * 100, metric = 7.95% * 100;
 Minibatch[1301-1400]: loss = 0.348581 * 100, metric = 7.75% * 100;
 Minibatch[1401-1500]: loss = 0.359992 * 100, metric = 7.99% * 100;
 Minibatch[1501-1600]: loss = 0.362615 * 100, metric = 7.86% * 100;
 Minibatch[1601-1700]: loss = 0.349682 * 100, metric = 7.78% * 100;
 Minibatch[1701-1800]: loss = 0.340710 * 100, metric = 7.56% * 100;
 Minibatch[1801-1900]: loss = 0.354633 * 100, metric = 7.86% * 100;
 Minibatch[1901-2000]: loss = 0.344749 * 100, metric = 7.46% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.360225 * 2000, metric = 7.97% * 2000 814.839s (  2.5 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 16.90% * 2000;
 Minibatch[   1- 100]: loss = 0.347802 * 100, metric = 7.48% * 100;
 Minibatch[ 101- 200]: loss = 0.349495 * 100, metric = 7.75% * 100;
 Minibatch[ 201- 300]: loss = 0.349520 * 100, metric = 7.66% * 100;
 Minibatch[ 301- 400]: loss = 0.374817 * 100, metric = 8.10% * 100;
 Minibatch[ 401- 500]: loss = 0.355668 * 100, metric = 7.85% * 100;
 Minibatch[ 501- 600]: loss = 0.360840 * 100, metric = 8.11% * 100;
 Minibatch[ 601- 700]: loss = 0.362959 * 100, metric = 8.06% * 100;
 Minibatch[ 701- 800]: loss = 0.358858 * 100, metric = 8.05% * 100;
 Minibatch[ 801- 900]: loss = 0.363988 * 100, metric = 8.12% * 100;
 Minibatch[ 901-1000]: loss = 0.363244 * 100, metric = 8.11% * 100;
 Minibatch[1001-1100]: loss = 0.338446 * 100, metric = 7.39% * 100;
 Minibatch[1101-1200]: loss = 0.355045 * 100, metric = 7.91% * 100;
 Minibatch[1201-1300]: loss = 0.366628 * 100, metric = 8.21% * 100;
 Minibatch[1301-1400]: loss = 0.363332 * 100, metric = 8.13% * 100;
 Minibatch[1401-1500]: loss = 0.349755 * 100, metric = 7.77% * 100;
 Minibatch[1501-1600]: loss = 0.372366 * 100, metric = 8.16% * 100;
 Minibatch[1601-1700]: loss = 0.351082 * 100, metric = 7.87% * 100;
 Minibatch[1701-1800]: loss = 0.366040 * 100, metric = 8.15% * 100;
 Minibatch[1801-1900]: loss = 0.355573 * 100, metric = 7.89% * 100;
 Minibatch[1901-2000]: loss = 0.352971 * 100, metric = 7.86% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.357921 * 2000, metric = 7.93% * 2000 810.251s (  2.5 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 17.72% * 2000;
 Minibatch[   1- 100]: loss = 0.351398 * 100, metric = 7.69% * 100;
 Minibatch[ 101- 200]: loss = 0.350082 * 100, metric = 7.83% * 100;
 Minibatch[ 201- 300]: loss = 0.344054 * 100, metric = 7.68% * 100;
 Minibatch[ 301- 400]: loss = 0.360882 * 100, metric = 8.05% * 100;
 Minibatch[ 401- 500]: loss = 0.342993 * 100, metric = 7.58% * 100;
 Minibatch[ 501- 600]: loss = 0.347584 * 100, metric = 7.71% * 100;
 Minibatch[ 601- 700]: loss = 0.349044 * 100, metric = 7.86% * 100;
 Minibatch[ 701- 800]: loss = 0.326114 * 100, metric = 7.14% * 100;
 Minibatch[ 801- 900]: loss = 0.355007 * 100, metric = 7.89% * 100;
 Minibatch[ 901-1000]: loss = 0.336588 * 100, metric = 7.41% * 100;
 Minibatch[1001-1100]: loss = 0.339490 * 100, metric = 7.50% * 100;
 Minibatch[1101-1200]: loss = 0.340236 * 100, metric = 7.38% * 100;
 Minibatch[1201-1300]: loss = 0.349900 * 100, metric = 7.66% * 100;
 Minibatch[1301-1400]: loss = 0.333273 * 100, metric = 7.22% * 100;
 Minibatch[1401-1500]: loss = 0.353998 * 100, metric = 7.82% * 100;
 Minibatch[1501-1600]: loss = 0.361444 * 100, metric = 8.16% * 100;
 Minibatch[1601-1700]: loss = 0.345153 * 100, metric = 7.71% * 100;
 Minibatch[1701-1800]: loss = 0.346652 * 100, metric = 7.54% * 100;
 Minibatch[1801-1900]: loss = 0.355155 * 100, metric = 8.00% * 100;
 Minibatch[1901-2000]: loss = 0.338497 * 100, metric = 7.46% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.346377 * 2000, metric = 7.66% * 2000 805.545s (  2.5 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 15.22% * 2000;
0.5026312016732991
 Minibatch[   1- 100]: loss = 0.349260 * 100, metric = 7.82% * 100;
 Minibatch[ 101- 200]: loss = 0.348937 * 100, metric = 7.68% * 100;
 Minibatch[ 201- 300]: loss = 0.344205 * 100, metric = 7.65% * 100;
 Minibatch[ 301- 400]: loss = 0.347728 * 100, metric = 7.71% * 100;
 Minibatch[ 401- 500]: loss = 0.336273 * 100, metric = 7.45% * 100;
 Minibatch[ 501- 600]: loss = 0.346319 * 100, metric = 7.63% * 100;
 Minibatch[ 601- 700]: loss = 0.339014 * 100, metric = 7.41% * 100;
 Minibatch[ 701- 800]: loss = 0.335900 * 100, metric = 7.60% * 100;
 Minibatch[ 801- 900]: loss = 0.346312 * 100, metric = 7.61% * 100;
 Minibatch[ 901-1000]: loss = 0.352500 * 100, metric = 7.78% * 100;
 Minibatch[1001-1100]: loss = 0.335913 * 100, metric = 7.37% * 100;
 Minibatch[1101-1200]: loss = 0.322569 * 100, metric = 6.84% * 100;
 Minibatch[1201-1300]: loss = 0.330121 * 100, metric = 7.28% * 100;
 Minibatch[1301-1400]: loss = 0.342682 * 100, metric = 7.62% * 100;
 Minibatch[1401-1500]: loss = 0.335921 * 100, metric = 7.41% * 100;
 Minibatch[1501-1600]: loss = 0.330283 * 100, metric = 7.24% * 100;
 Minibatch[1601-1700]: loss = 0.339127 * 100, metric = 7.49% * 100;
 Minibatch[1701-1800]: loss = 0.338043 * 100, metric = 7.21% * 100;
 Minibatch[1801-1900]: loss = 0.339263 * 100, metric = 7.48% * 100;
 Minibatch[1901-2000]: loss = 0.343787 * 100, metric = 7.33% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.340208 * 2000, metric = 7.48% * 2000 795.881s (  2.5 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 15.45% * 2000;
 Minibatch[   1- 100]: loss = 0.347269 * 100, metric = 7.63% * 100;
 Minibatch[ 101- 200]: loss = 0.353529 * 100, metric = 7.92% * 100;
 Minibatch[ 201- 300]: loss = 0.343800 * 100, metric = 7.60% * 100;
 Minibatch[ 301- 400]: loss = 0.352815 * 100, metric = 7.74% * 100;
 Minibatch[ 401- 500]: loss = 0.350995 * 100, metric = 7.70% * 100;
 Minibatch[ 501- 600]: loss = 0.343931 * 100, metric = 7.44% * 100;
 Minibatch[ 601- 700]: loss = 0.337780 * 100, metric = 7.25% * 100;
 Minibatch[ 701- 800]: loss = 0.323669 * 100, metric = 7.10% * 100;
 Minibatch[ 801- 900]: loss = 0.333072 * 100, metric = 7.32% * 100;
 Minibatch[ 901-1000]: loss = 0.339098 * 100, metric = 7.46% * 100;
 Minibatch[1001-1100]: loss = 0.338717 * 100, metric = 7.42% * 100;
 Minibatch[1101-1200]: loss = 0.339344 * 100, metric = 7.51% * 100;
 Minibatch[1201-1300]: loss = 0.339901 * 100, metric = 7.65% * 100;
 Minibatch[1301-1400]: loss = 0.346185 * 100, metric = 7.67% * 100;
 Minibatch[1401-1500]: loss = 0.326420 * 100, metric = 7.36% * 100;
 Minibatch[1501-1600]: loss = 0.331616 * 100, metric = 7.28% * 100;
 Minibatch[1601-1700]: loss = 0.338820 * 100, metric = 7.52% * 100;
 Minibatch[1701-1800]: loss = 0.340476 * 100, metric = 7.60% * 100;
 Minibatch[1801-1900]: loss = 0.337986 * 100, metric = 7.65% * 100;
 Minibatch[1901-2000]: loss = 0.341628 * 100, metric = 7.52% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.340353 * 2000, metric = 7.52% * 2000 796.527s (  2.5 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 15.98% * 2000;
 Minibatch[   1- 100]: loss = 0.325690 * 100, metric = 7.23% * 100;
 Minibatch[ 101- 200]: loss = 0.339564 * 100, metric = 7.64% * 100;
 Minibatch[ 201- 300]: loss = 0.332396 * 100, metric = 7.49% * 100;
 Minibatch[ 301- 400]: loss = 0.331647 * 100, metric = 7.40% * 100;
 Minibatch[ 401- 500]: loss = 0.343675 * 100, metric = 7.54% * 100;
 Minibatch[ 501- 600]: loss = 0.329615 * 100, metric = 7.34% * 100;
 Minibatch[ 601- 700]: loss = 0.339677 * 100, metric = 7.44% * 100;
 Minibatch[ 701- 800]: loss = 0.333867 * 100, metric = 7.45% * 100;
 Minibatch[ 801- 900]: loss = 0.337177 * 100, metric = 7.59% * 100;
 Minibatch[ 901-1000]: loss = 0.341894 * 100, metric = 7.57% * 100;
 Minibatch[1001-1100]: loss = 0.330710 * 100, metric = 7.31% * 100;
 Minibatch[1101-1200]: loss = 0.352509 * 100, metric = 7.96% * 100;
 Minibatch[1201-1300]: loss = 0.338082 * 100, metric = 7.49% * 100;
 Minibatch[1301-1400]: loss = 0.329775 * 100, metric = 7.22% * 100;
 Minibatch[1401-1500]: loss = 0.326887 * 100, metric = 7.12% * 100;
 Minibatch[1501-1600]: loss = 0.339656 * 100, metric = 7.41% * 100;
 Minibatch[1601-1700]: loss = 0.321785 * 100, metric = 6.98% * 100;
 Minibatch[1701-1800]: loss = 0.320526 * 100, metric = 6.99% * 100;
 Minibatch[1801-1900]: loss = 0.338466 * 100, metric = 7.42% * 100;
 Minibatch[1901-2000]: loss = 0.342405 * 100, metric = 7.63% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.334800 * 2000, metric = 7.41% * 2000 801.533s (  2.5 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 15.76% * 2000;
 Minibatch[   1- 100]: loss = 0.338580 * 100, metric = 7.45% * 100;
 Minibatch[ 101- 200]: loss = 0.335274 * 100, metric = 7.42% * 100;
 Minibatch[ 201- 300]: loss = 0.331962 * 100, metric = 7.41% * 100;
 Minibatch[ 301- 400]: loss = 0.332700 * 100, metric = 7.28% * 100;
 Minibatch[ 401- 500]: loss = 0.333362 * 100, metric = 7.32% * 100;
 Minibatch[ 501- 600]: loss = 0.332572 * 100, metric = 7.54% * 100;
 Minibatch[ 601- 700]: loss = 0.334898 * 100, metric = 7.34% * 100;
 Minibatch[ 701- 800]: loss = 0.321931 * 100, metric = 6.95% * 100;
 Minibatch[ 801- 900]: loss = 0.321159 * 100, metric = 7.02% * 100;
 Minibatch[ 901-1000]: loss = 0.330744 * 100, metric = 7.42% * 100;
 Minibatch[1001-1100]: loss = 0.327244 * 100, metric = 7.29% * 100;
 Minibatch[1101-1200]: loss = 0.337073 * 100, metric = 7.35% * 100;
 Minibatch[1201-1300]: loss = 0.343870 * 100, metric = 7.65% * 100;
 Minibatch[1301-1400]: loss = 0.322739 * 100, metric = 6.87% * 100;
 Minibatch[1401-1500]: loss = 0.318709 * 100, metric = 6.67% * 100;
 Minibatch[1501-1600]: loss = 0.338304 * 100, metric = 7.51% * 100;
 Minibatch[1601-1700]: loss = 0.327471 * 100, metric = 7.22% * 100;
 Minibatch[1701-1800]: loss = 0.331599 * 100, metric = 7.43% * 100;
 Minibatch[1801-1900]: loss = 0.317685 * 100, metric = 6.75% * 100;
 Minibatch[1901-2000]: loss = 0.312211 * 100, metric = 6.61% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.329504 * 2000, metric = 7.22% * 2000 794.790s (  2.5 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 15.25% * 2000;
 Minibatch[   1- 100]: loss = 0.326269 * 100, metric = 7.11% * 100;
 Minibatch[ 101- 200]: loss = 0.310321 * 100, metric = 6.59% * 100;
 Minibatch[ 201- 300]: loss = 0.326355 * 100, metric = 7.13% * 100;
 Minibatch[ 301- 400]: loss = 0.312943 * 100, metric = 6.92% * 100;
 Minibatch[ 401- 500]: loss = 0.323651 * 100, metric = 7.08% * 100;
 Minibatch[ 501- 600]: loss = 0.321155 * 100, metric = 6.92% * 100;
 Minibatch[ 601- 700]: loss = 0.330533 * 100, metric = 7.25% * 100;
 Minibatch[ 701- 800]: loss = 0.319099 * 100, metric = 7.16% * 100;
 Minibatch[ 801- 900]: loss = 0.309629 * 100, metric = 6.79% * 100;
 Minibatch[ 901-1000]: loss = 0.308273 * 100, metric = 6.67% * 100;
 Minibatch[1001-1100]: loss = 0.326372 * 100, metric = 7.35% * 100;
 Minibatch[1101-1200]: loss = 0.332955 * 100, metric = 7.39% * 100;
 Minibatch[1201-1300]: loss = 0.320834 * 100, metric = 7.03% * 100;
 Minibatch[1301-1400]: loss = 0.306580 * 100, metric = 6.58% * 100;
 Minibatch[1401-1500]: loss = 0.321380 * 100, metric = 7.10% * 100;
 Minibatch[1501-1600]: loss = 0.310630 * 100, metric = 6.59% * 100;
 Minibatch[1601-1700]: loss = 0.334189 * 100, metric = 7.33% * 100;
 Minibatch[1701-1800]: loss = 0.330846 * 100, metric = 7.24% * 100;
 Minibatch[1801-1900]: loss = 0.320323 * 100, metric = 7.06% * 100;
 Minibatch[1901-2000]: loss = 0.315970 * 100, metric = 6.79% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.320415 * 2000, metric = 7.00% * 2000 791.729s (  2.5 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.73% * 2000;
 Minibatch[   1- 100]: loss = 0.314009 * 100, metric = 6.86% * 100;
 Minibatch[ 101- 200]: loss = 0.323242 * 100, metric = 7.01% * 100;
 Minibatch[ 201- 300]: loss = 0.312178 * 100, metric = 6.95% * 100;
 Minibatch[ 301- 400]: loss = 0.310440 * 100, metric = 6.72% * 100;
 Minibatch[ 401- 500]: loss = 0.317737 * 100, metric = 6.91% * 100;
 Minibatch[ 501- 600]: loss = 0.309407 * 100, metric = 6.66% * 100;
 Minibatch[ 601- 700]: loss = 0.307196 * 100, metric = 6.68% * 100;
 Minibatch[ 701- 800]: loss = 0.315353 * 100, metric = 6.88% * 100;
 Minibatch[ 801- 900]: loss = 0.322131 * 100, metric = 6.98% * 100;
 Minibatch[ 901-1000]: loss = 0.313681 * 100, metric = 6.87% * 100;
 Minibatch[1001-1100]: loss = 0.304565 * 100, metric = 6.38% * 100;
 Minibatch[1101-1200]: loss = 0.323971 * 100, metric = 7.02% * 100;
 Minibatch[1201-1300]: loss = 0.312623 * 100, metric = 6.78% * 100;
 Minibatch[1301-1400]: loss = 0.329300 * 100, metric = 7.38% * 100;
 Minibatch[1401-1500]: loss = 0.309984 * 100, metric = 6.71% * 100;
 Minibatch[1501-1600]: loss = 0.317673 * 100, metric = 6.93% * 100;
 Minibatch[1601-1700]: loss = 0.304853 * 100, metric = 6.49% * 100;
 Minibatch[1701-1800]: loss = 0.305941 * 100, metric = 6.47% * 100;
 Minibatch[1801-1900]: loss = 0.307770 * 100, metric = 6.70% * 100;
 Minibatch[1901-2000]: loss = 0.315533 * 100, metric = 6.77% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.313879 * 2000, metric = 6.81% * 2000 787.626s (  2.5 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 14.65% * 2000;
 Minibatch[   1- 100]: loss = 0.311234 * 100, metric = 6.79% * 100;
 Minibatch[ 101- 200]: loss = 0.301793 * 100, metric = 6.44% * 100;
 Minibatch[ 201- 300]: loss = 0.313891 * 100, metric = 6.74% * 100;
 Minibatch[ 301- 400]: loss = 0.308987 * 100, metric = 6.69% * 100;
 Minibatch[ 401- 500]: loss = 0.312821 * 100, metric = 6.84% * 100;
 Minibatch[ 501- 600]: loss = 0.326107 * 100, metric = 7.29% * 100;
 Minibatch[ 601- 700]: loss = 0.303985 * 100, metric = 6.58% * 100;
 Minibatch[ 701- 800]: loss = 0.297342 * 100, metric = 6.35% * 100;
 Minibatch[ 801- 900]: loss = 0.313576 * 100, metric = 6.83% * 100;
 Minibatch[ 901-1000]: loss = 0.324158 * 100, metric = 7.43% * 100;
 Minibatch[1001-1100]: loss = 0.313548 * 100, metric = 6.89% * 100;
 Minibatch[1101-1200]: loss = 0.304319 * 100, metric = 6.61% * 100;
 Minibatch[1201-1300]: loss = 0.316250 * 100, metric = 6.92% * 100;
 Minibatch[1301-1400]: loss = 0.309864 * 100, metric = 6.66% * 100;
 Minibatch[1401-1500]: loss = 0.316183 * 100, metric = 6.92% * 100;
 Minibatch[1501-1600]: loss = 0.309626 * 100, metric = 6.76% * 100;
 Minibatch[1601-1700]: loss = 0.310096 * 100, metric = 6.63% * 100;
 Minibatch[1701-1800]: loss = 0.302949 * 100, metric = 6.56% * 100;
 Minibatch[1801-1900]: loss = 0.316050 * 100, metric = 7.03% * 100;
 Minibatch[1901-2000]: loss = 0.316788 * 100, metric = 6.81% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.311478 * 2000, metric = 6.79% * 2000 788.206s (  2.5 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 15.19% * 2000;
 Minibatch[   1- 100]: loss = 0.297762 * 100, metric = 6.51% * 100;
 Minibatch[ 101- 200]: loss = 0.306718 * 100, metric = 6.70% * 100;
 Minibatch[ 201- 300]: loss = 0.312808 * 100, metric = 7.01% * 100;
 Minibatch[ 301- 400]: loss = 0.324447 * 100, metric = 7.26% * 100;
 Minibatch[ 401- 500]: loss = 0.299507 * 100, metric = 6.50% * 100;
 Minibatch[ 501- 600]: loss = 0.308608 * 100, metric = 6.78% * 100;
 Minibatch[ 601- 700]: loss = 0.305701 * 100, metric = 6.69% * 100;
 Minibatch[ 701- 800]: loss = 0.321273 * 100, metric = 7.10% * 100;
 Minibatch[ 801- 900]: loss = 0.305823 * 100, metric = 6.80% * 100;
 Minibatch[ 901-1000]: loss = 0.311876 * 100, metric = 6.85% * 100;
 Minibatch[1001-1100]: loss = 0.302564 * 100, metric = 6.57% * 100;
 Minibatch[1101-1200]: loss = 0.299191 * 100, metric = 6.61% * 100;
 Minibatch[1201-1300]: loss = 0.310005 * 100, metric = 6.77% * 100;
 Minibatch[1301-1400]: loss = 0.294277 * 100, metric = 6.30% * 100;
 Minibatch[1401-1500]: loss = 0.319458 * 100, metric = 6.94% * 100;
 Minibatch[1501-1600]: loss = 0.298082 * 100, metric = 6.37% * 100;
 Minibatch[1601-1700]: loss = 0.315399 * 100, metric = 6.88% * 100;
 Minibatch[1701-1800]: loss = 0.293920 * 100, metric = 6.36% * 100;
 Minibatch[1801-1900]: loss = 0.318686 * 100, metric = 7.13% * 100;
 Minibatch[1901-2000]: loss = 0.306108 * 100, metric = 6.63% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.307611 * 2000, metric = 6.74% * 2000 790.492s (  2.5 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 15.98% * 2000;
 Minibatch[   1- 100]: loss = 0.323844 * 100, metric = 7.25% * 100;
 Minibatch[ 101- 200]: loss = 0.289104 * 100, metric = 6.14% * 100;
 Minibatch[ 201- 300]: loss = 0.299382 * 100, metric = 6.57% * 100;
 Minibatch[ 301- 400]: loss = 0.303814 * 100, metric = 6.67% * 100;
 Minibatch[ 401- 500]: loss = 0.308734 * 100, metric = 6.73% * 100;
 Minibatch[ 501- 600]: loss = 0.291911 * 100, metric = 6.27% * 100;
 Minibatch[ 601- 700]: loss = 0.302995 * 100, metric = 6.72% * 100;
 Minibatch[ 701- 800]: loss = 0.297825 * 100, metric = 6.11% * 100;
 Minibatch[ 801- 900]: loss = 0.314906 * 100, metric = 6.86% * 100;
 Minibatch[ 901-1000]: loss = 0.286559 * 100, metric = 6.04% * 100;
 Minibatch[1001-1100]: loss = 0.298331 * 100, metric = 6.31% * 100;
 Minibatch[1101-1200]: loss = 0.307944 * 100, metric = 6.76% * 100;
 Minibatch[1201-1300]: loss = 0.294312 * 100, metric = 6.28% * 100;
 Minibatch[1301-1400]: loss = 0.302146 * 100, metric = 6.55% * 100;
 Minibatch[1401-1500]: loss = 0.297578 * 100, metric = 6.46% * 100;
 Minibatch[1501-1600]: loss = 0.306311 * 100, metric = 6.72% * 100;
 Minibatch[1601-1700]: loss = 0.299669 * 100, metric = 6.53% * 100;
 Minibatch[1701-1800]: loss = 0.303808 * 100, metric = 6.56% * 100;
 Minibatch[1801-1900]: loss = 0.305496 * 100, metric = 6.64% * 100;
 Minibatch[1901-2000]: loss = 0.313265 * 100, metric = 6.86% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.302397 * 2000, metric = 6.55% * 2000 788.009s (  2.5 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 15.15% * 2000;
 Minibatch[   1- 100]: loss = 0.301037 * 100, metric = 6.37% * 100;
 Minibatch[ 101- 200]: loss = 0.317152 * 100, metric = 7.02% * 100;
 Minibatch[ 201- 300]: loss = 0.303591 * 100, metric = 6.59% * 100;
 Minibatch[ 301- 400]: loss = 0.298085 * 100, metric = 6.43% * 100;
 Minibatch[ 401- 500]: loss = 0.300492 * 100, metric = 6.41% * 100;
 Minibatch[ 501- 600]: loss = 0.296807 * 100, metric = 6.43% * 100;
 Minibatch[ 601- 700]: loss = 0.309605 * 100, metric = 6.77% * 100;
 Minibatch[ 701- 800]: loss = 0.307057 * 100, metric = 6.76% * 100;
 Minibatch[ 801- 900]: loss = 0.304592 * 100, metric = 6.48% * 100;
 Minibatch[ 901-1000]: loss = 0.293417 * 100, metric = 6.37% * 100;
 Minibatch[1001-1100]: loss = 0.296672 * 100, metric = 6.40% * 100;
 Minibatch[1101-1200]: loss = 0.301996 * 100, metric = 6.74% * 100;
 Minibatch[1201-1300]: loss = 0.300175 * 100, metric = 6.40% * 100;
 Minibatch[1301-1400]: loss = 0.291864 * 100, metric = 6.24% * 100;
 Minibatch[1401-1500]: loss = 0.310269 * 100, metric = 6.75% * 100;
 Minibatch[1501-1600]: loss = 0.289792 * 100, metric = 6.30% * 100;
 Minibatch[1601-1700]: loss = 0.301236 * 100, metric = 6.55% * 100;
 Minibatch[1701-1800]: loss = 0.297036 * 100, metric = 6.46% * 100;
 Minibatch[1801-1900]: loss = 0.303063 * 100, metric = 6.66% * 100;
 Minibatch[1901-2000]: loss = 0.301390 * 100, metric = 6.56% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.301266 * 2000, metric = 6.53% * 2000 780.919s (  2.6 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 15.05% * 2000;
 Minibatch[   1- 100]: loss = 0.301980 * 100, metric = 6.62% * 100;
 Minibatch[ 101- 200]: loss = 0.308224 * 100, metric = 6.70% * 100;
 Minibatch[ 201- 300]: loss = 0.310399 * 100, metric = 6.86% * 100;
 Minibatch[ 301- 400]: loss = 0.309207 * 100, metric = 6.72% * 100;
 Minibatch[ 401- 500]: loss = 0.301712 * 100, metric = 6.63% * 100;
 Minibatch[ 501- 600]: loss = 0.301508 * 100, metric = 6.67% * 100;
 Minibatch[ 601- 700]: loss = 0.283155 * 100, metric = 6.08% * 100;
 Minibatch[ 701- 800]: loss = 0.292112 * 100, metric = 6.29% * 100;
 Minibatch[ 801- 900]: loss = 0.299086 * 100, metric = 6.61% * 100;
 Minibatch[ 901-1000]: loss = 0.287458 * 100, metric = 6.07% * 100;
 Minibatch[1001-1100]: loss = 0.287267 * 100, metric = 6.13% * 100;
 Minibatch[1101-1200]: loss = 0.295854 * 100, metric = 6.42% * 100;
 Minibatch[1201-1300]: loss = 0.303025 * 100, metric = 6.80% * 100;
 Minibatch[1301-1400]: loss = 0.294489 * 100, metric = 6.44% * 100;
 Minibatch[1401-1500]: loss = 0.298400 * 100, metric = 6.69% * 100;
 Minibatch[1501-1600]: loss = 0.304221 * 100, metric = 6.68% * 100;
 Minibatch[1601-1700]: loss = 0.288705 * 100, metric = 6.30% * 100;
 Minibatch[1701-1800]: loss = 0.309108 * 100, metric = 6.85% * 100;
 Minibatch[1801-1900]: loss = 0.290866 * 100, metric = 6.11% * 100;
 Minibatch[1901-2000]: loss = 0.301395 * 100, metric = 6.81% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.298409 * 2000, metric = 6.53% * 2000 784.617s (  2.5 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 14.68% * 2000;
 Minibatch[   1- 100]: loss = 0.311344 * 100, metric = 6.95% * 100;
 Minibatch[ 101- 200]: loss = 0.295734 * 100, metric = 6.59% * 100;
 Minibatch[ 201- 300]: loss = 0.287549 * 100, metric = 6.26% * 100;
 Minibatch[ 301- 400]: loss = 0.296794 * 100, metric = 6.40% * 100;
 Minibatch[ 401- 500]: loss = 0.298777 * 100, metric = 6.68% * 100;
 Minibatch[ 501- 600]: loss = 0.300577 * 100, metric = 6.51% * 100;
 Minibatch[ 601- 700]: loss = 0.301045 * 100, metric = 6.62% * 100;
 Minibatch[ 701- 800]: loss = 0.297910 * 100, metric = 6.39% * 100;
 Minibatch[ 801- 900]: loss = 0.293885 * 100, metric = 6.31% * 100;
 Minibatch[ 901-1000]: loss = 0.287006 * 100, metric = 6.28% * 100;
 Minibatch[1001-1100]: loss = 0.293115 * 100, metric = 6.57% * 100;
 Minibatch[1101-1200]: loss = 0.276554 * 100, metric = 5.96% * 100;
 Minibatch[1201-1300]: loss = 0.300109 * 100, metric = 6.35% * 100;
 Minibatch[1301-1400]: loss = 0.279315 * 100, metric = 5.93% * 100;
 Minibatch[1401-1500]: loss = 0.306682 * 100, metric = 6.71% * 100;
 Minibatch[1501-1600]: loss = 0.300905 * 100, metric = 6.44% * 100;
 Minibatch[1601-1700]: loss = 0.289425 * 100, metric = 6.00% * 100;
 Minibatch[1701-1800]: loss = 0.285604 * 100, metric = 6.09% * 100;
 Minibatch[1801-1900]: loss = 0.282765 * 100, metric = 6.08% * 100;
 Minibatch[1901-2000]: loss = 0.305759 * 100, metric = 6.76% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.294543 * 2000, metric = 6.39% * 2000 782.450s (  2.6 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 14.19% * 2000;
 Minibatch[   1- 100]: loss = 0.284080 * 100, metric = 6.08% * 100;
 Minibatch[ 101- 200]: loss = 0.295325 * 100, metric = 6.42% * 100;
 Minibatch[ 201- 300]: loss = 0.289143 * 100, metric = 6.26% * 100;
 Minibatch[ 301- 400]: loss = 0.296314 * 100, metric = 6.52% * 100;
 Minibatch[ 401- 500]: loss = 0.289707 * 100, metric = 6.51% * 100;
 Minibatch[ 501- 600]: loss = 0.296507 * 100, metric = 6.44% * 100;
 Minibatch[ 601- 700]: loss = 0.294936 * 100, metric = 6.45% * 100;
 Minibatch[ 701- 800]: loss = 0.292545 * 100, metric = 6.39% * 100;
 Minibatch[ 801- 900]: loss = 0.276708 * 100, metric = 5.65% * 100;
 Minibatch[ 901-1000]: loss = 0.280975 * 100, metric = 6.25% * 100;
 Minibatch[1001-1100]: loss = 0.294312 * 100, metric = 6.56% * 100;
 Minibatch[1101-1200]: loss = 0.292874 * 100, metric = 6.43% * 100;
 Minibatch[1201-1300]: loss = 0.290857 * 100, metric = 6.37% * 100;
 Minibatch[1301-1400]: loss = 0.287755 * 100, metric = 6.16% * 100;
 Minibatch[1401-1500]: loss = 0.294972 * 100, metric = 6.57% * 100;
 Minibatch[1501-1600]: loss = 0.290854 * 100, metric = 6.18% * 100;
 Minibatch[1601-1700]: loss = 0.300959 * 100, metric = 6.73% * 100;
 Minibatch[1701-1800]: loss = 0.292481 * 100, metric = 6.55% * 100;
 Minibatch[1801-1900]: loss = 0.289329 * 100, metric = 6.35% * 100;
 Minibatch[1901-2000]: loss = 0.292731 * 100, metric = 6.31% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.291168 * 2000, metric = 6.36% * 2000 785.831s (  2.5 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.81% * 2000;
 Minibatch[   1- 100]: loss = 0.276549 * 100, metric = 5.88% * 100;
 Minibatch[ 101- 200]: loss = 0.284204 * 100, metric = 6.33% * 100;
 Minibatch[ 201- 300]: loss = 0.285779 * 100, metric = 6.19% * 100;
 Minibatch[ 301- 400]: loss = 0.279449 * 100, metric = 6.02% * 100;
 Minibatch[ 401- 500]: loss = 0.285940 * 100, metric = 5.96% * 100;
 Minibatch[ 501- 600]: loss = 0.271781 * 100, metric = 5.81% * 100;
 Minibatch[ 601- 700]: loss = 0.293488 * 100, metric = 6.38% * 100;
 Minibatch[ 701- 800]: loss = 0.272225 * 100, metric = 5.93% * 100;
 Minibatch[ 801- 900]: loss = 0.293659 * 100, metric = 6.47% * 100;
 Minibatch[ 901-1000]: loss = 0.280052 * 100, metric = 6.12% * 100;
 Minibatch[1001-1100]: loss = 0.300077 * 100, metric = 6.71% * 100;
 Minibatch[1101-1200]: loss = 0.280230 * 100, metric = 6.08% * 100;
 Minibatch[1201-1300]: loss = 0.287296 * 100, metric = 6.30% * 100;
 Minibatch[1301-1400]: loss = 0.293173 * 100, metric = 6.62% * 100;
 Minibatch[1401-1500]: loss = 0.282548 * 100, metric = 6.26% * 100;
 Minibatch[1501-1600]: loss = 0.284049 * 100, metric = 6.19% * 100;
 Minibatch[1601-1700]: loss = 0.283380 * 100, metric = 6.29% * 100;
 Minibatch[1701-1800]: loss = 0.275840 * 100, metric = 6.06% * 100;
 Minibatch[1801-1900]: loss = 0.297287 * 100, metric = 6.61% * 100;
 Minibatch[1901-2000]: loss = 0.280061 * 100, metric = 6.05% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.284353 * 2000, metric = 6.21% * 2000 779.047s (  2.6 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.76% * 2000;
0.5015566607564688
 Minibatch[   1- 100]: loss = 0.279171 * 100, metric = 5.93% * 100;
 Minibatch[ 101- 200]: loss = 0.269792 * 100, metric = 5.80% * 100;
 Minibatch[ 201- 300]: loss = 0.294819 * 100, metric = 6.55% * 100;
 Minibatch[ 301- 400]: loss = 0.282688 * 100, metric = 6.14% * 100;
 Minibatch[ 401- 500]: loss = 0.275754 * 100, metric = 6.04% * 100;
 Minibatch[ 501- 600]: loss = 0.284944 * 100, metric = 6.03% * 100;
 Minibatch[ 601- 700]: loss = 0.282551 * 100, metric = 5.88% * 100;
 Minibatch[ 701- 800]: loss = 0.267964 * 100, metric = 5.69% * 100;
 Minibatch[ 801- 900]: loss = 0.274019 * 100, metric = 6.07% * 100;
 Minibatch[ 901-1000]: loss = 0.290017 * 100, metric = 6.23% * 100;
 Minibatch[1001-1100]: loss = 0.293890 * 100, metric = 6.71% * 100;
 Minibatch[1101-1200]: loss = 0.281381 * 100, metric = 5.98% * 100;
 Minibatch[1201-1300]: loss = 0.283688 * 100, metric = 6.27% * 100;
 Minibatch[1301-1400]: loss = 0.264261 * 100, metric = 5.66% * 100;
 Minibatch[1401-1500]: loss = 0.273853 * 100, metric = 5.84% * 100;
 Minibatch[1501-1600]: loss = 0.284291 * 100, metric = 6.37% * 100;
 Minibatch[1601-1700]: loss = 0.290284 * 100, metric = 6.58% * 100;
 Minibatch[1701-1800]: loss = 0.285573 * 100, metric = 6.14% * 100;
 Minibatch[1801-1900]: loss = 0.279233 * 100, metric = 6.03% * 100;
 Minibatch[1901-2000]: loss = 0.282018 * 100, metric = 6.12% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.281010 * 2000, metric = 6.10% * 2000 781.667s (  2.6 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 14.34% * 2000;
 Minibatch[   1- 100]: loss = 0.284454 * 100, metric = 6.19% * 100;
 Minibatch[ 101- 200]: loss = 0.288184 * 100, metric = 6.34% * 100;
 Minibatch[ 201- 300]: loss = 0.287903 * 100, metric = 6.50% * 100;
 Minibatch[ 301- 400]: loss = 0.287460 * 100, metric = 6.28% * 100;
 Minibatch[ 401- 500]: loss = 0.283988 * 100, metric = 6.24% * 100;
 Minibatch[ 501- 600]: loss = 0.271222 * 100, metric = 5.97% * 100;
 Minibatch[ 601- 700]: loss = 0.282066 * 100, metric = 6.29% * 100;
 Minibatch[ 701- 800]: loss = 0.287556 * 100, metric = 6.39% * 100;
 Minibatch[ 801- 900]: loss = 0.278025 * 100, metric = 6.08% * 100;
 Minibatch[ 901-1000]: loss = 0.268260 * 100, metric = 5.63% * 100;
 Minibatch[1001-1100]: loss = 0.270685 * 100, metric = 5.91% * 100;
 Minibatch[1101-1200]: loss = 0.289405 * 100, metric = 6.54% * 100;
 Minibatch[1201-1300]: loss = 0.290976 * 100, metric = 6.30% * 100;
 Minibatch[1301-1400]: loss = 0.275404 * 100, metric = 5.77% * 100;
 Minibatch[1401-1500]: loss = 0.281882 * 100, metric = 6.25% * 100;
 Minibatch[1501-1600]: loss = 0.270880 * 100, metric = 5.88% * 100;
 Minibatch[1601-1700]: loss = 0.275908 * 100, metric = 5.98% * 100;
 Minibatch[1701-1800]: loss = 0.271852 * 100, metric = 5.97% * 100;
 Minibatch[1801-1900]: loss = 0.276685 * 100, metric = 6.02% * 100;
 Minibatch[1901-2000]: loss = 0.276663 * 100, metric = 6.12% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.279973 * 2000, metric = 6.13% * 2000 776.510s (  2.6 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 14.04% * 2000;
 Minibatch[   1- 100]: loss = 0.283757 * 100, metric = 6.16% * 100;
 Minibatch[ 101- 200]: loss = 0.279334 * 100, metric = 6.22% * 100;
 Minibatch[ 201- 300]: loss = 0.263427 * 100, metric = 5.67% * 100;
 Minibatch[ 301- 400]: loss = 0.266672 * 100, metric = 5.89% * 100;
 Minibatch[ 401- 500]: loss = 0.275073 * 100, metric = 5.86% * 100;
 Minibatch[ 501- 600]: loss = 0.276328 * 100, metric = 6.04% * 100;
 Minibatch[ 601- 700]: loss = 0.281280 * 100, metric = 6.15% * 100;
 Minibatch[ 701- 800]: loss = 0.271853 * 100, metric = 5.92% * 100;
 Minibatch[ 801- 900]: loss = 0.275747 * 100, metric = 6.04% * 100;
 Minibatch[ 901-1000]: loss = 0.276281 * 100, metric = 5.85% * 100;
 Minibatch[1001-1100]: loss = 0.283575 * 100, metric = 6.22% * 100;
 Minibatch[1101-1200]: loss = 0.272766 * 100, metric = 5.80% * 100;
 Minibatch[1201-1300]: loss = 0.274299 * 100, metric = 5.98% * 100;
 Minibatch[1301-1400]: loss = 0.282667 * 100, metric = 6.10% * 100;
 Minibatch[1401-1500]: loss = 0.279076 * 100, metric = 6.13% * 100;
 Minibatch[1501-1600]: loss = 0.278424 * 100, metric = 5.95% * 100;
 Minibatch[1601-1700]: loss = 0.265591 * 100, metric = 5.78% * 100;
 Minibatch[1701-1800]: loss = 0.268206 * 100, metric = 5.94% * 100;
 Minibatch[1801-1900]: loss = 0.274960 * 100, metric = 6.02% * 100;
 Minibatch[1901-2000]: loss = 0.279800 * 100, metric = 6.08% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.275456 * 2000, metric = 5.99% * 2000 784.018s (  2.6 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 13.73% * 2000;
 Minibatch[   1- 100]: loss = 0.273290 * 100, metric = 5.96% * 100;
 Minibatch[ 101- 200]: loss = 0.273537 * 100, metric = 5.98% * 100;
 Minibatch[ 201- 300]: loss = 0.272402 * 100, metric = 5.81% * 100;
 Minibatch[ 301- 400]: loss = 0.267998 * 100, metric = 5.74% * 100;
 Minibatch[ 401- 500]: loss = 0.267118 * 100, metric = 5.93% * 100;
 Minibatch[ 501- 600]: loss = 0.278866 * 100, metric = 6.16% * 100;
 Minibatch[ 601- 700]: loss = 0.276532 * 100, metric = 6.15% * 100;
 Minibatch[ 701- 800]: loss = 0.278012 * 100, metric = 6.12% * 100;
 Minibatch[ 801- 900]: loss = 0.261221 * 100, metric = 5.64% * 100;
 Minibatch[ 901-1000]: loss = 0.267022 * 100, metric = 5.73% * 100;
 Minibatch[1001-1100]: loss = 0.278535 * 100, metric = 5.95% * 100;
 Minibatch[1101-1200]: loss = 0.273299 * 100, metric = 5.97% * 100;
 Minibatch[1201-1300]: loss = 0.275841 * 100, metric = 6.01% * 100;
 Minibatch[1301-1400]: loss = 0.282441 * 100, metric = 6.22% * 100;
 Minibatch[1401-1500]: loss = 0.275584 * 100, metric = 6.05% * 100;
 Minibatch[1501-1600]: loss = 0.272742 * 100, metric = 5.80% * 100;
 Minibatch[1601-1700]: loss = 0.270430 * 100, metric = 5.81% * 100;
 Minibatch[1701-1800]: loss = 0.276998 * 100, metric = 6.18% * 100;
 Minibatch[1801-1900]: loss = 0.272867 * 100, metric = 6.07% * 100;
 Minibatch[1901-2000]: loss = 0.267676 * 100, metric = 5.75% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.273121 * 2000, metric = 5.95% * 2000 773.789s (  2.6 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.92% * 2000;
 Minibatch[   1- 100]: loss = 0.267558 * 100, metric = 5.98% * 100;
 Minibatch[ 101- 200]: loss = 0.259900 * 100, metric = 5.59% * 100;
 Minibatch[ 201- 300]: loss = 0.275267 * 100, metric = 5.82% * 100;
 Minibatch[ 301- 400]: loss = 0.275708 * 100, metric = 6.03% * 100;
 Minibatch[ 401- 500]: loss = 0.273245 * 100, metric = 5.98% * 100;
 Minibatch[ 501- 600]: loss = 0.271466 * 100, metric = 5.95% * 100;
 Minibatch[ 601- 700]: loss = 0.283217 * 100, metric = 6.19% * 100;
 Minibatch[ 701- 800]: loss = 0.264581 * 100, metric = 5.64% * 100;
 Minibatch[ 801- 900]: loss = 0.267547 * 100, metric = 5.84% * 100;
 Minibatch[ 901-1000]: loss = 0.272682 * 100, metric = 5.91% * 100;
 Minibatch[1001-1100]: loss = 0.284897 * 100, metric = 6.34% * 100;
 Minibatch[1101-1200]: loss = 0.270489 * 100, metric = 5.73% * 100;
 Minibatch[1201-1300]: loss = 0.270169 * 100, metric = 5.76% * 100;
 Minibatch[1301-1400]: loss = 0.273511 * 100, metric = 5.88% * 100;
 Minibatch[1401-1500]: loss = 0.270323 * 100, metric = 5.77% * 100;
 Minibatch[1501-1600]: loss = 0.278197 * 100, metric = 5.94% * 100;
 Minibatch[1601-1700]: loss = 0.275464 * 100, metric = 6.12% * 100;
 Minibatch[1701-1800]: loss = 0.267243 * 100, metric = 5.79% * 100;
 Minibatch[1801-1900]: loss = 0.265079 * 100, metric = 5.80% * 100;
 Minibatch[1901-2000]: loss = 0.278131 * 100, metric = 6.01% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.272234 * 2000, metric = 5.90% * 2000 777.382s (  2.6 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 13.96% * 2000;
 Minibatch[   1- 100]: loss = 0.267480 * 100, metric = 5.92% * 100;
 Minibatch[ 101- 200]: loss = 0.268446 * 100, metric = 5.86% * 100;
 Minibatch[ 201- 300]: loss = 0.274356 * 100, metric = 5.90% * 100;
 Minibatch[ 301- 400]: loss = 0.280702 * 100, metric = 6.20% * 100;
 Minibatch[ 401- 500]: loss = 0.272616 * 100, metric = 6.00% * 100;
 Minibatch[ 501- 600]: loss = 0.268738 * 100, metric = 5.67% * 100;
 Minibatch[ 601- 700]: loss = 0.276098 * 100, metric = 6.08% * 100;
 Minibatch[ 701- 800]: loss = 0.270632 * 100, metric = 5.90% * 100;
 Minibatch[ 801- 900]: loss = 0.264904 * 100, metric = 5.72% * 100;
 Minibatch[ 901-1000]: loss = 0.272362 * 100, metric = 6.07% * 100;
 Minibatch[1001-1100]: loss = 0.270794 * 100, metric = 5.77% * 100;
 Minibatch[1101-1200]: loss = 0.280438 * 100, metric = 6.25% * 100;
 Minibatch[1201-1300]: loss = 0.275894 * 100, metric = 5.96% * 100;
 Minibatch[1301-1400]: loss = 0.259244 * 100, metric = 5.45% * 100;
 Minibatch[1401-1500]: loss = 0.258858 * 100, metric = 5.59% * 100;
 Minibatch[1501-1600]: loss = 0.267307 * 100, metric = 5.64% * 100;
 Minibatch[1601-1700]: loss = 0.271007 * 100, metric = 5.89% * 100;
 Minibatch[1701-1800]: loss = 0.264045 * 100, metric = 5.68% * 100;
 Minibatch[1801-1900]: loss = 0.265509 * 100, metric = 5.78% * 100;
 Minibatch[1901-2000]: loss = 0.259511 * 100, metric = 5.64% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.269447 * 2000, metric = 5.85% * 2000 771.318s (  2.6 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 14.61% * 2000;
 Minibatch[   1- 100]: loss = 0.260132 * 100, metric = 5.77% * 100;
 Minibatch[ 101- 200]: loss = 0.261499 * 100, metric = 5.82% * 100;
 Minibatch[ 201- 300]: loss = 0.265384 * 100, metric = 5.88% * 100;
 Minibatch[ 301- 400]: loss = 0.264231 * 100, metric = 5.59% * 100;
 Minibatch[ 401- 500]: loss = 0.259821 * 100, metric = 5.56% * 100;
 Minibatch[ 501- 600]: loss = 0.260855 * 100, metric = 5.56% * 100;
 Minibatch[ 601- 700]: loss = 0.263559 * 100, metric = 5.69% * 100;
 Minibatch[ 701- 800]: loss = 0.252743 * 100, metric = 5.48% * 100;
 Minibatch[ 801- 900]: loss = 0.260779 * 100, metric = 5.74% * 100;
 Minibatch[ 901-1000]: loss = 0.273146 * 100, metric = 5.89% * 100;
 Minibatch[1001-1100]: loss = 0.263211 * 100, metric = 5.73% * 100;
 Minibatch[1101-1200]: loss = 0.264420 * 100, metric = 5.68% * 100;
 Minibatch[1201-1300]: loss = 0.262965 * 100, metric = 5.72% * 100;
 Minibatch[1301-1400]: loss = 0.266712 * 100, metric = 5.68% * 100;
 Minibatch[1401-1500]: loss = 0.257641 * 100, metric = 5.53% * 100;
 Minibatch[1501-1600]: loss = 0.260442 * 100, metric = 5.60% * 100;
 Minibatch[1601-1700]: loss = 0.267549 * 100, metric = 5.71% * 100;
 Minibatch[1701-1800]: loss = 0.262953 * 100, metric = 5.77% * 100;
 Minibatch[1801-1900]: loss = 0.265045 * 100, metric = 5.78% * 100;
 Minibatch[1901-2000]: loss = 0.264019 * 100, metric = 5.68% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.262855 * 2000, metric = 5.69% * 2000 782.311s (  2.6 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 13.97% * 2000;
 Minibatch[   1- 100]: loss = 0.280306 * 100, metric = 6.37% * 100;
 Minibatch[ 101- 200]: loss = 0.252703 * 100, metric = 5.29% * 100;
 Minibatch[ 201- 300]: loss = 0.265838 * 100, metric = 5.61% * 100;
 Minibatch[ 301- 400]: loss = 0.267402 * 100, metric = 5.76% * 100;
 Minibatch[ 401- 500]: loss = 0.254972 * 100, metric = 5.45% * 100;
 Minibatch[ 501- 600]: loss = 0.262132 * 100, metric = 5.69% * 100;
 Minibatch[ 601- 700]: loss = 0.267389 * 100, metric = 5.85% * 100;
 Minibatch[ 701- 800]: loss = 0.255264 * 100, metric = 5.65% * 100;
 Minibatch[ 801- 900]: loss = 0.260348 * 100, metric = 5.73% * 100;
 Minibatch[ 901-1000]: loss = 0.259349 * 100, metric = 5.55% * 100;
 Minibatch[1001-1100]: loss = 0.261759 * 100, metric = 5.78% * 100;
 Minibatch[1101-1200]: loss = 0.254552 * 100, metric = 5.46% * 100;
 Minibatch[1201-1300]: loss = 0.267480 * 100, metric = 6.14% * 100;
 Minibatch[1301-1400]: loss = 0.263803 * 100, metric = 5.92% * 100;
 Minibatch[1401-1500]: loss = 0.249849 * 100, metric = 5.20% * 100;
 Minibatch[1501-1600]: loss = 0.270318 * 100, metric = 5.81% * 100;
 Minibatch[1601-1700]: loss = 0.265009 * 100, metric = 5.91% * 100;
 Minibatch[1701-1800]: loss = 0.262457 * 100, metric = 5.74% * 100;
 Minibatch[1801-1900]: loss = 0.262886 * 100, metric = 5.96% * 100;
 Minibatch[1901-2000]: loss = 0.257280 * 100, metric = 5.56% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.262055 * 2000, metric = 5.72% * 2000 798.952s (  2.5 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 13.97% * 2000;
 Minibatch[   1- 100]: loss = 0.258322 * 100, metric = 5.65% * 100;
 Minibatch[ 101- 200]: loss = 0.256573 * 100, metric = 5.57% * 100;
 Minibatch[ 201- 300]: loss = 0.264521 * 100, metric = 5.66% * 100;
 Minibatch[ 301- 400]: loss = 0.263275 * 100, metric = 5.75% * 100;
 Minibatch[ 401- 500]: loss = 0.258793 * 100, metric = 5.49% * 100;
 Minibatch[ 501- 600]: loss = 0.256909 * 100, metric = 5.72% * 100;
 Minibatch[ 601- 700]: loss = 0.261686 * 100, metric = 5.67% * 100;
 Minibatch[ 701- 800]: loss = 0.241159 * 100, metric = 5.05% * 100;
 Minibatch[ 801- 900]: loss = 0.254059 * 100, metric = 5.42% * 100;
 Minibatch[ 901-1000]: loss = 0.248799 * 100, metric = 5.31% * 100;
 Minibatch[1001-1100]: loss = 0.253448 * 100, metric = 5.41% * 100;
 Minibatch[1101-1200]: loss = 0.246926 * 100, metric = 5.36% * 100;
 Minibatch[1201-1300]: loss = 0.249420 * 100, metric = 5.22% * 100;
 Minibatch[1301-1400]: loss = 0.244458 * 100, metric = 5.22% * 100;
 Minibatch[1401-1500]: loss = 0.242804 * 100, metric = 5.02% * 100;
 Minibatch[1501-1600]: loss = 0.237908 * 100, metric = 4.98% * 100;
 Minibatch[1601-1700]: loss = 0.247646 * 100, metric = 5.33% * 100;
 Minibatch[1701-1800]: loss = 0.261474 * 100, metric = 5.70% * 100;
 Minibatch[1801-1900]: loss = 0.252137 * 100, metric = 5.25% * 100;
 Minibatch[1901-2000]: loss = 0.247354 * 100, metric = 5.36% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.252383 * 2000, metric = 5.41% * 2000 814.000s (  2.5 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 14.36% * 2000;
 Minibatch[   1- 100]: loss = 0.256092 * 100, metric = 5.49% * 100;
 Minibatch[ 101- 200]: loss = 0.251299 * 100, metric = 5.28% * 100;
 Minibatch[ 201- 300]: loss = 0.253204 * 100, metric = 5.41% * 100;
 Minibatch[ 301- 400]: loss = 0.257086 * 100, metric = 5.62% * 100;
 Minibatch[ 401- 500]: loss = 0.249952 * 100, metric = 5.37% * 100;
 Minibatch[ 501- 600]: loss = 0.245300 * 100, metric = 5.02% * 100;
 Minibatch[ 601- 700]: loss = 0.244771 * 100, metric = 5.15% * 100;
 Minibatch[ 701- 800]: loss = 0.245180 * 100, metric = 5.38% * 100;
 Minibatch[ 801- 900]: loss = 0.263892 * 100, metric = 5.71% * 100;
 Minibatch[ 901-1000]: loss = 0.246313 * 100, metric = 5.27% * 100;
 Minibatch[1001-1100]: loss = 0.248546 * 100, metric = 5.29% * 100;
 Minibatch[1101-1200]: loss = 0.261259 * 100, metric = 5.34% * 100;
 Minibatch[1201-1300]: loss = 0.255569 * 100, metric = 5.44% * 100;
 Minibatch[1301-1400]: loss = 0.245130 * 100, metric = 5.16% * 100;
 Minibatch[1401-1500]: loss = 0.259126 * 100, metric = 5.69% * 100;
 Minibatch[1501-1600]: loss = 0.247021 * 100, metric = 5.21% * 100;
 Minibatch[1601-1700]: loss = 0.246092 * 100, metric = 5.38% * 100;
 Minibatch[1701-1800]: loss = 0.254980 * 100, metric = 5.56% * 100;
 Minibatch[1801-1900]: loss = 0.256816 * 100, metric = 5.76% * 100;
 Minibatch[1901-2000]: loss = 0.251034 * 100, metric = 5.32% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.251933 * 2000, metric = 5.39% * 2000 814.459s (  2.5 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 14.05% * 2000;
 Minibatch[   1- 100]: loss = 0.244186 * 100, metric = 5.34% * 100;
 Minibatch[ 101- 200]: loss = 0.255697 * 100, metric = 5.52% * 100;
 Minibatch[ 201- 300]: loss = 0.243611 * 100, metric = 5.29% * 100;
 Minibatch[ 301- 400]: loss = 0.263119 * 100, metric = 5.71% * 100;
 Minibatch[ 401- 500]: loss = 0.245794 * 100, metric = 5.22% * 100;
 Minibatch[ 501- 600]: loss = 0.248684 * 100, metric = 5.35% * 100;
 Minibatch[ 601- 700]: loss = 0.237214 * 100, metric = 5.08% * 100;
 Minibatch[ 701- 800]: loss = 0.238736 * 100, metric = 5.15% * 100;
 Minibatch[ 801- 900]: loss = 0.247583 * 100, metric = 5.33% * 100;
 Minibatch[ 901-1000]: loss = 0.251436 * 100, metric = 5.56% * 100;
 Minibatch[1001-1100]: loss = 0.245815 * 100, metric = 5.25% * 100;
 Minibatch[1101-1200]: loss = 0.256474 * 100, metric = 5.67% * 100;
 Minibatch[1201-1300]: loss = 0.248938 * 100, metric = 5.18% * 100;
 Minibatch[1301-1400]: loss = 0.247804 * 100, metric = 5.38% * 100;
 Minibatch[1401-1500]: loss = 0.244934 * 100, metric = 5.34% * 100;
 Minibatch[1501-1600]: loss = 0.255647 * 100, metric = 5.41% * 100;
 Minibatch[1601-1700]: loss = 0.242373 * 100, metric = 5.18% * 100;
 Minibatch[1701-1800]: loss = 0.258094 * 100, metric = 5.59% * 100;
 Minibatch[1801-1900]: loss = 0.243195 * 100, metric = 5.21% * 100;
 Minibatch[1901-2000]: loss = 0.250119 * 100, metric = 5.28% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.248473 * 2000, metric = 5.35% * 2000 767.552s (  2.6 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 13.87% * 2000;
 Minibatch[   1- 100]: loss = 0.249508 * 100, metric = 5.31% * 100;
 Minibatch[ 101- 200]: loss = 0.246205 * 100, metric = 5.34% * 100;
 Minibatch[ 201- 300]: loss = 0.251282 * 100, metric = 5.36% * 100;
 Minibatch[ 301- 400]: loss = 0.242826 * 100, metric = 5.23% * 100;
 Minibatch[ 401- 500]: loss = 0.242962 * 100, metric = 5.36% * 100;
 Minibatch[ 501- 600]: loss = 0.248602 * 100, metric = 5.46% * 100;
 Minibatch[ 601- 700]: loss = 0.251258 * 100, metric = 5.52% * 100;
 Minibatch[ 701- 800]: loss = 0.253956 * 100, metric = 5.66% * 100;
 Minibatch[ 801- 900]: loss = 0.247901 * 100, metric = 5.15% * 100;
 Minibatch[ 901-1000]: loss = 0.253327 * 100, metric = 5.40% * 100;
 Minibatch[1001-1100]: loss = 0.260715 * 100, metric = 5.66% * 100;
 Minibatch[1101-1200]: loss = 0.249327 * 100, metric = 5.36% * 100;
 Minibatch[1201-1300]: loss = 0.232213 * 100, metric = 5.02% * 100;
 Minibatch[1301-1400]: loss = 0.241744 * 100, metric = 5.28% * 100;
 Minibatch[1401-1500]: loss = 0.255336 * 100, metric = 5.54% * 100;
 Minibatch[1501-1600]: loss = 0.250319 * 100, metric = 5.33% * 100;
 Minibatch[1601-1700]: loss = 0.246694 * 100, metric = 5.30% * 100;
 Minibatch[1701-1800]: loss = 0.251503 * 100, metric = 5.30% * 100;
 Minibatch[1801-1900]: loss = 0.243463 * 100, metric = 5.31% * 100;
 Minibatch[1901-2000]: loss = 0.253241 * 100, metric = 5.46% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.248619 * 2000, metric = 5.37% * 2000 763.440s (  2.6 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 13.22% * 2000;
 Minibatch[   1- 100]: loss = 0.248408 * 100, metric = 5.44% * 100;
 Minibatch[ 101- 200]: loss = 0.246373 * 100, metric = 5.31% * 100;
 Minibatch[ 201- 300]: loss = 0.248674 * 100, metric = 5.44% * 100;
 Minibatch[ 301- 400]: loss = 0.243124 * 100, metric = 5.36% * 100;
 Minibatch[ 401- 500]: loss = 0.256447 * 100, metric = 5.50% * 100;
 Minibatch[ 501- 600]: loss = 0.259184 * 100, metric = 5.58% * 100;
 Minibatch[ 601- 700]: loss = 0.259038 * 100, metric = 5.55% * 100;
 Minibatch[ 701- 800]: loss = 0.242418 * 100, metric = 5.19% * 100;
 Minibatch[ 801- 900]: loss = 0.242224 * 100, metric = 5.10% * 100;
 Minibatch[ 901-1000]: loss = 0.248650 * 100, metric = 5.42% * 100;
 Minibatch[1001-1100]: loss = 0.244056 * 100, metric = 5.37% * 100;
 Minibatch[1101-1200]: loss = 0.238657 * 100, metric = 5.14% * 100;
 Minibatch[1201-1300]: loss = 0.242012 * 100, metric = 5.20% * 100;
 Minibatch[1301-1400]: loss = 0.238844 * 100, metric = 5.15% * 100;
 Minibatch[1401-1500]: loss = 0.243311 * 100, metric = 5.42% * 100;
 Minibatch[1501-1600]: loss = 0.245970 * 100, metric = 5.36% * 100;
 Minibatch[1601-1700]: loss = 0.240091 * 100, metric = 5.19% * 100;
 Minibatch[1701-1800]: loss = 0.243071 * 100, metric = 5.26% * 100;
 Minibatch[1801-1900]: loss = 0.245797 * 100, metric = 5.29% * 100;
 Minibatch[1901-2000]: loss = 0.236184 * 100, metric = 5.14% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.245627 * 2000, metric = 5.32% * 2000 756.867s (  2.6 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 13.31% * 2000;
 Minibatch[   1- 100]: loss = 0.249444 * 100, metric = 5.46% * 100;
 Minibatch[ 101- 200]: loss = 0.242660 * 100, metric = 5.18% * 100;
 Minibatch[ 201- 300]: loss = 0.251355 * 100, metric = 5.44% * 100;
 Minibatch[ 301- 400]: loss = 0.243262 * 100, metric = 5.20% * 100;
 Minibatch[ 401- 500]: loss = 0.254136 * 100, metric = 5.60% * 100;
 Minibatch[ 501- 600]: loss = 0.243868 * 100, metric = 5.38% * 100;
 Minibatch[ 601- 700]: loss = 0.236329 * 100, metric = 5.11% * 100;
 Minibatch[ 701- 800]: loss = 0.243706 * 100, metric = 5.43% * 100;
 Minibatch[ 801- 900]: loss = 0.234508 * 100, metric = 5.03% * 100;
 Minibatch[ 901-1000]: loss = 0.254055 * 100, metric = 5.63% * 100;
 Minibatch[1001-1100]: loss = 0.248581 * 100, metric = 5.37% * 100;
 Minibatch[1101-1200]: loss = 0.249596 * 100, metric = 5.45% * 100;
 Minibatch[1201-1300]: loss = 0.230615 * 100, metric = 4.87% * 100;
 Minibatch[1301-1400]: loss = 0.249645 * 100, metric = 5.41% * 100;
 Minibatch[1401-1500]: loss = 0.243574 * 100, metric = 5.30% * 100;
 Minibatch[1501-1600]: loss = 0.225992 * 100, metric = 4.73% * 100;
 Minibatch[1601-1700]: loss = 0.251924 * 100, metric = 5.68% * 100;
 Minibatch[1701-1800]: loss = 0.243287 * 100, metric = 5.36% * 100;
 Minibatch[1801-1900]: loss = 0.243565 * 100, metric = 5.19% * 100;
 Minibatch[1901-2000]: loss = 0.239243 * 100, metric = 5.06% * 100;
Finished Epoch[49 of 200]: [Training] loss = 0.243967 * 2000, metric = 5.29% * 2000 773.717s (  2.6 samples/s);
Finished Evaluation [49]: Minibatch[1-2000]: metric = 12.97% * 2000;
 Minibatch[   1- 100]: loss = 0.247737 * 100, metric = 5.46% * 100;
 Minibatch[ 101- 200]: loss = 0.231381 * 100, metric = 5.02% * 100;
 Minibatch[ 201- 300]: loss = 0.237362 * 100, metric = 5.04% * 100;
 Minibatch[ 301- 400]: loss = 0.232760 * 100, metric = 5.09% * 100;
 Minibatch[ 401- 500]: loss = 0.241429 * 100, metric = 5.32% * 100;
 Minibatch[ 501- 600]: loss = 0.249639 * 100, metric = 5.50% * 100;
 Minibatch[ 601- 700]: loss = 0.238390 * 100, metric = 5.05% * 100;
 Minibatch[ 701- 800]: loss = 0.236303 * 100, metric = 5.23% * 100;
 Minibatch[ 801- 900]: loss = 0.241849 * 100, metric = 5.12% * 100;
 Minibatch[ 901-1000]: loss = 0.235105 * 100, metric = 5.00% * 100;
 Minibatch[1001-1100]: loss = 0.230469 * 100, metric = 5.00% * 100;
 Minibatch[1101-1200]: loss = 0.243249 * 100, metric = 5.31% * 100;
 Minibatch[1201-1300]: loss = 0.244656 * 100, metric = 5.36% * 100;
 Minibatch[1301-1400]: loss = 0.229380 * 100, metric = 4.96% * 100;
 Minibatch[1401-1500]: loss = 0.239596 * 100, metric = 5.29% * 100;
 Minibatch[1501-1600]: loss = 0.226397 * 100, metric = 4.75% * 100;
 Minibatch[1601-1700]: loss = 0.232444 * 100, metric = 4.97% * 100;
 Minibatch[1701-1800]: loss = 0.241997 * 100, metric = 5.39% * 100;
 Minibatch[1801-1900]: loss = 0.244723 * 100, metric = 5.21% * 100;
 Minibatch[1901-2000]: loss = 0.238587 * 100, metric = 5.30% * 100;
Finished Epoch[50 of 200]: [Training] loss = 0.238173 * 2000, metric = 5.17% * 2000 764.684s (  2.6 samples/s);
Finished Evaluation [50]: Minibatch[1-2000]: metric = 14.23% * 2000;
 Minibatch[   1- 100]: loss = 0.229611 * 100, metric = 4.87% * 100;
 Minibatch[ 101- 200]: loss = 0.243481 * 100, metric = 5.21% * 100;
 Minibatch[ 201- 300]: loss = 0.241125 * 100, metric = 5.25% * 100;
 Minibatch[ 301- 400]: loss = 0.231749 * 100, metric = 4.95% * 100;
 Minibatch[ 401- 500]: loss = 0.235607 * 100, metric = 4.99% * 100;
 Minibatch[ 501- 600]: loss = 0.243623 * 100, metric = 5.31% * 100;
 Minibatch[ 601- 700]: loss = 0.231823 * 100, metric = 5.02% * 100;
 Minibatch[ 701- 800]: loss = 0.236706 * 100, metric = 5.11% * 100;
 Minibatch[ 801- 900]: loss = 0.239214 * 100, metric = 5.07% * 100;
 Minibatch[ 901-1000]: loss = 0.233930 * 100, metric = 4.87% * 100;
 Minibatch[1001-1100]: loss = 0.233124 * 100, metric = 5.04% * 100;
 Minibatch[1101-1200]: loss = 0.237631 * 100, metric = 5.03% * 100;
 Minibatch[1201-1300]: loss = 0.252394 * 100, metric = 5.28% * 100;
 Minibatch[1301-1400]: loss = 0.239552 * 100, metric = 5.17% * 100;
 Minibatch[1401-1500]: loss = 0.229548 * 100, metric = 4.91% * 100;
 Minibatch[1501-1600]: loss = 0.241301 * 100, metric = 5.16% * 100;
 Minibatch[1601-1700]: loss = 0.231877 * 100, metric = 5.04% * 100;
 Minibatch[1701-1800]: loss = 0.240407 * 100, metric = 5.33% * 100;
 Minibatch[1801-1900]: loss = 0.217625 * 100, metric = 4.67% * 100;
 Minibatch[1901-2000]: loss = 0.227186 * 100, metric = 4.90% * 100;
Finished Epoch[51 of 200]: [Training] loss = 0.235876 * 2000, metric = 5.06% * 2000 763.389s (  2.6 samples/s);
Finished Evaluation [51]: Minibatch[1-2000]: metric = 12.46% * 2000;
0.49629899972304703
 Minibatch[   1- 100]: loss = 0.225237 * 100, metric = 4.98% * 100;
 Minibatch[ 101- 200]: loss = 0.232033 * 100, metric = 4.94% * 100;
 Minibatch[ 201- 300]: loss = 0.239857 * 100, metric = 5.29% * 100;
 Minibatch[ 301- 400]: loss = 0.227179 * 100, metric = 4.98% * 100;
 Minibatch[ 401- 500]: loss = 0.236558 * 100, metric = 4.99% * 100;
 Minibatch[ 501- 600]: loss = 0.230616 * 100, metric = 4.91% * 100;
 Minibatch[ 601- 700]: loss = 0.230502 * 100, metric = 4.87% * 100;
 Minibatch[ 701- 800]: loss = 0.237359 * 100, metric = 5.05% * 100;
 Minibatch[ 801- 900]: loss = 0.235436 * 100, metric = 4.97% * 100;
 Minibatch[ 901-1000]: loss = 0.241163 * 100, metric = 5.18% * 100;
 Minibatch[1001-1100]: loss = 0.238172 * 100, metric = 5.18% * 100;
 Minibatch[1101-1200]: loss = 0.225693 * 100, metric = 4.66% * 100;
 Minibatch[1201-1300]: loss = 0.231886 * 100, metric = 5.01% * 100;
 Minibatch[1301-1400]: loss = 0.234825 * 100, metric = 4.89% * 100;
 Minibatch[1401-1500]: loss = 0.224016 * 100, metric = 4.65% * 100;
 Minibatch[1501-1600]: loss = 0.221475 * 100, metric = 4.76% * 100;
 Minibatch[1601-1700]: loss = 0.236568 * 100, metric = 5.07% * 100;
 Minibatch[1701-1800]: loss = 0.228678 * 100, metric = 5.09% * 100;
 Minibatch[1801-1900]: loss = 0.227483 * 100, metric = 4.72% * 100;
 Minibatch[1901-2000]: loss = 0.236064 * 100, metric = 5.15% * 100;
Finished Epoch[52 of 200]: [Training] loss = 0.232040 * 2000, metric = 4.97% * 2000 756.442s (  2.6 samples/s);
Finished Evaluation [52]: Minibatch[1-2000]: metric = 13.85% * 2000;
 Minibatch[   1- 100]: loss = 0.230464 * 100, metric = 4.82% * 100;
 Minibatch[ 101- 200]: loss = 0.220982 * 100, metric = 4.48% * 100;
 Minibatch[ 201- 300]: loss = 0.232055 * 100, metric = 5.12% * 100;
 Minibatch[ 301- 400]: loss = 0.228047 * 100, metric = 4.94% * 100;
 Minibatch[ 401- 500]: loss = 0.233847 * 100, metric = 5.10% * 100;
 Minibatch[ 501- 600]: loss = 0.225610 * 100, metric = 4.75% * 100;
 Minibatch[ 601- 700]: loss = 0.227484 * 100, metric = 4.90% * 100;
 Minibatch[ 701- 800]: loss = 0.230244 * 100, metric = 4.84% * 100;
 Minibatch[ 801- 900]: loss = 0.234787 * 100, metric = 4.99% * 100;
 Minibatch[ 901-1000]: loss = 0.228477 * 100, metric = 4.89% * 100;
 Minibatch[1001-1100]: loss = 0.232193 * 100, metric = 5.10% * 100;
 Minibatch[1101-1200]: loss = 0.225265 * 100, metric = 4.91% * 100;
 Minibatch[1201-1300]: loss = 0.223843 * 100, metric = 4.70% * 100;
 Minibatch[1301-1400]: loss = 0.224795 * 100, metric = 4.75% * 100;
 Minibatch[1401-1500]: loss = 0.223799 * 100, metric = 4.77% * 100;
 Minibatch[1501-1600]: loss = 0.231106 * 100, metric = 4.95% * 100;
 Minibatch[1601-1700]: loss = 0.226023 * 100, metric = 4.73% * 100;
 Minibatch[1701-1800]: loss = 0.234718 * 100, metric = 5.03% * 100;
 Minibatch[1801-1900]: loss = 0.238130 * 100, metric = 5.15% * 100;
 Minibatch[1901-2000]: loss = 0.220280 * 100, metric = 4.71% * 100;
Finished Epoch[53 of 200]: [Training] loss = 0.228607 * 2000, metric = 4.88% * 2000 764.581s (  2.6 samples/s);
Finished Evaluation [53]: Minibatch[1-2000]: metric = 12.74% * 2000;
 Minibatch[   1- 100]: loss = 0.226240 * 100, metric = 4.77% * 100;
 Minibatch[ 101- 200]: loss = 0.225916 * 100, metric = 4.83% * 100;
 Minibatch[ 201- 300]: loss = 0.220454 * 100, metric = 4.66% * 100;
 Minibatch[ 301- 400]: loss = 0.215000 * 100, metric = 4.41% * 100;
 Minibatch[ 401- 500]: loss = 0.227419 * 100, metric = 4.81% * 100;
 Minibatch[ 501- 600]: loss = 0.215486 * 100, metric = 4.62% * 100;
 Minibatch[ 601- 700]: loss = 0.231994 * 100, metric = 4.85% * 100;
 Minibatch[ 701- 800]: loss = 0.225164 * 100, metric = 4.81% * 100;
 Minibatch[ 801- 900]: loss = 0.214736 * 100, metric = 4.57% * 100;
 Minibatch[ 901-1000]: loss = 0.226741 * 100, metric = 4.92% * 100;
 Minibatch[1001-1100]: loss = 0.217478 * 100, metric = 4.59% * 100;
 Minibatch[1101-1200]: loss = 0.215410 * 100, metric = 4.55% * 100;
 Minibatch[1201-1300]: loss = 0.215032 * 100, metric = 4.49% * 100;
 Minibatch[1301-1400]: loss = 0.220732 * 100, metric = 4.72% * 100;
 Minibatch[1401-1500]: loss = 0.235228 * 100, metric = 5.03% * 100;
 Minibatch[1501-1600]: loss = 0.231783 * 100, metric = 5.00% * 100;
 Minibatch[1601-1700]: loss = 0.223314 * 100, metric = 4.75% * 100;
 Minibatch[1701-1800]: loss = 0.228673 * 100, metric = 4.93% * 100;
 Minibatch[1801-1900]: loss = 0.229806 * 100, metric = 4.97% * 100;
 Minibatch[1901-2000]: loss = 0.236022 * 100, metric = 5.13% * 100;
Finished Epoch[54 of 200]: [Training] loss = 0.224131 * 2000, metric = 4.77% * 2000 758.812s (  2.6 samples/s);
Finished Evaluation [54]: Minibatch[1-2000]: metric = 12.53% * 2000;
 Minibatch[   1- 100]: loss = 0.231858 * 100, metric = 4.88% * 100;
 Minibatch[ 101- 200]: loss = 0.232652 * 100, metric = 4.88% * 100;
 Minibatch[ 201- 300]: loss = 0.228289 * 100, metric = 4.88% * 100;
 Minibatch[ 301- 400]: loss = 0.218634 * 100, metric = 4.61% * 100;
 Minibatch[ 401- 500]: loss = 0.228960 * 100, metric = 4.85% * 100;
 Minibatch[ 501- 600]: loss = 0.233997 * 100, metric = 4.89% * 100;
 Minibatch[ 601- 700]: loss = 0.227362 * 100, metric = 4.82% * 100;
 Minibatch[ 701- 800]: loss = 0.236155 * 100, metric = 5.12% * 100;
 Minibatch[ 801- 900]: loss = 0.230438 * 100, metric = 4.99% * 100;
 Minibatch[ 901-1000]: loss = 0.223029 * 100, metric = 4.85% * 100;
 Minibatch[1001-1100]: loss = 0.228669 * 100, metric = 4.74% * 100;
 Minibatch[1101-1200]: loss = 0.227423 * 100, metric = 4.74% * 100;
 Minibatch[1201-1300]: loss = 0.227073 * 100, metric = 4.77% * 100;
 Minibatch[1301-1400]: loss = 0.217394 * 100, metric = 4.48% * 100;
 Minibatch[1401-1500]: loss = 0.218431 * 100, metric = 4.58% * 100;
 Minibatch[1501-1600]: loss = 0.224158 * 100, metric = 4.74% * 100;
 Minibatch[1601-1700]: loss = 0.228209 * 100, metric = 5.01% * 100;
 Minibatch[1701-1800]: loss = 0.224595 * 100, metric = 4.79% * 100;
 Minibatch[1801-1900]: loss = 0.212314 * 100, metric = 4.35% * 100;
 Minibatch[1901-2000]: loss = 0.225730 * 100, metric = 4.87% * 100;
Finished Epoch[55 of 200]: [Training] loss = 0.226269 * 2000, metric = 4.79% * 2000 755.238s (  2.6 samples/s);
Finished Evaluation [55]: Minibatch[1-2000]: metric = 12.91% * 2000;
 Minibatch[   1- 100]: loss = 0.231402 * 100, metric = 4.98% * 100;
 Minibatch[ 101- 200]: loss = 0.215244 * 100, metric = 4.48% * 100;
 Minibatch[ 201- 300]: loss = 0.230185 * 100, metric = 4.87% * 100;
 Minibatch[ 301- 400]: loss = 0.229268 * 100, metric = 4.83% * 100;
 Minibatch[ 401- 500]: loss = 0.231619 * 100, metric = 4.96% * 100;
 Minibatch[ 501- 600]: loss = 0.237564 * 100, metric = 5.11% * 100;
 Minibatch[ 601- 700]: loss = 0.225778 * 100, metric = 4.89% * 100;
 Minibatch[ 701- 800]: loss = 0.224137 * 100, metric = 4.90% * 100;
 Minibatch[ 801- 900]: loss = 0.225277 * 100, metric = 4.76% * 100;
 Minibatch[ 901-1000]: loss = 0.228693 * 100, metric = 4.92% * 100;
 Minibatch[1001-1100]: loss = 0.234411 * 100, metric = 4.98% * 100;
 Minibatch[1101-1200]: loss = 0.225465 * 100, metric = 4.78% * 100;
 Minibatch[1201-1300]: loss = 0.222883 * 100, metric = 4.66% * 100;
 Minibatch[1301-1400]: loss = 0.214017 * 100, metric = 4.55% * 100;
 Minibatch[1401-1500]: loss = 0.225396 * 100, metric = 4.85% * 100;
 Minibatch[1501-1600]: loss = 0.220694 * 100, metric = 4.53% * 100;
 Minibatch[1601-1700]: loss = 0.220716 * 100, metric = 4.51% * 100;
 Minibatch[1701-1800]: loss = 0.215046 * 100, metric = 4.47% * 100;
 Minibatch[1801-1900]: loss = 0.215414 * 100, metric = 4.52% * 100;
 Minibatch[1901-2000]: loss = 0.233489 * 100, metric = 5.05% * 100;
Finished Epoch[56 of 200]: [Training] loss = 0.225335 * 2000, metric = 4.78% * 2000 763.790s (  2.6 samples/s);
Finished Evaluation [56]: Minibatch[1-2000]: metric = 12.55% * 2000;
 Minibatch[   1- 100]: loss = 0.225483 * 100, metric = 4.86% * 100;
 Minibatch[ 101- 200]: loss = 0.218490 * 100, metric = 4.59% * 100;
 Minibatch[ 201- 300]: loss = 0.218707 * 100, metric = 4.57% * 100;
 Minibatch[ 301- 400]: loss = 0.224404 * 100, metric = 4.64% * 100;
 Minibatch[ 401- 500]: loss = 0.224519 * 100, metric = 4.65% * 100;
 Minibatch[ 501- 600]: loss = 0.216179 * 100, metric = 4.49% * 100;
 Minibatch[ 601- 700]: loss = 0.226194 * 100, metric = 4.78% * 100;
 Minibatch[ 701- 800]: loss = 0.214423 * 100, metric = 4.48% * 100;
 Minibatch[ 801- 900]: loss = 0.223515 * 100, metric = 4.91% * 100;
 Minibatch[ 901-1000]: loss = 0.222999 * 100, metric = 4.88% * 100;
 Minibatch[1001-1100]: loss = 0.226557 * 100, metric = 4.78% * 100;
 Minibatch[1101-1200]: loss = 0.222480 * 100, metric = 4.68% * 100;
 Minibatch[1201-1300]: loss = 0.220528 * 100, metric = 4.62% * 100;
 Minibatch[1301-1400]: loss = 0.216149 * 100, metric = 4.67% * 100;
 Minibatch[1401-1500]: loss = 0.226415 * 100, metric = 4.88% * 100;
 Minibatch[1501-1600]: loss = 0.219025 * 100, metric = 4.60% * 100;
 Minibatch[1601-1700]: loss = 0.218945 * 100, metric = 4.47% * 100;
 Minibatch[1701-1800]: loss = 0.222617 * 100, metric = 4.71% * 100;
 Minibatch[1801-1900]: loss = 0.225220 * 100, metric = 4.86% * 100;
 Minibatch[1901-2000]: loss = 0.232068 * 100, metric = 4.95% * 100;
Finished Epoch[57 of 200]: [Training] loss = 0.222246 * 2000, metric = 4.70% * 2000 764.807s (  2.6 samples/s);
Finished Evaluation [57]: Minibatch[1-2000]: metric = 12.67% * 2000;
 Minibatch[   1- 100]: loss = 0.217617 * 100, metric = 4.55% * 100;
 Minibatch[ 101- 200]: loss = 0.224261 * 100, metric = 4.80% * 100;
 Minibatch[ 201- 300]: loss = 0.217624 * 100, metric = 4.69% * 100;
 Minibatch[ 301- 400]: loss = 0.225683 * 100, metric = 4.80% * 100;
 Minibatch[ 401- 500]: loss = 0.229462 * 100, metric = 5.06% * 100;
 Minibatch[ 501- 600]: loss = 0.216043 * 100, metric = 4.49% * 100;
 Minibatch[ 601- 700]: loss = 0.217493 * 100, metric = 4.58% * 100;
 Minibatch[ 701- 800]: loss = 0.229485 * 100, metric = 4.94% * 100;
 Minibatch[ 801- 900]: loss = 0.221418 * 100, metric = 4.65% * 100;
 Minibatch[ 901-1000]: loss = 0.217405 * 100, metric = 4.68% * 100;
 Minibatch[1001-1100]: loss = 0.219933 * 100, metric = 4.66% * 100;
 Minibatch[1101-1200]: loss = 0.224999 * 100, metric = 4.74% * 100;
 Minibatch[1201-1300]: loss = 0.216216 * 100, metric = 4.61% * 100;
 Minibatch[1301-1400]: loss = 0.226859 * 100, metric = 4.96% * 100;
 Minibatch[1401-1500]: loss = 0.208286 * 100, metric = 4.30% * 100;
 Minibatch[1501-1600]: loss = 0.221184 * 100, metric = 4.77% * 100;
 Minibatch[1601-1700]: loss = 0.221417 * 100, metric = 4.65% * 100;
 Minibatch[1701-1800]: loss = 0.218382 * 100, metric = 4.65% * 100;
 Minibatch[1801-1900]: loss = 0.221789 * 100, metric = 4.68% * 100;
 Minibatch[1901-2000]: loss = 0.207312 * 100, metric = 4.36% * 100;
Finished Epoch[58 of 200]: [Training] loss = 0.220143 * 2000, metric = 4.68% * 2000 751.254s (  2.7 samples/s);
Finished Evaluation [58]: Minibatch[1-2000]: metric = 12.65% * 2000;
 Minibatch[   1- 100]: loss = 0.229918 * 100, metric = 5.03% * 100;
 Minibatch[ 101- 200]: loss = 0.232864 * 100, metric = 5.12% * 100;
 Minibatch[ 201- 300]: loss = 0.220834 * 100, metric = 4.58% * 100;
 Minibatch[ 301- 400]: loss = 0.214803 * 100, metric = 4.46% * 100;
 Minibatch[ 401- 500]: loss = 0.221184 * 100, metric = 4.78% * 100;
 Minibatch[ 501- 600]: loss = 0.212440 * 100, metric = 4.48% * 100;
 Minibatch[ 601- 700]: loss = 0.212967 * 100, metric = 4.62% * 100;
 Minibatch[ 701- 800]: loss = 0.215074 * 100, metric = 4.36% * 100;
 Minibatch[ 801- 900]: loss = 0.218426 * 100, metric = 4.65% * 100;
 Minibatch[ 901-1000]: loss = 0.216919 * 100, metric = 4.70% * 100;
 Minibatch[1001-1100]: loss = 0.210925 * 100, metric = 4.51% * 100;
 Minibatch[1101-1200]: loss = 0.220026 * 100, metric = 4.66% * 100;
 Minibatch[1201-1300]: loss = 0.213623 * 100, metric = 4.49% * 100;
 Minibatch[1301-1400]: loss = 0.219788 * 100, metric = 4.62% * 100;
 Minibatch[1401-1500]: loss = 0.216566 * 100, metric = 4.71% * 100;
 Minibatch[1501-1600]: loss = 0.214625 * 100, metric = 4.52% * 100;
 Minibatch[1601-1700]: loss = 0.220265 * 100, metric = 4.74% * 100;
 Minibatch[1701-1800]: loss = 0.219483 * 100, metric = 4.69% * 100;
 Minibatch[1801-1900]: loss = 0.223834 * 100, metric = 4.64% * 100;
 Minibatch[1901-2000]: loss = 0.224200 * 100, metric = 4.86% * 100;
Finished Epoch[59 of 200]: [Training] loss = 0.218938 * 2000, metric = 4.66% * 2000 749.263s (  2.7 samples/s);
Finished Evaluation [59]: Minibatch[1-2000]: metric = 14.28% * 2000;
 Minibatch[   1- 100]: loss = 0.213537 * 100, metric = 4.49% * 100;
 Minibatch[ 101- 200]: loss = 0.207674 * 100, metric = 4.46% * 100;
 Minibatch[ 201- 300]: loss = 0.209883 * 100, metric = 4.37% * 100;
 Minibatch[ 301- 400]: loss = 0.222012 * 100, metric = 4.71% * 100;
 Minibatch[ 401- 500]: loss = 0.223301 * 100, metric = 4.78% * 100;
 Minibatch[ 501- 600]: loss = 0.227987 * 100, metric = 4.96% * 100;
 Minibatch[ 601- 700]: loss = 0.209599 * 100, metric = 4.36% * 100;
 Minibatch[ 701- 800]: loss = 0.223211 * 100, metric = 4.74% * 100;
 Minibatch[ 801- 900]: loss = 0.217247 * 100, metric = 4.54% * 100;
 Minibatch[ 901-1000]: loss = 0.221332 * 100, metric = 4.80% * 100;
 Minibatch[1001-1100]: loss = 0.231929 * 100, metric = 5.10% * 100;
 Minibatch[1101-1200]: loss = 0.220374 * 100, metric = 4.64% * 100;
 Minibatch[1201-1300]: loss = 0.225360 * 100, metric = 4.84% * 100;
 Minibatch[1301-1400]: loss = 0.215875 * 100, metric = 4.63% * 100;
 Minibatch[1401-1500]: loss = 0.209061 * 100, metric = 4.39% * 100;
 Minibatch[1501-1600]: loss = 0.218990 * 100, metric = 4.65% * 100;
 Minibatch[1601-1700]: loss = 0.220709 * 100, metric = 4.68% * 100;
 Minibatch[1701-1800]: loss = 0.222427 * 100, metric = 4.79% * 100;
 Minibatch[1801-1900]: loss = 0.222084 * 100, metric = 4.76% * 100;
 Minibatch[1901-2000]: loss = 0.213186 * 100, metric = 4.51% * 100;
Finished Epoch[60 of 200]: [Training] loss = 0.218789 * 2000, metric = 4.66% * 2000 743.005s (  2.7 samples/s);
Finished Evaluation [60]: Minibatch[1-2000]: metric = 13.66% * 2000;
 Minibatch[   1- 100]: loss = 0.231738 * 100, metric = 5.08% * 100;
 Minibatch[ 101- 200]: loss = 0.210049 * 100, metric = 4.52% * 100;
 Minibatch[ 201- 300]: loss = 0.215980 * 100, metric = 4.70% * 100;
 Minibatch[ 301- 400]: loss = 0.220024 * 100, metric = 4.61% * 100;
 Minibatch[ 401- 500]: loss = 0.210205 * 100, metric = 4.44% * 100;
 Minibatch[ 501- 600]: loss = 0.198156 * 100, metric = 4.03% * 100;
 Minibatch[ 601- 700]: loss = 0.215160 * 100, metric = 4.52% * 100;
 Minibatch[ 701- 800]: loss = 0.216116 * 100, metric = 4.63% * 100;
 Minibatch[ 801- 900]: loss = 0.207352 * 100, metric = 4.28% * 100;
 Minibatch[ 901-1000]: loss = 0.209971 * 100, metric = 4.42% * 100;
 Minibatch[1001-1100]: loss = 0.216522 * 100, metric = 4.71% * 100;
 Minibatch[1101-1200]: loss = 0.224165 * 100, metric = 4.83% * 100;
 Minibatch[1201-1300]: loss = 0.208670 * 100, metric = 4.36% * 100;
 Minibatch[1301-1400]: loss = 0.200623 * 100, metric = 3.94% * 100;
 Minibatch[1401-1500]: loss = 0.219067 * 100, metric = 4.63% * 100;
 Minibatch[1501-1600]: loss = 0.220210 * 100, metric = 4.76% * 100;
 Minibatch[1601-1700]: loss = 0.227405 * 100, metric = 4.97% * 100;
 Minibatch[1701-1800]: loss = 0.213397 * 100, metric = 4.48% * 100;
 Minibatch[1801-1900]: loss = 0.215005 * 100, metric = 4.66% * 100;
 Minibatch[1901-2000]: loss = 0.211522 * 100, metric = 4.39% * 100;
Finished Epoch[61 of 200]: [Training] loss = 0.214567 * 2000, metric = 4.55% * 2000 747.445s (  2.7 samples/s);
Finished Evaluation [61]: Minibatch[1-2000]: metric = 12.65% * 2000;
 Minibatch[   1- 100]: loss = 0.210760 * 100, metric = 4.49% * 100;
 Minibatch[ 101- 200]: loss = 0.207388 * 100, metric = 4.25% * 100;
 Minibatch[ 201- 300]: loss = 0.209992 * 100, metric = 4.34% * 100;
 Minibatch[ 301- 400]: loss = 0.213734 * 100, metric = 4.77% * 100;
 Minibatch[ 401- 500]: loss = 0.216151 * 100, metric = 4.51% * 100;
 Minibatch[ 501- 600]: loss = 0.220155 * 100, metric = 4.78% * 100;
 Minibatch[ 601- 700]: loss = 0.222763 * 100, metric = 4.91% * 100;
 Minibatch[ 701- 800]: loss = 0.213784 * 100, metric = 4.56% * 100;
 Minibatch[ 801- 900]: loss = 0.217882 * 100, metric = 4.53% * 100;
 Minibatch[ 901-1000]: loss = 0.218013 * 100, metric = 4.67% * 100;
 Minibatch[1001-1100]: loss = 0.203346 * 100, metric = 4.25% * 100;
 Minibatch[1101-1200]: loss = 0.223204 * 100, metric = 4.77% * 100;
 Minibatch[1201-1300]: loss = 0.216388 * 100, metric = 4.58% * 100;
 Minibatch[1301-1400]: loss = 0.226333 * 100, metric = 4.72% * 100;
 Minibatch[1401-1500]: loss = 0.205971 * 100, metric = 4.43% * 100;
 Minibatch[1501-1600]: loss = 0.210890 * 100, metric = 4.34% * 100;
 Minibatch[1601-1700]: loss = 0.213967 * 100, metric = 4.52% * 100;
 Minibatch[1701-1800]: loss = 0.215401 * 100, metric = 4.63% * 100;
 Minibatch[1801-1900]: loss = 0.216617 * 100, metric = 4.58% * 100;
 Minibatch[1901-2000]: loss = 0.216772 * 100, metric = 4.65% * 100;
Finished Epoch[62 of 200]: [Training] loss = 0.214976 * 2000, metric = 4.56% * 2000 752.464s (  2.7 samples/s);
Finished Evaluation [62]: Minibatch[1-2000]: metric = 13.27% * 2000;
 Minibatch[   1- 100]: loss = 0.218086 * 100, metric = 4.68% * 100;
 Minibatch[ 101- 200]: loss = 0.206620 * 100, metric = 4.19% * 100;
 Minibatch[ 201- 300]: loss = 0.223311 * 100, metric = 4.72% * 100;
 Minibatch[ 301- 400]: loss = 0.203587 * 100, metric = 4.27% * 100;
 Minibatch[ 401- 500]: loss = 0.205826 * 100, metric = 4.37% * 100;
 Minibatch[ 501- 600]: loss = 0.209464 * 100, metric = 4.45% * 100;
 Minibatch[ 601- 700]: loss = 0.215376 * 100, metric = 4.63% * 100;
 Minibatch[ 701- 800]: loss = 0.214026 * 100, metric = 4.72% * 100;
 Minibatch[ 801- 900]: loss = 0.210585 * 100, metric = 4.43% * 100;
 Minibatch[ 901-1000]: loss = 0.205358 * 100, metric = 4.21% * 100;
 Minibatch[1001-1100]: loss = 0.217762 * 100, metric = 4.54% * 100;
 Minibatch[1101-1200]: loss = 0.208507 * 100, metric = 4.68% * 100;
 Minibatch[1201-1300]: loss = 0.215370 * 100, metric = 4.53% * 100;
 Minibatch[1301-1400]: loss = 0.212460 * 100, metric = 4.56% * 100;
 Minibatch[1401-1500]: loss = 0.203417 * 100, metric = 4.26% * 100;
 Minibatch[1501-1600]: loss = 0.207070 * 100, metric = 4.44% * 100;
 Minibatch[1601-1700]: loss = 0.208323 * 100, metric = 4.43% * 100;
 Minibatch[1701-1800]: loss = 0.204164 * 100, metric = 4.35% * 100;
 Minibatch[1801-1900]: loss = 0.206945 * 100, metric = 4.22% * 100;
 Minibatch[1901-2000]: loss = 0.213344 * 100, metric = 4.49% * 100;
Finished Epoch[63 of 200]: [Training] loss = 0.210480 * 2000, metric = 4.46% * 2000 747.531s (  2.7 samples/s);
Finished Evaluation [63]: Minibatch[1-2000]: metric = 12.61% * 2000;
 Minibatch[   1- 100]: loss = 0.205296 * 100, metric = 4.22% * 100;
 Minibatch[ 101- 200]: loss = 0.213507 * 100, metric = 4.54% * 100;
 Minibatch[ 201- 300]: loss = 0.209663 * 100, metric = 4.45% * 100;
 Minibatch[ 301- 400]: loss = 0.215289 * 100, metric = 4.58% * 100;
 Minibatch[ 401- 500]: loss = 0.205304 * 100, metric = 4.40% * 100;
 Minibatch[ 501- 600]: loss = 0.204855 * 100, metric = 4.25% * 100;
 Minibatch[ 601- 700]: loss = 0.206711 * 100, metric = 4.15% * 100;
 Minibatch[ 701- 800]: loss = 0.213810 * 100, metric = 4.59% * 100;
 Minibatch[ 801- 900]: loss = 0.211902 * 100, metric = 4.45% * 100;
 Minibatch[ 901-1000]: loss = 0.202882 * 100, metric = 4.36% * 100;
 Minibatch[1001-1100]: loss = 0.204605 * 100, metric = 4.35% * 100;
 Minibatch[1101-1200]: loss = 0.207141 * 100, metric = 4.32% * 100;
 Minibatch[1201-1300]: loss = 0.209487 * 100, metric = 4.45% * 100;
 Minibatch[1301-1400]: loss = 0.221414 * 100, metric = 4.81% * 100;
 Minibatch[1401-1500]: loss = 0.217237 * 100, metric = 4.78% * 100;
 Minibatch[1501-1600]: loss = 0.214613 * 100, metric = 4.66% * 100;
 Minibatch[1601-1700]: loss = 0.201901 * 100, metric = 4.25% * 100;
 Minibatch[1701-1800]: loss = 0.207352 * 100, metric = 4.33% * 100;
 Minibatch[1801-1900]: loss = 0.212551 * 100, metric = 4.57% * 100;
 Minibatch[1901-2000]: loss = 0.207523 * 100, metric = 4.51% * 100;
Finished Epoch[64 of 200]: [Training] loss = 0.209652 * 2000, metric = 4.45% * 2000 751.797s (  2.7 samples/s);
Finished Evaluation [64]: Minibatch[1-2000]: metric = 14.34% * 2000;
 Minibatch[   1- 100]: loss = 0.209905 * 100, metric = 4.49% * 100;
 Minibatch[ 101- 200]: loss = 0.203191 * 100, metric = 4.36% * 100;
 Minibatch[ 201- 300]: loss = 0.212112 * 100, metric = 4.49% * 100;
 Minibatch[ 301- 400]: loss = 0.217706 * 100, metric = 4.62% * 100;
 Minibatch[ 401- 500]: loss = 0.208692 * 100, metric = 4.39% * 100;
 Minibatch[ 501- 600]: loss = 0.205653 * 100, metric = 4.38% * 100;
 Minibatch[ 601- 700]: loss = 0.212453 * 100, metric = 4.47% * 100;
 Minibatch[ 701- 800]: loss = 0.221926 * 100, metric = 4.84% * 100;
 Minibatch[ 801- 900]: loss = 0.206027 * 100, metric = 4.38% * 100;
 Minibatch[ 901-1000]: loss = 0.210044 * 100, metric = 4.58% * 100;
 Minibatch[1001-1100]: loss = 0.208454 * 100, metric = 4.47% * 100;
 Minibatch[1101-1200]: loss = 0.204391 * 100, metric = 4.44% * 100;
 Minibatch[1201-1300]: loss = 0.219535 * 100, metric = 4.66% * 100;
 Minibatch[1301-1400]: loss = 0.206423 * 100, metric = 4.35% * 100;
 Minibatch[1401-1500]: loss = 0.206584 * 100, metric = 4.33% * 100;
 Minibatch[1501-1600]: loss = 0.201432 * 100, metric = 4.24% * 100;
 Minibatch[1601-1700]: loss = 0.214930 * 100, metric = 4.48% * 100;
 Minibatch[1701-1800]: loss = 0.217449 * 100, metric = 4.75% * 100;
 Minibatch[1801-1900]: loss = 0.215644 * 100, metric = 4.60% * 100;
 Minibatch[1901-2000]: loss = 0.210500 * 100, metric = 4.44% * 100;
Finished Epoch[65 of 200]: [Training] loss = 0.210653 * 2000, metric = 4.49% * 2000 778.775s (  2.6 samples/s);
Finished Evaluation [65]: Minibatch[1-2000]: metric = 13.15% * 2000;
 Minibatch[   1- 100]: loss = 0.207055 * 100, metric = 4.44% * 100;
 Minibatch[ 101- 200]: loss = 0.208906 * 100, metric = 4.43% * 100;
 Minibatch[ 201- 300]: loss = 0.208643 * 100, metric = 4.39% * 100;
 Minibatch[ 301- 400]: loss = 0.207797 * 100, metric = 4.42% * 100;
 Minibatch[ 401- 500]: loss = 0.212543 * 100, metric = 4.62% * 100;
 Minibatch[ 501- 600]: loss = 0.199987 * 100, metric = 4.11% * 100;
 Minibatch[ 601- 700]: loss = 0.200124 * 100, metric = 4.22% * 100;
 Minibatch[ 701- 800]: loss = 0.212195 * 100, metric = 4.50% * 100;
 Minibatch[ 801- 900]: loss = 0.192115 * 100, metric = 3.89% * 100;
 Minibatch[ 901-1000]: loss = 0.200480 * 100, metric = 4.01% * 100;
 Minibatch[1001-1100]: loss = 0.207357 * 100, metric = 4.44% * 100;
 Minibatch[1101-1200]: loss = 0.205708 * 100, metric = 4.44% * 100;
 Minibatch[1201-1300]: loss = 0.215004 * 100, metric = 4.55% * 100;
 Minibatch[1301-1400]: loss = 0.206541 * 100, metric = 4.29% * 100;
 Minibatch[1401-1500]: loss = 0.202039 * 100, metric = 4.36% * 100;
 Minibatch[1501-1600]: loss = 0.211194 * 100, metric = 4.53% * 100;
 Minibatch[1601-1700]: loss = 0.213618 * 100, metric = 4.52% * 100;
 Minibatch[1701-1800]: loss = 0.213233 * 100, metric = 4.59% * 100;
 Minibatch[1801-1900]: loss = 0.210715 * 100, metric = 4.58% * 100;
 Minibatch[1901-2000]: loss = 0.206349 * 100, metric = 4.47% * 100;
Finished Epoch[66 of 200]: [Training] loss = 0.207080 * 2000, metric = 4.39% * 2000 778.085s (  2.6 samples/s);
Finished Evaluation [66]: Minibatch[1-2000]: metric = 13.69% * 2000;
 Minibatch[   1- 100]: loss = 0.212447 * 100, metric = 4.52% * 100;
 Minibatch[ 101- 200]: loss = 0.208421 * 100, metric = 4.52% * 100;
 Minibatch[ 201- 300]: loss = 0.208751 * 100, metric = 4.27% * 100;
 Minibatch[ 301- 400]: loss = 0.213649 * 100, metric = 4.65% * 100;
 Minibatch[ 401- 500]: loss = 0.211339 * 100, metric = 4.54% * 100;
 Minibatch[ 501- 600]: loss = 0.210732 * 100, metric = 4.44% * 100;
 Minibatch[ 601- 700]: loss = 0.202114 * 100, metric = 4.31% * 100;
 Minibatch[ 701- 800]: loss = 0.211657 * 100, metric = 4.42% * 100;
 Minibatch[ 801- 900]: loss = 0.201742 * 100, metric = 4.18% * 100;
 Minibatch[ 901-1000]: loss = 0.212556 * 100, metric = 4.32% * 100;
 Minibatch[1001-1100]: loss = 0.201929 * 100, metric = 4.35% * 100;
 Minibatch[1101-1200]: loss = 0.212079 * 100, metric = 4.46% * 100;
 Minibatch[1201-1300]: loss = 0.209786 * 100, metric = 4.45% * 100;
 Minibatch[1301-1400]: loss = 0.213310 * 100, metric = 4.40% * 100;
 Minibatch[1401-1500]: loss = 0.197688 * 100, metric = 4.11% * 100;
 Minibatch[1501-1600]: loss = 0.205056 * 100, metric = 4.24% * 100;
 Minibatch[1601-1700]: loss = 0.198341 * 100, metric = 4.10% * 100;
 Minibatch[1701-1800]: loss = 0.213910 * 100, metric = 4.60% * 100;
 Minibatch[1801-1900]: loss = 0.202938 * 100, metric = 4.31% * 100;
 Minibatch[1901-2000]: loss = 0.213181 * 100, metric = 4.52% * 100;
Finished Epoch[67 of 200]: [Training] loss = 0.208081 * 2000, metric = 4.39% * 2000 787.140s (  2.5 samples/s);
Finished Evaluation [67]: Minibatch[1-2000]: metric = 12.62% * 2000;
 Minibatch[   1- 100]: loss = 0.197329 * 100, metric = 4.12% * 100;
 Minibatch[ 101- 200]: loss = 0.215335 * 100, metric = 4.66% * 100;
 Minibatch[ 201- 300]: loss = 0.209195 * 100, metric = 4.40% * 100;
 Minibatch[ 301- 400]: loss = 0.205042 * 100, metric = 4.38% * 100;
 Minibatch[ 401- 500]: loss = 0.215641 * 100, metric = 4.46% * 100;
 Minibatch[ 501- 600]: loss = 0.206601 * 100, metric = 4.50% * 100;
 Minibatch[ 601- 700]: loss = 0.207460 * 100, metric = 4.49% * 100;
 Minibatch[ 701- 800]: loss = 0.206034 * 100, metric = 4.42% * 100;
 Minibatch[ 801- 900]: loss = 0.204766 * 100, metric = 4.29% * 100;
 Minibatch[ 901-1000]: loss = 0.204768 * 100, metric = 4.27% * 100;
 Minibatch[1001-1100]: loss = 0.210198 * 100, metric = 4.26% * 100;
 Minibatch[1101-1200]: loss = 0.209470 * 100, metric = 4.40% * 100;
 Minibatch[1201-1300]: loss = 0.200754 * 100, metric = 4.11% * 100;
 Minibatch[1301-1400]: loss = 0.196460 * 100, metric = 4.12% * 100;
 Minibatch[1401-1500]: loss = 0.202137 * 100, metric = 4.32% * 100;
 Minibatch[1501-1600]: loss = 0.201202 * 100, metric = 4.33% * 100;
 Minibatch[1601-1700]: loss = 0.200356 * 100, metric = 4.15% * 100;
 Minibatch[1701-1800]: loss = 0.203212 * 100, metric = 4.21% * 100;
 Minibatch[1801-1900]: loss = 0.208692 * 100, metric = 4.45% * 100;
 Minibatch[1901-2000]: loss = 0.201376 * 100, metric = 4.30% * 100;
Finished Epoch[68 of 200]: [Training] loss = 0.205302 * 2000, metric = 4.33% * 2000 780.451s (  2.6 samples/s);
Finished Evaluation [68]: Minibatch[1-2000]: metric = 12.22% * 2000;
 Minibatch[   1- 100]: loss = 0.202104 * 100, metric = 4.40% * 100;
 Minibatch[ 101- 200]: loss = 0.206697 * 100, metric = 4.48% * 100;
 Minibatch[ 201- 300]: loss = 0.199395 * 100, metric = 4.12% * 100;
 Minibatch[ 301- 400]: loss = 0.206860 * 100, metric = 4.44% * 100;
 Minibatch[ 401- 500]: loss = 0.210259 * 100, metric = 4.56% * 100;
 Minibatch[ 501- 600]: loss = 0.213798 * 100, metric = 4.67% * 100;
 Minibatch[ 601- 700]: loss = 0.200543 * 100, metric = 4.20% * 100;
 Minibatch[ 701- 800]: loss = 0.209449 * 100, metric = 4.52% * 100;
 Minibatch[ 801- 900]: loss = 0.197254 * 100, metric = 4.07% * 100;
 Minibatch[ 901-1000]: loss = 0.206568 * 100, metric = 4.43% * 100;
 Minibatch[1001-1100]: loss = 0.209426 * 100, metric = 4.43% * 100;
 Minibatch[1101-1200]: loss = 0.200618 * 100, metric = 3.95% * 100;
 Minibatch[1201-1300]: loss = 0.216509 * 100, metric = 4.63% * 100;
 Minibatch[1301-1400]: loss = 0.204286 * 100, metric = 4.27% * 100;
 Minibatch[1401-1500]: loss = 0.201629 * 100, metric = 4.13% * 100;
 Minibatch[1501-1600]: loss = 0.202552 * 100, metric = 4.18% * 100;
 Minibatch[1601-1700]: loss = 0.207168 * 100, metric = 4.20% * 100;
 Minibatch[1701-1800]: loss = 0.210777 * 100, metric = 4.53% * 100;
 Minibatch[1801-1900]: loss = 0.201426 * 100, metric = 4.17% * 100;
 Minibatch[1901-2000]: loss = 0.206484 * 100, metric = 4.36% * 100;
Finished Epoch[69 of 200]: [Training] loss = 0.205690 * 2000, metric = 4.34% * 2000 783.253s (  2.6 samples/s);
Finished Evaluation [69]: Minibatch[1-2000]: metric = 12.97% * 2000;
 Minibatch[   1- 100]: loss = 0.199854 * 100, metric = 4.11% * 100;
 Minibatch[ 101- 200]: loss = 0.195281 * 100, metric = 4.27% * 100;
 Minibatch[ 201- 300]: loss = 0.197492 * 100, metric = 4.05% * 100;
 Minibatch[ 301- 400]: loss = 0.200378 * 100, metric = 4.17% * 100;
 Minibatch[ 401- 500]: loss = 0.201497 * 100, metric = 4.30% * 100;
 Minibatch[ 501- 600]: loss = 0.209570 * 100, metric = 4.48% * 100;
 Minibatch[ 601- 700]: loss = 0.197403 * 100, metric = 3.93% * 100;
 Minibatch[ 701- 800]: loss = 0.203969 * 100, metric = 4.38% * 100;
 Minibatch[ 801- 900]: loss = 0.200576 * 100, metric = 4.18% * 100;
 Minibatch[ 901-1000]: loss = 0.205460 * 100, metric = 4.35% * 100;
 Minibatch[1001-1100]: loss = 0.197947 * 100, metric = 4.08% * 100;
 Minibatch[1101-1200]: loss = 0.193112 * 100, metric = 4.02% * 100;
 Minibatch[1201-1300]: loss = 0.203077 * 100, metric = 4.39% * 100;
 Minibatch[1301-1400]: loss = 0.205288 * 100, metric = 4.46% * 100;
 Minibatch[1401-1500]: loss = 0.198011 * 100, metric = 3.96% * 100;
 Minibatch[1501-1600]: loss = 0.200412 * 100, metric = 4.31% * 100;
 Minibatch[1601-1700]: loss = 0.206006 * 100, metric = 4.55% * 100;
 Minibatch[1701-1800]: loss = 0.211038 * 100, metric = 4.53% * 100;
 Minibatch[1801-1900]: loss = 0.194401 * 100, metric = 3.99% * 100;
 Minibatch[1901-2000]: loss = 0.203161 * 100, metric = 4.33% * 100;
Finished Epoch[70 of 200]: [Training] loss = 0.201197 * 2000, metric = 4.24% * 2000 782.884s (  2.6 samples/s);
Finished Evaluation [70]: Minibatch[1-2000]: metric = 12.90% * 2000;
 Minibatch[   1- 100]: loss = 0.207413 * 100, metric = 4.46% * 100;
 Minibatch[ 101- 200]: loss = 0.200560 * 100, metric = 4.05% * 100;
 Minibatch[ 201- 300]: loss = 0.203139 * 100, metric = 4.28% * 100;
 Minibatch[ 301- 400]: loss = 0.200347 * 100, metric = 4.09% * 100;
 Minibatch[ 401- 500]: loss = 0.200076 * 100, metric = 4.34% * 100;
 Minibatch[ 501- 600]: loss = 0.217322 * 100, metric = 4.55% * 100;
 Minibatch[ 601- 700]: loss = 0.195862 * 100, metric = 4.26% * 100;
 Minibatch[ 701- 800]: loss = 0.204007 * 100, metric = 4.44% * 100;
 Minibatch[ 801- 900]: loss = 0.211027 * 100, metric = 4.51% * 100;
 Minibatch[ 901-1000]: loss = 0.204816 * 100, metric = 4.27% * 100;
 Minibatch[1001-1100]: loss = 0.205047 * 100, metric = 4.43% * 100;
 Minibatch[1101-1200]: loss = 0.196363 * 100, metric = 4.11% * 100;
 Minibatch[1201-1300]: loss = 0.198810 * 100, metric = 4.14% * 100;
 Minibatch[1301-1400]: loss = 0.196626 * 100, metric = 4.06% * 100;
 Minibatch[1401-1500]: loss = 0.203316 * 100, metric = 4.33% * 100;
 Minibatch[1501-1600]: loss = 0.212410 * 100, metric = 4.60% * 100;
 Minibatch[1601-1700]: loss = 0.201700 * 100, metric = 4.30% * 100;
 Minibatch[1701-1800]: loss = 0.203497 * 100, metric = 4.24% * 100;
 Minibatch[1801-1900]: loss = 0.204576 * 100, metric = 4.31% * 100;
 Minibatch[1901-2000]: loss = 0.205096 * 100, metric = 4.38% * 100;
Finished Epoch[71 of 200]: [Training] loss = 0.203601 * 2000, metric = 4.31% * 2000 780.841s (  2.6 samples/s);
Finished Evaluation [71]: Minibatch[1-2000]: metric = 12.35% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
