Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.347237 * 100, metric = 25.49% * 100;
 Minibatch[ 101- 200]: loss = 1.127251 * 100, metric = 23.46% * 100;
 Minibatch[ 201- 300]: loss = 1.058936 * 100, metric = 21.67% * 100;
 Minibatch[ 301- 400]: loss = 1.061262 * 100, metric = 21.44% * 100;
 Minibatch[ 401- 500]: loss = 1.009834 * 100, metric = 20.56% * 100;
 Minibatch[ 501- 600]: loss = 0.991927 * 100, metric = 19.53% * 100;
 Minibatch[ 601- 700]: loss = 0.961281 * 100, metric = 18.36% * 100;
 Minibatch[ 701- 800]: loss = 0.900639 * 100, metric = 17.23% * 100;
 Minibatch[ 801- 900]: loss = 0.928306 * 100, metric = 17.76% * 100;
 Minibatch[ 901-1000]: loss = 0.933201 * 100, metric = 18.04% * 100;
 Minibatch[1001-1100]: loss = 0.927390 * 100, metric = 17.95% * 100;
 Minibatch[1101-1200]: loss = 0.900945 * 100, metric = 16.80% * 100;
 Minibatch[1201-1300]: loss = 0.892316 * 100, metric = 17.10% * 100;
 Minibatch[1301-1400]: loss = 0.863896 * 100, metric = 16.25% * 100;
 Minibatch[1401-1500]: loss = 0.882981 * 100, metric = 16.43% * 100;
 Minibatch[1501-1600]: loss = 0.849001 * 100, metric = 16.10% * 100;
 Minibatch[1601-1700]: loss = 0.856858 * 100, metric = 16.47% * 100;
 Minibatch[1701-1800]: loss = 0.871041 * 100, metric = 16.22% * 100;
 Minibatch[1801-1900]: loss = 0.855319 * 100, metric = 15.90% * 100;
 Minibatch[1901-2000]: loss = 0.833503 * 100, metric = 15.01% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.952656 * 2000, metric = 18.39% * 2000 998.158s (  2.0 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 24.48% * 2000;
0.8547069217041134
 Minibatch[   1- 100]: loss = 0.828000 * 100, metric = 14.90% * 100;
 Minibatch[ 101- 200]: loss = 0.849145 * 100, metric = 16.15% * 100;
 Minibatch[ 201- 300]: loss = 0.839387 * 100, metric = 14.90% * 100;
 Minibatch[ 301- 400]: loss = 0.835110 * 100, metric = 15.14% * 100;
 Minibatch[ 401- 500]: loss = 0.824429 * 100, metric = 14.85% * 100;
 Minibatch[ 501- 600]: loss = 0.848313 * 100, metric = 14.53% * 100;
 Minibatch[ 601- 700]: loss = 0.806808 * 100, metric = 14.87% * 100;
 Minibatch[ 701- 800]: loss = 0.826221 * 100, metric = 15.32% * 100;
 Minibatch[ 801- 900]: loss = 0.808953 * 100, metric = 15.02% * 100;
 Minibatch[ 901-1000]: loss = 0.783826 * 100, metric = 13.75% * 100;
 Minibatch[1001-1100]: loss = 0.813036 * 100, metric = 14.72% * 100;
 Minibatch[1101-1200]: loss = 0.801439 * 100, metric = 14.27% * 100;
 Minibatch[1201-1300]: loss = 0.791912 * 100, metric = 14.07% * 100;
 Minibatch[1301-1400]: loss = 0.809835 * 100, metric = 14.64% * 100;
 Minibatch[1401-1500]: loss = 0.789969 * 100, metric = 14.01% * 100;
 Minibatch[1501-1600]: loss = 0.784725 * 100, metric = 14.03% * 100;
 Minibatch[1601-1700]: loss = 0.791614 * 100, metric = 13.91% * 100;
 Minibatch[1701-1800]: loss = 0.802993 * 100, metric = 14.40% * 100;
 Minibatch[1801-1900]: loss = 0.805334 * 100, metric = 14.32% * 100;
 Minibatch[1901-2000]: loss = 0.771239 * 100, metric = 13.96% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.810614 * 2000, metric = 14.59% * 2000 928.404s (  2.2 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 21.13% * 2000;
0.7993768156021833
 Minibatch[   1- 100]: loss = 0.781734 * 100, metric = 13.93% * 100;
 Minibatch[ 101- 200]: loss = 0.793347 * 100, metric = 14.26% * 100;
 Minibatch[ 201- 300]: loss = 0.783256 * 100, metric = 13.90% * 100;
 Minibatch[ 301- 400]: loss = 0.798427 * 100, metric = 14.44% * 100;
 Minibatch[ 401- 500]: loss = 0.795585 * 100, metric = 14.38% * 100;
 Minibatch[ 501- 600]: loss = 0.780217 * 100, metric = 13.86% * 100;
 Minibatch[ 601- 700]: loss = 0.797955 * 100, metric = 13.96% * 100;
 Minibatch[ 701- 800]: loss = 0.767744 * 100, metric = 13.20% * 100;
 Minibatch[ 801- 900]: loss = 0.797077 * 100, metric = 14.29% * 100;
 Minibatch[ 901-1000]: loss = 0.761659 * 100, metric = 13.65% * 100;
 Minibatch[1001-1100]: loss = 0.782954 * 100, metric = 13.91% * 100;
 Minibatch[1101-1200]: loss = 0.761603 * 100, metric = 13.51% * 100;
 Minibatch[1201-1300]: loss = 0.762032 * 100, metric = 13.34% * 100;
 Minibatch[1301-1400]: loss = 0.774638 * 100, metric = 13.42% * 100;
 Minibatch[1401-1500]: loss = 0.785093 * 100, metric = 13.97% * 100;
 Minibatch[1501-1600]: loss = 0.763851 * 100, metric = 13.39% * 100;
 Minibatch[1601-1700]: loss = 0.751809 * 100, metric = 13.10% * 100;
 Minibatch[1701-1800]: loss = 0.780786 * 100, metric = 13.65% * 100;
 Minibatch[1801-1900]: loss = 0.762527 * 100, metric = 13.08% * 100;
 Minibatch[1901-2000]: loss = 0.760488 * 100, metric = 13.44% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.777139 * 2000, metric = 13.73% * 2000 927.502s (  2.2 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 18.72% * 2000;
0.7729748507961631
 Minibatch[   1- 100]: loss = 0.786959 * 100, metric = 13.60% * 100;
 Minibatch[ 101- 200]: loss = 0.740994 * 100, metric = 12.72% * 100;
 Minibatch[ 201- 300]: loss = 0.769412 * 100, metric = 13.46% * 100;
 Minibatch[ 301- 400]: loss = 0.726553 * 100, metric = 12.65% * 100;
 Minibatch[ 401- 500]: loss = 0.763328 * 100, metric = 13.29% * 100;
 Minibatch[ 501- 600]: loss = 0.730862 * 100, metric = 12.29% * 100;
 Minibatch[ 601- 700]: loss = 0.743875 * 100, metric = 12.87% * 100;
 Minibatch[ 701- 800]: loss = 0.751807 * 100, metric = 13.02% * 100;
 Minibatch[ 801- 900]: loss = 0.747814 * 100, metric = 13.01% * 100;
 Minibatch[ 901-1000]: loss = 0.754937 * 100, metric = 13.14% * 100;
 Minibatch[1001-1100]: loss = 0.766236 * 100, metric = 13.55% * 100;
 Minibatch[1101-1200]: loss = 0.729458 * 100, metric = 12.90% * 100;
 Minibatch[1201-1300]: loss = 0.744721 * 100, metric = 12.81% * 100;
 Minibatch[1301-1400]: loss = 0.761690 * 100, metric = 13.32% * 100;
 Minibatch[1401-1500]: loss = 0.759691 * 100, metric = 13.28% * 100;
 Minibatch[1501-1600]: loss = 0.727866 * 100, metric = 12.37% * 100;
 Minibatch[1601-1700]: loss = 0.755093 * 100, metric = 13.08% * 100;
 Minibatch[1701-1800]: loss = 0.762836 * 100, metric = 13.38% * 100;
 Minibatch[1801-1900]: loss = 0.735237 * 100, metric = 12.41% * 100;
 Minibatch[1901-2000]: loss = 0.738960 * 100, metric = 12.77% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.749916 * 2000, metric = 13.00% * 2000 928.538s (  2.2 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 21.62% * 2000;
 Minibatch[   1- 100]: loss = 0.770213 * 100, metric = 13.25% * 100;
 Minibatch[ 101- 200]: loss = 0.742816 * 100, metric = 12.84% * 100;
 Minibatch[ 201- 300]: loss = 0.729570 * 100, metric = 12.75% * 100;
 Minibatch[ 301- 400]: loss = 0.767581 * 100, metric = 13.74% * 100;
 Minibatch[ 401- 500]: loss = 0.716693 * 100, metric = 12.10% * 100;
 Minibatch[ 501- 600]: loss = 0.715879 * 100, metric = 11.90% * 100;
 Minibatch[ 601- 700]: loss = 0.737368 * 100, metric = 12.27% * 100;
 Minibatch[ 701- 800]: loss = 0.748384 * 100, metric = 12.73% * 100;
 Minibatch[ 801- 900]: loss = 0.723759 * 100, metric = 11.98% * 100;
 Minibatch[ 901-1000]: loss = 0.713605 * 100, metric = 12.19% * 100;
 Minibatch[1001-1100]: loss = 0.735148 * 100, metric = 12.48% * 100;
 Minibatch[1101-1200]: loss = 0.717651 * 100, metric = 11.91% * 100;
 Minibatch[1201-1300]: loss = 0.727492 * 100, metric = 12.29% * 100;
 Minibatch[1301-1400]: loss = 0.751693 * 100, metric = 12.85% * 100;
 Minibatch[1401-1500]: loss = 0.723286 * 100, metric = 12.23% * 100;
 Minibatch[1501-1600]: loss = 0.715551 * 100, metric = 12.19% * 100;
 Minibatch[1601-1700]: loss = 0.738052 * 100, metric = 13.00% * 100;
 Minibatch[1701-1800]: loss = 0.735935 * 100, metric = 12.56% * 100;
 Minibatch[1801-1900]: loss = 0.727460 * 100, metric = 12.27% * 100;
 Minibatch[1901-2000]: loss = 0.714890 * 100, metric = 12.03% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.732651 * 2000, metric = 12.48% * 2000 932.129s (  2.1 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.23% * 2000;
 Minibatch[   1- 100]: loss = 0.708344 * 100, metric = 11.95% * 100;
 Minibatch[ 101- 200]: loss = 0.716040 * 100, metric = 12.18% * 100;
 Minibatch[ 201- 300]: loss = 0.724101 * 100, metric = 12.12% * 100;
 Minibatch[ 301- 400]: loss = 0.724099 * 100, metric = 12.13% * 100;
 Minibatch[ 401- 500]: loss = 0.691924 * 100, metric = 11.63% * 100;
 Minibatch[ 501- 600]: loss = 0.713968 * 100, metric = 12.13% * 100;
 Minibatch[ 601- 700]: loss = 0.709299 * 100, metric = 12.06% * 100;
 Minibatch[ 701- 800]: loss = 0.724204 * 100, metric = 12.32% * 100;
 Minibatch[ 801- 900]: loss = 0.715120 * 100, metric = 12.08% * 100;
 Minibatch[ 901-1000]: loss = 0.697805 * 100, metric = 12.00% * 100;
 Minibatch[1001-1100]: loss = 0.708271 * 100, metric = 11.50% * 100;
 Minibatch[1101-1200]: loss = 0.725876 * 100, metric = 12.38% * 100;
 Minibatch[1201-1300]: loss = 0.732507 * 100, metric = 12.15% * 100;
 Minibatch[1301-1400]: loss = 0.700064 * 100, metric = 11.81% * 100;
 Minibatch[1401-1500]: loss = 0.715665 * 100, metric = 12.25% * 100;
 Minibatch[1501-1600]: loss = 0.699050 * 100, metric = 11.39% * 100;
 Minibatch[1601-1700]: loss = 0.705275 * 100, metric = 11.70% * 100;
 Minibatch[1701-1800]: loss = 0.691426 * 100, metric = 11.40% * 100;
 Minibatch[1801-1900]: loss = 0.715774 * 100, metric = 12.04% * 100;
 Minibatch[1901-2000]: loss = 0.689573 * 100, metric = 11.45% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.710419 * 2000, metric = 11.93% * 2000 931.581s (  2.1 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.39% * 2000;
0.7720621557384729
 Minibatch[   1- 100]: loss = 0.701871 * 100, metric = 11.65% * 100;
 Minibatch[ 101- 200]: loss = 0.708741 * 100, metric = 11.38% * 100;
 Minibatch[ 201- 300]: loss = 0.712811 * 100, metric = 12.09% * 100;
 Minibatch[ 301- 400]: loss = 0.700574 * 100, metric = 11.34% * 100;
 Minibatch[ 401- 500]: loss = 0.707215 * 100, metric = 11.67% * 100;
 Minibatch[ 501- 600]: loss = 0.697773 * 100, metric = 11.61% * 100;
 Minibatch[ 601- 700]: loss = 0.713070 * 100, metric = 11.71% * 100;
 Minibatch[ 701- 800]: loss = 0.716301 * 100, metric = 11.96% * 100;
 Minibatch[ 801- 900]: loss = 0.720616 * 100, metric = 12.38% * 100;
 Minibatch[ 901-1000]: loss = 0.706397 * 100, metric = 11.92% * 100;
 Minibatch[1001-1100]: loss = 0.712050 * 100, metric = 12.30% * 100;
 Minibatch[1101-1200]: loss = 0.691281 * 100, metric = 11.66% * 100;
 Minibatch[1201-1300]: loss = 0.704473 * 100, metric = 11.89% * 100;
 Minibatch[1301-1400]: loss = 0.689982 * 100, metric = 11.47% * 100;
 Minibatch[1401-1500]: loss = 0.684645 * 100, metric = 11.52% * 100;
 Minibatch[1501-1600]: loss = 0.702722 * 100, metric = 11.77% * 100;
 Minibatch[1601-1700]: loss = 0.702748 * 100, metric = 11.96% * 100;
 Minibatch[1701-1800]: loss = 0.687688 * 100, metric = 11.67% * 100;
 Minibatch[1801-1900]: loss = 0.689694 * 100, metric = 11.75% * 100;
 Minibatch[1901-2000]: loss = 0.695980 * 100, metric = 11.75% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.702332 * 2000, metric = 11.77% * 2000 934.861s (  2.1 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.18% * 2000;
0.7434832490086556
 Minibatch[   1- 100]: loss = 0.702864 * 100, metric = 11.69% * 100;
 Minibatch[ 101- 200]: loss = 0.685492 * 100, metric = 11.62% * 100;
 Minibatch[ 201- 300]: loss = 0.675514 * 100, metric = 11.19% * 100;
 Minibatch[ 301- 400]: loss = 0.681931 * 100, metric = 11.42% * 100;
 Minibatch[ 401- 500]: loss = 0.693024 * 100, metric = 11.94% * 100;
 Minibatch[ 501- 600]: loss = 0.704713 * 100, metric = 11.96% * 100;
 Minibatch[ 601- 700]: loss = 0.671326 * 100, metric = 11.14% * 100;
 Minibatch[ 701- 800]: loss = 0.693350 * 100, metric = 11.56% * 100;
 Minibatch[ 801- 900]: loss = 0.669991 * 100, metric = 10.58% * 100;
 Minibatch[ 901-1000]: loss = 0.658039 * 100, metric = 10.51% * 100;
 Minibatch[1001-1100]: loss = 0.660805 * 100, metric = 10.79% * 100;
 Minibatch[1101-1200]: loss = 0.665349 * 100, metric = 11.10% * 100;
 Minibatch[1201-1300]: loss = 0.686674 * 100, metric = 11.66% * 100;
 Minibatch[1301-1400]: loss = 0.683192 * 100, metric = 11.48% * 100;
 Minibatch[1401-1500]: loss = 0.680621 * 100, metric = 11.27% * 100;
 Minibatch[1501-1600]: loss = 0.684189 * 100, metric = 11.32% * 100;
 Minibatch[1601-1700]: loss = 0.677769 * 100, metric = 11.06% * 100;
 Minibatch[1701-1800]: loss = 0.671227 * 100, metric = 11.03% * 100;
 Minibatch[1801-1900]: loss = 0.684253 * 100, metric = 11.27% * 100;
 Minibatch[1901-2000]: loss = 0.678439 * 100, metric = 11.12% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.680438 * 2000, metric = 11.28% * 2000 932.896s (  2.1 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 17.96% * 2000;
0.7198327537029982
 Minibatch[   1- 100]: loss = 0.649006 * 100, metric = 10.24% * 100;
 Minibatch[ 101- 200]: loss = 0.682589 * 100, metric = 11.62% * 100;
 Minibatch[ 201- 300]: loss = 0.680394 * 100, metric = 11.24% * 100;
 Minibatch[ 301- 400]: loss = 0.692355 * 100, metric = 11.48% * 100;
 Minibatch[ 401- 500]: loss = 0.667979 * 100, metric = 11.00% * 100;
 Minibatch[ 501- 600]: loss = 0.657809 * 100, metric = 10.64% * 100;
 Minibatch[ 601- 700]: loss = 0.661684 * 100, metric = 10.65% * 100;
 Minibatch[ 701- 800]: loss = 0.652704 * 100, metric = 10.38% * 100;
 Minibatch[ 801- 900]: loss = 0.663806 * 100, metric = 10.94% * 100;
 Minibatch[ 901-1000]: loss = 0.673561 * 100, metric = 11.23% * 100;
 Minibatch[1001-1100]: loss = 0.638784 * 100, metric = 10.14% * 100;
 Minibatch[1101-1200]: loss = 0.667985 * 100, metric = 11.19% * 100;
 Minibatch[1201-1300]: loss = 0.657054 * 100, metric = 10.72% * 100;
 Minibatch[1301-1400]: loss = 0.650786 * 100, metric = 10.50% * 100;
 Minibatch[1401-1500]: loss = 0.666899 * 100, metric = 11.12% * 100;
 Minibatch[1501-1600]: loss = 0.666644 * 100, metric = 10.84% * 100;
 Minibatch[1601-1700]: loss = 0.664088 * 100, metric = 10.73% * 100;
 Minibatch[1701-1800]: loss = 0.646714 * 100, metric = 10.37% * 100;
 Minibatch[1801-1900]: loss = 0.645300 * 100, metric = 10.52% * 100;
 Minibatch[1901-2000]: loss = 0.659037 * 100, metric = 10.51% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.662259 * 2000, metric = 10.80% * 2000 933.059s (  2.1 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 17.18% * 2000;
0.7160629836916923
 Minibatch[   1- 100]: loss = 0.682628 * 100, metric = 11.81% * 100;
 Minibatch[ 101- 200]: loss = 0.646212 * 100, metric = 10.58% * 100;
 Minibatch[ 201- 300]: loss = 0.648361 * 100, metric = 10.52% * 100;
 Minibatch[ 301- 400]: loss = 0.645328 * 100, metric = 10.31% * 100;
 Minibatch[ 401- 500]: loss = 0.660065 * 100, metric = 10.93% * 100;
 Minibatch[ 501- 600]: loss = 0.634991 * 100, metric = 10.21% * 100;
 Minibatch[ 601- 700]: loss = 0.628155 * 100, metric = 10.09% * 100;
 Minibatch[ 701- 800]: loss = 0.624745 * 100, metric = 9.53% * 100;
 Minibatch[ 801- 900]: loss = 0.643936 * 100, metric = 10.38% * 100;
 Minibatch[ 901-1000]: loss = 0.650611 * 100, metric = 10.54% * 100;
 Minibatch[1001-1100]: loss = 0.647931 * 100, metric = 10.81% * 100;
 Minibatch[1101-1200]: loss = 0.646758 * 100, metric = 10.53% * 100;
 Minibatch[1201-1300]: loss = 0.636349 * 100, metric = 10.32% * 100;
 Minibatch[1301-1400]: loss = 0.633975 * 100, metric = 10.44% * 100;
 Minibatch[1401-1500]: loss = 0.626264 * 100, metric = 9.96% * 100;
 Minibatch[1501-1600]: loss = 0.636857 * 100, metric = 10.42% * 100;
 Minibatch[1601-1700]: loss = 0.637606 * 100, metric = 10.27% * 100;
 Minibatch[1701-1800]: loss = 0.647648 * 100, metric = 10.48% * 100;
 Minibatch[1801-1900]: loss = 0.654138 * 100, metric = 10.66% * 100;
 Minibatch[1901-2000]: loss = 0.629191 * 100, metric = 10.23% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.643087 * 2000, metric = 10.45% * 2000 946.288s (  2.1 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 17.69% * 2000;
 Minibatch[   1- 100]: loss = 0.622400 * 100, metric = 9.75% * 100;
 Minibatch[ 101- 200]: loss = 0.637155 * 100, metric = 10.21% * 100;
 Minibatch[ 201- 300]: loss = 0.643137 * 100, metric = 10.56% * 100;
 Minibatch[ 301- 400]: loss = 0.636978 * 100, metric = 10.20% * 100;
 Minibatch[ 401- 500]: loss = 0.636895 * 100, metric = 10.42% * 100;
 Minibatch[ 501- 600]: loss = 0.646517 * 100, metric = 10.54% * 100;
 Minibatch[ 601- 700]: loss = 0.630212 * 100, metric = 10.26% * 100;
 Minibatch[ 701- 800]: loss = 0.638827 * 100, metric = 10.42% * 100;
 Minibatch[ 801- 900]: loss = 0.639022 * 100, metric = 10.35% * 100;
 Minibatch[ 901-1000]: loss = 0.653111 * 100, metric = 10.86% * 100;
 Minibatch[1001-1100]: loss = 0.633829 * 100, metric = 10.26% * 100;
 Minibatch[1101-1200]: loss = 0.636460 * 100, metric = 10.49% * 100;
 Minibatch[1201-1300]: loss = 0.632104 * 100, metric = 10.48% * 100;
 Minibatch[1301-1400]: loss = 0.619641 * 100, metric = 10.09% * 100;
 Minibatch[1401-1500]: loss = 0.644285 * 100, metric = 10.55% * 100;
 Minibatch[1501-1600]: loss = 0.627987 * 100, metric = 10.12% * 100;
 Minibatch[1601-1700]: loss = 0.627022 * 100, metric = 10.03% * 100;
 Minibatch[1701-1800]: loss = 0.640944 * 100, metric = 10.39% * 100;
 Minibatch[1801-1900]: loss = 0.626748 * 100, metric = 10.16% * 100;
 Minibatch[1901-2000]: loss = 0.631067 * 100, metric = 10.33% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.635217 * 2000, metric = 10.32% * 2000 962.954s (  2.1 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 17.36% * 2000;
0.7103772825300694
 Minibatch[   1- 100]: loss = 0.613220 * 100, metric = 9.95% * 100;
 Minibatch[ 101- 200]: loss = 0.622557 * 100, metric = 9.76% * 100;
 Minibatch[ 201- 300]: loss = 0.617809 * 100, metric = 10.24% * 100;
 Minibatch[ 301- 400]: loss = 0.652580 * 100, metric = 11.09% * 100;
 Minibatch[ 401- 500]: loss = 0.621334 * 100, metric = 9.86% * 100;
 Minibatch[ 501- 600]: loss = 0.597525 * 100, metric = 9.31% * 100;
 Minibatch[ 601- 700]: loss = 0.613404 * 100, metric = 9.71% * 100;
 Minibatch[ 701- 800]: loss = 0.620113 * 100, metric = 10.03% * 100;
 Minibatch[ 801- 900]: loss = 0.618348 * 100, metric = 9.97% * 100;
 Minibatch[ 901-1000]: loss = 0.624131 * 100, metric = 10.18% * 100;
 Minibatch[1001-1100]: loss = 0.619517 * 100, metric = 10.18% * 100;
 Minibatch[1101-1200]: loss = 0.620722 * 100, metric = 10.07% * 100;
 Minibatch[1201-1300]: loss = 0.620679 * 100, metric = 10.10% * 100;
 Minibatch[1301-1400]: loss = 0.610538 * 100, metric = 9.89% * 100;
 Minibatch[1401-1500]: loss = 0.615687 * 100, metric = 9.84% * 100;
 Minibatch[1501-1600]: loss = 0.584205 * 100, metric = 9.26% * 100;
 Minibatch[1601-1700]: loss = 0.612990 * 100, metric = 9.94% * 100;
 Minibatch[1701-1800]: loss = 0.604246 * 100, metric = 9.47% * 100;
 Minibatch[1801-1900]: loss = 0.607069 * 100, metric = 9.95% * 100;
 Minibatch[1901-2000]: loss = 0.612213 * 100, metric = 9.68% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.615444 * 2000, metric = 9.92% * 2000 965.078s (  2.1 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 18.22% * 2000;
 Minibatch[   1- 100]: loss = 0.612968 * 100, metric = 9.90% * 100;
 Minibatch[ 101- 200]: loss = 0.615130 * 100, metric = 9.89% * 100;
 Minibatch[ 201- 300]: loss = 0.612056 * 100, metric = 9.82% * 100;
 Minibatch[ 301- 400]: loss = 0.620591 * 100, metric = 10.03% * 100;
 Minibatch[ 401- 500]: loss = 0.622337 * 100, metric = 10.56% * 100;
 Minibatch[ 501- 600]: loss = 0.625336 * 100, metric = 10.25% * 100;
 Minibatch[ 601- 700]: loss = 0.589409 * 100, metric = 9.23% * 100;
 Minibatch[ 701- 800]: loss = 0.597060 * 100, metric = 9.35% * 100;
 Minibatch[ 801- 900]: loss = 0.597540 * 100, metric = 9.35% * 100;
 Minibatch[ 901-1000]: loss = 0.621749 * 100, metric = 10.05% * 100;
 Minibatch[1001-1100]: loss = 0.616666 * 100, metric = 10.06% * 100;
 Minibatch[1101-1200]: loss = 0.609159 * 100, metric = 9.78% * 100;
 Minibatch[1201-1300]: loss = 0.606439 * 100, metric = 9.67% * 100;
 Minibatch[1301-1400]: loss = 0.594404 * 100, metric = 9.37% * 100;
 Minibatch[1401-1500]: loss = 0.595599 * 100, metric = 9.33% * 100;
 Minibatch[1501-1600]: loss = 0.589229 * 100, metric = 9.24% * 100;
 Minibatch[1601-1700]: loss = 0.586998 * 100, metric = 9.40% * 100;
 Minibatch[1701-1800]: loss = 0.598704 * 100, metric = 9.35% * 100;
 Minibatch[1801-1900]: loss = 0.584620 * 100, metric = 9.17% * 100;
 Minibatch[1901-2000]: loss = 0.599624 * 100, metric = 9.83% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.604781 * 2000, metric = 9.68% * 2000 964.346s (  2.1 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 19.20% * 2000;
 Minibatch[   1- 100]: loss = 0.589868 * 100, metric = 9.17% * 100;
 Minibatch[ 101- 200]: loss = 0.588665 * 100, metric = 9.20% * 100;
 Minibatch[ 201- 300]: loss = 0.608016 * 100, metric = 9.75% * 100;
 Minibatch[ 301- 400]: loss = 0.602287 * 100, metric = 9.78% * 100;
 Minibatch[ 401- 500]: loss = 0.593634 * 100, metric = 9.47% * 100;
 Minibatch[ 501- 600]: loss = 0.591653 * 100, metric = 9.33% * 100;
 Minibatch[ 601- 700]: loss = 0.596743 * 100, metric = 9.54% * 100;
 Minibatch[ 701- 800]: loss = 0.606908 * 100, metric = 10.04% * 100;
 Minibatch[ 801- 900]: loss = 0.612973 * 100, metric = 10.28% * 100;
 Minibatch[ 901-1000]: loss = 0.606317 * 100, metric = 9.93% * 100;
 Minibatch[1001-1100]: loss = 0.603158 * 100, metric = 9.94% * 100;
 Minibatch[1101-1200]: loss = 0.596193 * 100, metric = 9.53% * 100;
 Minibatch[1201-1300]: loss = 0.578265 * 100, metric = 9.09% * 100;
 Minibatch[1301-1400]: loss = 0.606784 * 100, metric = 10.09% * 100;
 Minibatch[1401-1500]: loss = 0.598214 * 100, metric = 9.68% * 100;
 Minibatch[1501-1600]: loss = 0.575234 * 100, metric = 9.23% * 100;
 Minibatch[1601-1700]: loss = 0.595687 * 100, metric = 9.55% * 100;
 Minibatch[1701-1800]: loss = 0.595782 * 100, metric = 9.43% * 100;
 Minibatch[1801-1900]: loss = 0.597439 * 100, metric = 9.60% * 100;
 Minibatch[1901-2000]: loss = 0.596644 * 100, metric = 9.27% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.597023 * 2000, metric = 9.59% * 2000 954.217s (  2.1 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 19.16% * 2000;
 Minibatch[   1- 100]: loss = 0.585363 * 100, metric = 9.35% * 100;
 Minibatch[ 101- 200]: loss = 0.601042 * 100, metric = 9.72% * 100;
 Minibatch[ 201- 300]: loss = 0.598702 * 100, metric = 9.62% * 100;
 Minibatch[ 301- 400]: loss = 0.575845 * 100, metric = 9.19% * 100;
 Minibatch[ 401- 500]: loss = 0.587107 * 100, metric = 9.40% * 100;
 Minibatch[ 501- 600]: loss = 0.582310 * 100, metric = 8.94% * 100;
 Minibatch[ 601- 700]: loss = 0.572704 * 100, metric = 9.19% * 100;
 Minibatch[ 701- 800]: loss = 0.596281 * 100, metric = 9.65% * 100;
 Minibatch[ 801- 900]: loss = 0.606061 * 100, metric = 9.96% * 100;
 Minibatch[ 901-1000]: loss = 0.593981 * 100, metric = 9.36% * 100;
 Minibatch[1001-1100]: loss = 0.600950 * 100, metric = 9.65% * 100;
 Minibatch[1101-1200]: loss = 0.584583 * 100, metric = 9.57% * 100;
 Minibatch[1201-1300]: loss = 0.578512 * 100, metric = 9.00% * 100;
 Minibatch[1301-1400]: loss = 0.604074 * 100, metric = 9.98% * 100;
 Minibatch[1401-1500]: loss = 0.562367 * 100, metric = 8.87% * 100;
 Minibatch[1501-1600]: loss = 0.578591 * 100, metric = 9.51% * 100;
 Minibatch[1601-1700]: loss = 0.581075 * 100, metric = 9.26% * 100;
 Minibatch[1701-1800]: loss = 0.563785 * 100, metric = 8.70% * 100;
 Minibatch[1801-1900]: loss = 0.573099 * 100, metric = 9.39% * 100;
 Minibatch[1901-2000]: loss = 0.582767 * 100, metric = 9.29% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.585460 * 2000, metric = 9.38% * 2000 954.009s (  2.1 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 16.34% * 2000;
0.6859603246375918
 Minibatch[   1- 100]: loss = 0.599699 * 100, metric = 9.98% * 100;
 Minibatch[ 101- 200]: loss = 0.591761 * 100, metric = 9.27% * 100;
 Minibatch[ 201- 300]: loss = 0.589903 * 100, metric = 9.35% * 100;
 Minibatch[ 301- 400]: loss = 0.592104 * 100, metric = 9.45% * 100;
 Minibatch[ 401- 500]: loss = 0.559567 * 100, metric = 8.61% * 100;
 Minibatch[ 501- 600]: loss = 0.577990 * 100, metric = 9.34% * 100;
 Minibatch[ 601- 700]: loss = 0.569957 * 100, metric = 8.91% * 100;
 Minibatch[ 701- 800]: loss = 0.569843 * 100, metric = 8.74% * 100;
 Minibatch[ 801- 900]: loss = 0.571777 * 100, metric = 9.04% * 100;
 Minibatch[ 901-1000]: loss = 0.577754 * 100, metric = 9.36% * 100;
 Minibatch[1001-1100]: loss = 0.561264 * 100, metric = 8.78% * 100;
 Minibatch[1101-1200]: loss = 0.572303 * 100, metric = 9.27% * 100;
 Minibatch[1201-1300]: loss = 0.564371 * 100, metric = 8.80% * 100;
 Minibatch[1301-1400]: loss = 0.566844 * 100, metric = 8.99% * 100;
 Minibatch[1401-1500]: loss = 0.561783 * 100, metric = 9.18% * 100;
 Minibatch[1501-1600]: loss = 0.568898 * 100, metric = 9.08% * 100;
 Minibatch[1601-1700]: loss = 0.572234 * 100, metric = 8.97% * 100;
 Minibatch[1701-1800]: loss = 0.596079 * 100, metric = 9.32% * 100;
 Minibatch[1801-1900]: loss = 0.582860 * 100, metric = 9.48% * 100;
 Minibatch[1901-2000]: loss = 0.555695 * 100, metric = 8.91% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.575134 * 2000, metric = 9.14% * 2000 954.857s (  2.1 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 16.64% * 2000;
0.6851789495274424
 Minibatch[   1- 100]: loss = 0.560003 * 100, metric = 8.70% * 100;
 Minibatch[ 101- 200]: loss = 0.585516 * 100, metric = 9.47% * 100;
 Minibatch[ 201- 300]: loss = 0.574158 * 100, metric = 9.38% * 100;
 Minibatch[ 301- 400]: loss = 0.569311 * 100, metric = 9.12% * 100;
 Minibatch[ 401- 500]: loss = 0.577989 * 100, metric = 8.98% * 100;
 Minibatch[ 501- 600]: loss = 0.564322 * 100, metric = 8.81% * 100;
 Minibatch[ 601- 700]: loss = 0.544798 * 100, metric = 8.46% * 100;
 Minibatch[ 701- 800]: loss = 0.558029 * 100, metric = 8.63% * 100;
 Minibatch[ 801- 900]: loss = 0.563373 * 100, metric = 8.93% * 100;
 Minibatch[ 901-1000]: loss = 0.560536 * 100, metric = 8.77% * 100;
 Minibatch[1001-1100]: loss = 0.555982 * 100, metric = 8.73% * 100;
 Minibatch[1101-1200]: loss = 0.576736 * 100, metric = 9.14% * 100;
 Minibatch[1201-1300]: loss = 0.574653 * 100, metric = 9.20% * 100;
 Minibatch[1301-1400]: loss = 0.550928 * 100, metric = 8.63% * 100;
 Minibatch[1401-1500]: loss = 0.563945 * 100, metric = 9.06% * 100;
 Minibatch[1501-1600]: loss = 0.566117 * 100, metric = 8.96% * 100;
 Minibatch[1601-1700]: loss = 0.568068 * 100, metric = 9.06% * 100;
 Minibatch[1701-1800]: loss = 0.557794 * 100, metric = 8.65% * 100;
 Minibatch[1801-1900]: loss = 0.578864 * 100, metric = 9.49% * 100;
 Minibatch[1901-2000]: loss = 0.585042 * 100, metric = 9.32% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.566808 * 2000, metric = 8.97% * 2000 952.763s (  2.1 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 16.90% * 2000;
 Minibatch[   1- 100]: loss = 0.553178 * 100, metric = 8.65% * 100;
 Minibatch[ 101- 200]: loss = 0.575628 * 100, metric = 8.96% * 100;
 Minibatch[ 201- 300]: loss = 0.552135 * 100, metric = 8.80% * 100;
 Minibatch[ 301- 400]: loss = 0.563899 * 100, metric = 8.75% * 100;
 Minibatch[ 401- 500]: loss = 0.545819 * 100, metric = 8.19% * 100;
 Minibatch[ 501- 600]: loss = 0.548013 * 100, metric = 8.55% * 100;
 Minibatch[ 601- 700]: loss = 0.563638 * 100, metric = 8.96% * 100;
 Minibatch[ 701- 800]: loss = 0.542097 * 100, metric = 8.56% * 100;
 Minibatch[ 801- 900]: loss = 0.566921 * 100, metric = 8.75% * 100;
 Minibatch[ 901-1000]: loss = 0.563269 * 100, metric = 8.83% * 100;
 Minibatch[1001-1100]: loss = 0.571739 * 100, metric = 9.27% * 100;
 Minibatch[1101-1200]: loss = 0.563530 * 100, metric = 8.89% * 100;
 Minibatch[1201-1300]: loss = 0.569475 * 100, metric = 9.30% * 100;
 Minibatch[1301-1400]: loss = 0.566490 * 100, metric = 9.01% * 100;
 Minibatch[1401-1500]: loss = 0.541736 * 100, metric = 8.29% * 100;
 Minibatch[1501-1600]: loss = 0.557610 * 100, metric = 8.72% * 100;
 Minibatch[1601-1700]: loss = 0.529453 * 100, metric = 8.02% * 100;
 Minibatch[1701-1800]: loss = 0.552928 * 100, metric = 8.52% * 100;
 Minibatch[1801-1900]: loss = 0.533046 * 100, metric = 8.34% * 100;
 Minibatch[1901-2000]: loss = 0.530781 * 100, metric = 7.98% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.554569 * 2000, metric = 8.67% * 2000 940.985s (  2.1 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 16.57% * 2000;
 Minibatch[   1- 100]: loss = 0.553498 * 100, metric = 8.97% * 100;
 Minibatch[ 101- 200]: loss = 0.564658 * 100, metric = 8.83% * 100;
 Minibatch[ 201- 300]: loss = 0.544012 * 100, metric = 8.34% * 100;
 Minibatch[ 301- 400]: loss = 0.547350 * 100, metric = 8.45% * 100;
 Minibatch[ 401- 500]: loss = 0.553065 * 100, metric = 8.40% * 100;
 Minibatch[ 501- 600]: loss = 0.535556 * 100, metric = 8.26% * 100;
 Minibatch[ 601- 700]: loss = 0.556183 * 100, metric = 8.77% * 100;
 Minibatch[ 701- 800]: loss = 0.533723 * 100, metric = 8.27% * 100;
 Minibatch[ 801- 900]: loss = 0.572698 * 100, metric = 9.26% * 100;
 Minibatch[ 901-1000]: loss = 0.541618 * 100, metric = 8.16% * 100;
 Minibatch[1001-1100]: loss = 0.563644 * 100, metric = 8.83% * 100;
 Minibatch[1101-1200]: loss = 0.550170 * 100, metric = 8.62% * 100;
 Minibatch[1201-1300]: loss = 0.543740 * 100, metric = 8.19% * 100;
 Minibatch[1301-1400]: loss = 0.538531 * 100, metric = 8.38% * 100;
 Minibatch[1401-1500]: loss = 0.554956 * 100, metric = 8.61% * 100;
 Minibatch[1501-1600]: loss = 0.562314 * 100, metric = 9.04% * 100;
 Minibatch[1601-1700]: loss = 0.543779 * 100, metric = 8.66% * 100;
 Minibatch[1701-1800]: loss = 0.522608 * 100, metric = 7.90% * 100;
 Minibatch[1801-1900]: loss = 0.538216 * 100, metric = 8.51% * 100;
 Minibatch[1901-2000]: loss = 0.526505 * 100, metric = 8.09% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.547341 * 2000, metric = 8.53% * 2000 943.517s (  2.1 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 15.71% * 2000;
0.672971908338368
 Minibatch[   1- 100]: loss = 0.534584 * 100, metric = 8.22% * 100;
 Minibatch[ 101- 200]: loss = 0.544940 * 100, metric = 8.54% * 100;
 Minibatch[ 201- 300]: loss = 0.539727 * 100, metric = 8.34% * 100;
 Minibatch[ 301- 400]: loss = 0.556158 * 100, metric = 8.39% * 100;
 Minibatch[ 401- 500]: loss = 0.541376 * 100, metric = 8.41% * 100;
 Minibatch[ 501- 600]: loss = 0.544288 * 100, metric = 8.40% * 100;
 Minibatch[ 601- 700]: loss = 0.550055 * 100, metric = 8.76% * 100;
 Minibatch[ 701- 800]: loss = 0.546493 * 100, metric = 8.35% * 100;
 Minibatch[ 801- 900]: loss = 0.553688 * 100, metric = 8.61% * 100;
 Minibatch[ 901-1000]: loss = 0.556614 * 100, metric = 8.74% * 100;
 Minibatch[1001-1100]: loss = 0.523951 * 100, metric = 8.10% * 100;
 Minibatch[1101-1200]: loss = 0.539860 * 100, metric = 8.48% * 100;
 Minibatch[1201-1300]: loss = 0.541271 * 100, metric = 8.44% * 100;
 Minibatch[1301-1400]: loss = 0.551088 * 100, metric = 8.73% * 100;
 Minibatch[1401-1500]: loss = 0.534886 * 100, metric = 8.41% * 100;
 Minibatch[1501-1600]: loss = 0.556578 * 100, metric = 8.79% * 100;
 Minibatch[1601-1700]: loss = 0.544243 * 100, metric = 8.52% * 100;
 Minibatch[1701-1800]: loss = 0.555466 * 100, metric = 8.87% * 100;
 Minibatch[1801-1900]: loss = 0.542047 * 100, metric = 8.42% * 100;
 Minibatch[1901-2000]: loss = 0.541976 * 100, metric = 8.37% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.544964 * 2000, metric = 8.49% * 2000 952.427s (  2.1 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 15.82% * 2000;
0.6714992608129978
 Minibatch[   1- 100]: loss = 0.543873 * 100, metric = 8.45% * 100;
 Minibatch[ 101- 200]: loss = 0.543783 * 100, metric = 8.41% * 100;
 Minibatch[ 201- 300]: loss = 0.540794 * 100, metric = 8.45% * 100;
 Minibatch[ 301- 400]: loss = 0.552998 * 100, metric = 8.93% * 100;
 Minibatch[ 401- 500]: loss = 0.534684 * 100, metric = 8.19% * 100;
 Minibatch[ 501- 600]: loss = 0.529025 * 100, metric = 7.93% * 100;
 Minibatch[ 601- 700]: loss = 0.532660 * 100, metric = 8.31% * 100;
 Minibatch[ 701- 800]: loss = 0.515230 * 100, metric = 7.74% * 100;
 Minibatch[ 801- 900]: loss = 0.550527 * 100, metric = 8.46% * 100;
 Minibatch[ 901-1000]: loss = 0.520882 * 100, metric = 8.17% * 100;
 Minibatch[1001-1100]: loss = 0.531183 * 100, metric = 8.35% * 100;
 Minibatch[1101-1200]: loss = 0.522049 * 100, metric = 7.94% * 100;
 Minibatch[1201-1300]: loss = 0.526581 * 100, metric = 7.85% * 100;
 Minibatch[1301-1400]: loss = 0.521268 * 100, metric = 7.81% * 100;
 Minibatch[1401-1500]: loss = 0.538220 * 100, metric = 8.30% * 100;
 Minibatch[1501-1600]: loss = 0.550010 * 100, metric = 8.65% * 100;
 Minibatch[1601-1700]: loss = 0.531807 * 100, metric = 8.31% * 100;
 Minibatch[1701-1800]: loss = 0.532053 * 100, metric = 8.10% * 100;
 Minibatch[1801-1900]: loss = 0.556484 * 100, metric = 8.91% * 100;
 Minibatch[1901-2000]: loss = 0.515756 * 100, metric = 8.00% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.534493 * 2000, metric = 8.26% * 2000 931.856s (  2.1 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 14.62% * 2000;
0.645585128068924
 Minibatch[   1- 100]: loss = 0.545472 * 100, metric = 8.47% * 100;
 Minibatch[ 101- 200]: loss = 0.540288 * 100, metric = 8.44% * 100;
 Minibatch[ 201- 300]: loss = 0.544185 * 100, metric = 8.34% * 100;
 Minibatch[ 301- 400]: loss = 0.531506 * 100, metric = 8.13% * 100;
 Minibatch[ 401- 500]: loss = 0.523053 * 100, metric = 8.07% * 100;
 Minibatch[ 501- 600]: loss = 0.537973 * 100, metric = 8.26% * 100;
 Minibatch[ 601- 700]: loss = 0.528556 * 100, metric = 8.15% * 100;
 Minibatch[ 701- 800]: loss = 0.524002 * 100, metric = 8.13% * 100;
 Minibatch[ 801- 900]: loss = 0.541145 * 100, metric = 8.32% * 100;
 Minibatch[ 901-1000]: loss = 0.538324 * 100, metric = 8.35% * 100;
 Minibatch[1001-1100]: loss = 0.512928 * 100, metric = 7.88% * 100;
 Minibatch[1101-1200]: loss = 0.506216 * 100, metric = 7.46% * 100;
 Minibatch[1201-1300]: loss = 0.520721 * 100, metric = 7.81% * 100;
 Minibatch[1301-1400]: loss = 0.534437 * 100, metric = 8.29% * 100;
 Minibatch[1401-1500]: loss = 0.517525 * 100, metric = 8.00% * 100;
 Minibatch[1501-1600]: loss = 0.520544 * 100, metric = 7.92% * 100;
 Minibatch[1601-1700]: loss = 0.521672 * 100, metric = 7.91% * 100;
 Minibatch[1701-1800]: loss = 0.528661 * 100, metric = 7.94% * 100;
 Minibatch[1801-1900]: loss = 0.521463 * 100, metric = 8.10% * 100;
 Minibatch[1901-2000]: loss = 0.525347 * 100, metric = 7.76% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.528201 * 2000, metric = 8.09% * 2000 925.619s (  2.2 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 15.68% * 2000;
 Minibatch[   1- 100]: loss = 0.539648 * 100, metric = 8.36% * 100;
 Minibatch[ 101- 200]: loss = 0.538933 * 100, metric = 8.39% * 100;
 Minibatch[ 201- 300]: loss = 0.539094 * 100, metric = 8.23% * 100;
 Minibatch[ 301- 400]: loss = 0.540462 * 100, metric = 8.23% * 100;
 Minibatch[ 401- 500]: loss = 0.541905 * 100, metric = 8.36% * 100;
 Minibatch[ 501- 600]: loss = 0.531299 * 100, metric = 8.13% * 100;
 Minibatch[ 601- 700]: loss = 0.532582 * 100, metric = 8.19% * 100;
 Minibatch[ 701- 800]: loss = 0.518120 * 100, metric = 7.79% * 100;
 Minibatch[ 801- 900]: loss = 0.506847 * 100, metric = 7.84% * 100;
 Minibatch[ 901-1000]: loss = 0.537942 * 100, metric = 8.37% * 100;
 Minibatch[1001-1100]: loss = 0.522056 * 100, metric = 7.90% * 100;
 Minibatch[1101-1200]: loss = 0.524626 * 100, metric = 8.05% * 100;
 Minibatch[1201-1300]: loss = 0.531068 * 100, metric = 8.16% * 100;
 Minibatch[1301-1400]: loss = 0.534724 * 100, metric = 8.43% * 100;
 Minibatch[1401-1500]: loss = 0.513805 * 100, metric = 7.86% * 100;
 Minibatch[1501-1600]: loss = 0.527887 * 100, metric = 8.05% * 100;
 Minibatch[1601-1700]: loss = 0.529037 * 100, metric = 8.21% * 100;
 Minibatch[1701-1800]: loss = 0.527612 * 100, metric = 8.22% * 100;
 Minibatch[1801-1900]: loss = 0.530910 * 100, metric = 8.40% * 100;
 Minibatch[1901-2000]: loss = 0.532538 * 100, metric = 8.19% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.530055 * 2000, metric = 8.17% * 2000 922.575s (  2.2 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 15.86% * 2000;
 Minibatch[   1- 100]: loss = 0.509346 * 100, metric = 7.95% * 100;
 Minibatch[ 101- 200]: loss = 0.529179 * 100, metric = 8.32% * 100;
 Minibatch[ 201- 300]: loss = 0.519731 * 100, metric = 8.06% * 100;
 Minibatch[ 301- 400]: loss = 0.521915 * 100, metric = 7.82% * 100;
 Minibatch[ 401- 500]: loss = 0.518899 * 100, metric = 8.06% * 100;
 Minibatch[ 501- 600]: loss = 0.510553 * 100, metric = 7.66% * 100;
 Minibatch[ 601- 700]: loss = 0.531444 * 100, metric = 8.12% * 100;
 Minibatch[ 701- 800]: loss = 0.518587 * 100, metric = 7.98% * 100;
 Minibatch[ 801- 900]: loss = 0.529907 * 100, metric = 8.22% * 100;
 Minibatch[ 901-1000]: loss = 0.519617 * 100, metric = 8.01% * 100;
 Minibatch[1001-1100]: loss = 0.512896 * 100, metric = 7.78% * 100;
 Minibatch[1101-1200]: loss = 0.530752 * 100, metric = 8.27% * 100;
 Minibatch[1201-1300]: loss = 0.523918 * 100, metric = 8.12% * 100;
 Minibatch[1301-1400]: loss = 0.518204 * 100, metric = 7.82% * 100;
 Minibatch[1401-1500]: loss = 0.515148 * 100, metric = 7.80% * 100;
 Minibatch[1501-1600]: loss = 0.529834 * 100, metric = 7.99% * 100;
 Minibatch[1601-1700]: loss = 0.514673 * 100, metric = 7.88% * 100;
 Minibatch[1701-1800]: loss = 0.513914 * 100, metric = 7.79% * 100;
 Minibatch[1801-1900]: loss = 0.525390 * 100, metric = 7.94% * 100;
 Minibatch[1901-2000]: loss = 0.529634 * 100, metric = 8.14% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.521177 * 2000, metric = 7.98% * 2000 922.043s (  2.2 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 15.36% * 2000;
 Minibatch[   1- 100]: loss = 0.524011 * 100, metric = 8.07% * 100;
 Minibatch[ 101- 200]: loss = 0.516968 * 100, metric = 8.33% * 100;
 Minibatch[ 201- 300]: loss = 0.518606 * 100, metric = 8.21% * 100;
 Minibatch[ 301- 400]: loss = 0.521353 * 100, metric = 8.03% * 100;
 Minibatch[ 401- 500]: loss = 0.516822 * 100, metric = 7.64% * 100;
 Minibatch[ 501- 600]: loss = 0.516573 * 100, metric = 8.14% * 100;
 Minibatch[ 601- 700]: loss = 0.511971 * 100, metric = 7.60% * 100;
 Minibatch[ 701- 800]: loss = 0.505974 * 100, metric = 7.62% * 100;
 Minibatch[ 801- 900]: loss = 0.499697 * 100, metric = 7.71% * 100;
 Minibatch[ 901-1000]: loss = 0.515725 * 100, metric = 8.10% * 100;
 Minibatch[1001-1100]: loss = 0.514160 * 100, metric = 7.95% * 100;
 Minibatch[1101-1200]: loss = 0.524471 * 100, metric = 8.22% * 100;
 Minibatch[1201-1300]: loss = 0.539193 * 100, metric = 8.45% * 100;
 Minibatch[1301-1400]: loss = 0.514921 * 100, metric = 7.72% * 100;
 Minibatch[1401-1500]: loss = 0.504941 * 100, metric = 7.54% * 100;
 Minibatch[1501-1600]: loss = 0.516704 * 100, metric = 8.07% * 100;
 Minibatch[1601-1700]: loss = 0.503410 * 100, metric = 7.86% * 100;
 Minibatch[1701-1800]: loss = 0.519954 * 100, metric = 7.96% * 100;
 Minibatch[1801-1900]: loss = 0.505266 * 100, metric = 7.47% * 100;
 Minibatch[1901-2000]: loss = 0.496016 * 100, metric = 7.40% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.514337 * 2000, metric = 7.90% * 2000 919.957s (  2.2 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.74% * 2000;
 Minibatch[   1- 100]: loss = 0.507849 * 100, metric = 7.85% * 100;
 Minibatch[ 101- 200]: loss = 0.485609 * 100, metric = 7.08% * 100;
 Minibatch[ 201- 300]: loss = 0.508385 * 100, metric = 7.78% * 100;
 Minibatch[ 301- 400]: loss = 0.499285 * 100, metric = 7.60% * 100;
 Minibatch[ 401- 500]: loss = 0.501273 * 100, metric = 7.76% * 100;
 Minibatch[ 501- 600]: loss = 0.497116 * 100, metric = 7.52% * 100;
 Minibatch[ 601- 700]: loss = 0.516239 * 100, metric = 7.84% * 100;
 Minibatch[ 701- 800]: loss = 0.500025 * 100, metric = 7.74% * 100;
 Minibatch[ 801- 900]: loss = 0.493313 * 100, metric = 7.29% * 100;
 Minibatch[ 901-1000]: loss = 0.488568 * 100, metric = 7.45% * 100;
 Minibatch[1001-1100]: loss = 0.506385 * 100, metric = 8.04% * 100;
 Minibatch[1101-1200]: loss = 0.525110 * 100, metric = 8.08% * 100;
 Minibatch[1201-1300]: loss = 0.501794 * 100, metric = 7.58% * 100;
 Minibatch[1301-1400]: loss = 0.483595 * 100, metric = 7.14% * 100;
 Minibatch[1401-1500]: loss = 0.501952 * 100, metric = 7.63% * 100;
 Minibatch[1501-1600]: loss = 0.493928 * 100, metric = 7.32% * 100;
 Minibatch[1601-1700]: loss = 0.520339 * 100, metric = 7.99% * 100;
 Minibatch[1701-1800]: loss = 0.517221 * 100, metric = 7.84% * 100;
 Minibatch[1801-1900]: loss = 0.497484 * 100, metric = 7.44% * 100;
 Minibatch[1901-2000]: loss = 0.497870 * 100, metric = 7.45% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.502167 * 2000, metric = 7.62% * 2000 912.289s (  2.2 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.62% * 2000;
 Minibatch[   1- 100]: loss = 0.505579 * 100, metric = 7.47% * 100;
 Minibatch[ 101- 200]: loss = 0.508656 * 100, metric = 7.65% * 100;
 Minibatch[ 201- 300]: loss = 0.493597 * 100, metric = 7.45% * 100;
 Minibatch[ 301- 400]: loss = 0.503510 * 100, metric = 7.68% * 100;
 Minibatch[ 401- 500]: loss = 0.506247 * 100, metric = 7.83% * 100;
 Minibatch[ 501- 600]: loss = 0.491060 * 100, metric = 7.39% * 100;
 Minibatch[ 601- 700]: loss = 0.495863 * 100, metric = 7.34% * 100;
 Minibatch[ 701- 800]: loss = 0.498653 * 100, metric = 7.49% * 100;
 Minibatch[ 801- 900]: loss = 0.508892 * 100, metric = 7.77% * 100;
 Minibatch[ 901-1000]: loss = 0.503350 * 100, metric = 7.83% * 100;
 Minibatch[1001-1100]: loss = 0.494220 * 100, metric = 7.10% * 100;
 Minibatch[1101-1200]: loss = 0.511918 * 100, metric = 7.78% * 100;
 Minibatch[1201-1300]: loss = 0.498358 * 100, metric = 7.49% * 100;
 Minibatch[1301-1400]: loss = 0.515591 * 100, metric = 7.94% * 100;
 Minibatch[1401-1500]: loss = 0.498409 * 100, metric = 7.64% * 100;
 Minibatch[1501-1600]: loss = 0.498946 * 100, metric = 7.46% * 100;
 Minibatch[1601-1700]: loss = 0.476163 * 100, metric = 7.10% * 100;
 Minibatch[1701-1800]: loss = 0.498718 * 100, metric = 7.25% * 100;
 Minibatch[1801-1900]: loss = 0.496406 * 100, metric = 7.61% * 100;
 Minibatch[1901-2000]: loss = 0.501961 * 100, metric = 7.62% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.500305 * 2000, metric = 7.54% * 2000 909.324s (  2.2 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 14.49% * 2000;
 Minibatch[   1- 100]: loss = 0.501877 * 100, metric = 7.79% * 100;
 Minibatch[ 101- 200]: loss = 0.481518 * 100, metric = 7.15% * 100;
 Minibatch[ 201- 300]: loss = 0.503186 * 100, metric = 7.72% * 100;
 Minibatch[ 301- 400]: loss = 0.499746 * 100, metric = 7.43% * 100;
 Minibatch[ 401- 500]: loss = 0.497229 * 100, metric = 7.42% * 100;
 Minibatch[ 501- 600]: loss = 0.509084 * 100, metric = 7.95% * 100;
 Minibatch[ 601- 700]: loss = 0.488295 * 100, metric = 7.21% * 100;
 Minibatch[ 701- 800]: loss = 0.471586 * 100, metric = 7.05% * 100;
 Minibatch[ 801- 900]: loss = 0.491913 * 100, metric = 7.65% * 100;
 Minibatch[ 901-1000]: loss = 0.506440 * 100, metric = 8.07% * 100;
 Minibatch[1001-1100]: loss = 0.493087 * 100, metric = 7.41% * 100;
 Minibatch[1101-1200]: loss = 0.489728 * 100, metric = 7.06% * 100;
 Minibatch[1201-1300]: loss = 0.489055 * 100, metric = 7.48% * 100;
 Minibatch[1301-1400]: loss = 0.482876 * 100, metric = 7.03% * 100;
 Minibatch[1401-1500]: loss = 0.506991 * 100, metric = 7.67% * 100;
 Minibatch[1501-1600]: loss = 0.487893 * 100, metric = 7.25% * 100;
 Minibatch[1601-1700]: loss = 0.499545 * 100, metric = 7.43% * 100;
 Minibatch[1701-1800]: loss = 0.481689 * 100, metric = 7.04% * 100;
 Minibatch[1801-1900]: loss = 0.491965 * 100, metric = 7.47% * 100;
 Minibatch[1901-2000]: loss = 0.490887 * 100, metric = 7.44% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.493229 * 2000, metric = 7.44% * 2000 936.925s (  2.1 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.94% * 2000;
0.6378214988559484
 Minibatch[   1- 100]: loss = 0.477082 * 100, metric = 7.21% * 100;
 Minibatch[ 101- 200]: loss = 0.477570 * 100, metric = 7.28% * 100;
 Minibatch[ 201- 300]: loss = 0.496979 * 100, metric = 7.70% * 100;
 Minibatch[ 301- 400]: loss = 0.515371 * 100, metric = 7.77% * 100;
 Minibatch[ 401- 500]: loss = 0.478397 * 100, metric = 7.04% * 100;
 Minibatch[ 501- 600]: loss = 0.492771 * 100, metric = 7.24% * 100;
 Minibatch[ 601- 700]: loss = 0.486302 * 100, metric = 7.40% * 100;
 Minibatch[ 701- 800]: loss = 0.495815 * 100, metric = 7.63% * 100;
 Minibatch[ 801- 900]: loss = 0.480949 * 100, metric = 7.37% * 100;
 Minibatch[ 901-1000]: loss = 0.490294 * 100, metric = 7.32% * 100;
 Minibatch[1001-1100]: loss = 0.488631 * 100, metric = 7.48% * 100;
 Minibatch[1101-1200]: loss = 0.475646 * 100, metric = 6.93% * 100;
 Minibatch[1201-1300]: loss = 0.496193 * 100, metric = 7.51% * 100;
 Minibatch[1301-1400]: loss = 0.469342 * 100, metric = 7.06% * 100;
 Minibatch[1401-1500]: loss = 0.500599 * 100, metric = 7.51% * 100;
 Minibatch[1501-1600]: loss = 0.469402 * 100, metric = 7.06% * 100;
 Minibatch[1601-1700]: loss = 0.498342 * 100, metric = 7.54% * 100;
 Minibatch[1701-1800]: loss = 0.476974 * 100, metric = 7.20% * 100;
 Minibatch[1801-1900]: loss = 0.501826 * 100, metric = 7.49% * 100;
 Minibatch[1901-2000]: loss = 0.492186 * 100, metric = 7.43% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.488034 * 2000, metric = 7.36% * 2000 900.689s (  2.2 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 15.54% * 2000;
 Minibatch[   1- 100]: loss = 0.502650 * 100, metric = 7.56% * 100;
 Minibatch[ 101- 200]: loss = 0.471262 * 100, metric = 6.64% * 100;
 Minibatch[ 201- 300]: loss = 0.479435 * 100, metric = 7.03% * 100;
 Minibatch[ 301- 400]: loss = 0.492939 * 100, metric = 7.46% * 100;
 Minibatch[ 401- 500]: loss = 0.485321 * 100, metric = 7.12% * 100;
 Minibatch[ 501- 600]: loss = 0.460868 * 100, metric = 6.56% * 100;
 Minibatch[ 601- 700]: loss = 0.485974 * 100, metric = 7.32% * 100;
 Minibatch[ 701- 800]: loss = 0.476860 * 100, metric = 7.09% * 100;
 Minibatch[ 801- 900]: loss = 0.486414 * 100, metric = 7.32% * 100;
 Minibatch[ 901-1000]: loss = 0.458912 * 100, metric = 6.81% * 100;
 Minibatch[1001-1100]: loss = 0.476801 * 100, metric = 7.04% * 100;
 Minibatch[1101-1200]: loss = 0.492374 * 100, metric = 7.22% * 100;
 Minibatch[1201-1300]: loss = 0.476849 * 100, metric = 7.18% * 100;
 Minibatch[1301-1400]: loss = 0.476144 * 100, metric = 7.18% * 100;
 Minibatch[1401-1500]: loss = 0.476475 * 100, metric = 7.37% * 100;
 Minibatch[1501-1600]: loss = 0.493120 * 100, metric = 7.28% * 100;
 Minibatch[1601-1700]: loss = 0.488403 * 100, metric = 7.14% * 100;
 Minibatch[1701-1800]: loss = 0.493474 * 100, metric = 7.50% * 100;
 Minibatch[1801-1900]: loss = 0.483558 * 100, metric = 7.24% * 100;
 Minibatch[1901-2000]: loss = 0.497875 * 100, metric = 7.59% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.482785 * 2000, metric = 7.18% * 2000 958.131s (  2.1 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 15.28% * 2000;
 Minibatch[   1- 100]: loss = 0.477748 * 100, metric = 6.89% * 100;
 Minibatch[ 101- 200]: loss = 0.493365 * 100, metric = 7.60% * 100;
 Minibatch[ 201- 300]: loss = 0.476970 * 100, metric = 7.23% * 100;
 Minibatch[ 301- 400]: loss = 0.482037 * 100, metric = 7.05% * 100;
 Minibatch[ 401- 500]: loss = 0.478708 * 100, metric = 7.27% * 100;
 Minibatch[ 501- 600]: loss = 0.471926 * 100, metric = 6.96% * 100;
 Minibatch[ 601- 700]: loss = 0.495149 * 100, metric = 7.68% * 100;
 Minibatch[ 701- 800]: loss = 0.491150 * 100, metric = 7.42% * 100;
 Minibatch[ 801- 900]: loss = 0.481670 * 100, metric = 7.20% * 100;
 Minibatch[ 901-1000]: loss = 0.468203 * 100, metric = 6.90% * 100;
 Minibatch[1001-1100]: loss = 0.468956 * 100, metric = 6.98% * 100;
 Minibatch[1101-1200]: loss = 0.475226 * 100, metric = 7.42% * 100;
 Minibatch[1201-1300]: loss = 0.478973 * 100, metric = 7.16% * 100;
 Minibatch[1301-1400]: loss = 0.480031 * 100, metric = 7.31% * 100;
 Minibatch[1401-1500]: loss = 0.484003 * 100, metric = 7.29% * 100;
 Minibatch[1501-1600]: loss = 0.463358 * 100, metric = 6.91% * 100;
 Minibatch[1601-1700]: loss = 0.483273 * 100, metric = 7.20% * 100;
 Minibatch[1701-1800]: loss = 0.478579 * 100, metric = 7.33% * 100;
 Minibatch[1801-1900]: loss = 0.488019 * 100, metric = 7.41% * 100;
 Minibatch[1901-2000]: loss = 0.477413 * 100, metric = 7.16% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.479738 * 2000, metric = 7.22% * 2000 942.283s (  2.1 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 14.37% * 2000;
 Minibatch[   1- 100]: loss = 0.478417 * 100, metric = 7.10% * 100;
 Minibatch[ 101- 200]: loss = 0.488713 * 100, metric = 7.31% * 100;
 Minibatch[ 201- 300]: loss = 0.492203 * 100, metric = 7.42% * 100;
 Minibatch[ 301- 400]: loss = 0.495702 * 100, metric = 7.57% * 100;
 Minibatch[ 401- 500]: loss = 0.481745 * 100, metric = 7.50% * 100;
 Minibatch[ 501- 600]: loss = 0.478103 * 100, metric = 7.30% * 100;
 Minibatch[ 601- 700]: loss = 0.466797 * 100, metric = 6.79% * 100;
 Minibatch[ 701- 800]: loss = 0.468228 * 100, metric = 7.13% * 100;
 Minibatch[ 801- 900]: loss = 0.472030 * 100, metric = 7.17% * 100;
 Minibatch[ 901-1000]: loss = 0.465759 * 100, metric = 6.85% * 100;
 Minibatch[1001-1100]: loss = 0.471152 * 100, metric = 7.01% * 100;
 Minibatch[1101-1200]: loss = 0.476086 * 100, metric = 7.23% * 100;
 Minibatch[1201-1300]: loss = 0.481609 * 100, metric = 7.46% * 100;
 Minibatch[1301-1400]: loss = 0.475030 * 100, metric = 7.23% * 100;
 Minibatch[1401-1500]: loss = 0.474477 * 100, metric = 7.43% * 100;
 Minibatch[1501-1600]: loss = 0.477182 * 100, metric = 7.48% * 100;
 Minibatch[1601-1700]: loss = 0.466218 * 100, metric = 7.06% * 100;
 Minibatch[1701-1800]: loss = 0.480007 * 100, metric = 7.14% * 100;
 Minibatch[1801-1900]: loss = 0.467156 * 100, metric = 6.86% * 100;
 Minibatch[1901-2000]: loss = 0.481878 * 100, metric = 7.53% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.476925 * 2000, metric = 7.23% * 2000 990.226s (  2.0 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 14.67% * 2000;
 Minibatch[   1- 100]: loss = 0.489194 * 100, metric = 7.66% * 100;
 Minibatch[ 101- 200]: loss = 0.477298 * 100, metric = 7.29% * 100;
 Minibatch[ 201- 300]: loss = 0.469460 * 100, metric = 6.99% * 100;
 Minibatch[ 301- 400]: loss = 0.473077 * 100, metric = 7.42% * 100;
 Minibatch[ 401- 500]: loss = 0.471036 * 100, metric = 7.09% * 100;
 Minibatch[ 501- 600]: loss = 0.477220 * 100, metric = 7.16% * 100;
 Minibatch[ 601- 700]: loss = 0.478276 * 100, metric = 7.06% * 100;
 Minibatch[ 701- 800]: loss = 0.478715 * 100, metric = 7.16% * 100;
 Minibatch[ 801- 900]: loss = 0.467065 * 100, metric = 7.00% * 100;
 Minibatch[ 901-1000]: loss = 0.452677 * 100, metric = 6.87% * 100;
 Minibatch[1001-1100]: loss = 0.463729 * 100, metric = 6.95% * 100;
 Minibatch[1101-1200]: loss = 0.454451 * 100, metric = 6.83% * 100;
 Minibatch[1201-1300]: loss = 0.476713 * 100, metric = 7.21% * 100;
 Minibatch[1301-1400]: loss = 0.459299 * 100, metric = 6.64% * 100;
 Minibatch[1401-1500]: loss = 0.484521 * 100, metric = 7.49% * 100;
 Minibatch[1501-1600]: loss = 0.488135 * 100, metric = 7.52% * 100;
 Minibatch[1601-1700]: loss = 0.465215 * 100, metric = 6.90% * 100;
 Minibatch[1701-1800]: loss = 0.473862 * 100, metric = 7.21% * 100;
 Minibatch[1801-1900]: loss = 0.470817 * 100, metric = 6.86% * 100;
 Minibatch[1901-2000]: loss = 0.482742 * 100, metric = 7.43% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.472675 * 2000, metric = 7.14% * 2000 988.087s (  2.0 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 14.14% * 2000;
 Minibatch[   1- 100]: loss = 0.467558 * 100, metric = 7.10% * 100;
 Minibatch[ 101- 200]: loss = 0.477023 * 100, metric = 7.08% * 100;
 Minibatch[ 201- 300]: loss = 0.465022 * 100, metric = 6.82% * 100;
 Minibatch[ 301- 400]: loss = 0.476148 * 100, metric = 7.27% * 100;
 Minibatch[ 401- 500]: loss = 0.460494 * 100, metric = 6.97% * 100;
 Minibatch[ 501- 600]: loss = 0.472679 * 100, metric = 6.94% * 100;
 Minibatch[ 601- 700]: loss = 0.479775 * 100, metric = 7.33% * 100;
 Minibatch[ 701- 800]: loss = 0.466170 * 100, metric = 7.07% * 100;
 Minibatch[ 801- 900]: loss = 0.455612 * 100, metric = 6.38% * 100;
 Minibatch[ 901-1000]: loss = 0.459920 * 100, metric = 7.12% * 100;
 Minibatch[1001-1100]: loss = 0.464148 * 100, metric = 7.09% * 100;
 Minibatch[1101-1200]: loss = 0.464793 * 100, metric = 6.90% * 100;
 Minibatch[1201-1300]: loss = 0.466483 * 100, metric = 7.03% * 100;
 Minibatch[1301-1400]: loss = 0.466699 * 100, metric = 7.08% * 100;
 Minibatch[1401-1500]: loss = 0.472858 * 100, metric = 7.25% * 100;
 Minibatch[1501-1600]: loss = 0.478491 * 100, metric = 7.14% * 100;
 Minibatch[1601-1700]: loss = 0.481723 * 100, metric = 7.44% * 100;
 Minibatch[1701-1800]: loss = 0.473195 * 100, metric = 7.38% * 100;
 Minibatch[1801-1900]: loss = 0.462499 * 100, metric = 6.75% * 100;
 Minibatch[1901-2000]: loss = 0.474308 * 100, metric = 6.93% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.469280 * 2000, metric = 7.05% * 2000 954.627s (  2.1 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.94% * 2000;
 Minibatch[   1- 100]: loss = 0.449641 * 100, metric = 6.64% * 100;
 Minibatch[ 101- 200]: loss = 0.456338 * 100, metric = 6.87% * 100;
 Minibatch[ 201- 300]: loss = 0.466355 * 100, metric = 7.00% * 100;
 Minibatch[ 301- 400]: loss = 0.454060 * 100, metric = 6.67% * 100;
 Minibatch[ 401- 500]: loss = 0.456572 * 100, metric = 6.63% * 100;
 Minibatch[ 501- 600]: loss = 0.437374 * 100, metric = 6.37% * 100;
 Minibatch[ 601- 700]: loss = 0.473191 * 100, metric = 7.23% * 100;
 Minibatch[ 701- 800]: loss = 0.446265 * 100, metric = 6.58% * 100;
 Minibatch[ 801- 900]: loss = 0.454227 * 100, metric = 6.72% * 100;
 Minibatch[ 901-1000]: loss = 0.444943 * 100, metric = 6.59% * 100;
 Minibatch[1001-1100]: loss = 0.468610 * 100, metric = 7.06% * 100;
 Minibatch[1101-1200]: loss = 0.450742 * 100, metric = 6.58% * 100;
 Minibatch[1201-1300]: loss = 0.459401 * 100, metric = 6.94% * 100;
 Minibatch[1301-1400]: loss = 0.467450 * 100, metric = 7.13% * 100;
 Minibatch[1401-1500]: loss = 0.459916 * 100, metric = 6.78% * 100;
 Minibatch[1501-1600]: loss = 0.462917 * 100, metric = 7.06% * 100;
 Minibatch[1601-1700]: loss = 0.456879 * 100, metric = 6.93% * 100;
 Minibatch[1701-1800]: loss = 0.455046 * 100, metric = 6.72% * 100;
 Minibatch[1801-1900]: loss = 0.465538 * 100, metric = 7.12% * 100;
 Minibatch[1901-2000]: loss = 0.446725 * 100, metric = 6.68% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.456610 * 2000, metric = 6.81% * 2000 883.950s (  2.3 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.94% * 2000;
 Minibatch[   1- 100]: loss = 0.454288 * 100, metric = 6.70% * 100;
 Minibatch[ 101- 200]: loss = 0.443584 * 100, metric = 6.68% * 100;
 Minibatch[ 201- 300]: loss = 0.464554 * 100, metric = 7.13% * 100;
 Minibatch[ 301- 400]: loss = 0.445529 * 100, metric = 6.63% * 100;
 Minibatch[ 401- 500]: loss = 0.445603 * 100, metric = 6.53% * 100;
 Minibatch[ 501- 600]: loss = 0.455741 * 100, metric = 6.75% * 100;
 Minibatch[ 601- 700]: loss = 0.455390 * 100, metric = 6.73% * 100;
 Minibatch[ 701- 800]: loss = 0.436351 * 100, metric = 6.59% * 100;
 Minibatch[ 801- 900]: loss = 0.436206 * 100, metric = 6.50% * 100;
 Minibatch[ 901-1000]: loss = 0.461400 * 100, metric = 6.89% * 100;
 Minibatch[1001-1100]: loss = 0.467747 * 100, metric = 7.07% * 100;
 Minibatch[1101-1200]: loss = 0.449114 * 100, metric = 6.82% * 100;
 Minibatch[1201-1300]: loss = 0.458473 * 100, metric = 6.87% * 100;
 Minibatch[1301-1400]: loss = 0.434449 * 100, metric = 6.13% * 100;
 Minibatch[1401-1500]: loss = 0.445650 * 100, metric = 6.43% * 100;
 Minibatch[1501-1600]: loss = 0.441263 * 100, metric = 6.54% * 100;
 Minibatch[1601-1700]: loss = 0.466238 * 100, metric = 7.31% * 100;
 Minibatch[1701-1800]: loss = 0.454918 * 100, metric = 6.65% * 100;
 Minibatch[1801-1900]: loss = 0.451564 * 100, metric = 6.59% * 100;
 Minibatch[1901-2000]: loss = 0.451261 * 100, metric = 6.63% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.450966 * 2000, metric = 6.71% * 2000 809.575s (  2.5 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.92% * 2000;
 Minibatch[   1- 100]: loss = 0.456445 * 100, metric = 6.76% * 100;
 Minibatch[ 101- 200]: loss = 0.464014 * 100, metric = 7.08% * 100;
 Minibatch[ 201- 300]: loss = 0.452849 * 100, metric = 6.82% * 100;
 Minibatch[ 301- 400]: loss = 0.461111 * 100, metric = 6.70% * 100;
 Minibatch[ 401- 500]: loss = 0.451803 * 100, metric = 7.03% * 100;
 Minibatch[ 501- 600]: loss = 0.440866 * 100, metric = 6.58% * 100;
 Minibatch[ 601- 700]: loss = 0.448214 * 100, metric = 6.72% * 100;
 Minibatch[ 701- 800]: loss = 0.464674 * 100, metric = 7.17% * 100;
 Minibatch[ 801- 900]: loss = 0.452735 * 100, metric = 6.72% * 100;
 Minibatch[ 901-1000]: loss = 0.444409 * 100, metric = 6.39% * 100;
 Minibatch[1001-1100]: loss = 0.438026 * 100, metric = 6.60% * 100;
 Minibatch[1101-1200]: loss = 0.463961 * 100, metric = 7.11% * 100;
 Minibatch[1201-1300]: loss = 0.458136 * 100, metric = 7.01% * 100;
 Minibatch[1301-1400]: loss = 0.448212 * 100, metric = 6.53% * 100;
 Minibatch[1401-1500]: loss = 0.457649 * 100, metric = 7.03% * 100;
 Minibatch[1501-1600]: loss = 0.446429 * 100, metric = 6.62% * 100;
 Minibatch[1601-1700]: loss = 0.457921 * 100, metric = 6.88% * 100;
 Minibatch[1701-1800]: loss = 0.453959 * 100, metric = 6.60% * 100;
 Minibatch[1801-1900]: loss = 0.458718 * 100, metric = 6.81% * 100;
 Minibatch[1901-2000]: loss = 0.451627 * 100, metric = 6.73% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.453588 * 2000, metric = 6.79% * 2000 802.802s (  2.5 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 14.97% * 2000;
 Minibatch[   1- 100]: loss = 0.465275 * 100, metric = 7.03% * 100;
 Minibatch[ 101- 200]: loss = 0.458647 * 100, metric = 6.85% * 100;
 Minibatch[ 201- 300]: loss = 0.439539 * 100, metric = 6.47% * 100;
 Minibatch[ 301- 400]: loss = 0.447215 * 100, metric = 6.69% * 100;
 Minibatch[ 401- 500]: loss = 0.450231 * 100, metric = 6.79% * 100;
 Minibatch[ 501- 600]: loss = 0.452847 * 100, metric = 6.75% * 100;
 Minibatch[ 601- 700]: loss = 0.449178 * 100, metric = 6.69% * 100;
 Minibatch[ 701- 800]: loss = 0.450405 * 100, metric = 6.69% * 100;
 Minibatch[ 801- 900]: loss = 0.461862 * 100, metric = 6.83% * 100;
 Minibatch[ 901-1000]: loss = 0.454214 * 100, metric = 6.79% * 100;
 Minibatch[1001-1100]: loss = 0.460565 * 100, metric = 6.94% * 100;
 Minibatch[1101-1200]: loss = 0.439016 * 100, metric = 6.50% * 100;
 Minibatch[1201-1300]: loss = 0.441603 * 100, metric = 6.58% * 100;
 Minibatch[1301-1400]: loss = 0.458536 * 100, metric = 6.74% * 100;
 Minibatch[1401-1500]: loss = 0.447415 * 100, metric = 6.68% * 100;
 Minibatch[1501-1600]: loss = 0.457957 * 100, metric = 6.86% * 100;
 Minibatch[1601-1700]: loss = 0.439369 * 100, metric = 6.44% * 100;
 Minibatch[1701-1800]: loss = 0.448746 * 100, metric = 6.76% * 100;
 Minibatch[1801-1900]: loss = 0.450961 * 100, metric = 6.71% * 100;
 Minibatch[1901-2000]: loss = 0.452923 * 100, metric = 6.59% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.451325 * 2000, metric = 6.72% * 2000 808.639s (  2.5 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 13.40% * 2000;
 Minibatch[   1- 100]: loss = 0.443441 * 100, metric = 6.77% * 100;
 Minibatch[ 101- 200]: loss = 0.452021 * 100, metric = 6.73% * 100;
 Minibatch[ 201- 300]: loss = 0.451568 * 100, metric = 6.61% * 100;
 Minibatch[ 301- 400]: loss = 0.445482 * 100, metric = 6.51% * 100;
 Minibatch[ 401- 500]: loss = 0.450485 * 100, metric = 6.98% * 100;
 Minibatch[ 501- 600]: loss = 0.449862 * 100, metric = 6.76% * 100;
 Minibatch[ 601- 700]: loss = 0.444777 * 100, metric = 6.62% * 100;
 Minibatch[ 701- 800]: loss = 0.451870 * 100, metric = 6.69% * 100;
 Minibatch[ 801- 900]: loss = 0.433548 * 100, metric = 6.32% * 100;
 Minibatch[ 901-1000]: loss = 0.435089 * 100, metric = 6.41% * 100;
 Minibatch[1001-1100]: loss = 0.451126 * 100, metric = 7.01% * 100;
 Minibatch[1101-1200]: loss = 0.446747 * 100, metric = 6.89% * 100;
 Minibatch[1201-1300]: loss = 0.447421 * 100, metric = 6.51% * 100;
 Minibatch[1301-1400]: loss = 0.458802 * 100, metric = 6.92% * 100;
 Minibatch[1401-1500]: loss = 0.455268 * 100, metric = 6.91% * 100;
 Minibatch[1501-1600]: loss = 0.448022 * 100, metric = 6.69% * 100;
 Minibatch[1601-1700]: loss = 0.447634 * 100, metric = 6.66% * 100;
 Minibatch[1701-1800]: loss = 0.450132 * 100, metric = 6.83% * 100;
 Minibatch[1801-1900]: loss = 0.441777 * 100, metric = 6.63% * 100;
 Minibatch[1901-2000]: loss = 0.446010 * 100, metric = 6.51% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.447554 * 2000, metric = 6.70% * 2000 818.802s (  2.4 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.65% * 2000;
 Minibatch[   1- 100]: loss = 0.442287 * 100, metric = 6.85% * 100;
 Minibatch[ 101- 200]: loss = 0.434030 * 100, metric = 6.49% * 100;
 Minibatch[ 201- 300]: loss = 0.454259 * 100, metric = 6.64% * 100;
 Minibatch[ 301- 400]: loss = 0.448107 * 100, metric = 6.93% * 100;
 Minibatch[ 401- 500]: loss = 0.442650 * 100, metric = 6.70% * 100;
 Minibatch[ 501- 600]: loss = 0.431980 * 100, metric = 6.54% * 100;
 Minibatch[ 601- 700]: loss = 0.453648 * 100, metric = 6.75% * 100;
 Minibatch[ 701- 800]: loss = 0.443513 * 100, metric = 6.45% * 100;
 Minibatch[ 801- 900]: loss = 0.440214 * 100, metric = 6.58% * 100;
 Minibatch[ 901-1000]: loss = 0.441437 * 100, metric = 6.61% * 100;
 Minibatch[1001-1100]: loss = 0.448342 * 100, metric = 6.88% * 100;
 Minibatch[1101-1200]: loss = 0.447915 * 100, metric = 6.73% * 100;
 Minibatch[1201-1300]: loss = 0.438589 * 100, metric = 6.59% * 100;
 Minibatch[1301-1400]: loss = 0.445877 * 100, metric = 6.72% * 100;
 Minibatch[1401-1500]: loss = 0.440087 * 100, metric = 6.58% * 100;
 Minibatch[1501-1600]: loss = 0.449732 * 100, metric = 6.81% * 100;
 Minibatch[1601-1700]: loss = 0.447653 * 100, metric = 6.79% * 100;
 Minibatch[1701-1800]: loss = 0.431409 * 100, metric = 6.42% * 100;
 Minibatch[1801-1900]: loss = 0.432585 * 100, metric = 6.39% * 100;
 Minibatch[1901-2000]: loss = 0.449783 * 100, metric = 6.76% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.443205 * 2000, metric = 6.66% * 2000 867.379s (  2.3 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 14.24% * 2000;
 Minibatch[   1- 100]: loss = 0.441037 * 100, metric = 6.54% * 100;
 Minibatch[ 101- 200]: loss = 0.443597 * 100, metric = 6.75% * 100;
 Minibatch[ 201- 300]: loss = 0.451644 * 100, metric = 6.80% * 100;
 Minibatch[ 301- 400]: loss = 0.450499 * 100, metric = 6.88% * 100;
 Minibatch[ 401- 500]: loss = 0.444536 * 100, metric = 6.65% * 100;
 Minibatch[ 501- 600]: loss = 0.435883 * 100, metric = 6.25% * 100;
 Minibatch[ 601- 700]: loss = 0.448445 * 100, metric = 6.86% * 100;
 Minibatch[ 701- 800]: loss = 0.439084 * 100, metric = 6.43% * 100;
 Minibatch[ 801- 900]: loss = 0.429326 * 100, metric = 6.48% * 100;
 Minibatch[ 901-1000]: loss = 0.442023 * 100, metric = 6.76% * 100;
 Minibatch[1001-1100]: loss = 0.445999 * 100, metric = 6.55% * 100;
 Minibatch[1101-1200]: loss = 0.453633 * 100, metric = 6.87% * 100;
 Minibatch[1201-1300]: loss = 0.446752 * 100, metric = 6.74% * 100;
 Minibatch[1301-1400]: loss = 0.430958 * 100, metric = 6.22% * 100;
 Minibatch[1401-1500]: loss = 0.429058 * 100, metric = 6.30% * 100;
 Minibatch[1501-1600]: loss = 0.434486 * 100, metric = 6.21% * 100;
 Minibatch[1601-1700]: loss = 0.437736 * 100, metric = 6.48% * 100;
 Minibatch[1701-1800]: loss = 0.437352 * 100, metric = 6.82% * 100;
 Minibatch[1801-1900]: loss = 0.440217 * 100, metric = 6.71% * 100;
 Minibatch[1901-2000]: loss = 0.433507 * 100, metric = 6.36% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.440789 * 2000, metric = 6.58% * 2000 881.296s (  2.3 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 14.63% * 2000;
 Minibatch[   1- 100]: loss = 0.431536 * 100, metric = 6.55% * 100;
 Minibatch[ 101- 200]: loss = 0.424152 * 100, metric = 6.38% * 100;
 Minibatch[ 201- 300]: loss = 0.423721 * 100, metric = 6.26% * 100;
 Minibatch[ 301- 400]: loss = 0.425668 * 100, metric = 6.26% * 100;
 Minibatch[ 401- 500]: loss = 0.437204 * 100, metric = 6.35% * 100;
 Minibatch[ 501- 600]: loss = 0.437904 * 100, metric = 6.51% * 100;
 Minibatch[ 601- 700]: loss = 0.429479 * 100, metric = 6.52% * 100;
 Minibatch[ 701- 800]: loss = 0.424450 * 100, metric = 6.32% * 100;
 Minibatch[ 801- 900]: loss = 0.426080 * 100, metric = 6.37% * 100;
 Minibatch[ 901-1000]: loss = 0.438523 * 100, metric = 6.69% * 100;
 Minibatch[1001-1100]: loss = 0.428888 * 100, metric = 6.66% * 100;
 Minibatch[1101-1200]: loss = 0.423965 * 100, metric = 6.37% * 100;
 Minibatch[1201-1300]: loss = 0.427048 * 100, metric = 6.25% * 100;
 Minibatch[1301-1400]: loss = 0.436304 * 100, metric = 6.51% * 100;
 Minibatch[1401-1500]: loss = 0.424426 * 100, metric = 6.39% * 100;
 Minibatch[1501-1600]: loss = 0.430233 * 100, metric = 6.23% * 100;
 Minibatch[1601-1700]: loss = 0.427280 * 100, metric = 6.40% * 100;
 Minibatch[1701-1800]: loss = 0.435716 * 100, metric = 6.47% * 100;
 Minibatch[1801-1900]: loss = 0.433773 * 100, metric = 6.39% * 100;
 Minibatch[1901-2000]: loss = 0.428279 * 100, metric = 6.36% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.429731 * 2000, metric = 6.41% * 2000 856.155s (  2.3 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 13.05% * 2000;
0.6346905067563057
 Minibatch[   1- 100]: loss = 0.448253 * 100, metric = 7.17% * 100;
 Minibatch[ 101- 200]: loss = 0.428023 * 100, metric = 6.16% * 100;
 Minibatch[ 201- 300]: loss = 0.435359 * 100, metric = 6.32% * 100;
 Minibatch[ 301- 400]: loss = 0.436069 * 100, metric = 6.50% * 100;
 Minibatch[ 401- 500]: loss = 0.428641 * 100, metric = 6.08% * 100;
 Minibatch[ 501- 600]: loss = 0.424108 * 100, metric = 6.19% * 100;
 Minibatch[ 601- 700]: loss = 0.433885 * 100, metric = 6.47% * 100;
 Minibatch[ 701- 800]: loss = 0.425948 * 100, metric = 6.49% * 100;
 Minibatch[ 801- 900]: loss = 0.421872 * 100, metric = 6.35% * 100;
 Minibatch[ 901-1000]: loss = 0.431174 * 100, metric = 6.23% * 100;
 Minibatch[1001-1100]: loss = 0.426731 * 100, metric = 6.49% * 100;
 Minibatch[1101-1200]: loss = 0.428295 * 100, metric = 6.28% * 100;
 Minibatch[1201-1300]: loss = 0.430366 * 100, metric = 6.67% * 100;
 Minibatch[1301-1400]: loss = 0.432722 * 100, metric = 6.58% * 100;
 Minibatch[1401-1500]: loss = 0.417975 * 100, metric = 6.11% * 100;
 Minibatch[1501-1600]: loss = 0.440787 * 100, metric = 6.49% * 100;
 Minibatch[1601-1700]: loss = 0.422771 * 100, metric = 6.50% * 100;
 Minibatch[1701-1800]: loss = 0.420139 * 100, metric = 6.28% * 100;
 Minibatch[1801-1900]: loss = 0.435323 * 100, metric = 6.76% * 100;
 Minibatch[1901-2000]: loss = 0.429380 * 100, metric = 6.21% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.429891 * 2000, metric = 6.42% * 2000 876.564s (  2.3 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 14.00% * 2000;
 Minibatch[   1- 100]: loss = 0.424033 * 100, metric = 6.34% * 100;
 Minibatch[ 101- 200]: loss = 0.426569 * 100, metric = 6.22% * 100;
 Minibatch[ 201- 300]: loss = 0.427296 * 100, metric = 6.33% * 100;
 Minibatch[ 301- 400]: loss = 0.432564 * 100, metric = 6.32% * 100;
 Minibatch[ 401- 500]: loss = 0.424083 * 100, metric = 6.07% * 100;
 Minibatch[ 501- 600]: loss = 0.420647 * 100, metric = 6.33% * 100;
 Minibatch[ 601- 700]: loss = 0.437178 * 100, metric = 6.66% * 100;
 Minibatch[ 701- 800]: loss = 0.399545 * 100, metric = 5.59% * 100;
 Minibatch[ 801- 900]: loss = 0.416826 * 100, metric = 5.96% * 100;
 Minibatch[ 901-1000]: loss = 0.416943 * 100, metric = 6.11% * 100;
 Minibatch[1001-1100]: loss = 0.412538 * 100, metric = 5.94% * 100;
 Minibatch[1101-1200]: loss = 0.399882 * 100, metric = 5.68% * 100;
 Minibatch[1201-1300]: loss = 0.413641 * 100, metric = 5.93% * 100;
 Minibatch[1301-1400]: loss = 0.412573 * 100, metric = 5.93% * 100;
 Minibatch[1401-1500]: loss = 0.408292 * 100, metric = 6.09% * 100;
 Minibatch[1501-1600]: loss = 0.404298 * 100, metric = 5.80% * 100;
 Minibatch[1601-1700]: loss = 0.415571 * 100, metric = 5.98% * 100;
 Minibatch[1701-1800]: loss = 0.427199 * 100, metric = 6.56% * 100;
 Minibatch[1801-1900]: loss = 0.425058 * 100, metric = 6.15% * 100;
 Minibatch[1901-2000]: loss = 0.406852 * 100, metric = 5.90% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.417579 * 2000, metric = 6.09% * 2000 892.111s (  2.2 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 13.88% * 2000;
 Minibatch[   1- 100]: loss = 0.423174 * 100, metric = 6.27% * 100;
 Minibatch[ 101- 200]: loss = 0.413469 * 100, metric = 5.94% * 100;
 Minibatch[ 201- 300]: loss = 0.417707 * 100, metric = 6.10% * 100;
 Minibatch[ 301- 400]: loss = 0.429609 * 100, metric = 6.59% * 100;
 Minibatch[ 401- 500]: loss = 0.411343 * 100, metric = 6.03% * 100;
 Minibatch[ 501- 600]: loss = 0.401596 * 100, metric = 5.76% * 100;
 Minibatch[ 601- 700]: loss = 0.408322 * 100, metric = 5.85% * 100;
 Minibatch[ 701- 800]: loss = 0.400614 * 100, metric = 6.12% * 100;
 Minibatch[ 801- 900]: loss = 0.435535 * 100, metric = 6.51% * 100;
 Minibatch[ 901-1000]: loss = 0.415385 * 100, metric = 6.18% * 100;
 Minibatch[1001-1100]: loss = 0.403096 * 100, metric = 5.83% * 100;
 Minibatch[1101-1200]: loss = 0.425490 * 100, metric = 6.30% * 100;
 Minibatch[1201-1300]: loss = 0.417249 * 100, metric = 6.20% * 100;
 Minibatch[1301-1400]: loss = 0.415546 * 100, metric = 6.08% * 100;
 Minibatch[1401-1500]: loss = 0.413821 * 100, metric = 6.13% * 100;
 Minibatch[1501-1600]: loss = 0.412527 * 100, metric = 5.98% * 100;
 Minibatch[1601-1700]: loss = 0.406249 * 100, metric = 5.96% * 100;
 Minibatch[1701-1800]: loss = 0.414249 * 100, metric = 6.07% * 100;
 Minibatch[1801-1900]: loss = 0.425782 * 100, metric = 6.24% * 100;
 Minibatch[1901-2000]: loss = 0.408529 * 100, metric = 5.89% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.414965 * 2000, metric = 6.10% * 2000 918.223s (  2.2 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 13.81% * 2000;
 Minibatch[   1- 100]: loss = 0.407830 * 100, metric = 5.98% * 100;
 Minibatch[ 101- 200]: loss = 0.425649 * 100, metric = 6.17% * 100;
 Minibatch[ 201- 300]: loss = 0.410437 * 100, metric = 6.05% * 100;
 Minibatch[ 301- 400]: loss = 0.425806 * 100, metric = 6.43% * 100;
 Minibatch[ 401- 500]: loss = 0.415106 * 100, metric = 5.97% * 100;
 Minibatch[ 501- 600]: loss = 0.412755 * 100, metric = 6.11% * 100;
 Minibatch[ 601- 700]: loss = 0.404423 * 100, metric = 5.92% * 100;
 Minibatch[ 701- 800]: loss = 0.406051 * 100, metric = 6.06% * 100;
 Minibatch[ 801- 900]: loss = 0.414068 * 100, metric = 6.12% * 100;
 Minibatch[ 901-1000]: loss = 0.415929 * 100, metric = 6.06% * 100;
 Minibatch[1001-1100]: loss = 0.406596 * 100, metric = 6.01% * 100;
 Minibatch[1101-1200]: loss = 0.420450 * 100, metric = 6.33% * 100;
 Minibatch[1201-1300]: loss = 0.420775 * 100, metric = 6.18% * 100;
 Minibatch[1301-1400]: loss = 0.413853 * 100, metric = 6.11% * 100;
 Minibatch[1401-1500]: loss = 0.410418 * 100, metric = 6.04% * 100;
 Minibatch[1501-1600]: loss = 0.415677 * 100, metric = 6.04% * 100;
 Minibatch[1601-1700]: loss = 0.400651 * 100, metric = 5.78% * 100;
 Minibatch[1701-1800]: loss = 0.424497 * 100, metric = 6.24% * 100;
 Minibatch[1801-1900]: loss = 0.405857 * 100, metric = 5.83% * 100;
 Minibatch[1901-2000]: loss = 0.405081 * 100, metric = 5.87% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.413095 * 2000, metric = 6.06% * 2000 884.232s (  2.3 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 13.49% * 2000;
 Minibatch[   1- 100]: loss = 0.404941 * 100, metric = 5.87% * 100;
 Minibatch[ 101- 200]: loss = 0.404720 * 100, metric = 5.80% * 100;
 Minibatch[ 201- 300]: loss = 0.410789 * 100, metric = 6.05% * 100;
 Minibatch[ 301- 400]: loss = 0.406281 * 100, metric = 5.78% * 100;
 Minibatch[ 401- 500]: loss = 0.396052 * 100, metric = 5.78% * 100;
 Minibatch[ 501- 600]: loss = 0.404926 * 100, metric = 5.98% * 100;
 Minibatch[ 601- 700]: loss = 0.420530 * 100, metric = 6.20% * 100;
 Minibatch[ 701- 800]: loss = 0.411628 * 100, metric = 6.22% * 100;
 Minibatch[ 801- 900]: loss = 0.409186 * 100, metric = 5.98% * 100;
 Minibatch[ 901-1000]: loss = 0.415713 * 100, metric = 6.12% * 100;
 Minibatch[1001-1100]: loss = 0.423875 * 100, metric = 6.34% * 100;
 Minibatch[1101-1200]: loss = 0.414725 * 100, metric = 6.02% * 100;
 Minibatch[1201-1300]: loss = 0.387577 * 100, metric = 5.69% * 100;
 Minibatch[1301-1400]: loss = 0.403255 * 100, metric = 5.91% * 100;
 Minibatch[1401-1500]: loss = 0.417872 * 100, metric = 6.12% * 100;
 Minibatch[1501-1600]: loss = 0.418953 * 100, metric = 6.11% * 100;
 Minibatch[1601-1700]: loss = 0.403404 * 100, metric = 5.83% * 100;
 Minibatch[1701-1800]: loss = 0.410129 * 100, metric = 6.08% * 100;
 Minibatch[1801-1900]: loss = 0.408692 * 100, metric = 6.09% * 100;
 Minibatch[1901-2000]: loss = 0.412799 * 100, metric = 6.03% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.409302 * 2000, metric = 6.00% * 2000 886.649s (  2.3 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 13.29% * 2000;
 Minibatch[   1- 100]: loss = 0.412077 * 100, metric = 6.04% * 100;
 Minibatch[ 101- 200]: loss = 0.414836 * 100, metric = 6.17% * 100;
 Minibatch[ 201- 300]: loss = 0.399284 * 100, metric = 5.96% * 100;
 Minibatch[ 301- 400]: loss = 0.401667 * 100, metric = 5.74% * 100;
 Minibatch[ 401- 500]: loss = 0.415627 * 100, metric = 6.14% * 100;
 Minibatch[ 501- 600]: loss = 0.420365 * 100, metric = 6.17% * 100;
 Minibatch[ 601- 700]: loss = 0.426662 * 100, metric = 6.12% * 100;
 Minibatch[ 701- 800]: loss = 0.402536 * 100, metric = 5.83% * 100;
 Minibatch[ 801- 900]: loss = 0.401573 * 100, metric = 5.80% * 100;
 Minibatch[ 901-1000]: loss = 0.406225 * 100, metric = 6.14% * 100;
 Minibatch[1001-1100]: loss = 0.403603 * 100, metric = 6.09% * 100;
 Minibatch[1101-1200]: loss = 0.405851 * 100, metric = 5.97% * 100;
 Minibatch[1201-1300]: loss = 0.402295 * 100, metric = 5.95% * 100;
 Minibatch[1301-1400]: loss = 0.402453 * 100, metric = 5.82% * 100;
 Minibatch[1401-1500]: loss = 0.407264 * 100, metric = 6.02% * 100;
 Minibatch[1501-1600]: loss = 0.404184 * 100, metric = 6.07% * 100;
 Minibatch[1601-1700]: loss = 0.400355 * 100, metric = 5.80% * 100;
 Minibatch[1701-1800]: loss = 0.406222 * 100, metric = 5.66% * 100;
 Minibatch[1801-1900]: loss = 0.415538 * 100, metric = 6.11% * 100;
 Minibatch[1901-2000]: loss = 0.395796 * 100, metric = 5.49% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.407221 * 2000, metric = 5.95% * 2000 882.894s (  2.3 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 13.97% * 2000;
 Minibatch[   1- 100]: loss = 0.423249 * 100, metric = 6.21% * 100;
 Minibatch[ 101- 200]: loss = 0.399690 * 100, metric = 5.81% * 100;
 Minibatch[ 201- 300]: loss = 0.411009 * 100, metric = 6.00% * 100;
 Minibatch[ 301- 400]: loss = 0.400327 * 100, metric = 5.86% * 100;
 Minibatch[ 401- 500]: loss = 0.414293 * 100, metric = 6.10% * 100;
 Minibatch[ 501- 600]: loss = 0.406855 * 100, metric = 6.06% * 100;
 Minibatch[ 601- 700]: loss = 0.407489 * 100, metric = 5.87% * 100;
 Minibatch[ 701- 800]: loss = 0.407753 * 100, metric = 5.94% * 100;
 Minibatch[ 801- 900]: loss = 0.395385 * 100, metric = 5.66% * 100;
 Minibatch[ 901-1000]: loss = 0.421413 * 100, metric = 6.22% * 100;
 Minibatch[1001-1100]: loss = 0.413059 * 100, metric = 6.14% * 100;
 Minibatch[1101-1200]: loss = 0.418397 * 100, metric = 6.21% * 100;
 Minibatch[1201-1300]: loss = 0.394231 * 100, metric = 5.78% * 100;
 Minibatch[1301-1400]: loss = 0.419346 * 100, metric = 6.29% * 100;
 Minibatch[1401-1500]: loss = 0.397283 * 100, metric = 6.02% * 100;
 Minibatch[1501-1600]: loss = 0.386797 * 100, metric = 5.45% * 100;
 Minibatch[1601-1700]: loss = 0.419064 * 100, metric = 6.36% * 100;
 Minibatch[1701-1800]: loss = 0.413436 * 100, metric = 6.17% * 100;
 Minibatch[1801-1900]: loss = 0.405426 * 100, metric = 5.99% * 100;
 Minibatch[1901-2000]: loss = 0.400157 * 100, metric = 5.83% * 100;
Finished Epoch[49 of 200]: [Training] loss = 0.407733 * 2000, metric = 6.00% * 2000 886.701s (  2.3 samples/s);
Finished Evaluation [49]: Minibatch[1-2000]: metric = 13.43% * 2000;
 Minibatch[   1- 100]: loss = 0.411094 * 100, metric = 6.09% * 100;
 Minibatch[ 101- 200]: loss = 0.394229 * 100, metric = 5.70% * 100;
 Minibatch[ 201- 300]: loss = 0.399690 * 100, metric = 5.60% * 100;
 Minibatch[ 301- 400]: loss = 0.412167 * 100, metric = 5.81% * 100;
 Minibatch[ 401- 500]: loss = 0.407491 * 100, metric = 6.15% * 100;
 Minibatch[ 501- 600]: loss = 0.419301 * 100, metric = 6.23% * 100;
 Minibatch[ 601- 700]: loss = 0.401929 * 100, metric = 5.89% * 100;
 Minibatch[ 701- 800]: loss = 0.403152 * 100, metric = 5.84% * 100;
 Minibatch[ 801- 900]: loss = 0.406698 * 100, metric = 6.00% * 100;
 Minibatch[ 901-1000]: loss = 0.407307 * 100, metric = 5.71% * 100;
 Minibatch[1001-1100]: loss = 0.397835 * 100, metric = 5.90% * 100;
 Minibatch[1101-1200]: loss = 0.406631 * 100, metric = 5.91% * 100;
 Minibatch[1201-1300]: loss = 0.411487 * 100, metric = 6.08% * 100;
 Minibatch[1301-1400]: loss = 0.391723 * 100, metric = 5.71% * 100;
 Minibatch[1401-1500]: loss = 0.400569 * 100, metric = 5.89% * 100;
 Minibatch[1501-1600]: loss = 0.388124 * 100, metric = 5.53% * 100;
 Minibatch[1601-1700]: loss = 0.400159 * 100, metric = 5.81% * 100;
 Minibatch[1701-1800]: loss = 0.407813 * 100, metric = 5.95% * 100;
 Minibatch[1801-1900]: loss = 0.405988 * 100, metric = 5.86% * 100;
 Minibatch[1901-2000]: loss = 0.404568 * 100, metric = 6.10% * 100;
Finished Epoch[50 of 200]: [Training] loss = 0.403898 * 2000, metric = 5.89% * 2000 885.837s (  2.3 samples/s);
Finished Evaluation [50]: Minibatch[1-2000]: metric = 13.65% * 2000;
 Minibatch[   1- 100]: loss = 0.390785 * 100, metric = 5.54% * 100;
 Minibatch[ 101- 200]: loss = 0.404057 * 100, metric = 5.95% * 100;
 Minibatch[ 201- 300]: loss = 0.408164 * 100, metric = 5.98% * 100;
 Minibatch[ 301- 400]: loss = 0.396547 * 100, metric = 5.71% * 100;
 Minibatch[ 401- 500]: loss = 0.395002 * 100, metric = 5.64% * 100;
 Minibatch[ 501- 600]: loss = 0.401899 * 100, metric = 5.89% * 100;
 Minibatch[ 601- 700]: loss = 0.393689 * 100, metric = 5.76% * 100;
 Minibatch[ 701- 800]: loss = 0.396174 * 100, metric = 5.53% * 100;
 Minibatch[ 801- 900]: loss = 0.400302 * 100, metric = 5.89% * 100;
 Minibatch[ 901-1000]: loss = 0.393537 * 100, metric = 5.71% * 100;
 Minibatch[1001-1100]: loss = 0.399677 * 100, metric = 5.75% * 100;
 Minibatch[1101-1200]: loss = 0.402624 * 100, metric = 5.99% * 100;
 Minibatch[1201-1300]: loss = 0.417129 * 100, metric = 6.01% * 100;
 Minibatch[1301-1400]: loss = 0.405985 * 100, metric = 5.89% * 100;
 Minibatch[1401-1500]: loss = 0.393711 * 100, metric = 5.72% * 100;
 Minibatch[1501-1600]: loss = 0.405560 * 100, metric = 5.93% * 100;
 Minibatch[1601-1700]: loss = 0.391143 * 100, metric = 5.67% * 100;
 Minibatch[1701-1800]: loss = 0.397098 * 100, metric = 5.92% * 100;
 Minibatch[1801-1900]: loss = 0.382253 * 100, metric = 5.64% * 100;
 Minibatch[1901-2000]: loss = 0.385223 * 100, metric = 5.59% * 100;
Finished Epoch[51 of 200]: [Training] loss = 0.398028 * 2000, metric = 5.79% * 2000 888.105s (  2.3 samples/s);
Finished Evaluation [51]: Minibatch[1-2000]: metric = 13.11% * 2000;
 Minibatch[   1- 100]: loss = 0.380769 * 100, metric = 5.66% * 100;
 Minibatch[ 101- 200]: loss = 0.392326 * 100, metric = 5.62% * 100;
 Minibatch[ 201- 300]: loss = 0.403596 * 100, metric = 6.07% * 100;
 Minibatch[ 301- 400]: loss = 0.380987 * 100, metric = 5.65% * 100;
 Minibatch[ 401- 500]: loss = 0.405393 * 100, metric = 5.93% * 100;
 Minibatch[ 501- 600]: loss = 0.393925 * 100, metric = 5.71% * 100;
 Minibatch[ 601- 700]: loss = 0.386567 * 100, metric = 5.56% * 100;
 Minibatch[ 701- 800]: loss = 0.395871 * 100, metric = 5.65% * 100;
 Minibatch[ 801- 900]: loss = 0.403134 * 100, metric = 5.89% * 100;
 Minibatch[ 901-1000]: loss = 0.410141 * 100, metric = 6.01% * 100;
 Minibatch[1001-1100]: loss = 0.395051 * 100, metric = 5.67% * 100;
 Minibatch[1101-1200]: loss = 0.385232 * 100, metric = 5.43% * 100;
 Minibatch[1201-1300]: loss = 0.383615 * 100, metric = 5.56% * 100;
 Minibatch[1301-1400]: loss = 0.388072 * 100, metric = 5.54% * 100;
 Minibatch[1401-1500]: loss = 0.367825 * 100, metric = 5.22% * 100;
 Minibatch[1501-1600]: loss = 0.379796 * 100, metric = 5.31% * 100;
 Minibatch[1601-1700]: loss = 0.397785 * 100, metric = 5.87% * 100;
 Minibatch[1701-1800]: loss = 0.375461 * 100, metric = 5.51% * 100;
 Minibatch[1801-1900]: loss = 0.383716 * 100, metric = 5.41% * 100;
 Minibatch[1901-2000]: loss = 0.390614 * 100, metric = 5.70% * 100;
Finished Epoch[52 of 200]: [Training] loss = 0.389994 * 2000, metric = 5.65% * 2000 838.195s (  2.4 samples/s);
Finished Evaluation [52]: Minibatch[1-2000]: metric = 14.48% * 2000;
 Minibatch[   1- 100]: loss = 0.394352 * 100, metric = 5.78% * 100;
 Minibatch[ 101- 200]: loss = 0.379133 * 100, metric = 5.30% * 100;
 Minibatch[ 201- 300]: loss = 0.386351 * 100, metric = 5.68% * 100;
 Minibatch[ 301- 400]: loss = 0.391280 * 100, metric = 5.70% * 100;
 Minibatch[ 401- 500]: loss = 0.391895 * 100, metric = 5.69% * 100;
 Minibatch[ 501- 600]: loss = 0.394866 * 100, metric = 5.84% * 100;
 Minibatch[ 601- 700]: loss = 0.389058 * 100, metric = 5.66% * 100;
 Minibatch[ 701- 800]: loss = 0.391117 * 100, metric = 5.54% * 100;
 Minibatch[ 801- 900]: loss = 0.395633 * 100, metric = 5.90% * 100;
 Minibatch[ 901-1000]: loss = 0.386774 * 100, metric = 5.68% * 100;
 Minibatch[1001-1100]: loss = 0.400219 * 100, metric = 5.89% * 100;
 Minibatch[1101-1200]: loss = 0.384033 * 100, metric = 5.61% * 100;
 Minibatch[1201-1300]: loss = 0.381386 * 100, metric = 5.53% * 100;
 Minibatch[1301-1400]: loss = 0.391997 * 100, metric = 5.41% * 100;
 Minibatch[1401-1500]: loss = 0.388430 * 100, metric = 5.62% * 100;
 Minibatch[1501-1600]: loss = 0.394964 * 100, metric = 5.88% * 100;
 Minibatch[1601-1700]: loss = 0.386826 * 100, metric = 5.64% * 100;
 Minibatch[1701-1800]: loss = 0.399056 * 100, metric = 5.81% * 100;
 Minibatch[1801-1900]: loss = 0.405214 * 100, metric = 6.00% * 100;
 Minibatch[1901-2000]: loss = 0.378586 * 100, metric = 5.46% * 100;
Finished Epoch[53 of 200]: [Training] loss = 0.390559 * 2000, metric = 5.68% * 2000 848.562s (  2.4 samples/s);
Finished Evaluation [53]: Minibatch[1-2000]: metric = 13.01% * 2000;
 Minibatch[   1- 100]: loss = 0.388655 * 100, metric = 5.53% * 100;
 Minibatch[ 101- 200]: loss = 0.386744 * 100, metric = 5.67% * 100;
 Minibatch[ 201- 300]: loss = 0.386948 * 100, metric = 5.59% * 100;
 Minibatch[ 301- 400]: loss = 0.378158 * 100, metric = 5.39% * 100;
 Minibatch[ 401- 500]: loss = 0.388810 * 100, metric = 5.53% * 100;
 Minibatch[ 501- 600]: loss = 0.382235 * 100, metric = 5.31% * 100;
 Minibatch[ 601- 700]: loss = 0.394140 * 100, metric = 5.68% * 100;
 Minibatch[ 701- 800]: loss = 0.382017 * 100, metric = 5.57% * 100;
 Minibatch[ 801- 900]: loss = 0.372935 * 100, metric = 5.33% * 100;
 Minibatch[ 901-1000]: loss = 0.385386 * 100, metric = 5.51% * 100;
 Minibatch[1001-1100]: loss = 0.381185 * 100, metric = 5.41% * 100;
 Minibatch[1101-1200]: loss = 0.374160 * 100, metric = 5.37% * 100;
 Minibatch[1201-1300]: loss = 0.381079 * 100, metric = 5.51% * 100;
 Minibatch[1301-1400]: loss = 0.375901 * 100, metric = 5.61% * 100;
 Minibatch[1401-1500]: loss = 0.394234 * 100, metric = 5.74% * 100;
 Minibatch[1501-1600]: loss = 0.394309 * 100, metric = 5.82% * 100;
 Minibatch[1601-1700]: loss = 0.378418 * 100, metric = 5.62% * 100;
 Minibatch[1701-1800]: loss = 0.387205 * 100, metric = 5.71% * 100;
 Minibatch[1801-1900]: loss = 0.394944 * 100, metric = 5.78% * 100;
 Minibatch[1901-2000]: loss = 0.393403 * 100, metric = 5.75% * 100;
Finished Epoch[54 of 200]: [Training] loss = 0.385043 * 2000, metric = 5.57% * 2000 848.357s (  2.4 samples/s);
Finished Evaluation [54]: Minibatch[1-2000]: metric = 12.71% * 2000;
 Minibatch[   1- 100]: loss = 0.399196 * 100, metric = 5.81% * 100;
 Minibatch[ 101- 200]: loss = 0.399869 * 100, metric = 5.80% * 100;
 Minibatch[ 201- 300]: loss = 0.384540 * 100, metric = 5.62% * 100;
 Minibatch[ 301- 400]: loss = 0.374981 * 100, metric = 5.09% * 100;
 Minibatch[ 401- 500]: loss = 0.384059 * 100, metric = 5.43% * 100;
 Minibatch[ 501- 600]: loss = 0.389468 * 100, metric = 5.62% * 100;
 Minibatch[ 601- 700]: loss = 0.384540 * 100, metric = 5.54% * 100;
 Minibatch[ 701- 800]: loss = 0.398624 * 100, metric = 5.78% * 100;
 Minibatch[ 801- 900]: loss = 0.385686 * 100, metric = 5.59% * 100;
 Minibatch[ 901-1000]: loss = 0.378314 * 100, metric = 5.36% * 100;
 Minibatch[1001-1100]: loss = 0.390071 * 100, metric = 5.58% * 100;
 Minibatch[1101-1200]: loss = 0.398595 * 100, metric = 5.87% * 100;
 Minibatch[1201-1300]: loss = 0.397788 * 100, metric = 5.78% * 100;
 Minibatch[1301-1400]: loss = 0.378824 * 100, metric = 5.40% * 100;
 Minibatch[1401-1500]: loss = 0.376682 * 100, metric = 5.43% * 100;
 Minibatch[1501-1600]: loss = 0.393069 * 100, metric = 5.72% * 100;
 Minibatch[1601-1700]: loss = 0.382203 * 100, metric = 5.67% * 100;
 Minibatch[1701-1800]: loss = 0.392150 * 100, metric = 5.84% * 100;
 Minibatch[1801-1900]: loss = 0.382396 * 100, metric = 5.64% * 100;
 Minibatch[1901-2000]: loss = 0.380059 * 100, metric = 5.53% * 100;
Finished Epoch[55 of 200]: [Training] loss = 0.387556 * 2000, metric = 5.61% * 2000 843.568s (  2.4 samples/s);
Finished Evaluation [55]: Minibatch[1-2000]: metric = 13.18% * 2000;
 Minibatch[   1- 100]: loss = 0.386543 * 100, metric = 5.74% * 100;
 Minibatch[ 101- 200]: loss = 0.377719 * 100, metric = 5.44% * 100;
 Minibatch[ 201- 300]: loss = 0.387581 * 100, metric = 5.54% * 100;
 Minibatch[ 301- 400]: loss = 0.387666 * 100, metric = 5.67% * 100;
 Minibatch[ 401- 500]: loss = 0.392589 * 100, metric = 5.69% * 100;
 Minibatch[ 501- 600]: loss = 0.392426 * 100, metric = 5.73% * 100;
 Minibatch[ 601- 700]: loss = 0.384110 * 100, metric = 5.48% * 100;
 Minibatch[ 701- 800]: loss = 0.374750 * 100, metric = 5.32% * 100;
 Minibatch[ 801- 900]: loss = 0.379122 * 100, metric = 5.49% * 100;
 Minibatch[ 901-1000]: loss = 0.386638 * 100, metric = 5.61% * 100;
 Minibatch[1001-1100]: loss = 0.390667 * 100, metric = 5.62% * 100;
 Minibatch[1101-1200]: loss = 0.389934 * 100, metric = 5.55% * 100;
 Minibatch[1201-1300]: loss = 0.382886 * 100, metric = 5.24% * 100;
 Minibatch[1301-1400]: loss = 0.382419 * 100, metric = 5.31% * 100;
 Minibatch[1401-1500]: loss = 0.385687 * 100, metric = 5.50% * 100;
 Minibatch[1501-1600]: loss = 0.382114 * 100, metric = 5.47% * 100;
 Minibatch[1601-1700]: loss = 0.375655 * 100, metric = 5.24% * 100;
 Minibatch[1701-1800]: loss = 0.375523 * 100, metric = 5.44% * 100;
 Minibatch[1801-1900]: loss = 0.370078 * 100, metric = 5.20% * 100;
 Minibatch[1901-2000]: loss = 0.396656 * 100, metric = 5.83% * 100;
Finished Epoch[56 of 200]: [Training] loss = 0.384038 * 2000, metric = 5.51% * 2000 845.456s (  2.4 samples/s);
Finished Evaluation [56]: Minibatch[1-2000]: metric = 12.80% * 2000;
 Minibatch[   1- 100]: loss = 0.386247 * 100, metric = 5.36% * 100;
 Minibatch[ 101- 200]: loss = 0.372416 * 100, metric = 5.33% * 100;
 Minibatch[ 201- 300]: loss = 0.373324 * 100, metric = 5.24% * 100;
 Minibatch[ 301- 400]: loss = 0.376313 * 100, metric = 5.29% * 100;
 Minibatch[ 401- 500]: loss = 0.376826 * 100, metric = 5.29% * 100;
 Minibatch[ 501- 600]: loss = 0.365083 * 100, metric = 5.16% * 100;
 Minibatch[ 601- 700]: loss = 0.380368 * 100, metric = 5.45% * 100;
 Minibatch[ 701- 800]: loss = 0.368402 * 100, metric = 5.22% * 100;
 Minibatch[ 801- 900]: loss = 0.376629 * 100, metric = 5.35% * 100;
 Minibatch[ 901-1000]: loss = 0.379611 * 100, metric = 5.52% * 100;
 Minibatch[1001-1100]: loss = 0.386839 * 100, metric = 5.46% * 100;
 Minibatch[1101-1200]: loss = 0.375914 * 100, metric = 5.38% * 100;
 Minibatch[1201-1300]: loss = 0.379632 * 100, metric = 5.44% * 100;
 Minibatch[1301-1400]: loss = 0.370929 * 100, metric = 5.29% * 100;
 Minibatch[1401-1500]: loss = 0.384031 * 100, metric = 5.48% * 100;
 Minibatch[1501-1600]: loss = 0.369043 * 100, metric = 5.35% * 100;
 Minibatch[1601-1700]: loss = 0.377034 * 100, metric = 5.36% * 100;
 Minibatch[1701-1800]: loss = 0.380042 * 100, metric = 5.55% * 100;
 Minibatch[1801-1900]: loss = 0.385019 * 100, metric = 5.55% * 100;
 Minibatch[1901-2000]: loss = 0.387385 * 100, metric = 5.51% * 100;
Finished Epoch[57 of 200]: [Training] loss = 0.377554 * 2000, metric = 5.38% * 2000 841.529s (  2.4 samples/s);
Finished Evaluation [57]: Minibatch[1-2000]: metric = 12.64% * 2000;
 Minibatch[   1- 100]: loss = 0.376332 * 100, metric = 5.19% * 100;
 Minibatch[ 101- 200]: loss = 0.377550 * 100, metric = 5.41% * 100;
 Minibatch[ 201- 300]: loss = 0.370923 * 100, metric = 5.31% * 100;
 Minibatch[ 301- 400]: loss = 0.385317 * 100, metric = 5.46% * 100;
 Minibatch[ 401- 500]: loss = 0.404461 * 100, metric = 5.96% * 100;
 Minibatch[ 501- 600]: loss = 0.377775 * 100, metric = 5.54% * 100;
 Minibatch[ 601- 700]: loss = 0.385711 * 100, metric = 5.44% * 100;
 Minibatch[ 701- 800]: loss = 0.390314 * 100, metric = 5.79% * 100;
 Minibatch[ 801- 900]: loss = 0.384594 * 100, metric = 5.50% * 100;
 Minibatch[ 901-1000]: loss = 0.370066 * 100, metric = 5.24% * 100;
 Minibatch[1001-1100]: loss = 0.381187 * 100, metric = 5.47% * 100;
 Minibatch[1101-1200]: loss = 0.388657 * 100, metric = 5.52% * 100;
 Minibatch[1201-1300]: loss = 0.378450 * 100, metric = 5.46% * 100;
 Minibatch[1301-1400]: loss = 0.385007 * 100, metric = 5.63% * 100;
 Minibatch[1401-1500]: loss = 0.374216 * 100, metric = 5.33% * 100;
 Minibatch[1501-1600]: loss = 0.383207 * 100, metric = 5.66% * 100;
 Minibatch[1601-1700]: loss = 0.385958 * 100, metric = 5.38% * 100;
 Minibatch[1701-1800]: loss = 0.376640 * 100, metric = 5.43% * 100;
 Minibatch[1801-1900]: loss = 0.372392 * 100, metric = 5.55% * 100;
 Minibatch[1901-2000]: loss = 0.364509 * 100, metric = 5.03% * 100;
Finished Epoch[58 of 200]: [Training] loss = 0.380663 * 2000, metric = 5.47% * 2000 839.457s (  2.4 samples/s);
Finished Evaluation [58]: Minibatch[1-2000]: metric = 13.12% * 2000;
 Minibatch[   1- 100]: loss = 0.388433 * 100, metric = 5.67% * 100;
 Minibatch[ 101- 200]: loss = 0.394877 * 100, metric = 5.94% * 100;
 Minibatch[ 201- 300]: loss = 0.372476 * 100, metric = 5.45% * 100;
 Minibatch[ 301- 400]: loss = 0.369884 * 100, metric = 5.24% * 100;
 Minibatch[ 401- 500]: loss = 0.377618 * 100, metric = 5.44% * 100;
 Minibatch[ 501- 600]: loss = 0.372124 * 100, metric = 5.37% * 100;
 Minibatch[ 601- 700]: loss = 0.374795 * 100, metric = 5.43% * 100;
 Minibatch[ 701- 800]: loss = 0.382873 * 100, metric = 5.30% * 100;
 Minibatch[ 801- 900]: loss = 0.373568 * 100, metric = 5.43% * 100;
 Minibatch[ 901-1000]: loss = 0.375848 * 100, metric = 5.49% * 100;
 Minibatch[1001-1100]: loss = 0.379948 * 100, metric = 5.33% * 100;
 Minibatch[1101-1200]: loss = 0.381238 * 100, metric = 5.39% * 100;
 Minibatch[1201-1300]: loss = 0.379380 * 100, metric = 5.32% * 100;
 Minibatch[1301-1400]: loss = 0.376921 * 100, metric = 5.38% * 100;
 Minibatch[1401-1500]: loss = 0.378220 * 100, metric = 5.30% * 100;
 Minibatch[1501-1600]: loss = 0.377808 * 100, metric = 5.34% * 100;
 Minibatch[1601-1700]: loss = 0.377018 * 100, metric = 5.33% * 100;
 Minibatch[1701-1800]: loss = 0.375977 * 100, metric = 5.43% * 100;
 Minibatch[1801-1900]: loss = 0.373496 * 100, metric = 5.21% * 100;
 Minibatch[1901-2000]: loss = 0.389205 * 100, metric = 5.57% * 100;
Finished Epoch[59 of 200]: [Training] loss = 0.378585 * 2000, metric = 5.42% * 2000 841.357s (  2.4 samples/s);
Finished Evaluation [59]: Minibatch[1-2000]: metric = 12.90% * 2000;
 Minibatch[   1- 100]: loss = 0.372911 * 100, metric = 5.30% * 100;
 Minibatch[ 101- 200]: loss = 0.364777 * 100, metric = 5.03% * 100;
 Minibatch[ 201- 300]: loss = 0.353118 * 100, metric = 4.70% * 100;
 Minibatch[ 301- 400]: loss = 0.382340 * 100, metric = 5.48% * 100;
 Minibatch[ 401- 500]: loss = 0.382189 * 100, metric = 5.64% * 100;
 Minibatch[ 501- 600]: loss = 0.379098 * 100, metric = 5.77% * 100;
 Minibatch[ 601- 700]: loss = 0.358537 * 100, metric = 5.02% * 100;
 Minibatch[ 701- 800]: loss = 0.379882 * 100, metric = 5.30% * 100;
 Minibatch[ 801- 900]: loss = 0.371934 * 100, metric = 5.35% * 100;
 Minibatch[ 901-1000]: loss = 0.377574 * 100, metric = 5.37% * 100;
 Minibatch[1001-1100]: loss = 0.389063 * 100, metric = 5.71% * 100;
 Minibatch[1101-1200]: loss = 0.376367 * 100, metric = 5.37% * 100;
 Minibatch[1201-1300]: loss = 0.371043 * 100, metric = 5.38% * 100;
 Minibatch[1301-1400]: loss = 0.369752 * 100, metric = 5.41% * 100;
 Minibatch[1401-1500]: loss = 0.356589 * 100, metric = 4.98% * 100;
 Minibatch[1501-1600]: loss = 0.374077 * 100, metric = 5.25% * 100;
 Minibatch[1601-1700]: loss = 0.370558 * 100, metric = 5.36% * 100;
 Minibatch[1701-1800]: loss = 0.376204 * 100, metric = 5.38% * 100;
 Minibatch[1801-1900]: loss = 0.378674 * 100, metric = 5.59% * 100;
 Minibatch[1901-2000]: loss = 0.367950 * 100, metric = 5.18% * 100;
Finished Epoch[60 of 200]: [Training] loss = 0.372632 * 2000, metric = 5.33% * 2000 838.672s (  2.4 samples/s);
Finished Evaluation [60]: Minibatch[1-2000]: metric = 12.94% * 2000;
 Minibatch[   1- 100]: loss = 0.386671 * 100, metric = 5.53% * 100;
 Minibatch[ 101- 200]: loss = 0.367140 * 100, metric = 5.02% * 100;
 Minibatch[ 201- 300]: loss = 0.366939 * 100, metric = 5.27% * 100;
 Minibatch[ 301- 400]: loss = 0.377639 * 100, metric = 5.39% * 100;
 Minibatch[ 401- 500]: loss = 0.365294 * 100, metric = 5.21% * 100;
 Minibatch[ 501- 600]: loss = 0.359798 * 100, metric = 5.04% * 100;
 Minibatch[ 601- 700]: loss = 0.368855 * 100, metric = 5.11% * 100;
 Minibatch[ 701- 800]: loss = 0.379212 * 100, metric = 5.56% * 100;
 Minibatch[ 801- 900]: loss = 0.360526 * 100, metric = 5.13% * 100;
 Minibatch[ 901-1000]: loss = 0.369037 * 100, metric = 5.43% * 100;
 Minibatch[1001-1100]: loss = 0.380951 * 100, metric = 5.32% * 100;
 Minibatch[1101-1200]: loss = 0.372358 * 100, metric = 5.33% * 100;
 Minibatch[1201-1300]: loss = 0.360893 * 100, metric = 5.24% * 100;
 Minibatch[1301-1400]: loss = 0.355515 * 100, metric = 4.81% * 100;
 Minibatch[1401-1500]: loss = 0.382029 * 100, metric = 5.67% * 100;
 Minibatch[1501-1600]: loss = 0.387042 * 100, metric = 5.63% * 100;
 Minibatch[1601-1700]: loss = 0.383406 * 100, metric = 5.65% * 100;
 Minibatch[1701-1800]: loss = 0.374483 * 100, metric = 5.21% * 100;
 Minibatch[1801-1900]: loss = 0.370494 * 100, metric = 5.40% * 100;
 Minibatch[1901-2000]: loss = 0.360266 * 100, metric = 5.05% * 100;
Finished Epoch[61 of 200]: [Training] loss = 0.371428 * 2000, metric = 5.30% * 2000 836.462s (  2.4 samples/s);
Finished Evaluation [61]: Minibatch[1-2000]: metric = 13.01% * 2000;
 Minibatch[   1- 100]: loss = 0.369232 * 100, metric = 5.40% * 100;
 Minibatch[ 101- 200]: loss = 0.371702 * 100, metric = 5.14% * 100;
 Minibatch[ 201- 300]: loss = 0.373859 * 100, metric = 5.23% * 100;
 Minibatch[ 301- 400]: loss = 0.370784 * 100, metric = 5.26% * 100;
 Minibatch[ 401- 500]: loss = 0.376549 * 100, metric = 5.24% * 100;
 Minibatch[ 501- 600]: loss = 0.366504 * 100, metric = 5.17% * 100;
 Minibatch[ 601- 700]: loss = 0.377816 * 100, metric = 5.38% * 100;
 Minibatch[ 701- 800]: loss = 0.371038 * 100, metric = 5.27% * 100;
 Minibatch[ 801- 900]: loss = 0.372496 * 100, metric = 5.23% * 100;
 Minibatch[ 901-1000]: loss = 0.379829 * 100, metric = 5.41% * 100;
 Minibatch[1001-1100]: loss = 0.341629 * 100, metric = 4.72% * 100;
 Minibatch[1101-1200]: loss = 0.379564 * 100, metric = 5.44% * 100;
 Minibatch[1201-1300]: loss = 0.370099 * 100, metric = 5.31% * 100;
 Minibatch[1301-1400]: loss = 0.379724 * 100, metric = 5.38% * 100;
 Minibatch[1401-1500]: loss = 0.355574 * 100, metric = 5.10% * 100;
 Minibatch[1501-1600]: loss = 0.361786 * 100, metric = 4.96% * 100;
 Minibatch[1601-1700]: loss = 0.376393 * 100, metric = 5.53% * 100;
 Minibatch[1701-1800]: loss = 0.376287 * 100, metric = 5.39% * 100;
 Minibatch[1801-1900]: loss = 0.382142 * 100, metric = 5.55% * 100;
 Minibatch[1901-2000]: loss = 0.377950 * 100, metric = 5.59% * 100;
Finished Epoch[62 of 200]: [Training] loss = 0.371548 * 2000, metric = 5.28% * 2000 831.646s (  2.4 samples/s);
Finished Evaluation [62]: Minibatch[1-2000]: metric = 12.59% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
