Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 0.856064 * 100, metric = 24.40% * 100;
 Minibatch[ 101- 200]: loss = 0.682228 * 100, metric = 23.59% * 100;
 Minibatch[ 201- 300]: loss = 0.599422 * 100, metric = 21.97% * 100;
 Minibatch[ 301- 400]: loss = 0.577460 * 100, metric = 21.50% * 100;
 Minibatch[ 401- 500]: loss = 0.529088 * 100, metric = 20.42% * 100;
 Minibatch[ 501- 600]: loss = 0.505054 * 100, metric = 19.28% * 100;
 Minibatch[ 601- 700]: loss = 0.477303 * 100, metric = 18.34% * 100;
 Minibatch[ 701- 800]: loss = 0.436501 * 100, metric = 16.88% * 100;
 Minibatch[ 801- 900]: loss = 0.449997 * 100, metric = 17.73% * 100;
 Minibatch[ 901-1000]: loss = 0.468395 * 100, metric = 18.17% * 100;
 Minibatch[1001-1100]: loss = 0.454001 * 100, metric = 17.61% * 100;
 Minibatch[1101-1200]: loss = 0.436581 * 100, metric = 16.83% * 100;
 Minibatch[1201-1300]: loss = 0.443541 * 100, metric = 17.55% * 100;
 Minibatch[1301-1400]: loss = 0.426544 * 100, metric = 16.73% * 100;
 Minibatch[1401-1500]: loss = 0.431198 * 100, metric = 16.60% * 100;
 Minibatch[1501-1600]: loss = 0.412423 * 100, metric = 16.20% * 100;
 Minibatch[1601-1700]: loss = 0.411133 * 100, metric = 15.76% * 100;
 Minibatch[1701-1800]: loss = 0.415732 * 100, metric = 16.28% * 100;
 Minibatch[1801-1900]: loss = 0.420026 * 100, metric = 16.33% * 100;
 Minibatch[1901-2000]: loss = 0.395676 * 100, metric = 15.44% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.491418 * 2000, metric = 18.38% * 2000 939.457s (  2.1 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 24.06% * 2000;
0.5374580786600709
 Minibatch[   1- 100]: loss = 0.403078 * 100, metric = 15.57% * 100;
 Minibatch[ 101- 200]: loss = 0.406805 * 100, metric = 15.93% * 100;
 Minibatch[ 201- 300]: loss = 0.404860 * 100, metric = 15.25% * 100;
 Minibatch[ 301- 400]: loss = 0.405469 * 100, metric = 15.26% * 100;
 Minibatch[ 401- 500]: loss = 0.389972 * 100, metric = 14.94% * 100;
 Minibatch[ 501- 600]: loss = 0.407217 * 100, metric = 14.86% * 100;
 Minibatch[ 601- 700]: loss = 0.390178 * 100, metric = 14.57% * 100;
 Minibatch[ 701- 800]: loss = 0.396382 * 100, metric = 15.40% * 100;
 Minibatch[ 801- 900]: loss = 0.376042 * 100, metric = 14.77% * 100;
 Minibatch[ 901-1000]: loss = 0.369922 * 100, metric = 14.13% * 100;
 Minibatch[1001-1100]: loss = 0.386323 * 100, metric = 14.91% * 100;
 Minibatch[1101-1200]: loss = 0.383294 * 100, metric = 14.55% * 100;
 Minibatch[1201-1300]: loss = 0.370582 * 100, metric = 14.52% * 100;
 Minibatch[1301-1400]: loss = 0.384303 * 100, metric = 14.76% * 100;
 Minibatch[1401-1500]: loss = 0.367144 * 100, metric = 13.81% * 100;
 Minibatch[1501-1600]: loss = 0.365276 * 100, metric = 14.17% * 100;
 Minibatch[1601-1700]: loss = 0.381365 * 100, metric = 14.31% * 100;
 Minibatch[1701-1800]: loss = 0.376778 * 100, metric = 14.23% * 100;
 Minibatch[1801-1900]: loss = 0.372396 * 100, metric = 14.23% * 100;
 Minibatch[1901-2000]: loss = 0.362301 * 100, metric = 13.74% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.384984 * 2000, metric = 14.70% * 2000 882.917s (  2.3 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 22.29% * 2000;
0.49520081477612254
 Minibatch[   1- 100]: loss = 0.369501 * 100, metric = 13.95% * 100;
 Minibatch[ 101- 200]: loss = 0.371753 * 100, metric = 14.07% * 100;
 Minibatch[ 201- 300]: loss = 0.360076 * 100, metric = 13.73% * 100;
 Minibatch[ 301- 400]: loss = 0.373477 * 100, metric = 14.34% * 100;
 Minibatch[ 401- 500]: loss = 0.382214 * 100, metric = 14.62% * 100;
 Minibatch[ 501- 600]: loss = 0.372499 * 100, metric = 14.23% * 100;
 Minibatch[ 601- 700]: loss = 0.380808 * 100, metric = 14.41% * 100;
 Minibatch[ 701- 800]: loss = 0.353039 * 100, metric = 13.42% * 100;
 Minibatch[ 801- 900]: loss = 0.375953 * 100, metric = 14.37% * 100;
 Minibatch[ 901-1000]: loss = 0.354740 * 100, metric = 13.78% * 100;
 Minibatch[1001-1100]: loss = 0.360910 * 100, metric = 13.90% * 100;
 Minibatch[1101-1200]: loss = 0.353082 * 100, metric = 13.54% * 100;
 Minibatch[1201-1300]: loss = 0.350895 * 100, metric = 13.18% * 100;
 Minibatch[1301-1400]: loss = 0.365859 * 100, metric = 14.12% * 100;
 Minibatch[1401-1500]: loss = 0.360695 * 100, metric = 13.80% * 100;
 Minibatch[1501-1600]: loss = 0.352828 * 100, metric = 13.55% * 100;
 Minibatch[1601-1700]: loss = 0.348796 * 100, metric = 12.99% * 100;
 Minibatch[1701-1800]: loss = 0.357866 * 100, metric = 13.69% * 100;
 Minibatch[1801-1900]: loss = 0.347780 * 100, metric = 13.27% * 100;
 Minibatch[1901-2000]: loss = 0.347269 * 100, metric = 13.14% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.362002 * 2000, metric = 13.81% * 2000 901.672s (  2.2 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 21.21% * 2000;
0.48291600009799
 Minibatch[   1- 100]: loss = 0.365943 * 100, metric = 13.21% * 100;
 Minibatch[ 101- 200]: loss = 0.343749 * 100, metric = 13.12% * 100;
 Minibatch[ 201- 300]: loss = 0.351794 * 100, metric = 13.61% * 100;
 Minibatch[ 301- 400]: loss = 0.326445 * 100, metric = 12.67% * 100;
 Minibatch[ 401- 500]: loss = 0.357526 * 100, metric = 13.39% * 100;
 Minibatch[ 501- 600]: loss = 0.333811 * 100, metric = 12.81% * 100;
 Minibatch[ 601- 700]: loss = 0.335846 * 100, metric = 12.83% * 100;
 Minibatch[ 701- 800]: loss = 0.348905 * 100, metric = 13.43% * 100;
 Minibatch[ 801- 900]: loss = 0.350052 * 100, metric = 13.15% * 100;
 Minibatch[ 901-1000]: loss = 0.346558 * 100, metric = 13.34% * 100;
 Minibatch[1001-1100]: loss = 0.353513 * 100, metric = 13.48% * 100;
 Minibatch[1101-1200]: loss = 0.336230 * 100, metric = 12.99% * 100;
 Minibatch[1201-1300]: loss = 0.337031 * 100, metric = 12.97% * 100;
 Minibatch[1301-1400]: loss = 0.352263 * 100, metric = 13.34% * 100;
 Minibatch[1401-1500]: loss = 0.349778 * 100, metric = 13.24% * 100;
 Minibatch[1501-1600]: loss = 0.326636 * 100, metric = 12.48% * 100;
 Minibatch[1601-1700]: loss = 0.339664 * 100, metric = 13.22% * 100;
 Minibatch[1701-1800]: loss = 0.347462 * 100, metric = 13.43% * 100;
 Minibatch[1801-1900]: loss = 0.339216 * 100, metric = 12.91% * 100;
 Minibatch[1901-2000]: loss = 0.332855 * 100, metric = 12.67% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.343764 * 2000, metric = 13.11% * 2000 858.999s (  2.3 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 22.26% * 2000;
 Minibatch[   1- 100]: loss = 0.351352 * 100, metric = 13.54% * 100;
 Minibatch[ 101- 200]: loss = 0.337913 * 100, metric = 12.99% * 100;
 Minibatch[ 201- 300]: loss = 0.331242 * 100, metric = 12.43% * 100;
 Minibatch[ 301- 400]: loss = 0.359208 * 100, metric = 13.64% * 100;
 Minibatch[ 401- 500]: loss = 0.321145 * 100, metric = 12.16% * 100;
 Minibatch[ 501- 600]: loss = 0.329013 * 100, metric = 12.36% * 100;
 Minibatch[ 601- 700]: loss = 0.330678 * 100, metric = 12.38% * 100;
 Minibatch[ 701- 800]: loss = 0.333839 * 100, metric = 12.68% * 100;
 Minibatch[ 801- 900]: loss = 0.326640 * 100, metric = 12.34% * 100;
 Minibatch[ 901-1000]: loss = 0.329292 * 100, metric = 12.49% * 100;
 Minibatch[1001-1100]: loss = 0.333567 * 100, metric = 12.80% * 100;
 Minibatch[1101-1200]: loss = 0.317462 * 100, metric = 12.15% * 100;
 Minibatch[1201-1300]: loss = 0.333459 * 100, metric = 12.71% * 100;
 Minibatch[1301-1400]: loss = 0.335692 * 100, metric = 12.72% * 100;
 Minibatch[1401-1500]: loss = 0.331909 * 100, metric = 12.62% * 100;
 Minibatch[1501-1600]: loss = 0.329497 * 100, metric = 12.65% * 100;
 Minibatch[1601-1700]: loss = 0.336783 * 100, metric = 12.90% * 100;
 Minibatch[1701-1800]: loss = 0.339547 * 100, metric = 12.97% * 100;
 Minibatch[1801-1900]: loss = 0.337686 * 100, metric = 12.88% * 100;
 Minibatch[1901-2000]: loss = 0.327090 * 100, metric = 12.45% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.333651 * 2000, metric = 12.69% * 2000 850.075s (  2.4 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 21.45% * 2000;
 Minibatch[   1- 100]: loss = 0.319887 * 100, metric = 12.25% * 100;
 Minibatch[ 101- 200]: loss = 0.316454 * 100, metric = 12.23% * 100;
 Minibatch[ 201- 300]: loss = 0.321439 * 100, metric = 12.29% * 100;
 Minibatch[ 301- 400]: loss = 0.329174 * 100, metric = 12.07% * 100;
 Minibatch[ 401- 500]: loss = 0.309849 * 100, metric = 11.72% * 100;
 Minibatch[ 501- 600]: loss = 0.326298 * 100, metric = 12.45% * 100;
 Minibatch[ 601- 700]: loss = 0.320596 * 100, metric = 12.44% * 100;
 Minibatch[ 701- 800]: loss = 0.325145 * 100, metric = 12.34% * 100;
 Minibatch[ 801- 900]: loss = 0.325404 * 100, metric = 12.39% * 100;
 Minibatch[ 901-1000]: loss = 0.320711 * 100, metric = 12.23% * 100;
 Minibatch[1001-1100]: loss = 0.314953 * 100, metric = 11.66% * 100;
 Minibatch[1101-1200]: loss = 0.331320 * 100, metric = 12.24% * 100;
 Minibatch[1201-1300]: loss = 0.335959 * 100, metric = 12.71% * 100;
 Minibatch[1301-1400]: loss = 0.319374 * 100, metric = 12.20% * 100;
 Minibatch[1401-1500]: loss = 0.323228 * 100, metric = 12.51% * 100;
 Minibatch[1501-1600]: loss = 0.308907 * 100, metric = 11.69% * 100;
 Minibatch[1601-1700]: loss = 0.312608 * 100, metric = 12.05% * 100;
 Minibatch[1701-1800]: loss = 0.309754 * 100, metric = 11.85% * 100;
 Minibatch[1801-1900]: loss = 0.316302 * 100, metric = 12.02% * 100;
 Minibatch[1901-2000]: loss = 0.305834 * 100, metric = 11.70% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.319660 * 2000, metric = 12.15% * 2000 852.795s (  2.3 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 21.61% * 2000;
 Minibatch[   1- 100]: loss = 0.311990 * 100, metric = 11.90% * 100;
 Minibatch[ 101- 200]: loss = 0.321802 * 100, metric = 11.91% * 100;
 Minibatch[ 201- 300]: loss = 0.334973 * 100, metric = 12.58% * 100;
 Minibatch[ 301- 400]: loss = 0.314232 * 100, metric = 11.95% * 100;
 Minibatch[ 401- 500]: loss = 0.320911 * 100, metric = 11.94% * 100;
 Minibatch[ 501- 600]: loss = 0.300630 * 100, metric = 11.44% * 100;
 Minibatch[ 601- 700]: loss = 0.310683 * 100, metric = 11.47% * 100;
 Minibatch[ 701- 800]: loss = 0.318965 * 100, metric = 12.07% * 100;
 Minibatch[ 801- 900]: loss = 0.318001 * 100, metric = 12.03% * 100;
 Minibatch[ 901-1000]: loss = 0.313754 * 100, metric = 11.80% * 100;
 Minibatch[1001-1100]: loss = 0.325048 * 100, metric = 12.19% * 100;
 Minibatch[1101-1200]: loss = 0.307232 * 100, metric = 11.45% * 100;
 Minibatch[1201-1300]: loss = 0.317429 * 100, metric = 12.33% * 100;
 Minibatch[1301-1400]: loss = 0.307449 * 100, metric = 11.83% * 100;
 Minibatch[1401-1500]: loss = 0.303018 * 100, metric = 11.43% * 100;
 Minibatch[1501-1600]: loss = 0.312181 * 100, metric = 11.59% * 100;
 Minibatch[1601-1700]: loss = 0.316876 * 100, metric = 12.08% * 100;
 Minibatch[1701-1800]: loss = 0.309865 * 100, metric = 11.50% * 100;
 Minibatch[1801-1900]: loss = 0.314429 * 100, metric = 11.84% * 100;
 Minibatch[1901-2000]: loss = 0.317557 * 100, metric = 12.02% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.314851 * 2000, metric = 11.87% * 2000 892.731s (  2.2 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.65% * 2000;
0.43390533067286013
 Minibatch[   1- 100]: loss = 0.314493 * 100, metric = 12.04% * 100;
 Minibatch[ 101- 200]: loss = 0.311470 * 100, metric = 11.96% * 100;
 Minibatch[ 201- 300]: loss = 0.296824 * 100, metric = 11.24% * 100;
 Minibatch[ 301- 400]: loss = 0.306002 * 100, metric = 11.71% * 100;
 Minibatch[ 401- 500]: loss = 0.316235 * 100, metric = 12.26% * 100;
 Minibatch[ 501- 600]: loss = 0.324705 * 100, metric = 12.40% * 100;
 Minibatch[ 601- 700]: loss = 0.294806 * 100, metric = 11.16% * 100;
 Minibatch[ 701- 800]: loss = 0.311368 * 100, metric = 11.52% * 100;
 Minibatch[ 801- 900]: loss = 0.296782 * 100, metric = 11.11% * 100;
 Minibatch[ 901-1000]: loss = 0.289653 * 100, metric = 10.94% * 100;
 Minibatch[1001-1100]: loss = 0.301156 * 100, metric = 11.40% * 100;
 Minibatch[1101-1200]: loss = 0.297100 * 100, metric = 11.36% * 100;
 Minibatch[1201-1300]: loss = 0.314751 * 100, metric = 12.06% * 100;
 Minibatch[1301-1400]: loss = 0.312002 * 100, metric = 12.06% * 100;
 Minibatch[1401-1500]: loss = 0.306453 * 100, metric = 11.61% * 100;
 Minibatch[1501-1600]: loss = 0.309578 * 100, metric = 11.81% * 100;
 Minibatch[1601-1700]: loss = 0.303267 * 100, metric = 11.61% * 100;
 Minibatch[1701-1800]: loss = 0.304277 * 100, metric = 11.26% * 100;
 Minibatch[1801-1900]: loss = 0.303156 * 100, metric = 11.55% * 100;
 Minibatch[1901-2000]: loss = 0.303627 * 100, metric = 11.50% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.305885 * 2000, metric = 11.63% * 2000 868.030s (  2.3 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 19.02% * 2000;
0.4336789271682501
 Minibatch[   1- 100]: loss = 0.290110 * 100, metric = 10.91% * 100;
 Minibatch[ 101- 200]: loss = 0.321068 * 100, metric = 12.06% * 100;
 Minibatch[ 201- 300]: loss = 0.297634 * 100, metric = 11.21% * 100;
 Minibatch[ 301- 400]: loss = 0.318185 * 100, metric = 11.92% * 100;
 Minibatch[ 401- 500]: loss = 0.303330 * 100, metric = 11.22% * 100;
 Minibatch[ 501- 600]: loss = 0.297926 * 100, metric = 11.07% * 100;
 Minibatch[ 601- 700]: loss = 0.304373 * 100, metric = 11.71% * 100;
 Minibatch[ 701- 800]: loss = 0.288084 * 100, metric = 11.16% * 100;
 Minibatch[ 801- 900]: loss = 0.291843 * 100, metric = 11.24% * 100;
 Minibatch[ 901-1000]: loss = 0.306890 * 100, metric = 11.77% * 100;
 Minibatch[1001-1100]: loss = 0.278527 * 100, metric = 10.87% * 100;
 Minibatch[1101-1200]: loss = 0.299314 * 100, metric = 11.54% * 100;
 Minibatch[1201-1300]: loss = 0.293085 * 100, metric = 11.28% * 100;
 Minibatch[1301-1400]: loss = 0.289721 * 100, metric = 10.75% * 100;
 Minibatch[1401-1500]: loss = 0.306363 * 100, metric = 11.60% * 100;
 Minibatch[1501-1600]: loss = 0.293560 * 100, metric = 11.29% * 100;
 Minibatch[1601-1700]: loss = 0.297136 * 100, metric = 11.30% * 100;
 Minibatch[1701-1800]: loss = 0.289025 * 100, metric = 10.58% * 100;
 Minibatch[1801-1900]: loss = 0.292367 * 100, metric = 11.02% * 100;
 Minibatch[1901-2000]: loss = 0.297095 * 100, metric = 11.38% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.297782 * 2000, metric = 11.29% * 2000 868.532s (  2.3 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 17.77% * 2000;
0.42020452980697154
 Minibatch[   1- 100]: loss = 0.312464 * 100, metric = 12.12% * 100;
 Minibatch[ 101- 200]: loss = 0.296595 * 100, metric = 11.27% * 100;
 Minibatch[ 201- 300]: loss = 0.300412 * 100, metric = 11.43% * 100;
 Minibatch[ 301- 400]: loss = 0.285681 * 100, metric = 10.90% * 100;
 Minibatch[ 401- 500]: loss = 0.302054 * 100, metric = 11.53% * 100;
 Minibatch[ 501- 600]: loss = 0.286055 * 100, metric = 11.12% * 100;
 Minibatch[ 601- 700]: loss = 0.282145 * 100, metric = 10.54% * 100;
 Minibatch[ 701- 800]: loss = 0.276371 * 100, metric = 10.43% * 100;
 Minibatch[ 801- 900]: loss = 0.283253 * 100, metric = 11.05% * 100;
 Minibatch[ 901-1000]: loss = 0.299140 * 100, metric = 11.17% * 100;
 Minibatch[1001-1100]: loss = 0.299780 * 100, metric = 11.45% * 100;
 Minibatch[1101-1200]: loss = 0.292803 * 100, metric = 10.99% * 100;
 Minibatch[1201-1300]: loss = 0.294955 * 100, metric = 11.37% * 100;
 Minibatch[1301-1400]: loss = 0.290820 * 100, metric = 11.02% * 100;
 Minibatch[1401-1500]: loss = 0.280187 * 100, metric = 10.79% * 100;
 Minibatch[1501-1600]: loss = 0.288591 * 100, metric = 11.09% * 100;
 Minibatch[1601-1700]: loss = 0.291681 * 100, metric = 10.93% * 100;
 Minibatch[1701-1800]: loss = 0.290793 * 100, metric = 10.74% * 100;
 Minibatch[1801-1900]: loss = 0.296259 * 100, metric = 11.48% * 100;
 Minibatch[1901-2000]: loss = 0.284713 * 100, metric = 11.02% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.291738 * 2000, metric = 11.12% * 2000 869.778s (  2.3 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 17.58% * 2000;
 Minibatch[   1- 100]: loss = 0.276182 * 100, metric = 10.44% * 100;
 Minibatch[ 101- 200]: loss = 0.282649 * 100, metric = 10.79% * 100;
 Minibatch[ 201- 300]: loss = 0.295913 * 100, metric = 11.49% * 100;
 Minibatch[ 301- 400]: loss = 0.286028 * 100, metric = 10.82% * 100;
 Minibatch[ 401- 500]: loss = 0.290803 * 100, metric = 10.89% * 100;
 Minibatch[ 501- 600]: loss = 0.290029 * 100, metric = 11.17% * 100;
 Minibatch[ 601- 700]: loss = 0.284932 * 100, metric = 10.67% * 100;
 Minibatch[ 701- 800]: loss = 0.289216 * 100, metric = 11.03% * 100;
 Minibatch[ 801- 900]: loss = 0.288058 * 100, metric = 10.85% * 100;
 Minibatch[ 901-1000]: loss = 0.291664 * 100, metric = 10.92% * 100;
 Minibatch[1001-1100]: loss = 0.284737 * 100, metric = 10.70% * 100;
 Minibatch[1101-1200]: loss = 0.293542 * 100, metric = 11.10% * 100;
 Minibatch[1201-1300]: loss = 0.278497 * 100, metric = 10.62% * 100;
 Minibatch[1301-1400]: loss = 0.270316 * 100, metric = 10.45% * 100;
 Minibatch[1401-1500]: loss = 0.289811 * 100, metric = 11.10% * 100;
 Minibatch[1501-1600]: loss = 0.274192 * 100, metric = 10.58% * 100;
 Minibatch[1601-1700]: loss = 0.276965 * 100, metric = 10.45% * 100;
 Minibatch[1701-1800]: loss = 0.287915 * 100, metric = 10.92% * 100;
 Minibatch[1801-1900]: loss = 0.290632 * 100, metric = 10.89% * 100;
 Minibatch[1901-2000]: loss = 0.284285 * 100, metric = 10.97% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.285318 * 2000, metric = 10.84% * 2000 862.971s (  2.3 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 17.57% * 2000;
0.41722395884245633
 Minibatch[   1- 100]: loss = 0.271166 * 100, metric = 10.38% * 100;
 Minibatch[ 101- 200]: loss = 0.267033 * 100, metric = 10.10% * 100;
 Minibatch[ 201- 300]: loss = 0.275356 * 100, metric = 10.44% * 100;
 Minibatch[ 301- 400]: loss = 0.299978 * 100, metric = 11.63% * 100;
 Minibatch[ 401- 500]: loss = 0.273624 * 100, metric = 10.54% * 100;
 Minibatch[ 501- 600]: loss = 0.260010 * 100, metric = 9.69% * 100;
 Minibatch[ 601- 700]: loss = 0.271073 * 100, metric = 10.49% * 100;
 Minibatch[ 701- 800]: loss = 0.279626 * 100, metric = 10.36% * 100;
 Minibatch[ 801- 900]: loss = 0.277012 * 100, metric = 10.33% * 100;
 Minibatch[ 901-1000]: loss = 0.276005 * 100, metric = 10.50% * 100;
 Minibatch[1001-1100]: loss = 0.283119 * 100, metric = 11.02% * 100;
 Minibatch[1101-1200]: loss = 0.284735 * 100, metric = 10.72% * 100;
 Minibatch[1201-1300]: loss = 0.284043 * 100, metric = 10.82% * 100;
 Minibatch[1301-1400]: loss = 0.267997 * 100, metric = 10.16% * 100;
 Minibatch[1401-1500]: loss = 0.282410 * 100, metric = 10.79% * 100;
 Minibatch[1501-1600]: loss = 0.263877 * 100, metric = 10.01% * 100;
 Minibatch[1601-1700]: loss = 0.278391 * 100, metric = 10.75% * 100;
 Minibatch[1701-1800]: loss = 0.270900 * 100, metric = 10.33% * 100;
 Minibatch[1801-1900]: loss = 0.267807 * 100, metric = 10.12% * 100;
 Minibatch[1901-2000]: loss = 0.283762 * 100, metric = 10.68% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.275896 * 2000, metric = 10.49% * 2000 860.526s (  2.3 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 18.24% * 2000;
 Minibatch[   1- 100]: loss = 0.276800 * 100, metric = 10.41% * 100;
 Minibatch[ 101- 200]: loss = 0.279914 * 100, metric = 10.66% * 100;
 Minibatch[ 201- 300]: loss = 0.269421 * 100, metric = 10.11% * 100;
 Minibatch[ 301- 400]: loss = 0.279802 * 100, metric = 10.53% * 100;
 Minibatch[ 401- 500]: loss = 0.286505 * 100, metric = 10.98% * 100;
 Minibatch[ 501- 600]: loss = 0.288299 * 100, metric = 11.25% * 100;
 Minibatch[ 601- 700]: loss = 0.272373 * 100, metric = 9.98% * 100;
 Minibatch[ 701- 800]: loss = 0.263656 * 100, metric = 9.99% * 100;
 Minibatch[ 801- 900]: loss = 0.265741 * 100, metric = 9.83% * 100;
 Minibatch[ 901-1000]: loss = 0.279726 * 100, metric = 10.46% * 100;
 Minibatch[1001-1100]: loss = 0.280039 * 100, metric = 10.61% * 100;
 Minibatch[1101-1200]: loss = 0.268966 * 100, metric = 10.30% * 100;
 Minibatch[1201-1300]: loss = 0.276735 * 100, metric = 10.77% * 100;
 Minibatch[1301-1400]: loss = 0.273569 * 100, metric = 10.53% * 100;
 Minibatch[1401-1500]: loss = 0.268240 * 100, metric = 10.06% * 100;
 Minibatch[1501-1600]: loss = 0.263592 * 100, metric = 9.91% * 100;
 Minibatch[1601-1700]: loss = 0.261390 * 100, metric = 9.82% * 100;
 Minibatch[1701-1800]: loss = 0.270903 * 100, metric = 9.97% * 100;
 Minibatch[1801-1900]: loss = 0.254159 * 100, metric = 9.58% * 100;
 Minibatch[1901-2000]: loss = 0.271194 * 100, metric = 10.24% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.272551 * 2000, metric = 10.30% * 2000 862.441s (  2.3 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 18.95% * 2000;
 Minibatch[   1- 100]: loss = 0.263582 * 100, metric = 9.64% * 100;
 Minibatch[ 101- 200]: loss = 0.254795 * 100, metric = 9.70% * 100;
 Minibatch[ 201- 300]: loss = 0.274241 * 100, metric = 10.41% * 100;
 Minibatch[ 301- 400]: loss = 0.266353 * 100, metric = 10.15% * 100;
 Minibatch[ 401- 500]: loss = 0.266294 * 100, metric = 9.87% * 100;
 Minibatch[ 501- 600]: loss = 0.265651 * 100, metric = 10.14% * 100;
 Minibatch[ 601- 700]: loss = 0.263013 * 100, metric = 9.75% * 100;
 Minibatch[ 701- 800]: loss = 0.276279 * 100, metric = 10.52% * 100;
 Minibatch[ 801- 900]: loss = 0.284390 * 100, metric = 10.83% * 100;
 Minibatch[ 901-1000]: loss = 0.272544 * 100, metric = 10.66% * 100;
 Minibatch[1001-1100]: loss = 0.268701 * 100, metric = 9.98% * 100;
 Minibatch[1101-1200]: loss = 0.261616 * 100, metric = 9.90% * 100;
 Minibatch[1201-1300]: loss = 0.253008 * 100, metric = 9.35% * 100;
 Minibatch[1301-1400]: loss = 0.266695 * 100, metric = 10.31% * 100;
 Minibatch[1401-1500]: loss = 0.264215 * 100, metric = 9.93% * 100;
 Minibatch[1501-1600]: loss = 0.260386 * 100, metric = 10.03% * 100;
 Minibatch[1601-1700]: loss = 0.257593 * 100, metric = 9.69% * 100;
 Minibatch[1701-1800]: loss = 0.260072 * 100, metric = 9.83% * 100;
 Minibatch[1801-1900]: loss = 0.260712 * 100, metric = 10.04% * 100;
 Minibatch[1901-2000]: loss = 0.264304 * 100, metric = 10.03% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.265222 * 2000, metric = 10.04% * 2000 856.586s (  2.3 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 17.68% * 2000;
 Minibatch[   1- 100]: loss = 0.258561 * 100, metric = 9.78% * 100;
 Minibatch[ 101- 200]: loss = 0.262441 * 100, metric = 9.92% * 100;
 Minibatch[ 201- 300]: loss = 0.265556 * 100, metric = 10.16% * 100;
 Minibatch[ 301- 400]: loss = 0.248021 * 100, metric = 9.38% * 100;
 Minibatch[ 401- 500]: loss = 0.253630 * 100, metric = 9.67% * 100;
 Minibatch[ 501- 600]: loss = 0.246766 * 100, metric = 9.24% * 100;
 Minibatch[ 601- 700]: loss = 0.243368 * 100, metric = 9.22% * 100;
 Minibatch[ 701- 800]: loss = 0.265349 * 100, metric = 9.91% * 100;
 Minibatch[ 801- 900]: loss = 0.274914 * 100, metric = 10.36% * 100;
 Minibatch[ 901-1000]: loss = 0.254191 * 100, metric = 9.56% * 100;
 Minibatch[1001-1100]: loss = 0.259547 * 100, metric = 9.81% * 100;
 Minibatch[1101-1200]: loss = 0.262658 * 100, metric = 9.89% * 100;
 Minibatch[1201-1300]: loss = 0.248029 * 100, metric = 9.33% * 100;
 Minibatch[1301-1400]: loss = 0.276355 * 100, metric = 10.39% * 100;
 Minibatch[1401-1500]: loss = 0.241380 * 100, metric = 9.12% * 100;
 Minibatch[1501-1600]: loss = 0.250260 * 100, metric = 9.32% * 100;
 Minibatch[1601-1700]: loss = 0.256074 * 100, metric = 9.65% * 100;
 Minibatch[1701-1800]: loss = 0.247060 * 100, metric = 9.04% * 100;
 Minibatch[1801-1900]: loss = 0.255557 * 100, metric = 9.41% * 100;
 Minibatch[1901-2000]: loss = 0.256255 * 100, metric = 9.76% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.256299 * 2000, metric = 9.65% * 2000 855.395s (  2.3 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 16.31% * 2000;
0.4134978368245065
 Minibatch[   1- 100]: loss = 0.265755 * 100, metric = 10.15% * 100;
 Minibatch[ 101- 200]: loss = 0.253333 * 100, metric = 9.46% * 100;
 Minibatch[ 201- 300]: loss = 0.257258 * 100, metric = 9.69% * 100;
 Minibatch[ 301- 400]: loss = 0.258767 * 100, metric = 9.63% * 100;
 Minibatch[ 401- 500]: loss = 0.243689 * 100, metric = 9.15% * 100;
 Minibatch[ 501- 600]: loss = 0.261125 * 100, metric = 9.69% * 100;
 Minibatch[ 601- 700]: loss = 0.251718 * 100, metric = 9.43% * 100;
 Minibatch[ 701- 800]: loss = 0.250132 * 100, metric = 9.41% * 100;
 Minibatch[ 801- 900]: loss = 0.244582 * 100, metric = 9.31% * 100;
 Minibatch[ 901-1000]: loss = 0.252117 * 100, metric = 9.53% * 100;
 Minibatch[1001-1100]: loss = 0.242871 * 100, metric = 9.17% * 100;
 Minibatch[1101-1200]: loss = 0.246432 * 100, metric = 9.34% * 100;
 Minibatch[1201-1300]: loss = 0.242557 * 100, metric = 9.29% * 100;
 Minibatch[1301-1400]: loss = 0.251126 * 100, metric = 9.52% * 100;
 Minibatch[1401-1500]: loss = 0.248558 * 100, metric = 9.58% * 100;
 Minibatch[1501-1600]: loss = 0.245512 * 100, metric = 9.31% * 100;
 Minibatch[1601-1700]: loss = 0.248358 * 100, metric = 9.50% * 100;
 Minibatch[1701-1800]: loss = 0.254146 * 100, metric = 9.38% * 100;
 Minibatch[1801-1900]: loss = 0.258076 * 100, metric = 9.75% * 100;
 Minibatch[1901-2000]: loss = 0.240087 * 100, metric = 9.32% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.250810 * 2000, metric = 9.48% * 2000 857.499s (  2.3 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 16.88% * 2000;
 Minibatch[   1- 100]: loss = 0.239783 * 100, metric = 9.14% * 100;
 Minibatch[ 101- 200]: loss = 0.254301 * 100, metric = 9.74% * 100;
 Minibatch[ 201- 300]: loss = 0.256263 * 100, metric = 9.53% * 100;
 Minibatch[ 301- 400]: loss = 0.245495 * 100, metric = 9.21% * 100;
 Minibatch[ 401- 500]: loss = 0.250311 * 100, metric = 9.57% * 100;
 Minibatch[ 501- 600]: loss = 0.238422 * 100, metric = 8.83% * 100;
 Minibatch[ 601- 700]: loss = 0.225736 * 100, metric = 8.33% * 100;
 Minibatch[ 701- 800]: loss = 0.239293 * 100, metric = 8.79% * 100;
 Minibatch[ 801- 900]: loss = 0.242856 * 100, metric = 9.21% * 100;
 Minibatch[ 901-1000]: loss = 0.236627 * 100, metric = 8.95% * 100;
 Minibatch[1001-1100]: loss = 0.238899 * 100, metric = 8.93% * 100;
 Minibatch[1101-1200]: loss = 0.251024 * 100, metric = 9.40% * 100;
 Minibatch[1201-1300]: loss = 0.250815 * 100, metric = 9.50% * 100;
 Minibatch[1301-1400]: loss = 0.230297 * 100, metric = 8.65% * 100;
 Minibatch[1401-1500]: loss = 0.243266 * 100, metric = 9.22% * 100;
 Minibatch[1501-1600]: loss = 0.242487 * 100, metric = 9.27% * 100;
 Minibatch[1601-1700]: loss = 0.239099 * 100, metric = 8.97% * 100;
 Minibatch[1701-1800]: loss = 0.236539 * 100, metric = 8.87% * 100;
 Minibatch[1801-1900]: loss = 0.250652 * 100, metric = 9.53% * 100;
 Minibatch[1901-2000]: loss = 0.255144 * 100, metric = 9.70% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.243365 * 2000, metric = 9.17% * 2000 854.827s (  2.3 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 16.38% * 2000;
 Minibatch[   1- 100]: loss = 0.231522 * 100, metric = 8.65% * 100;
 Minibatch[ 101- 200]: loss = 0.247068 * 100, metric = 9.46% * 100;
 Minibatch[ 201- 300]: loss = 0.231820 * 100, metric = 8.83% * 100;
 Minibatch[ 301- 400]: loss = 0.239476 * 100, metric = 9.05% * 100;
 Minibatch[ 401- 500]: loss = 0.227567 * 100, metric = 8.61% * 100;
 Minibatch[ 501- 600]: loss = 0.234331 * 100, metric = 8.61% * 100;
 Minibatch[ 601- 700]: loss = 0.243699 * 100, metric = 9.11% * 100;
 Minibatch[ 701- 800]: loss = 0.230447 * 100, metric = 8.78% * 100;
 Minibatch[ 801- 900]: loss = 0.242621 * 100, metric = 8.97% * 100;
 Minibatch[ 901-1000]: loss = 0.238701 * 100, metric = 8.98% * 100;
 Minibatch[1001-1100]: loss = 0.247626 * 100, metric = 9.36% * 100;
 Minibatch[1101-1200]: loss = 0.239263 * 100, metric = 8.98% * 100;
 Minibatch[1201-1300]: loss = 0.250815 * 100, metric = 9.45% * 100;
 Minibatch[1301-1400]: loss = 0.251827 * 100, metric = 9.40% * 100;
 Minibatch[1401-1500]: loss = 0.225396 * 100, metric = 8.41% * 100;
 Minibatch[1501-1600]: loss = 0.235388 * 100, metric = 8.76% * 100;
 Minibatch[1601-1700]: loss = 0.223744 * 100, metric = 8.25% * 100;
 Minibatch[1701-1800]: loss = 0.232212 * 100, metric = 8.93% * 100;
 Minibatch[1801-1900]: loss = 0.223612 * 100, metric = 8.35% * 100;
 Minibatch[1901-2000]: loss = 0.227284 * 100, metric = 8.52% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.236221 * 2000, metric = 8.87% * 2000 843.811s (  2.4 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 17.46% * 2000;
 Minibatch[   1- 100]: loss = 0.244903 * 100, metric = 9.37% * 100;
 Minibatch[ 101- 200]: loss = 0.249539 * 100, metric = 9.32% * 100;
 Minibatch[ 201- 300]: loss = 0.222591 * 100, metric = 8.29% * 100;
 Minibatch[ 301- 400]: loss = 0.244018 * 100, metric = 8.88% * 100;
 Minibatch[ 401- 500]: loss = 0.236260 * 100, metric = 8.77% * 100;
 Minibatch[ 501- 600]: loss = 0.225504 * 100, metric = 8.36% * 100;
 Minibatch[ 601- 700]: loss = 0.237110 * 100, metric = 8.84% * 100;
 Minibatch[ 701- 800]: loss = 0.227562 * 100, metric = 8.54% * 100;
 Minibatch[ 801- 900]: loss = 0.252988 * 100, metric = 9.52% * 100;
 Minibatch[ 901-1000]: loss = 0.226849 * 100, metric = 8.64% * 100;
 Minibatch[1001-1100]: loss = 0.239691 * 100, metric = 9.01% * 100;
 Minibatch[1101-1200]: loss = 0.235112 * 100, metric = 8.87% * 100;
 Minibatch[1201-1300]: loss = 0.230121 * 100, metric = 8.78% * 100;
 Minibatch[1301-1400]: loss = 0.229363 * 100, metric = 8.58% * 100;
 Minibatch[1401-1500]: loss = 0.238654 * 100, metric = 9.04% * 100;
 Minibatch[1501-1600]: loss = 0.235960 * 100, metric = 9.02% * 100;
 Minibatch[1601-1700]: loss = 0.231790 * 100, metric = 8.80% * 100;
 Minibatch[1701-1800]: loss = 0.222383 * 100, metric = 8.34% * 100;
 Minibatch[1801-1900]: loss = 0.225112 * 100, metric = 8.42% * 100;
 Minibatch[1901-2000]: loss = 0.226396 * 100, metric = 8.43% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.234095 * 2000, metric = 8.79% * 2000 1061.959s (  1.9 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 17.74% * 2000;
 Minibatch[   1- 100]: loss = 0.228498 * 100, metric = 8.44% * 100;
 Minibatch[ 101- 200]: loss = 0.230853 * 100, metric = 8.64% * 100;
 Minibatch[ 201- 300]: loss = 0.227115 * 100, metric = 8.53% * 100;
 Minibatch[ 301- 400]: loss = 0.237121 * 100, metric = 8.60% * 100;
 Minibatch[ 401- 500]: loss = 0.228138 * 100, metric = 8.51% * 100;
 Minibatch[ 501- 600]: loss = 0.233928 * 100, metric = 8.83% * 100;
 Minibatch[ 601- 700]: loss = 0.239975 * 100, metric = 9.09% * 100;
 Minibatch[ 701- 800]: loss = 0.233162 * 100, metric = 8.89% * 100;
 Minibatch[ 801- 900]: loss = 0.237790 * 100, metric = 8.93% * 100;
 Minibatch[ 901-1000]: loss = 0.237715 * 100, metric = 8.96% * 100;
 Minibatch[1001-1100]: loss = 0.219783 * 100, metric = 8.23% * 100;
 Minibatch[1101-1200]: loss = 0.233856 * 100, metric = 8.76% * 100;
 Minibatch[1201-1300]: loss = 0.238162 * 100, metric = 8.82% * 100;
 Minibatch[1301-1400]: loss = 0.240103 * 100, metric = 9.16% * 100;
 Minibatch[1401-1500]: loss = 0.233952 * 100, metric = 8.90% * 100;
 Minibatch[1501-1600]: loss = 0.244176 * 100, metric = 8.98% * 100;
 Minibatch[1601-1700]: loss = 0.227734 * 100, metric = 8.47% * 100;
 Minibatch[1701-1800]: loss = 0.240093 * 100, metric = 9.07% * 100;
 Minibatch[1801-1900]: loss = 0.228003 * 100, metric = 8.54% * 100;
 Minibatch[1901-2000]: loss = 0.225758 * 100, metric = 8.56% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.233296 * 2000, metric = 8.75% * 2000 1154.444s (  1.7 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 17.12% * 2000;
 Minibatch[   1- 100]: loss = 0.232318 * 100, metric = 8.78% * 100;
 Minibatch[ 101- 200]: loss = 0.229175 * 100, metric = 8.69% * 100;
 Minibatch[ 201- 300]: loss = 0.224534 * 100, metric = 8.59% * 100;
 Minibatch[ 301- 400]: loss = 0.233766 * 100, metric = 8.88% * 100;
 Minibatch[ 401- 500]: loss = 0.222691 * 100, metric = 8.37% * 100;
 Minibatch[ 501- 600]: loss = 0.221238 * 100, metric = 8.44% * 100;
 Minibatch[ 601- 700]: loss = 0.227532 * 100, metric = 8.52% * 100;
 Minibatch[ 701- 800]: loss = 0.208830 * 100, metric = 8.07% * 100;
 Minibatch[ 801- 900]: loss = 0.227227 * 100, metric = 8.47% * 100;
 Minibatch[ 901-1000]: loss = 0.221006 * 100, metric = 8.38% * 100;
 Minibatch[1001-1100]: loss = 0.224079 * 100, metric = 8.38% * 100;
 Minibatch[1101-1200]: loss = 0.227842 * 100, metric = 8.22% * 100;
 Minibatch[1201-1300]: loss = 0.228590 * 100, metric = 8.50% * 100;
 Minibatch[1301-1400]: loss = 0.216379 * 100, metric = 8.12% * 100;
 Minibatch[1401-1500]: loss = 0.224900 * 100, metric = 8.32% * 100;
 Minibatch[1501-1600]: loss = 0.235230 * 100, metric = 9.00% * 100;
 Minibatch[1601-1700]: loss = 0.222301 * 100, metric = 8.35% * 100;
 Minibatch[1701-1800]: loss = 0.220833 * 100, metric = 8.16% * 100;
 Minibatch[1801-1900]: loss = 0.236057 * 100, metric = 8.91% * 100;
 Minibatch[1901-2000]: loss = 0.222166 * 100, metric = 8.05% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.225335 * 2000, metric = 8.46% * 2000 903.674s (  2.2 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 15.13% * 2000;
0.40391686856001613
 Minibatch[   1- 100]: loss = 0.232285 * 100, metric = 8.74% * 100;
 Minibatch[ 101- 200]: loss = 0.225816 * 100, metric = 8.48% * 100;
 Minibatch[ 201- 300]: loss = 0.229277 * 100, metric = 8.73% * 100;
 Minibatch[ 301- 400]: loss = 0.223075 * 100, metric = 8.56% * 100;
 Minibatch[ 401- 500]: loss = 0.226094 * 100, metric = 8.37% * 100;
 Minibatch[ 501- 600]: loss = 0.221700 * 100, metric = 8.31% * 100;
 Minibatch[ 601- 700]: loss = 0.214851 * 100, metric = 8.09% * 100;
 Minibatch[ 701- 800]: loss = 0.218496 * 100, metric = 8.24% * 100;
 Minibatch[ 801- 900]: loss = 0.223163 * 100, metric = 8.34% * 100;
 Minibatch[ 901-1000]: loss = 0.228734 * 100, metric = 8.62% * 100;
 Minibatch[1001-1100]: loss = 0.214655 * 100, metric = 7.99% * 100;
 Minibatch[1101-1200]: loss = 0.205537 * 100, metric = 7.61% * 100;
 Minibatch[1201-1300]: loss = 0.214048 * 100, metric = 8.00% * 100;
 Minibatch[1301-1400]: loss = 0.218231 * 100, metric = 8.24% * 100;
 Minibatch[1401-1500]: loss = 0.214902 * 100, metric = 8.09% * 100;
 Minibatch[1501-1600]: loss = 0.210550 * 100, metric = 7.88% * 100;
 Minibatch[1601-1700]: loss = 0.216259 * 100, metric = 8.07% * 100;
 Minibatch[1701-1800]: loss = 0.210919 * 100, metric = 7.85% * 100;
 Minibatch[1801-1900]: loss = 0.216442 * 100, metric = 8.15% * 100;
 Minibatch[1901-2000]: loss = 0.217626 * 100, metric = 7.93% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.219133 * 2000, metric = 8.21% * 2000 954.104s (  2.1 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 16.35% * 2000;
 Minibatch[   1- 100]: loss = 0.224537 * 100, metric = 8.29% * 100;
 Minibatch[ 101- 200]: loss = 0.224503 * 100, metric = 8.57% * 100;
 Minibatch[ 201- 300]: loss = 0.214377 * 100, metric = 8.14% * 100;
 Minibatch[ 301- 400]: loss = 0.223156 * 100, metric = 8.29% * 100;
 Minibatch[ 401- 500]: loss = 0.222327 * 100, metric = 8.28% * 100;
 Minibatch[ 501- 600]: loss = 0.213587 * 100, metric = 7.77% * 100;
 Minibatch[ 601- 700]: loss = 0.217116 * 100, metric = 7.86% * 100;
 Minibatch[ 701- 800]: loss = 0.199895 * 100, metric = 7.48% * 100;
 Minibatch[ 801- 900]: loss = 0.204917 * 100, metric = 7.78% * 100;
 Minibatch[ 901-1000]: loss = 0.220495 * 100, metric = 8.13% * 100;
 Minibatch[1001-1100]: loss = 0.207545 * 100, metric = 7.75% * 100;
 Minibatch[1101-1200]: loss = 0.214630 * 100, metric = 8.11% * 100;
 Minibatch[1201-1300]: loss = 0.214304 * 100, metric = 8.20% * 100;
 Minibatch[1301-1400]: loss = 0.215341 * 100, metric = 8.09% * 100;
 Minibatch[1401-1500]: loss = 0.210144 * 100, metric = 7.94% * 100;
 Minibatch[1501-1600]: loss = 0.214090 * 100, metric = 8.03% * 100;
 Minibatch[1601-1700]: loss = 0.213195 * 100, metric = 7.97% * 100;
 Minibatch[1701-1800]: loss = 0.217653 * 100, metric = 8.07% * 100;
 Minibatch[1801-1900]: loss = 0.220476 * 100, metric = 8.38% * 100;
 Minibatch[1901-2000]: loss = 0.211282 * 100, metric = 7.96% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.215179 * 2000, metric = 8.05% * 2000 805.269s (  2.5 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 15.52% * 2000;
 Minibatch[   1- 100]: loss = 0.207850 * 100, metric = 7.77% * 100;
 Minibatch[ 101- 200]: loss = 0.219035 * 100, metric = 8.30% * 100;
 Minibatch[ 201- 300]: loss = 0.208580 * 100, metric = 7.87% * 100;
 Minibatch[ 301- 400]: loss = 0.210098 * 100, metric = 7.90% * 100;
 Minibatch[ 401- 500]: loss = 0.215368 * 100, metric = 8.06% * 100;
 Minibatch[ 501- 600]: loss = 0.209560 * 100, metric = 8.09% * 100;
 Minibatch[ 601- 700]: loss = 0.223411 * 100, metric = 8.22% * 100;
 Minibatch[ 701- 800]: loss = 0.211006 * 100, metric = 8.02% * 100;
 Minibatch[ 801- 900]: loss = 0.219069 * 100, metric = 8.47% * 100;
 Minibatch[ 901-1000]: loss = 0.209537 * 100, metric = 7.82% * 100;
 Minibatch[1001-1100]: loss = 0.205122 * 100, metric = 7.69% * 100;
 Minibatch[1101-1200]: loss = 0.225579 * 100, metric = 8.33% * 100;
 Minibatch[1201-1300]: loss = 0.216476 * 100, metric = 8.10% * 100;
 Minibatch[1301-1400]: loss = 0.211231 * 100, metric = 7.99% * 100;
 Minibatch[1401-1500]: loss = 0.205446 * 100, metric = 7.73% * 100;
 Minibatch[1501-1600]: loss = 0.219583 * 100, metric = 8.40% * 100;
 Minibatch[1601-1700]: loss = 0.210783 * 100, metric = 7.84% * 100;
 Minibatch[1701-1800]: loss = 0.207665 * 100, metric = 7.82% * 100;
 Minibatch[1801-1900]: loss = 0.216777 * 100, metric = 8.29% * 100;
 Minibatch[1901-2000]: loss = 0.213163 * 100, metric = 8.14% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.213267 * 2000, metric = 8.04% * 2000 804.624s (  2.5 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 15.86% * 2000;
 Minibatch[   1- 100]: loss = 0.220084 * 100, metric = 8.17% * 100;
 Minibatch[ 101- 200]: loss = 0.215702 * 100, metric = 8.16% * 100;
 Minibatch[ 201- 300]: loss = 0.216870 * 100, metric = 8.34% * 100;
 Minibatch[ 301- 400]: loss = 0.213098 * 100, metric = 7.96% * 100;
 Minibatch[ 401- 500]: loss = 0.213767 * 100, metric = 7.88% * 100;
 Minibatch[ 501- 600]: loss = 0.213373 * 100, metric = 8.07% * 100;
 Minibatch[ 601- 700]: loss = 0.216019 * 100, metric = 7.98% * 100;
 Minibatch[ 701- 800]: loss = 0.201676 * 100, metric = 7.69% * 100;
 Minibatch[ 801- 900]: loss = 0.206761 * 100, metric = 7.83% * 100;
 Minibatch[ 901-1000]: loss = 0.215658 * 100, metric = 8.43% * 100;
 Minibatch[1001-1100]: loss = 0.210371 * 100, metric = 8.02% * 100;
 Minibatch[1101-1200]: loss = 0.218951 * 100, metric = 8.25% * 100;
 Minibatch[1201-1300]: loss = 0.228557 * 100, metric = 8.63% * 100;
 Minibatch[1301-1400]: loss = 0.203698 * 100, metric = 7.69% * 100;
 Minibatch[1401-1500]: loss = 0.199959 * 100, metric = 7.34% * 100;
 Minibatch[1501-1600]: loss = 0.214714 * 100, metric = 8.15% * 100;
 Minibatch[1601-1700]: loss = 0.210025 * 100, metric = 7.92% * 100;
 Minibatch[1701-1800]: loss = 0.213402 * 100, metric = 8.17% * 100;
 Minibatch[1801-1900]: loss = 0.204298 * 100, metric = 7.69% * 100;
 Minibatch[1901-2000]: loss = 0.197917 * 100, metric = 7.23% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.211745 * 2000, metric = 7.98% * 2000 797.075s (  2.5 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 16.15% * 2000;
 Minibatch[   1- 100]: loss = 0.210466 * 100, metric = 7.89% * 100;
 Minibatch[ 101- 200]: loss = 0.196806 * 100, metric = 7.30% * 100;
 Minibatch[ 201- 300]: loss = 0.209873 * 100, metric = 7.97% * 100;
 Minibatch[ 301- 400]: loss = 0.199926 * 100, metric = 7.46% * 100;
 Minibatch[ 401- 500]: loss = 0.209296 * 100, metric = 7.76% * 100;
 Minibatch[ 501- 600]: loss = 0.201201 * 100, metric = 7.46% * 100;
 Minibatch[ 601- 700]: loss = 0.218711 * 100, metric = 8.16% * 100;
 Minibatch[ 701- 800]: loss = 0.203775 * 100, metric = 7.75% * 100;
 Minibatch[ 801- 900]: loss = 0.192515 * 100, metric = 7.29% * 100;
 Minibatch[ 901-1000]: loss = 0.197872 * 100, metric = 7.29% * 100;
 Minibatch[1001-1100]: loss = 0.209911 * 100, metric = 8.12% * 100;
 Minibatch[1101-1200]: loss = 0.209768 * 100, metric = 7.92% * 100;
 Minibatch[1201-1300]: loss = 0.204241 * 100, metric = 7.55% * 100;
 Minibatch[1301-1400]: loss = 0.198115 * 100, metric = 7.33% * 100;
 Minibatch[1401-1500]: loss = 0.209188 * 100, metric = 7.83% * 100;
 Minibatch[1501-1600]: loss = 0.195579 * 100, metric = 7.27% * 100;
 Minibatch[1601-1700]: loss = 0.217388 * 100, metric = 8.08% * 100;
 Minibatch[1701-1800]: loss = 0.208951 * 100, metric = 7.75% * 100;
 Minibatch[1801-1900]: loss = 0.198857 * 100, metric = 7.42% * 100;
 Minibatch[1901-2000]: loss = 0.195032 * 100, metric = 7.42% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.204373 * 2000, metric = 7.65% * 2000 883.643s (  2.3 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 16.32% * 2000;
 Minibatch[   1- 100]: loss = 0.202745 * 100, metric = 7.40% * 100;
 Minibatch[ 101- 200]: loss = 0.209895 * 100, metric = 7.68% * 100;
 Minibatch[ 201- 300]: loss = 0.202508 * 100, metric = 7.52% * 100;
 Minibatch[ 301- 400]: loss = 0.200257 * 100, metric = 7.48% * 100;
 Minibatch[ 401- 500]: loss = 0.206077 * 100, metric = 7.71% * 100;
 Minibatch[ 501- 600]: loss = 0.206051 * 100, metric = 7.69% * 100;
 Minibatch[ 601- 700]: loss = 0.192219 * 100, metric = 7.05% * 100;
 Minibatch[ 701- 800]: loss = 0.197972 * 100, metric = 7.42% * 100;
 Minibatch[ 801- 900]: loss = 0.210812 * 100, metric = 7.83% * 100;
 Minibatch[ 901-1000]: loss = 0.209591 * 100, metric = 8.01% * 100;
 Minibatch[1001-1100]: loss = 0.197767 * 100, metric = 7.46% * 100;
 Minibatch[1101-1200]: loss = 0.205603 * 100, metric = 7.77% * 100;
 Minibatch[1201-1300]: loss = 0.204541 * 100, metric = 7.51% * 100;
 Minibatch[1301-1400]: loss = 0.213345 * 100, metric = 8.16% * 100;
 Minibatch[1401-1500]: loss = 0.202219 * 100, metric = 7.63% * 100;
 Minibatch[1501-1600]: loss = 0.202571 * 100, metric = 7.50% * 100;
 Minibatch[1601-1700]: loss = 0.190936 * 100, metric = 7.01% * 100;
 Minibatch[1701-1800]: loss = 0.198368 * 100, metric = 7.20% * 100;
 Minibatch[1801-1900]: loss = 0.198125 * 100, metric = 7.19% * 100;
 Minibatch[1901-2000]: loss = 0.203172 * 100, metric = 7.53% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.202739 * 2000, metric = 7.54% * 2000 874.965s (  2.3 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 15.08% * 2000;
 Minibatch[   1- 100]: loss = 0.207612 * 100, metric = 7.69% * 100;
 Minibatch[ 101- 200]: loss = 0.195966 * 100, metric = 7.25% * 100;
 Minibatch[ 201- 300]: loss = 0.204635 * 100, metric = 7.54% * 100;
 Minibatch[ 301- 400]: loss = 0.204335 * 100, metric = 7.30% * 100;
 Minibatch[ 401- 500]: loss = 0.200074 * 100, metric = 7.34% * 100;
 Minibatch[ 501- 600]: loss = 0.211575 * 100, metric = 8.01% * 100;
 Minibatch[ 601- 700]: loss = 0.194572 * 100, metric = 7.29% * 100;
 Minibatch[ 701- 800]: loss = 0.188735 * 100, metric = 7.04% * 100;
 Minibatch[ 801- 900]: loss = 0.198616 * 100, metric = 7.50% * 100;
 Minibatch[ 901-1000]: loss = 0.209947 * 100, metric = 7.80% * 100;
 Minibatch[1001-1100]: loss = 0.196444 * 100, metric = 7.47% * 100;
 Minibatch[1101-1200]: loss = 0.189312 * 100, metric = 6.94% * 100;
 Minibatch[1201-1300]: loss = 0.201397 * 100, metric = 7.55% * 100;
 Minibatch[1301-1400]: loss = 0.196389 * 100, metric = 7.36% * 100;
 Minibatch[1401-1500]: loss = 0.202688 * 100, metric = 7.68% * 100;
 Minibatch[1501-1600]: loss = 0.198278 * 100, metric = 7.22% * 100;
 Minibatch[1601-1700]: loss = 0.197299 * 100, metric = 7.32% * 100;
 Minibatch[1701-1800]: loss = 0.192773 * 100, metric = 7.15% * 100;
 Minibatch[1801-1900]: loss = 0.197444 * 100, metric = 7.40% * 100;
 Minibatch[1901-2000]: loss = 0.194481 * 100, metric = 7.07% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.199129 * 2000, metric = 7.40% * 2000 796.800s (  2.5 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.89% * 2000;
0.4024102315455675
 Minibatch[   1- 100]: loss = 0.186939 * 100, metric = 6.75% * 100;
 Minibatch[ 101- 200]: loss = 0.198624 * 100, metric = 7.43% * 100;
 Minibatch[ 201- 300]: loss = 0.196516 * 100, metric = 7.26% * 100;
 Minibatch[ 301- 400]: loss = 0.208897 * 100, metric = 7.87% * 100;
 Minibatch[ 401- 500]: loss = 0.190008 * 100, metric = 7.05% * 100;
 Minibatch[ 501- 600]: loss = 0.194675 * 100, metric = 7.33% * 100;
 Minibatch[ 601- 700]: loss = 0.195771 * 100, metric = 7.46% * 100;
 Minibatch[ 701- 800]: loss = 0.209556 * 100, metric = 7.80% * 100;
 Minibatch[ 801- 900]: loss = 0.199338 * 100, metric = 7.50% * 100;
 Minibatch[ 901-1000]: loss = 0.198554 * 100, metric = 7.44% * 100;
 Minibatch[1001-1100]: loss = 0.197788 * 100, metric = 7.53% * 100;
 Minibatch[1101-1200]: loss = 0.187496 * 100, metric = 7.03% * 100;
 Minibatch[1201-1300]: loss = 0.198896 * 100, metric = 7.64% * 100;
 Minibatch[1301-1400]: loss = 0.189876 * 100, metric = 7.25% * 100;
 Minibatch[1401-1500]: loss = 0.202365 * 100, metric = 7.55% * 100;
 Minibatch[1501-1600]: loss = 0.188448 * 100, metric = 7.08% * 100;
 Minibatch[1601-1700]: loss = 0.202564 * 100, metric = 7.63% * 100;
 Minibatch[1701-1800]: loss = 0.188952 * 100, metric = 7.14% * 100;
 Minibatch[1801-1900]: loss = 0.207374 * 100, metric = 7.70% * 100;
 Minibatch[1901-2000]: loss = 0.195170 * 100, metric = 7.33% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.196890 * 2000, metric = 7.39% * 2000 798.291s (  2.5 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 15.61% * 2000;
 Minibatch[   1- 100]: loss = 0.203926 * 100, metric = 7.63% * 100;
 Minibatch[ 101- 200]: loss = 0.177719 * 100, metric = 6.68% * 100;
 Minibatch[ 201- 300]: loss = 0.191772 * 100, metric = 7.18% * 100;
 Minibatch[ 301- 400]: loss = 0.196348 * 100, metric = 7.45% * 100;
 Minibatch[ 401- 500]: loss = 0.194639 * 100, metric = 7.33% * 100;
 Minibatch[ 501- 600]: loss = 0.180456 * 100, metric = 6.75% * 100;
 Minibatch[ 601- 700]: loss = 0.197719 * 100, metric = 7.54% * 100;
 Minibatch[ 701- 800]: loss = 0.187894 * 100, metric = 7.14% * 100;
 Minibatch[ 801- 900]: loss = 0.198058 * 100, metric = 7.24% * 100;
 Minibatch[ 901-1000]: loss = 0.178295 * 100, metric = 6.71% * 100;
 Minibatch[1001-1100]: loss = 0.190734 * 100, metric = 6.99% * 100;
 Minibatch[1101-1200]: loss = 0.200027 * 100, metric = 7.42% * 100;
 Minibatch[1201-1300]: loss = 0.184792 * 100, metric = 6.67% * 100;
 Minibatch[1301-1400]: loss = 0.189834 * 100, metric = 7.05% * 100;
 Minibatch[1401-1500]: loss = 0.189710 * 100, metric = 7.07% * 100;
 Minibatch[1501-1600]: loss = 0.195985 * 100, metric = 7.36% * 100;
 Minibatch[1601-1700]: loss = 0.194768 * 100, metric = 7.32% * 100;
 Minibatch[1701-1800]: loss = 0.196414 * 100, metric = 7.44% * 100;
 Minibatch[1801-1900]: loss = 0.192092 * 100, metric = 7.40% * 100;
 Minibatch[1901-2000]: loss = 0.211020 * 100, metric = 8.10% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.192610 * 2000, metric = 7.22% * 2000 797.966s (  2.5 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 15.83% * 2000;
 Minibatch[   1- 100]: loss = 0.191365 * 100, metric = 7.10% * 100;
 Minibatch[ 101- 200]: loss = 0.203918 * 100, metric = 7.79% * 100;
 Minibatch[ 201- 300]: loss = 0.192485 * 100, metric = 7.18% * 100;
 Minibatch[ 301- 400]: loss = 0.186208 * 100, metric = 7.02% * 100;
 Minibatch[ 401- 500]: loss = 0.191657 * 100, metric = 7.09% * 100;
 Minibatch[ 501- 600]: loss = 0.191301 * 100, metric = 7.06% * 100;
 Minibatch[ 601- 700]: loss = 0.199567 * 100, metric = 7.64% * 100;
 Minibatch[ 701- 800]: loss = 0.197973 * 100, metric = 7.37% * 100;
 Minibatch[ 801- 900]: loss = 0.194827 * 100, metric = 7.21% * 100;
 Minibatch[ 901-1000]: loss = 0.183365 * 100, metric = 6.91% * 100;
 Minibatch[1001-1100]: loss = 0.180140 * 100, metric = 6.61% * 100;
 Minibatch[1101-1200]: loss = 0.190345 * 100, metric = 7.27% * 100;
 Minibatch[1201-1300]: loss = 0.187086 * 100, metric = 6.96% * 100;
 Minibatch[1301-1400]: loss = 0.193346 * 100, metric = 7.20% * 100;
 Minibatch[1401-1500]: loss = 0.193681 * 100, metric = 7.16% * 100;
 Minibatch[1501-1600]: loss = 0.182932 * 100, metric = 6.81% * 100;
 Minibatch[1601-1700]: loss = 0.189858 * 100, metric = 7.15% * 100;
 Minibatch[1701-1800]: loss = 0.188669 * 100, metric = 6.99% * 100;
 Minibatch[1801-1900]: loss = 0.194976 * 100, metric = 7.28% * 100;
 Minibatch[1901-2000]: loss = 0.190374 * 100, metric = 7.23% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.191204 * 2000, metric = 7.15% * 2000 794.884s (  2.5 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 15.18% * 2000;
 Minibatch[   1- 100]: loss = 0.187831 * 100, metric = 7.01% * 100;
 Minibatch[ 101- 200]: loss = 0.188119 * 100, metric = 7.02% * 100;
 Minibatch[ 201- 300]: loss = 0.205762 * 100, metric = 7.65% * 100;
 Minibatch[ 301- 400]: loss = 0.201075 * 100, metric = 7.30% * 100;
 Minibatch[ 401- 500]: loss = 0.195244 * 100, metric = 7.26% * 100;
 Minibatch[ 501- 600]: loss = 0.192505 * 100, metric = 7.11% * 100;
 Minibatch[ 601- 700]: loss = 0.184220 * 100, metric = 6.99% * 100;
 Minibatch[ 701- 800]: loss = 0.186251 * 100, metric = 6.92% * 100;
 Minibatch[ 801- 900]: loss = 0.189040 * 100, metric = 6.97% * 100;
 Minibatch[ 901-1000]: loss = 0.181384 * 100, metric = 6.81% * 100;
 Minibatch[1001-1100]: loss = 0.188852 * 100, metric = 7.10% * 100;
 Minibatch[1101-1200]: loss = 0.191649 * 100, metric = 7.12% * 100;
 Minibatch[1201-1300]: loss = 0.195407 * 100, metric = 7.26% * 100;
 Minibatch[1301-1400]: loss = 0.189303 * 100, metric = 7.13% * 100;
 Minibatch[1401-1500]: loss = 0.192156 * 100, metric = 7.23% * 100;
 Minibatch[1501-1600]: loss = 0.193958 * 100, metric = 7.24% * 100;
 Minibatch[1601-1700]: loss = 0.184529 * 100, metric = 6.90% * 100;
 Minibatch[1701-1800]: loss = 0.195149 * 100, metric = 7.32% * 100;
 Minibatch[1801-1900]: loss = 0.180461 * 100, metric = 6.73% * 100;
 Minibatch[1901-2000]: loss = 0.194489 * 100, metric = 7.37% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.190869 * 2000, metric = 7.12% * 2000 795.732s (  2.5 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 14.67% * 2000;
 Minibatch[   1- 100]: loss = 0.201722 * 100, metric = 7.21% * 100;
 Minibatch[ 101- 200]: loss = 0.189559 * 100, metric = 7.08% * 100;
 Minibatch[ 201- 300]: loss = 0.186947 * 100, metric = 7.01% * 100;
 Minibatch[ 301- 400]: loss = 0.193506 * 100, metric = 7.38% * 100;
 Minibatch[ 401- 500]: loss = 0.183849 * 100, metric = 6.87% * 100;
 Minibatch[ 501- 600]: loss = 0.185707 * 100, metric = 6.91% * 100;
 Minibatch[ 601- 700]: loss = 0.195841 * 100, metric = 7.51% * 100;
 Minibatch[ 701- 800]: loss = 0.182022 * 100, metric = 7.03% * 100;
 Minibatch[ 801- 900]: loss = 0.186730 * 100, metric = 6.98% * 100;
 Minibatch[ 901-1000]: loss = 0.176025 * 100, metric = 6.50% * 100;
 Minibatch[1001-1100]: loss = 0.184828 * 100, metric = 6.92% * 100;
 Minibatch[1101-1200]: loss = 0.174059 * 100, metric = 6.50% * 100;
 Minibatch[1201-1300]: loss = 0.195486 * 100, metric = 6.98% * 100;
 Minibatch[1301-1400]: loss = 0.176282 * 100, metric = 6.64% * 100;
 Minibatch[1401-1500]: loss = 0.201359 * 100, metric = 7.20% * 100;
 Minibatch[1501-1600]: loss = 0.191251 * 100, metric = 7.05% * 100;
 Minibatch[1601-1700]: loss = 0.180807 * 100, metric = 6.70% * 100;
 Minibatch[1701-1800]: loss = 0.183483 * 100, metric = 6.91% * 100;
 Minibatch[1801-1900]: loss = 0.179284 * 100, metric = 6.68% * 100;
 Minibatch[1901-2000]: loss = 0.197200 * 100, metric = 7.36% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.187297 * 2000, metric = 6.97% * 2000 794.562s (  2.5 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 14.48% * 2000;
 Minibatch[   1- 100]: loss = 0.183138 * 100, metric = 6.89% * 100;
 Minibatch[ 101- 200]: loss = 0.184549 * 100, metric = 6.95% * 100;
 Minibatch[ 201- 300]: loss = 0.176314 * 100, metric = 6.68% * 100;
 Minibatch[ 301- 400]: loss = 0.189895 * 100, metric = 6.96% * 100;
 Minibatch[ 401- 500]: loss = 0.179526 * 100, metric = 6.55% * 100;
 Minibatch[ 501- 600]: loss = 0.184016 * 100, metric = 6.72% * 100;
 Minibatch[ 601- 700]: loss = 0.186520 * 100, metric = 6.96% * 100;
 Minibatch[ 701- 800]: loss = 0.180828 * 100, metric = 6.73% * 100;
 Minibatch[ 801- 900]: loss = 0.173489 * 100, metric = 6.33% * 100;
 Minibatch[ 901-1000]: loss = 0.184364 * 100, metric = 7.01% * 100;
 Minibatch[1001-1100]: loss = 0.185061 * 100, metric = 6.88% * 100;
 Minibatch[1101-1200]: loss = 0.180904 * 100, metric = 6.82% * 100;
 Minibatch[1201-1300]: loss = 0.183105 * 100, metric = 6.79% * 100;
 Minibatch[1301-1400]: loss = 0.183699 * 100, metric = 6.71% * 100;
 Minibatch[1401-1500]: loss = 0.186790 * 100, metric = 6.90% * 100;
 Minibatch[1501-1600]: loss = 0.184599 * 100, metric = 7.05% * 100;
 Minibatch[1601-1700]: loss = 0.196525 * 100, metric = 7.43% * 100;
 Minibatch[1701-1800]: loss = 0.187213 * 100, metric = 6.92% * 100;
 Minibatch[1801-1900]: loss = 0.182686 * 100, metric = 6.82% * 100;
 Minibatch[1901-2000]: loss = 0.179403 * 100, metric = 6.82% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.183631 * 2000, metric = 6.85% * 2000 795.792s (  2.5 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.67% * 2000;
 Minibatch[   1- 100]: loss = 0.171824 * 100, metric = 6.33% * 100;
 Minibatch[ 101- 200]: loss = 0.185891 * 100, metric = 6.89% * 100;
 Minibatch[ 201- 300]: loss = 0.181642 * 100, metric = 6.85% * 100;
 Minibatch[ 301- 400]: loss = 0.175636 * 100, metric = 6.67% * 100;
 Minibatch[ 401- 500]: loss = 0.181191 * 100, metric = 6.67% * 100;
 Minibatch[ 501- 600]: loss = 0.174058 * 100, metric = 6.37% * 100;
 Minibatch[ 601- 700]: loss = 0.185757 * 100, metric = 7.02% * 100;
 Minibatch[ 701- 800]: loss = 0.170555 * 100, metric = 6.32% * 100;
 Minibatch[ 801- 900]: loss = 0.187640 * 100, metric = 7.06% * 100;
 Minibatch[ 901-1000]: loss = 0.174192 * 100, metric = 6.52% * 100;
 Minibatch[1001-1100]: loss = 0.186562 * 100, metric = 6.87% * 100;
 Minibatch[1101-1200]: loss = 0.174635 * 100, metric = 6.54% * 100;
 Minibatch[1201-1300]: loss = 0.180862 * 100, metric = 6.63% * 100;
 Minibatch[1301-1400]: loss = 0.183086 * 100, metric = 6.79% * 100;
 Minibatch[1401-1500]: loss = 0.172511 * 100, metric = 6.38% * 100;
 Minibatch[1501-1600]: loss = 0.184559 * 100, metric = 7.01% * 100;
 Minibatch[1601-1700]: loss = 0.178842 * 100, metric = 6.57% * 100;
 Minibatch[1701-1800]: loss = 0.177483 * 100, metric = 6.53% * 100;
 Minibatch[1801-1900]: loss = 0.187275 * 100, metric = 7.03% * 100;
 Minibatch[1901-2000]: loss = 0.172813 * 100, metric = 6.53% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.179351 * 2000, metric = 6.68% * 2000 788.369s (  2.5 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 14.87% * 2000;
 Minibatch[   1- 100]: loss = 0.171891 * 100, metric = 6.49% * 100;
 Minibatch[ 101- 200]: loss = 0.163832 * 100, metric = 5.98% * 100;
 Minibatch[ 201- 300]: loss = 0.183402 * 100, metric = 6.85% * 100;
 Minibatch[ 301- 400]: loss = 0.174721 * 100, metric = 6.41% * 100;
 Minibatch[ 401- 500]: loss = 0.173643 * 100, metric = 6.38% * 100;
 Minibatch[ 501- 600]: loss = 0.172314 * 100, metric = 6.42% * 100;
 Minibatch[ 601- 700]: loss = 0.175140 * 100, metric = 6.40% * 100;
 Minibatch[ 701- 800]: loss = 0.162237 * 100, metric = 6.16% * 100;
 Minibatch[ 801- 900]: loss = 0.173451 * 100, metric = 6.34% * 100;
 Minibatch[ 901-1000]: loss = 0.177674 * 100, metric = 6.66% * 100;
 Minibatch[1001-1100]: loss = 0.183897 * 100, metric = 6.81% * 100;
 Minibatch[1101-1200]: loss = 0.174208 * 100, metric = 6.54% * 100;
 Minibatch[1201-1300]: loss = 0.179093 * 100, metric = 6.59% * 100;
 Minibatch[1301-1400]: loss = 0.163387 * 100, metric = 6.09% * 100;
 Minibatch[1401-1500]: loss = 0.167524 * 100, metric = 6.10% * 100;
 Minibatch[1501-1600]: loss = 0.173841 * 100, metric = 6.29% * 100;
 Minibatch[1601-1700]: loss = 0.183897 * 100, metric = 6.79% * 100;
 Minibatch[1701-1800]: loss = 0.170286 * 100, metric = 6.36% * 100;
 Minibatch[1801-1900]: loss = 0.172184 * 100, metric = 6.36% * 100;
 Minibatch[1901-2000]: loss = 0.173649 * 100, metric = 6.32% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.173514 * 2000, metric = 6.42% * 2000 788.282s (  2.5 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.73% * 2000;
 Minibatch[   1- 100]: loss = 0.173465 * 100, metric = 6.36% * 100;
 Minibatch[ 101- 200]: loss = 0.181698 * 100, metric = 6.71% * 100;
 Minibatch[ 201- 300]: loss = 0.182762 * 100, metric = 6.71% * 100;
 Minibatch[ 301- 400]: loss = 0.170332 * 100, metric = 6.41% * 100;
 Minibatch[ 401- 500]: loss = 0.171413 * 100, metric = 6.43% * 100;
 Minibatch[ 501- 600]: loss = 0.168276 * 100, metric = 6.26% * 100;
 Minibatch[ 601- 700]: loss = 0.171262 * 100, metric = 6.51% * 100;
 Minibatch[ 701- 800]: loss = 0.182978 * 100, metric = 6.75% * 100;
 Minibatch[ 801- 900]: loss = 0.173464 * 100, metric = 6.46% * 100;
 Minibatch[ 901-1000]: loss = 0.171099 * 100, metric = 6.10% * 100;
 Minibatch[1001-1100]: loss = 0.171679 * 100, metric = 6.43% * 100;
 Minibatch[1101-1200]: loss = 0.184020 * 100, metric = 7.02% * 100;
 Minibatch[1201-1300]: loss = 0.184053 * 100, metric = 6.71% * 100;
 Minibatch[1301-1400]: loss = 0.170684 * 100, metric = 6.41% * 100;
 Minibatch[1401-1500]: loss = 0.178754 * 100, metric = 6.66% * 100;
 Minibatch[1501-1600]: loss = 0.170560 * 100, metric = 6.26% * 100;
 Minibatch[1601-1700]: loss = 0.172528 * 100, metric = 6.54% * 100;
 Minibatch[1701-1800]: loss = 0.175734 * 100, metric = 6.57% * 100;
 Minibatch[1801-1900]: loss = 0.177097 * 100, metric = 6.54% * 100;
 Minibatch[1901-2000]: loss = 0.174931 * 100, metric = 6.42% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.175340 * 2000, metric = 6.51% * 2000 791.107s (  2.5 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 14.27% * 2000;
 Minibatch[   1- 100]: loss = 0.180558 * 100, metric = 6.71% * 100;
 Minibatch[ 101- 200]: loss = 0.179119 * 100, metric = 6.82% * 100;
 Minibatch[ 201- 300]: loss = 0.163414 * 100, metric = 6.16% * 100;
 Minibatch[ 301- 400]: loss = 0.169121 * 100, metric = 6.24% * 100;
 Minibatch[ 401- 500]: loss = 0.172273 * 100, metric = 6.41% * 100;
 Minibatch[ 501- 600]: loss = 0.172361 * 100, metric = 6.20% * 100;
 Minibatch[ 601- 700]: loss = 0.177564 * 100, metric = 6.69% * 100;
 Minibatch[ 701- 800]: loss = 0.171186 * 100, metric = 6.48% * 100;
 Minibatch[ 801- 900]: loss = 0.178042 * 100, metric = 6.67% * 100;
 Minibatch[ 901-1000]: loss = 0.171726 * 100, metric = 6.19% * 100;
 Minibatch[1001-1100]: loss = 0.182437 * 100, metric = 6.83% * 100;
 Minibatch[1101-1200]: loss = 0.167041 * 100, metric = 6.14% * 100;
 Minibatch[1201-1300]: loss = 0.173557 * 100, metric = 6.46% * 100;
 Minibatch[1301-1400]: loss = 0.177930 * 100, metric = 6.63% * 100;
 Minibatch[1401-1500]: loss = 0.171977 * 100, metric = 6.37% * 100;
 Minibatch[1501-1600]: loss = 0.175097 * 100, metric = 6.57% * 100;
 Minibatch[1601-1700]: loss = 0.167081 * 100, metric = 6.25% * 100;
 Minibatch[1701-1800]: loss = 0.167943 * 100, metric = 6.15% * 100;
 Minibatch[1801-1900]: loss = 0.174880 * 100, metric = 6.49% * 100;
 Minibatch[1901-2000]: loss = 0.173247 * 100, metric = 6.41% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.173328 * 2000, metric = 6.44% * 2000 791.593s (  2.5 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 14.04% * 2000;
 Minibatch[   1- 100]: loss = 0.169796 * 100, metric = 6.35% * 100;
 Minibatch[ 101- 200]: loss = 0.173869 * 100, metric = 6.35% * 100;
 Minibatch[ 201- 300]: loss = 0.173960 * 100, metric = 6.37% * 100;
 Minibatch[ 301- 400]: loss = 0.167921 * 100, metric = 6.32% * 100;
 Minibatch[ 401- 500]: loss = 0.171358 * 100, metric = 6.44% * 100;
 Minibatch[ 501- 600]: loss = 0.174880 * 100, metric = 6.53% * 100;
 Minibatch[ 601- 700]: loss = 0.174038 * 100, metric = 6.40% * 100;
 Minibatch[ 701- 800]: loss = 0.168684 * 100, metric = 6.34% * 100;
 Minibatch[ 801- 900]: loss = 0.160011 * 100, metric = 5.86% * 100;
 Minibatch[ 901-1000]: loss = 0.167100 * 100, metric = 6.18% * 100;
 Minibatch[1001-1100]: loss = 0.180925 * 100, metric = 6.62% * 100;
 Minibatch[1101-1200]: loss = 0.170695 * 100, metric = 6.32% * 100;
 Minibatch[1201-1300]: loss = 0.170165 * 100, metric = 6.21% * 100;
 Minibatch[1301-1400]: loss = 0.180961 * 100, metric = 6.46% * 100;
 Minibatch[1401-1500]: loss = 0.172758 * 100, metric = 6.46% * 100;
 Minibatch[1501-1600]: loss = 0.174232 * 100, metric = 6.22% * 100;
 Minibatch[1601-1700]: loss = 0.170066 * 100, metric = 6.25% * 100;
 Minibatch[1701-1800]: loss = 0.176331 * 100, metric = 6.57% * 100;
 Minibatch[1801-1900]: loss = 0.170695 * 100, metric = 6.30% * 100;
 Minibatch[1901-2000]: loss = 0.168478 * 100, metric = 6.17% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.171846 * 2000, metric = 6.34% * 2000 781.911s (  2.6 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.71% * 2000;
 Minibatch[   1- 100]: loss = 0.164354 * 100, metric = 6.13% * 100;
 Minibatch[ 101- 200]: loss = 0.164764 * 100, metric = 6.20% * 100;
 Minibatch[ 201- 300]: loss = 0.173902 * 100, metric = 6.40% * 100;
 Minibatch[ 301- 400]: loss = 0.173774 * 100, metric = 6.42% * 100;
 Minibatch[ 401- 500]: loss = 0.167549 * 100, metric = 6.22% * 100;
 Minibatch[ 501- 600]: loss = 0.175220 * 100, metric = 6.29% * 100;
 Minibatch[ 601- 700]: loss = 0.174719 * 100, metric = 6.59% * 100;
 Minibatch[ 701- 800]: loss = 0.168588 * 100, metric = 6.23% * 100;
 Minibatch[ 801- 900]: loss = 0.166130 * 100, metric = 6.17% * 100;
 Minibatch[ 901-1000]: loss = 0.167760 * 100, metric = 6.25% * 100;
 Minibatch[1001-1100]: loss = 0.179529 * 100, metric = 6.52% * 100;
 Minibatch[1101-1200]: loss = 0.170594 * 100, metric = 6.30% * 100;
 Minibatch[1201-1300]: loss = 0.166685 * 100, metric = 6.07% * 100;
 Minibatch[1301-1400]: loss = 0.171182 * 100, metric = 6.27% * 100;
 Minibatch[1401-1500]: loss = 0.165246 * 100, metric = 6.12% * 100;
 Minibatch[1501-1600]: loss = 0.169608 * 100, metric = 6.46% * 100;
 Minibatch[1601-1700]: loss = 0.170149 * 100, metric = 6.32% * 100;
 Minibatch[1701-1800]: loss = 0.163472 * 100, metric = 5.96% * 100;
 Minibatch[1801-1900]: loss = 0.162614 * 100, metric = 5.94% * 100;
 Minibatch[1901-2000]: loss = 0.173092 * 100, metric = 6.31% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.169446 * 2000, metric = 6.26% * 2000 786.310s (  2.5 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 13.70% * 2000;
 Minibatch[   1- 100]: loss = 0.170677 * 100, metric = 6.35% * 100;
 Minibatch[ 101- 200]: loss = 0.166198 * 100, metric = 6.09% * 100;
 Minibatch[ 201- 300]: loss = 0.173837 * 100, metric = 6.45% * 100;
 Minibatch[ 301- 400]: loss = 0.171677 * 100, metric = 6.38% * 100;
 Minibatch[ 401- 500]: loss = 0.168800 * 100, metric = 6.37% * 100;
 Minibatch[ 501- 600]: loss = 0.161592 * 100, metric = 5.87% * 100;
 Minibatch[ 601- 700]: loss = 0.175667 * 100, metric = 6.31% * 100;
 Minibatch[ 701- 800]: loss = 0.167579 * 100, metric = 6.07% * 100;
 Minibatch[ 801- 900]: loss = 0.161068 * 100, metric = 6.05% * 100;
 Minibatch[ 901-1000]: loss = 0.168358 * 100, metric = 6.21% * 100;
 Minibatch[1001-1100]: loss = 0.164453 * 100, metric = 6.04% * 100;
 Minibatch[1101-1200]: loss = 0.173401 * 100, metric = 6.48% * 100;
 Minibatch[1201-1300]: loss = 0.174418 * 100, metric = 6.38% * 100;
 Minibatch[1301-1400]: loss = 0.160147 * 100, metric = 5.88% * 100;
 Minibatch[1401-1500]: loss = 0.166254 * 100, metric = 5.98% * 100;
 Minibatch[1501-1600]: loss = 0.166406 * 100, metric = 6.20% * 100;
 Minibatch[1601-1700]: loss = 0.167242 * 100, metric = 6.13% * 100;
 Minibatch[1701-1800]: loss = 0.165444 * 100, metric = 6.25% * 100;
 Minibatch[1801-1900]: loss = 0.169284 * 100, metric = 6.24% * 100;
 Minibatch[1901-2000]: loss = 0.159886 * 100, metric = 5.98% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.167619 * 2000, metric = 6.19% * 2000 789.088s (  2.5 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 14.49% * 2000;
 Minibatch[   1- 100]: loss = 0.162543 * 100, metric = 6.02% * 100;
 Minibatch[ 101- 200]: loss = 0.169016 * 100, metric = 6.23% * 100;
 Minibatch[ 201- 300]: loss = 0.164186 * 100, metric = 6.06% * 100;
 Minibatch[ 301- 400]: loss = 0.163438 * 100, metric = 5.97% * 100;
 Minibatch[ 401- 500]: loss = 0.160350 * 100, metric = 5.84% * 100;
 Minibatch[ 501- 600]: loss = 0.165958 * 100, metric = 6.08% * 100;
 Minibatch[ 601- 700]: loss = 0.163893 * 100, metric = 6.16% * 100;
 Minibatch[ 701- 800]: loss = 0.161813 * 100, metric = 5.96% * 100;
 Minibatch[ 801- 900]: loss = 0.163539 * 100, metric = 6.02% * 100;
 Minibatch[ 901-1000]: loss = 0.165035 * 100, metric = 6.11% * 100;
 Minibatch[1001-1100]: loss = 0.166494 * 100, metric = 6.05% * 100;
 Minibatch[1101-1200]: loss = 0.167077 * 100, metric = 6.02% * 100;
 Minibatch[1201-1300]: loss = 0.163772 * 100, metric = 6.06% * 100;
 Minibatch[1301-1400]: loss = 0.161880 * 100, metric = 5.88% * 100;
 Minibatch[1401-1500]: loss = 0.160887 * 100, metric = 5.82% * 100;
 Minibatch[1501-1600]: loss = 0.163038 * 100, metric = 5.93% * 100;
 Minibatch[1601-1700]: loss = 0.167268 * 100, metric = 6.06% * 100;
 Minibatch[1701-1800]: loss = 0.162649 * 100, metric = 6.03% * 100;
 Minibatch[1801-1900]: loss = 0.164704 * 100, metric = 6.16% * 100;
 Minibatch[1901-2000]: loss = 0.162712 * 100, metric = 6.03% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.164013 * 2000, metric = 6.02% * 2000 788.280s (  2.5 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 14.24% * 2000;
 Minibatch[   1- 100]: loss = 0.179756 * 100, metric = 6.72% * 100;
 Minibatch[ 101- 200]: loss = 0.155944 * 100, metric = 5.79% * 100;
 Minibatch[ 201- 300]: loss = 0.169584 * 100, metric = 6.24% * 100;
 Minibatch[ 301- 400]: loss = 0.168454 * 100, metric = 6.25% * 100;
 Minibatch[ 401- 500]: loss = 0.160151 * 100, metric = 5.95% * 100;
 Minibatch[ 501- 600]: loss = 0.165278 * 100, metric = 6.11% * 100;
 Minibatch[ 601- 700]: loss = 0.169371 * 100, metric = 6.31% * 100;
 Minibatch[ 701- 800]: loss = 0.162496 * 100, metric = 6.15% * 100;
 Minibatch[ 801- 900]: loss = 0.161168 * 100, metric = 5.99% * 100;
 Minibatch[ 901-1000]: loss = 0.164111 * 100, metric = 6.12% * 100;
 Minibatch[1001-1100]: loss = 0.165152 * 100, metric = 6.10% * 100;
 Minibatch[1101-1200]: loss = 0.160211 * 100, metric = 6.04% * 100;
 Minibatch[1201-1300]: loss = 0.165236 * 100, metric = 6.12% * 100;
 Minibatch[1301-1400]: loss = 0.169723 * 100, metric = 6.27% * 100;
 Minibatch[1401-1500]: loss = 0.152528 * 100, metric = 5.69% * 100;
 Minibatch[1501-1600]: loss = 0.168244 * 100, metric = 6.16% * 100;
 Minibatch[1601-1700]: loss = 0.163144 * 100, metric = 6.05% * 100;
 Minibatch[1701-1800]: loss = 0.163043 * 100, metric = 6.08% * 100;
 Minibatch[1801-1900]: loss = 0.168235 * 100, metric = 6.29% * 100;
 Minibatch[1901-2000]: loss = 0.159590 * 100, metric = 5.96% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.164571 * 2000, metric = 6.12% * 2000 818.485s (  2.4 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 13.47% * 2000;
 Minibatch[   1- 100]: loss = 0.160675 * 100, metric = 5.98% * 100;
 Minibatch[ 101- 200]: loss = 0.164303 * 100, metric = 6.15% * 100;
 Minibatch[ 201- 300]: loss = 0.164521 * 100, metric = 5.83% * 100;
 Minibatch[ 301- 400]: loss = 0.166867 * 100, metric = 6.18% * 100;
 Minibatch[ 401- 500]: loss = 0.158323 * 100, metric = 5.85% * 100;
 Minibatch[ 501- 600]: loss = 0.160762 * 100, metric = 5.99% * 100;
 Minibatch[ 601- 700]: loss = 0.169136 * 100, metric = 6.25% * 100;
 Minibatch[ 701- 800]: loss = 0.148317 * 100, metric = 5.47% * 100;
 Minibatch[ 801- 900]: loss = 0.154716 * 100, metric = 5.75% * 100;
 Minibatch[ 901-1000]: loss = 0.159266 * 100, metric = 5.91% * 100;
 Minibatch[1001-1100]: loss = 0.155604 * 100, metric = 5.56% * 100;
 Minibatch[1101-1200]: loss = 0.156113 * 100, metric = 5.80% * 100;
 Minibatch[1201-1300]: loss = 0.160383 * 100, metric = 6.01% * 100;
 Minibatch[1301-1400]: loss = 0.155378 * 100, metric = 5.79% * 100;
 Minibatch[1401-1500]: loss = 0.155668 * 100, metric = 5.72% * 100;
 Minibatch[1501-1600]: loss = 0.152629 * 100, metric = 5.64% * 100;
 Minibatch[1601-1700]: loss = 0.162336 * 100, metric = 5.97% * 100;
 Minibatch[1701-1800]: loss = 0.166508 * 100, metric = 6.34% * 100;
 Minibatch[1801-1900]: loss = 0.159876 * 100, metric = 5.90% * 100;
 Minibatch[1901-2000]: loss = 0.155513 * 100, metric = 5.73% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.159345 * 2000, metric = 5.89% * 2000 864.886s (  2.3 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 14.19% * 2000;
 Minibatch[   1- 100]: loss = 0.164341 * 100, metric = 5.97% * 100;
 Minibatch[ 101- 200]: loss = 0.156279 * 100, metric = 5.61% * 100;
 Minibatch[ 201- 300]: loss = 0.156454 * 100, metric = 5.83% * 100;
 Minibatch[ 301- 400]: loss = 0.160263 * 100, metric = 5.89% * 100;
 Minibatch[ 401- 500]: loss = 0.158539 * 100, metric = 5.78% * 100;
 Minibatch[ 501- 600]: loss = 0.151845 * 100, metric = 5.68% * 100;
 Minibatch[ 601- 700]: loss = 0.154081 * 100, metric = 5.63% * 100;
 Minibatch[ 701- 800]: loss = 0.159319 * 100, metric = 5.84% * 100;
 Minibatch[ 801- 900]: loss = 0.167300 * 100, metric = 6.25% * 100;
 Minibatch[ 901-1000]: loss = 0.157259 * 100, metric = 5.92% * 100;
 Minibatch[1001-1100]: loss = 0.154726 * 100, metric = 5.62% * 100;
 Minibatch[1101-1200]: loss = 0.162556 * 100, metric = 5.73% * 100;
 Minibatch[1201-1300]: loss = 0.160079 * 100, metric = 5.77% * 100;
 Minibatch[1301-1400]: loss = 0.154215 * 100, metric = 5.67% * 100;
 Minibatch[1401-1500]: loss = 0.161795 * 100, metric = 6.00% * 100;
 Minibatch[1501-1600]: loss = 0.157420 * 100, metric = 5.81% * 100;
 Minibatch[1601-1700]: loss = 0.152429 * 100, metric = 5.60% * 100;
 Minibatch[1701-1800]: loss = 0.163245 * 100, metric = 5.90% * 100;
 Minibatch[1801-1900]: loss = 0.160921 * 100, metric = 6.06% * 100;
 Minibatch[1901-2000]: loss = 0.156288 * 100, metric = 5.73% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.158468 * 2000, metric = 5.81% * 2000 869.653s (  2.3 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 14.25% * 2000;
 Minibatch[   1- 100]: loss = 0.153875 * 100, metric = 5.80% * 100;
 Minibatch[ 101- 200]: loss = 0.163192 * 100, metric = 6.15% * 100;
 Minibatch[ 201- 300]: loss = 0.154735 * 100, metric = 5.66% * 100;
 Minibatch[ 301- 400]: loss = 0.167024 * 100, metric = 6.06% * 100;
 Minibatch[ 401- 500]: loss = 0.157493 * 100, metric = 5.95% * 100;
 Minibatch[ 501- 600]: loss = 0.158685 * 100, metric = 5.78% * 100;
 Minibatch[ 601- 700]: loss = 0.142345 * 100, metric = 5.23% * 100;
 Minibatch[ 701- 800]: loss = 0.151558 * 100, metric = 5.49% * 100;
 Minibatch[ 801- 900]: loss = 0.153789 * 100, metric = 5.70% * 100;
 Minibatch[ 901-1000]: loss = 0.158191 * 100, metric = 5.86% * 100;
 Minibatch[1001-1100]: loss = 0.153426 * 100, metric = 5.58% * 100;
 Minibatch[1101-1200]: loss = 0.162973 * 100, metric = 5.99% * 100;
 Minibatch[1201-1300]: loss = 0.157044 * 100, metric = 5.88% * 100;
 Minibatch[1301-1400]: loss = 0.158601 * 100, metric = 5.84% * 100;
 Minibatch[1401-1500]: loss = 0.150839 * 100, metric = 5.66% * 100;
 Minibatch[1501-1600]: loss = 0.156143 * 100, metric = 5.81% * 100;
 Minibatch[1601-1700]: loss = 0.146825 * 100, metric = 5.32% * 100;
 Minibatch[1701-1800]: loss = 0.161910 * 100, metric = 5.75% * 100;
 Minibatch[1801-1900]: loss = 0.148147 * 100, metric = 5.36% * 100;
 Minibatch[1901-2000]: loss = 0.151063 * 100, metric = 5.61% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.155393 * 2000, metric = 5.72% * 2000 866.517s (  2.3 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 14.09% * 2000;
 Minibatch[   1- 100]: loss = 0.152093 * 100, metric = 5.60% * 100;
 Minibatch[ 101- 200]: loss = 0.153628 * 100, metric = 5.68% * 100;
 Minibatch[ 201- 300]: loss = 0.154652 * 100, metric = 5.55% * 100;
 Minibatch[ 301- 400]: loss = 0.150723 * 100, metric = 5.51% * 100;
 Minibatch[ 401- 500]: loss = 0.152559 * 100, metric = 5.55% * 100;
 Minibatch[ 501- 600]: loss = 0.155974 * 100, metric = 5.71% * 100;
 Minibatch[ 601- 700]: loss = 0.158823 * 100, metric = 5.81% * 100;
 Minibatch[ 701- 800]: loss = 0.160093 * 100, metric = 5.93% * 100;
 Minibatch[ 801- 900]: loss = 0.148298 * 100, metric = 5.46% * 100;
 Minibatch[ 901-1000]: loss = 0.156138 * 100, metric = 5.77% * 100;
 Minibatch[1001-1100]: loss = 0.159855 * 100, metric = 5.77% * 100;
 Minibatch[1101-1200]: loss = 0.152610 * 100, metric = 5.62% * 100;
 Minibatch[1201-1300]: loss = 0.141877 * 100, metric = 5.04% * 100;
 Minibatch[1301-1400]: loss = 0.153519 * 100, metric = 5.58% * 100;
 Minibatch[1401-1500]: loss = 0.152843 * 100, metric = 5.62% * 100;
 Minibatch[1501-1600]: loss = 0.154882 * 100, metric = 5.70% * 100;
 Minibatch[1601-1700]: loss = 0.149061 * 100, metric = 5.36% * 100;
 Minibatch[1701-1800]: loss = 0.160105 * 100, metric = 5.83% * 100;
 Minibatch[1801-1900]: loss = 0.152404 * 100, metric = 5.70% * 100;
 Minibatch[1901-2000]: loss = 0.156729 * 100, metric = 5.78% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.153843 * 2000, metric = 5.63% * 2000 866.942s (  2.3 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 13.27% * 2000;
 Minibatch[   1- 100]: loss = 0.154413 * 100, metric = 5.65% * 100;
 Minibatch[ 101- 200]: loss = 0.151329 * 100, metric = 5.62% * 100;
 Minibatch[ 201- 300]: loss = 0.159692 * 100, metric = 5.64% * 100;
 Minibatch[ 301- 400]: loss = 0.148261 * 100, metric = 5.42% * 100;
 Minibatch[ 401- 500]: loss = 0.157393 * 100, metric = 5.78% * 100;
 Minibatch[ 501- 600]: loss = 0.167170 * 100, metric = 6.01% * 100;
 Minibatch[ 601- 700]: loss = 0.161131 * 100, metric = 5.71% * 100;
 Minibatch[ 701- 800]: loss = 0.146768 * 100, metric = 5.31% * 100;
 Minibatch[ 801- 900]: loss = 0.146372 * 100, metric = 5.29% * 100;
 Minibatch[ 901-1000]: loss = 0.157332 * 100, metric = 5.88% * 100;
 Minibatch[1001-1100]: loss = 0.153161 * 100, metric = 5.61% * 100;
 Minibatch[1101-1200]: loss = 0.151993 * 100, metric = 5.58% * 100;
 Minibatch[1201-1300]: loss = 0.153459 * 100, metric = 5.58% * 100;
 Minibatch[1301-1400]: loss = 0.148068 * 100, metric = 5.49% * 100;
 Minibatch[1401-1500]: loss = 0.146985 * 100, metric = 5.54% * 100;
 Minibatch[1501-1600]: loss = 0.153165 * 100, metric = 5.66% * 100;
 Minibatch[1601-1700]: loss = 0.146297 * 100, metric = 5.43% * 100;
 Minibatch[1701-1800]: loss = 0.150307 * 100, metric = 5.52% * 100;
 Minibatch[1801-1900]: loss = 0.149996 * 100, metric = 5.62% * 100;
 Minibatch[1901-2000]: loss = 0.140658 * 100, metric = 5.12% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.152198 * 2000, metric = 5.57% * 2000 870.518s (  2.3 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 12.74% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
