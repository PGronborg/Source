Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.325009 * 100, metric = 24.66% * 100;
 Minibatch[ 101- 200]: loss = 1.110237 * 100, metric = 22.47% * 100;
 Minibatch[ 201- 300]: loss = 1.039514 * 100, metric = 21.61% * 100;
 Minibatch[ 301- 400]: loss = 1.044573 * 100, metric = 20.87% * 100;
 Minibatch[ 401- 500]: loss = 0.983468 * 100, metric = 20.01% * 100;
 Minibatch[ 501- 600]: loss = 0.972007 * 100, metric = 19.48% * 100;
 Minibatch[ 601- 700]: loss = 0.944421 * 100, metric = 18.22% * 100;
 Minibatch[ 701- 800]: loss = 0.899907 * 100, metric = 17.14% * 100;
 Minibatch[ 801- 900]: loss = 0.925163 * 100, metric = 17.59% * 100;
 Minibatch[ 901-1000]: loss = 0.928139 * 100, metric = 17.83% * 100;
 Minibatch[1001-1100]: loss = 0.920835 * 100, metric = 17.51% * 100;
 Minibatch[1101-1200]: loss = 0.899254 * 100, metric = 16.55% * 100;
 Minibatch[1201-1300]: loss = 0.896003 * 100, metric = 16.64% * 100;
 Minibatch[1301-1400]: loss = 0.859894 * 100, metric = 15.89% * 100;
 Minibatch[1401-1500]: loss = 0.883851 * 100, metric = 16.60% * 100;
 Minibatch[1501-1600]: loss = 0.858472 * 100, metric = 15.64% * 100;
 Minibatch[1601-1700]: loss = 0.847793 * 100, metric = 15.63% * 100;
 Minibatch[1701-1800]: loss = 0.857123 * 100, metric = 15.80% * 100;
 Minibatch[1801-1900]: loss = 0.857620 * 100, metric = 15.84% * 100;
 Minibatch[1901-2000]: loss = 0.834980 * 100, metric = 15.02% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.944413 * 2000, metric = 18.05% * 2000 973.671s (  2.1 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 23.65% * 2000;
0.8366787330210209
 Minibatch[   1- 100]: loss = 0.838212 * 100, metric = 15.23% * 100;
 Minibatch[ 101- 200]: loss = 0.852722 * 100, metric = 15.89% * 100;
 Minibatch[ 201- 300]: loss = 0.831109 * 100, metric = 14.51% * 100;
 Minibatch[ 301- 400]: loss = 0.834485 * 100, metric = 15.25% * 100;
 Minibatch[ 401- 500]: loss = 0.832808 * 100, metric = 14.97% * 100;
 Minibatch[ 501- 600]: loss = 0.838400 * 100, metric = 14.79% * 100;
 Minibatch[ 601- 700]: loss = 0.792154 * 100, metric = 14.16% * 100;
 Minibatch[ 701- 800]: loss = 0.822842 * 100, metric = 15.03% * 100;
 Minibatch[ 801- 900]: loss = 0.801465 * 100, metric = 14.06% * 100;
 Minibatch[ 901-1000]: loss = 0.776384 * 100, metric = 13.53% * 100;
 Minibatch[1001-1100]: loss = 0.813152 * 100, metric = 14.88% * 100;
 Minibatch[1101-1200]: loss = 0.810210 * 100, metric = 14.52% * 100;
 Minibatch[1201-1300]: loss = 0.801398 * 100, metric = 14.46% * 100;
 Minibatch[1301-1400]: loss = 0.807834 * 100, metric = 14.33% * 100;
 Minibatch[1401-1500]: loss = 0.779872 * 100, metric = 13.64% * 100;
 Minibatch[1501-1600]: loss = 0.769778 * 100, metric = 13.43% * 100;
 Minibatch[1601-1700]: loss = 0.790679 * 100, metric = 13.98% * 100;
 Minibatch[1701-1800]: loss = 0.793568 * 100, metric = 14.52% * 100;
 Minibatch[1801-1900]: loss = 0.805334 * 100, metric = 14.28% * 100;
 Minibatch[1901-2000]: loss = 0.762728 * 100, metric = 13.54% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.807757 * 2000, metric = 14.45% * 2000 915.459s (  2.2 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 21.09% * 2000;
0.7932319244667888
 Minibatch[   1- 100]: loss = 0.786150 * 100, metric = 14.03% * 100;
 Minibatch[ 101- 200]: loss = 0.795347 * 100, metric = 14.11% * 100;
 Minibatch[ 201- 300]: loss = 0.778553 * 100, metric = 13.79% * 100;
 Minibatch[ 301- 400]: loss = 0.796406 * 100, metric = 14.41% * 100;
 Minibatch[ 401- 500]: loss = 0.795240 * 100, metric = 14.41% * 100;
 Minibatch[ 501- 600]: loss = 0.787294 * 100, metric = 14.02% * 100;
 Minibatch[ 601- 700]: loss = 0.802548 * 100, metric = 14.03% * 100;
 Minibatch[ 701- 800]: loss = 0.774017 * 100, metric = 13.23% * 100;
 Minibatch[ 801- 900]: loss = 0.791315 * 100, metric = 14.35% * 100;
 Minibatch[ 901-1000]: loss = 0.763595 * 100, metric = 13.74% * 100;
 Minibatch[1001-1100]: loss = 0.768504 * 100, metric = 13.52% * 100;
 Minibatch[1101-1200]: loss = 0.762307 * 100, metric = 13.42% * 100;
 Minibatch[1201-1300]: loss = 0.755964 * 100, metric = 13.05% * 100;
 Minibatch[1301-1400]: loss = 0.781858 * 100, metric = 13.82% * 100;
 Minibatch[1401-1500]: loss = 0.781780 * 100, metric = 13.72% * 100;
 Minibatch[1501-1600]: loss = 0.755328 * 100, metric = 13.09% * 100;
 Minibatch[1601-1700]: loss = 0.745809 * 100, metric = 12.81% * 100;
 Minibatch[1701-1800]: loss = 0.771406 * 100, metric = 13.46% * 100;
 Minibatch[1801-1900]: loss = 0.756831 * 100, metric = 13.00% * 100;
 Minibatch[1901-2000]: loss = 0.755743 * 100, metric = 13.12% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.775300 * 2000, metric = 13.66% * 2000 917.086s (  2.2 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 21.34% * 2000;
 Minibatch[   1- 100]: loss = 0.773157 * 100, metric = 13.18% * 100;
 Minibatch[ 101- 200]: loss = 0.744881 * 100, metric = 12.99% * 100;
 Minibatch[ 201- 300]: loss = 0.768309 * 100, metric = 13.55% * 100;
 Minibatch[ 301- 400]: loss = 0.730749 * 100, metric = 12.50% * 100;
 Minibatch[ 401- 500]: loss = 0.764463 * 100, metric = 13.24% * 100;
 Minibatch[ 501- 600]: loss = 0.736564 * 100, metric = 12.42% * 100;
 Minibatch[ 601- 700]: loss = 0.735969 * 100, metric = 13.03% * 100;
 Minibatch[ 701- 800]: loss = 0.764761 * 100, metric = 13.39% * 100;
 Minibatch[ 801- 900]: loss = 0.760434 * 100, metric = 13.35% * 100;
 Minibatch[ 901-1000]: loss = 0.754472 * 100, metric = 13.61% * 100;
 Minibatch[1001-1100]: loss = 0.768274 * 100, metric = 13.54% * 100;
 Minibatch[1101-1200]: loss = 0.740391 * 100, metric = 12.76% * 100;
 Minibatch[1201-1300]: loss = 0.745212 * 100, metric = 12.92% * 100;
 Minibatch[1301-1400]: loss = 0.767454 * 100, metric = 13.25% * 100;
 Minibatch[1401-1500]: loss = 0.761583 * 100, metric = 13.18% * 100;
 Minibatch[1501-1600]: loss = 0.726504 * 100, metric = 12.49% * 100;
 Minibatch[1601-1700]: loss = 0.755841 * 100, metric = 13.19% * 100;
 Minibatch[1701-1800]: loss = 0.759824 * 100, metric = 13.28% * 100;
 Minibatch[1801-1900]: loss = 0.740375 * 100, metric = 12.93% * 100;
 Minibatch[1901-2000]: loss = 0.725001 * 100, metric = 12.39% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.751211 * 2000, metric = 13.06% * 2000 917.026s (  2.2 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 22.67% * 2000;
 Minibatch[   1- 100]: loss = 0.759583 * 100, metric = 13.04% * 100;
 Minibatch[ 101- 200]: loss = 0.736178 * 100, metric = 12.64% * 100;
 Minibatch[ 201- 300]: loss = 0.730058 * 100, metric = 12.70% * 100;
 Minibatch[ 301- 400]: loss = 0.773903 * 100, metric = 13.56% * 100;
 Minibatch[ 401- 500]: loss = 0.723935 * 100, metric = 12.33% * 100;
 Minibatch[ 501- 600]: loss = 0.720396 * 100, metric = 12.17% * 100;
 Minibatch[ 601- 700]: loss = 0.733153 * 100, metric = 12.14% * 100;
 Minibatch[ 701- 800]: loss = 0.747715 * 100, metric = 12.91% * 100;
 Minibatch[ 801- 900]: loss = 0.736754 * 100, metric = 12.71% * 100;
 Minibatch[ 901-1000]: loss = 0.722158 * 100, metric = 12.58% * 100;
 Minibatch[1001-1100]: loss = 0.741448 * 100, metric = 12.86% * 100;
 Minibatch[1101-1200]: loss = 0.719894 * 100, metric = 12.21% * 100;
 Minibatch[1201-1300]: loss = 0.739951 * 100, metric = 12.69% * 100;
 Minibatch[1301-1400]: loss = 0.749925 * 100, metric = 13.07% * 100;
 Minibatch[1401-1500]: loss = 0.730758 * 100, metric = 12.91% * 100;
 Minibatch[1501-1600]: loss = 0.730316 * 100, metric = 12.53% * 100;
 Minibatch[1601-1700]: loss = 0.747045 * 100, metric = 13.29% * 100;
 Minibatch[1701-1800]: loss = 0.746239 * 100, metric = 13.03% * 100;
 Minibatch[1801-1900]: loss = 0.737572 * 100, metric = 12.78% * 100;
 Minibatch[1901-2000]: loss = 0.713641 * 100, metric = 12.25% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.737031 * 2000, metric = 12.72% * 2000 919.326s (  2.2 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.77% * 2000;
0.783895722694695
 Minibatch[   1- 100]: loss = 0.719702 * 100, metric = 12.28% * 100;
 Minibatch[ 101- 200]: loss = 0.712937 * 100, metric = 12.31% * 100;
 Minibatch[ 201- 300]: loss = 0.727719 * 100, metric = 12.50% * 100;
 Minibatch[ 301- 400]: loss = 0.728064 * 100, metric = 12.08% * 100;
 Minibatch[ 401- 500]: loss = 0.702034 * 100, metric = 12.02% * 100;
 Minibatch[ 501- 600]: loss = 0.724385 * 100, metric = 12.69% * 100;
 Minibatch[ 601- 700]: loss = 0.714090 * 100, metric = 12.45% * 100;
 Minibatch[ 701- 800]: loss = 0.730765 * 100, metric = 12.64% * 100;
 Minibatch[ 801- 900]: loss = 0.721544 * 100, metric = 12.27% * 100;
 Minibatch[ 901-1000]: loss = 0.703475 * 100, metric = 12.27% * 100;
 Minibatch[1001-1100]: loss = 0.713500 * 100, metric = 12.04% * 100;
 Minibatch[1101-1200]: loss = 0.726995 * 100, metric = 12.32% * 100;
 Minibatch[1201-1300]: loss = 0.736940 * 100, metric = 12.80% * 100;
 Minibatch[1301-1400]: loss = 0.707743 * 100, metric = 12.15% * 100;
 Minibatch[1401-1500]: loss = 0.720434 * 100, metric = 12.35% * 100;
 Minibatch[1501-1600]: loss = 0.709110 * 100, metric = 11.99% * 100;
 Minibatch[1601-1700]: loss = 0.710198 * 100, metric = 11.70% * 100;
 Minibatch[1701-1800]: loss = 0.693508 * 100, metric = 11.97% * 100;
 Minibatch[1801-1900]: loss = 0.714940 * 100, metric = 12.46% * 100;
 Minibatch[1901-2000]: loss = 0.696038 * 100, metric = 11.92% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.715706 * 2000, metric = 12.26% * 2000 914.932s (  2.2 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.80% * 2000;
 Minibatch[   1- 100]: loss = 0.701155 * 100, metric = 12.00% * 100;
 Minibatch[ 101- 200]: loss = 0.710824 * 100, metric = 11.94% * 100;
 Minibatch[ 201- 300]: loss = 0.721033 * 100, metric = 12.22% * 100;
 Minibatch[ 301- 400]: loss = 0.702131 * 100, metric = 11.83% * 100;
 Minibatch[ 401- 500]: loss = 0.716260 * 100, metric = 12.43% * 100;
 Minibatch[ 501- 600]: loss = 0.686720 * 100, metric = 11.47% * 100;
 Minibatch[ 601- 700]: loss = 0.706215 * 100, metric = 11.76% * 100;
 Minibatch[ 701- 800]: loss = 0.717650 * 100, metric = 12.08% * 100;
 Minibatch[ 801- 900]: loss = 0.712149 * 100, metric = 12.21% * 100;
 Minibatch[ 901-1000]: loss = 0.705283 * 100, metric = 12.01% * 100;
 Minibatch[1001-1100]: loss = 0.708534 * 100, metric = 12.11% * 100;
 Minibatch[1101-1200]: loss = 0.696589 * 100, metric = 11.77% * 100;
 Minibatch[1201-1300]: loss = 0.718002 * 100, metric = 12.36% * 100;
 Minibatch[1301-1400]: loss = 0.703215 * 100, metric = 12.20% * 100;
 Minibatch[1401-1500]: loss = 0.691858 * 100, metric = 11.51% * 100;
 Minibatch[1501-1600]: loss = 0.704823 * 100, metric = 11.77% * 100;
 Minibatch[1601-1700]: loss = 0.711257 * 100, metric = 11.95% * 100;
 Minibatch[1701-1800]: loss = 0.699418 * 100, metric = 11.80% * 100;
 Minibatch[1801-1900]: loss = 0.694318 * 100, metric = 11.72% * 100;
 Minibatch[1901-2000]: loss = 0.701586 * 100, metric = 11.89% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.705451 * 2000, metric = 11.95% * 2000 915.881s (  2.2 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 19.62% * 2000;
0.7597490028589964
 Minibatch[   1- 100]: loss = 0.707759 * 100, metric = 12.15% * 100;
 Minibatch[ 101- 200]: loss = 0.692744 * 100, metric = 11.90% * 100;
 Minibatch[ 201- 300]: loss = 0.683144 * 100, metric = 11.67% * 100;
 Minibatch[ 301- 400]: loss = 0.692779 * 100, metric = 11.74% * 100;
 Minibatch[ 401- 500]: loss = 0.691641 * 100, metric = 11.97% * 100;
 Minibatch[ 501- 600]: loss = 0.715514 * 100, metric = 12.53% * 100;
 Minibatch[ 601- 700]: loss = 0.676054 * 100, metric = 11.43% * 100;
 Minibatch[ 701- 800]: loss = 0.695332 * 100, metric = 11.75% * 100;
 Minibatch[ 801- 900]: loss = 0.684722 * 100, metric = 11.31% * 100;
 Minibatch[ 901-1000]: loss = 0.660192 * 100, metric = 10.65% * 100;
 Minibatch[1001-1100]: loss = 0.665734 * 100, metric = 11.34% * 100;
 Minibatch[1101-1200]: loss = 0.667568 * 100, metric = 10.95% * 100;
 Minibatch[1201-1300]: loss = 0.685565 * 100, metric = 11.51% * 100;
 Minibatch[1301-1400]: loss = 0.698149 * 100, metric = 12.01% * 100;
 Minibatch[1401-1500]: loss = 0.688070 * 100, metric = 11.44% * 100;
 Minibatch[1501-1600]: loss = 0.695920 * 100, metric = 11.66% * 100;
 Minibatch[1601-1700]: loss = 0.684625 * 100, metric = 11.29% * 100;
 Minibatch[1701-1800]: loss = 0.678376 * 100, metric = 11.32% * 100;
 Minibatch[1801-1900]: loss = 0.683679 * 100, metric = 11.43% * 100;
 Minibatch[1901-2000]: loss = 0.679574 * 100, metric = 11.28% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.686357 * 2000, metric = 11.57% * 2000 915.187s (  2.2 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 18.53% * 2000;
0.7332861479148268
 Minibatch[   1- 100]: loss = 0.664548 * 100, metric = 10.75% * 100;
 Minibatch[ 101- 200]: loss = 0.690745 * 100, metric = 11.81% * 100;
 Minibatch[ 201- 300]: loss = 0.677594 * 100, metric = 11.08% * 100;
 Minibatch[ 301- 400]: loss = 0.693770 * 100, metric = 11.71% * 100;
 Minibatch[ 401- 500]: loss = 0.686549 * 100, metric = 11.30% * 100;
 Minibatch[ 501- 600]: loss = 0.673791 * 100, metric = 11.32% * 100;
 Minibatch[ 601- 700]: loss = 0.679846 * 100, metric = 11.48% * 100;
 Minibatch[ 701- 800]: loss = 0.663188 * 100, metric = 10.72% * 100;
 Minibatch[ 801- 900]: loss = 0.667379 * 100, metric = 11.14% * 100;
 Minibatch[ 901-1000]: loss = 0.686175 * 100, metric = 11.65% * 100;
 Minibatch[1001-1100]: loss = 0.645131 * 100, metric = 10.38% * 100;
 Minibatch[1101-1200]: loss = 0.671873 * 100, metric = 11.36% * 100;
 Minibatch[1201-1300]: loss = 0.673020 * 100, metric = 11.18% * 100;
 Minibatch[1301-1400]: loss = 0.663806 * 100, metric = 10.58% * 100;
 Minibatch[1401-1500]: loss = 0.687331 * 100, metric = 11.60% * 100;
 Minibatch[1501-1600]: loss = 0.679402 * 100, metric = 11.19% * 100;
 Minibatch[1601-1700]: loss = 0.668743 * 100, metric = 11.24% * 100;
 Minibatch[1701-1800]: loss = 0.662985 * 100, metric = 11.08% * 100;
 Minibatch[1801-1900]: loss = 0.661071 * 100, metric = 11.16% * 100;
 Minibatch[1901-2000]: loss = 0.674036 * 100, metric = 11.36% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.673549 * 2000, metric = 11.21% * 2000 913.831s (  2.2 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 17.37% * 2000;
0.7129335096925498
 Minibatch[   1- 100]: loss = 0.688478 * 100, metric = 12.04% * 100;
 Minibatch[ 101- 200]: loss = 0.657350 * 100, metric = 11.03% * 100;
 Minibatch[ 201- 300]: loss = 0.669719 * 100, metric = 11.36% * 100;
 Minibatch[ 301- 400]: loss = 0.655846 * 100, metric = 10.63% * 100;
 Minibatch[ 401- 500]: loss = 0.667725 * 100, metric = 11.29% * 100;
 Minibatch[ 501- 600]: loss = 0.655948 * 100, metric = 10.98% * 100;
 Minibatch[ 601- 700]: loss = 0.647905 * 100, metric = 10.57% * 100;
 Minibatch[ 701- 800]: loss = 0.640021 * 100, metric = 10.15% * 100;
 Minibatch[ 801- 900]: loss = 0.660445 * 100, metric = 11.00% * 100;
 Minibatch[ 901-1000]: loss = 0.666004 * 100, metric = 11.20% * 100;
 Minibatch[1001-1100]: loss = 0.664261 * 100, metric = 11.19% * 100;
 Minibatch[1101-1200]: loss = 0.659830 * 100, metric = 10.92% * 100;
 Minibatch[1201-1300]: loss = 0.672468 * 100, metric = 11.26% * 100;
 Minibatch[1301-1400]: loss = 0.666127 * 100, metric = 11.37% * 100;
 Minibatch[1401-1500]: loss = 0.651323 * 100, metric = 10.73% * 100;
 Minibatch[1501-1600]: loss = 0.655775 * 100, metric = 11.03% * 100;
 Minibatch[1601-1700]: loss = 0.650560 * 100, metric = 10.46% * 100;
 Minibatch[1701-1800]: loss = 0.658467 * 100, metric = 10.65% * 100;
 Minibatch[1801-1900]: loss = 0.674753 * 100, metric = 11.25% * 100;
 Minibatch[1901-2000]: loss = 0.649773 * 100, metric = 10.97% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.660639 * 2000, metric = 11.00% * 2000 921.775s (  2.2 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 16.92% * 2000;
0.6993364246413112
 Minibatch[   1- 100]: loss = 0.642217 * 100, metric = 10.24% * 100;
 Minibatch[ 101- 200]: loss = 0.656057 * 100, metric = 10.83% * 100;
 Minibatch[ 201- 300]: loss = 0.663888 * 100, metric = 11.06% * 100;
 Minibatch[ 301- 400]: loss = 0.653815 * 100, metric = 10.78% * 100;
 Minibatch[ 401- 500]: loss = 0.647201 * 100, metric = 10.60% * 100;
 Minibatch[ 501- 600]: loss = 0.657462 * 100, metric = 11.07% * 100;
 Minibatch[ 601- 700]: loss = 0.641313 * 100, metric = 10.28% * 100;
 Minibatch[ 701- 800]: loss = 0.659186 * 100, metric = 11.11% * 100;
 Minibatch[ 801- 900]: loss = 0.653862 * 100, metric = 10.82% * 100;
 Minibatch[ 901-1000]: loss = 0.662879 * 100, metric = 11.17% * 100;
 Minibatch[1001-1100]: loss = 0.656176 * 100, metric = 10.85% * 100;
 Minibatch[1101-1200]: loss = 0.651488 * 100, metric = 11.02% * 100;
 Minibatch[1201-1300]: loss = 0.640335 * 100, metric = 10.42% * 100;
 Minibatch[1301-1400]: loss = 0.629763 * 100, metric = 10.29% * 100;
 Minibatch[1401-1500]: loss = 0.659067 * 100, metric = 11.16% * 100;
 Minibatch[1501-1600]: loss = 0.646662 * 100, metric = 10.87% * 100;
 Minibatch[1601-1700]: loss = 0.638899 * 100, metric = 10.50% * 100;
 Minibatch[1701-1800]: loss = 0.660433 * 100, metric = 11.02% * 100;
 Minibatch[1801-1900]: loss = 0.643960 * 100, metric = 10.68% * 100;
 Minibatch[1901-2000]: loss = 0.639639 * 100, metric = 10.77% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.650215 * 2000, metric = 10.78% * 2000 953.288s (  2.1 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 17.67% * 2000;
 Minibatch[   1- 100]: loss = 0.631046 * 100, metric = 10.22% * 100;
 Minibatch[ 101- 200]: loss = 0.643246 * 100, metric = 10.25% * 100;
 Minibatch[ 201- 300]: loss = 0.637339 * 100, metric = 10.53% * 100;
 Minibatch[ 301- 400]: loss = 0.675592 * 100, metric = 11.72% * 100;
 Minibatch[ 401- 500]: loss = 0.631227 * 100, metric = 10.19% * 100;
 Minibatch[ 501- 600]: loss = 0.622067 * 100, metric = 10.05% * 100;
 Minibatch[ 601- 700]: loss = 0.632789 * 100, metric = 10.25% * 100;
 Minibatch[ 701- 800]: loss = 0.639444 * 100, metric = 10.56% * 100;
 Minibatch[ 801- 900]: loss = 0.634489 * 100, metric = 10.28% * 100;
 Minibatch[ 901-1000]: loss = 0.640454 * 100, metric = 10.77% * 100;
 Minibatch[1001-1100]: loss = 0.635938 * 100, metric = 10.61% * 100;
 Minibatch[1101-1200]: loss = 0.643087 * 100, metric = 10.62% * 100;
 Minibatch[1201-1300]: loss = 0.643743 * 100, metric = 10.81% * 100;
 Minibatch[1301-1400]: loss = 0.627360 * 100, metric = 10.23% * 100;
 Minibatch[1401-1500]: loss = 0.648452 * 100, metric = 10.81% * 100;
 Minibatch[1501-1600]: loss = 0.607200 * 100, metric = 10.00% * 100;
 Minibatch[1601-1700]: loss = 0.630033 * 100, metric = 10.52% * 100;
 Minibatch[1701-1800]: loss = 0.618651 * 100, metric = 9.90% * 100;
 Minibatch[1801-1900]: loss = 0.629310 * 100, metric = 10.49% * 100;
 Minibatch[1901-2000]: loss = 0.643882 * 100, metric = 10.66% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.635768 * 2000, metric = 10.47% * 2000 944.683s (  2.1 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 18.04% * 2000;
 Minibatch[   1- 100]: loss = 0.640414 * 100, metric = 10.69% * 100;
 Minibatch[ 101- 200]: loss = 0.636342 * 100, metric = 10.66% * 100;
 Minibatch[ 201- 300]: loss = 0.631964 * 100, metric = 10.61% * 100;
 Minibatch[ 301- 400]: loss = 0.639417 * 100, metric = 10.70% * 100;
 Minibatch[ 401- 500]: loss = 0.640133 * 100, metric = 11.09% * 100;
 Minibatch[ 501- 600]: loss = 0.647881 * 100, metric = 11.05% * 100;
 Minibatch[ 601- 700]: loss = 0.616980 * 100, metric = 10.00% * 100;
 Minibatch[ 701- 800]: loss = 0.624073 * 100, metric = 10.16% * 100;
 Minibatch[ 801- 900]: loss = 0.637190 * 100, metric = 10.54% * 100;
 Minibatch[ 901-1000]: loss = 0.637817 * 100, metric = 10.77% * 100;
 Minibatch[1001-1100]: loss = 0.645303 * 100, metric = 11.03% * 100;
 Minibatch[1101-1200]: loss = 0.625411 * 100, metric = 10.20% * 100;
 Minibatch[1201-1300]: loss = 0.637957 * 100, metric = 10.59% * 100;
 Minibatch[1301-1400]: loss = 0.620438 * 100, metric = 10.14% * 100;
 Minibatch[1401-1500]: loss = 0.620391 * 100, metric = 10.02% * 100;
 Minibatch[1501-1600]: loss = 0.617961 * 100, metric = 9.87% * 100;
 Minibatch[1601-1700]: loss = 0.614178 * 100, metric = 10.22% * 100;
 Minibatch[1701-1800]: loss = 0.625093 * 100, metric = 9.96% * 100;
 Minibatch[1801-1900]: loss = 0.620063 * 100, metric = 10.05% * 100;
 Minibatch[1901-2000]: loss = 0.632181 * 100, metric = 10.48% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.630559 * 2000, metric = 10.44% * 2000 935.578s (  2.1 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 18.19% * 2000;
 Minibatch[   1- 100]: loss = 0.621426 * 100, metric = 10.05% * 100;
 Minibatch[ 101- 200]: loss = 0.609594 * 100, metric = 9.68% * 100;
 Minibatch[ 201- 300]: loss = 0.630877 * 100, metric = 10.57% * 100;
 Minibatch[ 301- 400]: loss = 0.620031 * 100, metric = 10.33% * 100;
 Minibatch[ 401- 500]: loss = 0.614907 * 100, metric = 10.40% * 100;
 Minibatch[ 501- 600]: loss = 0.622864 * 100, metric = 10.27% * 100;
 Minibatch[ 601- 700]: loss = 0.609835 * 100, metric = 10.23% * 100;
 Minibatch[ 701- 800]: loss = 0.630001 * 100, metric = 10.61% * 100;
 Minibatch[ 801- 900]: loss = 0.636636 * 100, metric = 10.90% * 100;
 Minibatch[ 901-1000]: loss = 0.622642 * 100, metric = 10.37% * 100;
 Minibatch[1001-1100]: loss = 0.624027 * 100, metric = 10.57% * 100;
 Minibatch[1101-1200]: loss = 0.618946 * 100, metric = 10.03% * 100;
 Minibatch[1201-1300]: loss = 0.597165 * 100, metric = 9.42% * 100;
 Minibatch[1301-1400]: loss = 0.608909 * 100, metric = 10.22% * 100;
 Minibatch[1401-1500]: loss = 0.621588 * 100, metric = 10.40% * 100;
 Minibatch[1501-1600]: loss = 0.601989 * 100, metric = 9.88% * 100;
 Minibatch[1601-1700]: loss = 0.620313 * 100, metric = 10.03% * 100;
 Minibatch[1701-1800]: loss = 0.608083 * 100, metric = 9.68% * 100;
 Minibatch[1801-1900]: loss = 0.608612 * 100, metric = 9.86% * 100;
 Minibatch[1901-2000]: loss = 0.614480 * 100, metric = 10.00% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.617146 * 2000, metric = 10.18% * 2000 941.196s (  2.1 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 17.96% * 2000;
 Minibatch[   1- 100]: loss = 0.602301 * 100, metric = 9.90% * 100;
 Minibatch[ 101- 200]: loss = 0.617712 * 100, metric = 10.19% * 100;
 Minibatch[ 201- 300]: loss = 0.616099 * 100, metric = 10.06% * 100;
 Minibatch[ 301- 400]: loss = 0.594174 * 100, metric = 9.44% * 100;
 Minibatch[ 401- 500]: loss = 0.596879 * 100, metric = 9.73% * 100;
 Minibatch[ 501- 600]: loss = 0.594432 * 100, metric = 9.44% * 100;
 Minibatch[ 601- 700]: loss = 0.578040 * 100, metric = 9.22% * 100;
 Minibatch[ 701- 800]: loss = 0.610098 * 100, metric = 10.11% * 100;
 Minibatch[ 801- 900]: loss = 0.619090 * 100, metric = 10.58% * 100;
 Minibatch[ 901-1000]: loss = 0.604101 * 100, metric = 9.79% * 100;
 Minibatch[1001-1100]: loss = 0.613666 * 100, metric = 10.07% * 100;
 Minibatch[1101-1200]: loss = 0.594918 * 100, metric = 9.74% * 100;
 Minibatch[1201-1300]: loss = 0.591351 * 100, metric = 9.13% * 100;
 Minibatch[1301-1400]: loss = 0.611794 * 100, metric = 10.21% * 100;
 Minibatch[1401-1500]: loss = 0.578032 * 100, metric = 9.30% * 100;
 Minibatch[1501-1600]: loss = 0.588157 * 100, metric = 9.61% * 100;
 Minibatch[1601-1700]: loss = 0.608008 * 100, metric = 9.91% * 100;
 Minibatch[1701-1800]: loss = 0.579016 * 100, metric = 9.23% * 100;
 Minibatch[1801-1900]: loss = 0.595923 * 100, metric = 9.69% * 100;
 Minibatch[1901-2000]: loss = 0.589225 * 100, metric = 9.51% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.599151 * 2000, metric = 9.74% * 2000 933.586s (  2.1 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 16.01% * 2000;
0.6854033722579479
 Minibatch[   1- 100]: loss = 0.609554 * 100, metric = 10.24% * 100;
 Minibatch[ 101- 200]: loss = 0.602313 * 100, metric = 9.55% * 100;
 Minibatch[ 201- 300]: loss = 0.607028 * 100, metric = 9.78% * 100;
 Minibatch[ 301- 400]: loss = 0.603532 * 100, metric = 9.97% * 100;
 Minibatch[ 401- 500]: loss = 0.577390 * 100, metric = 9.17% * 100;
 Minibatch[ 501- 600]: loss = 0.592669 * 100, metric = 9.46% * 100;
 Minibatch[ 601- 700]: loss = 0.594103 * 100, metric = 9.48% * 100;
 Minibatch[ 701- 800]: loss = 0.593749 * 100, metric = 9.70% * 100;
 Minibatch[ 801- 900]: loss = 0.585998 * 100, metric = 9.39% * 100;
 Minibatch[ 901-1000]: loss = 0.594852 * 100, metric = 9.88% * 100;
 Minibatch[1001-1100]: loss = 0.572278 * 100, metric = 9.38% * 100;
 Minibatch[1101-1200]: loss = 0.585578 * 100, metric = 9.53% * 100;
 Minibatch[1201-1300]: loss = 0.583658 * 100, metric = 9.28% * 100;
 Minibatch[1301-1400]: loss = 0.583831 * 100, metric = 9.36% * 100;
 Minibatch[1401-1500]: loss = 0.577385 * 100, metric = 9.48% * 100;
 Minibatch[1501-1600]: loss = 0.586145 * 100, metric = 9.61% * 100;
 Minibatch[1601-1700]: loss = 0.590847 * 100, metric = 9.36% * 100;
 Minibatch[1701-1800]: loss = 0.600288 * 100, metric = 9.69% * 100;
 Minibatch[1801-1900]: loss = 0.592053 * 100, metric = 9.72% * 100;
 Minibatch[1901-2000]: loss = 0.572026 * 100, metric = 9.28% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.590264 * 2000, metric = 9.56% * 2000 936.564s (  2.1 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 16.56% * 2000;
 Minibatch[   1- 100]: loss = 0.571094 * 100, metric = 9.02% * 100;
 Minibatch[ 101- 200]: loss = 0.595921 * 100, metric = 9.60% * 100;
 Minibatch[ 201- 300]: loss = 0.595863 * 100, metric = 9.72% * 100;
 Minibatch[ 301- 400]: loss = 0.583053 * 100, metric = 9.41% * 100;
 Minibatch[ 401- 500]: loss = 0.594415 * 100, metric = 9.48% * 100;
 Minibatch[ 501- 600]: loss = 0.574495 * 100, metric = 9.04% * 100;
 Minibatch[ 601- 700]: loss = 0.563630 * 100, metric = 8.78% * 100;
 Minibatch[ 701- 800]: loss = 0.575056 * 100, metric = 9.20% * 100;
 Minibatch[ 801- 900]: loss = 0.583938 * 100, metric = 9.61% * 100;
 Minibatch[ 901-1000]: loss = 0.574688 * 100, metric = 9.23% * 100;
 Minibatch[1001-1100]: loss = 0.571918 * 100, metric = 9.17% * 100;
 Minibatch[1101-1200]: loss = 0.593733 * 100, metric = 9.79% * 100;
 Minibatch[1201-1300]: loss = 0.585527 * 100, metric = 9.45% * 100;
 Minibatch[1301-1400]: loss = 0.565467 * 100, metric = 8.92% * 100;
 Minibatch[1401-1500]: loss = 0.584005 * 100, metric = 9.52% * 100;
 Minibatch[1501-1600]: loss = 0.582441 * 100, metric = 9.27% * 100;
 Minibatch[1601-1700]: loss = 0.587593 * 100, metric = 9.22% * 100;
 Minibatch[1701-1800]: loss = 0.570324 * 100, metric = 8.93% * 100;
 Minibatch[1801-1900]: loss = 0.593912 * 100, metric = 9.75% * 100;
 Minibatch[1901-2000]: loss = 0.604114 * 100, metric = 10.01% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.582559 * 2000, metric = 9.36% * 2000 934.444s (  2.1 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 16.05% * 2000;
0.6809319292530417
 Minibatch[   1- 100]: loss = 0.567587 * 100, metric = 8.88% * 100;
 Minibatch[ 101- 200]: loss = 0.590991 * 100, metric = 9.44% * 100;
 Minibatch[ 201- 300]: loss = 0.566413 * 100, metric = 8.91% * 100;
 Minibatch[ 301- 400]: loss = 0.583068 * 100, metric = 9.43% * 100;
 Minibatch[ 401- 500]: loss = 0.564485 * 100, metric = 8.80% * 100;
 Minibatch[ 501- 600]: loss = 0.567953 * 100, metric = 8.81% * 100;
 Minibatch[ 601- 700]: loss = 0.575040 * 100, metric = 9.25% * 100;
 Minibatch[ 701- 800]: loss = 0.565688 * 100, metric = 9.00% * 100;
 Minibatch[ 801- 900]: loss = 0.587912 * 100, metric = 9.36% * 100;
 Minibatch[ 901-1000]: loss = 0.586414 * 100, metric = 9.36% * 100;
 Minibatch[1001-1100]: loss = 0.591175 * 100, metric = 9.73% * 100;
 Minibatch[1101-1200]: loss = 0.582347 * 100, metric = 9.40% * 100;
 Minibatch[1201-1300]: loss = 0.592499 * 100, metric = 9.88% * 100;
 Minibatch[1301-1400]: loss = 0.580458 * 100, metric = 9.41% * 100;
 Minibatch[1401-1500]: loss = 0.568091 * 100, metric = 8.97% * 100;
 Minibatch[1501-1600]: loss = 0.574061 * 100, metric = 9.25% * 100;
 Minibatch[1601-1700]: loss = 0.552222 * 100, metric = 8.65% * 100;
 Minibatch[1701-1800]: loss = 0.563919 * 100, metric = 8.70% * 100;
 Minibatch[1801-1900]: loss = 0.554033 * 100, metric = 9.06% * 100;
 Minibatch[1901-2000]: loss = 0.557200 * 100, metric = 8.73% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.573578 * 2000, metric = 9.15% * 2000 921.377s (  2.2 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 16.36% * 2000;
0.6774399244710803
 Minibatch[   1- 100]: loss = 0.575046 * 100, metric = 9.50% * 100;
 Minibatch[ 101- 200]: loss = 0.590005 * 100, metric = 9.72% * 100;
 Minibatch[ 201- 300]: loss = 0.556068 * 100, metric = 8.64% * 100;
 Minibatch[ 301- 400]: loss = 0.571370 * 100, metric = 9.13% * 100;
 Minibatch[ 401- 500]: loss = 0.568117 * 100, metric = 8.99% * 100;
 Minibatch[ 501- 600]: loss = 0.557135 * 100, metric = 8.79% * 100;
 Minibatch[ 601- 700]: loss = 0.575675 * 100, metric = 9.28% * 100;
 Minibatch[ 701- 800]: loss = 0.550690 * 100, metric = 8.76% * 100;
 Minibatch[ 801- 900]: loss = 0.589671 * 100, metric = 9.70% * 100;
 Minibatch[ 901-1000]: loss = 0.560508 * 100, metric = 8.70% * 100;
 Minibatch[1001-1100]: loss = 0.579651 * 100, metric = 9.24% * 100;
 Minibatch[1101-1200]: loss = 0.565427 * 100, metric = 9.19% * 100;
 Minibatch[1201-1300]: loss = 0.567740 * 100, metric = 9.10% * 100;
 Minibatch[1301-1400]: loss = 0.554260 * 100, metric = 8.82% * 100;
 Minibatch[1401-1500]: loss = 0.568342 * 100, metric = 9.31% * 100;
 Minibatch[1501-1600]: loss = 0.569554 * 100, metric = 9.13% * 100;
 Minibatch[1601-1700]: loss = 0.555066 * 100, metric = 8.97% * 100;
 Minibatch[1701-1800]: loss = 0.545790 * 100, metric = 8.50% * 100;
 Minibatch[1801-1900]: loss = 0.550605 * 100, metric = 8.64% * 100;
 Minibatch[1901-2000]: loss = 0.543578 * 100, metric = 8.51% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.564715 * 2000, metric = 9.03% * 2000 927.147s (  2.2 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 16.13% * 2000;
 Minibatch[   1- 100]: loss = 0.560989 * 100, metric = 8.73% * 100;
 Minibatch[ 101- 200]: loss = 0.559678 * 100, metric = 8.72% * 100;
 Minibatch[ 201- 300]: loss = 0.560376 * 100, metric = 8.71% * 100;
 Minibatch[ 301- 400]: loss = 0.571704 * 100, metric = 9.07% * 100;
 Minibatch[ 401- 500]: loss = 0.561794 * 100, metric = 8.77% * 100;
 Minibatch[ 501- 600]: loss = 0.565755 * 100, metric = 9.11% * 100;
 Minibatch[ 601- 700]: loss = 0.576896 * 100, metric = 9.58% * 100;
 Minibatch[ 701- 800]: loss = 0.572193 * 100, metric = 9.08% * 100;
 Minibatch[ 801- 900]: loss = 0.571530 * 100, metric = 9.12% * 100;
 Minibatch[ 901-1000]: loss = 0.576240 * 100, metric = 9.36% * 100;
 Minibatch[1001-1100]: loss = 0.548398 * 100, metric = 8.76% * 100;
 Minibatch[1101-1200]: loss = 0.564043 * 100, metric = 9.08% * 100;
 Minibatch[1201-1300]: loss = 0.566326 * 100, metric = 9.22% * 100;
 Minibatch[1301-1400]: loss = 0.570356 * 100, metric = 9.32% * 100;
 Minibatch[1401-1500]: loss = 0.558177 * 100, metric = 9.10% * 100;
 Minibatch[1501-1600]: loss = 0.577285 * 100, metric = 9.41% * 100;
 Minibatch[1601-1700]: loss = 0.561111 * 100, metric = 9.03% * 100;
 Minibatch[1701-1800]: loss = 0.573152 * 100, metric = 9.41% * 100;
 Minibatch[1801-1900]: loss = 0.561573 * 100, metric = 9.20% * 100;
 Minibatch[1901-2000]: loss = 0.556045 * 100, metric = 8.98% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.565681 * 2000, metric = 9.09% * 2000 929.011s (  2.2 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 16.03% * 2000;
0.6732842358052731
 Minibatch[   1- 100]: loss = 0.569785 * 100, metric = 9.09% * 100;
 Minibatch[ 101- 200]: loss = 0.564343 * 100, metric = 9.03% * 100;
 Minibatch[ 201- 300]: loss = 0.556269 * 100, metric = 8.89% * 100;
 Minibatch[ 301- 400]: loss = 0.568163 * 100, metric = 9.17% * 100;
 Minibatch[ 401- 500]: loss = 0.550018 * 100, metric = 8.62% * 100;
 Minibatch[ 501- 600]: loss = 0.541939 * 100, metric = 8.47% * 100;
 Minibatch[ 601- 700]: loss = 0.545092 * 100, metric = 8.48% * 100;
 Minibatch[ 701- 800]: loss = 0.516509 * 100, metric = 8.06% * 100;
 Minibatch[ 801- 900]: loss = 0.556236 * 100, metric = 8.68% * 100;
 Minibatch[ 901-1000]: loss = 0.541609 * 100, metric = 8.63% * 100;
 Minibatch[1001-1100]: loss = 0.555697 * 100, metric = 8.92% * 100;
 Minibatch[1101-1200]: loss = 0.535759 * 100, metric = 8.35% * 100;
 Minibatch[1201-1300]: loss = 0.554960 * 100, metric = 8.61% * 100;
 Minibatch[1301-1400]: loss = 0.538960 * 100, metric = 8.33% * 100;
 Minibatch[1401-1500]: loss = 0.556351 * 100, metric = 8.71% * 100;
 Minibatch[1501-1600]: loss = 0.559769 * 100, metric = 9.34% * 100;
 Minibatch[1601-1700]: loss = 0.548381 * 100, metric = 8.73% * 100;
 Minibatch[1701-1800]: loss = 0.547601 * 100, metric = 8.57% * 100;
 Minibatch[1801-1900]: loss = 0.558277 * 100, metric = 8.94% * 100;
 Minibatch[1901-2000]: loss = 0.533384 * 100, metric = 8.36% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.549955 * 2000, metric = 8.70% * 2000 916.290s (  2.2 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 14.95% * 2000;
0.6601777414008975
 Minibatch[   1- 100]: loss = 0.549275 * 100, metric = 8.60% * 100;
 Minibatch[ 101- 200]: loss = 0.549238 * 100, metric = 8.62% * 100;
 Minibatch[ 201- 300]: loss = 0.558906 * 100, metric = 9.01% * 100;
 Minibatch[ 301- 400]: loss = 0.546895 * 100, metric = 8.64% * 100;
 Minibatch[ 401- 500]: loss = 0.548669 * 100, metric = 8.66% * 100;
 Minibatch[ 501- 600]: loss = 0.561117 * 100, metric = 8.94% * 100;
 Minibatch[ 601- 700]: loss = 0.542095 * 100, metric = 8.55% * 100;
 Minibatch[ 701- 800]: loss = 0.538107 * 100, metric = 8.54% * 100;
 Minibatch[ 801- 900]: loss = 0.548625 * 100, metric = 8.70% * 100;
 Minibatch[ 901-1000]: loss = 0.558147 * 100, metric = 8.89% * 100;
 Minibatch[1001-1100]: loss = 0.524031 * 100, metric = 8.06% * 100;
 Minibatch[1101-1200]: loss = 0.522449 * 100, metric = 8.23% * 100;
 Minibatch[1201-1300]: loss = 0.538907 * 100, metric = 8.51% * 100;
 Minibatch[1301-1400]: loss = 0.542036 * 100, metric = 8.54% * 100;
 Minibatch[1401-1500]: loss = 0.532526 * 100, metric = 8.27% * 100;
 Minibatch[1501-1600]: loss = 0.535897 * 100, metric = 8.35% * 100;
 Minibatch[1601-1700]: loss = 0.536682 * 100, metric = 8.48% * 100;
 Minibatch[1701-1800]: loss = 0.534196 * 100, metric = 8.38% * 100;
 Minibatch[1801-1900]: loss = 0.532435 * 100, metric = 8.29% * 100;
 Minibatch[1901-2000]: loss = 0.538684 * 100, metric = 8.36% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.541946 * 2000, metric = 8.53% * 2000 910.724s (  2.2 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 16.53% * 2000;
 Minibatch[   1- 100]: loss = 0.553568 * 100, metric = 8.68% * 100;
 Minibatch[ 101- 200]: loss = 0.544224 * 100, metric = 8.72% * 100;
 Minibatch[ 201- 300]: loss = 0.543954 * 100, metric = 8.49% * 100;
 Minibatch[ 301- 400]: loss = 0.550216 * 100, metric = 8.62% * 100;
 Minibatch[ 401- 500]: loss = 0.552388 * 100, metric = 8.71% * 100;
 Minibatch[ 501- 600]: loss = 0.539366 * 100, metric = 8.54% * 100;
 Minibatch[ 601- 700]: loss = 0.546550 * 100, metric = 8.46% * 100;
 Minibatch[ 701- 800]: loss = 0.522457 * 100, metric = 8.07% * 100;
 Minibatch[ 801- 900]: loss = 0.514225 * 100, metric = 7.98% * 100;
 Minibatch[ 901-1000]: loss = 0.541743 * 100, metric = 8.57% * 100;
 Minibatch[1001-1100]: loss = 0.533215 * 100, metric = 8.21% * 100;
 Minibatch[1101-1200]: loss = 0.538206 * 100, metric = 8.57% * 100;
 Minibatch[1201-1300]: loss = 0.542257 * 100, metric = 8.59% * 100;
 Minibatch[1301-1400]: loss = 0.543282 * 100, metric = 8.67% * 100;
 Minibatch[1401-1500]: loss = 0.516868 * 100, metric = 8.13% * 100;
 Minibatch[1501-1600]: loss = 0.535901 * 100, metric = 8.35% * 100;
 Minibatch[1601-1700]: loss = 0.531012 * 100, metric = 8.51% * 100;
 Minibatch[1701-1800]: loss = 0.537424 * 100, metric = 8.61% * 100;
 Minibatch[1801-1900]: loss = 0.530905 * 100, metric = 8.66% * 100;
 Minibatch[1901-2000]: loss = 0.535037 * 100, metric = 8.36% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.537640 * 2000, metric = 8.47% * 2000 904.993s (  2.2 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 16.18% * 2000;
 Minibatch[   1- 100]: loss = 0.515744 * 100, metric = 8.12% * 100;
 Minibatch[ 101- 200]: loss = 0.536996 * 100, metric = 8.49% * 100;
 Minibatch[ 201- 300]: loss = 0.526614 * 100, metric = 8.32% * 100;
 Minibatch[ 301- 400]: loss = 0.527879 * 100, metric = 8.22% * 100;
 Minibatch[ 401- 500]: loss = 0.529906 * 100, metric = 8.26% * 100;
 Minibatch[ 501- 600]: loss = 0.519530 * 100, metric = 8.26% * 100;
 Minibatch[ 601- 700]: loss = 0.536396 * 100, metric = 8.46% * 100;
 Minibatch[ 701- 800]: loss = 0.530477 * 100, metric = 8.45% * 100;
 Minibatch[ 801- 900]: loss = 0.539068 * 100, metric = 8.66% * 100;
 Minibatch[ 901-1000]: loss = 0.529383 * 100, metric = 8.42% * 100;
 Minibatch[1001-1100]: loss = 0.533979 * 100, metric = 8.48% * 100;
 Minibatch[1101-1200]: loss = 0.548505 * 100, metric = 8.81% * 100;
 Minibatch[1201-1300]: loss = 0.533770 * 100, metric = 8.42% * 100;
 Minibatch[1301-1400]: loss = 0.522385 * 100, metric = 7.94% * 100;
 Minibatch[1401-1500]: loss = 0.525153 * 100, metric = 8.10% * 100;
 Minibatch[1501-1600]: loss = 0.544980 * 100, metric = 8.67% * 100;
 Minibatch[1601-1700]: loss = 0.516899 * 100, metric = 7.95% * 100;
 Minibatch[1701-1800]: loss = 0.524586 * 100, metric = 8.19% * 100;
 Minibatch[1801-1900]: loss = 0.526233 * 100, metric = 8.21% * 100;
 Minibatch[1901-2000]: loss = 0.534418 * 100, metric = 8.35% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.530145 * 2000, metric = 8.34% * 2000 906.158s (  2.2 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 16.71% * 2000;
 Minibatch[   1- 100]: loss = 0.537357 * 100, metric = 8.53% * 100;
 Minibatch[ 101- 200]: loss = 0.524644 * 100, metric = 8.33% * 100;
 Minibatch[ 201- 300]: loss = 0.526308 * 100, metric = 8.59% * 100;
 Minibatch[ 301- 400]: loss = 0.530220 * 100, metric = 8.42% * 100;
 Minibatch[ 401- 500]: loss = 0.526209 * 100, metric = 8.10% * 100;
 Minibatch[ 501- 600]: loss = 0.524754 * 100, metric = 8.16% * 100;
 Minibatch[ 601- 700]: loss = 0.527496 * 100, metric = 8.22% * 100;
 Minibatch[ 701- 800]: loss = 0.510358 * 100, metric = 7.80% * 100;
 Minibatch[ 801- 900]: loss = 0.519279 * 100, metric = 8.17% * 100;
 Minibatch[ 901-1000]: loss = 0.525484 * 100, metric = 8.10% * 100;
 Minibatch[1001-1100]: loss = 0.524164 * 100, metric = 8.30% * 100;
 Minibatch[1101-1200]: loss = 0.535771 * 100, metric = 8.53% * 100;
 Minibatch[1201-1300]: loss = 0.546850 * 100, metric = 8.82% * 100;
 Minibatch[1301-1400]: loss = 0.524415 * 100, metric = 8.16% * 100;
 Minibatch[1401-1500]: loss = 0.517872 * 100, metric = 7.82% * 100;
 Minibatch[1501-1600]: loss = 0.539510 * 100, metric = 8.66% * 100;
 Minibatch[1601-1700]: loss = 0.527376 * 100, metric = 8.29% * 100;
 Minibatch[1701-1800]: loss = 0.527527 * 100, metric = 8.22% * 100;
 Minibatch[1801-1900]: loss = 0.516746 * 100, metric = 8.15% * 100;
 Minibatch[1901-2000]: loss = 0.511148 * 100, metric = 7.80% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.526174 * 2000, metric = 8.26% * 2000 901.064s (  2.2 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 15.08% * 2000;
 Minibatch[   1- 100]: loss = 0.523315 * 100, metric = 8.29% * 100;
 Minibatch[ 101- 200]: loss = 0.506585 * 100, metric = 7.72% * 100;
 Minibatch[ 201- 300]: loss = 0.514503 * 100, metric = 7.99% * 100;
 Minibatch[ 301- 400]: loss = 0.510250 * 100, metric = 7.60% * 100;
 Minibatch[ 401- 500]: loss = 0.522592 * 100, metric = 8.19% * 100;
 Minibatch[ 501- 600]: loss = 0.516775 * 100, metric = 7.84% * 100;
 Minibatch[ 601- 700]: loss = 0.536620 * 100, metric = 8.45% * 100;
 Minibatch[ 701- 800]: loss = 0.514064 * 100, metric = 8.12% * 100;
 Minibatch[ 801- 900]: loss = 0.509381 * 100, metric = 7.83% * 100;
 Minibatch[ 901-1000]: loss = 0.507413 * 100, metric = 7.81% * 100;
 Minibatch[1001-1100]: loss = 0.526910 * 100, metric = 8.27% * 100;
 Minibatch[1101-1200]: loss = 0.532386 * 100, metric = 8.49% * 100;
 Minibatch[1201-1300]: loss = 0.510877 * 100, metric = 7.87% * 100;
 Minibatch[1301-1400]: loss = 0.505468 * 100, metric = 7.74% * 100;
 Minibatch[1401-1500]: loss = 0.517227 * 100, metric = 8.22% * 100;
 Minibatch[1501-1600]: loss = 0.510095 * 100, metric = 7.68% * 100;
 Minibatch[1601-1700]: loss = 0.535668 * 100, metric = 8.46% * 100;
 Minibatch[1701-1800]: loss = 0.530034 * 100, metric = 8.36% * 100;
 Minibatch[1801-1900]: loss = 0.522794 * 100, metric = 8.08% * 100;
 Minibatch[1901-2000]: loss = 0.524033 * 100, metric = 8.16% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.518849 * 2000, metric = 8.06% * 2000 892.384s (  2.2 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 16.10% * 2000;
 Minibatch[   1- 100]: loss = 0.520090 * 100, metric = 8.04% * 100;
 Minibatch[ 101- 200]: loss = 0.526377 * 100, metric = 8.16% * 100;
 Minibatch[ 201- 300]: loss = 0.507751 * 100, metric = 7.92% * 100;
 Minibatch[ 301- 400]: loss = 0.507681 * 100, metric = 7.93% * 100;
 Minibatch[ 401- 500]: loss = 0.521971 * 100, metric = 8.11% * 100;
 Minibatch[ 501- 600]: loss = 0.510615 * 100, metric = 8.27% * 100;
 Minibatch[ 601- 700]: loss = 0.507977 * 100, metric = 7.88% * 100;
 Minibatch[ 701- 800]: loss = 0.519506 * 100, metric = 8.09% * 100;
 Minibatch[ 801- 900]: loss = 0.519979 * 100, metric = 8.10% * 100;
 Minibatch[ 901-1000]: loss = 0.514431 * 100, metric = 8.19% * 100;
 Minibatch[1001-1100]: loss = 0.508830 * 100, metric = 7.92% * 100;
 Minibatch[1101-1200]: loss = 0.520910 * 100, metric = 8.08% * 100;
 Minibatch[1201-1300]: loss = 0.501993 * 100, metric = 7.62% * 100;
 Minibatch[1301-1400]: loss = 0.525893 * 100, metric = 8.44% * 100;
 Minibatch[1401-1500]: loss = 0.502537 * 100, metric = 7.65% * 100;
 Minibatch[1501-1600]: loss = 0.515162 * 100, metric = 7.67% * 100;
 Minibatch[1601-1700]: loss = 0.488408 * 100, metric = 7.41% * 100;
 Minibatch[1701-1800]: loss = 0.504359 * 100, metric = 7.58% * 100;
 Minibatch[1801-1900]: loss = 0.508289 * 100, metric = 8.03% * 100;
 Minibatch[1901-2000]: loss = 0.508369 * 100, metric = 7.81% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.512056 * 2000, metric = 7.94% * 2000 893.081s (  2.2 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 14.92% * 2000;
 Minibatch[   1- 100]: loss = 0.514310 * 100, metric = 8.28% * 100;
 Minibatch[ 101- 200]: loss = 0.497728 * 100, metric = 7.44% * 100;
 Minibatch[ 201- 300]: loss = 0.508960 * 100, metric = 8.00% * 100;
 Minibatch[ 301- 400]: loss = 0.513992 * 100, metric = 7.87% * 100;
 Minibatch[ 401- 500]: loss = 0.511681 * 100, metric = 7.88% * 100;
 Minibatch[ 501- 600]: loss = 0.526241 * 100, metric = 8.45% * 100;
 Minibatch[ 601- 700]: loss = 0.503957 * 100, metric = 7.65% * 100;
 Minibatch[ 701- 800]: loss = 0.500745 * 100, metric = 7.74% * 100;
 Minibatch[ 801- 900]: loss = 0.515084 * 100, metric = 8.10% * 100;
 Minibatch[ 901-1000]: loss = 0.522110 * 100, metric = 8.41% * 100;
 Minibatch[1001-1100]: loss = 0.519655 * 100, metric = 8.11% * 100;
 Minibatch[1101-1200]: loss = 0.509127 * 100, metric = 7.83% * 100;
 Minibatch[1201-1300]: loss = 0.518137 * 100, metric = 8.12% * 100;
 Minibatch[1301-1400]: loss = 0.504541 * 100, metric = 7.76% * 100;
 Minibatch[1401-1500]: loss = 0.512761 * 100, metric = 8.05% * 100;
 Minibatch[1501-1600]: loss = 0.504529 * 100, metric = 7.60% * 100;
 Minibatch[1601-1700]: loss = 0.512184 * 100, metric = 7.88% * 100;
 Minibatch[1701-1800]: loss = 0.502411 * 100, metric = 7.70% * 100;
 Minibatch[1801-1900]: loss = 0.502794 * 100, metric = 7.68% * 100;
 Minibatch[1901-2000]: loss = 0.508030 * 100, metric = 7.82% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.510449 * 2000, metric = 7.92% * 2000 903.642s (  2.2 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 14.23% * 2000;
0.649583510607481
 Minibatch[   1- 100]: loss = 0.493028 * 100, metric = 7.53% * 100;
 Minibatch[ 101- 200]: loss = 0.500042 * 100, metric = 7.99% * 100;
 Minibatch[ 201- 300]: loss = 0.507495 * 100, metric = 8.12% * 100;
 Minibatch[ 301- 400]: loss = 0.526747 * 100, metric = 8.22% * 100;
 Minibatch[ 401- 500]: loss = 0.493523 * 100, metric = 7.33% * 100;
 Minibatch[ 501- 600]: loss = 0.510199 * 100, metric = 7.65% * 100;
 Minibatch[ 601- 700]: loss = 0.495920 * 100, metric = 7.73% * 100;
 Minibatch[ 701- 800]: loss = 0.508596 * 100, metric = 8.18% * 100;
 Minibatch[ 801- 900]: loss = 0.504251 * 100, metric = 7.75% * 100;
 Minibatch[ 901-1000]: loss = 0.511369 * 100, metric = 7.97% * 100;
 Minibatch[1001-1100]: loss = 0.503613 * 100, metric = 7.83% * 100;
 Minibatch[1101-1200]: loss = 0.500314 * 100, metric = 7.67% * 100;
 Minibatch[1201-1300]: loss = 0.507554 * 100, metric = 7.88% * 100;
 Minibatch[1301-1400]: loss = 0.490897 * 100, metric = 7.55% * 100;
 Minibatch[1401-1500]: loss = 0.520063 * 100, metric = 8.14% * 100;
 Minibatch[1501-1600]: loss = 0.491192 * 100, metric = 7.42% * 100;
 Minibatch[1601-1700]: loss = 0.518156 * 100, metric = 8.10% * 100;
 Minibatch[1701-1800]: loss = 0.496237 * 100, metric = 7.66% * 100;
 Minibatch[1801-1900]: loss = 0.517683 * 100, metric = 8.08% * 100;
 Minibatch[1901-2000]: loss = 0.505433 * 100, metric = 7.79% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.505116 * 2000, metric = 7.83% * 2000 927.745s (  2.2 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 15.76% * 2000;
 Minibatch[   1- 100]: loss = 0.522669 * 100, metric = 8.16% * 100;
 Minibatch[ 101- 200]: loss = 0.482949 * 100, metric = 7.25% * 100;
 Minibatch[ 201- 300]: loss = 0.488455 * 100, metric = 7.51% * 100;
 Minibatch[ 301- 400]: loss = 0.509545 * 100, metric = 7.92% * 100;
 Minibatch[ 401- 500]: loss = 0.499998 * 100, metric = 7.70% * 100;
 Minibatch[ 501- 600]: loss = 0.483675 * 100, metric = 7.14% * 100;
 Minibatch[ 601- 700]: loss = 0.506535 * 100, metric = 8.04% * 100;
 Minibatch[ 701- 800]: loss = 0.496574 * 100, metric = 7.38% * 100;
 Minibatch[ 801- 900]: loss = 0.505399 * 100, metric = 7.92% * 100;
 Minibatch[ 901-1000]: loss = 0.488894 * 100, metric = 7.58% * 100;
 Minibatch[1001-1100]: loss = 0.502274 * 100, metric = 7.44% * 100;
 Minibatch[1101-1200]: loss = 0.512753 * 100, metric = 8.02% * 100;
 Minibatch[1201-1300]: loss = 0.496199 * 100, metric = 7.63% * 100;
 Minibatch[1301-1400]: loss = 0.499263 * 100, metric = 7.76% * 100;
 Minibatch[1401-1500]: loss = 0.498141 * 100, metric = 7.59% * 100;
 Minibatch[1501-1600]: loss = 0.510881 * 100, metric = 7.97% * 100;
 Minibatch[1601-1700]: loss = 0.505253 * 100, metric = 7.74% * 100;
 Minibatch[1701-1800]: loss = 0.501705 * 100, metric = 7.76% * 100;
 Minibatch[1801-1900]: loss = 0.495308 * 100, metric = 7.65% * 100;
 Minibatch[1901-2000]: loss = 0.512971 * 100, metric = 8.11% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.500972 * 2000, metric = 7.71% * 2000 879.454s (  2.3 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 15.78% * 2000;
 Minibatch[   1- 100]: loss = 0.497277 * 100, metric = 7.68% * 100;
 Minibatch[ 101- 200]: loss = 0.516661 * 100, metric = 8.49% * 100;
 Minibatch[ 201- 300]: loss = 0.495351 * 100, metric = 7.73% * 100;
 Minibatch[ 301- 400]: loss = 0.496725 * 100, metric = 7.64% * 100;
 Minibatch[ 401- 500]: loss = 0.493196 * 100, metric = 7.64% * 100;
 Minibatch[ 501- 600]: loss = 0.492851 * 100, metric = 7.53% * 100;
 Minibatch[ 601- 700]: loss = 0.509763 * 100, metric = 7.90% * 100;
 Minibatch[ 701- 800]: loss = 0.499208 * 100, metric = 7.72% * 100;
 Minibatch[ 801- 900]: loss = 0.499737 * 100, metric = 7.66% * 100;
 Minibatch[ 901-1000]: loss = 0.484202 * 100, metric = 7.32% * 100;
 Minibatch[1001-1100]: loss = 0.483074 * 100, metric = 7.32% * 100;
 Minibatch[1101-1200]: loss = 0.499703 * 100, metric = 7.93% * 100;
 Minibatch[1201-1300]: loss = 0.493116 * 100, metric = 7.73% * 100;
 Minibatch[1301-1400]: loss = 0.496303 * 100, metric = 7.80% * 100;
 Minibatch[1401-1500]: loss = 0.496706 * 100, metric = 7.85% * 100;
 Minibatch[1501-1600]: loss = 0.478901 * 100, metric = 7.37% * 100;
 Minibatch[1601-1700]: loss = 0.496215 * 100, metric = 7.40% * 100;
 Minibatch[1701-1800]: loss = 0.490256 * 100, metric = 7.73% * 100;
 Minibatch[1801-1900]: loss = 0.501772 * 100, metric = 7.70% * 100;
 Minibatch[1901-2000]: loss = 0.497072 * 100, metric = 7.86% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.495904 * 2000, metric = 7.70% * 2000 968.919s (  2.1 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 14.40% * 2000;
 Minibatch[   1- 100]: loss = 0.493697 * 100, metric = 7.59% * 100;
 Minibatch[ 101- 200]: loss = 0.493341 * 100, metric = 7.51% * 100;
 Minibatch[ 201- 300]: loss = 0.497168 * 100, metric = 7.79% * 100;
 Minibatch[ 301- 400]: loss = 0.499641 * 100, metric = 7.71% * 100;
 Minibatch[ 401- 500]: loss = 0.493075 * 100, metric = 7.74% * 100;
 Minibatch[ 501- 600]: loss = 0.488435 * 100, metric = 7.56% * 100;
 Minibatch[ 601- 700]: loss = 0.491566 * 100, metric = 7.53% * 100;
 Minibatch[ 701- 800]: loss = 0.482273 * 100, metric = 7.23% * 100;
 Minibatch[ 801- 900]: loss = 0.483040 * 100, metric = 7.44% * 100;
 Minibatch[ 901-1000]: loss = 0.483225 * 100, metric = 7.30% * 100;
 Minibatch[1001-1100]: loss = 0.479361 * 100, metric = 7.13% * 100;
 Minibatch[1101-1200]: loss = 0.494927 * 100, metric = 7.71% * 100;
 Minibatch[1201-1300]: loss = 0.496835 * 100, metric = 7.75% * 100;
 Minibatch[1301-1400]: loss = 0.492705 * 100, metric = 7.69% * 100;
 Minibatch[1401-1500]: loss = 0.490186 * 100, metric = 7.73% * 100;
 Minibatch[1501-1600]: loss = 0.485967 * 100, metric = 7.58% * 100;
 Minibatch[1601-1700]: loss = 0.476755 * 100, metric = 7.23% * 100;
 Minibatch[1701-1800]: loss = 0.500027 * 100, metric = 7.75% * 100;
 Minibatch[1801-1900]: loss = 0.483518 * 100, metric = 7.24% * 100;
 Minibatch[1901-2000]: loss = 0.491608 * 100, metric = 7.69% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.489867 * 2000, metric = 7.55% * 2000 973.053s (  2.1 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 14.63% * 2000;
 Minibatch[   1- 100]: loss = 0.505964 * 100, metric = 7.96% * 100;
 Minibatch[ 101- 200]: loss = 0.483751 * 100, metric = 7.53% * 100;
 Minibatch[ 201- 300]: loss = 0.480217 * 100, metric = 7.49% * 100;
 Minibatch[ 301- 400]: loss = 0.490383 * 100, metric = 7.70% * 100;
 Minibatch[ 401- 500]: loss = 0.482905 * 100, metric = 7.42% * 100;
 Minibatch[ 501- 600]: loss = 0.497497 * 100, metric = 7.54% * 100;
 Minibatch[ 601- 700]: loss = 0.491518 * 100, metric = 7.67% * 100;
 Minibatch[ 701- 800]: loss = 0.485901 * 100, metric = 7.55% * 100;
 Minibatch[ 801- 900]: loss = 0.483536 * 100, metric = 7.28% * 100;
 Minibatch[ 901-1000]: loss = 0.474493 * 100, metric = 7.12% * 100;
 Minibatch[1001-1100]: loss = 0.482657 * 100, metric = 7.54% * 100;
 Minibatch[1101-1200]: loss = 0.467003 * 100, metric = 7.10% * 100;
 Minibatch[1201-1300]: loss = 0.489713 * 100, metric = 7.60% * 100;
 Minibatch[1301-1400]: loss = 0.467236 * 100, metric = 6.90% * 100;
 Minibatch[1401-1500]: loss = 0.498467 * 100, metric = 7.79% * 100;
 Minibatch[1501-1600]: loss = 0.500177 * 100, metric = 7.70% * 100;
 Minibatch[1601-1700]: loss = 0.489398 * 100, metric = 7.38% * 100;
 Minibatch[1701-1800]: loss = 0.481957 * 100, metric = 7.31% * 100;
 Minibatch[1801-1900]: loss = 0.481420 * 100, metric = 7.24% * 100;
 Minibatch[1901-2000]: loss = 0.492942 * 100, metric = 7.96% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.486357 * 2000, metric = 7.49% * 2000 999.485s (  2.0 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 14.64% * 2000;
 Minibatch[   1- 100]: loss = 0.479819 * 100, metric = 7.42% * 100;
 Minibatch[ 101- 200]: loss = 0.484078 * 100, metric = 7.51% * 100;
 Minibatch[ 201- 300]: loss = 0.464445 * 100, metric = 7.12% * 100;
 Minibatch[ 301- 400]: loss = 0.482737 * 100, metric = 7.44% * 100;
 Minibatch[ 401- 500]: loss = 0.470978 * 100, metric = 7.18% * 100;
 Minibatch[ 501- 600]: loss = 0.479726 * 100, metric = 7.31% * 100;
 Minibatch[ 601- 700]: loss = 0.486221 * 100, metric = 7.44% * 100;
 Minibatch[ 701- 800]: loss = 0.481104 * 100, metric = 7.31% * 100;
 Minibatch[ 801- 900]: loss = 0.461594 * 100, metric = 6.69% * 100;
 Minibatch[ 901-1000]: loss = 0.471342 * 100, metric = 7.42% * 100;
 Minibatch[1001-1100]: loss = 0.476796 * 100, metric = 7.44% * 100;
 Minibatch[1101-1200]: loss = 0.469309 * 100, metric = 7.30% * 100;
 Minibatch[1201-1300]: loss = 0.481796 * 100, metric = 7.37% * 100;
 Minibatch[1301-1400]: loss = 0.480423 * 100, metric = 7.36% * 100;
 Minibatch[1401-1500]: loss = 0.484211 * 100, metric = 7.69% * 100;
 Minibatch[1501-1600]: loss = 0.486686 * 100, metric = 7.43% * 100;
 Minibatch[1601-1700]: loss = 0.497259 * 100, metric = 7.91% * 100;
 Minibatch[1701-1800]: loss = 0.485022 * 100, metric = 7.66% * 100;
 Minibatch[1801-1900]: loss = 0.482195 * 100, metric = 7.49% * 100;
 Minibatch[1901-2000]: loss = 0.480172 * 100, metric = 7.33% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.479296 * 2000, metric = 7.39% * 2000 1000.214s (  2.0 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.58% * 2000;
 Minibatch[   1- 100]: loss = 0.458096 * 100, metric = 6.70% * 100;
 Minibatch[ 101- 200]: loss = 0.478149 * 100, metric = 7.24% * 100;
 Minibatch[ 201- 300]: loss = 0.471594 * 100, metric = 7.11% * 100;
 Minibatch[ 301- 400]: loss = 0.462316 * 100, metric = 6.76% * 100;
 Minibatch[ 401- 500]: loss = 0.467608 * 100, metric = 6.84% * 100;
 Minibatch[ 501- 600]: loss = 0.442646 * 100, metric = 6.48% * 100;
 Minibatch[ 601- 700]: loss = 0.485909 * 100, metric = 7.40% * 100;
 Minibatch[ 701- 800]: loss = 0.450470 * 100, metric = 6.96% * 100;
 Minibatch[ 801- 900]: loss = 0.481504 * 100, metric = 7.48% * 100;
 Minibatch[ 901-1000]: loss = 0.460330 * 100, metric = 6.97% * 100;
 Minibatch[1001-1100]: loss = 0.481543 * 100, metric = 7.45% * 100;
 Minibatch[1101-1200]: loss = 0.460611 * 100, metric = 6.90% * 100;
 Minibatch[1201-1300]: loss = 0.471038 * 100, metric = 7.33% * 100;
 Minibatch[1301-1400]: loss = 0.477417 * 100, metric = 7.34% * 100;
 Minibatch[1401-1500]: loss = 0.472781 * 100, metric = 6.91% * 100;
 Minibatch[1501-1600]: loss = 0.475493 * 100, metric = 7.16% * 100;
 Minibatch[1601-1700]: loss = 0.468180 * 100, metric = 7.23% * 100;
 Minibatch[1701-1800]: loss = 0.468071 * 100, metric = 7.08% * 100;
 Minibatch[1801-1900]: loss = 0.472817 * 100, metric = 7.41% * 100;
 Minibatch[1901-2000]: loss = 0.465725 * 100, metric = 6.86% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.468615 * 2000, metric = 7.08% * 2000 913.482s (  2.2 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 14.49% * 2000;
 Minibatch[   1- 100]: loss = 0.463197 * 100, metric = 6.93% * 100;
 Minibatch[ 101- 200]: loss = 0.449274 * 100, metric = 6.57% * 100;
 Minibatch[ 201- 300]: loss = 0.475903 * 100, metric = 7.34% * 100;
 Minibatch[ 301- 400]: loss = 0.460668 * 100, metric = 7.02% * 100;
 Minibatch[ 401- 500]: loss = 0.459590 * 100, metric = 6.88% * 100;
 Minibatch[ 501- 600]: loss = 0.465636 * 100, metric = 7.09% * 100;
 Minibatch[ 601- 700]: loss = 0.470155 * 100, metric = 6.90% * 100;
 Minibatch[ 701- 800]: loss = 0.446250 * 100, metric = 6.67% * 100;
 Minibatch[ 801- 900]: loss = 0.448936 * 100, metric = 6.70% * 100;
 Minibatch[ 901-1000]: loss = 0.471362 * 100, metric = 7.09% * 100;
 Minibatch[1001-1100]: loss = 0.471726 * 100, metric = 7.21% * 100;
 Minibatch[1101-1200]: loss = 0.457301 * 100, metric = 6.86% * 100;
 Minibatch[1201-1300]: loss = 0.466044 * 100, metric = 7.41% * 100;
 Minibatch[1301-1400]: loss = 0.447119 * 100, metric = 6.75% * 100;
 Minibatch[1401-1500]: loss = 0.450963 * 100, metric = 6.88% * 100;
 Minibatch[1501-1600]: loss = 0.459622 * 100, metric = 7.02% * 100;
 Minibatch[1601-1700]: loss = 0.471634 * 100, metric = 7.19% * 100;
 Minibatch[1701-1800]: loss = 0.462671 * 100, metric = 7.14% * 100;
 Minibatch[1801-1900]: loss = 0.464152 * 100, metric = 6.79% * 100;
 Minibatch[1901-2000]: loss = 0.460338 * 100, metric = 6.82% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.461127 * 2000, metric = 6.96% * 2000 821.445s (  2.4 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 14.25% * 2000;
 Minibatch[   1- 100]: loss = 0.468991 * 100, metric = 6.96% * 100;
 Minibatch[ 101- 200]: loss = 0.469457 * 100, metric = 7.22% * 100;
 Minibatch[ 201- 300]: loss = 0.457403 * 100, metric = 6.98% * 100;
 Minibatch[ 301- 400]: loss = 0.468532 * 100, metric = 7.13% * 100;
 Minibatch[ 401- 500]: loss = 0.460210 * 100, metric = 7.22% * 100;
 Minibatch[ 501- 600]: loss = 0.455393 * 100, metric = 6.94% * 100;
 Minibatch[ 601- 700]: loss = 0.468467 * 100, metric = 7.15% * 100;
 Minibatch[ 701- 800]: loss = 0.474928 * 100, metric = 7.32% * 100;
 Minibatch[ 801- 900]: loss = 0.469090 * 100, metric = 7.01% * 100;
 Minibatch[ 901-1000]: loss = 0.453848 * 100, metric = 6.61% * 100;
 Minibatch[1001-1100]: loss = 0.455040 * 100, metric = 6.89% * 100;
 Minibatch[1101-1200]: loss = 0.480922 * 100, metric = 7.60% * 100;
 Minibatch[1201-1300]: loss = 0.478076 * 100, metric = 7.49% * 100;
 Minibatch[1301-1400]: loss = 0.464496 * 100, metric = 6.82% * 100;
 Minibatch[1401-1500]: loss = 0.473231 * 100, metric = 7.42% * 100;
 Minibatch[1501-1600]: loss = 0.452266 * 100, metric = 6.86% * 100;
 Minibatch[1601-1700]: loss = 0.467427 * 100, metric = 7.26% * 100;
 Minibatch[1701-1800]: loss = 0.458929 * 100, metric = 6.81% * 100;
 Minibatch[1801-1900]: loss = 0.467815 * 100, metric = 7.35% * 100;
 Minibatch[1901-2000]: loss = 0.461321 * 100, metric = 6.99% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.465292 * 2000, metric = 7.10% * 2000 799.675s (  2.5 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.72% * 2000;
 Minibatch[   1- 100]: loss = 0.469019 * 100, metric = 7.20% * 100;
 Minibatch[ 101- 200]: loss = 0.465201 * 100, metric = 7.15% * 100;
 Minibatch[ 201- 300]: loss = 0.446385 * 100, metric = 6.46% * 100;
 Minibatch[ 301- 400]: loss = 0.446395 * 100, metric = 6.87% * 100;
 Minibatch[ 401- 500]: loss = 0.460278 * 100, metric = 6.89% * 100;
 Minibatch[ 501- 600]: loss = 0.452699 * 100, metric = 6.89% * 100;
 Minibatch[ 601- 700]: loss = 0.458633 * 100, metric = 7.02% * 100;
 Minibatch[ 701- 800]: loss = 0.454095 * 100, metric = 6.83% * 100;
 Minibatch[ 801- 900]: loss = 0.462177 * 100, metric = 6.93% * 100;
 Minibatch[ 901-1000]: loss = 0.459080 * 100, metric = 6.76% * 100;
 Minibatch[1001-1100]: loss = 0.464535 * 100, metric = 7.15% * 100;
 Minibatch[1101-1200]: loss = 0.448104 * 100, metric = 6.72% * 100;
 Minibatch[1201-1300]: loss = 0.457014 * 100, metric = 6.96% * 100;
 Minibatch[1301-1400]: loss = 0.470519 * 100, metric = 7.29% * 100;
 Minibatch[1401-1500]: loss = 0.460111 * 100, metric = 6.86% * 100;
 Minibatch[1501-1600]: loss = 0.461789 * 100, metric = 7.09% * 100;
 Minibatch[1601-1700]: loss = 0.454724 * 100, metric = 6.78% * 100;
 Minibatch[1701-1800]: loss = 0.459321 * 100, metric = 7.17% * 100;
 Minibatch[1801-1900]: loss = 0.461998 * 100, metric = 7.10% * 100;
 Minibatch[1901-2000]: loss = 0.463548 * 100, metric = 6.89% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.458781 * 2000, metric = 6.95% * 2000 799.662s (  2.5 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 13.95% * 2000;
 Minibatch[   1- 100]: loss = 0.448484 * 100, metric = 6.63% * 100;
 Minibatch[ 101- 200]: loss = 0.460210 * 100, metric = 7.17% * 100;
 Minibatch[ 201- 300]: loss = 0.458182 * 100, metric = 6.80% * 100;
 Minibatch[ 301- 400]: loss = 0.451743 * 100, metric = 7.03% * 100;
 Minibatch[ 401- 500]: loss = 0.441525 * 100, metric = 6.65% * 100;
 Minibatch[ 501- 600]: loss = 0.461924 * 100, metric = 6.91% * 100;
 Minibatch[ 601- 700]: loss = 0.454490 * 100, metric = 6.97% * 100;
 Minibatch[ 701- 800]: loss = 0.461716 * 100, metric = 6.88% * 100;
 Minibatch[ 801- 900]: loss = 0.439962 * 100, metric = 6.49% * 100;
 Minibatch[ 901-1000]: loss = 0.450076 * 100, metric = 6.68% * 100;
 Minibatch[1001-1100]: loss = 0.454276 * 100, metric = 7.02% * 100;
 Minibatch[1101-1200]: loss = 0.458338 * 100, metric = 6.97% * 100;
 Minibatch[1201-1300]: loss = 0.464018 * 100, metric = 6.99% * 100;
 Minibatch[1301-1400]: loss = 0.466365 * 100, metric = 7.11% * 100;
 Minibatch[1401-1500]: loss = 0.471646 * 100, metric = 7.16% * 100;
 Minibatch[1501-1600]: loss = 0.461363 * 100, metric = 7.06% * 100;
 Minibatch[1601-1700]: loss = 0.457697 * 100, metric = 6.65% * 100;
 Minibatch[1701-1800]: loss = 0.465363 * 100, metric = 7.08% * 100;
 Minibatch[1801-1900]: loss = 0.460279 * 100, metric = 7.03% * 100;
 Minibatch[1901-2000]: loss = 0.453216 * 100, metric = 6.85% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.457044 * 2000, metric = 6.91% * 2000 805.057s (  2.5 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 14.35% * 2000;
 Minibatch[   1- 100]: loss = 0.448585 * 100, metric = 6.88% * 100;
 Minibatch[ 101- 200]: loss = 0.440626 * 100, metric = 6.58% * 100;
 Minibatch[ 201- 300]: loss = 0.458655 * 100, metric = 7.04% * 100;
 Minibatch[ 301- 400]: loss = 0.457306 * 100, metric = 7.00% * 100;
 Minibatch[ 401- 500]: loss = 0.458595 * 100, metric = 6.90% * 100;
 Minibatch[ 501- 600]: loss = 0.438377 * 100, metric = 6.62% * 100;
 Minibatch[ 601- 700]: loss = 0.467310 * 100, metric = 7.06% * 100;
 Minibatch[ 701- 800]: loss = 0.454155 * 100, metric = 6.71% * 100;
 Minibatch[ 801- 900]: loss = 0.446986 * 100, metric = 6.80% * 100;
 Minibatch[ 901-1000]: loss = 0.451704 * 100, metric = 6.84% * 100;
 Minibatch[1001-1100]: loss = 0.462088 * 100, metric = 7.35% * 100;
 Minibatch[1101-1200]: loss = 0.446726 * 100, metric = 6.68% * 100;
 Minibatch[1201-1300]: loss = 0.449569 * 100, metric = 6.73% * 100;
 Minibatch[1301-1400]: loss = 0.458649 * 100, metric = 6.97% * 100;
 Minibatch[1401-1500]: loss = 0.446747 * 100, metric = 6.56% * 100;
 Minibatch[1501-1600]: loss = 0.458213 * 100, metric = 7.05% * 100;
 Minibatch[1601-1700]: loss = 0.455599 * 100, metric = 6.82% * 100;
 Minibatch[1701-1800]: loss = 0.443549 * 100, metric = 6.55% * 100;
 Minibatch[1801-1900]: loss = 0.440201 * 100, metric = 6.38% * 100;
 Minibatch[1901-2000]: loss = 0.446256 * 100, metric = 6.88% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.451495 * 2000, metric = 6.82% * 2000 820.931s (  2.4 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 13.86% * 2000;
 Minibatch[   1- 100]: loss = 0.445578 * 100, metric = 6.79% * 100;
 Minibatch[ 101- 200]: loss = 0.432387 * 100, metric = 6.42% * 100;
 Minibatch[ 201- 300]: loss = 0.460722 * 100, metric = 7.00% * 100;
 Minibatch[ 301- 400]: loss = 0.448206 * 100, metric = 6.88% * 100;
 Minibatch[ 401- 500]: loss = 0.460086 * 100, metric = 6.99% * 100;
 Minibatch[ 501- 600]: loss = 0.449329 * 100, metric = 6.49% * 100;
 Minibatch[ 601- 700]: loss = 0.438249 * 100, metric = 6.52% * 100;
 Minibatch[ 701- 800]: loss = 0.441406 * 100, metric = 6.50% * 100;
 Minibatch[ 801- 900]: loss = 0.449428 * 100, metric = 6.83% * 100;
 Minibatch[ 901-1000]: loss = 0.457583 * 100, metric = 7.01% * 100;
 Minibatch[1001-1100]: loss = 0.453594 * 100, metric = 6.89% * 100;
 Minibatch[1101-1200]: loss = 0.456004 * 100, metric = 6.96% * 100;
 Minibatch[1201-1300]: loss = 0.462841 * 100, metric = 7.15% * 100;
 Minibatch[1301-1400]: loss = 0.434933 * 100, metric = 6.27% * 100;
 Minibatch[1401-1500]: loss = 0.437098 * 100, metric = 6.75% * 100;
 Minibatch[1501-1600]: loss = 0.453094 * 100, metric = 6.85% * 100;
 Minibatch[1601-1700]: loss = 0.452543 * 100, metric = 6.86% * 100;
 Minibatch[1701-1800]: loss = 0.451860 * 100, metric = 6.84% * 100;
 Minibatch[1801-1900]: loss = 0.450828 * 100, metric = 6.93% * 100;
 Minibatch[1901-2000]: loss = 0.435461 * 100, metric = 6.48% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.448562 * 2000, metric = 6.77% * 2000 862.704s (  2.3 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 13.87% * 2000;
 Minibatch[   1- 100]: loss = 0.433515 * 100, metric = 6.51% * 100;
 Minibatch[ 101- 200]: loss = 0.437268 * 100, metric = 6.65% * 100;
 Minibatch[ 201- 300]: loss = 0.443641 * 100, metric = 6.58% * 100;
 Minibatch[ 301- 400]: loss = 0.437475 * 100, metric = 6.49% * 100;
 Minibatch[ 401- 500]: loss = 0.451909 * 100, metric = 6.64% * 100;
 Minibatch[ 501- 600]: loss = 0.446933 * 100, metric = 6.74% * 100;
 Minibatch[ 601- 700]: loss = 0.436446 * 100, metric = 6.54% * 100;
 Minibatch[ 701- 800]: loss = 0.436481 * 100, metric = 6.68% * 100;
 Minibatch[ 801- 900]: loss = 0.432590 * 100, metric = 6.47% * 100;
 Minibatch[ 901-1000]: loss = 0.453805 * 100, metric = 6.83% * 100;
 Minibatch[1001-1100]: loss = 0.437061 * 100, metric = 6.70% * 100;
 Minibatch[1101-1200]: loss = 0.442273 * 100, metric = 6.56% * 100;
 Minibatch[1201-1300]: loss = 0.454369 * 100, metric = 6.87% * 100;
 Minibatch[1301-1400]: loss = 0.454770 * 100, metric = 6.95% * 100;
 Minibatch[1401-1500]: loss = 0.437536 * 100, metric = 6.52% * 100;
 Minibatch[1501-1600]: loss = 0.449084 * 100, metric = 6.60% * 100;
 Minibatch[1601-1700]: loss = 0.446261 * 100, metric = 6.74% * 100;
 Minibatch[1701-1800]: loss = 0.445598 * 100, metric = 6.62% * 100;
 Minibatch[1801-1900]: loss = 0.440895 * 100, metric = 6.65% * 100;
 Minibatch[1901-2000]: loss = 0.441326 * 100, metric = 6.58% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.442962 * 2000, metric = 6.65% * 2000 858.703s (  2.3 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 13.34% * 2000;
0.6395945921242238
 Minibatch[   1- 100]: loss = 0.450354 * 100, metric = 6.84% * 100;
 Minibatch[ 101- 200]: loss = 0.429385 * 100, metric = 6.18% * 100;
 Minibatch[ 201- 300]: loss = 0.443835 * 100, metric = 6.69% * 100;
 Minibatch[ 301- 400]: loss = 0.443187 * 100, metric = 6.59% * 100;
 Minibatch[ 401- 500]: loss = 0.440194 * 100, metric = 6.54% * 100;
 Minibatch[ 501- 600]: loss = 0.426562 * 100, metric = 6.41% * 100;
 Minibatch[ 601- 700]: loss = 0.450375 * 100, metric = 6.96% * 100;
 Minibatch[ 701- 800]: loss = 0.430395 * 100, metric = 6.80% * 100;
 Minibatch[ 801- 900]: loss = 0.442857 * 100, metric = 6.63% * 100;
 Minibatch[ 901-1000]: loss = 0.443829 * 100, metric = 6.63% * 100;
 Minibatch[1001-1100]: loss = 0.440204 * 100, metric = 6.79% * 100;
 Minibatch[1101-1200]: loss = 0.424081 * 100, metric = 6.38% * 100;
 Minibatch[1201-1300]: loss = 0.441992 * 100, metric = 6.86% * 100;
 Minibatch[1301-1400]: loss = 0.443790 * 100, metric = 6.83% * 100;
 Minibatch[1401-1500]: loss = 0.420098 * 100, metric = 6.20% * 100;
 Minibatch[1501-1600]: loss = 0.449214 * 100, metric = 7.03% * 100;
 Minibatch[1601-1700]: loss = 0.437082 * 100, metric = 6.60% * 100;
 Minibatch[1701-1800]: loss = 0.433354 * 100, metric = 6.61% * 100;
 Minibatch[1801-1900]: loss = 0.436735 * 100, metric = 6.63% * 100;
 Minibatch[1901-2000]: loss = 0.434264 * 100, metric = 6.35% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.438090 * 2000, metric = 6.63% * 2000 865.327s (  2.3 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 13.53% * 2000;
 Minibatch[   1- 100]: loss = 0.434114 * 100, metric = 6.59% * 100;
 Minibatch[ 101- 200]: loss = 0.439909 * 100, metric = 6.68% * 100;
 Minibatch[ 201- 300]: loss = 0.442864 * 100, metric = 6.65% * 100;
 Minibatch[ 301- 400]: loss = 0.448185 * 100, metric = 6.73% * 100;
 Minibatch[ 401- 500]: loss = 0.442445 * 100, metric = 6.49% * 100;
 Minibatch[ 501- 600]: loss = 0.428604 * 100, metric = 6.66% * 100;
 Minibatch[ 601- 700]: loss = 0.445448 * 100, metric = 6.85% * 100;
 Minibatch[ 701- 800]: loss = 0.415651 * 100, metric = 6.10% * 100;
 Minibatch[ 801- 900]: loss = 0.430566 * 100, metric = 6.35% * 100;
 Minibatch[ 901-1000]: loss = 0.434594 * 100, metric = 6.57% * 100;
 Minibatch[1001-1100]: loss = 0.426967 * 100, metric = 6.33% * 100;
 Minibatch[1101-1200]: loss = 0.424252 * 100, metric = 6.34% * 100;
 Minibatch[1201-1300]: loss = 0.437101 * 100, metric = 6.40% * 100;
 Minibatch[1301-1400]: loss = 0.423517 * 100, metric = 6.29% * 100;
 Minibatch[1401-1500]: loss = 0.430311 * 100, metric = 6.33% * 100;
 Minibatch[1501-1600]: loss = 0.416661 * 100, metric = 6.28% * 100;
 Minibatch[1601-1700]: loss = 0.436973 * 100, metric = 6.43% * 100;
 Minibatch[1701-1800]: loss = 0.442548 * 100, metric = 6.83% * 100;
 Minibatch[1801-1900]: loss = 0.430009 * 100, metric = 6.35% * 100;
 Minibatch[1901-2000]: loss = 0.422091 * 100, metric = 6.14% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.432641 * 2000, metric = 6.47% * 2000 872.067s (  2.3 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 14.70% * 2000;
 Minibatch[   1- 100]: loss = 0.442568 * 100, metric = 6.59% * 100;
 Minibatch[ 101- 200]: loss = 0.424101 * 100, metric = 6.01% * 100;
 Minibatch[ 201- 300]: loss = 0.427267 * 100, metric = 6.23% * 100;
 Minibatch[ 301- 400]: loss = 0.440401 * 100, metric = 6.79% * 100;
 Minibatch[ 401- 500]: loss = 0.431715 * 100, metric = 6.37% * 100;
 Minibatch[ 501- 600]: loss = 0.417962 * 100, metric = 6.08% * 100;
 Minibatch[ 601- 700]: loss = 0.433215 * 100, metric = 6.26% * 100;
 Minibatch[ 701- 800]: loss = 0.416249 * 100, metric = 6.37% * 100;
 Minibatch[ 801- 900]: loss = 0.450813 * 100, metric = 7.08% * 100;
 Minibatch[ 901-1000]: loss = 0.430392 * 100, metric = 6.29% * 100;
 Minibatch[1001-1100]: loss = 0.426449 * 100, metric = 6.28% * 100;
 Minibatch[1101-1200]: loss = 0.441661 * 100, metric = 6.49% * 100;
 Minibatch[1201-1300]: loss = 0.428950 * 100, metric = 6.49% * 100;
 Minibatch[1301-1400]: loss = 0.425455 * 100, metric = 6.33% * 100;
 Minibatch[1401-1500]: loss = 0.444177 * 100, metric = 6.66% * 100;
 Minibatch[1501-1600]: loss = 0.429096 * 100, metric = 6.41% * 100;
 Minibatch[1601-1700]: loss = 0.418737 * 100, metric = 6.27% * 100;
 Minibatch[1701-1800]: loss = 0.430807 * 100, metric = 6.61% * 100;
 Minibatch[1801-1900]: loss = 0.429587 * 100, metric = 6.50% * 100;
 Minibatch[1901-2000]: loss = 0.436262 * 100, metric = 6.47% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.431293 * 2000, metric = 6.43% * 2000 897.032s (  2.2 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 14.22% * 2000;
 Minibatch[   1- 100]: loss = 0.423156 * 100, metric = 6.46% * 100;
 Minibatch[ 101- 200]: loss = 0.442851 * 100, metric = 6.79% * 100;
 Minibatch[ 201- 300]: loss = 0.429997 * 100, metric = 6.31% * 100;
 Minibatch[ 301- 400]: loss = 0.444553 * 100, metric = 6.74% * 100;
 Minibatch[ 401- 500]: loss = 0.432962 * 100, metric = 6.37% * 100;
 Minibatch[ 501- 600]: loss = 0.432913 * 100, metric = 6.53% * 100;
 Minibatch[ 601- 700]: loss = 0.418695 * 100, metric = 5.93% * 100;
 Minibatch[ 701- 800]: loss = 0.419891 * 100, metric = 6.10% * 100;
 Minibatch[ 801- 900]: loss = 0.428964 * 100, metric = 6.49% * 100;
 Minibatch[ 901-1000]: loss = 0.430683 * 100, metric = 6.48% * 100;
 Minibatch[1001-1100]: loss = 0.424747 * 100, metric = 6.52% * 100;
 Minibatch[1101-1200]: loss = 0.438253 * 100, metric = 6.83% * 100;
 Minibatch[1201-1300]: loss = 0.437611 * 100, metric = 6.71% * 100;
 Minibatch[1301-1400]: loss = 0.431623 * 100, metric = 6.44% * 100;
 Minibatch[1401-1500]: loss = 0.421572 * 100, metric = 6.25% * 100;
 Minibatch[1501-1600]: loss = 0.425752 * 100, metric = 6.22% * 100;
 Minibatch[1601-1700]: loss = 0.424276 * 100, metric = 6.21% * 100;
 Minibatch[1701-1800]: loss = 0.434868 * 100, metric = 6.57% * 100;
 Minibatch[1801-1900]: loss = 0.421550 * 100, metric = 6.13% * 100;
 Minibatch[1901-2000]: loss = 0.429261 * 100, metric = 6.23% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.429709 * 2000, metric = 6.42% * 2000 895.441s (  2.2 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 13.61% * 2000;
 Minibatch[   1- 100]: loss = 0.422356 * 100, metric = 6.19% * 100;
 Minibatch[ 101- 200]: loss = 0.414502 * 100, metric = 6.26% * 100;
 Minibatch[ 201- 300]: loss = 0.428697 * 100, metric = 6.34% * 100;
 Minibatch[ 301- 400]: loss = 0.419890 * 100, metric = 6.12% * 100;
 Minibatch[ 401- 500]: loss = 0.413752 * 100, metric = 6.19% * 100;
 Minibatch[ 501- 600]: loss = 0.422449 * 100, metric = 6.50% * 100;
 Minibatch[ 601- 700]: loss = 0.436772 * 100, metric = 6.51% * 100;
 Minibatch[ 701- 800]: loss = 0.438366 * 100, metric = 6.69% * 100;
 Minibatch[ 801- 900]: loss = 0.421522 * 100, metric = 6.13% * 100;
 Minibatch[ 901-1000]: loss = 0.427766 * 100, metric = 6.30% * 100;
 Minibatch[1001-1100]: loss = 0.431520 * 100, metric = 6.53% * 100;
 Minibatch[1101-1200]: loss = 0.429026 * 100, metric = 6.29% * 100;
 Minibatch[1201-1300]: loss = 0.401407 * 100, metric = 5.88% * 100;
 Minibatch[1301-1400]: loss = 0.410047 * 100, metric = 6.07% * 100;
 Minibatch[1401-1500]: loss = 0.437830 * 100, metric = 6.65% * 100;
 Minibatch[1501-1600]: loss = 0.436354 * 100, metric = 6.45% * 100;
 Minibatch[1601-1700]: loss = 0.422604 * 100, metric = 6.08% * 100;
 Minibatch[1701-1800]: loss = 0.436516 * 100, metric = 6.54% * 100;
 Minibatch[1801-1900]: loss = 0.434339 * 100, metric = 6.41% * 100;
 Minibatch[1901-2000]: loss = 0.433218 * 100, metric = 6.50% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.425947 * 2000, metric = 6.33% * 2000 881.942s (  2.3 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 13.42% * 2000;
0.6359646843671799
 Minibatch[   1- 100]: loss = 0.426229 * 100, metric = 6.44% * 100;
 Minibatch[ 101- 200]: loss = 0.426259 * 100, metric = 6.42% * 100;
 Minibatch[ 201- 300]: loss = 0.421887 * 100, metric = 6.38% * 100;
 Minibatch[ 301- 400]: loss = 0.418457 * 100, metric = 6.27% * 100;
 Minibatch[ 401- 500]: loss = 0.436002 * 100, metric = 6.72% * 100;
 Minibatch[ 501- 600]: loss = 0.438036 * 100, metric = 6.80% * 100;
 Minibatch[ 601- 700]: loss = 0.445385 * 100, metric = 6.75% * 100;
 Minibatch[ 701- 800]: loss = 0.428929 * 100, metric = 6.53% * 100;
 Minibatch[ 801- 900]: loss = 0.427894 * 100, metric = 6.18% * 100;
 Minibatch[ 901-1000]: loss = 0.426947 * 100, metric = 6.53% * 100;
 Minibatch[1001-1100]: loss = 0.420617 * 100, metric = 6.46% * 100;
 Minibatch[1101-1200]: loss = 0.427412 * 100, metric = 6.38% * 100;
 Minibatch[1201-1300]: loss = 0.422281 * 100, metric = 6.17% * 100;
 Minibatch[1301-1400]: loss = 0.416019 * 100, metric = 6.15% * 100;
 Minibatch[1401-1500]: loss = 0.418189 * 100, metric = 6.33% * 100;
 Minibatch[1501-1600]: loss = 0.425967 * 100, metric = 6.51% * 100;
 Minibatch[1601-1700]: loss = 0.414417 * 100, metric = 6.18% * 100;
 Minibatch[1701-1800]: loss = 0.425797 * 100, metric = 6.29% * 100;
 Minibatch[1801-1900]: loss = 0.437066 * 100, metric = 6.39% * 100;
 Minibatch[1901-2000]: loss = 0.412192 * 100, metric = 6.19% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.425799 * 2000, metric = 6.40% * 2000 888.999s (  2.2 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 13.98% * 2000;
 Minibatch[   1- 100]: loss = 0.434885 * 100, metric = 6.68% * 100;
 Minibatch[ 101- 200]: loss = 0.422207 * 100, metric = 6.38% * 100;
 Minibatch[ 201- 300]: loss = 0.427105 * 100, metric = 6.33% * 100;
 Minibatch[ 301- 400]: loss = 0.430000 * 100, metric = 6.54% * 100;
 Minibatch[ 401- 500]: loss = 0.438668 * 100, metric = 6.72% * 100;
 Minibatch[ 501- 600]: loss = 0.427348 * 100, metric = 6.45% * 100;
 Minibatch[ 601- 700]: loss = 0.432447 * 100, metric = 6.41% * 100;
 Minibatch[ 701- 800]: loss = 0.425350 * 100, metric = 6.44% * 100;
 Minibatch[ 801- 900]: loss = 0.421404 * 100, metric = 6.33% * 100;
 Minibatch[ 901-1000]: loss = 0.433189 * 100, metric = 6.68% * 100;
 Minibatch[1001-1100]: loss = 0.427134 * 100, metric = 6.41% * 100;
 Minibatch[1101-1200]: loss = 0.430029 * 100, metric = 6.40% * 100;
 Minibatch[1201-1300]: loss = 0.408093 * 100, metric = 6.13% * 100;
 Minibatch[1301-1400]: loss = 0.422552 * 100, metric = 6.41% * 100;
 Minibatch[1401-1500]: loss = 0.426669 * 100, metric = 6.53% * 100;
 Minibatch[1501-1600]: loss = 0.399584 * 100, metric = 5.75% * 100;
 Minibatch[1601-1700]: loss = 0.430424 * 100, metric = 6.89% * 100;
 Minibatch[1701-1800]: loss = 0.422724 * 100, metric = 6.32% * 100;
 Minibatch[1801-1900]: loss = 0.417843 * 100, metric = 6.31% * 100;
 Minibatch[1901-2000]: loss = 0.415689 * 100, metric = 6.06% * 100;
Finished Epoch[49 of 200]: [Training] loss = 0.424667 * 2000, metric = 6.41% * 2000 891.542s (  2.2 samples/s);
Finished Evaluation [49]: Minibatch[1-2000]: metric = 13.59% * 2000;
 Minibatch[   1- 100]: loss = 0.431957 * 100, metric = 6.71% * 100;
 Minibatch[ 101- 200]: loss = 0.406725 * 100, metric = 6.22% * 100;
 Minibatch[ 201- 300]: loss = 0.407674 * 100, metric = 5.91% * 100;
 Minibatch[ 301- 400]: loss = 0.414251 * 100, metric = 6.12% * 100;
 Minibatch[ 401- 500]: loss = 0.419946 * 100, metric = 6.21% * 100;
 Minibatch[ 501- 600]: loss = 0.429459 * 100, metric = 6.47% * 100;
 Minibatch[ 601- 700]: loss = 0.411622 * 100, metric = 6.17% * 100;
 Minibatch[ 701- 800]: loss = 0.418900 * 100, metric = 6.06% * 100;
 Minibatch[ 801- 900]: loss = 0.415772 * 100, metric = 6.08% * 100;
 Minibatch[ 901-1000]: loss = 0.424286 * 100, metric = 6.31% * 100;
 Minibatch[1001-1100]: loss = 0.410303 * 100, metric = 6.20% * 100;
 Minibatch[1101-1200]: loss = 0.413040 * 100, metric = 6.23% * 100;
 Minibatch[1201-1300]: loss = 0.416008 * 100, metric = 6.42% * 100;
 Minibatch[1301-1400]: loss = 0.403940 * 100, metric = 6.01% * 100;
 Minibatch[1401-1500]: loss = 0.411573 * 100, metric = 6.30% * 100;
 Minibatch[1501-1600]: loss = 0.405372 * 100, metric = 5.84% * 100;
 Minibatch[1601-1700]: loss = 0.406705 * 100, metric = 6.02% * 100;
 Minibatch[1701-1800]: loss = 0.423265 * 100, metric = 6.51% * 100;
 Minibatch[1801-1900]: loss = 0.419987 * 100, metric = 6.14% * 100;
 Minibatch[1901-2000]: loss = 0.409132 * 100, metric = 5.95% * 100;
Finished Epoch[50 of 200]: [Training] loss = 0.414996 * 2000, metric = 6.19% * 2000 888.346s (  2.3 samples/s);
Finished Evaluation [50]: Minibatch[1-2000]: metric = 13.69% * 2000;
 Minibatch[   1- 100]: loss = 0.396755 * 100, metric = 5.89% * 100;
 Minibatch[ 101- 200]: loss = 0.414702 * 100, metric = 6.15% * 100;
 Minibatch[ 201- 300]: loss = 0.422659 * 100, metric = 6.11% * 100;
 Minibatch[ 301- 400]: loss = 0.423881 * 100, metric = 6.16% * 100;
 Minibatch[ 401- 500]: loss = 0.407030 * 100, metric = 6.07% * 100;
 Minibatch[ 501- 600]: loss = 0.413889 * 100, metric = 6.37% * 100;
 Minibatch[ 601- 700]: loss = 0.405750 * 100, metric = 6.08% * 100;
 Minibatch[ 701- 800]: loss = 0.410624 * 100, metric = 6.01% * 100;
 Minibatch[ 801- 900]: loss = 0.409983 * 100, metric = 6.10% * 100;
 Minibatch[ 901-1000]: loss = 0.409298 * 100, metric = 6.17% * 100;
 Minibatch[1001-1100]: loss = 0.423489 * 100, metric = 6.51% * 100;
 Minibatch[1101-1200]: loss = 0.413614 * 100, metric = 6.29% * 100;
 Minibatch[1201-1300]: loss = 0.421953 * 100, metric = 6.30% * 100;
 Minibatch[1301-1400]: loss = 0.413804 * 100, metric = 6.07% * 100;
 Minibatch[1401-1500]: loss = 0.405215 * 100, metric = 6.01% * 100;
 Minibatch[1501-1600]: loss = 0.418021 * 100, metric = 6.18% * 100;
 Minibatch[1601-1700]: loss = 0.398517 * 100, metric = 5.81% * 100;
 Minibatch[1701-1800]: loss = 0.413773 * 100, metric = 6.44% * 100;
 Minibatch[1801-1900]: loss = 0.398668 * 100, metric = 5.93% * 100;
 Minibatch[1901-2000]: loss = 0.408062 * 100, metric = 6.08% * 100;
Finished Epoch[51 of 200]: [Training] loss = 0.411484 * 2000, metric = 6.14% * 2000 875.160s (  2.3 samples/s);
Finished Evaluation [51]: Minibatch[1-2000]: metric = 13.00% * 2000;
0.6278579138219357
 Minibatch[   1- 100]: loss = 0.404063 * 100, metric = 6.21% * 100;
 Minibatch[ 101- 200]: loss = 0.411967 * 100, metric = 6.02% * 100;
 Minibatch[ 201- 300]: loss = 0.411883 * 100, metric = 6.20% * 100;
 Minibatch[ 301- 400]: loss = 0.401037 * 100, metric = 5.78% * 100;
 Minibatch[ 401- 500]: loss = 0.421687 * 100, metric = 6.35% * 100;
 Minibatch[ 501- 600]: loss = 0.409755 * 100, metric = 6.26% * 100;
 Minibatch[ 601- 700]: loss = 0.394541 * 100, metric = 5.89% * 100;
 Minibatch[ 701- 800]: loss = 0.418517 * 100, metric = 6.52% * 100;
 Minibatch[ 801- 900]: loss = 0.421563 * 100, metric = 6.36% * 100;
 Minibatch[ 901-1000]: loss = 0.428547 * 100, metric = 6.45% * 100;
 Minibatch[1001-1100]: loss = 0.411127 * 100, metric = 6.18% * 100;
 Minibatch[1101-1200]: loss = 0.400358 * 100, metric = 5.63% * 100;
 Minibatch[1201-1300]: loss = 0.398113 * 100, metric = 5.75% * 100;
 Minibatch[1301-1400]: loss = 0.405933 * 100, metric = 5.78% * 100;
 Minibatch[1401-1500]: loss = 0.392817 * 100, metric = 5.66% * 100;
 Minibatch[1501-1600]: loss = 0.383090 * 100, metric = 5.60% * 100;
 Minibatch[1601-1700]: loss = 0.410178 * 100, metric = 6.01% * 100;
 Minibatch[1701-1800]: loss = 0.383942 * 100, metric = 5.57% * 100;
 Minibatch[1801-1900]: loss = 0.399742 * 100, metric = 5.82% * 100;
 Minibatch[1901-2000]: loss = 0.414393 * 100, metric = 6.29% * 100;
Finished Epoch[52 of 200]: [Training] loss = 0.406163 * 2000, metric = 6.02% * 2000 851.529s (  2.3 samples/s);
Finished Evaluation [52]: Minibatch[1-2000]: metric = 13.45% * 2000;
 Minibatch[   1- 100]: loss = 0.407626 * 100, metric = 5.87% * 100;
 Minibatch[ 101- 200]: loss = 0.392898 * 100, metric = 5.60% * 100;
 Minibatch[ 201- 300]: loss = 0.399071 * 100, metric = 5.79% * 100;
 Minibatch[ 301- 400]: loss = 0.404852 * 100, metric = 5.88% * 100;
 Minibatch[ 401- 500]: loss = 0.403228 * 100, metric = 5.92% * 100;
 Minibatch[ 501- 600]: loss = 0.405380 * 100, metric = 6.03% * 100;
 Minibatch[ 601- 700]: loss = 0.400171 * 100, metric = 5.79% * 100;
 Minibatch[ 701- 800]: loss = 0.407516 * 100, metric = 5.90% * 100;
 Minibatch[ 801- 900]: loss = 0.402975 * 100, metric = 5.85% * 100;
 Minibatch[ 901-1000]: loss = 0.399927 * 100, metric = 5.77% * 100;
 Minibatch[1001-1100]: loss = 0.409012 * 100, metric = 6.09% * 100;
 Minibatch[1101-1200]: loss = 0.396379 * 100, metric = 5.93% * 100;
 Minibatch[1201-1300]: loss = 0.395269 * 100, metric = 5.97% * 100;
 Minibatch[1301-1400]: loss = 0.402158 * 100, metric = 5.53% * 100;
 Minibatch[1401-1500]: loss = 0.397147 * 100, metric = 5.80% * 100;
 Minibatch[1501-1600]: loss = 0.403747 * 100, metric = 5.95% * 100;
 Minibatch[1601-1700]: loss = 0.400529 * 100, metric = 5.88% * 100;
 Minibatch[1701-1800]: loss = 0.410432 * 100, metric = 5.99% * 100;
 Minibatch[1801-1900]: loss = 0.411572 * 100, metric = 6.05% * 100;
 Minibatch[1901-2000]: loss = 0.390880 * 100, metric = 5.76% * 100;
Finished Epoch[53 of 200]: [Training] loss = 0.402038 * 2000, metric = 5.87% * 2000 855.207s (  2.3 samples/s);
Finished Evaluation [53]: Minibatch[1-2000]: metric = 13.27% * 2000;
 Minibatch[   1- 100]: loss = 0.394100 * 100, metric = 5.62% * 100;
 Minibatch[ 101- 200]: loss = 0.398923 * 100, metric = 5.92% * 100;
 Minibatch[ 201- 300]: loss = 0.394684 * 100, metric = 5.84% * 100;
 Minibatch[ 301- 400]: loss = 0.384699 * 100, metric = 5.39% * 100;
 Minibatch[ 401- 500]: loss = 0.404408 * 100, metric = 5.89% * 100;
 Minibatch[ 501- 600]: loss = 0.394145 * 100, metric = 5.53% * 100;
 Minibatch[ 601- 700]: loss = 0.406954 * 100, metric = 5.82% * 100;
 Minibatch[ 701- 800]: loss = 0.395250 * 100, metric = 5.79% * 100;
 Minibatch[ 801- 900]: loss = 0.385631 * 100, metric = 5.46% * 100;
 Minibatch[ 901-1000]: loss = 0.399410 * 100, metric = 5.79% * 100;
 Minibatch[1001-1100]: loss = 0.385026 * 100, metric = 5.47% * 100;
 Minibatch[1101-1200]: loss = 0.393854 * 100, metric = 5.67% * 100;
 Minibatch[1201-1300]: loss = 0.394366 * 100, metric = 5.61% * 100;
 Minibatch[1301-1400]: loss = 0.381740 * 100, metric = 5.78% * 100;
 Minibatch[1401-1500]: loss = 0.402900 * 100, metric = 5.83% * 100;
 Minibatch[1501-1600]: loss = 0.399653 * 100, metric = 5.73% * 100;
 Minibatch[1601-1700]: loss = 0.391680 * 100, metric = 5.63% * 100;
 Minibatch[1701-1800]: loss = 0.399793 * 100, metric = 5.98% * 100;
 Minibatch[1801-1900]: loss = 0.406816 * 100, metric = 6.16% * 100;
 Minibatch[1901-2000]: loss = 0.400109 * 100, metric = 5.81% * 100;
Finished Epoch[54 of 200]: [Training] loss = 0.395707 * 2000, metric = 5.74% * 2000 845.727s (  2.4 samples/s);
Finished Evaluation [54]: Minibatch[1-2000]: metric = 13.64% * 2000;
 Minibatch[   1- 100]: loss = 0.396660 * 100, metric = 5.70% * 100;
 Minibatch[ 101- 200]: loss = 0.396168 * 100, metric = 5.62% * 100;
 Minibatch[ 201- 300]: loss = 0.409373 * 100, metric = 5.94% * 100;
 Minibatch[ 301- 400]: loss = 0.394029 * 100, metric = 5.64% * 100;
 Minibatch[ 401- 500]: loss = 0.398848 * 100, metric = 5.79% * 100;
 Minibatch[ 501- 600]: loss = 0.403002 * 100, metric = 5.78% * 100;
 Minibatch[ 601- 700]: loss = 0.395366 * 100, metric = 5.93% * 100;
 Minibatch[ 701- 800]: loss = 0.414241 * 100, metric = 5.95% * 100;
 Minibatch[ 801- 900]: loss = 0.401219 * 100, metric = 5.94% * 100;
 Minibatch[ 901-1000]: loss = 0.389758 * 100, metric = 5.47% * 100;
 Minibatch[1001-1100]: loss = 0.401866 * 100, metric = 5.67% * 100;
 Minibatch[1101-1200]: loss = 0.402310 * 100, metric = 5.87% * 100;
 Minibatch[1201-1300]: loss = 0.398195 * 100, metric = 5.67% * 100;
 Minibatch[1301-1400]: loss = 0.378868 * 100, metric = 5.30% * 100;
 Minibatch[1401-1500]: loss = 0.396329 * 100, metric = 5.97% * 100;
 Minibatch[1501-1600]: loss = 0.404906 * 100, metric = 5.76% * 100;
 Minibatch[1601-1700]: loss = 0.396895 * 100, metric = 5.92% * 100;
 Minibatch[1701-1800]: loss = 0.397538 * 100, metric = 5.73% * 100;
 Minibatch[1801-1900]: loss = 0.388571 * 100, metric = 5.87% * 100;
 Minibatch[1901-2000]: loss = 0.392390 * 100, metric = 5.72% * 100;
Finished Epoch[55 of 200]: [Training] loss = 0.397827 * 2000, metric = 5.76% * 2000 841.691s (  2.4 samples/s);
Finished Evaluation [55]: Minibatch[1-2000]: metric = 13.12% * 2000;
 Minibatch[   1- 100]: loss = 0.406588 * 100, metric = 6.06% * 100;
 Minibatch[ 101- 200]: loss = 0.398898 * 100, metric = 5.65% * 100;
 Minibatch[ 201- 300]: loss = 0.402209 * 100, metric = 5.95% * 100;
 Minibatch[ 301- 400]: loss = 0.402717 * 100, metric = 5.84% * 100;
 Minibatch[ 401- 500]: loss = 0.405730 * 100, metric = 5.82% * 100;
 Minibatch[ 501- 600]: loss = 0.399798 * 100, metric = 6.01% * 100;
 Minibatch[ 601- 700]: loss = 0.398008 * 100, metric = 5.94% * 100;
 Minibatch[ 701- 800]: loss = 0.394691 * 100, metric = 5.78% * 100;
 Minibatch[ 801- 900]: loss = 0.403018 * 100, metric = 5.94% * 100;
 Minibatch[ 901-1000]: loss = 0.398771 * 100, metric = 5.77% * 100;
 Minibatch[1001-1100]: loss = 0.407421 * 100, metric = 5.95% * 100;
 Minibatch[1101-1200]: loss = 0.403412 * 100, metric = 5.93% * 100;
 Minibatch[1201-1300]: loss = 0.397526 * 100, metric = 5.67% * 100;
 Minibatch[1301-1400]: loss = 0.394102 * 100, metric = 5.64% * 100;
 Minibatch[1401-1500]: loss = 0.401246 * 100, metric = 5.89% * 100;
 Minibatch[1501-1600]: loss = 0.393054 * 100, metric = 5.53% * 100;
 Minibatch[1601-1700]: loss = 0.388524 * 100, metric = 5.41% * 100;
 Minibatch[1701-1800]: loss = 0.392523 * 100, metric = 5.74% * 100;
 Minibatch[1801-1900]: loss = 0.390676 * 100, metric = 5.65% * 100;
 Minibatch[1901-2000]: loss = 0.413312 * 100, metric = 6.14% * 100;
Finished Epoch[56 of 200]: [Training] loss = 0.399611 * 2000, metric = 5.81% * 2000 849.503s (  2.4 samples/s);
Finished Evaluation [56]: Minibatch[1-2000]: metric = 12.81% * 2000;
 Minibatch[   1- 100]: loss = 0.397023 * 100, metric = 5.63% * 100;
 Minibatch[ 101- 200]: loss = 0.384278 * 100, metric = 5.52% * 100;
 Minibatch[ 201- 300]: loss = 0.381053 * 100, metric = 5.59% * 100;
 Minibatch[ 301- 400]: loss = 0.387973 * 100, metric = 5.44% * 100;
 Minibatch[ 401- 500]: loss = 0.391253 * 100, metric = 5.48% * 100;
 Minibatch[ 501- 600]: loss = 0.381197 * 100, metric = 5.37% * 100;
 Minibatch[ 601- 700]: loss = 0.402402 * 100, metric = 5.56% * 100;
 Minibatch[ 701- 800]: loss = 0.375832 * 100, metric = 5.45% * 100;
 Minibatch[ 801- 900]: loss = 0.387179 * 100, metric = 5.60% * 100;
 Minibatch[ 901-1000]: loss = 0.382307 * 100, metric = 5.55% * 100;
 Minibatch[1001-1100]: loss = 0.394946 * 100, metric = 5.65% * 100;
 Minibatch[1101-1200]: loss = 0.382078 * 100, metric = 5.52% * 100;
 Minibatch[1201-1300]: loss = 0.380501 * 100, metric = 5.53% * 100;
 Minibatch[1301-1400]: loss = 0.379208 * 100, metric = 5.46% * 100;
 Minibatch[1401-1500]: loss = 0.395571 * 100, metric = 5.72% * 100;
 Minibatch[1501-1600]: loss = 0.384981 * 100, metric = 5.55% * 100;
 Minibatch[1601-1700]: loss = 0.388002 * 100, metric = 5.57% * 100;
 Minibatch[1701-1800]: loss = 0.385728 * 100, metric = 5.56% * 100;
 Minibatch[1801-1900]: loss = 0.396094 * 100, metric = 5.59% * 100;
 Minibatch[1901-2000]: loss = 0.390884 * 100, metric = 5.57% * 100;
Finished Epoch[57 of 200]: [Training] loss = 0.387424 * 2000, metric = 5.55% * 2000 847.501s (  2.4 samples/s);
Finished Evaluation [57]: Minibatch[1-2000]: metric = 13.31% * 2000;
 Minibatch[   1- 100]: loss = 0.394362 * 100, metric = 5.50% * 100;
 Minibatch[ 101- 200]: loss = 0.398116 * 100, metric = 5.83% * 100;
 Minibatch[ 201- 300]: loss = 0.385598 * 100, metric = 5.67% * 100;
 Minibatch[ 301- 400]: loss = 0.396303 * 100, metric = 5.64% * 100;
 Minibatch[ 401- 500]: loss = 0.412093 * 100, metric = 6.22% * 100;
 Minibatch[ 501- 600]: loss = 0.388315 * 100, metric = 5.58% * 100;
 Minibatch[ 601- 700]: loss = 0.394559 * 100, metric = 5.67% * 100;
 Minibatch[ 701- 800]: loss = 0.400567 * 100, metric = 5.93% * 100;
 Minibatch[ 801- 900]: loss = 0.398866 * 100, metric = 5.77% * 100;
 Minibatch[ 901-1000]: loss = 0.389221 * 100, metric = 5.72% * 100;
 Minibatch[1001-1100]: loss = 0.403335 * 100, metric = 6.06% * 100;
 Minibatch[1101-1200]: loss = 0.400139 * 100, metric = 5.88% * 100;
 Minibatch[1201-1300]: loss = 0.394107 * 100, metric = 5.83% * 100;
 Minibatch[1301-1400]: loss = 0.397675 * 100, metric = 5.87% * 100;
 Minibatch[1401-1500]: loss = 0.380605 * 100, metric = 5.29% * 100;
 Minibatch[1501-1600]: loss = 0.398436 * 100, metric = 5.99% * 100;
 Minibatch[1601-1700]: loss = 0.390066 * 100, metric = 5.69% * 100;
 Minibatch[1701-1800]: loss = 0.392216 * 100, metric = 5.73% * 100;
 Minibatch[1801-1900]: loss = 0.392841 * 100, metric = 5.81% * 100;
 Minibatch[1901-2000]: loss = 0.374149 * 100, metric = 5.27% * 100;
Finished Epoch[58 of 200]: [Training] loss = 0.394078 * 2000, metric = 5.75% * 2000 847.011s (  2.4 samples/s);
Finished Evaluation [58]: Minibatch[1-2000]: metric = 12.95% * 2000;
 Minibatch[   1- 100]: loss = 0.394506 * 100, metric = 5.82% * 100;
 Minibatch[ 101- 200]: loss = 0.398997 * 100, metric = 6.08% * 100;
 Minibatch[ 201- 300]: loss = 0.377346 * 100, metric = 5.56% * 100;
 Minibatch[ 301- 400]: loss = 0.377701 * 100, metric = 5.30% * 100;
 Minibatch[ 401- 500]: loss = 0.385770 * 100, metric = 5.62% * 100;
 Minibatch[ 501- 600]: loss = 0.374241 * 100, metric = 5.46% * 100;
 Minibatch[ 601- 700]: loss = 0.372791 * 100, metric = 5.32% * 100;
 Minibatch[ 701- 800]: loss = 0.384725 * 100, metric = 5.40% * 100;
 Minibatch[ 801- 900]: loss = 0.373459 * 100, metric = 5.46% * 100;
 Minibatch[ 901-1000]: loss = 0.384171 * 100, metric = 5.48% * 100;
 Minibatch[1001-1100]: loss = 0.379252 * 100, metric = 5.50% * 100;
 Minibatch[1101-1200]: loss = 0.394341 * 100, metric = 5.63% * 100;
 Minibatch[1201-1300]: loss = 0.393699 * 100, metric = 5.75% * 100;
 Minibatch[1301-1400]: loss = 0.384081 * 100, metric = 5.48% * 100;
 Minibatch[1401-1500]: loss = 0.389017 * 100, metric = 5.80% * 100;
 Minibatch[1501-1600]: loss = 0.387361 * 100, metric = 5.56% * 100;
 Minibatch[1601-1700]: loss = 0.387039 * 100, metric = 5.92% * 100;
 Minibatch[1701-1800]: loss = 0.388542 * 100, metric = 5.48% * 100;
 Minibatch[1801-1900]: loss = 0.384848 * 100, metric = 5.52% * 100;
 Minibatch[1901-2000]: loss = 0.388564 * 100, metric = 5.68% * 100;
Finished Epoch[59 of 200]: [Training] loss = 0.385023 * 2000, metric = 5.59% * 2000 849.247s (  2.4 samples/s);
Finished Evaluation [59]: Minibatch[1-2000]: metric = 13.55% * 2000;
 Minibatch[   1- 100]: loss = 0.383403 * 100, metric = 5.50% * 100;
 Minibatch[ 101- 200]: loss = 0.372260 * 100, metric = 5.27% * 100;
 Minibatch[ 201- 300]: loss = 0.371508 * 100, metric = 5.14% * 100;
 Minibatch[ 301- 400]: loss = 0.385633 * 100, metric = 5.50% * 100;
 Minibatch[ 401- 500]: loss = 0.385726 * 100, metric = 5.58% * 100;
 Minibatch[ 501- 600]: loss = 0.384600 * 100, metric = 5.77% * 100;
 Minibatch[ 601- 700]: loss = 0.380469 * 100, metric = 5.24% * 100;
 Minibatch[ 701- 800]: loss = 0.394049 * 100, metric = 5.46% * 100;
 Minibatch[ 801- 900]: loss = 0.387823 * 100, metric = 5.75% * 100;
 Minibatch[ 901-1000]: loss = 0.389338 * 100, metric = 5.64% * 100;
 Minibatch[1001-1100]: loss = 0.402544 * 100, metric = 5.95% * 100;
 Minibatch[1101-1200]: loss = 0.389885 * 100, metric = 5.68% * 100;
 Minibatch[1201-1300]: loss = 0.388354 * 100, metric = 5.62% * 100;
 Minibatch[1301-1400]: loss = 0.390526 * 100, metric = 5.70% * 100;
 Minibatch[1401-1500]: loss = 0.366623 * 100, metric = 5.07% * 100;
 Minibatch[1501-1600]: loss = 0.388211 * 100, metric = 5.45% * 100;
 Minibatch[1601-1700]: loss = 0.391234 * 100, metric = 5.66% * 100;
 Minibatch[1701-1800]: loss = 0.396248 * 100, metric = 5.58% * 100;
 Minibatch[1801-1900]: loss = 0.400204 * 100, metric = 5.81% * 100;
 Minibatch[1901-2000]: loss = 0.385170 * 100, metric = 5.48% * 100;
Finished Epoch[60 of 200]: [Training] loss = 0.386691 * 2000, metric = 5.54% * 2000 850.137s (  2.4 samples/s);
Finished Evaluation [60]: Minibatch[1-2000]: metric = 13.31% * 2000;
 Minibatch[   1- 100]: loss = 0.398284 * 100, metric = 5.74% * 100;
 Minibatch[ 101- 200]: loss = 0.378513 * 100, metric = 5.37% * 100;
 Minibatch[ 201- 300]: loss = 0.376553 * 100, metric = 5.51% * 100;
 Minibatch[ 301- 400]: loss = 0.384087 * 100, metric = 5.48% * 100;
 Minibatch[ 401- 500]: loss = 0.380082 * 100, metric = 5.50% * 100;
 Minibatch[ 501- 600]: loss = 0.370659 * 100, metric = 5.18% * 100;
 Minibatch[ 601- 700]: loss = 0.387567 * 100, metric = 5.40% * 100;
 Minibatch[ 701- 800]: loss = 0.382021 * 100, metric = 5.43% * 100;
 Minibatch[ 801- 900]: loss = 0.376991 * 100, metric = 5.43% * 100;
 Minibatch[ 901-1000]: loss = 0.377203 * 100, metric = 5.44% * 100;
 Minibatch[1001-1100]: loss = 0.382697 * 100, metric = 5.55% * 100;
 Minibatch[1101-1200]: loss = 0.381952 * 100, metric = 5.68% * 100;
 Minibatch[1201-1300]: loss = 0.367319 * 100, metric = 5.28% * 100;
 Minibatch[1301-1400]: loss = 0.364720 * 100, metric = 4.85% * 100;
 Minibatch[1401-1500]: loss = 0.391578 * 100, metric = 5.51% * 100;
 Minibatch[1501-1600]: loss = 0.394487 * 100, metric = 5.68% * 100;
 Minibatch[1601-1700]: loss = 0.384813 * 100, metric = 5.56% * 100;
 Minibatch[1701-1800]: loss = 0.379903 * 100, metric = 5.45% * 100;
 Minibatch[1801-1900]: loss = 0.382490 * 100, metric = 5.43% * 100;
 Minibatch[1901-2000]: loss = 0.379888 * 100, metric = 5.39% * 100;
Finished Epoch[61 of 200]: [Training] loss = 0.381090 * 2000, metric = 5.44% * 2000 848.494s (  2.4 samples/s);
Finished Evaluation [61]: Minibatch[1-2000]: metric = 13.09% * 2000;
 Minibatch[   1- 100]: loss = 0.373978 * 100, metric = 5.19% * 100;
 Minibatch[ 101- 200]: loss = 0.378997 * 100, metric = 5.29% * 100;
 Minibatch[ 201- 300]: loss = 0.384203 * 100, metric = 5.39% * 100;
 Minibatch[ 301- 400]: loss = 0.388491 * 100, metric = 5.50% * 100;
 Minibatch[ 401- 500]: loss = 0.385502 * 100, metric = 5.38% * 100;
 Minibatch[ 501- 600]: loss = 0.378701 * 100, metric = 5.40% * 100;
 Minibatch[ 601- 700]: loss = 0.385376 * 100, metric = 5.54% * 100;
 Minibatch[ 701- 800]: loss = 0.383449 * 100, metric = 5.57% * 100;
 Minibatch[ 801- 900]: loss = 0.385102 * 100, metric = 5.46% * 100;
 Minibatch[ 901-1000]: loss = 0.397984 * 100, metric = 5.81% * 100;
 Minibatch[1001-1100]: loss = 0.362233 * 100, metric = 5.19% * 100;
 Minibatch[1101-1200]: loss = 0.394838 * 100, metric = 5.70% * 100;
 Minibatch[1201-1300]: loss = 0.377602 * 100, metric = 5.42% * 100;
 Minibatch[1301-1400]: loss = 0.393289 * 100, metric = 5.68% * 100;
 Minibatch[1401-1500]: loss = 0.368642 * 100, metric = 5.26% * 100;
 Minibatch[1501-1600]: loss = 0.372597 * 100, metric = 5.05% * 100;
 Minibatch[1601-1700]: loss = 0.384751 * 100, metric = 5.75% * 100;
 Minibatch[1701-1800]: loss = 0.397550 * 100, metric = 5.78% * 100;
 Minibatch[1801-1900]: loss = 0.393346 * 100, metric = 5.84% * 100;
 Minibatch[1901-2000]: loss = 0.387826 * 100, metric = 5.71% * 100;
Finished Epoch[62 of 200]: [Training] loss = 0.383723 * 2000, metric = 5.50% * 2000 845.006s (  2.4 samples/s);
Finished Evaluation [62]: Minibatch[1-2000]: metric = 12.81% * 2000;
 Minibatch[   1- 100]: loss = 0.384027 * 100, metric = 5.61% * 100;
 Minibatch[ 101- 200]: loss = 0.374913 * 100, metric = 5.37% * 100;
 Minibatch[ 201- 300]: loss = 0.391722 * 100, metric = 5.75% * 100;
 Minibatch[ 301- 400]: loss = 0.364778 * 100, metric = 5.26% * 100;
 Minibatch[ 401- 500]: loss = 0.373843 * 100, metric = 5.16% * 100;
 Minibatch[ 501- 600]: loss = 0.373615 * 100, metric = 5.27% * 100;
 Minibatch[ 601- 700]: loss = 0.386493 * 100, metric = 5.62% * 100;
 Minibatch[ 701- 800]: loss = 0.385882 * 100, metric = 5.69% * 100;
 Minibatch[ 801- 900]: loss = 0.373634 * 100, metric = 5.29% * 100;
 Minibatch[ 901-1000]: loss = 0.373523 * 100, metric = 5.17% * 100;
 Minibatch[1001-1100]: loss = 0.379113 * 100, metric = 5.45% * 100;
 Minibatch[1101-1200]: loss = 0.367184 * 100, metric = 5.37% * 100;
 Minibatch[1201-1300]: loss = 0.379071 * 100, metric = 5.32% * 100;
 Minibatch[1301-1400]: loss = 0.385877 * 100, metric = 5.52% * 100;
 Minibatch[1401-1500]: loss = 0.367657 * 100, metric = 5.19% * 100;
 Minibatch[1501-1600]: loss = 0.373997 * 100, metric = 5.30% * 100;
 Minibatch[1601-1700]: loss = 0.373254 * 100, metric = 5.29% * 100;
 Minibatch[1701-1800]: loss = 0.363005 * 100, metric = 5.01% * 100;
 Minibatch[1801-1900]: loss = 0.371736 * 100, metric = 5.09% * 100;
 Minibatch[1901-2000]: loss = 0.379924 * 100, metric = 5.46% * 100;
Finished Epoch[63 of 200]: [Training] loss = 0.376162 * 2000, metric = 5.36% * 2000 838.721s (  2.4 samples/s);
Finished Evaluation [63]: Minibatch[1-2000]: metric = 13.01% * 2000;
 Minibatch[   1- 100]: loss = 0.368279 * 100, metric = 5.25% * 100;
 Minibatch[ 101- 200]: loss = 0.382720 * 100, metric = 5.49% * 100;
 Minibatch[ 201- 300]: loss = 0.382989 * 100, metric = 5.53% * 100;
 Minibatch[ 301- 400]: loss = 0.382617 * 100, metric = 5.48% * 100;
 Minibatch[ 401- 500]: loss = 0.377453 * 100, metric = 5.46% * 100;
 Minibatch[ 501- 600]: loss = 0.378517 * 100, metric = 5.34% * 100;
 Minibatch[ 601- 700]: loss = 0.363461 * 100, metric = 5.02% * 100;
 Minibatch[ 701- 800]: loss = 0.376523 * 100, metric = 5.54% * 100;
 Minibatch[ 801- 900]: loss = 0.375765 * 100, metric = 5.37% * 100;
 Minibatch[ 901-1000]: loss = 0.366599 * 100, metric = 5.12% * 100;
 Minibatch[1001-1100]: loss = 0.374533 * 100, metric = 5.24% * 100;
 Minibatch[1101-1200]: loss = 0.373178 * 100, metric = 5.32% * 100;
 Minibatch[1201-1300]: loss = 0.364795 * 100, metric = 5.29% * 100;
 Minibatch[1301-1400]: loss = 0.386228 * 100, metric = 5.69% * 100;
 Minibatch[1401-1500]: loss = 0.379421 * 100, metric = 5.64% * 100;
 Minibatch[1501-1600]: loss = 0.380814 * 100, metric = 5.50% * 100;
 Minibatch[1601-1700]: loss = 0.356743 * 100, metric = 5.10% * 100;
 Minibatch[1701-1800]: loss = 0.374451 * 100, metric = 5.20% * 100;
 Minibatch[1801-1900]: loss = 0.381441 * 100, metric = 5.65% * 100;
 Minibatch[1901-2000]: loss = 0.365385 * 100, metric = 5.42% * 100;
Finished Epoch[64 of 200]: [Training] loss = 0.374596 * 2000, metric = 5.38% * 2000 861.636s (  2.3 samples/s);
Finished Evaluation [64]: Minibatch[1-2000]: metric = 13.96% * 2000;
 Minibatch[   1- 100]: loss = 0.359845 * 100, metric = 5.22% * 100;
 Minibatch[ 101- 200]: loss = 0.372262 * 100, metric = 5.00% * 100;
 Minibatch[ 201- 300]: loss = 0.375696 * 100, metric = 5.33% * 100;
 Minibatch[ 301- 400]: loss = 0.382978 * 100, metric = 5.65% * 100;
 Minibatch[ 401- 500]: loss = 0.365838 * 100, metric = 5.01% * 100;
 Minibatch[ 501- 600]: loss = 0.377109 * 100, metric = 5.42% * 100;
 Minibatch[ 601- 700]: loss = 0.368508 * 100, metric = 5.26% * 100;
 Minibatch[ 701- 800]: loss = 0.386115 * 100, metric = 5.67% * 100;
 Minibatch[ 801- 900]: loss = 0.370457 * 100, metric = 5.26% * 100;
 Minibatch[ 901-1000]: loss = 0.376420 * 100, metric = 5.36% * 100;
 Minibatch[1001-1100]: loss = 0.368541 * 100, metric = 5.33% * 100;
 Minibatch[1101-1200]: loss = 0.371678 * 100, metric = 5.28% * 100;
 Minibatch[1201-1300]: loss = 0.384059 * 100, metric = 5.47% * 100;
 Minibatch[1301-1400]: loss = 0.369124 * 100, metric = 5.14% * 100;
 Minibatch[1401-1500]: loss = 0.364899 * 100, metric = 5.13% * 100;
 Minibatch[1501-1600]: loss = 0.362023 * 100, metric = 4.96% * 100;
 Minibatch[1601-1700]: loss = 0.383182 * 100, metric = 5.32% * 100;
 Minibatch[1701-1800]: loss = 0.372202 * 100, metric = 5.30% * 100;
 Minibatch[1801-1900]: loss = 0.372529 * 100, metric = 5.21% * 100;
 Minibatch[1901-2000]: loss = 0.373423 * 100, metric = 5.14% * 100;
Finished Epoch[65 of 200]: [Training] loss = 0.372844 * 2000, metric = 5.27% * 2000 868.301s (  2.3 samples/s);
Finished Evaluation [65]: Minibatch[1-2000]: metric = 12.89% * 2000;
 Minibatch[   1- 100]: loss = 0.369008 * 100, metric = 5.26% * 100;
 Minibatch[ 101- 200]: loss = 0.371200 * 100, metric = 5.10% * 100;
 Minibatch[ 201- 300]: loss = 0.371709 * 100, metric = 5.13% * 100;
 Minibatch[ 301- 400]: loss = 0.367073 * 100, metric = 5.21% * 100;
 Minibatch[ 401- 500]: loss = 0.370512 * 100, metric = 5.05% * 100;
 Minibatch[ 501- 600]: loss = 0.368340 * 100, metric = 5.01% * 100;
 Minibatch[ 601- 700]: loss = 0.365029 * 100, metric = 5.10% * 100;
 Minibatch[ 701- 800]: loss = 0.368562 * 100, metric = 5.17% * 100;
 Minibatch[ 801- 900]: loss = 0.348769 * 100, metric = 4.56% * 100;
 Minibatch[ 901-1000]: loss = 0.352643 * 100, metric = 4.86% * 100;
 Minibatch[1001-1100]: loss = 0.371632 * 100, metric = 5.15% * 100;
 Minibatch[1101-1200]: loss = 0.359800 * 100, metric = 5.08% * 100;
 Minibatch[1201-1300]: loss = 0.381033 * 100, metric = 5.27% * 100;
 Minibatch[1301-1400]: loss = 0.366678 * 100, metric = 4.97% * 100;
 Minibatch[1401-1500]: loss = 0.367676 * 100, metric = 5.15% * 100;
 Minibatch[1501-1600]: loss = 0.368495 * 100, metric = 5.24% * 100;
 Minibatch[1601-1700]: loss = 0.370020 * 100, metric = 5.23% * 100;
 Minibatch[1701-1800]: loss = 0.376584 * 100, metric = 5.47% * 100;
 Minibatch[1801-1900]: loss = 0.369009 * 100, metric = 5.28% * 100;
 Minibatch[1901-2000]: loss = 0.370819 * 100, metric = 5.26% * 100;
Finished Epoch[66 of 200]: [Training] loss = 0.367730 * 2000, metric = 5.13% * 2000 858.048s (  2.3 samples/s);
Finished Evaluation [66]: Minibatch[1-2000]: metric = 14.01% * 2000;
 Minibatch[   1- 100]: loss = 0.369918 * 100, metric = 5.27% * 100;
 Minibatch[ 101- 200]: loss = 0.374107 * 100, metric = 5.40% * 100;
 Minibatch[ 201- 300]: loss = 0.368582 * 100, metric = 5.20% * 100;
 Minibatch[ 301- 400]: loss = 0.373915 * 100, metric = 5.31% * 100;
 Minibatch[ 401- 500]: loss = 0.368563 * 100, metric = 5.26% * 100;
 Minibatch[ 501- 600]: loss = 0.374299 * 100, metric = 5.34% * 100;
 Minibatch[ 601- 700]: loss = 0.365372 * 100, metric = 5.07% * 100;
 Minibatch[ 701- 800]: loss = 0.369037 * 100, metric = 5.31% * 100;
 Minibatch[ 801- 900]: loss = 0.369751 * 100, metric = 5.14% * 100;
 Minibatch[ 901-1000]: loss = 0.371548 * 100, metric = 5.35% * 100;
 Minibatch[1001-1100]: loss = 0.362394 * 100, metric = 4.97% * 100;
 Minibatch[1101-1200]: loss = 0.367993 * 100, metric = 5.06% * 100;
 Minibatch[1201-1300]: loss = 0.371087 * 100, metric = 5.12% * 100;
 Minibatch[1301-1400]: loss = 0.368981 * 100, metric = 5.18% * 100;
 Minibatch[1401-1500]: loss = 0.354329 * 100, metric = 4.80% * 100;
 Minibatch[1501-1600]: loss = 0.364241 * 100, metric = 5.11% * 100;
 Minibatch[1601-1700]: loss = 0.358823 * 100, metric = 4.96% * 100;
 Minibatch[1701-1800]: loss = 0.375364 * 100, metric = 5.32% * 100;
 Minibatch[1801-1900]: loss = 0.356395 * 100, metric = 4.93% * 100;
 Minibatch[1901-2000]: loss = 0.374117 * 100, metric = 5.25% * 100;
Finished Epoch[67 of 200]: [Training] loss = 0.367941 * 2000, metric = 5.17% * 2000 841.996s (  2.4 samples/s);
Finished Evaluation [67]: Minibatch[1-2000]: metric = 12.56% * 2000;
 Minibatch[   1- 100]: loss = 0.355690 * 100, metric = 4.88% * 100;
 Minibatch[ 101- 200]: loss = 0.380227 * 100, metric = 5.45% * 100;
 Minibatch[ 201- 300]: loss = 0.375355 * 100, metric = 5.36% * 100;
 Minibatch[ 301- 400]: loss = 0.370971 * 100, metric = 5.11% * 100;
 Minibatch[ 401- 500]: loss = 0.376129 * 100, metric = 5.02% * 100;
 Minibatch[ 501- 600]: loss = 0.357371 * 100, metric = 4.99% * 100;
 Minibatch[ 601- 700]: loss = 0.366092 * 100, metric = 5.17% * 100;
 Minibatch[ 701- 800]: loss = 0.366155 * 100, metric = 5.08% * 100;
 Minibatch[ 801- 900]: loss = 0.357734 * 100, metric = 4.87% * 100;
 Minibatch[ 901-1000]: loss = 0.369478 * 100, metric = 5.10% * 100;
 Minibatch[1001-1100]: loss = 0.375739 * 100, metric = 5.22% * 100;
 Minibatch[1101-1200]: loss = 0.375281 * 100, metric = 5.32% * 100;
 Minibatch[1201-1300]: loss = 0.362336 * 100, metric = 5.23% * 100;
 Minibatch[1301-1400]: loss = 0.356254 * 100, metric = 4.86% * 100;
 Minibatch[1401-1500]: loss = 0.359644 * 100, metric = 5.18% * 100;
 Minibatch[1501-1600]: loss = 0.360320 * 100, metric = 5.10% * 100;
 Minibatch[1601-1700]: loss = 0.356428 * 100, metric = 4.85% * 100;
 Minibatch[1701-1800]: loss = 0.371158 * 100, metric = 5.26% * 100;
 Minibatch[1801-1900]: loss = 0.368873 * 100, metric = 5.15% * 100;
 Minibatch[1901-2000]: loss = 0.349297 * 100, metric = 4.80% * 100;
Finished Epoch[68 of 200]: [Training] loss = 0.365527 * 2000, metric = 5.10% * 2000 829.333s (  2.4 samples/s);
Finished Evaluation [68]: Minibatch[1-2000]: metric = 12.40% * 2000;
0.6277816110402346
 Minibatch[   1- 100]: loss = 0.363821 * 100, metric = 5.12% * 100;
 Minibatch[ 101- 200]: loss = 0.370866 * 100, metric = 5.24% * 100;
 Minibatch[ 201- 300]: loss = 0.352696 * 100, metric = 4.86% * 100;
 Minibatch[ 301- 400]: loss = 0.371947 * 100, metric = 5.24% * 100;
 Minibatch[ 401- 500]: loss = 0.368578 * 100, metric = 5.09% * 100;
 Minibatch[ 501- 600]: loss = 0.372344 * 100, metric = 5.31% * 100;
 Minibatch[ 601- 700]: loss = 0.363158 * 100, metric = 4.85% * 100;
 Minibatch[ 701- 800]: loss = 0.364171 * 100, metric = 5.03% * 100;
 Minibatch[ 801- 900]: loss = 0.357668 * 100, metric = 5.00% * 100;
 Minibatch[ 901-1000]: loss = 0.358910 * 100, metric = 4.88% * 100;
 Minibatch[1001-1100]: loss = 0.368270 * 100, metric = 5.24% * 100;
 Minibatch[1101-1200]: loss = 0.350102 * 100, metric = 4.58% * 100;
 Minibatch[1201-1300]: loss = 0.371600 * 100, metric = 5.09% * 100;
 Minibatch[1301-1400]: loss = 0.362078 * 100, metric = 5.01% * 100;
 Minibatch[1401-1500]: loss = 0.363474 * 100, metric = 4.83% * 100;
 Minibatch[1501-1600]: loss = 0.354948 * 100, metric = 4.82% * 100;
 Minibatch[1601-1700]: loss = 0.368012 * 100, metric = 5.02% * 100;
 Minibatch[1701-1800]: loss = 0.371239 * 100, metric = 5.18% * 100;
 Minibatch[1801-1900]: loss = 0.357029 * 100, metric = 4.94% * 100;
 Minibatch[1901-2000]: loss = 0.361994 * 100, metric = 5.05% * 100;
Finished Epoch[69 of 200]: [Training] loss = 0.363645 * 2000, metric = 5.02% * 2000 808.632s (  2.5 samples/s);
Finished Evaluation [69]: Minibatch[1-2000]: metric = 12.56% * 2000;
 Minibatch[   1- 100]: loss = 0.358729 * 100, metric = 4.82% * 100;
 Minibatch[ 101- 200]: loss = 0.338090 * 100, metric = 4.61% * 100;
 Minibatch[ 201- 300]: loss = 0.359342 * 100, metric = 4.83% * 100;
 Minibatch[ 301- 400]: loss = 0.354373 * 100, metric = 4.79% * 100;
 Minibatch[ 401- 500]: loss = 0.361221 * 100, metric = 5.01% * 100;
 Minibatch[ 501- 600]: loss = 0.359303 * 100, metric = 4.95% * 100;
 Minibatch[ 601- 700]: loss = 0.359897 * 100, metric = 4.79% * 100;
 Minibatch[ 701- 800]: loss = 0.360910 * 100, metric = 5.12% * 100;
 Minibatch[ 801- 900]: loss = 0.351840 * 100, metric = 4.65% * 100;
 Minibatch[ 901-1000]: loss = 0.357239 * 100, metric = 5.05% * 100;
 Minibatch[1001-1100]: loss = 0.345125 * 100, metric = 4.59% * 100;
 Minibatch[1101-1200]: loss = 0.344758 * 100, metric = 4.60% * 100;
 Minibatch[1201-1300]: loss = 0.352780 * 100, metric = 4.91% * 100;
 Minibatch[1301-1400]: loss = 0.364367 * 100, metric = 5.16% * 100;
 Minibatch[1401-1500]: loss = 0.359518 * 100, metric = 4.80% * 100;
 Minibatch[1501-1600]: loss = 0.352625 * 100, metric = 4.73% * 100;
 Minibatch[1601-1700]: loss = 0.366156 * 100, metric = 5.08% * 100;
 Minibatch[1701-1800]: loss = 0.369692 * 100, metric = 5.00% * 100;
 Minibatch[1801-1900]: loss = 0.353253 * 100, metric = 4.68% * 100;
 Minibatch[1901-2000]: loss = 0.350716 * 100, metric = 4.90% * 100;
Finished Epoch[70 of 200]: [Training] loss = 0.355997 * 2000, metric = 4.85% * 2000 798.528s (  2.5 samples/s);
Finished Evaluation [70]: Minibatch[1-2000]: metric = 12.48% * 2000;
 Minibatch[   1- 100]: loss = 0.352522 * 100, metric = 5.00% * 100;
 Minibatch[ 101- 200]: loss = 0.348480 * 100, metric = 4.62% * 100;
 Minibatch[ 201- 300]: loss = 0.363437 * 100, metric = 4.99% * 100;
 Minibatch[ 301- 400]: loss = 0.359692 * 100, metric = 4.74% * 100;
 Minibatch[ 401- 500]: loss = 0.348620 * 100, metric = 4.70% * 100;
 Minibatch[ 501- 600]: loss = 0.353651 * 100, metric = 4.95% * 100;
 Minibatch[ 601- 700]: loss = 0.355513 * 100, metric = 4.67% * 100;
 Minibatch[ 701- 800]: loss = 0.352271 * 100, metric = 4.76% * 100;
 Minibatch[ 801- 900]: loss = 0.366281 * 100, metric = 5.00% * 100;
 Minibatch[ 901-1000]: loss = 0.353395 * 100, metric = 4.68% * 100;
 Minibatch[1001-1100]: loss = 0.360422 * 100, metric = 4.96% * 100;
 Minibatch[1101-1200]: loss = 0.352096 * 100, metric = 4.79% * 100;
 Minibatch[1201-1300]: loss = 0.352226 * 100, metric = 4.72% * 100;
 Minibatch[1301-1400]: loss = 0.344073 * 100, metric = 4.66% * 100;
 Minibatch[1401-1500]: loss = 0.352517 * 100, metric = 4.73% * 100;
 Minibatch[1501-1600]: loss = 0.365844 * 100, metric = 4.97% * 100;
 Minibatch[1601-1700]: loss = 0.351819 * 100, metric = 4.69% * 100;
 Minibatch[1701-1800]: loss = 0.355756 * 100, metric = 4.81% * 100;
 Minibatch[1801-1900]: loss = 0.354742 * 100, metric = 4.83% * 100;
 Minibatch[1901-2000]: loss = 0.360638 * 100, metric = 4.94% * 100;
Finished Epoch[71 of 200]: [Training] loss = 0.355200 * 2000, metric = 4.81% * 2000 804.522s (  2.5 samples/s);
Finished Evaluation [71]: Minibatch[1-2000]: metric = 11.94% * 2000;
 Minibatch[   1- 100]: loss = 0.371418 * 100, metric = 5.11% * 100;
 Minibatch[ 101- 200]: loss = 0.351687 * 100, metric = 4.84% * 100;
 Minibatch[ 201- 300]: loss = 0.353404 * 100, metric = 4.65% * 100;
 Minibatch[ 301- 400]: loss = 0.342694 * 100, metric = 4.66% * 100;
 Minibatch[ 401- 500]: loss = 0.349451 * 100, metric = 4.67% * 100;
 Minibatch[ 501- 600]: loss = 0.346321 * 100, metric = 4.53% * 100;
 Minibatch[ 601- 700]: loss = 0.346669 * 100, metric = 4.64% * 100;
 Minibatch[ 701- 800]: loss = 0.361604 * 100, metric = 4.78% * 100;
 Minibatch[ 801- 900]: loss = 0.347168 * 100, metric = 4.66% * 100;
 Minibatch[ 901-1000]: loss = 0.349589 * 100, metric = 4.67% * 100;
 Minibatch[1001-1100]: loss = 0.355024 * 100, metric = 4.80% * 100;
 Minibatch[1101-1200]: loss = 0.341969 * 100, metric = 4.52% * 100;
 Minibatch[1201-1300]: loss = 0.338605 * 100, metric = 4.37% * 100;
 Minibatch[1301-1400]: loss = 0.355075 * 100, metric = 4.92% * 100;
 Minibatch[1401-1500]: loss = 0.348167 * 100, metric = 4.61% * 100;
 Minibatch[1501-1600]: loss = 0.353087 * 100, metric = 4.70% * 100;
 Minibatch[1601-1700]: loss = 0.365029 * 100, metric = 4.90% * 100;
 Minibatch[1701-1800]: loss = 0.356147 * 100, metric = 4.64% * 100;
 Minibatch[1801-1900]: loss = 0.357537 * 100, metric = 4.88% * 100;
 Minibatch[1901-2000]: loss = 0.354945 * 100, metric = 4.70% * 100;
Finished Epoch[72 of 200]: [Training] loss = 0.352280 * 2000, metric = 4.71% * 2000 810.165s (  2.5 samples/s);
Finished Evaluation [72]: Minibatch[1-2000]: metric = 13.08% * 2000;
 Minibatch[   1- 100]: loss = 0.357841 * 100, metric = 4.93% * 100;
 Minibatch[ 101- 200]: loss = 0.349906 * 100, metric = 4.87% * 100;
 Minibatch[ 201- 300]: loss = 0.335688 * 100, metric = 4.47% * 100;
 Minibatch[ 301- 400]: loss = 0.354001 * 100, metric = 4.86% * 100;
 Minibatch[ 401- 500]: loss = 0.345455 * 100, metric = 4.62% * 100;
 Minibatch[ 501- 600]: loss = 0.351750 * 100, metric = 4.81% * 100;
 Minibatch[ 601- 700]: loss = 0.341357 * 100, metric = 4.63% * 100;
 Minibatch[ 701- 800]: loss = 0.338243 * 100, metric = 4.57% * 100;
 Minibatch[ 801- 900]: loss = 0.352302 * 100, metric = 4.65% * 100;
 Minibatch[ 901-1000]: loss = 0.352685 * 100, metric = 4.73% * 100;
 Minibatch[1001-1100]: loss = 0.347202 * 100, metric = 4.76% * 100;
 Minibatch[1101-1200]: loss = 0.335917 * 100, metric = 4.63% * 100;
 Minibatch[1201-1300]: loss = 0.358882 * 100, metric = 4.86% * 100;
 Minibatch[1301-1400]: loss = 0.356851 * 100, metric = 4.85% * 100;
 Minibatch[1401-1500]: loss = 0.349363 * 100, metric = 4.57% * 100;
 Minibatch[1501-1600]: loss = 0.356749 * 100, metric = 4.87% * 100;
 Minibatch[1601-1700]: loss = 0.351978 * 100, metric = 4.72% * 100;
 Minibatch[1701-1800]: loss = 0.349691 * 100, metric = 4.75% * 100;
 Minibatch[1801-1900]: loss = 0.345607 * 100, metric = 4.65% * 100;
 Minibatch[1901-2000]: loss = 0.350941 * 100, metric = 4.90% * 100;
Finished Epoch[73 of 200]: [Training] loss = 0.349120 * 2000, metric = 4.74% * 2000 813.806s (  2.5 samples/s);
Finished Evaluation [73]: Minibatch[1-2000]: metric = 12.03% * 2000;
 Minibatch[   1- 100]: loss = 0.333813 * 100, metric = 4.59% * 100;
 Minibatch[ 101- 200]: loss = 0.349271 * 100, metric = 4.83% * 100;
 Minibatch[ 201- 300]: loss = 0.343585 * 100, metric = 4.52% * 100;
 Minibatch[ 301- 400]: loss = 0.341229 * 100, metric = 4.57% * 100;
 Minibatch[ 401- 500]: loss = 0.353231 * 100, metric = 4.90% * 100;
 Minibatch[ 501- 600]: loss = 0.351247 * 100, metric = 4.85% * 100;
 Minibatch[ 601- 700]: loss = 0.350854 * 100, metric = 4.63% * 100;
 Minibatch[ 701- 800]: loss = 0.344094 * 100, metric = 4.68% * 100;
 Minibatch[ 801- 900]: loss = 0.356676 * 100, metric = 4.88% * 100;
 Minibatch[ 901-1000]: loss = 0.354498 * 100, metric = 4.96% * 100;
 Minibatch[1001-1100]: loss = 0.346881 * 100, metric = 4.68% * 100;
 Minibatch[1101-1200]: loss = 0.359127 * 100, metric = 5.05% * 100;
 Minibatch[1201-1300]: loss = 0.341529 * 100, metric = 4.63% * 100;
 Minibatch[1301-1400]: loss = 0.344999 * 100, metric = 4.57% * 100;
 Minibatch[1401-1500]: loss = 0.341122 * 100, metric = 4.38% * 100;
 Minibatch[1501-1600]: loss = 0.358954 * 100, metric = 4.87% * 100;
 Minibatch[1601-1700]: loss = 0.333878 * 100, metric = 4.26% * 100;
 Minibatch[1701-1800]: loss = 0.338882 * 100, metric = 4.48% * 100;
 Minibatch[1801-1900]: loss = 0.339127 * 100, metric = 4.38% * 100;
 Minibatch[1901-2000]: loss = 0.351097 * 100, metric = 4.63% * 100;
Finished Epoch[74 of 200]: [Training] loss = 0.346705 * 2000, metric = 4.67% * 2000 821.814s (  2.4 samples/s);
Finished Evaluation [74]: Minibatch[1-2000]: metric = 11.83% * 2000;
0.6274862519837916
 Minibatch[   1- 100]: loss = 0.339764 * 100, metric = 4.60% * 100;
 Minibatch[ 101- 200]: loss = 0.349775 * 100, metric = 4.88% * 100;
 Minibatch[ 201- 300]: loss = 0.341796 * 100, metric = 4.62% * 100;
 Minibatch[ 301- 400]: loss = 0.344295 * 100, metric = 4.58% * 100;
 Minibatch[ 401- 500]: loss = 0.342859 * 100, metric = 4.64% * 100;
 Minibatch[ 501- 600]: loss = 0.344925 * 100, metric = 4.79% * 100;
 Minibatch[ 601- 700]: loss = 0.359457 * 100, metric = 4.90% * 100;
 Minibatch[ 701- 800]: loss = 0.348914 * 100, metric = 4.80% * 100;
 Minibatch[ 801- 900]: loss = 0.351217 * 100, metric = 4.81% * 100;
 Minibatch[ 901-1000]: loss = 0.348126 * 100, metric = 4.59% * 100;
 Minibatch[1001-1100]: loss = 0.345235 * 100, metric = 4.69% * 100;
 Minibatch[1101-1200]: loss = 0.342845 * 100, metric = 4.63% * 100;
 Minibatch[1201-1300]: loss = 0.348044 * 100, metric = 4.71% * 100;
 Minibatch[1301-1400]: loss = 0.331595 * 100, metric = 4.19% * 100;
 Minibatch[1401-1500]: loss = 0.339014 * 100, metric = 4.41% * 100;
 Minibatch[1501-1600]: loss = 0.341083 * 100, metric = 4.61% * 100;
 Minibatch[1601-1700]: loss = 0.340909 * 100, metric = 4.62% * 100;
 Minibatch[1701-1800]: loss = 0.337495 * 100, metric = 4.56% * 100;
 Minibatch[1801-1900]: loss = 0.344785 * 100, metric = 4.45% * 100;
 Minibatch[1901-2000]: loss = 0.346401 * 100, metric = 4.44% * 100;
Finished Epoch[75 of 200]: [Training] loss = 0.344427 * 2000, metric = 4.63% * 2000 824.100s (  2.4 samples/s);
Finished Evaluation [75]: Minibatch[1-2000]: metric = 12.42% * 2000;
 Minibatch[   1- 100]: loss = 0.342803 * 100, metric = 4.33% * 100;
 Minibatch[ 101- 200]: loss = 0.349968 * 100, metric = 4.45% * 100;
 Minibatch[ 201- 300]: loss = 0.360940 * 100, metric = 4.89% * 100;
 Minibatch[ 301- 400]: loss = 0.344972 * 100, metric = 4.62% * 100;
 Minibatch[ 401- 500]: loss = 0.348194 * 100, metric = 4.63% * 100;
 Minibatch[ 501- 600]: loss = 0.324753 * 100, metric = 4.21% * 100;
 Minibatch[ 601- 700]: loss = 0.334909 * 100, metric = 4.42% * 100;
 Minibatch[ 701- 800]: loss = 0.334531 * 100, metric = 4.42% * 100;
 Minibatch[ 801- 900]: loss = 0.349071 * 100, metric = 4.71% * 100;
 Minibatch[ 901-1000]: loss = 0.345971 * 100, metric = 4.61% * 100;
 Minibatch[1001-1100]: loss = 0.342732 * 100, metric = 4.48% * 100;
 Minibatch[1101-1200]: loss = 0.340994 * 100, metric = 4.44% * 100;
 Minibatch[1201-1300]: loss = 0.346259 * 100, metric = 4.56% * 100;
 Minibatch[1301-1400]: loss = 0.350511 * 100, metric = 4.77% * 100;
 Minibatch[1401-1500]: loss = 0.350465 * 100, metric = 4.61% * 100;
 Minibatch[1501-1600]: loss = 0.341132 * 100, metric = 4.57% * 100;
 Minibatch[1601-1700]: loss = 0.342099 * 100, metric = 4.68% * 100;
 Minibatch[1701-1800]: loss = 0.326611 * 100, metric = 4.39% * 100;
 Minibatch[1801-1900]: loss = 0.337519 * 100, metric = 4.63% * 100;
 Minibatch[1901-2000]: loss = 0.327047 * 100, metric = 4.44% * 100;
Finished Epoch[76 of 200]: [Training] loss = 0.342074 * 2000, metric = 4.54% * 2000 830.244s (  2.4 samples/s);
Finished Evaluation [76]: Minibatch[1-2000]: metric = 13.23% * 2000;
 Minibatch[   1- 100]: loss = 0.342895 * 100, metric = 4.52% * 100;
 Minibatch[ 101- 200]: loss = 0.341040 * 100, metric = 4.38% * 100;
 Minibatch[ 201- 300]: loss = 0.333582 * 100, metric = 4.44% * 100;
 Minibatch[ 301- 400]: loss = 0.347668 * 100, metric = 4.64% * 100;
 Minibatch[ 401- 500]: loss = 0.344761 * 100, metric = 4.80% * 100;
 Minibatch[ 501- 600]: loss = 0.325163 * 100, metric = 4.21% * 100;
 Minibatch[ 601- 700]: loss = 0.342762 * 100, metric = 4.54% * 100;
 Minibatch[ 701- 800]: loss = 0.340335 * 100, metric = 4.51% * 100;
 Minibatch[ 801- 900]: loss = 0.339792 * 100, metric = 4.50% * 100;
 Minibatch[ 901-1000]: loss = 0.334474 * 100, metric = 4.28% * 100;
 Minibatch[1001-1100]: loss = 0.333898 * 100, metric = 4.44% * 100;
 Minibatch[1101-1200]: loss = 0.347763 * 100, metric = 4.62% * 100;
 Minibatch[1201-1300]: loss = 0.349865 * 100, metric = 4.76% * 100;
 Minibatch[1301-1400]: loss = 0.327587 * 100, metric = 4.19% * 100;
 Minibatch[1401-1500]: loss = 0.354113 * 100, metric = 4.72% * 100;
 Minibatch[1501-1600]: loss = 0.339432 * 100, metric = 4.54% * 100;
 Minibatch[1601-1700]: loss = 0.332891 * 100, metric = 4.30% * 100;
 Minibatch[1701-1800]: loss = 0.336226 * 100, metric = 4.51% * 100;
 Minibatch[1801-1900]: loss = 0.343878 * 100, metric = 4.58% * 100;
 Minibatch[1901-2000]: loss = 0.338922 * 100, metric = 4.57% * 100;
Finished Epoch[77 of 200]: [Training] loss = 0.339852 * 2000, metric = 4.50% * 2000 835.878s (  2.4 samples/s);
Finished Evaluation [77]: Minibatch[1-2000]: metric = 12.57% * 2000;
 Minibatch[   1- 100]: loss = 0.335144 * 100, metric = 4.28% * 100;
 Minibatch[ 101- 200]: loss = 0.332688 * 100, metric = 4.31% * 100;
 Minibatch[ 201- 300]: loss = 0.320982 * 100, metric = 4.20% * 100;
 Minibatch[ 301- 400]: loss = 0.335764 * 100, metric = 4.41% * 100;
 Minibatch[ 401- 500]: loss = 0.343341 * 100, metric = 4.45% * 100;
 Minibatch[ 501- 600]: loss = 0.346145 * 100, metric = 4.60% * 100;
 Minibatch[ 601- 700]: loss = 0.336389 * 100, metric = 4.58% * 100;
 Minibatch[ 701- 800]: loss = 0.341493 * 100, metric = 4.40% * 100;
 Minibatch[ 801- 900]: loss = 0.330982 * 100, metric = 4.22% * 100;
 Minibatch[ 901-1000]: loss = 0.348406 * 100, metric = 4.60% * 100;
 Minibatch[1001-1100]: loss = 0.344122 * 100, metric = 4.63% * 100;
 Minibatch[1101-1200]: loss = 0.335537 * 100, metric = 4.36% * 100;
 Minibatch[1201-1300]: loss = 0.349092 * 100, metric = 4.76% * 100;
 Minibatch[1301-1400]: loss = 0.340522 * 100, metric = 4.34% * 100;
 Minibatch[1401-1500]: loss = 0.343576 * 100, metric = 4.29% * 100;
 Minibatch[1501-1600]: loss = 0.331665 * 100, metric = 4.39% * 100;
 Minibatch[1601-1700]: loss = 0.330230 * 100, metric = 4.27% * 100;
 Minibatch[1701-1800]: loss = 0.340984 * 100, metric = 4.75% * 100;
 Minibatch[1801-1900]: loss = 0.341356 * 100, metric = 4.70% * 100;
 Minibatch[1901-2000]: loss = 0.344614 * 100, metric = 4.64% * 100;
Finished Epoch[78 of 200]: [Training] loss = 0.338652 * 2000, metric = 4.46% * 2000 831.655s (  2.4 samples/s);
Finished Evaluation [78]: Minibatch[1-2000]: metric = 12.59% * 2000;
 Minibatch[   1- 100]: loss = 0.326329 * 100, metric = 4.21% * 100;
 Minibatch[ 101- 200]: loss = 0.339757 * 100, metric = 4.48% * 100;
 Minibatch[ 201- 300]: loss = 0.339557 * 100, metric = 4.48% * 100;
 Minibatch[ 301- 400]: loss = 0.339181 * 100, metric = 4.22% * 100;
 Minibatch[ 401- 500]: loss = 0.343302 * 100, metric = 4.42% * 100;
 Minibatch[ 501- 600]: loss = 0.333717 * 100, metric = 4.20% * 100;
 Minibatch[ 601- 700]: loss = 0.337290 * 100, metric = 4.49% * 100;
 Minibatch[ 701- 800]: loss = 0.340215 * 100, metric = 4.52% * 100;
 Minibatch[ 801- 900]: loss = 0.347389 * 100, metric = 4.52% * 100;
 Minibatch[ 901-1000]: loss = 0.342527 * 100, metric = 4.51% * 100;
 Minibatch[1001-1100]: loss = 0.349062 * 100, metric = 4.82% * 100;
 Minibatch[1101-1200]: loss = 0.326271 * 100, metric = 4.19% * 100;
 Minibatch[1201-1300]: loss = 0.342669 * 100, metric = 4.68% * 100;
 Minibatch[1301-1400]: loss = 0.335262 * 100, metric = 4.42% * 100;
 Minibatch[1401-1500]: loss = 0.341910 * 100, metric = 4.60% * 100;
 Minibatch[1501-1600]: loss = 0.333560 * 100, metric = 4.31% * 100;
 Minibatch[1601-1700]: loss = 0.340970 * 100, metric = 4.42% * 100;
 Minibatch[1701-1800]: loss = 0.333146 * 100, metric = 4.30% * 100;
 Minibatch[1801-1900]: loss = 0.329785 * 100, metric = 4.34% * 100;
 Minibatch[1901-2000]: loss = 0.349291 * 100, metric = 4.65% * 100;
Finished Epoch[79 of 200]: [Training] loss = 0.338560 * 2000, metric = 4.44% * 2000 825.728s (  2.4 samples/s);
Finished Evaluation [79]: Minibatch[1-2000]: metric = 11.96% * 2000;
0.6258303503803909
 Minibatch[   1- 100]: loss = 0.326164 * 100, metric = 4.21% * 100;
 Minibatch[ 101- 200]: loss = 0.341191 * 100, metric = 4.53% * 100;
 Minibatch[ 201- 300]: loss = 0.326375 * 100, metric = 4.14% * 100;
 Minibatch[ 301- 400]: loss = 0.322738 * 100, metric = 4.02% * 100;
 Minibatch[ 401- 500]: loss = 0.342816 * 100, metric = 4.44% * 100;
 Minibatch[ 501- 600]: loss = 0.332798 * 100, metric = 4.29% * 100;
 Minibatch[ 601- 700]: loss = 0.338761 * 100, metric = 4.54% * 100;
 Minibatch[ 701- 800]: loss = 0.333027 * 100, metric = 4.28% * 100;
 Minibatch[ 801- 900]: loss = 0.335474 * 100, metric = 4.36% * 100;
 Minibatch[ 901-1000]: loss = 0.321279 * 100, metric = 4.20% * 100;
 Minibatch[1001-1100]: loss = 0.334469 * 100, metric = 4.46% * 100;
 Minibatch[1101-1200]: loss = 0.329959 * 100, metric = 4.19% * 100;
 Minibatch[1201-1300]: loss = 0.317609 * 100, metric = 4.00% * 100;
 Minibatch[1301-1400]: loss = 0.329310 * 100, metric = 4.06% * 100;
 Minibatch[1401-1500]: loss = 0.328886 * 100, metric = 4.03% * 100;
 Minibatch[1501-1600]: loss = 0.322334 * 100, metric = 4.12% * 100;
 Minibatch[1601-1700]: loss = 0.347234 * 100, metric = 4.61% * 100;
 Minibatch[1701-1800]: loss = 0.340375 * 100, metric = 4.30% * 100;
 Minibatch[1801-1900]: loss = 0.337051 * 100, metric = 4.19% * 100;
 Minibatch[1901-2000]: loss = 0.329302 * 100, metric = 4.15% * 100;
Finished Epoch[80 of 200]: [Training] loss = 0.331858 * 2000, metric = 4.26% * 2000 823.853s (  2.4 samples/s);
Finished Evaluation [80]: Minibatch[1-2000]: metric = 12.05% * 2000;
 Minibatch[   1- 100]: loss = 0.327869 * 100, metric = 4.26% * 100;
 Minibatch[ 101- 200]: loss = 0.329610 * 100, metric = 4.32% * 100;
 Minibatch[ 201- 300]: loss = 0.334475 * 100, metric = 4.27% * 100;
 Minibatch[ 301- 400]: loss = 0.339233 * 100, metric = 4.32% * 100;
 Minibatch[ 401- 500]: loss = 0.337226 * 100, metric = 4.32% * 100;
 Minibatch[ 501- 600]: loss = 0.356065 * 100, metric = 4.59% * 100;
 Minibatch[ 601- 700]: loss = 0.340576 * 100, metric = 4.45% * 100;
 Minibatch[ 701- 800]: loss = 0.335555 * 100, metric = 4.35% * 100;
 Minibatch[ 801- 900]: loss = 0.344508 * 100, metric = 4.43% * 100;
 Minibatch[ 901-1000]: loss = 0.327673 * 100, metric = 4.29% * 100;
 Minibatch[1001-1100]: loss = 0.339973 * 100, metric = 4.44% * 100;
 Minibatch[1101-1200]: loss = 0.339226 * 100, metric = 4.62% * 100;
 Minibatch[1201-1300]: loss = 0.336804 * 100, metric = 4.49% * 100;
 Minibatch[1301-1400]: loss = 0.338662 * 100, metric = 4.54% * 100;
 Minibatch[1401-1500]: loss = 0.330558 * 100, metric = 4.10% * 100;
 Minibatch[1501-1600]: loss = 0.338591 * 100, metric = 4.32% * 100;
 Minibatch[1601-1700]: loss = 0.332977 * 100, metric = 4.27% * 100;
 Minibatch[1701-1800]: loss = 0.338254 * 100, metric = 4.48% * 100;
 Minibatch[1801-1900]: loss = 0.332802 * 100, metric = 4.10% * 100;
 Minibatch[1901-2000]: loss = 0.334955 * 100, metric = 4.34% * 100;
Finished Epoch[81 of 200]: [Training] loss = 0.336780 * 2000, metric = 4.37% * 2000 825.278s (  2.4 samples/s);
Finished Evaluation [81]: Minibatch[1-2000]: metric = 12.46% * 2000;
 Minibatch[   1- 100]: loss = 0.341242 * 100, metric = 4.37% * 100;
 Minibatch[ 101- 200]: loss = 0.333982 * 100, metric = 4.20% * 100;
 Minibatch[ 201- 300]: loss = 0.331578 * 100, metric = 4.22% * 100;
 Minibatch[ 301- 400]: loss = 0.336991 * 100, metric = 4.46% * 100;
 Minibatch[ 401- 500]: loss = 0.337498 * 100, metric = 4.36% * 100;
 Minibatch[ 501- 600]: loss = 0.337364 * 100, metric = 4.44% * 100;
 Minibatch[ 601- 700]: loss = 0.332619 * 100, metric = 4.24% * 100;
 Minibatch[ 701- 800]: loss = 0.329114 * 100, metric = 4.05% * 100;
 Minibatch[ 801- 900]: loss = 0.340162 * 100, metric = 4.18% * 100;
 Minibatch[ 901-1000]: loss = 0.320876 * 100, metric = 4.10% * 100;
 Minibatch[1001-1100]: loss = 0.338354 * 100, metric = 4.38% * 100;
 Minibatch[1101-1200]: loss = 0.339946 * 100, metric = 4.47% * 100;
 Minibatch[1201-1300]: loss = 0.329967 * 100, metric = 4.20% * 100;
 Minibatch[1301-1400]: loss = 0.336060 * 100, metric = 4.26% * 100;
 Minibatch[1401-1500]: loss = 0.338874 * 100, metric = 4.18% * 100;
 Minibatch[1501-1600]: loss = 0.336882 * 100, metric = 4.20% * 100;
 Minibatch[1601-1700]: loss = 0.329308 * 100, metric = 4.18% * 100;
 Minibatch[1701-1800]: loss = 0.338683 * 100, metric = 4.33% * 100;
 Minibatch[1801-1900]: loss = 0.330091 * 100, metric = 4.19% * 100;
 Minibatch[1901-2000]: loss = 0.322863 * 100, metric = 4.12% * 100;
Finished Epoch[82 of 200]: [Training] loss = 0.334123 * 2000, metric = 4.26% * 2000 815.821s (  2.5 samples/s);
Finished Evaluation [82]: Minibatch[1-2000]: metric = 12.33% * 2000;
 Minibatch[   1- 100]: loss = 0.319236 * 100, metric = 3.84% * 100;
 Minibatch[ 101- 200]: loss = 0.330079 * 100, metric = 4.26% * 100;
 Minibatch[ 201- 300]: loss = 0.314518 * 100, metric = 3.86% * 100;
 Minibatch[ 301- 400]: loss = 0.336923 * 100, metric = 4.40% * 100;
 Minibatch[ 401- 500]: loss = 0.311174 * 100, metric = 3.87% * 100;
 Minibatch[ 501- 600]: loss = 0.328254 * 100, metric = 4.16% * 100;
 Minibatch[ 601- 700]: loss = 0.342652 * 100, metric = 4.27% * 100;
 Minibatch[ 701- 800]: loss = 0.321650 * 100, metric = 4.02% * 100;
 Minibatch[ 801- 900]: loss = 0.338282 * 100, metric = 4.33% * 100;
 Minibatch[ 901-1000]: loss = 0.343355 * 100, metric = 4.53% * 100;
 Minibatch[1001-1100]: loss = 0.328785 * 100, metric = 4.07% * 100;
 Minibatch[1101-1200]: loss = 0.326074 * 100, metric = 4.18% * 100;
 Minibatch[1201-1300]: loss = 0.328723 * 100, metric = 4.11% * 100;
 Minibatch[1301-1400]: loss = 0.314396 * 100, metric = 3.72% * 100;
 Minibatch[1401-1500]: loss = 0.327187 * 100, metric = 3.89% * 100;
 Minibatch[1501-1600]: loss = 0.337106 * 100, metric = 4.26% * 100;
 Minibatch[1601-1700]: loss = 0.329851 * 100, metric = 3.96% * 100;
 Minibatch[1701-1800]: loss = 0.320004 * 100, metric = 4.07% * 100;
 Minibatch[1801-1900]: loss = 0.329333 * 100, metric = 4.21% * 100;
 Minibatch[1901-2000]: loss = 0.325309 * 100, metric = 4.27% * 100;
Finished Epoch[83 of 200]: [Training] loss = 0.327645 * 2000, metric = 4.11% * 2000 829.583s (  2.4 samples/s);
Finished Evaluation [83]: Minibatch[1-2000]: metric = 12.52% * 2000;
 Minibatch[   1- 100]: loss = 0.333929 * 100, metric = 4.09% * 100;
 Minibatch[ 101- 200]: loss = 0.333713 * 100, metric = 4.26% * 100;
 Minibatch[ 201- 300]: loss = 0.330327 * 100, metric = 4.11% * 100;
 Minibatch[ 301- 400]: loss = 0.326217 * 100, metric = 4.23% * 100;
 Minibatch[ 401- 500]: loss = 0.336422 * 100, metric = 4.16% * 100;
 Minibatch[ 501- 600]: loss = 0.332205 * 100, metric = 4.05% * 100;
 Minibatch[ 601- 700]: loss = 0.337300 * 100, metric = 4.38% * 100;
 Minibatch[ 701- 800]: loss = 0.325841 * 100, metric = 4.19% * 100;
 Minibatch[ 801- 900]: loss = 0.319941 * 100, metric = 4.11% * 100;
 Minibatch[ 901-1000]: loss = 0.339889 * 100, metric = 4.42% * 100;
 Minibatch[1001-1100]: loss = 0.325507 * 100, metric = 4.21% * 100;
 Minibatch[1101-1200]: loss = 0.320854 * 100, metric = 4.15% * 100;
 Minibatch[1201-1300]: loss = 0.335993 * 100, metric = 4.32% * 100;
 Minibatch[1301-1400]: loss = 0.338941 * 100, metric = 4.18% * 100;
 Minibatch[1401-1500]: loss = 0.334392 * 100, metric = 4.17% * 100;
 Minibatch[1501-1600]: loss = 0.330049 * 100, metric = 4.19% * 100;
 Minibatch[1601-1700]: loss = 0.329999 * 100, metric = 4.20% * 100;
 Minibatch[1701-1800]: loss = 0.330171 * 100, metric = 4.16% * 100;
 Minibatch[1801-1900]: loss = 0.323060 * 100, metric = 4.12% * 100;
 Minibatch[1901-2000]: loss = 0.335352 * 100, metric = 4.27% * 100;
Finished Epoch[84 of 200]: [Training] loss = 0.331005 * 2000, metric = 4.20% * 2000 830.539s (  2.4 samples/s);
Finished Evaluation [84]: Minibatch[1-2000]: metric = 12.49% * 2000;
 Minibatch[   1- 100]: loss = 0.326691 * 100, metric = 4.12% * 100;
 Minibatch[ 101- 200]: loss = 0.321586 * 100, metric = 4.11% * 100;
 Minibatch[ 201- 300]: loss = 0.332230 * 100, metric = 4.30% * 100;
 Minibatch[ 301- 400]: loss = 0.329409 * 100, metric = 4.15% * 100;
 Minibatch[ 401- 500]: loss = 0.316087 * 100, metric = 4.03% * 100;
 Minibatch[ 501- 600]: loss = 0.334148 * 100, metric = 4.19% * 100;
 Minibatch[ 601- 700]: loss = 0.330061 * 100, metric = 3.98% * 100;
 Minibatch[ 701- 800]: loss = 0.326294 * 100, metric = 3.99% * 100;
 Minibatch[ 801- 900]: loss = 0.325186 * 100, metric = 4.12% * 100;
 Minibatch[ 901-1000]: loss = 0.333416 * 100, metric = 4.13% * 100;
 Minibatch[1001-1100]: loss = 0.342415 * 100, metric = 4.17% * 100;
 Minibatch[1101-1200]: loss = 0.329176 * 100, metric = 4.26% * 100;
 Minibatch[1201-1300]: loss = 0.317293 * 100, metric = 3.92% * 100;
 Minibatch[1301-1400]: loss = 0.326363 * 100, metric = 4.15% * 100;
 Minibatch[1401-1500]: loss = 0.326645 * 100, metric = 3.99% * 100;
 Minibatch[1501-1600]: loss = 0.329575 * 100, metric = 4.06% * 100;
 Minibatch[1601-1700]: loss = 0.330078 * 100, metric = 4.27% * 100;
 Minibatch[1701-1800]: loss = 0.324418 * 100, metric = 3.98% * 100;
 Minibatch[1801-1900]: loss = 0.330717 * 100, metric = 4.16% * 100;
 Minibatch[1901-2000]: loss = 0.324731 * 100, metric = 3.83% * 100;
Finished Epoch[85 of 200]: [Training] loss = 0.327826 * 2000, metric = 4.10% * 2000 825.846s (  2.4 samples/s);
Finished Evaluation [85]: Minibatch[1-2000]: metric = 12.37% * 2000;
 Minibatch[   1- 100]: loss = 0.322004 * 100, metric = 3.93% * 100;
 Minibatch[ 101- 200]: loss = 0.312488 * 100, metric = 3.78% * 100;
 Minibatch[ 201- 300]: loss = 0.338067 * 100, metric = 4.18% * 100;
 Minibatch[ 301- 400]: loss = 0.338801 * 100, metric = 4.17% * 100;
 Minibatch[ 401- 500]: loss = 0.338289 * 100, metric = 4.27% * 100;
 Minibatch[ 501- 600]: loss = 0.321806 * 100, metric = 3.96% * 100;
 Minibatch[ 601- 700]: loss = 0.318642 * 100, metric = 3.97% * 100;
 Minibatch[ 701- 800]: loss = 0.327981 * 100, metric = 4.10% * 100;
 Minibatch[ 801- 900]: loss = 0.301714 * 100, metric = 3.67% * 100;
 Minibatch[ 901-1000]: loss = 0.323645 * 100, metric = 4.01% * 100;
 Minibatch[1001-1100]: loss = 0.322533 * 100, metric = 3.82% * 100;
 Minibatch[1101-1200]: loss = 0.333840 * 100, metric = 4.16% * 100;
 Minibatch[1201-1300]: loss = 0.327142 * 100, metric = 4.04% * 100;
 Minibatch[1301-1400]: loss = 0.323678 * 100, metric = 3.98% * 100;
 Minibatch[1401-1500]: loss = 0.324641 * 100, metric = 3.95% * 100;
 Minibatch[1501-1600]: loss = 0.328016 * 100, metric = 3.90% * 100;
 Minibatch[1601-1700]: loss = 0.333647 * 100, metric = 4.09% * 100;
 Minibatch[1701-1800]: loss = 0.340200 * 100, metric = 4.17% * 100;
 Minibatch[1801-1900]: loss = 0.333628 * 100, metric = 4.06% * 100;
 Minibatch[1901-2000]: loss = 0.330369 * 100, metric = 4.04% * 100;
Finished Epoch[86 of 200]: [Training] loss = 0.327057 * 2000, metric = 4.01% * 2000 828.494s (  2.4 samples/s);
Finished Evaluation [86]: Minibatch[1-2000]: metric = 11.85% * 2000;
 Minibatch[   1- 100]: loss = 0.313024 * 100, metric = 3.83% * 100;
 Minibatch[ 101- 200]: loss = 0.331047 * 100, metric = 4.20% * 100;
 Minibatch[ 201- 300]: loss = 0.323238 * 100, metric = 3.92% * 100;
 Minibatch[ 301- 400]: loss = 0.323157 * 100, metric = 3.95% * 100;
 Minibatch[ 401- 500]: loss = 0.322937 * 100, metric = 4.12% * 100;
 Minibatch[ 501- 600]: loss = 0.329236 * 100, metric = 4.29% * 100;
 Minibatch[ 601- 700]: loss = 0.330560 * 100, metric = 4.23% * 100;
 Minibatch[ 701- 800]: loss = 0.327314 * 100, metric = 4.10% * 100;
 Minibatch[ 801- 900]: loss = 0.316429 * 100, metric = 4.00% * 100;
 Minibatch[ 901-1000]: loss = 0.324330 * 100, metric = 3.99% * 100;
 Minibatch[1001-1100]: loss = 0.323825 * 100, metric = 3.98% * 100;
 Minibatch[1101-1200]: loss = 0.305236 * 100, metric = 3.93% * 100;
 Minibatch[1201-1300]: loss = 0.320625 * 100, metric = 3.90% * 100;
 Minibatch[1301-1400]: loss = 0.315695 * 100, metric = 3.90% * 100;
 Minibatch[1401-1500]: loss = 0.320242 * 100, metric = 4.04% * 100;
 Minibatch[1501-1600]: loss = 0.318686 * 100, metric = 3.87% * 100;
 Minibatch[1601-1700]: loss = 0.323632 * 100, metric = 4.02% * 100;
 Minibatch[1701-1800]: loss = 0.322181 * 100, metric = 4.11% * 100;
 Minibatch[1801-1900]: loss = 0.326179 * 100, metric = 4.21% * 100;
 Minibatch[1901-2000]: loss = 0.324678 * 100, metric = 4.11% * 100;
Finished Epoch[87 of 200]: [Training] loss = 0.322113 * 2000, metric = 4.04% * 2000 825.909s (  2.4 samples/s);
Finished Evaluation [87]: Minibatch[1-2000]: metric = 12.72% * 2000;
 Minibatch[   1- 100]: loss = 0.330223 * 100, metric = 4.06% * 100;
 Minibatch[ 101- 200]: loss = 0.332497 * 100, metric = 4.07% * 100;
 Minibatch[ 201- 300]: loss = 0.317876 * 100, metric = 3.78% * 100;
 Minibatch[ 301- 400]: loss = 0.333671 * 100, metric = 4.24% * 100;
 Minibatch[ 401- 500]: loss = 0.327449 * 100, metric = 4.14% * 100;
 Minibatch[ 501- 600]: loss = 0.313780 * 100, metric = 3.72% * 100;
 Minibatch[ 601- 700]: loss = 0.320335 * 100, metric = 4.01% * 100;
 Minibatch[ 701- 800]: loss = 0.321556 * 100, metric = 4.04% * 100;
 Minibatch[ 801- 900]: loss = 0.332295 * 100, metric = 4.31% * 100;
 Minibatch[ 901-1000]: loss = 0.319014 * 100, metric = 3.99% * 100;
 Minibatch[1001-1100]: loss = 0.325249 * 100, metric = 4.08% * 100;
 Minibatch[1101-1200]: loss = 0.327914 * 100, metric = 4.12% * 100;
 Minibatch[1201-1300]: loss = 0.324993 * 100, metric = 3.86% * 100;
 Minibatch[1301-1400]: loss = 0.318629 * 100, metric = 3.89% * 100;
 Minibatch[1401-1500]: loss = 0.317509 * 100, metric = 4.03% * 100;
 Minibatch[1501-1600]: loss = 0.305396 * 100, metric = 3.76% * 100;
 Minibatch[1601-1700]: loss = 0.322235 * 100, metric = 4.01% * 100;
 Minibatch[1701-1800]: loss = 0.314401 * 100, metric = 4.01% * 100;
 Minibatch[1801-1900]: loss = 0.335698 * 100, metric = 4.26% * 100;
 Minibatch[1901-2000]: loss = 0.293210 * 100, metric = 3.42% * 100;
Finished Epoch[88 of 200]: [Training] loss = 0.321696 * 2000, metric = 3.99% * 2000 824.508s (  2.4 samples/s);
Finished Evaluation [88]: Minibatch[1-2000]: metric = 11.90% * 2000;
0.6249950191415846
 Minibatch[   1- 100]: loss = 0.310684 * 100, metric = 3.87% * 100;
 Minibatch[ 101- 200]: loss = 0.325586 * 100, metric = 4.27% * 100;
 Minibatch[ 201- 300]: loss = 0.312151 * 100, metric = 3.75% * 100;
 Minibatch[ 301- 400]: loss = 0.314984 * 100, metric = 3.91% * 100;
 Minibatch[ 401- 500]: loss = 0.316575 * 100, metric = 3.97% * 100;
 Minibatch[ 501- 600]: loss = 0.318159 * 100, metric = 3.97% * 100;
 Minibatch[ 601- 700]: loss = 0.325679 * 100, metric = 4.14% * 100;
 Minibatch[ 701- 800]: loss = 0.318067 * 100, metric = 3.82% * 100;
 Minibatch[ 801- 900]: loss = 0.318724 * 100, metric = 3.96% * 100;
 Minibatch[ 901-1000]: loss = 0.333781 * 100, metric = 4.21% * 100;
 Minibatch[1001-1100]: loss = 0.324033 * 100, metric = 4.06% * 100;
 Minibatch[1101-1200]: loss = 0.320090 * 100, metric = 4.05% * 100;
 Minibatch[1201-1300]: loss = 0.325992 * 100, metric = 4.13% * 100;
 Minibatch[1301-1400]: loss = 0.317934 * 100, metric = 3.89% * 100;
 Minibatch[1401-1500]: loss = 0.330851 * 100, metric = 4.21% * 100;
 Minibatch[1501-1600]: loss = 0.315846 * 100, metric = 3.78% * 100;
 Minibatch[1601-1700]: loss = 0.318618 * 100, metric = 4.11% * 100;
 Minibatch[1701-1800]: loss = 0.332593 * 100, metric = 4.19% * 100;
 Minibatch[1801-1900]: loss = 0.316146 * 100, metric = 4.06% * 100;
 Minibatch[1901-2000]: loss = 0.307003 * 100, metric = 3.80% * 100;
Finished Epoch[89 of 200]: [Training] loss = 0.320175 * 2000, metric = 4.01% * 2000 821.883s (  2.4 samples/s);
Finished Evaluation [89]: Minibatch[1-2000]: metric = 12.18% * 2000;
 Minibatch[   1- 100]: loss = 0.315004 * 100, metric = 3.81% * 100;
 Minibatch[ 101- 200]: loss = 0.312184 * 100, metric = 3.87% * 100;
 Minibatch[ 201- 300]: loss = 0.330941 * 100, metric = 4.11% * 100;
 Minibatch[ 301- 400]: loss = 0.323019 * 100, metric = 4.02% * 100;
 Minibatch[ 401- 500]: loss = 0.331230 * 100, metric = 4.02% * 100;
 Minibatch[ 501- 600]: loss = 0.341314 * 100, metric = 4.06% * 100;
 Minibatch[ 601- 700]: loss = 0.343868 * 100, metric = 4.01% * 100;
 Minibatch[ 701- 800]: loss = 0.317443 * 100, metric = 3.88% * 100;
 Minibatch[ 801- 900]: loss = 0.330774 * 100, metric = 4.10% * 100;
 Minibatch[ 901-1000]: loss = 0.336201 * 100, metric = 4.09% * 100;
 Minibatch[1001-1100]: loss = 0.313483 * 100, metric = 3.81% * 100;
 Minibatch[1101-1200]: loss = 0.304716 * 100, metric = 3.61% * 100;
 Minibatch[1201-1300]: loss = 0.309132 * 100, metric = 3.70% * 100;
 Minibatch[1301-1400]: loss = 0.315111 * 100, metric = 3.82% * 100;
 Minibatch[1401-1500]: loss = 0.323423 * 100, metric = 4.06% * 100;
 Minibatch[1501-1600]: loss = 0.324835 * 100, metric = 3.85% * 100;
 Minibatch[1601-1700]: loss = 0.308018 * 100, metric = 3.61% * 100;
 Minibatch[1701-1800]: loss = 0.313955 * 100, metric = 3.92% * 100;
 Minibatch[1801-1900]: loss = 0.321053 * 100, metric = 3.95% * 100;
 Minibatch[1901-2000]: loss = 0.320409 * 100, metric = 3.99% * 100;
Finished Epoch[90 of 200]: [Training] loss = 0.321806 * 2000, metric = 3.91% * 2000 820.411s (  2.4 samples/s);
Finished Evaluation [90]: Minibatch[1-2000]: metric = 12.86% * 2000;
 Minibatch[   1- 100]: loss = 0.308972 * 100, metric = 3.87% * 100;
 Minibatch[ 101- 200]: loss = 0.324533 * 100, metric = 4.13% * 100;
 Minibatch[ 201- 300]: loss = 0.303587 * 100, metric = 3.58% * 100;
 Minibatch[ 301- 400]: loss = 0.309941 * 100, metric = 3.70% * 100;
 Minibatch[ 401- 500]: loss = 0.322421 * 100, metric = 4.00% * 100;
 Minibatch[ 501- 600]: loss = 0.324654 * 100, metric = 4.06% * 100;
 Minibatch[ 601- 700]: loss = 0.327488 * 100, metric = 3.92% * 100;
 Minibatch[ 701- 800]: loss = 0.335116 * 100, metric = 4.33% * 100;
 Minibatch[ 801- 900]: loss = 0.317993 * 100, metric = 3.67% * 100;
 Minibatch[ 901-1000]: loss = 0.323096 * 100, metric = 3.96% * 100;
 Minibatch[1001-1100]: loss = 0.319127 * 100, metric = 3.71% * 100;
 Minibatch[1101-1200]: loss = 0.322021 * 100, metric = 3.94% * 100;
 Minibatch[1201-1300]: loss = 0.308589 * 100, metric = 3.76% * 100;
 Minibatch[1301-1400]: loss = 0.314219 * 100, metric = 3.83% * 100;
 Minibatch[1401-1500]: loss = 0.304772 * 100, metric = 3.71% * 100;
 Minibatch[1501-1600]: loss = 0.307306 * 100, metric = 3.84% * 100;
 Minibatch[1601-1700]: loss = 0.312093 * 100, metric = 3.84% * 100;
 Minibatch[1701-1800]: loss = 0.332990 * 100, metric = 4.13% * 100;
 Minibatch[1801-1900]: loss = 0.327072 * 100, metric = 3.94% * 100;
 Minibatch[1901-2000]: loss = 0.315107 * 100, metric = 3.69% * 100;
Finished Epoch[91 of 200]: [Training] loss = 0.318055 * 2000, metric = 3.88% * 2000 814.455s (  2.5 samples/s);
Finished Evaluation [91]: Minibatch[1-2000]: metric = 12.18% * 2000;
 Minibatch[   1- 100]: loss = 0.325619 * 100, metric = 3.98% * 100;
 Minibatch[ 101- 200]: loss = 0.318727 * 100, metric = 3.80% * 100;
 Minibatch[ 201- 300]: loss = 0.327538 * 100, metric = 4.12% * 100;
 Minibatch[ 301- 400]: loss = 0.318106 * 100, metric = 3.86% * 100;
 Minibatch[ 401- 500]: loss = 0.324285 * 100, metric = 3.94% * 100;
 Minibatch[ 501- 600]: loss = 0.335218 * 100, metric = 4.14% * 100;
 Minibatch[ 601- 700]: loss = 0.322691 * 100, metric = 3.99% * 100;
 Minibatch[ 701- 800]: loss = 0.322303 * 100, metric = 3.84% * 100;
 Minibatch[ 801- 900]: loss = 0.316066 * 100, metric = 3.88% * 100;
 Minibatch[ 901-1000]: loss = 0.321432 * 100, metric = 3.94% * 100;
 Minibatch[1001-1100]: loss = 0.313820 * 100, metric = 3.72% * 100;
 Minibatch[1101-1200]: loss = 0.318925 * 100, metric = 3.81% * 100;
 Minibatch[1201-1300]: loss = 0.320295 * 100, metric = 3.81% * 100;
 Minibatch[1301-1400]: loss = 0.320755 * 100, metric = 3.93% * 100;
 Minibatch[1401-1500]: loss = 0.313453 * 100, metric = 3.68% * 100;
 Minibatch[1501-1600]: loss = 0.322214 * 100, metric = 4.02% * 100;
 Minibatch[1601-1700]: loss = 0.308051 * 100, metric = 3.72% * 100;
 Minibatch[1701-1800]: loss = 0.301003 * 100, metric = 3.69% * 100;
 Minibatch[1801-1900]: loss = 0.317878 * 100, metric = 3.77% * 100;
 Minibatch[1901-2000]: loss = 0.322390 * 100, metric = 4.08% * 100;
Finished Epoch[92 of 200]: [Training] loss = 0.319538 * 2000, metric = 3.89% * 2000 806.526s (  2.5 samples/s);
Finished Evaluation [92]: Minibatch[1-2000]: metric = 11.32% * 2000;
 Minibatch[   1- 100]: loss = 0.321611 * 100, metric = 3.88% * 100;
 Minibatch[ 101- 200]: loss = 0.317718 * 100, metric = 3.79% * 100;
 Minibatch[ 201- 300]: loss = 0.325196 * 100, metric = 4.01% * 100;
 Minibatch[ 301- 400]: loss = 0.315880 * 100, metric = 3.72% * 100;
 Minibatch[ 401- 500]: loss = 0.311103 * 100, metric = 3.63% * 100;
 Minibatch[ 501- 600]: loss = 0.325323 * 100, metric = 3.97% * 100;
 Minibatch[ 601- 700]: loss = 0.318287 * 100, metric = 3.77% * 100;
 Minibatch[ 701- 800]: loss = 0.325870 * 100, metric = 3.76% * 100;
 Minibatch[ 801- 900]: loss = 0.318813 * 100, metric = 3.74% * 100;
 Minibatch[ 901-1000]: loss = 0.308395 * 100, metric = 3.52% * 100;
 Minibatch[1001-1100]: loss = 0.314014 * 100, metric = 3.75% * 100;
 Minibatch[1101-1200]: loss = 0.314889 * 100, metric = 3.53% * 100;
 Minibatch[1201-1300]: loss = 0.326459 * 100, metric = 3.81% * 100;
 Minibatch[1301-1400]: loss = 0.316767 * 100, metric = 3.67% * 100;
 Minibatch[1401-1500]: loss = 0.318884 * 100, metric = 3.83% * 100;
 Minibatch[1501-1600]: loss = 0.311076 * 100, metric = 3.65% * 100;
 Minibatch[1601-1700]: loss = 0.323387 * 100, metric = 3.79% * 100;
 Minibatch[1701-1800]: loss = 0.318198 * 100, metric = 3.57% * 100;
 Minibatch[1801-1900]: loss = 0.315807 * 100, metric = 3.62% * 100;
 Minibatch[1901-2000]: loss = 0.313497 * 100, metric = 3.67% * 100;
Finished Epoch[93 of 200]: [Training] loss = 0.318059 * 2000, metric = 3.74% * 2000 803.679s (  2.5 samples/s);
Finished Evaluation [93]: Minibatch[1-2000]: metric = 12.14% * 2000;
 Minibatch[   1- 100]: loss = 0.307458 * 100, metric = 3.85% * 100;
 Minibatch[ 101- 200]: loss = 0.318795 * 100, metric = 4.09% * 100;
 Minibatch[ 201- 300]: loss = 0.317562 * 100, metric = 3.87% * 100;
 Minibatch[ 301- 400]: loss = 0.305350 * 100, metric = 3.46% * 100;
 Minibatch[ 401- 500]: loss = 0.303502 * 100, metric = 3.71% * 100;
 Minibatch[ 501- 600]: loss = 0.306625 * 100, metric = 3.54% * 100;
 Minibatch[ 601- 700]: loss = 0.294109 * 100, metric = 3.46% * 100;
 Minibatch[ 701- 800]: loss = 0.316601 * 100, metric = 3.85% * 100;
 Minibatch[ 801- 900]: loss = 0.308396 * 100, metric = 3.60% * 100;
 Minibatch[ 901-1000]: loss = 0.310543 * 100, metric = 3.62% * 100;
 Minibatch[1001-1100]: loss = 0.333203 * 100, metric = 4.06% * 100;
 Minibatch[1101-1200]: loss = 0.324185 * 100, metric = 3.84% * 100;
 Minibatch[1201-1300]: loss = 0.315391 * 100, metric = 3.67% * 100;
 Minibatch[1301-1400]: loss = 0.312916 * 100, metric = 3.47% * 100;
 Minibatch[1401-1500]: loss = 0.317258 * 100, metric = 3.70% * 100;
 Minibatch[1501-1600]: loss = 0.322108 * 100, metric = 3.72% * 100;
 Minibatch[1601-1700]: loss = 0.305181 * 100, metric = 3.56% * 100;
 Minibatch[1701-1800]: loss = 0.312109 * 100, metric = 3.56% * 100;
 Minibatch[1801-1900]: loss = 0.316399 * 100, metric = 3.72% * 100;
 Minibatch[1901-2000]: loss = 0.309905 * 100, metric = 3.73% * 100;
Finished Epoch[94 of 200]: [Training] loss = 0.312880 * 2000, metric = 3.70% * 2000 805.197s (  2.5 samples/s);
Finished Evaluation [94]: Minibatch[1-2000]: metric = 12.27% * 2000;
 Minibatch[   1- 100]: loss = 0.303663 * 100, metric = 3.65% * 100;
 Minibatch[ 101- 200]: loss = 0.304590 * 100, metric = 3.62% * 100;
 Minibatch[ 201- 300]: loss = 0.310245 * 100, metric = 3.56% * 100;
 Minibatch[ 301- 400]: loss = 0.309301 * 100, metric = 3.64% * 100;
 Minibatch[ 401- 500]: loss = 0.304811 * 100, metric = 3.46% * 100;
 Minibatch[ 501- 600]: loss = 0.310819 * 100, metric = 3.54% * 100;
 Minibatch[ 601- 700]: loss = 0.299631 * 100, metric = 3.56% * 100;
 Minibatch[ 701- 800]: loss = 0.310175 * 100, metric = 3.74% * 100;
 Minibatch[ 801- 900]: loss = 0.308034 * 100, metric = 3.52% * 100;
 Minibatch[ 901-1000]: loss = 0.304026 * 100, metric = 3.68% * 100;
 Minibatch[1001-1100]: loss = 0.298894 * 100, metric = 3.61% * 100;
 Minibatch[1101-1200]: loss = 0.310240 * 100, metric = 3.69% * 100;
 Minibatch[1201-1300]: loss = 0.318959 * 100, metric = 3.88% * 100;
 Minibatch[1301-1400]: loss = 0.312030 * 100, metric = 3.61% * 100;
 Minibatch[1401-1500]: loss = 0.310392 * 100, metric = 3.69% * 100;
 Minibatch[1501-1600]: loss = 0.310421 * 100, metric = 3.71% * 100;
 Minibatch[1601-1700]: loss = 0.314362 * 100, metric = 3.69% * 100;
 Minibatch[1701-1800]: loss = 0.303185 * 100, metric = 3.54% * 100;
 Minibatch[1801-1900]: loss = 0.304532 * 100, metric = 3.58% * 100;
 Minibatch[1901-2000]: loss = 0.305567 * 100, metric = 3.59% * 100;
Finished Epoch[95 of 200]: [Training] loss = 0.307694 * 2000, metric = 3.63% * 2000 802.363s (  2.5 samples/s);
Finished Evaluation [95]: Minibatch[1-2000]: metric = 11.57% * 2000;
 Minibatch[   1- 100]: loss = 0.301935 * 100, metric = 3.53% * 100;
 Minibatch[ 101- 200]: loss = 0.327825 * 100, metric = 3.87% * 100;
 Minibatch[ 201- 300]: loss = 0.315723 * 100, metric = 3.78% * 100;
 Minibatch[ 301- 400]: loss = 0.304559 * 100, metric = 3.71% * 100;
 Minibatch[ 401- 500]: loss = 0.320430 * 100, metric = 3.76% * 100;
 Minibatch[ 501- 600]: loss = 0.295236 * 100, metric = 3.54% * 100;
 Minibatch[ 601- 700]: loss = 0.310099 * 100, metric = 3.61% * 100;
 Minibatch[ 701- 800]: loss = 0.326339 * 100, metric = 3.86% * 100;
 Minibatch[ 801- 900]: loss = 0.312707 * 100, metric = 3.69% * 100;
 Minibatch[ 901-1000]: loss = 0.322890 * 100, metric = 3.66% * 100;
 Minibatch[1001-1100]: loss = 0.317775 * 100, metric = 3.73% * 100;
 Minibatch[1101-1200]: loss = 0.304307 * 100, metric = 3.54% * 100;
 Minibatch[1201-1300]: loss = 0.314575 * 100, metric = 3.69% * 100;
 Minibatch[1301-1400]: loss = 0.309184 * 100, metric = 3.57% * 100;
 Minibatch[1401-1500]: loss = 0.311808 * 100, metric = 3.64% * 100;
 Minibatch[1501-1600]: loss = 0.296896 * 100, metric = 3.38% * 100;
 Minibatch[1601-1700]: loss = 0.304448 * 100, metric = 3.69% * 100;
 Minibatch[1701-1800]: loss = 0.320167 * 100, metric = 3.79% * 100;
 Minibatch[1801-1900]: loss = 0.322060 * 100, metric = 3.80% * 100;
 Minibatch[1901-2000]: loss = 0.328602 * 100, metric = 4.09% * 100;
Finished Epoch[96 of 200]: [Training] loss = 0.313378 * 2000, metric = 3.70% * 2000 802.290s (  2.5 samples/s);
Finished Evaluation [96]: Minibatch[1-2000]: metric = 12.08% * 2000;
 Minibatch[   1- 100]: loss = 0.324133 * 100, metric = 3.94% * 100;
 Minibatch[ 101- 200]: loss = 0.305777 * 100, metric = 3.62% * 100;
 Minibatch[ 201- 300]: loss = 0.300783 * 100, metric = 3.45% * 100;
 Minibatch[ 301- 400]: loss = 0.311085 * 100, metric = 3.54% * 100;
 Minibatch[ 401- 500]: loss = 0.309642 * 100, metric = 3.50% * 100;
 Minibatch[ 501- 600]: loss = 0.309968 * 100, metric = 3.61% * 100;
 Minibatch[ 601- 700]: loss = 0.303788 * 100, metric = 3.54% * 100;
 Minibatch[ 701- 800]: loss = 0.319094 * 100, metric = 3.82% * 100;
 Minibatch[ 801- 900]: loss = 0.317721 * 100, metric = 3.69% * 100;
 Minibatch[ 901-1000]: loss = 0.318922 * 100, metric = 3.58% * 100;
 Minibatch[1001-1100]: loss = 0.294401 * 100, metric = 3.42% * 100;
 Minibatch[1101-1200]: loss = 0.304909 * 100, metric = 3.40% * 100;
 Minibatch[1201-1300]: loss = 0.309659 * 100, metric = 3.70% * 100;
 Minibatch[1301-1400]: loss = 0.304052 * 100, metric = 3.42% * 100;
 Minibatch[1401-1500]: loss = 0.311792 * 100, metric = 3.48% * 100;
 Minibatch[1501-1600]: loss = 0.288110 * 100, metric = 3.43% * 100;
 Minibatch[1601-1700]: loss = 0.308696 * 100, metric = 3.61% * 100;
 Minibatch[1701-1800]: loss = 0.317290 * 100, metric = 3.70% * 100;
 Minibatch[1801-1900]: loss = 0.303955 * 100, metric = 3.48% * 100;
 Minibatch[1901-2000]: loss = 0.321025 * 100, metric = 3.70% * 100;
Finished Epoch[97 of 200]: [Training] loss = 0.309240 * 2000, metric = 3.58% * 2000 811.003s (  2.5 samples/s);
Finished Evaluation [97]: Minibatch[1-2000]: metric = 12.03% * 2000;
 Minibatch[   1- 100]: loss = 0.303820 * 100, metric = 3.53% * 100;
 Minibatch[ 101- 200]: loss = 0.296670 * 100, metric = 3.32% * 100;
 Minibatch[ 201- 300]: loss = 0.308679 * 100, metric = 3.66% * 100;
 Minibatch[ 301- 400]: loss = 0.312735 * 100, metric = 3.74% * 100;
 Minibatch[ 401- 500]: loss = 0.294934 * 100, metric = 3.22% * 100;
 Minibatch[ 501- 600]: loss = 0.306896 * 100, metric = 3.62% * 100;
 Minibatch[ 601- 700]: loss = 0.306403 * 100, metric = 3.67% * 100;
 Minibatch[ 701- 800]: loss = 0.309347 * 100, metric = 3.61% * 100;
 Minibatch[ 801- 900]: loss = 0.303374 * 100, metric = 3.51% * 100;
 Minibatch[ 901-1000]: loss = 0.306521 * 100, metric = 3.51% * 100;
 Minibatch[1001-1100]: loss = 0.300604 * 100, metric = 3.62% * 100;
 Minibatch[1101-1200]: loss = 0.302639 * 100, metric = 3.34% * 100;
 Minibatch[1201-1300]: loss = 0.312188 * 100, metric = 3.59% * 100;
 Minibatch[1301-1400]: loss = 0.304117 * 100, metric = 3.55% * 100;
 Minibatch[1401-1500]: loss = 0.314984 * 100, metric = 3.61% * 100;
 Minibatch[1501-1600]: loss = 0.298395 * 100, metric = 3.70% * 100;
 Minibatch[1601-1700]: loss = 0.307598 * 100, metric = 3.48% * 100;
 Minibatch[1701-1800]: loss = 0.302916 * 100, metric = 3.51% * 100;
 Minibatch[1801-1900]: loss = 0.309570 * 100, metric = 3.47% * 100;
 Minibatch[1901-2000]: loss = 0.306342 * 100, metric = 3.34% * 100;
Finished Epoch[98 of 200]: [Training] loss = 0.305437 * 2000, metric = 3.53% * 2000 812.403s (  2.5 samples/s);
Finished Evaluation [98]: Minibatch[1-2000]: metric = 12.08% * 2000;
 Minibatch[   1- 100]: loss = 0.321639 * 100, metric = 3.83% * 100;
 Minibatch[ 101- 200]: loss = 0.304792 * 100, metric = 3.60% * 100;
 Minibatch[ 201- 300]: loss = 0.294376 * 100, metric = 3.34% * 100;
 Minibatch[ 301- 400]: loss = 0.295541 * 100, metric = 3.43% * 100;
 Minibatch[ 401- 500]: loss = 0.294607 * 100, metric = 3.38% * 100;
 Minibatch[ 501- 600]: loss = 0.312624 * 100, metric = 3.74% * 100;
 Minibatch[ 601- 700]: loss = 0.309838 * 100, metric = 3.61% * 100;
 Minibatch[ 701- 800]: loss = 0.307518 * 100, metric = 3.50% * 100;
 Minibatch[ 801- 900]: loss = 0.304562 * 100, metric = 3.52% * 100;
 Minibatch[ 901-1000]: loss = 0.311370 * 100, metric = 3.72% * 100;
 Minibatch[1001-1100]: loss = 0.295953 * 100, metric = 3.26% * 100;
 Minibatch[1101-1200]: loss = 0.312238 * 100, metric = 3.70% * 100;
 Minibatch[1201-1300]: loss = 0.297572 * 100, metric = 3.36% * 100;
 Minibatch[1301-1400]: loss = 0.297748 * 100, metric = 3.46% * 100;
 Minibatch[1401-1500]: loss = 0.301706 * 100, metric = 3.37% * 100;
 Minibatch[1501-1600]: loss = 0.305335 * 100, metric = 3.32% * 100;
 Minibatch[1601-1700]: loss = 0.316442 * 100, metric = 3.64% * 100;
 Minibatch[1701-1800]: loss = 0.321926 * 100, metric = 3.70% * 100;
 Minibatch[1801-1900]: loss = 0.298802 * 100, metric = 3.28% * 100;
 Minibatch[1901-2000]: loss = 0.303072 * 100, metric = 3.43% * 100;
Finished Epoch[99 of 200]: [Training] loss = 0.305383 * 2000, metric = 3.51% * 2000 824.063s (  2.4 samples/s);
Finished Evaluation [99]: Minibatch[1-2000]: metric = 12.04% * 2000;
 Minibatch[   1- 100]: loss = 0.301956 * 100, metric = 3.54% * 100;
 Minibatch[ 101- 200]: loss = 0.305615 * 100, metric = 3.59% * 100;
 Minibatch[ 201- 300]: loss = 0.313556 * 100, metric = 3.50% * 100;
 Minibatch[ 301- 400]: loss = 0.314352 * 100, metric = 3.35% * 100;
 Minibatch[ 401- 500]: loss = 0.314132 * 100, metric = 3.80% * 100;
 Minibatch[ 501- 600]: loss = 0.309273 * 100, metric = 3.62% * 100;
 Minibatch[ 601- 700]: loss = 0.308948 * 100, metric = 3.48% * 100;
 Minibatch[ 701- 800]: loss = 0.295498 * 100, metric = 3.43% * 100;
 Minibatch[ 801- 900]: loss = 0.303736 * 100, metric = 3.61% * 100;
 Minibatch[ 901-1000]: loss = 0.286726 * 100, metric = 3.31% * 100;
 Minibatch[1001-1100]: loss = 0.301179 * 100, metric = 3.49% * 100;
 Minibatch[1101-1200]: loss = 0.297132 * 100, metric = 3.37% * 100;
 Minibatch[1201-1300]: loss = 0.288779 * 100, metric = 3.17% * 100;
 Minibatch[1301-1400]: loss = 0.314109 * 100, metric = 3.66% * 100;
 Minibatch[1401-1500]: loss = 0.309103 * 100, metric = 3.56% * 100;
 Minibatch[1501-1600]: loss = 0.290507 * 100, metric = 3.28% * 100;
 Minibatch[1601-1700]: loss = 0.299892 * 100, metric = 3.45% * 100;
 Minibatch[1701-1800]: loss = 0.304913 * 100, metric = 3.24% * 100;
 Minibatch[1801-1900]: loss = 0.316089 * 100, metric = 3.53% * 100;
 Minibatch[1901-2000]: loss = 0.311182 * 100, metric = 3.63% * 100;
Finished Epoch[100 of 200]: [Training] loss = 0.304334 * 2000, metric = 3.48% * 2000 825.394s (  2.4 samples/s);
Finished Evaluation [100]: Minibatch[1-2000]: metric = 11.91% * 2000;
 Minibatch[   1- 100]: loss = 0.301411 * 100, metric = 3.37% * 100;
 Minibatch[ 101- 200]: loss = 0.296846 * 100, metric = 3.28% * 100;
 Minibatch[ 201- 300]: loss = 0.293610 * 100, metric = 3.25% * 100;
 Minibatch[ 301- 400]: loss = 0.306170 * 100, metric = 3.58% * 100;
 Minibatch[ 401- 500]: loss = 0.306212 * 100, metric = 3.33% * 100;
 Minibatch[ 501- 600]: loss = 0.299684 * 100, metric = 3.38% * 100;
 Minibatch[ 601- 700]: loss = 0.288531 * 100, metric = 3.09% * 100;
 Minibatch[ 701- 800]: loss = 0.303376 * 100, metric = 3.48% * 100;
 Minibatch[ 801- 900]: loss = 0.288542 * 100, metric = 3.21% * 100;
 Minibatch[ 901-1000]: loss = 0.295231 * 100, metric = 3.27% * 100;
 Minibatch[1001-1100]: loss = 0.311911 * 100, metric = 3.48% * 100;
 Minibatch[1101-1200]: loss = 0.294792 * 100, metric = 3.28% * 100;
 Minibatch[1201-1300]: loss = 0.301074 * 100, metric = 3.55% * 100;
 Minibatch[1301-1400]: loss = 0.301245 * 100, metric = 3.50% * 100;
 Minibatch[1401-1500]: loss = 0.287433 * 100, metric = 3.18% * 100;
 Minibatch[1501-1600]: loss = 0.291327 * 100, metric = 3.35% * 100;
 Minibatch[1601-1700]: loss = 0.312424 * 100, metric = 3.61% * 100;
 Minibatch[1701-1800]: loss = 0.297512 * 100, metric = 3.31% * 100;
 Minibatch[1801-1900]: loss = 0.306741 * 100, metric = 3.55% * 100;
 Minibatch[1901-2000]: loss = 0.280891 * 100, metric = 3.09% * 100;
Finished Epoch[101 of 200]: [Training] loss = 0.298248 * 2000, metric = 3.36% * 2000 809.172s (  2.5 samples/s);
Finished Evaluation [101]: Minibatch[1-2000]: metric = 12.00% * 2000;
 Minibatch[   1- 100]: loss = 0.290593 * 100, metric = 3.37% * 100;
 Minibatch[ 101- 200]: loss = 0.305301 * 100, metric = 3.53% * 100;
 Minibatch[ 201- 300]: loss = 0.308043 * 100, metric = 3.51% * 100;
 Minibatch[ 301- 400]: loss = 0.314703 * 100, metric = 3.76% * 100;
 Minibatch[ 401- 500]: loss = 0.295728 * 100, metric = 3.30% * 100;
 Minibatch[ 501- 600]: loss = 0.277659 * 100, metric = 2.97% * 100;
 Minibatch[ 601- 700]: loss = 0.282780 * 100, metric = 3.14% * 100;
 Minibatch[ 701- 800]: loss = 0.298355 * 100, metric = 3.45% * 100;
 Minibatch[ 801- 900]: loss = 0.288708 * 100, metric = 3.29% * 100;
 Minibatch[ 901-1000]: loss = 0.308081 * 100, metric = 3.31% * 100;
 Minibatch[1001-1100]: loss = 0.309688 * 100, metric = 3.41% * 100;
 Minibatch[1101-1200]: loss = 0.284133 * 100, metric = 3.24% * 100;
 Minibatch[1201-1300]: loss = 0.284630 * 100, metric = 3.23% * 100;
 Minibatch[1301-1400]: loss = 0.289761 * 100, metric = 3.22% * 100;
 Minibatch[1401-1500]: loss = 0.295056 * 100, metric = 3.36% * 100;
 Minibatch[1501-1600]: loss = 0.304011 * 100, metric = 3.33% * 100;
 Minibatch[1601-1700]: loss = 0.298003 * 100, metric = 3.34% * 100;
 Minibatch[1701-1800]: loss = 0.287246 * 100, metric = 3.27% * 100;
 Minibatch[1801-1900]: loss = 0.284423 * 100, metric = 3.16% * 100;
 Minibatch[1901-2000]: loss = 0.304916 * 100, metric = 3.50% * 100;
Finished Epoch[102 of 200]: [Training] loss = 0.295591 * 2000, metric = 3.34% * 2000 803.720s (  2.5 samples/s);
Finished Evaluation [102]: Minibatch[1-2000]: metric = 11.50% * 2000;
 Minibatch[   1- 100]: loss = 0.303953 * 100, metric = 3.42% * 100;
 Minibatch[ 101- 200]: loss = 0.298679 * 100, metric = 3.32% * 100;
 Minibatch[ 201- 300]: loss = 0.297029 * 100, metric = 3.20% * 100;
 Minibatch[ 301- 400]: loss = 0.292248 * 100, metric = 3.35% * 100;
 Minibatch[ 401- 500]: loss = 0.302251 * 100, metric = 3.29% * 100;
 Minibatch[ 501- 600]: loss = 0.296367 * 100, metric = 3.28% * 100;
 Minibatch[ 601- 700]: loss = 0.306445 * 100, metric = 3.35% * 100;
 Minibatch[ 701- 800]: loss = 0.304846 * 100, metric = 3.62% * 100;
 Minibatch[ 801- 900]: loss = 0.292532 * 100, metric = 3.37% * 100;
 Minibatch[ 901-1000]: loss = 0.290919 * 100, metric = 3.20% * 100;
 Minibatch[1001-1100]: loss = 0.311173 * 100, metric = 3.68% * 100;
 Minibatch[1101-1200]: loss = 0.300796 * 100, metric = 3.27% * 100;
 Minibatch[1201-1300]: loss = 0.303385 * 100, metric = 3.51% * 100;
 Minibatch[1301-1400]: loss = 0.281501 * 100, metric = 3.09% * 100;
 Minibatch[1401-1500]: loss = 0.284518 * 100, metric = 3.29% * 100;
 Minibatch[1501-1600]: loss = 0.291294 * 100, metric = 3.20% * 100;
 Minibatch[1601-1700]: loss = 0.291078 * 100, metric = 3.12% * 100;
 Minibatch[1701-1800]: loss = 0.282094 * 100, metric = 3.05% * 100;
 Minibatch[1801-1900]: loss = 0.293553 * 100, metric = 3.23% * 100;
 Minibatch[1901-2000]: loss = 0.296779 * 100, metric = 3.29% * 100;
Finished Epoch[103 of 200]: [Training] loss = 0.296072 * 2000, metric = 3.31% * 2000 796.944s (  2.5 samples/s);
Finished Evaluation [103]: Minibatch[1-2000]: metric = 12.80% * 2000;
 Minibatch[   1- 100]: loss = 0.298003 * 100, metric = 3.38% * 100;
 Minibatch[ 101- 200]: loss = 0.293888 * 100, metric = 3.39% * 100;
 Minibatch[ 201- 300]: loss = 0.301158 * 100, metric = 3.54% * 100;
 Minibatch[ 301- 400]: loss = 0.279706 * 100, metric = 3.09% * 100;
 Minibatch[ 401- 500]: loss = 0.292297 * 100, metric = 3.28% * 100;
 Minibatch[ 501- 600]: loss = 0.286209 * 100, metric = 3.20% * 100;
 Minibatch[ 601- 700]: loss = 0.298897 * 100, metric = 3.36% * 100;
 Minibatch[ 701- 800]: loss = 0.302854 * 100, metric = 3.33% * 100;
 Minibatch[ 801- 900]: loss = 0.292536 * 100, metric = 3.19% * 100;
 Minibatch[ 901-1000]: loss = 0.288719 * 100, metric = 3.11% * 100;
 Minibatch[1001-1100]: loss = 0.292789 * 100, metric = 3.38% * 100;
 Minibatch[1101-1200]: loss = 0.289872 * 100, metric = 3.27% * 100;
 Minibatch[1201-1300]: loss = 0.284255 * 100, metric = 3.05% * 100;
 Minibatch[1301-1400]: loss = 0.299051 * 100, metric = 3.34% * 100;
 Minibatch[1401-1500]: loss = 0.284282 * 100, metric = 3.04% * 100;
 Minibatch[1501-1600]: loss = 0.307871 * 100, metric = 3.49% * 100;
 Minibatch[1601-1700]: loss = 0.284504 * 100, metric = 3.16% * 100;
 Minibatch[1701-1800]: loss = 0.304071 * 100, metric = 3.44% * 100;
 Minibatch[1801-1900]: loss = 0.287895 * 100, metric = 3.25% * 100;
 Minibatch[1901-2000]: loss = 0.289052 * 100, metric = 3.13% * 100;
Finished Epoch[104 of 200]: [Training] loss = 0.292895 * 2000, metric = 3.27% * 2000 805.295s (  2.5 samples/s);
Finished Evaluation [104]: Minibatch[1-2000]: metric = 12.19% * 2000;
 Minibatch[   1- 100]: loss = 0.300877 * 100, metric = 3.44% * 100;
 Minibatch[ 101- 200]: loss = 0.299620 * 100, metric = 3.39% * 100;
 Minibatch[ 201- 300]: loss = 0.298019 * 100, metric = 3.42% * 100;
 Minibatch[ 301- 400]: loss = 0.287632 * 100, metric = 3.24% * 100;
 Minibatch[ 401- 500]: loss = 0.296194 * 100, metric = 3.22% * 100;
 Minibatch[ 501- 600]: loss = 0.304367 * 100, metric = 3.38% * 100;
 Minibatch[ 601- 700]: loss = 0.285083 * 100, metric = 3.05% * 100;
 Minibatch[ 701- 800]: loss = 0.302132 * 100, metric = 3.48% * 100;
 Minibatch[ 801- 900]: loss = 0.300109 * 100, metric = 3.42% * 100;
 Minibatch[ 901-1000]: loss = 0.308646 * 100, metric = 3.60% * 100;
 Minibatch[1001-1100]: loss = 0.293769 * 100, metric = 3.09% * 100;
 Minibatch[1101-1200]: loss = 0.307476 * 100, metric = 3.42% * 100;
 Minibatch[1201-1300]: loss = 0.278591 * 100, metric = 3.05% * 100;
 Minibatch[1301-1400]: loss = 0.310583 * 100, metric = 3.55% * 100;
 Minibatch[1401-1500]: loss = 0.297271 * 100, metric = 3.39% * 100;
 Minibatch[1501-1600]: loss = 0.297309 * 100, metric = 3.45% * 100;
 Minibatch[1601-1700]: loss = 0.288081 * 100, metric = 3.23% * 100;
 Minibatch[1701-1800]: loss = 0.280379 * 100, metric = 2.93% * 100;
 Minibatch[1801-1900]: loss = 0.302145 * 100, metric = 3.35% * 100;
 Minibatch[1901-2000]: loss = 0.294811 * 100, metric = 3.33% * 100;
Finished Epoch[105 of 200]: [Training] loss = 0.296655 * 2000, metric = 3.32% * 2000 808.213s (  2.5 samples/s);
Finished Evaluation [105]: Minibatch[1-2000]: metric = 12.03% * 2000;
 Minibatch[   1- 100]: loss = 0.297670 * 100, metric = 3.27% * 100;
 Minibatch[ 101- 200]: loss = 0.293519 * 100, metric = 3.06% * 100;
 Minibatch[ 201- 300]: loss = 0.294682 * 100, metric = 3.21% * 100;
 Minibatch[ 301- 400]: loss = 0.300154 * 100, metric = 3.19% * 100;
 Minibatch[ 401- 500]: loss = 0.288399 * 100, metric = 3.16% * 100;
 Minibatch[ 501- 600]: loss = 0.303105 * 100, metric = 3.36% * 100;
 Minibatch[ 601- 700]: loss = 0.295495 * 100, metric = 3.13% * 100;
 Minibatch[ 701- 800]: loss = 0.295800 * 100, metric = 3.35% * 100;
 Minibatch[ 801- 900]: loss = 0.308550 * 100, metric = 3.47% * 100;
 Minibatch[ 901-1000]: loss = 0.284842 * 100, metric = 3.14% * 100;
 Minibatch[1001-1100]: loss = 0.302204 * 100, metric = 3.36% * 100;
 Minibatch[1101-1200]: loss = 0.298035 * 100, metric = 3.38% * 100;
 Minibatch[1201-1300]: loss = 0.297339 * 100, metric = 3.31% * 100;
 Minibatch[1301-1400]: loss = 0.293557 * 100, metric = 3.20% * 100;
 Minibatch[1401-1500]: loss = 0.307295 * 100, metric = 3.40% * 100;
 Minibatch[1501-1600]: loss = 0.282914 * 100, metric = 3.09% * 100;
 Minibatch[1601-1700]: loss = 0.291823 * 100, metric = 3.19% * 100;
 Minibatch[1701-1800]: loss = 0.297681 * 100, metric = 3.51% * 100;
 Minibatch[1801-1900]: loss = 0.291787 * 100, metric = 3.19% * 100;
 Minibatch[1901-2000]: loss = 0.307166 * 100, metric = 3.38% * 100;
Finished Epoch[106 of 200]: [Training] loss = 0.296601 * 2000, metric = 3.27% * 2000 804.163s (  2.5 samples/s);
Finished Evaluation [106]: Minibatch[1-2000]: metric = 11.40% * 2000;
0.6183174284361302
 Minibatch[   1- 100]: loss = 0.286213 * 100, metric = 3.05% * 100;
 Minibatch[ 101- 200]: loss = 0.286259 * 100, metric = 3.17% * 100;
 Minibatch[ 201- 300]: loss = 0.307329 * 100, metric = 3.35% * 100;
 Minibatch[ 301- 400]: loss = 0.292089 * 100, metric = 3.25% * 100;
 Minibatch[ 401- 500]: loss = 0.293169 * 100, metric = 3.33% * 100;
 Minibatch[ 501- 600]: loss = 0.302117 * 100, metric = 3.48% * 100;
 Minibatch[ 601- 700]: loss = 0.282896 * 100, metric = 3.27% * 100;
 Minibatch[ 701- 800]: loss = 0.282876 * 100, metric = 3.05% * 100;
 Minibatch[ 801- 900]: loss = 0.286544 * 100, metric = 3.03% * 100;
 Minibatch[ 901-1000]: loss = 0.282180 * 100, metric = 2.97% * 100;
 Minibatch[1001-1100]: loss = 0.293729 * 100, metric = 3.32% * 100;
 Minibatch[1101-1200]: loss = 0.291742 * 100, metric = 3.30% * 100;
 Minibatch[1201-1300]: loss = 0.288188 * 100, metric = 3.19% * 100;
 Minibatch[1301-1400]: loss = 0.281918 * 100, metric = 3.17% * 100;
 Minibatch[1401-1500]: loss = 0.295393 * 100, metric = 3.26% * 100;
 Minibatch[1501-1600]: loss = 0.303057 * 100, metric = 3.61% * 100;
 Minibatch[1601-1700]: loss = 0.308051 * 100, metric = 3.40% * 100;
 Minibatch[1701-1800]: loss = 0.297407 * 100, metric = 3.42% * 100;
 Minibatch[1801-1900]: loss = 0.294978 * 100, metric = 3.34% * 100;
 Minibatch[1901-2000]: loss = 0.292568 * 100, metric = 3.21% * 100;
Finished Epoch[107 of 200]: [Training] loss = 0.292435 * 2000, metric = 3.26% * 2000 811.489s (  2.5 samples/s);
Finished Evaluation [107]: Minibatch[1-2000]: metric = 10.99% * 2000;
 Minibatch[   1- 100]: loss = 0.287121 * 100, metric = 3.09% * 100;
 Minibatch[ 101- 200]: loss = 0.295653 * 100, metric = 3.33% * 100;
 Minibatch[ 201- 300]: loss = 0.306417 * 100, metric = 3.30% * 100;
 Minibatch[ 301- 400]: loss = 0.280907 * 100, metric = 3.14% * 100;
 Minibatch[ 401- 500]: loss = 0.286301 * 100, metric = 3.02% * 100;
 Minibatch[ 501- 600]: loss = 0.284557 * 100, metric = 3.10% * 100;
 Minibatch[ 601- 700]: loss = 0.297034 * 100, metric = 3.34% * 100;
 Minibatch[ 701- 800]: loss = 0.310226 * 100, metric = 3.59% * 100;
 Minibatch[ 801- 900]: loss = 0.300733 * 100, metric = 3.44% * 100;
 Minibatch[ 901-1000]: loss = 0.279077 * 100, metric = 3.00% * 100;
 Minibatch[1001-1100]: loss = 0.301017 * 100, metric = 3.24% * 100;
 Minibatch[1101-1200]: loss = 0.295744 * 100, metric = 3.22% * 100;
 Minibatch[1201-1300]: loss = 0.296984 * 100, metric = 3.28% * 100;
 Minibatch[1301-1400]: loss = 0.302654 * 100, metric = 3.47% * 100;
 Minibatch[1401-1500]: loss = 0.287506 * 100, metric = 3.08% * 100;
 Minibatch[1501-1600]: loss = 0.286967 * 100, metric = 3.08% * 100;
 Minibatch[1601-1700]: loss = 0.293757 * 100, metric = 3.14% * 100;
 Minibatch[1701-1800]: loss = 0.274808 * 100, metric = 2.92% * 100;
 Minibatch[1801-1900]: loss = 0.287987 * 100, metric = 3.17% * 100;
 Minibatch[1901-2000]: loss = 0.298399 * 100, metric = 3.37% * 100;
Finished Epoch[108 of 200]: [Training] loss = 0.292692 * 2000, metric = 3.22% * 2000 816.882s (  2.4 samples/s);
Finished Evaluation [108]: Minibatch[1-2000]: metric = 10.83% * 2000;
 Minibatch[   1- 100]: loss = 0.296583 * 100, metric = 3.31% * 100;
 Minibatch[ 101- 200]: loss = 0.301821 * 100, metric = 3.26% * 100;
 Minibatch[ 201- 300]: loss = 0.297830 * 100, metric = 3.22% * 100;
 Minibatch[ 301- 400]: loss = 0.304280 * 100, metric = 3.21% * 100;
 Minibatch[ 401- 500]: loss = 0.288330 * 100, metric = 3.19% * 100;
 Minibatch[ 501- 600]: loss = 0.291708 * 100, metric = 2.97% * 100;
 Minibatch[ 601- 700]: loss = 0.288721 * 100, metric = 3.06% * 100;
 Minibatch[ 701- 800]: loss = 0.292458 * 100, metric = 3.32% * 100;
 Minibatch[ 801- 900]: loss = 0.299377 * 100, metric = 3.04% * 100;
 Minibatch[ 901-1000]: loss = 0.293231 * 100, metric = 3.21% * 100;
 Minibatch[1001-1100]: loss = 0.306781 * 100, metric = 3.46% * 100;
 Minibatch[1101-1200]: loss = 0.288987 * 100, metric = 3.09% * 100;
 Minibatch[1201-1300]: loss = 0.284730 * 100, metric = 3.10% * 100;
 Minibatch[1301-1400]: loss = 0.294406 * 100, metric = 3.19% * 100;
 Minibatch[1401-1500]: loss = 0.296501 * 100, metric = 3.20% * 100;
 Minibatch[1501-1600]: loss = 0.291689 * 100, metric = 3.19% * 100;
 Minibatch[1601-1700]: loss = 0.294153 * 100, metric = 3.13% * 100;
 Minibatch[1701-1800]: loss = 0.285790 * 100, metric = 3.05% * 100;
 Minibatch[1801-1900]: loss = 0.305147 * 100, metric = 3.28% * 100;
 Minibatch[1901-2000]: loss = 0.292203 * 100, metric = 3.03% * 100;
Finished Epoch[109 of 200]: [Training] loss = 0.294736 * 2000, metric = 3.18% * 2000 803.016s (  2.5 samples/s);
Finished Evaluation [109]: Minibatch[1-2000]: metric = 11.65% * 2000;
 Minibatch[   1- 100]: loss = 0.296887 * 100, metric = 3.23% * 100;
 Minibatch[ 101- 200]: loss = 0.287987 * 100, metric = 3.02% * 100;
 Minibatch[ 201- 300]: loss = 0.282524 * 100, metric = 2.97% * 100;
 Minibatch[ 301- 400]: loss = 0.296179 * 100, metric = 3.20% * 100;
 Minibatch[ 401- 500]: loss = 0.300204 * 100, metric = 3.43% * 100;
 Minibatch[ 501- 600]: loss = 0.289179 * 100, metric = 3.11% * 100;
 Minibatch[ 601- 700]: loss = 0.283225 * 100, metric = 3.15% * 100;
 Minibatch[ 701- 800]: loss = 0.284587 * 100, metric = 3.16% * 100;
 Minibatch[ 801- 900]: loss = 0.281341 * 100, metric = 3.07% * 100;
 Minibatch[ 901-1000]: loss = 0.290620 * 100, metric = 3.09% * 100;
 Minibatch[1001-1100]: loss = 0.267772 * 100, metric = 2.90% * 100;
 Minibatch[1101-1200]: loss = 0.276415 * 100, metric = 3.05% * 100;
 Minibatch[1201-1300]: loss = 0.281605 * 100, metric = 3.08% * 100;
 Minibatch[1301-1400]: loss = 0.283779 * 100, metric = 3.11% * 100;
 Minibatch[1401-1500]: loss = 0.285767 * 100, metric = 3.14% * 100;
 Minibatch[1501-1600]: loss = 0.302426 * 100, metric = 3.48% * 100;
 Minibatch[1601-1700]: loss = 0.292556 * 100, metric = 3.45% * 100;
 Minibatch[1701-1800]: loss = 0.291142 * 100, metric = 3.18% * 100;
 Minibatch[1801-1900]: loss = 0.282441 * 100, metric = 3.05% * 100;
 Minibatch[1901-2000]: loss = 0.293686 * 100, metric = 3.33% * 100;
Finished Epoch[110 of 200]: [Training] loss = 0.287516 * 2000, metric = 3.16% * 2000 805.755s (  2.5 samples/s);
Finished Evaluation [110]: Minibatch[1-2000]: metric = 11.18% * 2000;
 Minibatch[   1- 100]: loss = 0.298426 * 100, metric = 3.29% * 100;
 Minibatch[ 101- 200]: loss = 0.286423 * 100, metric = 3.08% * 100;
 Minibatch[ 201- 300]: loss = 0.287274 * 100, metric = 3.05% * 100;
 Minibatch[ 301- 400]: loss = 0.295812 * 100, metric = 3.14% * 100;
 Minibatch[ 401- 500]: loss = 0.279393 * 100, metric = 2.96% * 100;
 Minibatch[ 501- 600]: loss = 0.285932 * 100, metric = 2.96% * 100;
 Minibatch[ 601- 700]: loss = 0.289605 * 100, metric = 3.05% * 100;
 Minibatch[ 701- 800]: loss = 0.294207 * 100, metric = 2.98% * 100;
 Minibatch[ 801- 900]: loss = 0.302448 * 100, metric = 3.52% * 100;
 Minibatch[ 901-1000]: loss = 0.309662 * 100, metric = 3.27% * 100;
 Minibatch[1001-1100]: loss = 0.295031 * 100, metric = 3.30% * 100;
 Minibatch[1101-1200]: loss = 0.291533 * 100, metric = 3.11% * 100;
 Minibatch[1201-1300]: loss = 0.289577 * 100, metric = 3.18% * 100;
 Minibatch[1301-1400]: loss = 0.303053 * 100, metric = 3.45% * 100;
 Minibatch[1401-1500]: loss = 0.296818 * 100, metric = 3.39% * 100;
 Minibatch[1501-1600]: loss = 0.302125 * 100, metric = 3.20% * 100;
 Minibatch[1601-1700]: loss = 0.279019 * 100, metric = 3.03% * 100;
 Minibatch[1701-1800]: loss = 0.272173 * 100, metric = 2.82% * 100;
 Minibatch[1801-1900]: loss = 0.292951 * 100, metric = 3.25% * 100;
 Minibatch[1901-2000]: loss = 0.294821 * 100, metric = 3.17% * 100;
Finished Epoch[111 of 200]: [Training] loss = 0.292314 * 2000, metric = 3.16% * 2000 792.198s (  2.5 samples/s);
Finished Evaluation [111]: Minibatch[1-2000]: metric = 11.57% * 2000;
 Minibatch[   1- 100]: loss = 0.290244 * 100, metric = 3.02% * 100;
 Minibatch[ 101- 200]: loss = 0.282568 * 100, metric = 3.16% * 100;
 Minibatch[ 201- 300]: loss = 0.291793 * 100, metric = 3.18% * 100;
 Minibatch[ 301- 400]: loss = 0.280456 * 100, metric = 3.08% * 100;
 Minibatch[ 401- 500]: loss = 0.286548 * 100, metric = 3.12% * 100;
 Minibatch[ 501- 600]: loss = 0.290191 * 100, metric = 3.24% * 100;
 Minibatch[ 601- 700]: loss = 0.277343 * 100, metric = 2.96% * 100;
 Minibatch[ 701- 800]: loss = 0.289000 * 100, metric = 3.21% * 100;
 Minibatch[ 801- 900]: loss = 0.289664 * 100, metric = 3.09% * 100;
 Minibatch[ 901-1000]: loss = 0.293698 * 100, metric = 3.13% * 100;
 Minibatch[1001-1100]: loss = 0.284320 * 100, metric = 2.96% * 100;
 Minibatch[1101-1200]: loss = 0.282126 * 100, metric = 2.85% * 100;
 Minibatch[1201-1300]: loss = 0.292062 * 100, metric = 3.15% * 100;
 Minibatch[1301-1400]: loss = 0.294098 * 100, metric = 3.15% * 100;
 Minibatch[1401-1500]: loss = 0.289501 * 100, metric = 3.04% * 100;
 Minibatch[1501-1600]: loss = 0.307488 * 100, metric = 3.23% * 100;
 Minibatch[1601-1700]: loss = 0.290413 * 100, metric = 3.13% * 100;
 Minibatch[1701-1800]: loss = 0.285304 * 100, metric = 3.13% * 100;
 Minibatch[1801-1900]: loss = 0.294847 * 100, metric = 3.08% * 100;
 Minibatch[1901-2000]: loss = 0.293470 * 100, metric = 3.15% * 100;
Finished Epoch[112 of 200]: [Training] loss = 0.289257 * 2000, metric = 3.10% * 2000 793.989s (  2.5 samples/s);
Finished Evaluation [112]: Minibatch[1-2000]: metric = 13.03% * 2000;
 Minibatch[   1- 100]: loss = 0.291048 * 100, metric = 3.13% * 100;
 Minibatch[ 101- 200]: loss = 0.297546 * 100, metric = 3.11% * 100;
 Minibatch[ 201- 300]: loss = 0.297490 * 100, metric = 3.38% * 100;
 Minibatch[ 301- 400]: loss = 0.294443 * 100, metric = 3.19% * 100;
 Minibatch[ 401- 500]: loss = 0.279861 * 100, metric = 3.12% * 100;
 Minibatch[ 501- 600]: loss = 0.284424 * 100, metric = 3.10% * 100;
 Minibatch[ 601- 700]: loss = 0.272486 * 100, metric = 2.92% * 100;
 Minibatch[ 701- 800]: loss = 0.271928 * 100, metric = 3.08% * 100;
 Minibatch[ 801- 900]: loss = 0.303439 * 100, metric = 3.35% * 100;
 Minibatch[ 901-1000]: loss = 0.273680 * 100, metric = 2.87% * 100;
 Minibatch[1001-1100]: loss = 0.290972 * 100, metric = 3.37% * 100;
 Minibatch[1101-1200]: loss = 0.297183 * 100, metric = 3.15% * 100;
 Minibatch[1201-1300]: loss = 0.303286 * 100, metric = 3.19% * 100;
 Minibatch[1301-1400]: loss = 0.285186 * 100, metric = 3.08% * 100;
 Minibatch[1401-1500]: loss = 0.298358 * 100, metric = 3.26% * 100;
 Minibatch[1501-1600]: loss = 0.297426 * 100, metric = 3.00% * 100;
 Minibatch[1601-1700]: loss = 0.294839 * 100, metric = 3.13% * 100;
 Minibatch[1701-1800]: loss = 0.300603 * 100, metric = 3.40% * 100;
 Minibatch[1801-1900]: loss = 0.283044 * 100, metric = 3.02% * 100;
 Minibatch[1901-2000]: loss = 0.284069 * 100, metric = 3.01% * 100;
Finished Epoch[113 of 200]: [Training] loss = 0.290065 * 2000, metric = 3.14% * 2000 810.904s (  2.5 samples/s);
Finished Evaluation [113]: Minibatch[1-2000]: metric = 11.24% * 2000;
0.6155726011544466
 Minibatch[   1- 100]: loss = 0.291786 * 100, metric = 3.11% * 100;
 Minibatch[ 101- 200]: loss = 0.286610 * 100, metric = 3.10% * 100;
 Minibatch[ 201- 300]: loss = 0.290345 * 100, metric = 3.21% * 100;
 Minibatch[ 301- 400]: loss = 0.286209 * 100, metric = 3.19% * 100;
 Minibatch[ 401- 500]: loss = 0.277507 * 100, metric = 2.98% * 100;
 Minibatch[ 501- 600]: loss = 0.294630 * 100, metric = 3.17% * 100;
 Minibatch[ 601- 700]: loss = 0.288512 * 100, metric = 3.01% * 100;
 Minibatch[ 701- 800]: loss = 0.287620 * 100, metric = 3.07% * 100;
 Minibatch[ 801- 900]: loss = 0.295630 * 100, metric = 3.12% * 100;
 Minibatch[ 901-1000]: loss = 0.294370 * 100, metric = 3.23% * 100;
 Minibatch[1001-1100]: loss = 0.272901 * 100, metric = 2.95% * 100;
 Minibatch[1101-1200]: loss = 0.291471 * 100, metric = 2.99% * 100;
 Minibatch[1201-1300]: loss = 0.296002 * 100, metric = 3.43% * 100;
 Minibatch[1301-1400]: loss = 0.273018 * 100, metric = 3.01% * 100;
 Minibatch[1401-1500]: loss = 0.293426 * 100, metric = 3.17% * 100;
 Minibatch[1501-1600]: loss = 0.280056 * 100, metric = 2.89% * 100;
 Minibatch[1601-1700]: loss = 0.283488 * 100, metric = 3.21% * 100;
 Minibatch[1701-1800]: loss = 0.294061 * 100, metric = 3.13% * 100;
 Minibatch[1801-1900]: loss = 0.304955 * 100, metric = 3.26% * 100;
 Minibatch[1901-2000]: loss = 0.287102 * 100, metric = 3.12% * 100;
Finished Epoch[114 of 200]: [Training] loss = 0.288485 * 2000, metric = 3.12% * 2000 807.738s (  2.5 samples/s);
Finished Evaluation [114]: Minibatch[1-2000]: metric = 11.43% * 2000;
 Minibatch[   1- 100]: loss = 0.286119 * 100, metric = 3.05% * 100;
 Minibatch[ 101- 200]: loss = 0.279797 * 100, metric = 2.92% * 100;
 Minibatch[ 201- 300]: loss = 0.292275 * 100, metric = 3.27% * 100;
 Minibatch[ 301- 400]: loss = 0.310736 * 100, metric = 3.43% * 100;
 Minibatch[ 401- 500]: loss = 0.295918 * 100, metric = 3.21% * 100;
 Minibatch[ 501- 600]: loss = 0.293068 * 100, metric = 3.25% * 100;
 Minibatch[ 601- 700]: loss = 0.297081 * 100, metric = 3.27% * 100;
 Minibatch[ 701- 800]: loss = 0.286642 * 100, metric = 2.85% * 100;
 Minibatch[ 801- 900]: loss = 0.293473 * 100, metric = 3.12% * 100;
 Minibatch[ 901-1000]: loss = 0.288940 * 100, metric = 3.24% * 100;
 Minibatch[1001-1100]: loss = 0.292795 * 100, metric = 3.17% * 100;
 Minibatch[1101-1200]: loss = 0.287400 * 100, metric = 2.88% * 100;
 Minibatch[1201-1300]: loss = 0.264942 * 100, metric = 2.82% * 100;
 Minibatch[1301-1400]: loss = 0.289865 * 100, metric = 3.23% * 100;
 Minibatch[1401-1500]: loss = 0.290568 * 100, metric = 3.38% * 100;
 Minibatch[1501-1600]: loss = 0.300231 * 100, metric = 3.25% * 100;
 Minibatch[1601-1700]: loss = 0.284163 * 100, metric = 3.10% * 100;
 Minibatch[1701-1800]: loss = 0.288365 * 100, metric = 3.05% * 100;
 Minibatch[1801-1900]: loss = 0.274467 * 100, metric = 2.86% * 100;
 Minibatch[1901-2000]: loss = 0.276962 * 100, metric = 2.98% * 100;
Finished Epoch[115 of 200]: [Training] loss = 0.288690 * 2000, metric = 3.12% * 2000 808.847s (  2.5 samples/s);
Finished Evaluation [115]: Minibatch[1-2000]: metric = 11.22% * 2000;
 Minibatch[   1- 100]: loss = 0.277077 * 100, metric = 2.92% * 100;
 Minibatch[ 101- 200]: loss = 0.290031 * 100, metric = 3.10% * 100;
 Minibatch[ 201- 300]: loss = 0.278657 * 100, metric = 2.90% * 100;
 Minibatch[ 301- 400]: loss = 0.281473 * 100, metric = 3.02% * 100;
 Minibatch[ 401- 500]: loss = 0.291203 * 100, metric = 3.13% * 100;
 Minibatch[ 501- 600]: loss = 0.274398 * 100, metric = 2.89% * 100;
 Minibatch[ 601- 700]: loss = 0.262800 * 100, metric = 2.61% * 100;
 Minibatch[ 701- 800]: loss = 0.272406 * 100, metric = 2.86% * 100;
 Minibatch[ 801- 900]: loss = 0.276442 * 100, metric = 3.01% * 100;
 Minibatch[ 901-1000]: loss = 0.277222 * 100, metric = 2.87% * 100;
 Minibatch[1001-1100]: loss = 0.275782 * 100, metric = 2.87% * 100;
 Minibatch[1101-1200]: loss = 0.273451 * 100, metric = 2.85% * 100;
 Minibatch[1201-1300]: loss = 0.280692 * 100, metric = 3.00% * 100;
 Minibatch[1301-1400]: loss = 0.284616 * 100, metric = 3.06% * 100;
 Minibatch[1401-1500]: loss = 0.282145 * 100, metric = 2.96% * 100;
 Minibatch[1501-1600]: loss = 0.269720 * 100, metric = 2.85% * 100;
 Minibatch[1601-1700]: loss = 0.272760 * 100, metric = 2.79% * 100;
 Minibatch[1701-1800]: loss = 0.272088 * 100, metric = 2.92% * 100;
 Minibatch[1801-1900]: loss = 0.291471 * 100, metric = 2.78% * 100;
 Minibatch[1901-2000]: loss = 0.274337 * 100, metric = 2.73% * 100;
Finished Epoch[116 of 200]: [Training] loss = 0.277938 * 2000, metric = 2.91% * 2000 812.315s (  2.5 samples/s);
Finished Evaluation [116]: Minibatch[1-2000]: metric = 11.42% * 2000;
 Minibatch[   1- 100]: loss = 0.269147 * 100, metric = 2.70% * 100;
 Minibatch[ 101- 200]: loss = 0.299418 * 100, metric = 3.20% * 100;
 Minibatch[ 201- 300]: loss = 0.282241 * 100, metric = 2.96% * 100;
 Minibatch[ 301- 400]: loss = 0.280132 * 100, metric = 2.93% * 100;
 Minibatch[ 401- 500]: loss = 0.273923 * 100, metric = 3.01% * 100;
 Minibatch[ 501- 600]: loss = 0.266500 * 100, metric = 2.77% * 100;
 Minibatch[ 601- 700]: loss = 0.274100 * 100, metric = 2.84% * 100;
 Minibatch[ 701- 800]: loss = 0.269973 * 100, metric = 2.83% * 100;
 Minibatch[ 801- 900]: loss = 0.284465 * 100, metric = 3.05% * 100;
 Minibatch[ 901-1000]: loss = 0.293586 * 100, metric = 3.10% * 100;
 Minibatch[1001-1100]: loss = 0.282946 * 100, metric = 3.07% * 100;
 Minibatch[1101-1200]: loss = 0.285849 * 100, metric = 3.15% * 100;
 Minibatch[1201-1300]: loss = 0.286141 * 100, metric = 3.05% * 100;
 Minibatch[1301-1400]: loss = 0.279156 * 100, metric = 2.94% * 100;
 Minibatch[1401-1500]: loss = 0.281121 * 100, metric = 3.01% * 100;
 Minibatch[1501-1600]: loss = 0.279974 * 100, metric = 3.01% * 100;
 Minibatch[1601-1700]: loss = 0.264672 * 100, metric = 2.71% * 100;
 Minibatch[1701-1800]: loss = 0.283531 * 100, metric = 2.96% * 100;
 Minibatch[1801-1900]: loss = 0.278128 * 100, metric = 2.82% * 100;
 Minibatch[1901-2000]: loss = 0.270198 * 100, metric = 2.72% * 100;
Finished Epoch[117 of 200]: [Training] loss = 0.279260 * 2000, metric = 2.94% * 2000 794.912s (  2.5 samples/s);
Finished Evaluation [117]: Minibatch[1-2000]: metric = 10.86% * 2000;
0.6120141889788211
 Minibatch[   1- 100]: loss = 0.288814 * 100, metric = 3.07% * 100;
 Minibatch[ 101- 200]: loss = 0.286206 * 100, metric = 2.92% * 100;
 Minibatch[ 201- 300]: loss = 0.284643 * 100, metric = 2.89% * 100;
 Minibatch[ 301- 400]: loss = 0.284649 * 100, metric = 3.05% * 100;
 Minibatch[ 401- 500]: loss = 0.278393 * 100, metric = 2.93% * 100;
 Minibatch[ 501- 600]: loss = 0.282911 * 100, metric = 2.89% * 100;
 Minibatch[ 601- 700]: loss = 0.275320 * 100, metric = 2.92% * 100;
 Minibatch[ 701- 800]: loss = 0.261055 * 100, metric = 2.77% * 100;
 Minibatch[ 801- 900]: loss = 0.275145 * 100, metric = 2.88% * 100;
 Minibatch[ 901-1000]: loss = 0.278120 * 100, metric = 2.82% * 100;
 Minibatch[1001-1100]: loss = 0.273433 * 100, metric = 2.82% * 100;
 Minibatch[1101-1200]: loss = 0.270545 * 100, metric = 2.72% * 100;
 Minibatch[1201-1300]: loss = 0.270336 * 100, metric = 2.85% * 100;
 Minibatch[1301-1400]: loss = 0.264621 * 100, metric = 2.78% * 100;
 Minibatch[1401-1500]: loss = 0.276921 * 100, metric = 3.01% * 100;
 Minibatch[1501-1600]: loss = 0.276286 * 100, metric = 2.99% * 100;
 Minibatch[1601-1700]: loss = 0.273222 * 100, metric = 2.75% * 100;
 Minibatch[1701-1800]: loss = 0.267615 * 100, metric = 2.71% * 100;
 Minibatch[1801-1900]: loss = 0.271349 * 100, metric = 2.88% * 100;
 Minibatch[1901-2000]: loss = 0.281521 * 100, metric = 2.99% * 100;
Finished Epoch[118 of 200]: [Training] loss = 0.276055 * 2000, metric = 2.88% * 2000 769.547s (  2.6 samples/s);
Finished Evaluation [118]: Minibatch[1-2000]: metric = 11.43% * 2000;
 Minibatch[   1- 100]: loss = 0.270866 * 100, metric = 2.76% * 100;
 Minibatch[ 101- 200]: loss = 0.264241 * 100, metric = 2.71% * 100;
 Minibatch[ 201- 300]: loss = 0.279567 * 100, metric = 2.90% * 100;
 Minibatch[ 301- 400]: loss = 0.269073 * 100, metric = 2.91% * 100;
 Minibatch[ 401- 500]: loss = 0.277136 * 100, metric = 2.86% * 100;
 Minibatch[ 501- 600]: loss = 0.268938 * 100, metric = 2.87% * 100;
 Minibatch[ 601- 700]: loss = 0.279894 * 100, metric = 2.91% * 100;
 Minibatch[ 701- 800]: loss = 0.267907 * 100, metric = 2.72% * 100;
 Minibatch[ 801- 900]: loss = 0.273814 * 100, metric = 2.85% * 100;
 Minibatch[ 901-1000]: loss = 0.279656 * 100, metric = 2.90% * 100;
 Minibatch[1001-1100]: loss = 0.281949 * 100, metric = 2.92% * 100;
 Minibatch[1101-1200]: loss = 0.288901 * 100, metric = 2.95% * 100;
 Minibatch[1201-1300]: loss = 0.276167 * 100, metric = 2.80% * 100;
 Minibatch[1301-1400]: loss = 0.292369 * 100, metric = 2.99% * 100;
 Minibatch[1401-1500]: loss = 0.282306 * 100, metric = 2.68% * 100;
 Minibatch[1501-1600]: loss = 0.266060 * 100, metric = 2.70% * 100;
 Minibatch[1601-1700]: loss = 0.263521 * 100, metric = 2.70% * 100;
 Minibatch[1701-1800]: loss = 0.275338 * 100, metric = 2.79% * 100;
 Minibatch[1801-1900]: loss = 0.283600 * 100, metric = 2.79% * 100;
 Minibatch[1901-2000]: loss = 0.284802 * 100, metric = 2.92% * 100;
Finished Epoch[119 of 200]: [Training] loss = 0.276305 * 2000, metric = 2.83% * 2000 863.307s (  2.3 samples/s);
Finished Evaluation [119]: Minibatch[1-2000]: metric = 11.03% * 2000;
 Minibatch[   1- 100]: loss = 0.281695 * 100, metric = 2.86% * 100;
 Minibatch[ 101- 200]: loss = 0.275392 * 100, metric = 2.92% * 100;
 Minibatch[ 201- 300]: loss = 0.272558 * 100, metric = 2.72% * 100;
 Minibatch[ 301- 400]: loss = 0.277175 * 100, metric = 2.93% * 100;
 Minibatch[ 401- 500]: loss = 0.278478 * 100, metric = 2.90% * 100;
 Minibatch[ 501- 600]: loss = 0.282045 * 100, metric = 2.92% * 100;
 Minibatch[ 601- 700]: loss = 0.278373 * 100, metric = 2.93% * 100;
 Minibatch[ 701- 800]: loss = 0.275693 * 100, metric = 2.94% * 100;
 Minibatch[ 801- 900]: loss = 0.274727 * 100, metric = 2.86% * 100;
 Minibatch[ 901-1000]: loss = 0.268989 * 100, metric = 2.82% * 100;
 Minibatch[1001-1100]: loss = 0.281288 * 100, metric = 3.02% * 100;
 Minibatch[1101-1200]: loss = 0.281675 * 100, metric = 2.94% * 100;
 Minibatch[1201-1300]: loss = 0.274690 * 100, metric = 2.75% * 100;
 Minibatch[1301-1400]: loss = 0.270239 * 100, metric = 2.65% * 100;
 Minibatch[1401-1500]: loss = 0.254830 * 100, metric = 2.55% * 100;
 Minibatch[1501-1600]: loss = 0.271653 * 100, metric = 2.88% * 100;
 Minibatch[1601-1700]: loss = 0.267008 * 100, metric = 2.75% * 100;
 Minibatch[1701-1800]: loss = 0.263342 * 100, metric = 2.69% * 100;
 Minibatch[1801-1900]: loss = 0.274963 * 100, metric = 2.80% * 100;
 Minibatch[1901-2000]: loss = 0.276540 * 100, metric = 2.92% * 100;
Finished Epoch[120 of 200]: [Training] loss = 0.274068 * 2000, metric = 2.84% * 2000 741.722s (  2.7 samples/s);
Finished Evaluation [120]: Minibatch[1-2000]: metric = 10.64% * 2000;
0.6104478287957609
 Minibatch[   1- 100]: loss = 0.279211 * 100, metric = 2.93% * 100;
 Minibatch[ 101- 200]: loss = 0.269897 * 100, metric = 2.64% * 100;
 Minibatch[ 201- 300]: loss = 0.271056 * 100, metric = 2.67% * 100;
 Minibatch[ 301- 400]: loss = 0.266489 * 100, metric = 2.73% * 100;
 Minibatch[ 401- 500]: loss = 0.278109 * 100, metric = 3.04% * 100;
 Minibatch[ 501- 600]: loss = 0.266979 * 100, metric = 2.69% * 100;
 Minibatch[ 601- 700]: loss = 0.262586 * 100, metric = 2.76% * 100;
 Minibatch[ 701- 800]: loss = 0.274499 * 100, metric = 2.88% * 100;
 Minibatch[ 801- 900]: loss = 0.271278 * 100, metric = 2.70% * 100;
 Minibatch[ 901-1000]: loss = 0.277406 * 100, metric = 2.75% * 100;
 Minibatch[1001-1100]: loss = 0.268723 * 100, metric = 2.70% * 100;
 Minibatch[1101-1200]: loss = 0.267882 * 100, metric = 2.78% * 100;
 Minibatch[1201-1300]: loss = 0.286762 * 100, metric = 3.18% * 100;
 Minibatch[1301-1400]: loss = 0.274702 * 100, metric = 2.86% * 100;
 Minibatch[1401-1500]: loss = 0.280778 * 100, metric = 2.90% * 100;
 Minibatch[1501-1600]: loss = 0.279356 * 100, metric = 2.88% * 100;
 Minibatch[1601-1700]: loss = 0.271417 * 100, metric = 2.91% * 100;
 Minibatch[1701-1800]: loss = 0.278288 * 100, metric = 2.93% * 100;
 Minibatch[1801-1900]: loss = 0.269670 * 100, metric = 2.76% * 100;
 Minibatch[1901-2000]: loss = 0.281115 * 100, metric = 3.04% * 100;
Finished Epoch[121 of 200]: [Training] loss = 0.273810 * 2000, metric = 2.84% * 2000 697.140s (  2.9 samples/s);
Finished Evaluation [121]: Minibatch[1-2000]: metric = 11.68% * 2000;
 Minibatch[   1- 100]: loss = 0.277946 * 100, metric = 2.79% * 100;
 Minibatch[ 101- 200]: loss = 0.277339 * 100, metric = 2.84% * 100;
 Minibatch[ 201- 300]: loss = 0.270693 * 100, metric = 2.73% * 100;
 Minibatch[ 301- 400]: loss = 0.283117 * 100, metric = 3.14% * 100;
 Minibatch[ 401- 500]: loss = 0.267552 * 100, metric = 2.81% * 100;
 Minibatch[ 501- 600]: loss = 0.270162 * 100, metric = 2.90% * 100;
 Minibatch[ 601- 700]: loss = 0.271919 * 100, metric = 2.85% * 100;
 Minibatch[ 701- 800]: loss = 0.268369 * 100, metric = 2.78% * 100;
 Minibatch[ 801- 900]: loss = 0.261275 * 100, metric = 2.71% * 100;
 Minibatch[ 901-1000]: loss = 0.274679 * 100, metric = 2.86% * 100;
 Minibatch[1001-1100]: loss = 0.268827 * 100, metric = 2.65% * 100;
 Minibatch[1101-1200]: loss = 0.265216 * 100, metric = 2.60% * 100;
 Minibatch[1201-1300]: loss = 0.283936 * 100, metric = 3.07% * 100;
 Minibatch[1301-1400]: loss = 0.275619 * 100, metric = 2.80% * 100;
 Minibatch[1401-1500]: loss = 0.275013 * 100, metric = 2.89% * 100;
 Minibatch[1501-1600]: loss = 0.275859 * 100, metric = 2.83% * 100;
 Minibatch[1601-1700]: loss = 0.279959 * 100, metric = 2.78% * 100;
 Minibatch[1701-1800]: loss = 0.265538 * 100, metric = 2.70% * 100;
 Minibatch[1801-1900]: loss = 0.268618 * 100, metric = 2.83% * 100;
 Minibatch[1901-2000]: loss = 0.272984 * 100, metric = 2.77% * 100;
Finished Epoch[122 of 200]: [Training] loss = 0.272731 * 2000, metric = 2.82% * 2000 702.497s (  2.8 samples/s);
Finished Evaluation [122]: Minibatch[1-2000]: metric = 10.88% * 2000;
 Minibatch[   1- 100]: loss = 0.274478 * 100, metric = 2.75% * 100;
 Minibatch[ 101- 200]: loss = 0.273627 * 100, metric = 2.80% * 100;
 Minibatch[ 201- 300]: loss = 0.284555 * 100, metric = 3.09% * 100;
 Minibatch[ 301- 400]: loss = 0.274605 * 100, metric = 2.96% * 100;
 Minibatch[ 401- 500]: loss = 0.270497 * 100, metric = 2.81% * 100;
 Minibatch[ 501- 600]: loss = 0.275763 * 100, metric = 2.90% * 100;
 Minibatch[ 601- 700]: loss = 0.271147 * 100, metric = 2.97% * 100;
 Minibatch[ 701- 800]: loss = 0.271287 * 100, metric = 2.82% * 100;
 Minibatch[ 801- 900]: loss = 0.263723 * 100, metric = 2.70% * 100;
 Minibatch[ 901-1000]: loss = 0.276810 * 100, metric = 2.95% * 100;
 Minibatch[1001-1100]: loss = 0.266534 * 100, metric = 2.74% * 100;
 Minibatch[1101-1200]: loss = 0.274983 * 100, metric = 2.86% * 100;
 Minibatch[1201-1300]: loss = 0.275836 * 100, metric = 2.96% * 100;
 Minibatch[1301-1400]: loss = 0.268184 * 100, metric = 2.65% * 100;
 Minibatch[1401-1500]: loss = 0.266834 * 100, metric = 2.75% * 100;
 Minibatch[1501-1600]: loss = 0.270726 * 100, metric = 2.71% * 100;
 Minibatch[1601-1700]: loss = 0.276023 * 100, metric = 2.89% * 100;
 Minibatch[1701-1800]: loss = 0.271064 * 100, metric = 2.70% * 100;
 Minibatch[1801-1900]: loss = 0.268396 * 100, metric = 2.86% * 100;
 Minibatch[1901-2000]: loss = 0.281178 * 100, metric = 2.91% * 100;
Finished Epoch[123 of 200]: [Training] loss = 0.272812 * 2000, metric = 2.84% * 2000 708.127s (  2.8 samples/s);
Finished Evaluation [123]: Minibatch[1-2000]: metric = 11.24% * 2000;
 Minibatch[   1- 100]: loss = 0.263979 * 100, metric = 2.60% * 100;
 Minibatch[ 101- 200]: loss = 0.263556 * 100, metric = 2.72% * 100;
 Minibatch[ 201- 300]: loss = 0.263830 * 100, metric = 2.80% * 100;
 Minibatch[ 301- 400]: loss = 0.261289 * 100, metric = 2.69% * 100;
 Minibatch[ 401- 500]: loss = 0.273807 * 100, metric = 2.91% * 100;
 Minibatch[ 501- 600]: loss = 0.276700 * 100, metric = 2.88% * 100;
 Minibatch[ 601- 700]: loss = 0.281346 * 100, metric = 2.97% * 100;
 Minibatch[ 701- 800]: loss = 0.285607 * 100, metric = 2.99% * 100;
 Minibatch[ 801- 900]: loss = 0.282873 * 100, metric = 2.97% * 100;
 Minibatch[ 901-1000]: loss = 0.278882 * 100, metric = 2.76% * 100;
 Minibatch[1001-1100]: loss = 0.263721 * 100, metric = 2.68% * 100;
 Minibatch[1101-1200]: loss = 0.279122 * 100, metric = 2.90% * 100;
 Minibatch[1201-1300]: loss = 0.285008 * 100, metric = 3.01% * 100;
 Minibatch[1301-1400]: loss = 0.270993 * 100, metric = 2.77% * 100;
 Minibatch[1401-1500]: loss = 0.285212 * 100, metric = 2.95% * 100;
 Minibatch[1501-1600]: loss = 0.277791 * 100, metric = 2.89% * 100;
 Minibatch[1601-1700]: loss = 0.278806 * 100, metric = 3.02% * 100;
 Minibatch[1701-1800]: loss = 0.269919 * 100, metric = 2.87% * 100;
 Minibatch[1801-1900]: loss = 0.268280 * 100, metric = 2.89% * 100;
 Minibatch[1901-2000]: loss = 0.271558 * 100, metric = 2.74% * 100;
Finished Epoch[124 of 200]: [Training] loss = 0.274114 * 2000, metric = 2.85% * 2000 819.404s (  2.4 samples/s);
Finished Evaluation [124]: Minibatch[1-2000]: metric = 11.01% * 2000;
 Minibatch[   1- 100]: loss = 0.270899 * 100, metric = 2.91% * 100;
 Minibatch[ 101- 200]: loss = 0.279593 * 100, metric = 2.98% * 100;
 Minibatch[ 201- 300]: loss = 0.273032 * 100, metric = 2.64% * 100;
 Minibatch[ 301- 400]: loss = 0.277148 * 100, metric = 3.00% * 100;
 Minibatch[ 401- 500]: loss = 0.274522 * 100, metric = 2.93% * 100;
 Minibatch[ 501- 600]: loss = 0.274084 * 100, metric = 2.81% * 100;
 Minibatch[ 601- 700]: loss = 0.270536 * 100, metric = 2.81% * 100;
 Minibatch[ 701- 800]: loss = 0.270546 * 100, metric = 2.89% * 100;
 Minibatch[ 801- 900]: loss = 0.260843 * 100, metric = 2.62% * 100;
 Minibatch[ 901-1000]: loss = 0.271446 * 100, metric = 2.59% * 100;
 Minibatch[1001-1100]: loss = 0.275326 * 100, metric = 2.87% * 100;
 Minibatch[1101-1200]: loss = 0.271039 * 100, metric = 2.66% * 100;
 Minibatch[1201-1300]: loss = 0.273808 * 100, metric = 2.83% * 100;
 Minibatch[1301-1400]: loss = 0.275716 * 100, metric = 2.67% * 100;
 Minibatch[1401-1500]: loss = 0.280373 * 100, metric = 2.96% * 100;
 Minibatch[1501-1600]: loss = 0.266542 * 100, metric = 2.73% * 100;
 Minibatch[1601-1700]: loss = 0.270373 * 100, metric = 2.76% * 100;
 Minibatch[1701-1800]: loss = 0.265412 * 100, metric = 2.75% * 100;
 Minibatch[1801-1900]: loss = 0.268366 * 100, metric = 2.75% * 100;
 Minibatch[1901-2000]: loss = 0.283804 * 100, metric = 2.96% * 100;
Finished Epoch[125 of 200]: [Training] loss = 0.272670 * 2000, metric = 2.81% * 2000 826.752s (  2.4 samples/s);
Finished Evaluation [125]: Minibatch[1-2000]: metric = 10.77% * 2000;
 Minibatch[   1- 100]: loss = 0.282669 * 100, metric = 2.84% * 100;
 Minibatch[ 101- 200]: loss = 0.278472 * 100, metric = 2.97% * 100;
 Minibatch[ 201- 300]: loss = 0.272030 * 100, metric = 2.76% * 100;
 Minibatch[ 301- 400]: loss = 0.267531 * 100, metric = 2.69% * 100;
 Minibatch[ 401- 500]: loss = 0.277957 * 100, metric = 3.03% * 100;
 Minibatch[ 501- 600]: loss = 0.261272 * 100, metric = 2.78% * 100;
 Minibatch[ 601- 700]: loss = 0.265890 * 100, metric = 2.78% * 100;
 Minibatch[ 701- 800]: loss = 0.271460 * 100, metric = 2.82% * 100;
 Minibatch[ 801- 900]: loss = 0.277600 * 100, metric = 2.81% * 100;
 Minibatch[ 901-1000]: loss = 0.274019 * 100, metric = 2.55% * 100;
 Minibatch[1001-1100]: loss = 0.270883 * 100, metric = 2.84% * 100;
 Minibatch[1101-1200]: loss = 0.258187 * 100, metric = 2.55% * 100;
 Minibatch[1201-1300]: loss = 0.263080 * 100, metric = 2.63% * 100;
 Minibatch[1301-1400]: loss = 0.274707 * 100, metric = 2.93% * 100;
 Minibatch[1401-1500]: loss = 0.257364 * 100, metric = 2.68% * 100;
 Minibatch[1501-1600]: loss = 0.270115 * 100, metric = 2.88% * 100;
 Minibatch[1601-1700]: loss = 0.271364 * 100, metric = 2.82% * 100;
 Minibatch[1701-1800]: loss = 0.260304 * 100, metric = 2.62% * 100;
 Minibatch[1801-1900]: loss = 0.266122 * 100, metric = 2.70% * 100;
 Minibatch[1901-2000]: loss = 0.265810 * 100, metric = 2.79% * 100;
Finished Epoch[126 of 200]: [Training] loss = 0.269342 * 2000, metric = 2.77% * 2000 799.904s (  2.5 samples/s);
Finished Evaluation [126]: Minibatch[1-2000]: metric = 11.60% * 2000;
 Minibatch[   1- 100]: loss = 0.268280 * 100, metric = 2.73% * 100;
 Minibatch[ 101- 200]: loss = 0.261529 * 100, metric = 2.64% * 100;
 Minibatch[ 201- 300]: loss = 0.277917 * 100, metric = 2.97% * 100;
 Minibatch[ 301- 400]: loss = 0.278166 * 100, metric = 2.80% * 100;
 Minibatch[ 401- 500]: loss = 0.278827 * 100, metric = 2.73% * 100;
 Minibatch[ 501- 600]: loss = 0.270350 * 100, metric = 2.77% * 100;
 Minibatch[ 601- 700]: loss = 0.264260 * 100, metric = 2.64% * 100;
 Minibatch[ 701- 800]: loss = 0.263206 * 100, metric = 2.83% * 100;
 Minibatch[ 801- 900]: loss = 0.263213 * 100, metric = 2.65% * 100;
 Minibatch[ 901-1000]: loss = 0.291363 * 100, metric = 3.03% * 100;
 Minibatch[1001-1100]: loss = 0.264603 * 100, metric = 2.70% * 100;
 Minibatch[1101-1200]: loss = 0.260087 * 100, metric = 2.56% * 100;
 Minibatch[1201-1300]: loss = 0.259199 * 100, metric = 2.57% * 100;
 Minibatch[1301-1400]: loss = 0.271844 * 100, metric = 2.71% * 100;
 Minibatch[1401-1500]: loss = 0.267052 * 100, metric = 2.74% * 100;
 Minibatch[1501-1600]: loss = 0.266419 * 100, metric = 2.69% * 100;
 Minibatch[1601-1700]: loss = 0.269487 * 100, metric = 2.82% * 100;
 Minibatch[1701-1800]: loss = 0.262913 * 100, metric = 2.63% * 100;
 Minibatch[1801-1900]: loss = 0.264068 * 100, metric = 2.58% * 100;
 Minibatch[1901-2000]: loss = 0.257327 * 100, metric = 2.47% * 100;
Finished Epoch[127 of 200]: [Training] loss = 0.268006 * 2000, metric = 2.71% * 2000 795.561s (  2.5 samples/s);
Finished Evaluation [127]: Minibatch[1-2000]: metric = 11.48% * 2000;
 Minibatch[   1- 100]: loss = 0.262978 * 100, metric = 2.58% * 100;
 Minibatch[ 101- 200]: loss = 0.271815 * 100, metric = 2.72% * 100;
 Minibatch[ 201- 300]: loss = 0.263740 * 100, metric = 2.57% * 100;
 Minibatch[ 301- 400]: loss = 0.275642 * 100, metric = 2.85% * 100;
 Minibatch[ 401- 500]: loss = 0.275792 * 100, metric = 2.79% * 100;
 Minibatch[ 501- 600]: loss = 0.269352 * 100, metric = 2.78% * 100;
 Minibatch[ 601- 700]: loss = 0.257846 * 100, metric = 2.56% * 100;
 Minibatch[ 701- 800]: loss = 0.277353 * 100, metric = 2.86% * 100;
 Minibatch[ 801- 900]: loss = 0.265698 * 100, metric = 2.88% * 100;
 Minibatch[ 901-1000]: loss = 0.259951 * 100, metric = 2.59% * 100;
 Minibatch[1001-1100]: loss = 0.266324 * 100, metric = 2.69% * 100;
 Minibatch[1101-1200]: loss = 0.258726 * 100, metric = 2.53% * 100;
 Minibatch[1201-1300]: loss = 0.277840 * 100, metric = 2.59% * 100;
 Minibatch[1301-1400]: loss = 0.270434 * 100, metric = 2.86% * 100;
 Minibatch[1401-1500]: loss = 0.265864 * 100, metric = 2.66% * 100;
 Minibatch[1501-1600]: loss = 0.274177 * 100, metric = 2.71% * 100;
 Minibatch[1601-1700]: loss = 0.271453 * 100, metric = 2.83% * 100;
 Minibatch[1701-1800]: loss = 0.278812 * 100, metric = 2.82% * 100;
 Minibatch[1801-1900]: loss = 0.267819 * 100, metric = 2.61% * 100;
 Minibatch[1901-2000]: loss = 0.270390 * 100, metric = 2.65% * 100;
Finished Epoch[128 of 200]: [Training] loss = 0.269100 * 2000, metric = 2.71% * 2000 787.296s (  2.5 samples/s);
Finished Evaluation [128]: Minibatch[1-2000]: metric = 10.74% * 2000;
0.6072744972258807
 Minibatch[   1- 100]: loss = 0.268108 * 100, metric = 2.61% * 100;
 Minibatch[ 101- 200]: loss = 0.280497 * 100, metric = 2.80% * 100;
 Minibatch[ 201- 300]: loss = 0.285117 * 100, metric = 3.02% * 100;
 Minibatch[ 301- 400]: loss = 0.272309 * 100, metric = 2.83% * 100;
 Minibatch[ 401- 500]: loss = 0.266583 * 100, metric = 2.90% * 100;
 Minibatch[ 501- 600]: loss = 0.277552 * 100, metric = 2.91% * 100;
 Minibatch[ 601- 700]: loss = 0.269308 * 100, metric = 2.75% * 100;
 Minibatch[ 701- 800]: loss = 0.278151 * 100, metric = 2.90% * 100;
 Minibatch[ 801- 900]: loss = 0.259690 * 100, metric = 2.48% * 100;
 Minibatch[ 901-1000]: loss = 0.277414 * 100, metric = 2.66% * 100;
 Minibatch[1001-1100]: loss = 0.264233 * 100, metric = 2.72% * 100;
 Minibatch[1101-1200]: loss = 0.265368 * 100, metric = 2.65% * 100;
 Minibatch[1201-1300]: loss = 0.277466 * 100, metric = 2.86% * 100;
 Minibatch[1301-1400]: loss = 0.266342 * 100, metric = 2.66% * 100;
 Minibatch[1401-1500]: loss = 0.268796 * 100, metric = 2.61% * 100;
 Minibatch[1501-1600]: loss = 0.266631 * 100, metric = 2.80% * 100;
 Minibatch[1601-1700]: loss = 0.264622 * 100, metric = 2.82% * 100;
 Minibatch[1701-1800]: loss = 0.267814 * 100, metric = 2.62% * 100;
 Minibatch[1801-1900]: loss = 0.259224 * 100, metric = 2.56% * 100;
 Minibatch[1901-2000]: loss = 0.277725 * 100, metric = 2.66% * 100;
Finished Epoch[129 of 200]: [Training] loss = 0.270647 * 2000, metric = 2.74% * 2000 789.900s (  2.5 samples/s);
Finished Evaluation [129]: Minibatch[1-2000]: metric = 10.51% * 2000;
0.6031043772958219
 Minibatch[   1- 100]: loss = 0.283825 * 100, metric = 2.91% * 100;
 Minibatch[ 101- 200]: loss = 0.267096 * 100, metric = 2.85% * 100;
 Minibatch[ 201- 300]: loss = 0.258057 * 100, metric = 2.72% * 100;
 Minibatch[ 301- 400]: loss = 0.261585 * 100, metric = 2.68% * 100;
 Minibatch[ 401- 500]: loss = 0.274406 * 100, metric = 2.88% * 100;
 Minibatch[ 501- 600]: loss = 0.280191 * 100, metric = 2.96% * 100;
 Minibatch[ 601- 700]: loss = 0.278615 * 100, metric = 2.98% * 100;
 Minibatch[ 701- 800]: loss = 0.259170 * 100, metric = 2.47% * 100;
 Minibatch[ 801- 900]: loss = 0.273118 * 100, metric = 2.78% * 100;
 Minibatch[ 901-1000]: loss = 0.276123 * 100, metric = 2.74% * 100;
 Minibatch[1001-1100]: loss = 0.280651 * 100, metric = 2.87% * 100;
 Minibatch[1101-1200]: loss = 0.281010 * 100, metric = 2.75% * 100;
 Minibatch[1201-1300]: loss = 0.266472 * 100, metric = 2.72% * 100;
 Minibatch[1301-1400]: loss = 0.264281 * 100, metric = 2.63% * 100;
 Minibatch[1401-1500]: loss = 0.268623 * 100, metric = 2.84% * 100;
 Minibatch[1501-1600]: loss = 0.258501 * 100, metric = 2.50% * 100;
 Minibatch[1601-1700]: loss = 0.258510 * 100, metric = 2.53% * 100;
 Minibatch[1701-1800]: loss = 0.255536 * 100, metric = 2.63% * 100;
 Minibatch[1801-1900]: loss = 0.259234 * 100, metric = 2.59% * 100;
 Minibatch[1901-2000]: loss = 0.256984 * 100, metric = 2.56% * 100;
Finished Epoch[130 of 200]: [Training] loss = 0.268099 * 2000, metric = 2.73% * 2000 786.438s (  2.5 samples/s);
Finished Evaluation [130]: Minibatch[1-2000]: metric = 11.18% * 2000;
 Minibatch[   1- 100]: loss = 0.275226 * 100, metric = 2.77% * 100;
 Minibatch[ 101- 200]: loss = 0.265714 * 100, metric = 2.82% * 100;
 Minibatch[ 201- 300]: loss = 0.260404 * 100, metric = 2.65% * 100;
 Minibatch[ 301- 400]: loss = 0.259670 * 100, metric = 2.51% * 100;
 Minibatch[ 401- 500]: loss = 0.258568 * 100, metric = 2.60% * 100;
 Minibatch[ 501- 600]: loss = 0.261770 * 100, metric = 2.75% * 100;
 Minibatch[ 601- 700]: loss = 0.253855 * 100, metric = 2.55% * 100;
 Minibatch[ 701- 800]: loss = 0.249179 * 100, metric = 2.34% * 100;
 Minibatch[ 801- 900]: loss = 0.256483 * 100, metric = 2.44% * 100;
 Minibatch[ 901-1000]: loss = 0.262817 * 100, metric = 2.55% * 100;
 Minibatch[1001-1100]: loss = 0.270488 * 100, metric = 2.72% * 100;
 Minibatch[1101-1200]: loss = 0.252906 * 100, metric = 2.53% * 100;
 Minibatch[1201-1300]: loss = 0.266732 * 100, metric = 2.70% * 100;
 Minibatch[1301-1400]: loss = 0.266647 * 100, metric = 2.90% * 100;
 Minibatch[1401-1500]: loss = 0.273847 * 100, metric = 2.90% * 100;
 Minibatch[1501-1600]: loss = 0.270098 * 100, metric = 2.60% * 100;
 Minibatch[1601-1700]: loss = 0.260548 * 100, metric = 2.61% * 100;
 Minibatch[1701-1800]: loss = 0.263188 * 100, metric = 2.75% * 100;
 Minibatch[1801-1900]: loss = 0.271404 * 100, metric = 2.85% * 100;
 Minibatch[1901-2000]: loss = 0.256974 * 100, metric = 2.62% * 100;
Finished Epoch[131 of 200]: [Training] loss = 0.262826 * 2000, metric = 2.66% * 2000 789.544s (  2.5 samples/s);
Finished Evaluation [131]: Minibatch[1-2000]: metric = 10.59% * 2000;
 Minibatch[   1- 100]: loss = 0.275015 * 100, metric = 2.73% * 100;
 Minibatch[ 101- 200]: loss = 0.262360 * 100, metric = 2.71% * 100;
 Minibatch[ 201- 300]: loss = 0.270028 * 100, metric = 2.87% * 100;
 Minibatch[ 301- 400]: loss = 0.252639 * 100, metric = 2.53% * 100;
 Minibatch[ 401- 500]: loss = 0.266527 * 100, metric = 2.72% * 100;
 Minibatch[ 501- 600]: loss = 0.258809 * 100, metric = 2.60% * 100;
 Minibatch[ 601- 700]: loss = 0.259636 * 100, metric = 2.62% * 100;
 Minibatch[ 701- 800]: loss = 0.261554 * 100, metric = 2.51% * 100;
 Minibatch[ 801- 900]: loss = 0.271757 * 100, metric = 2.72% * 100;
 Minibatch[ 901-1000]: loss = 0.262769 * 100, metric = 2.61% * 100;
 Minibatch[1001-1100]: loss = 0.257191 * 100, metric = 2.43% * 100;
 Minibatch[1101-1200]: loss = 0.261472 * 100, metric = 2.61% * 100;
 Minibatch[1201-1300]: loss = 0.267913 * 100, metric = 2.59% * 100;
 Minibatch[1301-1400]: loss = 0.265769 * 100, metric = 2.63% * 100;
 Minibatch[1401-1500]: loss = 0.267711 * 100, metric = 2.59% * 100;
 Minibatch[1501-1600]: loss = 0.258434 * 100, metric = 2.51% * 100;
 Minibatch[1601-1700]: loss = 0.261206 * 100, metric = 2.55% * 100;
 Minibatch[1701-1800]: loss = 0.259669 * 100, metric = 2.57% * 100;
 Minibatch[1801-1900]: loss = 0.244855 * 100, metric = 2.33% * 100;
 Minibatch[1901-2000]: loss = 0.270002 * 100, metric = 2.72% * 100;
Finished Epoch[132 of 200]: [Training] loss = 0.262766 * 2000, metric = 2.61% * 2000 785.183s (  2.5 samples/s);
Finished Evaluation [132]: Minibatch[1-2000]: metric = 10.88% * 2000;
 Minibatch[   1- 100]: loss = 0.276628 * 100, metric = 2.74% * 100;
 Minibatch[ 101- 200]: loss = 0.259900 * 100, metric = 2.56% * 100;
 Minibatch[ 201- 300]: loss = 0.265678 * 100, metric = 2.64% * 100;
 Minibatch[ 301- 400]: loss = 0.257305 * 100, metric = 2.42% * 100;
 Minibatch[ 401- 500]: loss = 0.262233 * 100, metric = 2.59% * 100;
 Minibatch[ 501- 600]: loss = 0.268209 * 100, metric = 2.74% * 100;
 Minibatch[ 601- 700]: loss = 0.257270 * 100, metric = 2.65% * 100;
 Minibatch[ 701- 800]: loss = 0.257713 * 100, metric = 2.56% * 100;
 Minibatch[ 801- 900]: loss = 0.258692 * 100, metric = 2.52% * 100;
 Minibatch[ 901-1000]: loss = 0.260084 * 100, metric = 2.68% * 100;
 Minibatch[1001-1100]: loss = 0.272312 * 100, metric = 2.92% * 100;
 Minibatch[1101-1200]: loss = 0.270965 * 100, metric = 2.85% * 100;
 Minibatch[1201-1300]: loss = 0.262453 * 100, metric = 2.67% * 100;
 Minibatch[1301-1400]: loss = 0.266740 * 100, metric = 2.66% * 100;
 Minibatch[1401-1500]: loss = 0.276722 * 100, metric = 2.86% * 100;
 Minibatch[1501-1600]: loss = 0.272059 * 100, metric = 2.81% * 100;
 Minibatch[1601-1700]: loss = 0.271248 * 100, metric = 2.58% * 100;
 Minibatch[1701-1800]: loss = 0.274565 * 100, metric = 2.75% * 100;
 Minibatch[1801-1900]: loss = 0.272270 * 100, metric = 2.71% * 100;
 Minibatch[1901-2000]: loss = 0.265965 * 100, metric = 2.68% * 100;
Finished Epoch[133 of 200]: [Training] loss = 0.266451 * 2000, metric = 2.68% * 2000 793.124s (  2.5 samples/s);
Finished Evaluation [133]: Minibatch[1-2000]: metric = 10.72% * 2000;
 Minibatch[   1- 100]: loss = 0.272277 * 100, metric = 2.73% * 100;
 Minibatch[ 101- 200]: loss = 0.264505 * 100, metric = 2.53% * 100;
 Minibatch[ 201- 300]: loss = 0.270058 * 100, metric = 2.68% * 100;
 Minibatch[ 301- 400]: loss = 0.266681 * 100, metric = 2.73% * 100;
 Minibatch[ 401- 500]: loss = 0.273420 * 100, metric = 2.71% * 100;
 Minibatch[ 501- 600]: loss = 0.257583 * 100, metric = 2.60% * 100;
 Minibatch[ 601- 700]: loss = 0.253650 * 100, metric = 2.45% * 100;
 Minibatch[ 701- 800]: loss = 0.257068 * 100, metric = 2.50% * 100;
 Minibatch[ 801- 900]: loss = 0.264319 * 100, metric = 2.73% * 100;
 Minibatch[ 901-1000]: loss = 0.261927 * 100, metric = 2.61% * 100;
 Minibatch[1001-1100]: loss = 0.260428 * 100, metric = 2.57% * 100;
 Minibatch[1101-1200]: loss = 0.257800 * 100, metric = 2.49% * 100;
 Minibatch[1201-1300]: loss = 0.258910 * 100, metric = 2.67% * 100;
 Minibatch[1301-1400]: loss = 0.259917 * 100, metric = 2.46% * 100;
 Minibatch[1401-1500]: loss = 0.261869 * 100, metric = 2.67% * 100;
 Minibatch[1501-1600]: loss = 0.259384 * 100, metric = 2.62% * 100;
 Minibatch[1601-1700]: loss = 0.260818 * 100, metric = 2.55% * 100;
 Minibatch[1701-1800]: loss = 0.257953 * 100, metric = 2.43% * 100;
 Minibatch[1801-1900]: loss = 0.272607 * 100, metric = 2.72% * 100;
 Minibatch[1901-2000]: loss = 0.260129 * 100, metric = 2.50% * 100;
Finished Epoch[134 of 200]: [Training] loss = 0.262565 * 2000, metric = 2.60% * 2000 787.583s (  2.5 samples/s);
Finished Evaluation [134]: Minibatch[1-2000]: metric = 11.34% * 2000;
 Minibatch[   1- 100]: loss = 0.260307 * 100, metric = 2.53% * 100;
 Minibatch[ 101- 200]: loss = 0.256022 * 100, metric = 2.42% * 100;
 Minibatch[ 201- 300]: loss = 0.261622 * 100, metric = 2.56% * 100;
 Minibatch[ 301- 400]: loss = 0.260314 * 100, metric = 2.47% * 100;
 Minibatch[ 401- 500]: loss = 0.258443 * 100, metric = 2.48% * 100;
 Minibatch[ 501- 600]: loss = 0.263504 * 100, metric = 2.63% * 100;
 Minibatch[ 601- 700]: loss = 0.265695 * 100, metric = 2.61% * 100;
 Minibatch[ 701- 800]: loss = 0.250504 * 100, metric = 2.50% * 100;
 Minibatch[ 801- 900]: loss = 0.249972 * 100, metric = 2.57% * 100;
 Minibatch[ 901-1000]: loss = 0.263243 * 100, metric = 2.65% * 100;
 Minibatch[1001-1100]: loss = 0.265352 * 100, metric = 2.71% * 100;
 Minibatch[1101-1200]: loss = 0.267690 * 100, metric = 2.73% * 100;
 Minibatch[1201-1300]: loss = 0.259126 * 100, metric = 2.63% * 100;
 Minibatch[1301-1400]: loss = 0.264576 * 100, metric = 2.54% * 100;
 Minibatch[1401-1500]: loss = 0.266180 * 100, metric = 2.67% * 100;
 Minibatch[1501-1600]: loss = 0.250272 * 100, metric = 2.30% * 100;
 Minibatch[1601-1700]: loss = 0.256514 * 100, metric = 2.65% * 100;
 Minibatch[1701-1800]: loss = 0.260381 * 100, metric = 2.49% * 100;
 Minibatch[1801-1900]: loss = 0.268040 * 100, metric = 2.66% * 100;
 Minibatch[1901-2000]: loss = 0.269081 * 100, metric = 2.66% * 100;
Finished Epoch[135 of 200]: [Training] loss = 0.260842 * 2000, metric = 2.57% * 2000 790.071s (  2.5 samples/s);
Finished Evaluation [135]: Minibatch[1-2000]: metric = 10.95% * 2000;
 Minibatch[   1- 100]: loss = 0.272511 * 100, metric = 2.78% * 100;
 Minibatch[ 101- 200]: loss = 0.264853 * 100, metric = 2.59% * 100;
 Minibatch[ 201- 300]: loss = 0.254701 * 100, metric = 2.51% * 100;
 Minibatch[ 301- 400]: loss = 0.266380 * 100, metric = 2.58% * 100;
 Minibatch[ 401- 500]: loss = 0.264630 * 100, metric = 2.55% * 100;
 Minibatch[ 501- 600]: loss = 0.266966 * 100, metric = 2.71% * 100;
 Minibatch[ 601- 700]: loss = 0.261773 * 100, metric = 2.69% * 100;
 Minibatch[ 701- 800]: loss = 0.271607 * 100, metric = 2.60% * 100;
 Minibatch[ 801- 900]: loss = 0.258793 * 100, metric = 2.44% * 100;
 Minibatch[ 901-1000]: loss = 0.269538 * 100, metric = 2.72% * 100;
 Minibatch[1001-1100]: loss = 0.268501 * 100, metric = 2.65% * 100;
 Minibatch[1101-1200]: loss = 0.264887 * 100, metric = 2.63% * 100;
 Minibatch[1201-1300]: loss = 0.270379 * 100, metric = 2.71% * 100;
 Minibatch[1301-1400]: loss = 0.267370 * 100, metric = 2.73% * 100;
 Minibatch[1401-1500]: loss = 0.262195 * 100, metric = 2.54% * 100;
 Minibatch[1501-1600]: loss = 0.273305 * 100, metric = 2.71% * 100;
 Minibatch[1601-1700]: loss = 0.256112 * 100, metric = 2.45% * 100;
 Minibatch[1701-1800]: loss = 0.260865 * 100, metric = 2.60% * 100;
 Minibatch[1801-1900]: loss = 0.259200 * 100, metric = 2.50% * 100;
 Minibatch[1901-2000]: loss = 0.263069 * 100, metric = 2.45% * 100;
Finished Epoch[136 of 200]: [Training] loss = 0.264882 * 2000, metric = 2.61% * 2000 781.966s (  2.6 samples/s);
Finished Evaluation [136]: Minibatch[1-2000]: metric = 11.38% * 2000;
 Minibatch[   1- 100]: loss = 0.266418 * 100, metric = 2.62% * 100;
 Minibatch[ 101- 200]: loss = 0.266782 * 100, metric = 2.62% * 100;
 Minibatch[ 201- 300]: loss = 0.266238 * 100, metric = 2.59% * 100;
 Minibatch[ 301- 400]: loss = 0.268962 * 100, metric = 2.75% * 100;
 Minibatch[ 401- 500]: loss = 0.253555 * 100, metric = 2.48% * 100;
 Minibatch[ 501- 600]: loss = 0.269699 * 100, metric = 2.62% * 100;
 Minibatch[ 601- 700]: loss = 0.267702 * 100, metric = 2.57% * 100;
 Minibatch[ 701- 800]: loss = 0.258538 * 100, metric = 2.46% * 100;
 Minibatch[ 801- 900]: loss = 0.253728 * 100, metric = 2.52% * 100;
 Minibatch[ 901-1000]: loss = 0.269619 * 100, metric = 2.61% * 100;
 Minibatch[1001-1100]: loss = 0.261904 * 100, metric = 2.65% * 100;
 Minibatch[1101-1200]: loss = 0.266305 * 100, metric = 2.61% * 100;
 Minibatch[1201-1300]: loss = 0.265120 * 100, metric = 2.46% * 100;
 Minibatch[1301-1400]: loss = 0.258029 * 100, metric = 2.50% * 100;
 Minibatch[1401-1500]: loss = 0.260359 * 100, metric = 2.67% * 100;
 Minibatch[1501-1600]: loss = 0.271721 * 100, metric = 2.58% * 100;
 Minibatch[1601-1700]: loss = 0.267570 * 100, metric = 2.66% * 100;
 Minibatch[1701-1800]: loss = 0.260484 * 100, metric = 2.65% * 100;
 Minibatch[1801-1900]: loss = 0.254399 * 100, metric = 2.48% * 100;
 Minibatch[1901-2000]: loss = 0.264467 * 100, metric = 2.59% * 100;
Finished Epoch[137 of 200]: [Training] loss = 0.263580 * 2000, metric = 2.58% * 2000 787.370s (  2.5 samples/s);
Finished Evaluation [137]: Minibatch[1-2000]: metric = 10.46% * 2000;
0.5947325586713851
 Minibatch[   1- 100]: loss = 0.272615 * 100, metric = 2.84% * 100;
 Minibatch[ 101- 200]: loss = 0.259958 * 100, metric = 2.44% * 100;
 Minibatch[ 201- 300]: loss = 0.252387 * 100, metric = 2.39% * 100;
 Minibatch[ 301- 400]: loss = 0.246255 * 100, metric = 2.45% * 100;
 Minibatch[ 401- 500]: loss = 0.251193 * 100, metric = 2.53% * 100;
 Minibatch[ 501- 600]: loss = 0.271227 * 100, metric = 2.73% * 100;
 Minibatch[ 601- 700]: loss = 0.255566 * 100, metric = 2.39% * 100;
 Minibatch[ 701- 800]: loss = 0.261048 * 100, metric = 2.70% * 100;
 Minibatch[ 801- 900]: loss = 0.257683 * 100, metric = 2.56% * 100;
 Minibatch[ 901-1000]: loss = 0.263515 * 100, metric = 2.65% * 100;
 Minibatch[1001-1100]: loss = 0.245752 * 100, metric = 2.43% * 100;
 Minibatch[1101-1200]: loss = 0.249724 * 100, metric = 2.28% * 100;
 Minibatch[1201-1300]: loss = 0.247152 * 100, metric = 2.49% * 100;
 Minibatch[1301-1400]: loss = 0.267550 * 100, metric = 2.65% * 100;
 Minibatch[1401-1500]: loss = 0.247609 * 100, metric = 2.41% * 100;
 Minibatch[1501-1600]: loss = 0.249272 * 100, metric = 2.39% * 100;
 Minibatch[1601-1700]: loss = 0.267006 * 100, metric = 2.65% * 100;
 Minibatch[1701-1800]: loss = 0.250911 * 100, metric = 2.32% * 100;
 Minibatch[1801-1900]: loss = 0.257878 * 100, metric = 2.49% * 100;
 Minibatch[1901-2000]: loss = 0.256008 * 100, metric = 2.49% * 100;
Finished Epoch[138 of 200]: [Training] loss = 0.256515 * 2000, metric = 2.51% * 2000 781.620s (  2.6 samples/s);
Finished Evaluation [138]: Minibatch[1-2000]: metric = 10.56% * 2000;
 Minibatch[   1- 100]: loss = 0.261912 * 100, metric = 2.54% * 100;
 Minibatch[ 101- 200]: loss = 0.265580 * 100, metric = 2.55% * 100;
 Minibatch[ 201- 300]: loss = 0.249962 * 100, metric = 2.41% * 100;
 Minibatch[ 301- 400]: loss = 0.261922 * 100, metric = 2.57% * 100;
 Minibatch[ 401- 500]: loss = 0.250212 * 100, metric = 2.34% * 100;
 Minibatch[ 501- 600]: loss = 0.258739 * 100, metric = 2.68% * 100;
 Minibatch[ 601- 700]: loss = 0.249924 * 100, metric = 2.39% * 100;
 Minibatch[ 701- 800]: loss = 0.252867 * 100, metric = 2.24% * 100;
 Minibatch[ 801- 900]: loss = 0.269813 * 100, metric = 2.71% * 100;
 Minibatch[ 901-1000]: loss = 0.252086 * 100, metric = 2.40% * 100;
 Minibatch[1001-1100]: loss = 0.273732 * 100, metric = 2.77% * 100;
 Minibatch[1101-1200]: loss = 0.238827 * 100, metric = 2.46% * 100;
 Minibatch[1201-1300]: loss = 0.263510 * 100, metric = 2.75% * 100;
 Minibatch[1301-1400]: loss = 0.267171 * 100, metric = 2.64% * 100;
 Minibatch[1401-1500]: loss = 0.249607 * 100, metric = 2.47% * 100;
 Minibatch[1501-1600]: loss = 0.244285 * 100, metric = 2.31% * 100;
 Minibatch[1601-1700]: loss = 0.257643 * 100, metric = 2.54% * 100;
 Minibatch[1701-1800]: loss = 0.261489 * 100, metric = 2.47% * 100;
 Minibatch[1801-1900]: loss = 0.259395 * 100, metric = 2.48% * 100;
 Minibatch[1901-2000]: loss = 0.261548 * 100, metric = 2.54% * 100;
Finished Epoch[139 of 200]: [Training] loss = 0.257511 * 2000, metric = 2.51% * 2000 784.100s (  2.6 samples/s);
Finished Evaluation [139]: Minibatch[1-2000]: metric = 10.99% * 2000;
 Minibatch[   1- 100]: loss = 0.260236 * 100, metric = 2.58% * 100;
 Minibatch[ 101- 200]: loss = 0.269910 * 100, metric = 2.55% * 100;
 Minibatch[ 201- 300]: loss = 0.246975 * 100, metric = 2.32% * 100;
 Minibatch[ 301- 400]: loss = 0.240679 * 100, metric = 2.32% * 100;
 Minibatch[ 401- 500]: loss = 0.248102 * 100, metric = 2.30% * 100;
 Minibatch[ 501- 600]: loss = 0.260844 * 100, metric = 2.62% * 100;
 Minibatch[ 601- 700]: loss = 0.255625 * 100, metric = 2.53% * 100;
 Minibatch[ 701- 800]: loss = 0.252482 * 100, metric = 2.49% * 100;
 Minibatch[ 801- 900]: loss = 0.249654 * 100, metric = 2.42% * 100;
 Minibatch[ 901-1000]: loss = 0.252106 * 100, metric = 2.48% * 100;
 Minibatch[1001-1100]: loss = 0.252988 * 100, metric = 2.38% * 100;
 Minibatch[1101-1200]: loss = 0.244661 * 100, metric = 2.21% * 100;
 Minibatch[1201-1300]: loss = 0.258276 * 100, metric = 2.47% * 100;
 Minibatch[1301-1400]: loss = 0.258216 * 100, metric = 2.48% * 100;
 Minibatch[1401-1500]: loss = 0.252704 * 100, metric = 2.48% * 100;
 Minibatch[1501-1600]: loss = 0.257990 * 100, metric = 2.58% * 100;
 Minibatch[1601-1700]: loss = 0.251784 * 100, metric = 2.44% * 100;
 Minibatch[1701-1800]: loss = 0.248457 * 100, metric = 2.39% * 100;
 Minibatch[1801-1900]: loss = 0.247366 * 100, metric = 2.45% * 100;
 Minibatch[1901-2000]: loss = 0.246938 * 100, metric = 2.40% * 100;
Finished Epoch[140 of 200]: [Training] loss = 0.252800 * 2000, metric = 2.44% * 2000 781.331s (  2.6 samples/s);
Finished Evaluation [140]: Minibatch[1-2000]: metric = 10.50% * 2000;
 Minibatch[   1- 100]: loss = 0.251149 * 100, metric = 2.47% * 100;
 Minibatch[ 101- 200]: loss = 0.247974 * 100, metric = 2.48% * 100;
 Minibatch[ 201- 300]: loss = 0.240167 * 100, metric = 2.37% * 100;
 Minibatch[ 301- 400]: loss = 0.253212 * 100, metric = 2.43% * 100;
 Minibatch[ 401- 500]: loss = 0.255381 * 100, metric = 2.51% * 100;
 Minibatch[ 501- 600]: loss = 0.243698 * 100, metric = 2.41% * 100;
 Minibatch[ 601- 700]: loss = 0.239642 * 100, metric = 2.34% * 100;
 Minibatch[ 701- 800]: loss = 0.262253 * 100, metric = 2.59% * 100;
 Minibatch[ 801- 900]: loss = 0.271582 * 100, metric = 2.67% * 100;
 Minibatch[ 901-1000]: loss = 0.261526 * 100, metric = 2.59% * 100;
 Minibatch[1001-1100]: loss = 0.247607 * 100, metric = 2.48% * 100;
 Minibatch[1101-1200]: loss = 0.259012 * 100, metric = 2.53% * 100;
 Minibatch[1201-1300]: loss = 0.273273 * 100, metric = 2.77% * 100;
 Minibatch[1301-1400]: loss = 0.256161 * 100, metric = 2.33% * 100;
 Minibatch[1401-1500]: loss = 0.253438 * 100, metric = 2.46% * 100;
 Minibatch[1501-1600]: loss = 0.259448 * 100, metric = 2.52% * 100;
 Minibatch[1601-1700]: loss = 0.252082 * 100, metric = 2.42% * 100;
 Minibatch[1701-1800]: loss = 0.255104 * 100, metric = 2.59% * 100;
 Minibatch[1801-1900]: loss = 0.253254 * 100, metric = 2.53% * 100;
 Minibatch[1901-2000]: loss = 0.254105 * 100, metric = 2.54% * 100;
Finished Epoch[141 of 200]: [Training] loss = 0.254503 * 2000, metric = 2.50% * 2000 780.710s (  2.6 samples/s);
Finished Evaluation [141]: Minibatch[1-2000]: metric = 10.83% * 2000;
 Minibatch[   1- 100]: loss = 0.263158 * 100, metric = 2.69% * 100;
 Minibatch[ 101- 200]: loss = 0.244710 * 100, metric = 2.33% * 100;
 Minibatch[ 201- 300]: loss = 0.250369 * 100, metric = 2.31% * 100;
 Minibatch[ 301- 400]: loss = 0.241892 * 100, metric = 2.20% * 100;
 Minibatch[ 401- 500]: loss = 0.250691 * 100, metric = 2.49% * 100;
 Minibatch[ 501- 600]: loss = 0.247540 * 100, metric = 2.27% * 100;
 Minibatch[ 601- 700]: loss = 0.252776 * 100, metric = 2.38% * 100;
 Minibatch[ 701- 800]: loss = 0.251792 * 100, metric = 2.53% * 100;
 Minibatch[ 801- 900]: loss = 0.257347 * 100, metric = 2.52% * 100;
 Minibatch[ 901-1000]: loss = 0.257437 * 100, metric = 2.53% * 100;
 Minibatch[1001-1100]: loss = 0.260652 * 100, metric = 2.49% * 100;
 Minibatch[1101-1200]: loss = 0.263861 * 100, metric = 2.64% * 100;
 Minibatch[1201-1300]: loss = 0.249479 * 100, metric = 2.48% * 100;
 Minibatch[1301-1400]: loss = 0.252246 * 100, metric = 2.34% * 100;
 Minibatch[1401-1500]: loss = 0.269477 * 100, metric = 2.80% * 100;
 Minibatch[1501-1600]: loss = 0.250310 * 100, metric = 2.36% * 100;
 Minibatch[1601-1700]: loss = 0.256626 * 100, metric = 2.33% * 100;
 Minibatch[1701-1800]: loss = 0.248933 * 100, metric = 2.36% * 100;
 Minibatch[1801-1900]: loss = 0.248466 * 100, metric = 2.26% * 100;
 Minibatch[1901-2000]: loss = 0.264313 * 100, metric = 2.57% * 100;
Finished Epoch[142 of 200]: [Training] loss = 0.254104 * 2000, metric = 2.44% * 2000 786.863s (  2.5 samples/s);
Finished Evaluation [142]: Minibatch[1-2000]: metric = 11.07% * 2000;
 Minibatch[   1- 100]: loss = 0.241547 * 100, metric = 2.34% * 100;
 Minibatch[ 101- 200]: loss = 0.251768 * 100, metric = 2.41% * 100;
 Minibatch[ 201- 300]: loss = 0.261550 * 100, metric = 2.58% * 100;
 Minibatch[ 301- 400]: loss = 0.256275 * 100, metric = 2.51% * 100;
 Minibatch[ 401- 500]: loss = 0.257650 * 100, metric = 2.53% * 100;
 Minibatch[ 501- 600]: loss = 0.259443 * 100, metric = 2.43% * 100;
 Minibatch[ 601- 700]: loss = 0.259428 * 100, metric = 2.54% * 100;
 Minibatch[ 701- 800]: loss = 0.267792 * 100, metric = 2.63% * 100;
 Minibatch[ 801- 900]: loss = 0.259516 * 100, metric = 2.72% * 100;
 Minibatch[ 901-1000]: loss = 0.257186 * 100, metric = 2.50% * 100;
 Minibatch[1001-1100]: loss = 0.261220 * 100, metric = 2.55% * 100;
 Minibatch[1101-1200]: loss = 0.250049 * 100, metric = 2.41% * 100;
 Minibatch[1201-1300]: loss = 0.255118 * 100, metric = 2.39% * 100;
 Minibatch[1301-1400]: loss = 0.248562 * 100, metric = 2.47% * 100;
 Minibatch[1401-1500]: loss = 0.255869 * 100, metric = 2.53% * 100;
 Minibatch[1501-1600]: loss = 0.256534 * 100, metric = 2.56% * 100;
 Minibatch[1601-1700]: loss = 0.255802 * 100, metric = 2.50% * 100;
 Minibatch[1701-1800]: loss = 0.262737 * 100, metric = 2.47% * 100;
 Minibatch[1801-1900]: loss = 0.247729 * 100, metric = 2.35% * 100;
 Minibatch[1901-2000]: loss = 0.260389 * 100, metric = 2.43% * 100;
Finished Epoch[143 of 200]: [Training] loss = 0.256308 * 2000, metric = 2.49% * 2000 783.845s (  2.6 samples/s);
Finished Evaluation [143]: Minibatch[1-2000]: metric = 10.70% * 2000;
 Minibatch[   1- 100]: loss = 0.267590 * 100, metric = 2.57% * 100;
 Minibatch[ 101- 200]: loss = 0.257081 * 100, metric = 2.47% * 100;
 Minibatch[ 201- 300]: loss = 0.255775 * 100, metric = 2.35% * 100;
 Minibatch[ 301- 400]: loss = 0.263845 * 100, metric = 2.55% * 100;
 Minibatch[ 401- 500]: loss = 0.255786 * 100, metric = 2.36% * 100;
 Minibatch[ 501- 600]: loss = 0.258428 * 100, metric = 2.51% * 100;
 Minibatch[ 601- 700]: loss = 0.251403 * 100, metric = 2.38% * 100;
 Minibatch[ 701- 800]: loss = 0.264310 * 100, metric = 2.67% * 100;
 Minibatch[ 801- 900]: loss = 0.273579 * 100, metric = 2.60% * 100;
 Minibatch[ 901-1000]: loss = 0.270713 * 100, metric = 2.58% * 100;
 Minibatch[1001-1100]: loss = 0.260129 * 100, metric = 2.65% * 100;
 Minibatch[1101-1200]: loss = 0.272808 * 100, metric = 2.56% * 100;
 Minibatch[1201-1300]: loss = 0.253407 * 100, metric = 2.31% * 100;
 Minibatch[1301-1400]: loss = 0.250292 * 100, metric = 2.54% * 100;
 Minibatch[1401-1500]: loss = 0.255637 * 100, metric = 2.52% * 100;
 Minibatch[1501-1600]: loss = 0.256198 * 100, metric = 2.38% * 100;
 Minibatch[1601-1700]: loss = 0.251618 * 100, metric = 2.35% * 100;
 Minibatch[1701-1800]: loss = 0.246677 * 100, metric = 2.39% * 100;
 Minibatch[1801-1900]: loss = 0.256302 * 100, metric = 2.54% * 100;
 Minibatch[1901-2000]: loss = 0.261328 * 100, metric = 2.52% * 100;
Finished Epoch[144 of 200]: [Training] loss = 0.259145 * 2000, metric = 2.49% * 2000 777.031s (  2.6 samples/s);
Finished Evaluation [144]: Minibatch[1-2000]: metric = 11.51% * 2000;
 Minibatch[   1- 100]: loss = 0.249752 * 100, metric = 2.50% * 100;
 Minibatch[ 101- 200]: loss = 0.243801 * 100, metric = 2.38% * 100;
 Minibatch[ 201- 300]: loss = 0.245982 * 100, metric = 2.34% * 100;
 Minibatch[ 301- 400]: loss = 0.258943 * 100, metric = 2.37% * 100;
 Minibatch[ 401- 500]: loss = 0.261599 * 100, metric = 2.47% * 100;
 Minibatch[ 501- 600]: loss = 0.249923 * 100, metric = 2.36% * 100;
 Minibatch[ 601- 700]: loss = 0.258775 * 100, metric = 2.50% * 100;
 Minibatch[ 701- 800]: loss = 0.257391 * 100, metric = 2.45% * 100;
 Minibatch[ 801- 900]: loss = 0.249718 * 100, metric = 2.42% * 100;
 Minibatch[ 901-1000]: loss = 0.270210 * 100, metric = 2.62% * 100;
 Minibatch[1001-1100]: loss = 0.254421 * 100, metric = 2.57% * 100;
 Minibatch[1101-1200]: loss = 0.242375 * 100, metric = 2.34% * 100;
 Minibatch[1201-1300]: loss = 0.260794 * 100, metric = 2.57% * 100;
 Minibatch[1301-1400]: loss = 0.248338 * 100, metric = 2.36% * 100;
 Minibatch[1401-1500]: loss = 0.254850 * 100, metric = 2.38% * 100;
 Minibatch[1501-1600]: loss = 0.250404 * 100, metric = 2.39% * 100;
 Minibatch[1601-1700]: loss = 0.253294 * 100, metric = 2.49% * 100;
 Minibatch[1701-1800]: loss = 0.251999 * 100, metric = 2.46% * 100;
 Minibatch[1801-1900]: loss = 0.252115 * 100, metric = 2.37% * 100;
 Minibatch[1901-2000]: loss = 0.242021 * 100, metric = 2.16% * 100;
Finished Epoch[145 of 200]: [Training] loss = 0.252835 * 2000, metric = 2.42% * 2000 787.352s (  2.5 samples/s);
Finished Evaluation [145]: Minibatch[1-2000]: metric = 10.41% * 2000;
 Minibatch[   1- 100]: loss = 0.247225 * 100, metric = 2.30% * 100;
 Minibatch[ 101- 200]: loss = 0.242334 * 100, metric = 2.29% * 100;
 Minibatch[ 201- 300]: loss = 0.244270 * 100, metric = 2.34% * 100;
 Minibatch[ 301- 400]: loss = 0.251492 * 100, metric = 2.38% * 100;
 Minibatch[ 401- 500]: loss = 0.249293 * 100, metric = 2.32% * 100;
 Minibatch[ 501- 600]: loss = 0.244166 * 100, metric = 2.21% * 100;
 Minibatch[ 601- 700]: loss = 0.259676 * 100, metric = 2.65% * 100;
 Minibatch[ 701- 800]: loss = 0.255172 * 100, metric = 2.44% * 100;
 Minibatch[ 801- 900]: loss = 0.251022 * 100, metric = 2.50% * 100;
 Minibatch[ 901-1000]: loss = 0.253183 * 100, metric = 2.50% * 100;
 Minibatch[1001-1100]: loss = 0.251953 * 100, metric = 2.40% * 100;
 Minibatch[1101-1200]: loss = 0.254987 * 100, metric = 2.48% * 100;
 Minibatch[1201-1300]: loss = 0.252458 * 100, metric = 2.50% * 100;
 Minibatch[1301-1400]: loss = 0.253592 * 100, metric = 2.44% * 100;
 Minibatch[1401-1500]: loss = 0.248633 * 100, metric = 2.30% * 100;
 Minibatch[1501-1600]: loss = 0.251234 * 100, metric = 2.39% * 100;
 Minibatch[1601-1700]: loss = 0.253242 * 100, metric = 2.43% * 100;
 Minibatch[1701-1800]: loss = 0.255397 * 100, metric = 2.55% * 100;
 Minibatch[1801-1900]: loss = 0.251366 * 100, metric = 2.48% * 100;
 Minibatch[1901-2000]: loss = 0.237945 * 100, metric = 2.31% * 100;
Finished Epoch[146 of 200]: [Training] loss = 0.250432 * 2000, metric = 2.41% * 2000 715.332s (  2.8 samples/s);
Finished Evaluation [146]: Minibatch[1-2000]: metric = 10.78% * 2000;
 Minibatch[   1- 100]: loss = 0.249171 * 100, metric = 2.37% * 100;
 Minibatch[ 101- 200]: loss = 0.241713 * 100, metric = 2.41% * 100;
 Minibatch[ 201- 300]: loss = 0.253259 * 100, metric = 2.48% * 100;
 Minibatch[ 301- 400]: loss = 0.245563 * 100, metric = 2.31% * 100;
 Minibatch[ 401- 500]: loss = 0.241392 * 100, metric = 2.25% * 100;
 Minibatch[ 501- 600]: loss = 0.243632 * 100, metric = 2.32% * 100;
 Minibatch[ 601- 700]: loss = 0.251495 * 100, metric = 2.56% * 100;
 Minibatch[ 701- 800]: loss = 0.248124 * 100, metric = 2.29% * 100;
 Minibatch[ 801- 900]: loss = 0.245055 * 100, metric = 2.30% * 100;
 Minibatch[ 901-1000]: loss = 0.257669 * 100, metric = 2.53% * 100;
 Minibatch[1001-1100]: loss = 0.246373 * 100, metric = 2.34% * 100;
 Minibatch[1101-1200]: loss = 0.257441 * 100, metric = 2.55% * 100;
 Minibatch[1201-1300]: loss = 0.254030 * 100, metric = 2.38% * 100;
 Minibatch[1301-1400]: loss = 0.251416 * 100, metric = 2.34% * 100;
 Minibatch[1401-1500]: loss = 0.250535 * 100, metric = 2.31% * 100;
 Minibatch[1501-1600]: loss = 0.243613 * 100, metric = 2.44% * 100;
 Minibatch[1601-1700]: loss = 0.249962 * 100, metric = 2.46% * 100;
 Minibatch[1701-1800]: loss = 0.263461 * 100, metric = 2.49% * 100;
 Minibatch[1801-1900]: loss = 0.249972 * 100, metric = 2.31% * 100;
 Minibatch[1901-2000]: loss = 0.259337 * 100, metric = 2.64% * 100;
Finished Epoch[147 of 200]: [Training] loss = 0.250161 * 2000, metric = 2.40% * 2000 689.760s (  2.9 samples/s);
Finished Evaluation [147]: Minibatch[1-2000]: metric = 10.44% * 2000;
0.5940480187423527
 Minibatch[   1- 100]: loss = 0.262681 * 100, metric = 2.46% * 100;
 Minibatch[ 101- 200]: loss = 0.254894 * 100, metric = 2.48% * 100;
 Minibatch[ 201- 300]: loss = 0.256389 * 100, metric = 2.39% * 100;
 Minibatch[ 301- 400]: loss = 0.248498 * 100, metric = 2.29% * 100;
 Minibatch[ 401- 500]: loss = 0.253410 * 100, metric = 2.43% * 100;
 Minibatch[ 501- 600]: loss = 0.258868 * 100, metric = 2.45% * 100;
 Minibatch[ 601- 700]: loss = 0.248493 * 100, metric = 2.31% * 100;
 Minibatch[ 701- 800]: loss = 0.252564 * 100, metric = 2.35% * 100;
 Minibatch[ 801- 900]: loss = 0.257691 * 100, metric = 2.37% * 100;
 Minibatch[ 901-1000]: loss = 0.262745 * 100, metric = 2.40% * 100;
 Minibatch[1001-1100]: loss = 0.254962 * 100, metric = 2.23% * 100;
 Minibatch[1101-1200]: loss = 0.245728 * 100, metric = 2.41% * 100;
 Minibatch[1201-1300]: loss = 0.250872 * 100, metric = 2.42% * 100;
 Minibatch[1301-1400]: loss = 0.257141 * 100, metric = 2.46% * 100;
 Minibatch[1401-1500]: loss = 0.245117 * 100, metric = 2.38% * 100;
 Minibatch[1501-1600]: loss = 0.248916 * 100, metric = 2.33% * 100;
 Minibatch[1601-1700]: loss = 0.251678 * 100, metric = 2.45% * 100;
 Minibatch[1701-1800]: loss = 0.251286 * 100, metric = 2.40% * 100;
 Minibatch[1801-1900]: loss = 0.240493 * 100, metric = 2.31% * 100;
 Minibatch[1901-2000]: loss = 0.244545 * 100, metric = 2.40% * 100;
Finished Epoch[148 of 200]: [Training] loss = 0.252349 * 2000, metric = 2.39% * 2000 690.852s (  2.9 samples/s);
Finished Evaluation [148]: Minibatch[1-2000]: metric = 10.67% * 2000;
 Minibatch[   1- 100]: loss = 0.251670 * 100, metric = 2.46% * 100;
 Minibatch[ 101- 200]: loss = 0.248855 * 100, metric = 2.38% * 100;
 Minibatch[ 201- 300]: loss = 0.245624 * 100, metric = 2.31% * 100;
 Minibatch[ 301- 400]: loss = 0.247826 * 100, metric = 2.40% * 100;
 Minibatch[ 401- 500]: loss = 0.255597 * 100, metric = 2.29% * 100;
 Minibatch[ 501- 600]: loss = 0.240025 * 100, metric = 2.20% * 100;
 Minibatch[ 601- 700]: loss = 0.238772 * 100, metric = 2.36% * 100;
 Minibatch[ 701- 800]: loss = 0.243904 * 100, metric = 2.29% * 100;
 Minibatch[ 801- 900]: loss = 0.246387 * 100, metric = 2.32% * 100;
 Minibatch[ 901-1000]: loss = 0.253624 * 100, metric = 2.35% * 100;
 Minibatch[1001-1100]: loss = 0.252292 * 100, metric = 2.35% * 100;
 Minibatch[1101-1200]: loss = 0.252037 * 100, metric = 2.48% * 100;
 Minibatch[1201-1300]: loss = 0.247212 * 100, metric = 2.42% * 100;
 Minibatch[1301-1400]: loss = 0.248675 * 100, metric = 2.45% * 100;
 Minibatch[1401-1500]: loss = 0.250401 * 100, metric = 2.40% * 100;
 Minibatch[1501-1600]: loss = 0.238249 * 100, metric = 2.14% * 100;
 Minibatch[1601-1700]: loss = 0.257244 * 100, metric = 2.38% * 100;
 Minibatch[1701-1800]: loss = 0.267856 * 100, metric = 2.56% * 100;
 Minibatch[1801-1900]: loss = 0.248717 * 100, metric = 2.29% * 100;
 Minibatch[1901-2000]: loss = 0.238630 * 100, metric = 2.11% * 100;
Finished Epoch[149 of 200]: [Training] loss = 0.248680 * 2000, metric = 2.35% * 2000 696.164s (  2.9 samples/s);
Finished Evaluation [149]: Minibatch[1-2000]: metric = 10.63% * 2000;
 Minibatch[   1- 100]: loss = 0.250545 * 100, metric = 2.33% * 100;
 Minibatch[ 101- 200]: loss = 0.240299 * 100, metric = 2.27% * 100;
 Minibatch[ 201- 300]: loss = 0.244878 * 100, metric = 2.25% * 100;
 Minibatch[ 301- 400]: loss = 0.237152 * 100, metric = 2.13% * 100;
 Minibatch[ 401- 500]: loss = 0.253818 * 100, metric = 2.31% * 100;
 Minibatch[ 501- 600]: loss = 0.246346 * 100, metric = 2.42% * 100;
 Minibatch[ 601- 700]: loss = 0.252282 * 100, metric = 2.49% * 100;
 Minibatch[ 701- 800]: loss = 0.254147 * 100, metric = 2.49% * 100;
 Minibatch[ 801- 900]: loss = 0.244286 * 100, metric = 2.27% * 100;
 Minibatch[ 901-1000]: loss = 0.240589 * 100, metric = 2.34% * 100;
 Minibatch[1001-1100]: loss = 0.245979 * 100, metric = 2.32% * 100;
 Minibatch[1101-1200]: loss = 0.249392 * 100, metric = 2.35% * 100;
 Minibatch[1201-1300]: loss = 0.246775 * 100, metric = 2.19% * 100;
 Minibatch[1301-1400]: loss = 0.252786 * 100, metric = 2.42% * 100;
 Minibatch[1401-1500]: loss = 0.251514 * 100, metric = 2.27% * 100;
 Minibatch[1501-1600]: loss = 0.247281 * 100, metric = 2.37% * 100;
 Minibatch[1601-1700]: loss = 0.254629 * 100, metric = 2.47% * 100;
 Minibatch[1701-1800]: loss = 0.249618 * 100, metric = 2.38% * 100;
 Minibatch[1801-1900]: loss = 0.247622 * 100, metric = 2.33% * 100;
 Minibatch[1901-2000]: loss = 0.247870 * 100, metric = 2.36% * 100;
Finished Epoch[150 of 200]: [Training] loss = 0.247890 * 2000, metric = 2.34% * 2000 696.108s (  2.9 samples/s);
Finished Evaluation [150]: Minibatch[1-2000]: metric = 10.56% * 2000;
 Minibatch[   1- 100]: loss = 0.243831 * 100, metric = 2.21% * 100;
 Minibatch[ 101- 200]: loss = 0.254996 * 100, metric = 2.44% * 100;
 Minibatch[ 201- 300]: loss = 0.244180 * 100, metric = 2.26% * 100;
 Minibatch[ 301- 400]: loss = 0.244417 * 100, metric = 2.38% * 100;
 Minibatch[ 401- 500]: loss = 0.240298 * 100, metric = 2.21% * 100;
 Minibatch[ 501- 600]: loss = 0.238883 * 100, metric = 2.11% * 100;
 Minibatch[ 601- 700]: loss = 0.236112 * 100, metric = 2.24% * 100;
 Minibatch[ 701- 800]: loss = 0.239338 * 100, metric = 2.21% * 100;
 Minibatch[ 801- 900]: loss = 0.230325 * 100, metric = 2.22% * 100;
 Minibatch[ 901-1000]: loss = 0.237366 * 100, metric = 2.32% * 100;
 Minibatch[1001-1100]: loss = 0.259004 * 100, metric = 2.54% * 100;
 Minibatch[1101-1200]: loss = 0.242331 * 100, metric = 2.26% * 100;
 Minibatch[1201-1300]: loss = 0.252281 * 100, metric = 2.44% * 100;
 Minibatch[1301-1400]: loss = 0.239706 * 100, metric = 2.20% * 100;
 Minibatch[1401-1500]: loss = 0.249126 * 100, metric = 2.35% * 100;
 Minibatch[1501-1600]: loss = 0.251037 * 100, metric = 2.33% * 100;
 Minibatch[1601-1700]: loss = 0.245940 * 100, metric = 2.38% * 100;
 Minibatch[1701-1800]: loss = 0.245791 * 100, metric = 2.36% * 100;
 Minibatch[1801-1900]: loss = 0.241718 * 100, metric = 2.32% * 100;
 Minibatch[1901-2000]: loss = 0.245116 * 100, metric = 2.40% * 100;
Finished Epoch[151 of 200]: [Training] loss = 0.244090 * 2000, metric = 2.31% * 2000 696.736s (  2.9 samples/s);
Finished Evaluation [151]: Minibatch[1-2000]: metric = 10.19% * 2000;
 Minibatch[   1- 100]: loss = 0.239812 * 100, metric = 2.33% * 100;
 Minibatch[ 101- 200]: loss = 0.246600 * 100, metric = 2.29% * 100;
 Minibatch[ 201- 300]: loss = 0.263188 * 100, metric = 2.59% * 100;
 Minibatch[ 301- 400]: loss = 0.248182 * 100, metric = 2.34% * 100;
 Minibatch[ 401- 500]: loss = 0.261578 * 100, metric = 2.53% * 100;
 Minibatch[ 501- 600]: loss = 0.244014 * 100, metric = 2.36% * 100;
 Minibatch[ 601- 700]: loss = 0.251196 * 100, metric = 2.44% * 100;
 Minibatch[ 701- 800]: loss = 0.250357 * 100, metric = 2.39% * 100;
 Minibatch[ 801- 900]: loss = 0.245894 * 100, metric = 2.27% * 100;
 Minibatch[ 901-1000]: loss = 0.253810 * 100, metric = 2.45% * 100;
 Minibatch[1001-1100]: loss = 0.242376 * 100, metric = 2.33% * 100;
 Minibatch[1101-1200]: loss = 0.248902 * 100, metric = 2.38% * 100;
 Minibatch[1201-1300]: loss = 0.234175 * 100, metric = 2.12% * 100;
 Minibatch[1301-1400]: loss = 0.239138 * 100, metric = 2.27% * 100;
 Minibatch[1401-1500]: loss = 0.247386 * 100, metric = 2.41% * 100;
 Minibatch[1501-1600]: loss = 0.243593 * 100, metric = 2.38% * 100;
 Minibatch[1601-1700]: loss = 0.242305 * 100, metric = 2.33% * 100;
 Minibatch[1701-1800]: loss = 0.253787 * 100, metric = 2.35% * 100;
 Minibatch[1801-1900]: loss = 0.254684 * 100, metric = 2.30% * 100;
 Minibatch[1901-2000]: loss = 0.247163 * 100, metric = 2.32% * 100;
Finished Epoch[152 of 200]: [Training] loss = 0.247907 * 2000, metric = 2.36% * 2000 693.568s (  2.9 samples/s);
Finished Evaluation [152]: Minibatch[1-2000]: metric = 10.04% * 2000;
 Minibatch[   1- 100]: loss = 0.243988 * 100, metric = 2.29% * 100;
 Minibatch[ 101- 200]: loss = 0.257433 * 100, metric = 2.63% * 100;
 Minibatch[ 201- 300]: loss = 0.246541 * 100, metric = 2.35% * 100;
 Minibatch[ 301- 400]: loss = 0.242822 * 100, metric = 2.39% * 100;
 Minibatch[ 401- 500]: loss = 0.266745 * 100, metric = 2.63% * 100;
 Minibatch[ 501- 600]: loss = 0.256100 * 100, metric = 2.47% * 100;
 Minibatch[ 601- 700]: loss = 0.243298 * 100, metric = 2.37% * 100;
 Minibatch[ 701- 800]: loss = 0.247887 * 100, metric = 2.23% * 100;
 Minibatch[ 801- 900]: loss = 0.249543 * 100, metric = 2.36% * 100;
 Minibatch[ 901-1000]: loss = 0.246855 * 100, metric = 2.18% * 100;
 Minibatch[1001-1100]: loss = 0.255528 * 100, metric = 2.54% * 100;
 Minibatch[1101-1200]: loss = 0.234818 * 100, metric = 2.35% * 100;
 Minibatch[1201-1300]: loss = 0.242718 * 100, metric = 2.39% * 100;
 Minibatch[1301-1400]: loss = 0.239458 * 100, metric = 2.17% * 100;
 Minibatch[1401-1500]: loss = 0.249119 * 100, metric = 2.41% * 100;
 Minibatch[1501-1600]: loss = 0.251618 * 100, metric = 2.39% * 100;
 Minibatch[1601-1700]: loss = 0.242991 * 100, metric = 2.32% * 100;
 Minibatch[1701-1800]: loss = 0.250301 * 100, metric = 2.35% * 100;
 Minibatch[1801-1900]: loss = 0.236058 * 100, metric = 2.31% * 100;
 Minibatch[1901-2000]: loss = 0.240937 * 100, metric = 2.29% * 100;
Finished Epoch[153 of 200]: [Training] loss = 0.247238 * 2000, metric = 2.37% * 2000 703.661s (  2.8 samples/s);
Finished Evaluation [153]: Minibatch[1-2000]: metric = 9.97% * 2000;
 Minibatch[   1- 100]: loss = 0.238582 * 100, metric = 2.19% * 100;
 Minibatch[ 101- 200]: loss = 0.239954 * 100, metric = 2.36% * 100;
 Minibatch[ 201- 300]: loss = 0.241595 * 100, metric = 2.18% * 100;
 Minibatch[ 301- 400]: loss = 0.245739 * 100, metric = 2.31% * 100;
 Minibatch[ 401- 500]: loss = 0.247165 * 100, metric = 2.33% * 100;
 Minibatch[ 501- 600]: loss = 0.245428 * 100, metric = 2.31% * 100;
 Minibatch[ 601- 700]: loss = 0.235145 * 100, metric = 2.19% * 100;
 Minibatch[ 701- 800]: loss = 0.245865 * 100, metric = 2.23% * 100;
 Minibatch[ 801- 900]: loss = 0.242471 * 100, metric = 2.37% * 100;
 Minibatch[ 901-1000]: loss = 0.245437 * 100, metric = 2.25% * 100;
 Minibatch[1001-1100]: loss = 0.238266 * 100, metric = 2.26% * 100;
 Minibatch[1101-1200]: loss = 0.257268 * 100, metric = 2.58% * 100;
 Minibatch[1201-1300]: loss = 0.239445 * 100, metric = 2.25% * 100;
 Minibatch[1301-1400]: loss = 0.241570 * 100, metric = 2.21% * 100;
 Minibatch[1401-1500]: loss = 0.247921 * 100, metric = 2.42% * 100;
 Minibatch[1501-1600]: loss = 0.257134 * 100, metric = 2.49% * 100;
 Minibatch[1601-1700]: loss = 0.257836 * 100, metric = 2.47% * 100;
 Minibatch[1701-1800]: loss = 0.245122 * 100, metric = 2.28% * 100;
 Minibatch[1801-1900]: loss = 0.236277 * 100, metric = 2.32% * 100;
 Minibatch[1901-2000]: loss = 0.251803 * 100, metric = 2.36% * 100;
Finished Epoch[154 of 200]: [Training] loss = 0.245001 * 2000, metric = 2.32% * 2000 703.957s (  2.8 samples/s);
Finished Evaluation [154]: Minibatch[1-2000]: metric = 11.74% * 2000;
 Minibatch[   1- 100]: loss = 0.255345 * 100, metric = 2.39% * 100;
 Minibatch[ 101- 200]: loss = 0.265955 * 100, metric = 2.61% * 100;
 Minibatch[ 201- 300]: loss = 0.259980 * 100, metric = 2.49% * 100;
 Minibatch[ 301- 400]: loss = 0.245395 * 100, metric = 2.38% * 100;
 Minibatch[ 401- 500]: loss = 0.245127 * 100, metric = 2.35% * 100;
 Minibatch[ 501- 600]: loss = 0.243985 * 100, metric = 2.35% * 100;
 Minibatch[ 601- 700]: loss = 0.250235 * 100, metric = 2.36% * 100;
 Minibatch[ 701- 800]: loss = 0.245345 * 100, metric = 2.39% * 100;
 Minibatch[ 801- 900]: loss = 0.254191 * 100, metric = 2.45% * 100;
 Minibatch[ 901-1000]: loss = 0.240205 * 100, metric = 2.26% * 100;
 Minibatch[1001-1100]: loss = 0.245975 * 100, metric = 2.31% * 100;
 Minibatch[1101-1200]: loss = 0.248897 * 100, metric = 2.22% * 100;
 Minibatch[1201-1300]: loss = 0.253026 * 100, metric = 2.45% * 100;
 Minibatch[1301-1400]: loss = 0.252169 * 100, metric = 2.43% * 100;
 Minibatch[1401-1500]: loss = 0.241926 * 100, metric = 2.34% * 100;
 Minibatch[1501-1600]: loss = 0.255305 * 100, metric = 2.31% * 100;
 Minibatch[1601-1700]: loss = 0.250789 * 100, metric = 2.31% * 100;
 Minibatch[1701-1800]: loss = 0.253418 * 100, metric = 2.37% * 100;
 Minibatch[1801-1900]: loss = 0.236898 * 100, metric = 2.25% * 100;
 Minibatch[1901-2000]: loss = 0.223545 * 100, metric = 2.14% * 100;
Finished Epoch[155 of 200]: [Training] loss = 0.248385 * 2000, metric = 2.36% * 2000 790.582s (  2.5 samples/s);
Finished Evaluation [155]: Minibatch[1-2000]: metric = 10.67% * 2000;
 Minibatch[   1- 100]: loss = 0.241234 * 100, metric = 2.32% * 100;
 Minibatch[ 101- 200]: loss = 0.236187 * 100, metric = 2.07% * 100;
 Minibatch[ 201- 300]: loss = 0.250136 * 100, metric = 2.40% * 100;
 Minibatch[ 301- 400]: loss = 0.238318 * 100, metric = 2.26% * 100;
 Minibatch[ 401- 500]: loss = 0.237463 * 100, metric = 2.26% * 100;
 Minibatch[ 501- 600]: loss = 0.244921 * 100, metric = 2.24% * 100;
 Minibatch[ 601- 700]: loss = 0.256645 * 100, metric = 2.51% * 100;
 Minibatch[ 701- 800]: loss = 0.249785 * 100, metric = 2.57% * 100;
 Minibatch[ 801- 900]: loss = 0.243447 * 100, metric = 2.41% * 100;
 Minibatch[ 901-1000]: loss = 0.237359 * 100, metric = 2.25% * 100;
 Minibatch[1001-1100]: loss = 0.233643 * 100, metric = 2.03% * 100;
 Minibatch[1101-1200]: loss = 0.247007 * 100, metric = 2.20% * 100;
 Minibatch[1201-1300]: loss = 0.244296 * 100, metric = 2.21% * 100;
 Minibatch[1301-1400]: loss = 0.235447 * 100, metric = 2.04% * 100;
 Minibatch[1401-1500]: loss = 0.242726 * 100, metric = 2.20% * 100;
 Minibatch[1501-1600]: loss = 0.237686 * 100, metric = 2.21% * 100;
 Minibatch[1601-1700]: loss = 0.241812 * 100, metric = 2.08% * 100;
 Minibatch[1701-1800]: loss = 0.242798 * 100, metric = 2.53% * 100;
 Minibatch[1801-1900]: loss = 0.245351 * 100, metric = 2.26% * 100;
 Minibatch[1901-2000]: loss = 0.246268 * 100, metric = 2.32% * 100;
Finished Epoch[156 of 200]: [Training] loss = 0.242626 * 2000, metric = 2.27% * 2000 826.528s (  2.4 samples/s);
Finished Evaluation [156]: Minibatch[1-2000]: metric = 10.10% * 2000;
 Minibatch[   1- 100]: loss = 0.252410 * 100, metric = 2.35% * 100;
 Minibatch[ 101- 200]: loss = 0.243088 * 100, metric = 2.34% * 100;
 Minibatch[ 201- 300]: loss = 0.250238 * 100, metric = 2.36% * 100;
 Minibatch[ 301- 400]: loss = 0.254502 * 100, metric = 2.60% * 100;
 Minibatch[ 401- 500]: loss = 0.240440 * 100, metric = 2.29% * 100;
 Minibatch[ 501- 600]: loss = 0.242397 * 100, metric = 2.08% * 100;
 Minibatch[ 601- 700]: loss = 0.246437 * 100, metric = 2.33% * 100;
 Minibatch[ 701- 800]: loss = 0.231972 * 100, metric = 2.12% * 100;
 Minibatch[ 801- 900]: loss = 0.236637 * 100, metric = 2.19% * 100;
 Minibatch[ 901-1000]: loss = 0.239364 * 100, metric = 2.25% * 100;
 Minibatch[1001-1100]: loss = 0.239244 * 100, metric = 2.28% * 100;
 Minibatch[1101-1200]: loss = 0.247012 * 100, metric = 2.24% * 100;
 Minibatch[1201-1300]: loss = 0.245505 * 100, metric = 2.33% * 100;
 Minibatch[1301-1400]: loss = 0.234739 * 100, metric = 2.11% * 100;
 Minibatch[1401-1500]: loss = 0.246935 * 100, metric = 2.36% * 100;
 Minibatch[1501-1600]: loss = 0.240452 * 100, metric = 2.16% * 100;
 Minibatch[1601-1700]: loss = 0.248945 * 100, metric = 2.34% * 100;
 Minibatch[1701-1800]: loss = 0.252641 * 100, metric = 2.47% * 100;
 Minibatch[1801-1900]: loss = 0.249490 * 100, metric = 2.34% * 100;
 Minibatch[1901-2000]: loss = 0.244969 * 100, metric = 2.32% * 100;
Finished Epoch[157 of 200]: [Training] loss = 0.244371 * 2000, metric = 2.29% * 2000 872.063s (  2.3 samples/s);
Finished Evaluation [157]: Minibatch[1-2000]: metric = 10.21% * 2000;
 Minibatch[   1- 100]: loss = 0.252307 * 100, metric = 2.46% * 100;
 Minibatch[ 101- 200]: loss = 0.246707 * 100, metric = 2.46% * 100;
 Minibatch[ 201- 300]: loss = 0.246040 * 100, metric = 2.37% * 100;
 Minibatch[ 301- 400]: loss = 0.255187 * 100, metric = 2.38% * 100;
 Minibatch[ 401- 500]: loss = 0.242552 * 100, metric = 2.27% * 100;
 Minibatch[ 501- 600]: loss = 0.252054 * 100, metric = 2.59% * 100;
 Minibatch[ 601- 700]: loss = 0.247082 * 100, metric = 2.19% * 100;
 Minibatch[ 701- 800]: loss = 0.252141 * 100, metric = 2.25% * 100;
 Minibatch[ 801- 900]: loss = 0.242396 * 100, metric = 2.28% * 100;
 Minibatch[ 901-1000]: loss = 0.236787 * 100, metric = 2.20% * 100;
 Minibatch[1001-1100]: loss = 0.240282 * 100, metric = 2.11% * 100;
 Minibatch[1101-1200]: loss = 0.255374 * 100, metric = 2.45% * 100;
 Minibatch[1201-1300]: loss = 0.242596 * 100, metric = 2.21% * 100;
 Minibatch[1301-1400]: loss = 0.248169 * 100, metric = 2.48% * 100;
 Minibatch[1401-1500]: loss = 0.238499 * 100, metric = 2.29% * 100;
 Minibatch[1501-1600]: loss = 0.252661 * 100, metric = 2.33% * 100;
 Minibatch[1601-1700]: loss = 0.242061 * 100, metric = 2.25% * 100;
 Minibatch[1701-1800]: loss = 0.239717 * 100, metric = 2.23% * 100;
 Minibatch[1801-1900]: loss = 0.246972 * 100, metric = 2.28% * 100;
 Minibatch[1901-2000]: loss = 0.241956 * 100, metric = 2.32% * 100;
Finished Epoch[158 of 200]: [Training] loss = 0.246077 * 2000, metric = 2.32% * 2000 784.152s (  2.6 samples/s);
Finished Evaluation [158]: Minibatch[1-2000]: metric = 10.70% * 2000;
 Minibatch[   1- 100]: loss = 0.244215 * 100, metric = 2.21% * 100;
 Minibatch[ 101- 200]: loss = 0.245335 * 100, metric = 2.19% * 100;
 Minibatch[ 201- 300]: loss = 0.235750 * 100, metric = 2.26% * 100;
 Minibatch[ 301- 400]: loss = 0.251432 * 100, metric = 2.28% * 100;
 Minibatch[ 401- 500]: loss = 0.242050 * 100, metric = 2.14% * 100;
 Minibatch[ 501- 600]: loss = 0.235304 * 100, metric = 2.24% * 100;
 Minibatch[ 601- 700]: loss = 0.243063 * 100, metric = 2.23% * 100;
 Minibatch[ 701- 800]: loss = 0.240889 * 100, metric = 2.26% * 100;
 Minibatch[ 801- 900]: loss = 0.231282 * 100, metric = 2.13% * 100;
 Minibatch[ 901-1000]: loss = 0.247819 * 100, metric = 2.29% * 100;
 Minibatch[1001-1100]: loss = 0.248712 * 100, metric = 2.29% * 100;
 Minibatch[1101-1200]: loss = 0.243579 * 100, metric = 2.37% * 100;
 Minibatch[1201-1300]: loss = 0.245211 * 100, metric = 2.22% * 100;
 Minibatch[1301-1400]: loss = 0.238243 * 100, metric = 2.06% * 100;
 Minibatch[1401-1500]: loss = 0.240966 * 100, metric = 2.19% * 100;
 Minibatch[1501-1600]: loss = 0.244280 * 100, metric = 2.28% * 100;
 Minibatch[1601-1700]: loss = 0.251841 * 100, metric = 2.26% * 100;
 Minibatch[1701-1800]: loss = 0.247149 * 100, metric = 2.32% * 100;
 Minibatch[1801-1900]: loss = 0.234128 * 100, metric = 2.18% * 100;
 Minibatch[1901-2000]: loss = 0.245485 * 100, metric = 2.29% * 100;
Finished Epoch[159 of 200]: [Training] loss = 0.242837 * 2000, metric = 2.24% * 2000 804.527s (  2.5 samples/s);
Finished Evaluation [159]: Minibatch[1-2000]: metric = 10.62% * 2000;
 Minibatch[   1- 100]: loss = 0.234534 * 100, metric = 2.18% * 100;
 Minibatch[ 101- 200]: loss = 0.246444 * 100, metric = 2.29% * 100;
 Minibatch[ 201- 300]: loss = 0.243835 * 100, metric = 2.23% * 100;
 Minibatch[ 301- 400]: loss = 0.244730 * 100, metric = 2.33% * 100;
 Minibatch[ 401- 500]: loss = 0.253554 * 100, metric = 2.32% * 100;
 Minibatch[ 501- 600]: loss = 0.250806 * 100, metric = 2.38% * 100;
 Minibatch[ 601- 700]: loss = 0.253349 * 100, metric = 2.36% * 100;
 Minibatch[ 701- 800]: loss = 0.237638 * 100, metric = 2.09% * 100;
 Minibatch[ 801- 900]: loss = 0.246535 * 100, metric = 2.32% * 100;
 Minibatch[ 901-1000]: loss = 0.253861 * 100, metric = 2.42% * 100;
 Minibatch[1001-1100]: loss = 0.250224 * 100, metric = 2.43% * 100;
 Minibatch[1101-1200]: loss = 0.245771 * 100, metric = 2.22% * 100;
 Minibatch[1201-1300]: loss = 0.245703 * 100, metric = 2.29% * 100;
 Minibatch[1301-1400]: loss = 0.236422 * 100, metric = 2.15% * 100;
 Minibatch[1401-1500]: loss = 0.244321 * 100, metric = 2.31% * 100;
 Minibatch[1501-1600]: loss = 0.234322 * 100, metric = 2.21% * 100;
 Minibatch[1601-1700]: loss = 0.228675 * 100, metric = 2.04% * 100;
 Minibatch[1701-1800]: loss = 0.232821 * 100, metric = 2.09% * 100;
 Minibatch[1801-1900]: loss = 0.248579 * 100, metric = 2.34% * 100;
 Minibatch[1901-2000]: loss = 0.238943 * 100, metric = 2.31% * 100;
Finished Epoch[160 of 200]: [Training] loss = 0.243553 * 2000, metric = 2.27% * 2000 851.031s (  2.4 samples/s);
Finished Evaluation [160]: Minibatch[1-2000]: metric = 10.66% * 2000;
 Minibatch[   1- 100]: loss = 0.239194 * 100, metric = 2.07% * 100;
 Minibatch[ 101- 200]: loss = 0.254857 * 100, metric = 2.39% * 100;
 Minibatch[ 201- 300]: loss = 0.248612 * 100, metric = 2.38% * 100;
 Minibatch[ 301- 400]: loss = 0.241852 * 100, metric = 2.21% * 100;
 Minibatch[ 401- 500]: loss = 0.235702 * 100, metric = 2.23% * 100;
 Minibatch[ 501- 600]: loss = 0.254943 * 100, metric = 2.47% * 100;
 Minibatch[ 601- 700]: loss = 0.242982 * 100, metric = 2.35% * 100;
 Minibatch[ 701- 800]: loss = 0.256131 * 100, metric = 2.53% * 100;
 Minibatch[ 801- 900]: loss = 0.243137 * 100, metric = 2.17% * 100;
 Minibatch[ 901-1000]: loss = 0.243330 * 100, metric = 2.19% * 100;
 Minibatch[1001-1100]: loss = 0.251686 * 100, metric = 2.42% * 100;
 Minibatch[1101-1200]: loss = 0.245412 * 100, metric = 2.23% * 100;
 Minibatch[1201-1300]: loss = 0.242387 * 100, metric = 2.26% * 100;
 Minibatch[1301-1400]: loss = 0.238343 * 100, metric = 2.08% * 100;
 Minibatch[1401-1500]: loss = 0.223971 * 100, metric = 1.94% * 100;
 Minibatch[1501-1600]: loss = 0.246939 * 100, metric = 2.43% * 100;
 Minibatch[1601-1700]: loss = 0.237146 * 100, metric = 2.17% * 100;
 Minibatch[1701-1800]: loss = 0.245157 * 100, metric = 2.28% * 100;
 Minibatch[1801-1900]: loss = 0.249919 * 100, metric = 2.29% * 100;
 Minibatch[1901-2000]: loss = 0.246988 * 100, metric = 2.30% * 100;
Finished Epoch[161 of 200]: [Training] loss = 0.244434 * 2000, metric = 2.27% * 2000 795.357s (  2.5 samples/s);
Finished Evaluation [161]: Minibatch[1-2000]: metric = 10.58% * 2000;
 Minibatch[   1- 100]: loss = 0.248188 * 100, metric = 2.39% * 100;
 Minibatch[ 101- 200]: loss = 0.239141 * 100, metric = 2.29% * 100;
 Minibatch[ 201- 300]: loss = 0.236673 * 100, metric = 2.24% * 100;
 Minibatch[ 301- 400]: loss = 0.241299 * 100, metric = 2.18% * 100;
 Minibatch[ 401- 500]: loss = 0.239862 * 100, metric = 2.23% * 100;
 Minibatch[ 501- 600]: loss = 0.247529 * 100, metric = 2.34% * 100;
 Minibatch[ 601- 700]: loss = 0.242795 * 100, metric = 2.14% * 100;
 Minibatch[ 701- 800]: loss = 0.243326 * 100, metric = 2.23% * 100;
 Minibatch[ 801- 900]: loss = 0.244720 * 100, metric = 2.30% * 100;
 Minibatch[ 901-1000]: loss = 0.254825 * 100, metric = 2.30% * 100;
 Minibatch[1001-1100]: loss = 0.238752 * 100, metric = 2.19% * 100;
 Minibatch[1101-1200]: loss = 0.243370 * 100, metric = 2.25% * 100;
 Minibatch[1201-1300]: loss = 0.229370 * 100, metric = 1.98% * 100;
 Minibatch[1301-1400]: loss = 0.245883 * 100, metric = 2.25% * 100;
 Minibatch[1401-1500]: loss = 0.248764 * 100, metric = 2.19% * 100;
 Minibatch[1501-1600]: loss = 0.239378 * 100, metric = 2.17% * 100;
 Minibatch[1601-1700]: loss = 0.248186 * 100, metric = 2.32% * 100;
 Minibatch[1701-1800]: loss = 0.242692 * 100, metric = 2.38% * 100;
 Minibatch[1801-1900]: loss = 0.248130 * 100, metric = 2.27% * 100;
 Minibatch[1901-2000]: loss = 0.249687 * 100, metric = 2.33% * 100;
Finished Epoch[162 of 200]: [Training] loss = 0.243628 * 2000, metric = 2.25% * 2000 814.069s (  2.5 samples/s);
Finished Evaluation [162]: Minibatch[1-2000]: metric = 10.30% * 2000;
 Minibatch[   1- 100]: loss = 0.252062 * 100, metric = 2.33% * 100;
 Minibatch[ 101- 200]: loss = 0.247128 * 100, metric = 2.24% * 100;
 Minibatch[ 201- 300]: loss = 0.243900 * 100, metric = 2.16% * 100;
 Minibatch[ 301- 400]: loss = 0.239055 * 100, metric = 2.25% * 100;
 Minibatch[ 401- 500]: loss = 0.239416 * 100, metric = 2.18% * 100;
 Minibatch[ 501- 600]: loss = 0.232299 * 100, metric = 2.26% * 100;
 Minibatch[ 601- 700]: loss = 0.243768 * 100, metric = 2.21% * 100;
 Minibatch[ 701- 800]: loss = 0.240545 * 100, metric = 2.19% * 100;
 Minibatch[ 801- 900]: loss = 0.239880 * 100, metric = 2.27% * 100;
 Minibatch[ 901-1000]: loss = 0.236251 * 100, metric = 2.05% * 100;
 Minibatch[1001-1100]: loss = 0.234121 * 100, metric = 2.17% * 100;
 Minibatch[1101-1200]: loss = 0.237552 * 100, metric = 2.28% * 100;
 Minibatch[1201-1300]: loss = 0.244149 * 100, metric = 2.32% * 100;
 Minibatch[1301-1400]: loss = 0.242758 * 100, metric = 2.35% * 100;
 Minibatch[1401-1500]: loss = 0.240862 * 100, metric = 2.22% * 100;
 Minibatch[1501-1600]: loss = 0.256327 * 100, metric = 2.53% * 100;
 Minibatch[1601-1700]: loss = 0.245077 * 100, metric = 2.36% * 100;
 Minibatch[1701-1800]: loss = 0.243069 * 100, metric = 2.08% * 100;
 Minibatch[1801-1900]: loss = 0.241514 * 100, metric = 2.14% * 100;
 Minibatch[1901-2000]: loss = 0.237882 * 100, metric = 2.18% * 100;
Finished Epoch[163 of 200]: [Training] loss = 0.241881 * 2000, metric = 2.24% * 2000 863.889s (  2.3 samples/s);
Finished Evaluation [163]: Minibatch[1-2000]: metric = 9.50% * 2000;
0.583970931109041
 Minibatch[   1- 100]: loss = 0.255422 * 100, metric = 2.40% * 100;
 Minibatch[ 101- 200]: loss = 0.252498 * 100, metric = 2.38% * 100;
 Minibatch[ 201- 300]: loss = 0.234142 * 100, metric = 2.14% * 100;
 Minibatch[ 301- 400]: loss = 0.236620 * 100, metric = 2.24% * 100;
 Minibatch[ 401- 500]: loss = 0.226850 * 100, metric = 2.03% * 100;
 Minibatch[ 501- 600]: loss = 0.234326 * 100, metric = 2.23% * 100;
 Minibatch[ 601- 700]: loss = 0.235104 * 100, metric = 2.13% * 100;
 Minibatch[ 701- 800]: loss = 0.236099 * 100, metric = 2.27% * 100;
 Minibatch[ 801- 900]: loss = 0.236656 * 100, metric = 2.35% * 100;
 Minibatch[ 901-1000]: loss = 0.244643 * 100, metric = 2.30% * 100;
 Minibatch[1001-1100]: loss = 0.242059 * 100, metric = 2.25% * 100;
 Minibatch[1101-1200]: loss = 0.234970 * 100, metric = 2.23% * 100;
 Minibatch[1201-1300]: loss = 0.243618 * 100, metric = 2.29% * 100;
 Minibatch[1301-1400]: loss = 0.245576 * 100, metric = 2.38% * 100;
 Minibatch[1401-1500]: loss = 0.234178 * 100, metric = 2.17% * 100;
 Minibatch[1501-1600]: loss = 0.250658 * 100, metric = 2.34% * 100;
 Minibatch[1601-1700]: loss = 0.238194 * 100, metric = 2.29% * 100;
 Minibatch[1701-1800]: loss = 0.236407 * 100, metric = 2.21% * 100;
 Minibatch[1801-1900]: loss = 0.240351 * 100, metric = 2.13% * 100;
 Minibatch[1901-2000]: loss = 0.245660 * 100, metric = 2.26% * 100;
Finished Epoch[164 of 200]: [Training] loss = 0.240202 * 2000, metric = 2.25% * 2000 837.568s (  2.4 samples/s);
Finished Evaluation [164]: Minibatch[1-2000]: metric = 10.15% * 2000;
 Minibatch[   1- 100]: loss = 0.229431 * 100, metric = 2.13% * 100;
 Minibatch[ 101- 200]: loss = 0.242799 * 100, metric = 2.28% * 100;
 Minibatch[ 201- 300]: loss = 0.238376 * 100, metric = 2.10% * 100;
 Minibatch[ 301- 400]: loss = 0.247503 * 100, metric = 2.42% * 100;
 Minibatch[ 401- 500]: loss = 0.231016 * 100, metric = 2.13% * 100;
 Minibatch[ 501- 600]: loss = 0.247764 * 100, metric = 2.36% * 100;
 Minibatch[ 601- 700]: loss = 0.244425 * 100, metric = 2.30% * 100;
 Minibatch[ 701- 800]: loss = 0.233654 * 100, metric = 1.97% * 100;
 Minibatch[ 801- 900]: loss = 0.236540 * 100, metric = 2.11% * 100;
 Minibatch[ 901-1000]: loss = 0.231524 * 100, metric = 2.14% * 100;
 Minibatch[1001-1100]: loss = 0.235848 * 100, metric = 2.03% * 100;
 Minibatch[1101-1200]: loss = 0.235876 * 100, metric = 2.12% * 100;
 Minibatch[1201-1300]: loss = 0.244578 * 100, metric = 2.29% * 100;
 Minibatch[1301-1400]: loss = 0.245967 * 100, metric = 2.32% * 100;
 Minibatch[1401-1500]: loss = 0.234301 * 100, metric = 2.19% * 100;
 Minibatch[1501-1600]: loss = 0.235771 * 100, metric = 2.22% * 100;
 Minibatch[1601-1700]: loss = 0.250139 * 100, metric = 2.35% * 100;
 Minibatch[1701-1800]: loss = 0.238354 * 100, metric = 2.12% * 100;
 Minibatch[1801-1900]: loss = 0.243053 * 100, metric = 2.20% * 100;
 Minibatch[1901-2000]: loss = 0.244406 * 100, metric = 2.36% * 100;
Finished Epoch[165 of 200]: [Training] loss = 0.239566 * 2000, metric = 2.21% * 2000 815.667s (  2.5 samples/s);
Finished Evaluation [165]: Minibatch[1-2000]: metric = 10.13% * 2000;
 Minibatch[   1- 100]: loss = 0.243300 * 100, metric = 2.24% * 100;
 Minibatch[ 101- 200]: loss = 0.233706 * 100, metric = 2.21% * 100;
 Minibatch[ 201- 300]: loss = 0.231201 * 100, metric = 2.07% * 100;
 Minibatch[ 301- 400]: loss = 0.240251 * 100, metric = 2.15% * 100;
 Minibatch[ 401- 500]: loss = 0.243145 * 100, metric = 2.32% * 100;
 Minibatch[ 501- 600]: loss = 0.236450 * 100, metric = 2.25% * 100;
 Minibatch[ 601- 700]: loss = 0.254020 * 100, metric = 2.43% * 100;
 Minibatch[ 701- 800]: loss = 0.239944 * 100, metric = 2.29% * 100;
 Minibatch[ 801- 900]: loss = 0.246218 * 100, metric = 2.26% * 100;
 Minibatch[ 901-1000]: loss = 0.258282 * 100, metric = 2.48% * 100;
 Minibatch[1001-1100]: loss = 0.249709 * 100, metric = 2.34% * 100;
 Minibatch[1101-1200]: loss = 0.245353 * 100, metric = 2.36% * 100;
 Minibatch[1201-1300]: loss = 0.241598 * 100, metric = 2.22% * 100;
 Minibatch[1301-1400]: loss = 0.235087 * 100, metric = 2.19% * 100;
 Minibatch[1401-1500]: loss = 0.243487 * 100, metric = 2.28% * 100;
 Minibatch[1501-1600]: loss = 0.235092 * 100, metric = 2.22% * 100;
 Minibatch[1601-1700]: loss = 0.244798 * 100, metric = 2.28% * 100;
 Minibatch[1701-1800]: loss = 0.246925 * 100, metric = 2.31% * 100;
 Minibatch[1801-1900]: loss = 0.243549 * 100, metric = 2.27% * 100;
 Minibatch[1901-2000]: loss = 0.235981 * 100, metric = 2.16% * 100;
Finished Epoch[166 of 200]: [Training] loss = 0.242405 * 2000, metric = 2.27% * 2000 811.041s (  2.5 samples/s);
Finished Evaluation [166]: Minibatch[1-2000]: metric = 10.98% * 2000;
 Minibatch[   1- 100]: loss = 0.234512 * 100, metric = 2.09% * 100;
 Minibatch[ 101- 200]: loss = 0.239322 * 100, metric = 2.30% * 100;
 Minibatch[ 201- 300]: loss = 0.222539 * 100, metric = 2.04% * 100;
 Minibatch[ 301- 400]: loss = 0.245315 * 100, metric = 2.26% * 100;
 Minibatch[ 401- 500]: loss = 0.240275 * 100, metric = 2.20% * 100;
 Minibatch[ 501- 600]: loss = 0.236231 * 100, metric = 2.15% * 100;
 Minibatch[ 601- 700]: loss = 0.232950 * 100, metric = 2.14% * 100;
 Minibatch[ 701- 800]: loss = 0.235091 * 100, metric = 2.02% * 100;
 Minibatch[ 801- 900]: loss = 0.247194 * 100, metric = 2.35% * 100;
 Minibatch[ 901-1000]: loss = 0.220709 * 100, metric = 1.98% * 100;
 Minibatch[1001-1100]: loss = 0.235031 * 100, metric = 2.18% * 100;
 Minibatch[1101-1200]: loss = 0.233535 * 100, metric = 2.18% * 100;
 Minibatch[1201-1300]: loss = 0.237289 * 100, metric = 2.25% * 100;
 Minibatch[1301-1400]: loss = 0.240556 * 100, metric = 2.11% * 100;
 Minibatch[1401-1500]: loss = 0.234240 * 100, metric = 2.15% * 100;
 Minibatch[1501-1600]: loss = 0.223677 * 100, metric = 2.01% * 100;
 Minibatch[1601-1700]: loss = 0.252234 * 100, metric = 2.32% * 100;
 Minibatch[1701-1800]: loss = 0.242802 * 100, metric = 2.13% * 100;
 Minibatch[1801-1900]: loss = 0.238485 * 100, metric = 2.29% * 100;
 Minibatch[1901-2000]: loss = 0.247285 * 100, metric = 2.44% * 100;
Finished Epoch[167 of 200]: [Training] loss = 0.236964 * 2000, metric = 2.18% * 2000 843.373s (  2.4 samples/s);
Finished Evaluation [167]: Minibatch[1-2000]: metric = 10.09% * 2000;
 Minibatch[   1- 100]: loss = 0.238807 * 100, metric = 2.22% * 100;
 Minibatch[ 101- 200]: loss = 0.237493 * 100, metric = 2.28% * 100;
 Minibatch[ 201- 300]: loss = 0.248846 * 100, metric = 2.36% * 100;
 Minibatch[ 301- 400]: loss = 0.239367 * 100, metric = 2.22% * 100;
 Minibatch[ 401- 500]: loss = 0.238125 * 100, metric = 2.13% * 100;
 Minibatch[ 501- 600]: loss = 0.234448 * 100, metric = 2.10% * 100;
 Minibatch[ 601- 700]: loss = 0.247501 * 100, metric = 2.29% * 100;
 Minibatch[ 701- 800]: loss = 0.244669 * 100, metric = 2.29% * 100;
 Minibatch[ 801- 900]: loss = 0.246240 * 100, metric = 2.31% * 100;
 Minibatch[ 901-1000]: loss = 0.243636 * 100, metric = 2.18% * 100;
 Minibatch[1001-1100]: loss = 0.238910 * 100, metric = 2.23% * 100;
 Minibatch[1101-1200]: loss = 0.231052 * 100, metric = 2.07% * 100;
 Minibatch[1201-1300]: loss = 0.240586 * 100, metric = 2.30% * 100;
 Minibatch[1301-1400]: loss = 0.237843 * 100, metric = 2.23% * 100;
 Minibatch[1401-1500]: loss = 0.242166 * 100, metric = 2.25% * 100;
 Minibatch[1501-1600]: loss = 0.231037 * 100, metric = 2.14% * 100;
 Minibatch[1601-1700]: loss = 0.240207 * 100, metric = 2.23% * 100;
 Minibatch[1701-1800]: loss = 0.244974 * 100, metric = 2.23% * 100;
 Minibatch[1801-1900]: loss = 0.237140 * 100, metric = 2.17% * 100;
 Minibatch[1901-2000]: loss = 0.232956 * 100, metric = 2.15% * 100;
Finished Epoch[168 of 200]: [Training] loss = 0.239800 * 2000, metric = 2.22% * 2000 815.547s (  2.5 samples/s);
Finished Evaluation [168]: Minibatch[1-2000]: metric = 10.44% * 2000;
 Minibatch[   1- 100]: loss = 0.248475 * 100, metric = 2.32% * 100;
 Minibatch[ 101- 200]: loss = 0.243379 * 100, metric = 2.12% * 100;
 Minibatch[ 201- 300]: loss = 0.238753 * 100, metric = 2.25% * 100;
 Minibatch[ 301- 400]: loss = 0.236631 * 100, metric = 2.12% * 100;
 Minibatch[ 401- 500]: loss = 0.233532 * 100, metric = 2.10% * 100;
 Minibatch[ 501- 600]: loss = 0.238525 * 100, metric = 2.25% * 100;
 Minibatch[ 601- 700]: loss = 0.231355 * 100, metric = 2.07% * 100;
 Minibatch[ 701- 800]: loss = 0.242787 * 100, metric = 2.37% * 100;
 Minibatch[ 801- 900]: loss = 0.241252 * 100, metric = 2.21% * 100;
 Minibatch[ 901-1000]: loss = 0.231990 * 100, metric = 2.07% * 100;
 Minibatch[1001-1100]: loss = 0.237369 * 100, metric = 2.25% * 100;
 Minibatch[1101-1200]: loss = 0.249593 * 100, metric = 2.34% * 100;
 Minibatch[1201-1300]: loss = 0.252735 * 100, metric = 2.29% * 100;
 Minibatch[1301-1400]: loss = 0.227111 * 100, metric = 2.06% * 100;
 Minibatch[1401-1500]: loss = 0.245229 * 100, metric = 2.27% * 100;
 Minibatch[1501-1600]: loss = 0.242671 * 100, metric = 2.12% * 100;
 Minibatch[1601-1700]: loss = 0.239323 * 100, metric = 2.08% * 100;
 Minibatch[1701-1800]: loss = 0.229067 * 100, metric = 2.05% * 100;
 Minibatch[1801-1900]: loss = 0.230909 * 100, metric = 2.08% * 100;
 Minibatch[1901-2000]: loss = 0.240012 * 100, metric = 2.07% * 100;
Finished Epoch[169 of 200]: [Training] loss = 0.239035 * 2000, metric = 2.17% * 2000 811.524s (  2.5 samples/s);
Finished Evaluation [169]: Minibatch[1-2000]: metric = 11.05% * 2000;
 Minibatch[   1- 100]: loss = 0.241402 * 100, metric = 2.22% * 100;
 Minibatch[ 101- 200]: loss = 0.236955 * 100, metric = 2.21% * 100;
 Minibatch[ 201- 300]: loss = 0.232303 * 100, metric = 2.12% * 100;
 Minibatch[ 301- 400]: loss = 0.236878 * 100, metric = 2.23% * 100;
 Minibatch[ 401- 500]: loss = 0.237532 * 100, metric = 2.20% * 100;
 Minibatch[ 501- 600]: loss = 0.246255 * 100, metric = 2.30% * 100;
 Minibatch[ 601- 700]: loss = 0.232275 * 100, metric = 2.14% * 100;
 Minibatch[ 701- 800]: loss = 0.248024 * 100, metric = 2.30% * 100;
 Minibatch[ 801- 900]: loss = 0.238597 * 100, metric = 2.18% * 100;
 Minibatch[ 901-1000]: loss = 0.236003 * 100, metric = 2.21% * 100;
 Minibatch[1001-1100]: loss = 0.242728 * 100, metric = 2.18% * 100;
 Minibatch[1101-1200]: loss = 0.235934 * 100, metric = 2.12% * 100;
 Minibatch[1201-1300]: loss = 0.235680 * 100, metric = 2.13% * 100;
 Minibatch[1301-1400]: loss = 0.241559 * 100, metric = 2.17% * 100;
 Minibatch[1401-1500]: loss = 0.229869 * 100, metric = 2.21% * 100;
 Minibatch[1501-1600]: loss = 0.238673 * 100, metric = 2.21% * 100;
 Minibatch[1601-1700]: loss = 0.238792 * 100, metric = 2.14% * 100;
 Minibatch[1701-1800]: loss = 0.234356 * 100, metric = 2.19% * 100;
 Minibatch[1801-1900]: loss = 0.240227 * 100, metric = 2.17% * 100;
 Minibatch[1901-2000]: loss = 0.231628 * 100, metric = 2.08% * 100;
Finished Epoch[170 of 200]: [Training] loss = 0.237784 * 2000, metric = 2.19% * 2000 855.464s (  2.3 samples/s);
Finished Evaluation [170]: Minibatch[1-2000]: metric = 9.79% * 2000;
 Minibatch[   1- 100]: loss = 0.235287 * 100, metric = 2.01% * 100;
 Minibatch[ 101- 200]: loss = 0.241042 * 100, metric = 2.27% * 100;
 Minibatch[ 201- 300]: loss = 0.243812 * 100, metric = 2.37% * 100;
 Minibatch[ 301- 400]: loss = 0.235231 * 100, metric = 2.12% * 100;
 Minibatch[ 401- 500]: loss = 0.239269 * 100, metric = 2.17% * 100;
 Minibatch[ 501- 600]: loss = 0.235369 * 100, metric = 2.17% * 100;
 Minibatch[ 601- 700]: loss = 0.230335 * 100, metric = 2.19% * 100;
 Minibatch[ 701- 800]: loss = 0.234937 * 100, metric = 2.21% * 100;
 Minibatch[ 801- 900]: loss = 0.240528 * 100, metric = 2.27% * 100;
 Minibatch[ 901-1000]: loss = 0.237758 * 100, metric = 2.26% * 100;
 Minibatch[1001-1100]: loss = 0.244991 * 100, metric = 2.31% * 100;
 Minibatch[1101-1200]: loss = 0.235604 * 100, metric = 2.09% * 100;
 Minibatch[1201-1300]: loss = 0.225915 * 100, metric = 2.03% * 100;
 Minibatch[1301-1400]: loss = 0.240405 * 100, metric = 2.29% * 100;
 Minibatch[1401-1500]: loss = 0.232014 * 100, metric = 2.21% * 100;
 Minibatch[1501-1600]: loss = 0.226176 * 100, metric = 2.03% * 100;
 Minibatch[1601-1700]: loss = 0.234787 * 100, metric = 2.11% * 100;
 Minibatch[1701-1800]: loss = 0.243698 * 100, metric = 2.19% * 100;
 Minibatch[1801-1900]: loss = 0.231110 * 100, metric = 2.24% * 100;
 Minibatch[1901-2000]: loss = 0.235785 * 100, metric = 2.22% * 100;
Finished Epoch[171 of 200]: [Training] loss = 0.236203 * 2000, metric = 2.19% * 2000 822.696s (  2.4 samples/s);
Finished Evaluation [171]: Minibatch[1-2000]: metric = 10.16% * 2000;
 Minibatch[   1- 100]: loss = 0.243288 * 100, metric = 2.18% * 100;
 Minibatch[ 101- 200]: loss = 0.233989 * 100, metric = 2.12% * 100;
 Minibatch[ 201- 300]: loss = 0.242007 * 100, metric = 2.34% * 100;
 Minibatch[ 301- 400]: loss = 0.236272 * 100, metric = 2.12% * 100;
 Minibatch[ 401- 500]: loss = 0.233926 * 100, metric = 2.02% * 100;
 Minibatch[ 501- 600]: loss = 0.239198 * 100, metric = 2.21% * 100;
 Minibatch[ 601- 700]: loss = 0.231536 * 100, metric = 2.25% * 100;
 Minibatch[ 701- 800]: loss = 0.241699 * 100, metric = 2.13% * 100;
 Minibatch[ 801- 900]: loss = 0.228997 * 100, metric = 2.14% * 100;
 Minibatch[ 901-1000]: loss = 0.238990 * 100, metric = 2.32% * 100;
 Minibatch[1001-1100]: loss = 0.245234 * 100, metric = 2.21% * 100;
 Minibatch[1101-1200]: loss = 0.242528 * 100, metric = 2.27% * 100;
 Minibatch[1201-1300]: loss = 0.243204 * 100, metric = 2.29% * 100;
 Minibatch[1301-1400]: loss = 0.230252 * 100, metric = 2.02% * 100;
 Minibatch[1401-1500]: loss = 0.237316 * 100, metric = 2.10% * 100;
 Minibatch[1501-1600]: loss = 0.243415 * 100, metric = 2.30% * 100;
 Minibatch[1601-1700]: loss = 0.235670 * 100, metric = 2.13% * 100;
 Minibatch[1701-1800]: loss = 0.245312 * 100, metric = 2.25% * 100;
 Minibatch[1801-1900]: loss = 0.241303 * 100, metric = 2.27% * 100;
 Minibatch[1901-2000]: loss = 0.239239 * 100, metric = 2.20% * 100;
Finished Epoch[172 of 200]: [Training] loss = 0.238669 * 2000, metric = 2.19% * 2000 830.096s (  2.4 samples/s);
Finished Evaluation [172]: Minibatch[1-2000]: metric = 11.22% * 2000;
 Minibatch[   1- 100]: loss = 0.242766 * 100, metric = 2.10% * 100;
 Minibatch[ 101- 200]: loss = 0.231589 * 100, metric = 2.11% * 100;
 Minibatch[ 201- 300]: loss = 0.238597 * 100, metric = 2.27% * 100;
 Minibatch[ 301- 400]: loss = 0.239486 * 100, metric = 2.21% * 100;
 Minibatch[ 401- 500]: loss = 0.226434 * 100, metric = 2.04% * 100;
 Minibatch[ 501- 600]: loss = 0.231592 * 100, metric = 2.05% * 100;
 Minibatch[ 601- 700]: loss = 0.239896 * 100, metric = 2.14% * 100;
 Minibatch[ 701- 800]: loss = 0.235500 * 100, metric = 2.19% * 100;
 Minibatch[ 801- 900]: loss = 0.248746 * 100, metric = 2.37% * 100;
 Minibatch[ 901-1000]: loss = 0.225613 * 100, metric = 1.98% * 100;
 Minibatch[1001-1100]: loss = 0.235871 * 100, metric = 2.13% * 100;
 Minibatch[1101-1200]: loss = 0.241597 * 100, metric = 2.30% * 100;
 Minibatch[1201-1300]: loss = 0.232781 * 100, metric = 2.22% * 100;
 Minibatch[1301-1400]: loss = 0.234910 * 100, metric = 2.17% * 100;
 Minibatch[1401-1500]: loss = 0.222650 * 100, metric = 2.04% * 100;
 Minibatch[1501-1600]: loss = 0.230147 * 100, metric = 2.02% * 100;
 Minibatch[1601-1700]: loss = 0.237046 * 100, metric = 2.21% * 100;
 Minibatch[1701-1800]: loss = 0.231715 * 100, metric = 2.13% * 100;
 Minibatch[1801-1900]: loss = 0.244364 * 100, metric = 2.31% * 100;
 Minibatch[1901-2000]: loss = 0.244024 * 100, metric = 2.21% * 100;
Finished Epoch[173 of 200]: [Training] loss = 0.235766 * 2000, metric = 2.16% * 2000 844.052s (  2.4 samples/s);
Finished Evaluation [173]: Minibatch[1-2000]: metric = 9.80% * 2000;
 Minibatch[   1- 100]: loss = 0.231411 * 100, metric = 2.21% * 100;
 Minibatch[ 101- 200]: loss = 0.229536 * 100, metric = 2.00% * 100;
 Minibatch[ 201- 300]: loss = 0.243931 * 100, metric = 2.31% * 100;
 Minibatch[ 301- 400]: loss = 0.236237 * 100, metric = 2.17% * 100;
 Minibatch[ 401- 500]: loss = 0.229676 * 100, metric = 2.03% * 100;
 Minibatch[ 501- 600]: loss = 0.237553 * 100, metric = 2.18% * 100;
 Minibatch[ 601- 700]: loss = 0.235144 * 100, metric = 2.09% * 100;
 Minibatch[ 701- 800]: loss = 0.231691 * 100, metric = 2.12% * 100;
 Minibatch[ 801- 900]: loss = 0.245272 * 100, metric = 2.17% * 100;
 Minibatch[ 901-1000]: loss = 0.235128 * 100, metric = 2.16% * 100;
 Minibatch[1001-1100]: loss = 0.231440 * 100, metric = 2.13% * 100;
 Minibatch[1101-1200]: loss = 0.236623 * 100, metric = 2.05% * 100;
 Minibatch[1201-1300]: loss = 0.235906 * 100, metric = 2.16% * 100;
 Minibatch[1301-1400]: loss = 0.231077 * 100, metric = 2.07% * 100;
 Minibatch[1401-1500]: loss = 0.503989 * 100, metric = 7.27% * 100;
 Minibatch[1501-1600]: loss = 0.475818 * 100, metric = 7.13% * 100;
 Minibatch[1601-1700]: loss = 0.468676 * 100, metric = 7.04% * 100;
 Minibatch[1701-1800]: loss = 0.396488 * 100, metric = 5.79% * 100;
 Minibatch[1801-1900]: loss = 0.411754 * 100, metric = 5.80% * 100;
 Minibatch[1901-2000]: loss = 0.387690 * 100, metric = 5.43% * 100;
Finished Epoch[174 of 200]: [Training] loss = 0.296752 * 2000, metric = 3.42% * 2000 901.854s (  2.2 samples/s);
Finished Evaluation [174]: Minibatch[1-2000]: metric = 11.19% * 2000;
0.5005871837548912
 Minibatch[   1- 100]: loss = 0.355946 * 100, metric = 4.72% * 100;
 Minibatch[ 101- 200]: loss = 0.331948 * 100, metric = 4.28% * 100;
 Minibatch[ 201- 300]: loss = 0.328258 * 100, metric = 4.13% * 100;
 Minibatch[ 301- 400]: loss = 0.344832 * 100, metric = 4.45% * 100;
 Minibatch[ 401- 500]: loss = 0.310728 * 100, metric = 3.85% * 100;
 Minibatch[ 501- 600]: loss = 0.315354 * 100, metric = 4.02% * 100;
 Minibatch[ 601- 700]: loss = 0.308895 * 100, metric = 3.72% * 100;
 Minibatch[ 701- 800]: loss = 0.315182 * 100, metric = 3.87% * 100;
 Minibatch[ 801- 900]: loss = 0.324498 * 100, metric = 4.01% * 100;
 Minibatch[ 901-1000]: loss = 0.309597 * 100, metric = 3.74% * 100;
 Minibatch[1001-1100]: loss = 0.311796 * 100, metric = 3.81% * 100;
 Minibatch[1101-1200]: loss = 0.320301 * 100, metric = 3.93% * 100;
 Minibatch[1201-1300]: loss = 0.312387 * 100, metric = 3.87% * 100;
 Minibatch[1301-1400]: loss = 0.327767 * 100, metric = 3.98% * 100;
 Minibatch[1401-1500]: loss = 0.304807 * 100, metric = 3.65% * 100;
 Minibatch[1501-1600]: loss = 0.328690 * 100, metric = 4.07% * 100;
 Minibatch[1601-1700]: loss = 0.304830 * 100, metric = 3.88% * 100;
 Minibatch[1701-1800]: loss = 0.306843 * 100, metric = 3.66% * 100;
 Minibatch[1801-1900]: loss = 0.294485 * 100, metric = 3.44% * 100;
 Minibatch[1901-2000]: loss = 0.305601 * 100, metric = 3.73% * 100;
Finished Epoch[175 of 200]: [Training] loss = 0.318137 * 2000, metric = 3.94% * 2000 841.479s (  2.4 samples/s);
Finished Evaluation [175]: Minibatch[1-2000]: metric = 11.49% * 2000;
 Minibatch[   1- 100]: loss = 0.307607 * 100, metric = 3.72% * 100;
 Minibatch[ 101- 200]: loss = 0.321679 * 100, metric = 3.88% * 100;
 Minibatch[ 201- 300]: loss = 0.310338 * 100, metric = 3.76% * 100;
 Minibatch[ 301- 400]: loss = 0.320587 * 100, metric = 3.72% * 100;
 Minibatch[ 401- 500]: loss = 0.318271 * 100, metric = 3.86% * 100;
 Minibatch[ 501- 600]: loss = 0.321877 * 100, metric = 3.90% * 100;
 Minibatch[ 601- 700]: loss = 0.327792 * 100, metric = 4.02% * 100;
 Minibatch[ 701- 800]: loss = 0.310099 * 100, metric = 3.72% * 100;
 Minibatch[ 801- 900]: loss = 0.315671 * 100, metric = 3.63% * 100;
 Minibatch[ 901-1000]: loss = 0.315182 * 100, metric = 3.87% * 100;
 Minibatch[1001-1100]: loss = 0.323574 * 100, metric = 3.95% * 100;
 Minibatch[1101-1200]: loss = 0.323306 * 100, metric = 3.93% * 100;
 Minibatch[1201-1300]: loss = 0.309469 * 100, metric = 3.65% * 100;
 Minibatch[1301-1400]: loss = 0.327402 * 100, metric = 3.91% * 100;
 Minibatch[1401-1500]: loss = 0.311183 * 100, metric = 3.80% * 100;
 Minibatch[1501-1600]: loss = 0.314371 * 100, metric = 3.94% * 100;
 Minibatch[1601-1700]: loss = 0.322416 * 100, metric = 4.04% * 100;
 Minibatch[1701-1800]: loss = 0.291482 * 100, metric = 3.24% * 100;
 Minibatch[1801-1900]: loss = 0.312961 * 100, metric = 3.57% * 100;
 Minibatch[1901-2000]: loss = 0.306528 * 100, metric = 3.65% * 100;
Finished Epoch[176 of 200]: [Training] loss = 0.315590 * 2000, metric = 3.79% * 2000 895.571s (  2.2 samples/s);
Finished Evaluation [176]: Minibatch[1-2000]: metric = 11.22% * 2000;
 Minibatch[   1- 100]: loss = 0.308070 * 100, metric = 3.72% * 100;
 Minibatch[ 101- 200]: loss = 0.312742 * 100, metric = 3.93% * 100;
 Minibatch[ 201- 300]: loss = 0.314571 * 100, metric = 3.71% * 100;
 Minibatch[ 301- 400]: loss = 0.315402 * 100, metric = 3.63% * 100;
 Minibatch[ 401- 500]: loss = 0.321802 * 100, metric = 3.82% * 100;
 Minibatch[ 501- 600]: loss = 0.314245 * 100, metric = 3.71% * 100;
 Minibatch[ 601- 700]: loss = 0.312514 * 100, metric = 3.62% * 100;
 Minibatch[ 701- 800]: loss = 0.309541 * 100, metric = 3.63% * 100;
 Minibatch[ 801- 900]: loss = 0.299496 * 100, metric = 3.65% * 100;
 Minibatch[ 901-1000]: loss = 0.309674 * 100, metric = 3.87% * 100;
 Minibatch[1001-1100]: loss = 0.300667 * 100, metric = 3.53% * 100;
 Minibatch[1101-1200]: loss = 0.325586 * 100, metric = 3.77% * 100;
 Minibatch[1201-1300]: loss = 0.307893 * 100, metric = 3.71% * 100;
 Minibatch[1301-1400]: loss = 0.323969 * 100, metric = 3.91% * 100;
 Minibatch[1401-1500]: loss = 0.316906 * 100, metric = 3.79% * 100;
 Minibatch[1501-1600]: loss = 0.301070 * 100, metric = 3.60% * 100;
 Minibatch[1601-1700]: loss = 0.314261 * 100, metric = 3.80% * 100;
 Minibatch[1701-1800]: loss = 0.304725 * 100, metric = 3.58% * 100;
 Minibatch[1801-1900]: loss = 0.308474 * 100, metric = 3.48% * 100;
 Minibatch[1901-2000]: loss = 0.309240 * 100, metric = 3.69% * 100;
Finished Epoch[177 of 200]: [Training] loss = 0.311542 * 2000, metric = 3.71% * 2000 943.076s (  2.1 samples/s);
Finished Evaluation [177]: Minibatch[1-2000]: metric = 9.78% * 2000;
0.48093692312017083
 Minibatch[   1- 100]: loss = 0.299567 * 100, metric = 3.44% * 100;
 Minibatch[ 101- 200]: loss = 0.299345 * 100, metric = 3.37% * 100;
 Minibatch[ 201- 300]: loss = 0.313861 * 100, metric = 3.71% * 100;
 Minibatch[ 301- 400]: loss = 0.307915 * 100, metric = 3.54% * 100;
 Minibatch[ 401- 500]: loss = 0.316968 * 100, metric = 3.73% * 100;
 Minibatch[ 501- 600]: loss = 0.309643 * 100, metric = 3.52% * 100;
 Minibatch[ 601- 700]: loss = 0.289965 * 100, metric = 3.25% * 100;
 Minibatch[ 701- 800]: loss = 0.299937 * 100, metric = 3.38% * 100;
 Minibatch[ 801- 900]: loss = 0.302344 * 100, metric = 3.54% * 100;
 Minibatch[ 901-1000]: loss = 0.300366 * 100, metric = 3.43% * 100;
 Minibatch[1001-1100]: loss = 0.306408 * 100, metric = 3.50% * 100;
 Minibatch[1101-1200]: loss = 0.294370 * 100, metric = 3.31% * 100;
 Minibatch[1201-1300]: loss = 0.301027 * 100, metric = 3.42% * 100;
 Minibatch[1301-1400]: loss = 0.309244 * 100, metric = 3.50% * 100;
 Minibatch[1401-1500]: loss = 0.326914 * 100, metric = 3.86% * 100;
 Minibatch[1501-1600]: loss = 0.312431 * 100, metric = 3.63% * 100;
 Minibatch[1601-1700]: loss = 0.301781 * 100, metric = 3.47% * 100;
 Minibatch[1701-1800]: loss = 0.296477 * 100, metric = 3.54% * 100;
 Minibatch[1801-1900]: loss = 0.293527 * 100, metric = 3.41% * 100;
 Minibatch[1901-2000]: loss = 0.316307 * 100, metric = 3.54% * 100;
Finished Epoch[178 of 200]: [Training] loss = 0.304920 * 2000, metric = 3.50% * 2000 839.228s (  2.4 samples/s);
Finished Evaluation [178]: Minibatch[1-2000]: metric = 11.75% * 2000;
 Minibatch[   1- 100]: loss = 0.306239 * 100, metric = 3.57% * 100;
 Minibatch[ 101- 200]: loss = 0.293014 * 100, metric = 3.29% * 100;
 Minibatch[ 201- 300]: loss = 0.303372 * 100, metric = 3.34% * 100;
 Minibatch[ 301- 400]: loss = 0.304950 * 100, metric = 3.42% * 100;
 Minibatch[ 401- 500]: loss = 0.301108 * 100, metric = 3.50% * 100;
 Minibatch[ 501- 600]: loss = 0.296214 * 100, metric = 3.44% * 100;
 Minibatch[ 601- 700]: loss = 0.301343 * 100, metric = 3.48% * 100;
 Minibatch[ 701- 800]: loss = 0.289548 * 100, metric = 3.12% * 100;
 Minibatch[ 801- 900]: loss = 0.300736 * 100, metric = 3.40% * 100;
 Minibatch[ 901-1000]: loss = 0.290942 * 100, metric = 3.28% * 100;
 Minibatch[1001-1100]: loss = 0.293818 * 100, metric = 3.37% * 100;
 Minibatch[1101-1200]: loss = 0.292955 * 100, metric = 3.21% * 100;
 Minibatch[1201-1300]: loss = 0.291998 * 100, metric = 3.39% * 100;
 Minibatch[1301-1400]: loss = 0.282942 * 100, metric = 3.03% * 100;
 Minibatch[1401-1500]: loss = 0.288174 * 100, metric = 3.09% * 100;
 Minibatch[1501-1600]: loss = 0.288430 * 100, metric = 3.20% * 100;
 Minibatch[1601-1700]: loss = 0.296911 * 100, metric = 3.21% * 100;
 Minibatch[1701-1800]: loss = 0.276488 * 100, metric = 2.94% * 100;
 Minibatch[1801-1900]: loss = 0.301760 * 100, metric = 3.50% * 100;
 Minibatch[1901-2000]: loss = 0.298136 * 100, metric = 3.41% * 100;
Finished Epoch[179 of 200]: [Training] loss = 0.294954 * 2000, metric = 3.31% * 2000 862.415s (  2.3 samples/s);
Finished Evaluation [179]: Minibatch[1-2000]: metric = 9.99% * 2000;
 Minibatch[   1- 100]: loss = 0.295980 * 100, metric = 3.41% * 100;
 Minibatch[ 101- 200]: loss = 0.295386 * 100, metric = 3.48% * 100;
 Minibatch[ 201- 300]: loss = 0.291546 * 100, metric = 3.08% * 100;
 Minibatch[ 301- 400]: loss = 0.289237 * 100, metric = 3.24% * 100;
 Minibatch[ 401- 500]: loss = 0.297577 * 100, metric = 3.14% * 100;
 Minibatch[ 501- 600]: loss = 0.294004 * 100, metric = 3.21% * 100;
 Minibatch[ 601- 700]: loss = 0.291109 * 100, metric = 3.25% * 100;
 Minibatch[ 701- 800]: loss = 0.284630 * 100, metric = 3.17% * 100;
 Minibatch[ 801- 900]: loss = 0.279241 * 100, metric = 3.04% * 100;
 Minibatch[ 901-1000]: loss = 0.274564 * 100, metric = 2.97% * 100;
 Minibatch[1001-1100]: loss = 0.281978 * 100, metric = 3.15% * 100;
 Minibatch[1101-1200]: loss = 0.290713 * 100, metric = 3.29% * 100;
 Minibatch[1201-1300]: loss = 0.303862 * 100, metric = 3.63% * 100;
 Minibatch[1301-1400]: loss = 0.284025 * 100, metric = 3.07% * 100;
 Minibatch[1401-1500]: loss = 0.302232 * 100, metric = 3.36% * 100;
 Minibatch[1501-1600]: loss = 0.293082 * 100, metric = 3.31% * 100;
 Minibatch[1601-1700]: loss = 0.289712 * 100, metric = 3.22% * 100;
 Minibatch[1701-1800]: loss = 0.284985 * 100, metric = 3.20% * 100;
 Minibatch[1801-1900]: loss = 0.295251 * 100, metric = 3.26% * 100;
 Minibatch[1901-2000]: loss = 0.284873 * 100, metric = 3.13% * 100;
Finished Epoch[180 of 200]: [Training] loss = 0.290199 * 2000, metric = 3.23% * 2000 877.200s (  2.3 samples/s);
Finished Evaluation [180]: Minibatch[1-2000]: metric = 10.48% * 2000;
 Minibatch[   1- 100]: loss = 0.294822 * 100, metric = 3.13% * 100;
 Minibatch[ 101- 200]: loss = 0.291199 * 100, metric = 3.18% * 100;
 Minibatch[ 201- 300]: loss = 0.288549 * 100, metric = 3.17% * 100;
 Minibatch[ 301- 400]: loss = 0.283356 * 100, metric = 3.05% * 100;
 Minibatch[ 401- 500]: loss = 0.294985 * 100, metric = 3.28% * 100;
 Minibatch[ 501- 600]: loss = 0.284740 * 100, metric = 3.13% * 100;
 Minibatch[ 601- 700]: loss = 0.276107 * 100, metric = 2.95% * 100;
 Minibatch[ 701- 800]: loss = 0.299463 * 100, metric = 3.37% * 100;
 Minibatch[ 801- 900]: loss = 0.279635 * 100, metric = 2.94% * 100;
 Minibatch[ 901-1000]: loss = 0.285280 * 100, metric = 3.15% * 100;
 Minibatch[1001-1100]: loss = 0.295365 * 100, metric = 3.28% * 100;
 Minibatch[1101-1200]: loss = 0.286939 * 100, metric = 3.13% * 100;
 Minibatch[1201-1300]: loss = 0.298798 * 100, metric = 3.36% * 100;
 Minibatch[1301-1400]: loss = 0.276618 * 100, metric = 3.04% * 100;
 Minibatch[1401-1500]: loss = 0.278896 * 100, metric = 3.01% * 100;
 Minibatch[1501-1600]: loss = 0.268315 * 100, metric = 2.93% * 100;
 Minibatch[1601-1700]: loss = 0.280604 * 100, metric = 2.94% * 100;
 Minibatch[1701-1800]: loss = 0.292460 * 100, metric = 3.26% * 100;
 Minibatch[1801-1900]: loss = 0.273690 * 100, metric = 2.95% * 100;
 Minibatch[1901-2000]: loss = 0.280685 * 100, metric = 2.89% * 100;
Finished Epoch[181 of 200]: [Training] loss = 0.285525 * 2000, metric = 3.11% * 2000 830.103s (  2.4 samples/s);
Finished Evaluation [181]: Minibatch[1-2000]: metric = 11.28% * 2000;
 Minibatch[   1- 100]: loss = 0.290835 * 100, metric = 3.34% * 100;
 Minibatch[ 101- 200]: loss = 0.295565 * 100, metric = 3.16% * 100;
 Minibatch[ 201- 300]: loss = 0.288972 * 100, metric = 3.20% * 100;
 Minibatch[ 301- 400]: loss = 0.285286 * 100, metric = 3.07% * 100;
 Minibatch[ 401- 500]: loss = 0.280220 * 100, metric = 3.05% * 100;
 Minibatch[ 501- 600]: loss = 0.285414 * 100, metric = 2.91% * 100;
 Minibatch[ 601- 700]: loss = 0.279284 * 100, metric = 3.06% * 100;
 Minibatch[ 701- 800]: loss = 0.267796 * 100, metric = 2.85% * 100;
 Minibatch[ 801- 900]: loss = 0.289428 * 100, metric = 3.10% * 100;
 Minibatch[ 901-1000]: loss = 0.274236 * 100, metric = 2.84% * 100;
 Minibatch[1001-1100]: loss = 0.270352 * 100, metric = 2.87% * 100;
 Minibatch[1101-1200]: loss = 0.282606 * 100, metric = 2.97% * 100;
 Minibatch[1201-1300]: loss = 0.287554 * 100, metric = 3.03% * 100;
 Minibatch[1301-1400]: loss = 0.280790 * 100, metric = 2.97% * 100;
 Minibatch[1401-1500]: loss = 0.283792 * 100, metric = 3.12% * 100;
 Minibatch[1501-1600]: loss = 0.291586 * 100, metric = 3.19% * 100;
 Minibatch[1601-1700]: loss = 0.281920 * 100, metric = 3.02% * 100;
 Minibatch[1701-1800]: loss = 0.280640 * 100, metric = 3.12% * 100;
 Minibatch[1801-1900]: loss = 0.268519 * 100, metric = 2.80% * 100;
 Minibatch[1901-2000]: loss = 0.262355 * 100, metric = 2.80% * 100;
Finished Epoch[182 of 200]: [Training] loss = 0.281357 * 2000, metric = 3.02% * 2000 840.108s (  2.4 samples/s);
Finished Evaluation [182]: Minibatch[1-2000]: metric = 10.80% * 2000;
 Minibatch[   1- 100]: loss = 0.275225 * 100, metric = 3.03% * 100;
 Minibatch[ 101- 200]: loss = 0.280315 * 100, metric = 2.90% * 100;
 Minibatch[ 201- 300]: loss = 0.282054 * 100, metric = 3.07% * 100;
 Minibatch[ 301- 400]: loss = 0.276702 * 100, metric = 2.96% * 100;
 Minibatch[ 401- 500]: loss = 0.287797 * 100, metric = 3.14% * 100;
 Minibatch[ 501- 600]: loss = 0.281031 * 100, metric = 2.91% * 100;
 Minibatch[ 601- 700]: loss = 0.298960 * 100, metric = 3.15% * 100;
 Minibatch[ 701- 800]: loss = 0.283706 * 100, metric = 3.22% * 100;
 Minibatch[ 801- 900]: loss = 0.279357 * 100, metric = 2.87% * 100;
 Minibatch[ 901-1000]: loss = 0.286348 * 100, metric = 3.09% * 100;
 Minibatch[1001-1100]: loss = 0.287529 * 100, metric = 3.11% * 100;
 Minibatch[1101-1200]: loss = 0.273343 * 100, metric = 2.83% * 100;
 Minibatch[1201-1300]: loss = 0.282377 * 100, metric = 2.93% * 100;
 Minibatch[1301-1400]: loss = 0.282883 * 100, metric = 3.07% * 100;
 Minibatch[1401-1500]: loss = 0.265448 * 100, metric = 2.77% * 100;
 Minibatch[1501-1600]: loss = 0.271760 * 100, metric = 2.92% * 100;
 Minibatch[1601-1700]: loss = 0.295999 * 100, metric = 3.14% * 100;
 Minibatch[1701-1800]: loss = 0.282262 * 100, metric = 2.90% * 100;
 Minibatch[1801-1900]: loss = 0.285120 * 100, metric = 3.06% * 100;
 Minibatch[1901-2000]: loss = 0.280864 * 100, metric = 2.99% * 100;
Finished Epoch[183 of 200]: [Training] loss = 0.281954 * 2000, metric = 3.00% * 2000 899.899s (  2.2 samples/s);
Finished Evaluation [183]: Minibatch[1-2000]: metric = 10.59% * 2000;
 Minibatch[   1- 100]: loss = 0.269612 * 100, metric = 2.80% * 100;
 Minibatch[ 101- 200]: loss = 0.268162 * 100, metric = 2.72% * 100;
 Minibatch[ 201- 300]: loss = 0.256143 * 100, metric = 2.75% * 100;
 Minibatch[ 301- 400]: loss = 0.266277 * 100, metric = 2.75% * 100;
 Minibatch[ 401- 500]: loss = 0.280775 * 100, metric = 2.89% * 100;
 Minibatch[ 501- 600]: loss = 0.270708 * 100, metric = 2.77% * 100;
 Minibatch[ 601- 700]: loss = 0.295444 * 100, metric = 3.20% * 100;
 Minibatch[ 701- 800]: loss = 0.283861 * 100, metric = 2.94% * 100;
 Minibatch[ 801- 900]: loss = 0.278573 * 100, metric = 2.99% * 100;
 Minibatch[ 901-1000]: loss = 0.272089 * 100, metric = 2.81% * 100;
 Minibatch[1001-1100]: loss = 0.267100 * 100, metric = 2.79% * 100;
 Minibatch[1101-1200]: loss = 0.266713 * 100, metric = 2.79% * 100;
 Minibatch[1201-1300]: loss = 0.267964 * 100, metric = 2.67% * 100;
 Minibatch[1301-1400]: loss = 0.269680 * 100, metric = 2.86% * 100;
 Minibatch[1401-1500]: loss = 0.276834 * 100, metric = 2.96% * 100;
 Minibatch[1501-1600]: loss = 0.264332 * 100, metric = 2.73% * 100;
 Minibatch[1601-1700]: loss = 0.279444 * 100, metric = 3.10% * 100;
 Minibatch[1701-1800]: loss = 0.265260 * 100, metric = 2.85% * 100;
 Minibatch[1801-1900]: loss = 0.259444 * 100, metric = 2.85% * 100;
 Minibatch[1901-2000]: loss = 0.279858 * 100, metric = 2.91% * 100;
Finished Epoch[184 of 200]: [Training] loss = 0.271914 * 2000, metric = 2.86% * 2000 870.404s (  2.3 samples/s);
Finished Evaluation [184]: Minibatch[1-2000]: metric = 10.22% * 2000;
 Minibatch[   1- 100]: loss = 0.272507 * 100, metric = 2.89% * 100;
 Minibatch[ 101- 200]: loss = 0.272010 * 100, metric = 2.83% * 100;
 Minibatch[ 201- 300]: loss = 0.273419 * 100, metric = 2.89% * 100;
 Minibatch[ 301- 400]: loss = 0.274755 * 100, metric = 2.88% * 100;
 Minibatch[ 401- 500]: loss = 0.273913 * 100, metric = 2.84% * 100;
 Minibatch[ 501- 600]: loss = 0.260528 * 100, metric = 2.76% * 100;
 Minibatch[ 601- 700]: loss = 0.268192 * 100, metric = 2.78% * 100;
 Minibatch[ 701- 800]: loss = 0.260614 * 100, metric = 2.60% * 100;
 Minibatch[ 801- 900]: loss = 0.266106 * 100, metric = 2.65% * 100;
 Minibatch[ 901-1000]: loss = 0.257784 * 100, metric = 2.66% * 100;
 Minibatch[1001-1100]: loss = 0.266685 * 100, metric = 2.60% * 100;
 Minibatch[1101-1200]: loss = 0.269840 * 100, metric = 2.71% * 100;
 Minibatch[1201-1300]: loss = 0.257129 * 100, metric = 2.62% * 100;
 Minibatch[1301-1400]: loss = 0.262956 * 100, metric = 2.77% * 100;
 Minibatch[1401-1500]: loss = 0.265543 * 100, metric = 2.74% * 100;
 Minibatch[1501-1600]: loss = 0.261895 * 100, metric = 2.61% * 100;
 Minibatch[1601-1700]: loss = 0.275598 * 100, metric = 2.89% * 100;
 Minibatch[1701-1800]: loss = 0.263428 * 100, metric = 2.74% * 100;
 Minibatch[1801-1900]: loss = 0.262791 * 100, metric = 2.74% * 100;
 Minibatch[1901-2000]: loss = 0.260290 * 100, metric = 2.64% * 100;
Finished Epoch[185 of 200]: [Training] loss = 0.266299 * 2000, metric = 2.74% * 2000 842.324s (  2.4 samples/s);
Finished Evaluation [185]: Minibatch[1-2000]: metric = 10.55% * 2000;
 Minibatch[   1- 100]: loss = 0.275269 * 100, metric = 2.79% * 100;
 Minibatch[ 101- 200]: loss = 0.282408 * 100, metric = 2.99% * 100;
 Minibatch[ 201- 300]: loss = 0.271022 * 100, metric = 2.89% * 100;
 Minibatch[ 301- 400]: loss = 0.263414 * 100, metric = 2.70% * 100;
 Minibatch[ 401- 500]: loss = 0.272300 * 100, metric = 2.87% * 100;
 Minibatch[ 501- 600]: loss = 0.261046 * 100, metric = 2.66% * 100;
 Minibatch[ 601- 700]: loss = 0.272418 * 100, metric = 2.90% * 100;
 Minibatch[ 701- 800]: loss = 0.269183 * 100, metric = 2.87% * 100;
 Minibatch[ 801- 900]: loss = 0.263633 * 100, metric = 2.75% * 100;
 Minibatch[ 901-1000]: loss = 0.255593 * 100, metric = 2.61% * 100;
 Minibatch[1001-1100]: loss = 0.271808 * 100, metric = 2.84% * 100;
 Minibatch[1101-1200]: loss = 0.272808 * 100, metric = 2.82% * 100;
 Minibatch[1201-1300]: loss = 0.280187 * 100, metric = 2.95% * 100;
 Minibatch[1301-1400]: loss = 0.248731 * 100, metric = 2.48% * 100;
 Minibatch[1401-1500]: loss = 0.259488 * 100, metric = 2.71% * 100;
 Minibatch[1501-1600]: loss = 0.266245 * 100, metric = 2.66% * 100;
 Minibatch[1601-1700]: loss = 0.264892 * 100, metric = 2.68% * 100;
 Minibatch[1701-1800]: loss = 0.270171 * 100, metric = 2.85% * 100;
 Minibatch[1801-1900]: loss = 0.258831 * 100, metric = 2.66% * 100;
 Minibatch[1901-2000]: loss = 0.262641 * 100, metric = 2.79% * 100;
Finished Epoch[186 of 200]: [Training] loss = 0.267104 * 2000, metric = 2.77% * 2000 851.308s (  2.3 samples/s);
Finished Evaluation [186]: Minibatch[1-2000]: metric = 10.18% * 2000;
 Minibatch[   1- 100]: loss = 0.263747 * 100, metric = 2.72% * 100;
 Minibatch[ 101- 200]: loss = 0.266915 * 100, metric = 2.55% * 100;
 Minibatch[ 201- 300]: loss = 0.269518 * 100, metric = 3.00% * 100;
 Minibatch[ 301- 400]: loss = 0.259634 * 100, metric = 2.76% * 100;
 Minibatch[ 401- 500]: loss = 0.253635 * 100, metric = 2.55% * 100;
 Minibatch[ 501- 600]: loss = 0.267985 * 100, metric = 2.79% * 100;
 Minibatch[ 601- 700]: loss = 0.264943 * 100, metric = 2.92% * 100;
 Minibatch[ 701- 800]: loss = 0.273617 * 100, metric = 2.90% * 100;
 Minibatch[ 801- 900]: loss = 0.269105 * 100, metric = 2.75% * 100;
 Minibatch[ 901-1000]: loss = 0.256323 * 100, metric = 2.66% * 100;
 Minibatch[1001-1100]: loss = 0.264819 * 100, metric = 2.72% * 100;
 Minibatch[1101-1200]: loss = 0.262543 * 100, metric = 2.75% * 100;
 Minibatch[1201-1300]: loss = 0.274759 * 100, metric = 2.85% * 100;
 Minibatch[1301-1400]: loss = 0.259773 * 100, metric = 2.61% * 100;
 Minibatch[1401-1500]: loss = 0.276833 * 100, metric = 2.84% * 100;
 Minibatch[1501-1600]: loss = 0.259071 * 100, metric = 2.66% * 100;
 Minibatch[1601-1700]: loss = 0.265714 * 100, metric = 2.80% * 100;
 Minibatch[1701-1800]: loss = 0.255450 * 100, metric = 2.59% * 100;
 Minibatch[1801-1900]: loss = 0.273134 * 100, metric = 2.97% * 100;
 Minibatch[1901-2000]: loss = 0.266354 * 100, metric = 2.73% * 100;
Finished Epoch[187 of 200]: [Training] loss = 0.265194 * 2000, metric = 2.76% * 2000 838.757s (  2.4 samples/s);
Finished Evaluation [187]: Minibatch[1-2000]: metric = 11.20% * 2000;
 Minibatch[   1- 100]: loss = 0.267974 * 100, metric = 2.81% * 100;
 Minibatch[ 101- 200]: loss = 0.257292 * 100, metric = 2.62% * 100;
 Minibatch[ 201- 300]: loss = 0.252163 * 100, metric = 2.44% * 100;
 Minibatch[ 301- 400]: loss = 0.254027 * 100, metric = 2.50% * 100;
 Minibatch[ 401- 500]: loss = 0.261003 * 100, metric = 2.73% * 100;
 Minibatch[ 501- 600]: loss = 0.252640 * 100, metric = 2.46% * 100;
 Minibatch[ 601- 700]: loss = 0.264952 * 100, metric = 2.74% * 100;
 Minibatch[ 701- 800]: loss = 0.275825 * 100, metric = 2.79% * 100;
 Minibatch[ 801- 900]: loss = 0.267954 * 100, metric = 2.88% * 100;
 Minibatch[ 901-1000]: loss = 0.264563 * 100, metric = 2.70% * 100;
 Minibatch[1001-1100]: loss = 0.254688 * 100, metric = 2.46% * 100;
 Minibatch[1101-1200]: loss = 0.269043 * 100, metric = 2.70% * 100;
 Minibatch[1201-1300]: loss = 0.275306 * 100, metric = 2.78% * 100;
 Minibatch[1301-1400]: loss = 0.271033 * 100, metric = 2.79% * 100;
 Minibatch[1401-1500]: loss = 0.257012 * 100, metric = 2.78% * 100;
 Minibatch[1501-1600]: loss = 0.253889 * 100, metric = 2.63% * 100;
 Minibatch[1601-1700]: loss = 0.264979 * 100, metric = 2.62% * 100;
 Minibatch[1701-1800]: loss = 0.262147 * 100, metric = 2.59% * 100;
 Minibatch[1801-1900]: loss = 0.256931 * 100, metric = 2.77% * 100;
 Minibatch[1901-2000]: loss = 0.258427 * 100, metric = 2.50% * 100;
Finished Epoch[188 of 200]: [Training] loss = 0.262092 * 2000, metric = 2.66% * 2000 811.940s (  2.5 samples/s);
Finished Evaluation [188]: Minibatch[1-2000]: metric = 11.62% * 2000;
 Minibatch[   1- 100]: loss = 0.248863 * 100, metric = 2.42% * 100;
 Minibatch[ 101- 200]: loss = 0.258967 * 100, metric = 2.64% * 100;
 Minibatch[ 201- 300]: loss = 0.261137 * 100, metric = 2.67% * 100;
 Minibatch[ 301- 400]: loss = 0.262181 * 100, metric = 2.59% * 100;
 Minibatch[ 401- 500]: loss = 0.278230 * 100, metric = 2.95% * 100;
 Minibatch[ 501- 600]: loss = 0.264347 * 100, metric = 2.77% * 100;
 Minibatch[ 601- 700]: loss = 0.259294 * 100, metric = 2.65% * 100;
 Minibatch[ 701- 800]: loss = 0.262561 * 100, metric = 2.52% * 100;
 Minibatch[ 801- 900]: loss = 0.265905 * 100, metric = 2.71% * 100;
 Minibatch[ 901-1000]: loss = 0.249231 * 100, metric = 2.48% * 100;
 Minibatch[1001-1100]: loss = 0.262644 * 100, metric = 2.63% * 100;
 Minibatch[1101-1200]: loss = 0.278507 * 100, metric = 2.89% * 100;
 Minibatch[1201-1300]: loss = 0.256087 * 100, metric = 2.49% * 100;
 Minibatch[1301-1400]: loss = 0.253398 * 100, metric = 2.52% * 100;
 Minibatch[1401-1500]: loss = 0.246265 * 100, metric = 2.30% * 100;
 Minibatch[1501-1600]: loss = 0.275417 * 100, metric = 2.77% * 100;
 Minibatch[1601-1700]: loss = 0.253643 * 100, metric = 2.54% * 100;
 Minibatch[1701-1800]: loss = 0.258230 * 100, metric = 2.62% * 100;
 Minibatch[1801-1900]: loss = 0.263238 * 100, metric = 2.63% * 100;
 Minibatch[1901-2000]: loss = 0.262394 * 100, metric = 2.78% * 100;
Finished Epoch[189 of 200]: [Training] loss = 0.261027 * 2000, metric = 2.63% * 2000 801.229s (  2.5 samples/s);
Finished Evaluation [189]: Minibatch[1-2000]: metric = 9.99% * 2000;
 Minibatch[   1- 100]: loss = 0.258887 * 100, metric = 2.68% * 100;
 Minibatch[ 101- 200]: loss = 0.252761 * 100, metric = 2.60% * 100;
 Minibatch[ 201- 300]: loss = 0.262871 * 100, metric = 2.63% * 100;
 Minibatch[ 301- 400]: loss = 0.257917 * 100, metric = 2.68% * 100;
 Minibatch[ 401- 500]: loss = 0.261528 * 100, metric = 2.55% * 100;
 Minibatch[ 501- 600]: loss = 0.272807 * 100, metric = 2.88% * 100;
 Minibatch[ 601- 700]: loss = 0.259605 * 100, metric = 2.61% * 100;
 Minibatch[ 701- 800]: loss = 0.261040 * 100, metric = 2.66% * 100;
 Minibatch[ 801- 900]: loss = 0.263367 * 100, metric = 2.69% * 100;
 Minibatch[ 901-1000]: loss = 0.255034 * 100, metric = 2.59% * 100;
 Minibatch[1001-1100]: loss = 0.270704 * 100, metric = 2.72% * 100;
 Minibatch[1101-1200]: loss = 0.258541 * 100, metric = 2.49% * 100;
 Minibatch[1201-1300]: loss = 0.257060 * 100, metric = 2.59% * 100;
 Minibatch[1301-1400]: loss = 0.262782 * 100, metric = 2.74% * 100;
 Minibatch[1401-1500]: loss = 0.248962 * 100, metric = 2.47% * 100;
 Minibatch[1501-1600]: loss = 0.246695 * 100, metric = 2.44% * 100;
 Minibatch[1601-1700]: loss = 0.258270 * 100, metric = 2.66% * 100;
 Minibatch[1701-1800]: loss = 0.265158 * 100, metric = 2.55% * 100;
 Minibatch[1801-1900]: loss = 0.267177 * 100, metric = 2.78% * 100;
 Minibatch[1901-2000]: loss = 0.261054 * 100, metric = 2.67% * 100;
Finished Epoch[190 of 200]: [Training] loss = 0.260111 * 2000, metric = 2.63% * 2000 794.347s (  2.5 samples/s);
Finished Evaluation [190]: Minibatch[1-2000]: metric = 10.72% * 2000;
 Minibatch[   1- 100]: loss = 0.262966 * 100, metric = 2.55% * 100;
 Minibatch[ 101- 200]: loss = 0.267950 * 100, metric = 2.80% * 100;
 Minibatch[ 201- 300]: loss = 0.264832 * 100, metric = 2.73% * 100;
 Minibatch[ 301- 400]: loss = 0.273324 * 100, metric = 2.76% * 100;
 Minibatch[ 401- 500]: loss = 0.260710 * 100, metric = 2.56% * 100;
 Minibatch[ 501- 600]: loss = 0.252647 * 100, metric = 2.39% * 100;
 Minibatch[ 601- 700]: loss = 0.246390 * 100, metric = 2.44% * 100;
 Minibatch[ 701- 800]: loss = 0.247949 * 100, metric = 2.39% * 100;
 Minibatch[ 801- 900]: loss = 0.269249 * 100, metric = 2.62% * 100;
 Minibatch[ 901-1000]: loss = 0.252977 * 100, metric = 2.48% * 100;
 Minibatch[1001-1100]: loss = 0.253583 * 100, metric = 2.33% * 100;
 Minibatch[1101-1200]: loss = 0.265378 * 100, metric = 2.60% * 100;
 Minibatch[1201-1300]: loss = 0.256644 * 100, metric = 2.53% * 100;
 Minibatch[1301-1400]: loss = 0.255024 * 100, metric = 2.52% * 100;
 Minibatch[1401-1500]: loss = 0.267003 * 100, metric = 2.78% * 100;
 Minibatch[1501-1600]: loss = 0.264332 * 100, metric = 2.82% * 100;
 Minibatch[1601-1700]: loss = 0.265887 * 100, metric = 2.61% * 100;
 Minibatch[1701-1800]: loss = 0.269411 * 100, metric = 2.62% * 100;
 Minibatch[1801-1900]: loss = 0.256127 * 100, metric = 2.64% * 100;
 Minibatch[1901-2000]: loss = 0.253622 * 100, metric = 2.45% * 100;
Finished Epoch[191 of 200]: [Training] loss = 0.260300 * 2000, metric = 2.58% * 2000 804.886s (  2.5 samples/s);
Finished Evaluation [191]: Minibatch[1-2000]: metric = 10.44% * 2000;
 Minibatch[   1- 100]: loss = 0.255673 * 100, metric = 2.48% * 100;
 Minibatch[ 101- 200]: loss = 0.262694 * 100, metric = 2.73% * 100;
 Minibatch[ 201- 300]: loss = 0.261275 * 100, metric = 2.56% * 100;
 Minibatch[ 301- 400]: loss = 0.257281 * 100, metric = 2.57% * 100;
 Minibatch[ 401- 500]: loss = 0.254892 * 100, metric = 2.43% * 100;
 Minibatch[ 501- 600]: loss = 0.261882 * 100, metric = 2.55% * 100;
 Minibatch[ 601- 700]: loss = 0.263762 * 100, metric = 2.54% * 100;
 Minibatch[ 701- 800]: loss = 0.254029 * 100, metric = 2.52% * 100;
 Minibatch[ 801- 900]: loss = 0.246832 * 100, metric = 2.39% * 100;
 Minibatch[ 901-1000]: loss = 0.255339 * 100, metric = 2.66% * 100;
 Minibatch[1001-1100]: loss = 0.267068 * 100, metric = 2.50% * 100;
 Minibatch[1101-1200]: loss = 0.250845 * 100, metric = 2.53% * 100;
 Minibatch[1201-1300]: loss = 0.246360 * 100, metric = 2.26% * 100;
 Minibatch[1301-1400]: loss = 0.251466 * 100, metric = 2.50% * 100;
 Minibatch[1401-1500]: loss = 0.263373 * 100, metric = 2.71% * 100;
 Minibatch[1501-1600]: loss = 0.256342 * 100, metric = 2.57% * 100;
 Minibatch[1601-1700]: loss = 0.260746 * 100, metric = 2.53% * 100;
 Minibatch[1701-1800]: loss = 0.259463 * 100, metric = 2.63% * 100;
 Minibatch[1801-1900]: loss = 0.275352 * 100, metric = 2.79% * 100;
 Minibatch[1901-2000]: loss = 0.260028 * 100, metric = 2.70% * 100;
Finished Epoch[192 of 200]: [Training] loss = 0.258235 * 2000, metric = 2.56% * 2000 802.296s (  2.5 samples/s);
Finished Evaluation [192]: Minibatch[1-2000]: metric = 9.98% * 2000;
 Minibatch[   1- 100]: loss = 0.257917 * 100, metric = 2.48% * 100;
 Minibatch[ 101- 200]: loss = 0.243897 * 100, metric = 2.33% * 100;
 Minibatch[ 201- 300]: loss = 0.252070 * 100, metric = 2.55% * 100;
 Minibatch[ 301- 400]: loss = 0.248971 * 100, metric = 2.46% * 100;
 Minibatch[ 401- 500]: loss = 0.256964 * 100, metric = 2.55% * 100;
 Minibatch[ 501- 600]: loss = 0.246207 * 100, metric = 2.42% * 100;
 Minibatch[ 601- 700]: loss = 0.260330 * 100, metric = 2.57% * 100;
 Minibatch[ 701- 800]: loss = 0.262211 * 100, metric = 2.53% * 100;
 Minibatch[ 801- 900]: loss = 0.262265 * 100, metric = 2.61% * 100;
 Minibatch[ 901-1000]: loss = 0.261713 * 100, metric = 2.62% * 100;
 Minibatch[1001-1100]: loss = 0.252845 * 100, metric = 2.52% * 100;
 Minibatch[1101-1200]: loss = 0.258666 * 100, metric = 2.54% * 100;
 Minibatch[1201-1300]: loss = 0.255013 * 100, metric = 2.46% * 100;
 Minibatch[1301-1400]: loss = 0.250511 * 100, metric = 2.34% * 100;
 Minibatch[1401-1500]: loss = 0.269197 * 100, metric = 2.68% * 100;
 Minibatch[1501-1600]: loss = 0.236971 * 100, metric = 2.43% * 100;
 Minibatch[1601-1700]: loss = 0.253167 * 100, metric = 2.59% * 100;
 Minibatch[1701-1800]: loss = 0.251134 * 100, metric = 2.43% * 100;
 Minibatch[1801-1900]: loss = 0.253135 * 100, metric = 2.56% * 100;
 Minibatch[1901-2000]: loss = 0.247978 * 100, metric = 2.47% * 100;
Finished Epoch[193 of 200]: [Training] loss = 0.254058 * 2000, metric = 2.51% * 2000 791.061s (  2.5 samples/s);
Finished Evaluation [193]: Minibatch[1-2000]: metric = 10.56% * 2000;
 Minibatch[   1- 100]: loss = 0.254952 * 100, metric = 2.60% * 100;
 Minibatch[ 101- 200]: loss = 0.249022 * 100, metric = 2.59% * 100;
 Minibatch[ 201- 300]: loss = 0.248037 * 100, metric = 2.45% * 100;
 Minibatch[ 301- 400]: loss = 0.257329 * 100, metric = 2.55% * 100;
 Minibatch[ 401- 500]: loss = 0.249451 * 100, metric = 2.40% * 100;
 Minibatch[ 501- 600]: loss = 0.253757 * 100, metric = 2.48% * 100;
 Minibatch[ 601- 700]: loss = 0.249417 * 100, metric = 2.52% * 100;
 Minibatch[ 701- 800]: loss = 0.241648 * 100, metric = 2.38% * 100;
 Minibatch[ 801- 900]: loss = 0.248154 * 100, metric = 2.46% * 100;
 Minibatch[ 901-1000]: loss = 0.252114 * 100, metric = 2.61% * 100;
 Minibatch[1001-1100]: loss = 0.260255 * 100, metric = 2.78% * 100;
 Minibatch[1101-1200]: loss = 0.257690 * 100, metric = 2.48% * 100;
 Minibatch[1201-1300]: loss = 0.258888 * 100, metric = 2.47% * 100;
 Minibatch[1301-1400]: loss = 0.253691 * 100, metric = 2.44% * 100;
 Minibatch[1401-1500]: loss = 0.254005 * 100, metric = 2.61% * 100;
 Minibatch[1501-1600]: loss = 0.249174 * 100, metric = 2.42% * 100;
 Minibatch[1601-1700]: loss = 0.258116 * 100, metric = 2.64% * 100;
 Minibatch[1701-1800]: loss = 0.256802 * 100, metric = 2.48% * 100;
 Minibatch[1801-1900]: loss = 0.260414 * 100, metric = 2.69% * 100;
 Minibatch[1901-2000]: loss = 0.257544 * 100, metric = 2.49% * 100;
Finished Epoch[194 of 200]: [Training] loss = 0.253523 * 2000, metric = 2.53% * 2000 801.289s (  2.5 samples/s);
Finished Evaluation [194]: Minibatch[1-2000]: metric = 10.92% * 2000;
 Minibatch[   1- 100]: loss = 0.250468 * 100, metric = 2.44% * 100;
 Minibatch[ 101- 200]: loss = 0.248085 * 100, metric = 2.42% * 100;
 Minibatch[ 201- 300]: loss = 0.266864 * 100, metric = 2.80% * 100;
 Minibatch[ 301- 400]: loss = 0.251012 * 100, metric = 2.44% * 100;
 Minibatch[ 401- 500]: loss = 0.257068 * 100, metric = 2.50% * 100;
 Minibatch[ 501- 600]: loss = 0.260209 * 100, metric = 2.54% * 100;
 Minibatch[ 601- 700]: loss = 0.257390 * 100, metric = 2.58% * 100;
 Minibatch[ 701- 800]: loss = 0.250757 * 100, metric = 2.38% * 100;
 Minibatch[ 801- 900]: loss = 0.257559 * 100, metric = 2.59% * 100;
 Minibatch[ 901-1000]: loss = 0.255195 * 100, metric = 2.56% * 100;
 Minibatch[1001-1100]: loss = 0.264674 * 100, metric = 2.54% * 100;
 Minibatch[1101-1200]: loss = 0.246436 * 100, metric = 2.40% * 100;
 Minibatch[1201-1300]: loss = 0.255394 * 100, metric = 2.50% * 100;
 Minibatch[1301-1400]: loss = 0.248014 * 100, metric = 2.41% * 100;
 Minibatch[1401-1500]: loss = 0.253167 * 100, metric = 2.51% * 100;
 Minibatch[1501-1600]: loss = 0.249623 * 100, metric = 2.39% * 100;
 Minibatch[1601-1700]: loss = 0.253094 * 100, metric = 2.47% * 100;
 Minibatch[1701-1800]: loss = 0.263014 * 100, metric = 2.61% * 100;
 Minibatch[1801-1900]: loss = 0.253018 * 100, metric = 2.43% * 100;
 Minibatch[1901-2000]: loss = 0.235797 * 100, metric = 2.22% * 100;
Finished Epoch[195 of 200]: [Training] loss = 0.253842 * 2000, metric = 2.49% * 2000 793.928s (  2.5 samples/s);
Finished Evaluation [195]: Minibatch[1-2000]: metric = 10.55% * 2000;
 Minibatch[   1- 100]: loss = 0.244465 * 100, metric = 2.30% * 100;
 Minibatch[ 101- 200]: loss = 0.254619 * 100, metric = 2.50% * 100;
 Minibatch[ 201- 300]: loss = 0.248341 * 100, metric = 2.44% * 100;
 Minibatch[ 301- 400]: loss = 0.251058 * 100, metric = 2.60% * 100;
 Minibatch[ 401- 500]: loss = 0.240324 * 100, metric = 2.31% * 100;
 Minibatch[ 501- 600]: loss = 0.246836 * 100, metric = 2.33% * 100;
 Minibatch[ 601- 700]: loss = 0.245673 * 100, metric = 2.31% * 100;
 Minibatch[ 701- 800]: loss = 0.257419 * 100, metric = 2.60% * 100;
 Minibatch[ 801- 900]: loss = 0.240479 * 100, metric = 2.17% * 100;
 Minibatch[ 901-1000]: loss = 0.242307 * 100, metric = 2.31% * 100;
 Minibatch[1001-1100]: loss = 0.238624 * 100, metric = 2.28% * 100;
 Minibatch[1101-1200]: loss = 0.258160 * 100, metric = 2.74% * 100;
 Minibatch[1201-1300]: loss = 0.247960 * 100, metric = 2.55% * 100;
 Minibatch[1301-1400]: loss = 0.258633 * 100, metric = 2.62% * 100;
 Minibatch[1401-1500]: loss = 0.260363 * 100, metric = 2.67% * 100;
 Minibatch[1501-1600]: loss = 0.253728 * 100, metric = 2.48% * 100;
 Minibatch[1601-1700]: loss = 0.244823 * 100, metric = 2.39% * 100;
 Minibatch[1701-1800]: loss = 0.241654 * 100, metric = 2.43% * 100;
 Minibatch[1801-1900]: loss = 0.244460 * 100, metric = 2.53% * 100;
 Minibatch[1901-2000]: loss = 0.252099 * 100, metric = 2.52% * 100;
Finished Epoch[196 of 200]: [Training] loss = 0.248601 * 2000, metric = 2.45% * 2000 786.230s (  2.5 samples/s);
Finished Evaluation [196]: Minibatch[1-2000]: metric = 10.63% * 2000;
 Minibatch[   1- 100]: loss = 0.247923 * 100, metric = 2.38% * 100;
 Minibatch[ 101- 200]: loss = 0.246970 * 100, metric = 2.40% * 100;
 Minibatch[ 201- 300]: loss = 0.246452 * 100, metric = 2.35% * 100;
 Minibatch[ 301- 400]: loss = 0.252404 * 100, metric = 2.56% * 100;
 Minibatch[ 401- 500]: loss = 0.254428 * 100, metric = 2.41% * 100;
 Minibatch[ 501- 600]: loss = 0.246716 * 100, metric = 2.44% * 100;
 Minibatch[ 601- 700]: loss = 0.253695 * 100, metric = 2.42% * 100;
 Minibatch[ 701- 800]: loss = 0.259450 * 100, metric = 2.54% * 100;
 Minibatch[ 801- 900]: loss = 0.247041 * 100, metric = 2.44% * 100;
 Minibatch[ 901-1000]: loss = 0.257326 * 100, metric = 2.49% * 100;
 Minibatch[1001-1100]: loss = 0.263056 * 100, metric = 2.59% * 100;
 Minibatch[1101-1200]: loss = 0.238431 * 100, metric = 2.34% * 100;
 Minibatch[1201-1300]: loss = 0.254393 * 100, metric = 2.58% * 100;
 Minibatch[1301-1400]: loss = 0.244078 * 100, metric = 2.34% * 100;
 Minibatch[1401-1500]: loss = 0.253239 * 100, metric = 2.56% * 100;
 Minibatch[1501-1600]: loss = 0.258220 * 100, metric = 2.67% * 100;
 Minibatch[1601-1700]: loss = 0.235594 * 100, metric = 2.29% * 100;
 Minibatch[1701-1800]: loss = 0.246437 * 100, metric = 2.33% * 100;
 Minibatch[1801-1900]: loss = 0.255506 * 100, metric = 2.48% * 100;
 Minibatch[1901-2000]: loss = 0.240865 * 100, metric = 2.38% * 100;
Finished Epoch[197 of 200]: [Training] loss = 0.250111 * 2000, metric = 2.45% * 2000 764.207s (  2.6 samples/s);
Finished Evaluation [197]: Minibatch[1-2000]: metric = 10.31% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
