Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.358613 * 100, metric = 25.00% * 100;
 Minibatch[ 101- 200]: loss = 1.147610 * 100, metric = 23.27% * 100;
 Minibatch[ 201- 300]: loss = 1.031286 * 100, metric = 21.40% * 100;
 Minibatch[ 301- 400]: loss = 1.026346 * 100, metric = 20.61% * 100;
 Minibatch[ 401- 500]: loss = 0.984335 * 100, metric = 19.68% * 100;
 Minibatch[ 501- 600]: loss = 0.949050 * 100, metric = 18.29% * 100;
 Minibatch[ 601- 700]: loss = 0.934991 * 100, metric = 18.02% * 100;
 Minibatch[ 701- 800]: loss = 0.884641 * 100, metric = 16.83% * 100;
 Minibatch[ 801- 900]: loss = 0.924844 * 100, metric = 17.53% * 100;
 Minibatch[ 901-1000]: loss = 0.934227 * 100, metric = 18.04% * 100;
 Minibatch[1001-1100]: loss = 0.910840 * 100, metric = 17.12% * 100;
 Minibatch[1101-1200]: loss = 0.895393 * 100, metric = 16.71% * 100;
 Minibatch[1201-1300]: loss = 0.888710 * 100, metric = 16.63% * 100;
 Minibatch[1301-1400]: loss = 0.864441 * 100, metric = 16.31% * 100;
 Minibatch[1401-1500]: loss = 0.891453 * 100, metric = 16.88% * 100;
 Minibatch[1501-1600]: loss = 0.854667 * 100, metric = 16.03% * 100;
 Minibatch[1601-1700]: loss = 0.840477 * 100, metric = 15.83% * 100;
 Minibatch[1701-1800]: loss = 0.861376 * 100, metric = 15.93% * 100;
 Minibatch[1801-1900]: loss = 0.855907 * 100, metric = 16.00% * 100;
 Minibatch[1901-2000]: loss = 0.842877 * 100, metric = 15.55% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.944104 * 2000, metric = 18.08% * 2000 937.046s (  2.1 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 25.07% * 2000;
0.8718522044792771
 Minibatch[   1- 100]: loss = 0.832423 * 100, metric = 15.60% * 100;
 Minibatch[ 101- 200]: loss = 0.851587 * 100, metric = 16.06% * 100;
 Minibatch[ 201- 300]: loss = 0.846557 * 100, metric = 15.32% * 100;
 Minibatch[ 301- 400]: loss = 0.832356 * 100, metric = 14.94% * 100;
 Minibatch[ 401- 500]: loss = 0.829819 * 100, metric = 15.17% * 100;
 Minibatch[ 501- 600]: loss = 0.849720 * 100, metric = 15.14% * 100;
 Minibatch[ 601- 700]: loss = 0.804133 * 100, metric = 14.32% * 100;
 Minibatch[ 701- 800]: loss = 0.810062 * 100, metric = 14.92% * 100;
 Minibatch[ 801- 900]: loss = 0.793433 * 100, metric = 14.44% * 100;
 Minibatch[ 901-1000]: loss = 0.791244 * 100, metric = 13.96% * 100;
 Minibatch[1001-1100]: loss = 0.811512 * 100, metric = 14.95% * 100;
 Minibatch[1101-1200]: loss = 0.807819 * 100, metric = 14.50% * 100;
 Minibatch[1201-1300]: loss = 0.794373 * 100, metric = 14.11% * 100;
 Minibatch[1301-1400]: loss = 0.804419 * 100, metric = 14.51% * 100;
 Minibatch[1401-1500]: loss = 0.792804 * 100, metric = 14.31% * 100;
 Minibatch[1501-1600]: loss = 0.788724 * 100, metric = 14.24% * 100;
 Minibatch[1601-1700]: loss = 0.804015 * 100, metric = 14.42% * 100;
 Minibatch[1701-1800]: loss = 0.798953 * 100, metric = 14.59% * 100;
 Minibatch[1801-1900]: loss = 0.808816 * 100, metric = 14.62% * 100;
 Minibatch[1901-2000]: loss = 0.780543 * 100, metric = 14.29% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.811666 * 2000, metric = 14.72% * 2000 865.026s (  2.3 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 20.49% * 2000;
0.7903501423448325
 Minibatch[   1- 100]: loss = 0.789570 * 100, metric = 14.04% * 100;
 Minibatch[ 101- 200]: loss = 0.801713 * 100, metric = 14.59% * 100;
 Minibatch[ 201- 300]: loss = 0.788636 * 100, metric = 14.31% * 100;
 Minibatch[ 301- 400]: loss = 0.803604 * 100, metric = 14.52% * 100;
 Minibatch[ 401- 500]: loss = 0.809092 * 100, metric = 14.84% * 100;
 Minibatch[ 501- 600]: loss = 0.790299 * 100, metric = 14.14% * 100;
 Minibatch[ 601- 700]: loss = 0.796536 * 100, metric = 14.17% * 100;
 Minibatch[ 701- 800]: loss = 0.778145 * 100, metric = 13.57% * 100;
 Minibatch[ 801- 900]: loss = 0.800405 * 100, metric = 14.44% * 100;
 Minibatch[ 901-1000]: loss = 0.763252 * 100, metric = 14.02% * 100;
 Minibatch[1001-1100]: loss = 0.788375 * 100, metric = 14.28% * 100;
 Minibatch[1101-1200]: loss = 0.770626 * 100, metric = 13.80% * 100;
 Minibatch[1201-1300]: loss = 0.765095 * 100, metric = 13.52% * 100;
 Minibatch[1301-1400]: loss = 0.779901 * 100, metric = 13.63% * 100;
 Minibatch[1401-1500]: loss = 0.787068 * 100, metric = 13.88% * 100;
 Minibatch[1501-1600]: loss = 0.771044 * 100, metric = 13.43% * 100;
 Minibatch[1601-1700]: loss = 0.761313 * 100, metric = 13.58% * 100;
 Minibatch[1701-1800]: loss = 0.785048 * 100, metric = 14.00% * 100;
 Minibatch[1801-1900]: loss = 0.767933 * 100, metric = 13.54% * 100;
 Minibatch[1901-2000]: loss = 0.764948 * 100, metric = 13.67% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.783130 * 2000, metric = 14.00% * 2000 870.563s (  2.3 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 19.79% * 2000;
0.7747560663297772
 Minibatch[   1- 100]: loss = 0.786765 * 100, metric = 13.72% * 100;
 Minibatch[ 101- 200]: loss = 0.752265 * 100, metric = 13.19% * 100;
 Minibatch[ 201- 300]: loss = 0.759983 * 100, metric = 13.66% * 100;
 Minibatch[ 301- 400]: loss = 0.737995 * 100, metric = 12.89% * 100;
 Minibatch[ 401- 500]: loss = 0.773497 * 100, metric = 13.94% * 100;
 Minibatch[ 501- 600]: loss = 0.751294 * 100, metric = 12.86% * 100;
 Minibatch[ 601- 700]: loss = 0.750794 * 100, metric = 13.29% * 100;
 Minibatch[ 701- 800]: loss = 0.765204 * 100, metric = 13.27% * 100;
 Minibatch[ 801- 900]: loss = 0.756940 * 100, metric = 13.39% * 100;
 Minibatch[ 901-1000]: loss = 0.760006 * 100, metric = 13.70% * 100;
 Minibatch[1001-1100]: loss = 0.774279 * 100, metric = 13.78% * 100;
 Minibatch[1101-1200]: loss = 0.749794 * 100, metric = 13.34% * 100;
 Minibatch[1201-1300]: loss = 0.753215 * 100, metric = 13.20% * 100;
 Minibatch[1301-1400]: loss = 0.771812 * 100, metric = 13.43% * 100;
 Minibatch[1401-1500]: loss = 0.770710 * 100, metric = 13.63% * 100;
 Minibatch[1501-1600]: loss = 0.725742 * 100, metric = 12.49% * 100;
 Minibatch[1601-1700]: loss = 0.760544 * 100, metric = 13.40% * 100;
 Minibatch[1701-1800]: loss = 0.755836 * 100, metric = 13.47% * 100;
 Minibatch[1801-1900]: loss = 0.744358 * 100, metric = 13.05% * 100;
 Minibatch[1901-2000]: loss = 0.744503 * 100, metric = 12.92% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.757277 * 2000, metric = 13.33% * 2000 878.623s (  2.3 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 21.12% * 2000;
 Minibatch[   1- 100]: loss = 0.769303 * 100, metric = 13.55% * 100;
 Minibatch[ 101- 200]: loss = 0.752452 * 100, metric = 13.22% * 100;
 Minibatch[ 201- 300]: loss = 0.734771 * 100, metric = 12.97% * 100;
 Minibatch[ 301- 400]: loss = 0.771209 * 100, metric = 13.93% * 100;
 Minibatch[ 401- 500]: loss = 0.721655 * 100, metric = 12.59% * 100;
 Minibatch[ 501- 600]: loss = 0.719724 * 100, metric = 12.19% * 100;
 Minibatch[ 601- 700]: loss = 0.729474 * 100, metric = 12.40% * 100;
 Minibatch[ 701- 800]: loss = 0.743994 * 100, metric = 12.97% * 100;
 Minibatch[ 801- 900]: loss = 0.723823 * 100, metric = 12.13% * 100;
 Minibatch[ 901-1000]: loss = 0.719122 * 100, metric = 12.59% * 100;
 Minibatch[1001-1100]: loss = 0.733801 * 100, metric = 12.60% * 100;
 Minibatch[1101-1200]: loss = 0.715058 * 100, metric = 12.25% * 100;
 Minibatch[1201-1300]: loss = 0.736184 * 100, metric = 12.80% * 100;
 Minibatch[1301-1400]: loss = 0.762024 * 100, metric = 13.44% * 100;
 Minibatch[1401-1500]: loss = 0.722388 * 100, metric = 12.52% * 100;
 Minibatch[1501-1600]: loss = 0.732561 * 100, metric = 13.03% * 100;
 Minibatch[1601-1700]: loss = 0.745211 * 100, metric = 13.16% * 100;
 Minibatch[1701-1800]: loss = 0.753315 * 100, metric = 13.24% * 100;
 Minibatch[1801-1900]: loss = 0.748839 * 100, metric = 13.12% * 100;
 Minibatch[1901-2000]: loss = 0.713466 * 100, metric = 12.38% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.737419 * 2000, metric = 12.85% * 2000 880.252s (  2.3 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.95% * 2000;
 Minibatch[   1- 100]: loss = 0.719185 * 100, metric = 12.39% * 100;
 Minibatch[ 101- 200]: loss = 0.708427 * 100, metric = 12.49% * 100;
 Minibatch[ 201- 300]: loss = 0.721842 * 100, metric = 12.43% * 100;
 Minibatch[ 301- 400]: loss = 0.725135 * 100, metric = 12.20% * 100;
 Minibatch[ 401- 500]: loss = 0.696261 * 100, metric = 11.89% * 100;
 Minibatch[ 501- 600]: loss = 0.715661 * 100, metric = 12.28% * 100;
 Minibatch[ 601- 700]: loss = 0.709037 * 100, metric = 12.14% * 100;
 Minibatch[ 701- 800]: loss = 0.723292 * 100, metric = 12.53% * 100;
 Minibatch[ 801- 900]: loss = 0.713450 * 100, metric = 12.33% * 100;
 Minibatch[ 901-1000]: loss = 0.705978 * 100, metric = 12.30% * 100;
 Minibatch[1001-1100]: loss = 0.713511 * 100, metric = 12.02% * 100;
 Minibatch[1101-1200]: loss = 0.718845 * 100, metric = 12.30% * 100;
 Minibatch[1201-1300]: loss = 0.738618 * 100, metric = 12.93% * 100;
 Minibatch[1301-1400]: loss = 0.711092 * 100, metric = 12.44% * 100;
 Minibatch[1401-1500]: loss = 0.729782 * 100, metric = 12.90% * 100;
 Minibatch[1501-1600]: loss = 0.705854 * 100, metric = 11.88% * 100;
 Minibatch[1601-1700]: loss = 0.704872 * 100, metric = 11.88% * 100;
 Minibatch[1701-1800]: loss = 0.696248 * 100, metric = 11.89% * 100;
 Minibatch[1801-1900]: loss = 0.717235 * 100, metric = 12.52% * 100;
 Minibatch[1901-2000]: loss = 0.704812 * 100, metric = 12.13% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.713957 * 2000, metric = 12.29% * 2000 881.612s (  2.3 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 21.90% * 2000;
 Minibatch[   1- 100]: loss = 0.712559 * 100, metric = 12.38% * 100;
 Minibatch[ 101- 200]: loss = 0.713973 * 100, metric = 12.01% * 100;
 Minibatch[ 201- 300]: loss = 0.715798 * 100, metric = 12.28% * 100;
 Minibatch[ 301- 400]: loss = 0.692168 * 100, metric = 11.53% * 100;
 Minibatch[ 401- 500]: loss = 0.703601 * 100, metric = 11.73% * 100;
 Minibatch[ 501- 600]: loss = 0.683713 * 100, metric = 11.50% * 100;
 Minibatch[ 601- 700]: loss = 0.711213 * 100, metric = 11.73% * 100;
 Minibatch[ 701- 800]: loss = 0.709745 * 100, metric = 11.90% * 100;
 Minibatch[ 801- 900]: loss = 0.697823 * 100, metric = 11.80% * 100;
 Minibatch[ 901-1000]: loss = 0.704639 * 100, metric = 12.04% * 100;
 Minibatch[1001-1100]: loss = 0.712361 * 100, metric = 12.25% * 100;
 Minibatch[1101-1200]: loss = 0.691508 * 100, metric = 11.69% * 100;
 Minibatch[1201-1300]: loss = 0.707427 * 100, metric = 12.38% * 100;
 Minibatch[1301-1400]: loss = 0.689519 * 100, metric = 12.05% * 100;
 Minibatch[1401-1500]: loss = 0.682607 * 100, metric = 11.56% * 100;
 Minibatch[1501-1600]: loss = 0.706196 * 100, metric = 12.10% * 100;
 Minibatch[1601-1700]: loss = 0.706786 * 100, metric = 12.33% * 100;
 Minibatch[1701-1800]: loss = 0.694672 * 100, metric = 11.75% * 100;
 Minibatch[1801-1900]: loss = 0.701785 * 100, metric = 12.09% * 100;
 Minibatch[1901-2000]: loss = 0.697124 * 100, metric = 11.92% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.701761 * 2000, metric = 11.95% * 2000 882.154s (  2.3 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.44% * 2000;
0.7282731364369393
 Minibatch[   1- 100]: loss = 0.704514 * 100, metric = 12.05% * 100;
 Minibatch[ 101- 200]: loss = 0.692507 * 100, metric = 11.75% * 100;
 Minibatch[ 201- 300]: loss = 0.670821 * 100, metric = 11.31% * 100;
 Minibatch[ 301- 400]: loss = 0.677073 * 100, metric = 11.50% * 100;
 Minibatch[ 401- 500]: loss = 0.688679 * 100, metric = 12.04% * 100;
 Minibatch[ 501- 600]: loss = 0.708938 * 100, metric = 12.35% * 100;
 Minibatch[ 601- 700]: loss = 0.663098 * 100, metric = 11.22% * 100;
 Minibatch[ 701- 800]: loss = 0.692753 * 100, metric = 11.44% * 100;
 Minibatch[ 801- 900]: loss = 0.672827 * 100, metric = 11.11% * 100;
 Minibatch[ 901-1000]: loss = 0.652057 * 100, metric = 10.48% * 100;
 Minibatch[1001-1100]: loss = 0.663927 * 100, metric = 11.11% * 100;
 Minibatch[1101-1200]: loss = 0.664760 * 100, metric = 10.98% * 100;
 Minibatch[1201-1300]: loss = 0.680892 * 100, metric = 11.39% * 100;
 Minibatch[1301-1400]: loss = 0.680516 * 100, metric = 11.45% * 100;
 Minibatch[1401-1500]: loss = 0.672247 * 100, metric = 11.04% * 100;
 Minibatch[1501-1600]: loss = 0.685419 * 100, metric = 11.55% * 100;
 Minibatch[1601-1700]: loss = 0.675530 * 100, metric = 11.23% * 100;
 Minibatch[1701-1800]: loss = 0.674448 * 100, metric = 11.26% * 100;
 Minibatch[1801-1900]: loss = 0.681361 * 100, metric = 11.51% * 100;
 Minibatch[1901-2000]: loss = 0.672246 * 100, metric = 10.96% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.678731 * 2000, metric = 11.39% * 2000 877.597s (  2.3 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 18.08% * 2000;
0.7133083174452186
 Minibatch[   1- 100]: loss = 0.651956 * 100, metric = 10.72% * 100;
 Minibatch[ 101- 200]: loss = 0.685273 * 100, metric = 11.68% * 100;
 Minibatch[ 201- 300]: loss = 0.670753 * 100, metric = 11.26% * 100;
 Minibatch[ 301- 400]: loss = 0.689491 * 100, metric = 11.75% * 100;
 Minibatch[ 401- 500]: loss = 0.675811 * 100, metric = 11.45% * 100;
 Minibatch[ 501- 600]: loss = 0.661448 * 100, metric = 10.95% * 100;
 Minibatch[ 601- 700]: loss = 0.669648 * 100, metric = 11.26% * 100;
 Minibatch[ 701- 800]: loss = 0.651290 * 100, metric = 10.61% * 100;
 Minibatch[ 801- 900]: loss = 0.664259 * 100, metric = 11.28% * 100;
 Minibatch[ 901-1000]: loss = 0.676345 * 100, metric = 11.48% * 100;
 Minibatch[1001-1100]: loss = 0.644925 * 100, metric = 10.38% * 100;
 Minibatch[1101-1200]: loss = 0.679175 * 100, metric = 11.29% * 100;
 Minibatch[1201-1300]: loss = 0.662126 * 100, metric = 10.93% * 100;
 Minibatch[1301-1400]: loss = 0.646995 * 100, metric = 10.72% * 100;
 Minibatch[1401-1500]: loss = 0.673373 * 100, metric = 11.50% * 100;
 Minibatch[1501-1600]: loss = 0.673111 * 100, metric = 11.50% * 100;
 Minibatch[1601-1700]: loss = 0.675261 * 100, metric = 11.48% * 100;
 Minibatch[1701-1800]: loss = 0.657266 * 100, metric = 10.66% * 100;
 Minibatch[1801-1900]: loss = 0.653864 * 100, metric = 10.86% * 100;
 Minibatch[1901-2000]: loss = 0.673134 * 100, metric = 11.25% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.666775 * 2000, metric = 11.15% * 2000 884.643s (  2.3 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 17.25% * 2000;
0.6975135090351104
 Minibatch[   1- 100]: loss = 0.683982 * 100, metric = 11.78% * 100;
 Minibatch[ 101- 200]: loss = 0.652955 * 100, metric = 10.99% * 100;
 Minibatch[ 201- 300]: loss = 0.656673 * 100, metric = 10.90% * 100;
 Minibatch[ 301- 400]: loss = 0.651927 * 100, metric = 10.74% * 100;
 Minibatch[ 401- 500]: loss = 0.662721 * 100, metric = 11.24% * 100;
 Minibatch[ 501- 600]: loss = 0.642471 * 100, metric = 10.66% * 100;
 Minibatch[ 601- 700]: loss = 0.638688 * 100, metric = 10.69% * 100;
 Minibatch[ 701- 800]: loss = 0.634943 * 100, metric = 10.19% * 100;
 Minibatch[ 801- 900]: loss = 0.656038 * 100, metric = 10.79% * 100;
 Minibatch[ 901-1000]: loss = 0.662593 * 100, metric = 11.02% * 100;
 Minibatch[1001-1100]: loss = 0.652948 * 100, metric = 11.12% * 100;
 Minibatch[1101-1200]: loss = 0.663396 * 100, metric = 10.98% * 100;
 Minibatch[1201-1300]: loss = 0.657859 * 100, metric = 10.91% * 100;
 Minibatch[1301-1400]: loss = 0.644792 * 100, metric = 11.03% * 100;
 Minibatch[1401-1500]: loss = 0.645765 * 100, metric = 10.69% * 100;
 Minibatch[1501-1600]: loss = 0.647362 * 100, metric = 10.96% * 100;
 Minibatch[1601-1700]: loss = 0.649001 * 100, metric = 10.56% * 100;
 Minibatch[1701-1800]: loss = 0.647660 * 100, metric = 10.63% * 100;
 Minibatch[1801-1900]: loss = 0.659924 * 100, metric = 11.11% * 100;
 Minibatch[1901-2000]: loss = 0.630225 * 100, metric = 10.71% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.652096 * 2000, metric = 10.88% * 2000 896.402s (  2.2 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 17.21% * 2000;
0.6974120113626122
 Minibatch[   1- 100]: loss = 0.621886 * 100, metric = 9.91% * 100;
 Minibatch[ 101- 200]: loss = 0.638713 * 100, metric = 10.56% * 100;
 Minibatch[ 201- 300]: loss = 0.646252 * 100, metric = 10.89% * 100;
 Minibatch[ 301- 400]: loss = 0.635270 * 100, metric = 10.59% * 100;
 Minibatch[ 401- 500]: loss = 0.631325 * 100, metric = 10.37% * 100;
 Minibatch[ 501- 600]: loss = 0.641115 * 100, metric = 10.74% * 100;
 Minibatch[ 601- 700]: loss = 0.626693 * 100, metric = 10.30% * 100;
 Minibatch[ 701- 800]: loss = 0.646097 * 100, metric = 10.88% * 100;
 Minibatch[ 801- 900]: loss = 0.641436 * 100, metric = 10.71% * 100;
 Minibatch[ 901-1000]: loss = 0.643052 * 100, metric = 10.61% * 100;
 Minibatch[1001-1100]: loss = 0.636486 * 100, metric = 10.54% * 100;
 Minibatch[1101-1200]: loss = 0.641899 * 100, metric = 10.89% * 100;
 Minibatch[1201-1300]: loss = 0.624178 * 100, metric = 10.33% * 100;
 Minibatch[1301-1400]: loss = 0.615717 * 100, metric = 10.22% * 100;
 Minibatch[1401-1500]: loss = 0.650046 * 100, metric = 11.09% * 100;
 Minibatch[1501-1600]: loss = 0.623010 * 100, metric = 10.44% * 100;
 Minibatch[1601-1700]: loss = 0.624997 * 100, metric = 10.40% * 100;
 Minibatch[1701-1800]: loss = 0.647771 * 100, metric = 11.17% * 100;
 Minibatch[1801-1900]: loss = 0.638820 * 100, metric = 10.76% * 100;
 Minibatch[1901-2000]: loss = 0.627024 * 100, metric = 10.54% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.635089 * 2000, metric = 10.60% * 2000 901.228s (  2.2 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 17.44% * 2000;
 Minibatch[   1- 100]: loss = 0.618540 * 100, metric = 10.21% * 100;
 Minibatch[ 101- 200]: loss = 0.615290 * 100, metric = 9.98% * 100;
 Minibatch[ 201- 300]: loss = 0.620703 * 100, metric = 10.64% * 100;
 Minibatch[ 301- 400]: loss = 0.659582 * 100, metric = 11.32% * 100;
 Minibatch[ 401- 500]: loss = 0.621474 * 100, metric = 10.32% * 100;
 Minibatch[ 501- 600]: loss = 0.600152 * 100, metric = 9.52% * 100;
 Minibatch[ 601- 700]: loss = 0.612034 * 100, metric = 10.04% * 100;
 Minibatch[ 701- 800]: loss = 0.622919 * 100, metric = 10.33% * 100;
 Minibatch[ 801- 900]: loss = 0.615363 * 100, metric = 9.98% * 100;
 Minibatch[ 901-1000]: loss = 0.626339 * 100, metric = 10.36% * 100;
 Minibatch[1001-1100]: loss = 0.628657 * 100, metric = 10.69% * 100;
 Minibatch[1101-1200]: loss = 0.624521 * 100, metric = 10.44% * 100;
 Minibatch[1201-1300]: loss = 0.631733 * 100, metric = 10.65% * 100;
 Minibatch[1301-1400]: loss = 0.614129 * 100, metric = 9.83% * 100;
 Minibatch[1401-1500]: loss = 0.628205 * 100, metric = 10.47% * 100;
 Minibatch[1501-1600]: loss = 0.595679 * 100, metric = 9.86% * 100;
 Minibatch[1601-1700]: loss = 0.625828 * 100, metric = 10.69% * 100;
 Minibatch[1701-1800]: loss = 0.615623 * 100, metric = 10.19% * 100;
 Minibatch[1801-1900]: loss = 0.613157 * 100, metric = 10.30% * 100;
 Minibatch[1901-2000]: loss = 0.634993 * 100, metric = 10.47% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.621246 * 2000, metric = 10.31% * 2000 914.977s (  2.2 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 18.18% * 2000;
 Minibatch[   1- 100]: loss = 0.621977 * 100, metric = 10.59% * 100;
 Minibatch[ 101- 200]: loss = 0.619719 * 100, metric = 10.33% * 100;
 Minibatch[ 201- 300]: loss = 0.608841 * 100, metric = 10.15% * 100;
 Minibatch[ 301- 400]: loss = 0.629498 * 100, metric = 10.45% * 100;
 Minibatch[ 401- 500]: loss = 0.616493 * 100, metric = 10.71% * 100;
 Minibatch[ 501- 600]: loss = 0.634815 * 100, metric = 10.97% * 100;
 Minibatch[ 601- 700]: loss = 0.598141 * 100, metric = 9.66% * 100;
 Minibatch[ 701- 800]: loss = 0.603640 * 100, metric = 9.71% * 100;
 Minibatch[ 801- 900]: loss = 0.617339 * 100, metric = 10.14% * 100;
 Minibatch[ 901-1000]: loss = 0.626779 * 100, metric = 10.35% * 100;
 Minibatch[1001-1100]: loss = 0.629397 * 100, metric = 10.32% * 100;
 Minibatch[1101-1200]: loss = 0.611616 * 100, metric = 10.05% * 100;
 Minibatch[1201-1300]: loss = 0.618353 * 100, metric = 10.17% * 100;
 Minibatch[1301-1400]: loss = 0.616885 * 100, metric = 10.32% * 100;
 Minibatch[1401-1500]: loss = 0.608547 * 100, metric = 9.99% * 100;
 Minibatch[1501-1600]: loss = 0.608280 * 100, metric = 9.78% * 100;
 Minibatch[1601-1700]: loss = 0.598011 * 100, metric = 9.99% * 100;
 Minibatch[1701-1800]: loss = 0.606536 * 100, metric = 9.64% * 100;
 Minibatch[1801-1900]: loss = 0.599385 * 100, metric = 9.63% * 100;
 Minibatch[1901-2000]: loss = 0.615358 * 100, metric = 10.22% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.614480 * 2000, metric = 10.16% * 2000 893.087s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 19.27% * 2000;
 Minibatch[   1- 100]: loss = 0.606106 * 100, metric = 10.03% * 100;
 Minibatch[ 101- 200]: loss = 0.596302 * 100, metric = 9.38% * 100;
 Minibatch[ 201- 300]: loss = 0.612797 * 100, metric = 10.04% * 100;
 Minibatch[ 301- 400]: loss = 0.602163 * 100, metric = 9.99% * 100;
 Minibatch[ 401- 500]: loss = 0.595492 * 100, metric = 9.89% * 100;
 Minibatch[ 501- 600]: loss = 0.601656 * 100, metric = 9.79% * 100;
 Minibatch[ 601- 700]: loss = 0.594825 * 100, metric = 9.69% * 100;
 Minibatch[ 701- 800]: loss = 0.614583 * 100, metric = 10.36% * 100;
 Minibatch[ 801- 900]: loss = 0.613462 * 100, metric = 10.15% * 100;
 Minibatch[ 901-1000]: loss = 0.611154 * 100, metric = 10.27% * 100;
 Minibatch[1001-1100]: loss = 0.601877 * 100, metric = 9.82% * 100;
 Minibatch[1101-1200]: loss = 0.594071 * 100, metric = 9.74% * 100;
 Minibatch[1201-1300]: loss = 0.583621 * 100, metric = 9.29% * 100;
 Minibatch[1301-1400]: loss = 0.599819 * 100, metric = 10.12% * 100;
 Minibatch[1401-1500]: loss = 0.601865 * 100, metric = 9.87% * 100;
 Minibatch[1501-1600]: loss = 0.581072 * 100, metric = 9.49% * 100;
 Minibatch[1601-1700]: loss = 0.597056 * 100, metric = 9.78% * 100;
 Minibatch[1701-1800]: loss = 0.598041 * 100, metric = 9.54% * 100;
 Minibatch[1801-1900]: loss = 0.598473 * 100, metric = 9.81% * 100;
 Minibatch[1901-2000]: loss = 0.605242 * 100, metric = 9.71% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.600484 * 2000, metric = 9.84% * 2000 899.501s (  2.2 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 17.99% * 2000;
 Minibatch[   1- 100]: loss = 0.599831 * 100, metric = 9.82% * 100;
 Minibatch[ 101- 200]: loss = 0.606519 * 100, metric = 10.17% * 100;
 Minibatch[ 201- 300]: loss = 0.596745 * 100, metric = 9.62% * 100;
 Minibatch[ 301- 400]: loss = 0.581022 * 100, metric = 9.42% * 100;
 Minibatch[ 401- 500]: loss = 0.587372 * 100, metric = 9.57% * 100;
 Minibatch[ 501- 600]: loss = 0.581856 * 100, metric = 9.31% * 100;
 Minibatch[ 601- 700]: loss = 0.572241 * 100, metric = 9.51% * 100;
 Minibatch[ 701- 800]: loss = 0.597848 * 100, metric = 9.95% * 100;
 Minibatch[ 801- 900]: loss = 0.602697 * 100, metric = 10.36% * 100;
 Minibatch[ 901-1000]: loss = 0.601477 * 100, metric = 9.82% * 100;
 Minibatch[1001-1100]: loss = 0.607893 * 100, metric = 9.87% * 100;
 Minibatch[1101-1200]: loss = 0.592350 * 100, metric = 9.73% * 100;
 Minibatch[1201-1300]: loss = 0.585556 * 100, metric = 9.29% * 100;
 Minibatch[1301-1400]: loss = 0.605151 * 100, metric = 10.30% * 100;
 Minibatch[1401-1500]: loss = 0.563154 * 100, metric = 9.04% * 100;
 Minibatch[1501-1600]: loss = 0.583240 * 100, metric = 9.58% * 100;
 Minibatch[1601-1700]: loss = 0.588221 * 100, metric = 9.49% * 100;
 Minibatch[1701-1800]: loss = 0.569739 * 100, metric = 8.99% * 100;
 Minibatch[1801-1900]: loss = 0.583878 * 100, metric = 9.57% * 100;
 Minibatch[1901-2000]: loss = 0.589291 * 100, metric = 9.85% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.589804 * 2000, metric = 9.66% * 2000 937.641s (  2.1 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 15.34% * 2000;
0.6592290144115687
 Minibatch[   1- 100]: loss = 0.601343 * 100, metric = 9.84% * 100;
 Minibatch[ 101- 200]: loss = 0.591721 * 100, metric = 9.53% * 100;
 Minibatch[ 201- 300]: loss = 0.589880 * 100, metric = 9.61% * 100;
 Minibatch[ 301- 400]: loss = 0.591526 * 100, metric = 9.59% * 100;
 Minibatch[ 401- 500]: loss = 0.572845 * 100, metric = 9.31% * 100;
 Minibatch[ 501- 600]: loss = 0.581093 * 100, metric = 9.53% * 100;
 Minibatch[ 601- 700]: loss = 0.579248 * 100, metric = 9.29% * 100;
 Minibatch[ 701- 800]: loss = 0.577477 * 100, metric = 9.44% * 100;
 Minibatch[ 801- 900]: loss = 0.579007 * 100, metric = 9.53% * 100;
 Minibatch[ 901-1000]: loss = 0.578028 * 100, metric = 9.64% * 100;
 Minibatch[1001-1100]: loss = 0.563733 * 100, metric = 9.26% * 100;
 Minibatch[1101-1200]: loss = 0.576040 * 100, metric = 9.17% * 100;
 Minibatch[1201-1300]: loss = 0.566478 * 100, metric = 9.07% * 100;
 Minibatch[1301-1400]: loss = 0.572884 * 100, metric = 9.50% * 100;
 Minibatch[1401-1500]: loss = 0.566263 * 100, metric = 9.46% * 100;
 Minibatch[1501-1600]: loss = 0.569680 * 100, metric = 9.45% * 100;
 Minibatch[1601-1700]: loss = 0.569904 * 100, metric = 9.39% * 100;
 Minibatch[1701-1800]: loss = 0.591647 * 100, metric = 9.54% * 100;
 Minibatch[1801-1900]: loss = 0.585602 * 100, metric = 9.55% * 100;
 Minibatch[1901-2000]: loss = 0.563099 * 100, metric = 9.21% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.578375 * 2000, metric = 9.44% * 2000 900.821s (  2.2 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 15.54% * 2000;
 Minibatch[   1- 100]: loss = 0.554162 * 100, metric = 9.08% * 100;
 Minibatch[ 101- 200]: loss = 0.584263 * 100, metric = 9.70% * 100;
 Minibatch[ 201- 300]: loss = 0.582306 * 100, metric = 9.50% * 100;
 Minibatch[ 301- 400]: loss = 0.571297 * 100, metric = 9.25% * 100;
 Minibatch[ 401- 500]: loss = 0.586314 * 100, metric = 9.50% * 100;
 Minibatch[ 501- 600]: loss = 0.570096 * 100, metric = 9.24% * 100;
 Minibatch[ 601- 700]: loss = 0.552216 * 100, metric = 8.73% * 100;
 Minibatch[ 701- 800]: loss = 0.566930 * 100, metric = 8.97% * 100;
 Minibatch[ 801- 900]: loss = 0.578412 * 100, metric = 9.69% * 100;
 Minibatch[ 901-1000]: loss = 0.568087 * 100, metric = 9.22% * 100;
 Minibatch[1001-1100]: loss = 0.559201 * 100, metric = 9.23% * 100;
 Minibatch[1101-1200]: loss = 0.579517 * 100, metric = 9.50% * 100;
 Minibatch[1201-1300]: loss = 0.583406 * 100, metric = 9.56% * 100;
 Minibatch[1301-1400]: loss = 0.564979 * 100, metric = 9.13% * 100;
 Minibatch[1401-1500]: loss = 0.572574 * 100, metric = 9.41% * 100;
 Minibatch[1501-1600]: loss = 0.572516 * 100, metric = 9.46% * 100;
 Minibatch[1601-1700]: loss = 0.575101 * 100, metric = 9.38% * 100;
 Minibatch[1701-1800]: loss = 0.553654 * 100, metric = 8.80% * 100;
 Minibatch[1801-1900]: loss = 0.582778 * 100, metric = 9.61% * 100;
 Minibatch[1901-2000]: loss = 0.585728 * 100, metric = 9.80% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.572177 * 2000, metric = 9.34% * 2000 864.873s (  2.3 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 15.50% * 2000;
 Minibatch[   1- 100]: loss = 0.557332 * 100, metric = 9.03% * 100;
 Minibatch[ 101- 200]: loss = 0.580335 * 100, metric = 9.46% * 100;
 Minibatch[ 201- 300]: loss = 0.553284 * 100, metric = 9.01% * 100;
 Minibatch[ 301- 400]: loss = 0.567926 * 100, metric = 9.15% * 100;
 Minibatch[ 401- 500]: loss = 0.548353 * 100, metric = 8.79% * 100;
 Minibatch[ 501- 600]: loss = 0.555993 * 100, metric = 9.02% * 100;
 Minibatch[ 601- 700]: loss = 0.561918 * 100, metric = 9.15% * 100;
 Minibatch[ 701- 800]: loss = 0.550183 * 100, metric = 8.94% * 100;
 Minibatch[ 801- 900]: loss = 0.573614 * 100, metric = 9.14% * 100;
 Minibatch[ 901-1000]: loss = 0.569856 * 100, metric = 9.12% * 100;
 Minibatch[1001-1100]: loss = 0.571616 * 100, metric = 9.52% * 100;
 Minibatch[1101-1200]: loss = 0.568776 * 100, metric = 9.21% * 100;
 Minibatch[1201-1300]: loss = 0.576257 * 100, metric = 9.69% * 100;
 Minibatch[1301-1400]: loss = 0.578956 * 100, metric = 9.29% * 100;
 Minibatch[1401-1500]: loss = 0.550090 * 100, metric = 8.64% * 100;
 Minibatch[1501-1600]: loss = 0.566362 * 100, metric = 9.19% * 100;
 Minibatch[1601-1700]: loss = 0.536618 * 100, metric = 8.47% * 100;
 Minibatch[1701-1800]: loss = 0.557734 * 100, metric = 8.87% * 100;
 Minibatch[1801-1900]: loss = 0.537216 * 100, metric = 8.59% * 100;
 Minibatch[1901-2000]: loss = 0.546677 * 100, metric = 8.70% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.560455 * 2000, metric = 9.05% * 2000 891.321s (  2.2 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 17.00% * 2000;
 Minibatch[   1- 100]: loss = 0.561721 * 100, metric = 9.17% * 100;
 Minibatch[ 101- 200]: loss = 0.564994 * 100, metric = 8.83% * 100;
 Minibatch[ 201- 300]: loss = 0.547607 * 100, metric = 8.39% * 100;
 Minibatch[ 301- 400]: loss = 0.564447 * 100, metric = 9.04% * 100;
 Minibatch[ 401- 500]: loss = 0.562530 * 100, metric = 8.94% * 100;
 Minibatch[ 501- 600]: loss = 0.546376 * 100, metric = 8.49% * 100;
 Minibatch[ 601- 700]: loss = 0.562740 * 100, metric = 9.10% * 100;
 Minibatch[ 701- 800]: loss = 0.547151 * 100, metric = 8.74% * 100;
 Minibatch[ 801- 900]: loss = 0.580795 * 100, metric = 9.67% * 100;
 Minibatch[ 901-1000]: loss = 0.548766 * 100, metric = 8.77% * 100;
 Minibatch[1001-1100]: loss = 0.572490 * 100, metric = 9.27% * 100;
 Minibatch[1101-1200]: loss = 0.552349 * 100, metric = 8.95% * 100;
 Minibatch[1201-1300]: loss = 0.560326 * 100, metric = 9.06% * 100;
 Minibatch[1301-1400]: loss = 0.549026 * 100, metric = 8.71% * 100;
 Minibatch[1401-1500]: loss = 0.558863 * 100, metric = 9.09% * 100;
 Minibatch[1501-1600]: loss = 0.569745 * 100, metric = 9.47% * 100;
 Minibatch[1601-1700]: loss = 0.544803 * 100, metric = 8.84% * 100;
 Minibatch[1701-1800]: loss = 0.534601 * 100, metric = 8.36% * 100;
 Minibatch[1801-1900]: loss = 0.545470 * 100, metric = 8.56% * 100;
 Minibatch[1901-2000]: loss = 0.538463 * 100, metric = 8.64% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.555663 * 2000, metric = 8.90% * 2000 887.576s (  2.3 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 16.56% * 2000;
 Minibatch[   1- 100]: loss = 0.545342 * 100, metric = 8.65% * 100;
 Minibatch[ 101- 200]: loss = 0.540357 * 100, metric = 8.44% * 100;
 Minibatch[ 201- 300]: loss = 0.540102 * 100, metric = 8.50% * 100;
 Minibatch[ 301- 400]: loss = 0.564477 * 100, metric = 8.81% * 100;
 Minibatch[ 401- 500]: loss = 0.546962 * 100, metric = 8.88% * 100;
 Minibatch[ 501- 600]: loss = 0.551960 * 100, metric = 8.79% * 100;
 Minibatch[ 601- 700]: loss = 0.557754 * 100, metric = 9.08% * 100;
 Minibatch[ 701- 800]: loss = 0.558841 * 100, metric = 9.13% * 100;
 Minibatch[ 801- 900]: loss = 0.558374 * 100, metric = 9.04% * 100;
 Minibatch[ 901-1000]: loss = 0.560295 * 100, metric = 9.20% * 100;
 Minibatch[1001-1100]: loss = 0.525768 * 100, metric = 8.24% * 100;
 Minibatch[1101-1200]: loss = 0.548762 * 100, metric = 8.85% * 100;
 Minibatch[1201-1300]: loss = 0.552079 * 100, metric = 8.85% * 100;
 Minibatch[1301-1400]: loss = 0.555282 * 100, metric = 9.22% * 100;
 Minibatch[1401-1500]: loss = 0.535774 * 100, metric = 8.72% * 100;
 Minibatch[1501-1600]: loss = 0.572712 * 100, metric = 9.37% * 100;
 Minibatch[1601-1700]: loss = 0.544288 * 100, metric = 8.78% * 100;
 Minibatch[1701-1800]: loss = 0.551637 * 100, metric = 8.97% * 100;
 Minibatch[1801-1900]: loss = 0.543167 * 100, metric = 8.61% * 100;
 Minibatch[1901-2000]: loss = 0.545657 * 100, metric = 8.82% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.549979 * 2000, metric = 8.85% * 2000 882.913s (  2.3 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 16.08% * 2000;
 Minibatch[   1- 100]: loss = 0.548529 * 100, metric = 8.89% * 100;
 Minibatch[ 101- 200]: loss = 0.539899 * 100, metric = 8.71% * 100;
 Minibatch[ 201- 300]: loss = 0.541766 * 100, metric = 8.68% * 100;
 Minibatch[ 301- 400]: loss = 0.554103 * 100, metric = 9.10% * 100;
 Minibatch[ 401- 500]: loss = 0.534613 * 100, metric = 8.50% * 100;
 Minibatch[ 501- 600]: loss = 0.533496 * 100, metric = 8.29% * 100;
 Minibatch[ 601- 700]: loss = 0.527561 * 100, metric = 8.38% * 100;
 Minibatch[ 701- 800]: loss = 0.503285 * 100, metric = 7.81% * 100;
 Minibatch[ 801- 900]: loss = 0.542550 * 100, metric = 8.47% * 100;
 Minibatch[ 901-1000]: loss = 0.519217 * 100, metric = 8.28% * 100;
 Minibatch[1001-1100]: loss = 0.530715 * 100, metric = 8.37% * 100;
 Minibatch[1101-1200]: loss = 0.521413 * 100, metric = 8.24% * 100;
 Minibatch[1201-1300]: loss = 0.528014 * 100, metric = 8.36% * 100;
 Minibatch[1301-1400]: loss = 0.520723 * 100, metric = 8.07% * 100;
 Minibatch[1401-1500]: loss = 0.535175 * 100, metric = 8.47% * 100;
 Minibatch[1501-1600]: loss = 0.538984 * 100, metric = 9.01% * 100;
 Minibatch[1601-1700]: loss = 0.521975 * 100, metric = 8.33% * 100;
 Minibatch[1701-1800]: loss = 0.523793 * 100, metric = 8.17% * 100;
 Minibatch[1801-1900]: loss = 0.539233 * 100, metric = 8.65% * 100;
 Minibatch[1901-2000]: loss = 0.505832 * 100, metric = 8.05% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.530544 * 2000, metric = 8.44% * 2000 866.833s (  2.3 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 15.05% * 2000;
0.6442223505601287
 Minibatch[   1- 100]: loss = 0.536708 * 100, metric = 8.74% * 100;
 Minibatch[ 101- 200]: loss = 0.531201 * 100, metric = 8.54% * 100;
 Minibatch[ 201- 300]: loss = 0.532014 * 100, metric = 8.58% * 100;
 Minibatch[ 301- 400]: loss = 0.523468 * 100, metric = 8.44% * 100;
 Minibatch[ 401- 500]: loss = 0.517877 * 100, metric = 8.16% * 100;
 Minibatch[ 501- 600]: loss = 0.534425 * 100, metric = 8.57% * 100;
 Minibatch[ 601- 700]: loss = 0.526006 * 100, metric = 8.29% * 100;
 Minibatch[ 701- 800]: loss = 0.524181 * 100, metric = 8.25% * 100;
 Minibatch[ 801- 900]: loss = 0.539189 * 100, metric = 8.59% * 100;
 Minibatch[ 901-1000]: loss = 0.541112 * 100, metric = 8.83% * 100;
 Minibatch[1001-1100]: loss = 0.512934 * 100, metric = 8.10% * 100;
 Minibatch[1101-1200]: loss = 0.501479 * 100, metric = 7.62% * 100;
 Minibatch[1201-1300]: loss = 0.523121 * 100, metric = 8.20% * 100;
 Minibatch[1301-1400]: loss = 0.527576 * 100, metric = 8.45% * 100;
 Minibatch[1401-1500]: loss = 0.519964 * 100, metric = 8.26% * 100;
 Minibatch[1501-1600]: loss = 0.516771 * 100, metric = 8.13% * 100;
 Minibatch[1601-1700]: loss = 0.523242 * 100, metric = 8.36% * 100;
 Minibatch[1701-1800]: loss = 0.515924 * 100, metric = 7.84% * 100;
 Minibatch[1801-1900]: loss = 0.520754 * 100, metric = 8.28% * 100;
 Minibatch[1901-2000]: loss = 0.519705 * 100, metric = 8.07% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.524382 * 2000, metric = 8.32% * 2000 870.837s (  2.3 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 16.18% * 2000;
 Minibatch[   1- 100]: loss = 0.530648 * 100, metric = 8.36% * 100;
 Minibatch[ 101- 200]: loss = 0.537469 * 100, metric = 8.66% * 100;
 Minibatch[ 201- 300]: loss = 0.524954 * 100, metric = 8.06% * 100;
 Minibatch[ 301- 400]: loss = 0.532737 * 100, metric = 8.40% * 100;
 Minibatch[ 401- 500]: loss = 0.538428 * 100, metric = 8.65% * 100;
 Minibatch[ 501- 600]: loss = 0.519854 * 100, metric = 8.06% * 100;
 Minibatch[ 601- 700]: loss = 0.516854 * 100, metric = 7.98% * 100;
 Minibatch[ 701- 800]: loss = 0.509239 * 100, metric = 7.97% * 100;
 Minibatch[ 801- 900]: loss = 0.500744 * 100, metric = 7.91% * 100;
 Minibatch[ 901-1000]: loss = 0.527059 * 100, metric = 8.46% * 100;
 Minibatch[1001-1100]: loss = 0.520613 * 100, metric = 7.99% * 100;
 Minibatch[1101-1200]: loss = 0.522816 * 100, metric = 8.34% * 100;
 Minibatch[1201-1300]: loss = 0.531190 * 100, metric = 8.51% * 100;
 Minibatch[1301-1400]: loss = 0.534585 * 100, metric = 8.51% * 100;
 Minibatch[1401-1500]: loss = 0.511744 * 100, metric = 8.12% * 100;
 Minibatch[1501-1600]: loss = 0.525431 * 100, metric = 8.36% * 100;
 Minibatch[1601-1700]: loss = 0.515870 * 100, metric = 8.18% * 100;
 Minibatch[1701-1800]: loss = 0.524067 * 100, metric = 8.45% * 100;
 Minibatch[1801-1900]: loss = 0.521664 * 100, metric = 8.51% * 100;
 Minibatch[1901-2000]: loss = 0.525552 * 100, metric = 8.36% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.523576 * 2000, metric = 8.29% * 2000 869.551s (  2.3 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 17.16% * 2000;
 Minibatch[   1- 100]: loss = 0.506416 * 100, metric = 8.08% * 100;
 Minibatch[ 101- 200]: loss = 0.533256 * 100, metric = 8.65% * 100;
 Minibatch[ 201- 300]: loss = 0.516166 * 100, metric = 8.16% * 100;
 Minibatch[ 301- 400]: loss = 0.523189 * 100, metric = 8.32% * 100;
 Minibatch[ 401- 500]: loss = 0.521166 * 100, metric = 8.34% * 100;
 Minibatch[ 501- 600]: loss = 0.510141 * 100, metric = 8.01% * 100;
 Minibatch[ 601- 700]: loss = 0.530958 * 100, metric = 8.28% * 100;
 Minibatch[ 701- 800]: loss = 0.518502 * 100, metric = 8.26% * 100;
 Minibatch[ 801- 900]: loss = 0.531315 * 100, metric = 8.54% * 100;
 Minibatch[ 901-1000]: loss = 0.520133 * 100, metric = 8.13% * 100;
 Minibatch[1001-1100]: loss = 0.523851 * 100, metric = 8.38% * 100;
 Minibatch[1101-1200]: loss = 0.536473 * 100, metric = 8.60% * 100;
 Minibatch[1201-1300]: loss = 0.527720 * 100, metric = 8.56% * 100;
 Minibatch[1301-1400]: loss = 0.512261 * 100, metric = 7.91% * 100;
 Minibatch[1401-1500]: loss = 0.513918 * 100, metric = 8.02% * 100;
 Minibatch[1501-1600]: loss = 0.528202 * 100, metric = 8.28% * 100;
 Minibatch[1601-1700]: loss = 0.507358 * 100, metric = 7.77% * 100;
 Minibatch[1701-1800]: loss = 0.499795 * 100, metric = 7.77% * 100;
 Minibatch[1801-1900]: loss = 0.524804 * 100, metric = 8.32% * 100;
 Minibatch[1901-2000]: loss = 0.537709 * 100, metric = 8.73% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.521167 * 2000, metric = 8.26% * 2000 871.050s (  2.3 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 15.04% * 2000;
 Minibatch[   1- 100]: loss = 0.523005 * 100, metric = 8.24% * 100;
 Minibatch[ 101- 200]: loss = 0.524140 * 100, metric = 8.47% * 100;
 Minibatch[ 201- 300]: loss = 0.531041 * 100, metric = 8.52% * 100;
 Minibatch[ 301- 400]: loss = 0.523985 * 100, metric = 8.33% * 100;
 Minibatch[ 401- 500]: loss = 0.522360 * 100, metric = 8.23% * 100;
 Minibatch[ 501- 600]: loss = 0.514054 * 100, metric = 8.16% * 100;
 Minibatch[ 601- 700]: loss = 0.522551 * 100, metric = 8.10% * 100;
 Minibatch[ 701- 800]: loss = 0.500695 * 100, metric = 7.55% * 100;
 Minibatch[ 801- 900]: loss = 0.512589 * 100, metric = 8.11% * 100;
 Minibatch[ 901-1000]: loss = 0.513389 * 100, metric = 8.19% * 100;
 Minibatch[1001-1100]: loss = 0.517996 * 100, metric = 8.25% * 100;
 Minibatch[1101-1200]: loss = 0.521085 * 100, metric = 8.32% * 100;
 Minibatch[1201-1300]: loss = 0.536564 * 100, metric = 8.71% * 100;
 Minibatch[1301-1400]: loss = 0.510073 * 100, metric = 8.04% * 100;
 Minibatch[1401-1500]: loss = 0.507759 * 100, metric = 7.90% * 100;
 Minibatch[1501-1600]: loss = 0.526024 * 100, metric = 8.45% * 100;
 Minibatch[1601-1700]: loss = 0.508334 * 100, metric = 8.12% * 100;
 Minibatch[1701-1800]: loss = 0.514331 * 100, metric = 8.18% * 100;
 Minibatch[1801-1900]: loss = 0.509464 * 100, metric = 7.88% * 100;
 Minibatch[1901-2000]: loss = 0.501097 * 100, metric = 7.79% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.517027 * 2000, metric = 8.18% * 2000 868.168s (  2.3 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 15.08% * 2000;
 Minibatch[   1- 100]: loss = 0.512697 * 100, metric = 8.21% * 100;
 Minibatch[ 101- 200]: loss = 0.494229 * 100, metric = 7.78% * 100;
 Minibatch[ 201- 300]: loss = 0.500446 * 100, metric = 7.93% * 100;
 Minibatch[ 301- 400]: loss = 0.500036 * 100, metric = 7.76% * 100;
 Minibatch[ 401- 500]: loss = 0.502117 * 100, metric = 8.00% * 100;
 Minibatch[ 501- 600]: loss = 0.501840 * 100, metric = 7.66% * 100;
 Minibatch[ 601- 700]: loss = 0.520207 * 100, metric = 8.45% * 100;
 Minibatch[ 701- 800]: loss = 0.496188 * 100, metric = 7.90% * 100;
 Minibatch[ 801- 900]: loss = 0.495319 * 100, metric = 7.67% * 100;
 Minibatch[ 901-1000]: loss = 0.490981 * 100, metric = 7.71% * 100;
 Minibatch[1001-1100]: loss = 0.514262 * 100, metric = 8.44% * 100;
 Minibatch[1101-1200]: loss = 0.515488 * 100, metric = 8.07% * 100;
 Minibatch[1201-1300]: loss = 0.499034 * 100, metric = 7.84% * 100;
 Minibatch[1301-1400]: loss = 0.488719 * 100, metric = 7.48% * 100;
 Minibatch[1401-1500]: loss = 0.504548 * 100, metric = 7.92% * 100;
 Minibatch[1501-1600]: loss = 0.495696 * 100, metric = 7.41% * 100;
 Minibatch[1601-1700]: loss = 0.511871 * 100, metric = 8.07% * 100;
 Minibatch[1701-1800]: loss = 0.508547 * 100, metric = 8.03% * 100;
 Minibatch[1801-1900]: loss = 0.496905 * 100, metric = 7.67% * 100;
 Minibatch[1901-2000]: loss = 0.494261 * 100, metric = 7.70% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.502170 * 2000, metric = 7.89% * 2000 866.396s (  2.3 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.93% * 2000;
 Minibatch[   1- 100]: loss = 0.498884 * 100, metric = 7.79% * 100;
 Minibatch[ 101- 200]: loss = 0.511846 * 100, metric = 8.15% * 100;
 Minibatch[ 201- 300]: loss = 0.496836 * 100, metric = 7.91% * 100;
 Minibatch[ 301- 400]: loss = 0.490855 * 100, metric = 7.69% * 100;
 Minibatch[ 401- 500]: loss = 0.490237 * 100, metric = 7.55% * 100;
 Minibatch[ 501- 600]: loss = 0.482143 * 100, metric = 7.29% * 100;
 Minibatch[ 601- 700]: loss = 0.487015 * 100, metric = 7.55% * 100;
 Minibatch[ 701- 800]: loss = 0.500462 * 100, metric = 7.87% * 100;
 Minibatch[ 801- 900]: loss = 0.506592 * 100, metric = 7.90% * 100;
 Minibatch[ 901-1000]: loss = 0.496866 * 100, metric = 7.94% * 100;
 Minibatch[1001-1100]: loss = 0.486547 * 100, metric = 7.58% * 100;
 Minibatch[1101-1200]: loss = 0.513039 * 100, metric = 8.18% * 100;
 Minibatch[1201-1300]: loss = 0.491289 * 100, metric = 7.52% * 100;
 Minibatch[1301-1400]: loss = 0.518544 * 100, metric = 8.24% * 100;
 Minibatch[1401-1500]: loss = 0.492052 * 100, metric = 7.73% * 100;
 Minibatch[1501-1600]: loss = 0.500820 * 100, metric = 7.85% * 100;
 Minibatch[1601-1700]: loss = 0.477257 * 100, metric = 7.31% * 100;
 Minibatch[1701-1800]: loss = 0.495892 * 100, metric = 7.57% * 100;
 Minibatch[1801-1900]: loss = 0.499073 * 100, metric = 7.88% * 100;
 Minibatch[1901-2000]: loss = 0.494753 * 100, metric = 7.59% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.496550 * 2000, metric = 7.75% * 2000 865.043s (  2.3 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 14.22% * 2000;
0.6398978671729565
 Minibatch[   1- 100]: loss = 0.508172 * 100, metric = 8.04% * 100;
 Minibatch[ 101- 200]: loss = 0.487200 * 100, metric = 7.51% * 100;
 Minibatch[ 201- 300]: loss = 0.498989 * 100, metric = 7.75% * 100;
 Minibatch[ 301- 400]: loss = 0.496353 * 100, metric = 7.74% * 100;
 Minibatch[ 401- 500]: loss = 0.493919 * 100, metric = 7.86% * 100;
 Minibatch[ 501- 600]: loss = 0.512230 * 100, metric = 8.27% * 100;
 Minibatch[ 601- 700]: loss = 0.482160 * 100, metric = 7.24% * 100;
 Minibatch[ 701- 800]: loss = 0.483139 * 100, metric = 7.32% * 100;
 Minibatch[ 801- 900]: loss = 0.505130 * 100, metric = 7.97% * 100;
 Minibatch[ 901-1000]: loss = 0.506398 * 100, metric = 7.96% * 100;
 Minibatch[1001-1100]: loss = 0.497558 * 100, metric = 7.88% * 100;
 Minibatch[1101-1200]: loss = 0.499424 * 100, metric = 7.77% * 100;
 Minibatch[1201-1300]: loss = 0.496491 * 100, metric = 7.73% * 100;
 Minibatch[1301-1400]: loss = 0.487838 * 100, metric = 7.63% * 100;
 Minibatch[1401-1500]: loss = 0.510062 * 100, metric = 7.95% * 100;
 Minibatch[1501-1600]: loss = 0.485955 * 100, metric = 7.40% * 100;
 Minibatch[1601-1700]: loss = 0.492770 * 100, metric = 7.54% * 100;
 Minibatch[1701-1800]: loss = 0.478716 * 100, metric = 7.44% * 100;
 Minibatch[1801-1900]: loss = 0.486473 * 100, metric = 7.63% * 100;
 Minibatch[1901-2000]: loss = 0.489212 * 100, metric = 7.49% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.494910 * 2000, metric = 7.71% * 2000 872.763s (  2.3 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.78% * 2000;
0.6271902530193328
 Minibatch[   1- 100]: loss = 0.477526 * 100, metric = 7.22% * 100;
 Minibatch[ 101- 200]: loss = 0.487545 * 100, metric = 7.71% * 100;
 Minibatch[ 201- 300]: loss = 0.493321 * 100, metric = 7.62% * 100;
 Minibatch[ 301- 400]: loss = 0.509421 * 100, metric = 8.00% * 100;
 Minibatch[ 401- 500]: loss = 0.477409 * 100, metric = 7.16% * 100;
 Minibatch[ 501- 600]: loss = 0.493003 * 100, metric = 7.72% * 100;
 Minibatch[ 601- 700]: loss = 0.482687 * 100, metric = 7.54% * 100;
 Minibatch[ 701- 800]: loss = 0.492534 * 100, metric = 7.75% * 100;
 Minibatch[ 801- 900]: loss = 0.483225 * 100, metric = 7.59% * 100;
 Minibatch[ 901-1000]: loss = 0.491939 * 100, metric = 7.65% * 100;
 Minibatch[1001-1100]: loss = 0.481560 * 100, metric = 7.57% * 100;
 Minibatch[1101-1200]: loss = 0.471013 * 100, metric = 7.22% * 100;
 Minibatch[1201-1300]: loss = 0.489323 * 100, metric = 7.51% * 100;
 Minibatch[1301-1400]: loss = 0.470803 * 100, metric = 7.19% * 100;
 Minibatch[1401-1500]: loss = 0.496141 * 100, metric = 7.84% * 100;
 Minibatch[1501-1600]: loss = 0.468246 * 100, metric = 7.22% * 100;
 Minibatch[1601-1700]: loss = 0.490887 * 100, metric = 7.89% * 100;
 Minibatch[1701-1800]: loss = 0.471436 * 100, metric = 7.28% * 100;
 Minibatch[1801-1900]: loss = 0.495357 * 100, metric = 7.62% * 100;
 Minibatch[1901-2000]: loss = 0.483229 * 100, metric = 7.59% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.485330 * 2000, metric = 7.54% * 2000 869.870s (  2.3 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 15.91% * 2000;
 Minibatch[   1- 100]: loss = 0.491932 * 100, metric = 7.66% * 100;
 Minibatch[ 101- 200]: loss = 0.464233 * 100, metric = 7.08% * 100;
 Minibatch[ 201- 300]: loss = 0.468633 * 100, metric = 7.31% * 100;
 Minibatch[ 301- 400]: loss = 0.496819 * 100, metric = 7.97% * 100;
 Minibatch[ 401- 500]: loss = 0.484057 * 100, metric = 7.56% * 100;
 Minibatch[ 501- 600]: loss = 0.460120 * 100, metric = 6.93% * 100;
 Minibatch[ 601- 700]: loss = 0.484949 * 100, metric = 7.63% * 100;
 Minibatch[ 701- 800]: loss = 0.479984 * 100, metric = 7.54% * 100;
 Minibatch[ 801- 900]: loss = 0.493452 * 100, metric = 7.63% * 100;
 Minibatch[ 901-1000]: loss = 0.460417 * 100, metric = 6.95% * 100;
 Minibatch[1001-1100]: loss = 0.491278 * 100, metric = 7.50% * 100;
 Minibatch[1101-1200]: loss = 0.495275 * 100, metric = 7.96% * 100;
 Minibatch[1201-1300]: loss = 0.470340 * 100, metric = 7.25% * 100;
 Minibatch[1301-1400]: loss = 0.477496 * 100, metric = 7.42% * 100;
 Minibatch[1401-1500]: loss = 0.474379 * 100, metric = 7.52% * 100;
 Minibatch[1501-1600]: loss = 0.488727 * 100, metric = 7.65% * 100;
 Minibatch[1601-1700]: loss = 0.484446 * 100, metric = 7.52% * 100;
 Minibatch[1701-1800]: loss = 0.486992 * 100, metric = 7.60% * 100;
 Minibatch[1801-1900]: loss = 0.481662 * 100, metric = 7.67% * 100;
 Minibatch[1901-2000]: loss = 0.501091 * 100, metric = 7.98% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.481814 * 2000, metric = 7.52% * 2000 873.239s (  2.3 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.83% * 2000;
 Minibatch[   1- 100]: loss = 0.480297 * 100, metric = 7.30% * 100;
 Minibatch[ 101- 200]: loss = 0.494679 * 100, metric = 8.01% * 100;
 Minibatch[ 201- 300]: loss = 0.476002 * 100, metric = 7.34% * 100;
 Minibatch[ 301- 400]: loss = 0.471998 * 100, metric = 7.35% * 100;
 Minibatch[ 401- 500]: loss = 0.480795 * 100, metric = 7.47% * 100;
 Minibatch[ 501- 600]: loss = 0.477702 * 100, metric = 7.36% * 100;
 Minibatch[ 601- 700]: loss = 0.488362 * 100, metric = 7.90% * 100;
 Minibatch[ 701- 800]: loss = 0.482146 * 100, metric = 7.51% * 100;
 Minibatch[ 801- 900]: loss = 0.479997 * 100, metric = 7.49% * 100;
 Minibatch[ 901-1000]: loss = 0.468592 * 100, metric = 7.27% * 100;
 Minibatch[1001-1100]: loss = 0.475866 * 100, metric = 7.19% * 100;
 Minibatch[1101-1200]: loss = 0.477798 * 100, metric = 7.51% * 100;
 Minibatch[1201-1300]: loss = 0.475931 * 100, metric = 7.44% * 100;
 Minibatch[1301-1400]: loss = 0.474069 * 100, metric = 7.52% * 100;
 Minibatch[1401-1500]: loss = 0.480965 * 100, metric = 7.43% * 100;
 Minibatch[1501-1600]: loss = 0.461603 * 100, metric = 7.28% * 100;
 Minibatch[1601-1700]: loss = 0.479244 * 100, metric = 7.42% * 100;
 Minibatch[1701-1800]: loss = 0.469261 * 100, metric = 7.46% * 100;
 Minibatch[1801-1900]: loss = 0.486942 * 100, metric = 7.86% * 100;
 Minibatch[1901-2000]: loss = 0.471080 * 100, metric = 7.29% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.477667 * 2000, metric = 7.47% * 2000 864.197s (  2.3 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 14.32% * 2000;
 Minibatch[   1- 100]: loss = 0.477823 * 100, metric = 7.44% * 100;
 Minibatch[ 101- 200]: loss = 0.486281 * 100, metric = 7.76% * 100;
 Minibatch[ 201- 300]: loss = 0.487617 * 100, metric = 7.86% * 100;
 Minibatch[ 301- 400]: loss = 0.494584 * 100, metric = 7.46% * 100;
 Minibatch[ 401- 500]: loss = 0.479806 * 100, metric = 7.56% * 100;
 Minibatch[ 501- 600]: loss = 0.484933 * 100, metric = 7.74% * 100;
 Minibatch[ 601- 700]: loss = 0.471566 * 100, metric = 7.24% * 100;
 Minibatch[ 701- 800]: loss = 0.466101 * 100, metric = 7.03% * 100;
 Minibatch[ 801- 900]: loss = 0.466027 * 100, metric = 7.30% * 100;
 Minibatch[ 901-1000]: loss = 0.458480 * 100, metric = 7.06% * 100;
 Minibatch[1001-1100]: loss = 0.462194 * 100, metric = 6.98% * 100;
 Minibatch[1101-1200]: loss = 0.477845 * 100, metric = 7.38% * 100;
 Minibatch[1201-1300]: loss = 0.479474 * 100, metric = 7.62% * 100;
 Minibatch[1301-1400]: loss = 0.467582 * 100, metric = 7.22% * 100;
 Minibatch[1401-1500]: loss = 0.464257 * 100, metric = 7.28% * 100;
 Minibatch[1501-1600]: loss = 0.477178 * 100, metric = 7.45% * 100;
 Minibatch[1601-1700]: loss = 0.461815 * 100, metric = 7.13% * 100;
 Minibatch[1701-1800]: loss = 0.497081 * 100, metric = 7.95% * 100;
 Minibatch[1801-1900]: loss = 0.466611 * 100, metric = 7.14% * 100;
 Minibatch[1901-2000]: loss = 0.483977 * 100, metric = 7.80% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.475562 * 2000, metric = 7.42% * 2000 870.340s (  2.3 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 14.85% * 2000;
 Minibatch[   1- 100]: loss = 0.489972 * 100, metric = 7.78% * 100;
 Minibatch[ 101- 200]: loss = 0.475523 * 100, metric = 7.49% * 100;
 Minibatch[ 201- 300]: loss = 0.466557 * 100, metric = 7.25% * 100;
 Minibatch[ 301- 400]: loss = 0.479240 * 100, metric = 7.76% * 100;
 Minibatch[ 401- 500]: loss = 0.470161 * 100, metric = 7.41% * 100;
 Minibatch[ 501- 600]: loss = 0.476794 * 100, metric = 7.43% * 100;
 Minibatch[ 601- 700]: loss = 0.476906 * 100, metric = 7.54% * 100;
 Minibatch[ 701- 800]: loss = 0.468236 * 100, metric = 7.24% * 100;
 Minibatch[ 801- 900]: loss = 0.475229 * 100, metric = 7.41% * 100;
 Minibatch[ 901-1000]: loss = 0.455329 * 100, metric = 7.21% * 100;
 Minibatch[1001-1100]: loss = 0.465007 * 100, metric = 7.30% * 100;
 Minibatch[1101-1200]: loss = 0.456256 * 100, metric = 7.18% * 100;
 Minibatch[1201-1300]: loss = 0.479907 * 100, metric = 7.49% * 100;
 Minibatch[1301-1400]: loss = 0.461508 * 100, metric = 7.04% * 100;
 Minibatch[1401-1500]: loss = 0.480287 * 100, metric = 7.60% * 100;
 Minibatch[1501-1600]: loss = 0.482278 * 100, metric = 7.62% * 100;
 Minibatch[1601-1700]: loss = 0.464661 * 100, metric = 7.15% * 100;
 Minibatch[1701-1800]: loss = 0.470240 * 100, metric = 7.39% * 100;
 Minibatch[1801-1900]: loss = 0.465757 * 100, metric = 7.07% * 100;
 Minibatch[1901-2000]: loss = 0.485348 * 100, metric = 7.74% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.472260 * 2000, metric = 7.41% * 2000 860.376s (  2.3 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 14.00% * 2000;
 Minibatch[   1- 100]: loss = 0.467501 * 100, metric = 7.12% * 100;
 Minibatch[ 101- 200]: loss = 0.480252 * 100, metric = 7.38% * 100;
 Minibatch[ 201- 300]: loss = 0.458728 * 100, metric = 7.14% * 100;
 Minibatch[ 301- 400]: loss = 0.472975 * 100, metric = 7.24% * 100;
 Minibatch[ 401- 500]: loss = 0.459002 * 100, metric = 7.31% * 100;
 Minibatch[ 501- 600]: loss = 0.466510 * 100, metric = 7.20% * 100;
 Minibatch[ 601- 700]: loss = 0.480081 * 100, metric = 7.47% * 100;
 Minibatch[ 701- 800]: loss = 0.465723 * 100, metric = 7.27% * 100;
 Minibatch[ 801- 900]: loss = 0.450218 * 100, metric = 6.68% * 100;
 Minibatch[ 901-1000]: loss = 0.460391 * 100, metric = 7.34% * 100;
 Minibatch[1001-1100]: loss = 0.463017 * 100, metric = 7.49% * 100;
 Minibatch[1101-1200]: loss = 0.461930 * 100, metric = 7.19% * 100;
 Minibatch[1201-1300]: loss = 0.460682 * 100, metric = 7.05% * 100;
 Minibatch[1301-1400]: loss = 0.456133 * 100, metric = 7.14% * 100;
 Minibatch[1401-1500]: loss = 0.467190 * 100, metric = 7.30% * 100;
 Minibatch[1501-1600]: loss = 0.475115 * 100, metric = 7.35% * 100;
 Minibatch[1601-1700]: loss = 0.477837 * 100, metric = 7.63% * 100;
 Minibatch[1701-1800]: loss = 0.465173 * 100, metric = 7.31% * 100;
 Minibatch[1801-1900]: loss = 0.455812 * 100, metric = 7.16% * 100;
 Minibatch[1901-2000]: loss = 0.468027 * 100, metric = 7.23% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.465615 * 2000, metric = 7.25% * 2000 859.266s (  2.3 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.65% * 2000;
 Minibatch[   1- 100]: loss = 0.441108 * 100, metric = 6.47% * 100;
 Minibatch[ 101- 200]: loss = 0.464908 * 100, metric = 7.19% * 100;
 Minibatch[ 201- 300]: loss = 0.467209 * 100, metric = 7.03% * 100;
 Minibatch[ 301- 400]: loss = 0.448713 * 100, metric = 6.83% * 100;
 Minibatch[ 401- 500]: loss = 0.458995 * 100, metric = 7.24% * 100;
 Minibatch[ 501- 600]: loss = 0.438180 * 100, metric = 6.62% * 100;
 Minibatch[ 601- 700]: loss = 0.479638 * 100, metric = 7.46% * 100;
 Minibatch[ 701- 800]: loss = 0.442933 * 100, metric = 6.70% * 100;
 Minibatch[ 801- 900]: loss = 0.465771 * 100, metric = 7.04% * 100;
 Minibatch[ 901-1000]: loss = 0.440363 * 100, metric = 6.78% * 100;
 Minibatch[1001-1100]: loss = 0.468694 * 100, metric = 7.27% * 100;
 Minibatch[1101-1200]: loss = 0.456810 * 100, metric = 6.91% * 100;
 Minibatch[1201-1300]: loss = 0.458781 * 100, metric = 7.21% * 100;
 Minibatch[1301-1400]: loss = 0.466884 * 100, metric = 7.30% * 100;
 Minibatch[1401-1500]: loss = 0.449791 * 100, metric = 6.61% * 100;
 Minibatch[1501-1600]: loss = 0.469677 * 100, metric = 7.28% * 100;
 Minibatch[1601-1700]: loss = 0.461649 * 100, metric = 7.05% * 100;
 Minibatch[1701-1800]: loss = 0.449846 * 100, metric = 6.80% * 100;
 Minibatch[1801-1900]: loss = 0.466487 * 100, metric = 7.34% * 100;
 Minibatch[1901-2000]: loss = 0.445034 * 100, metric = 6.67% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.457074 * 2000, metric = 6.99% * 2000 855.460s (  2.3 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.53% * 2000;
 Minibatch[   1- 100]: loss = 0.447879 * 100, metric = 6.86% * 100;
 Minibatch[ 101- 200]: loss = 0.442432 * 100, metric = 6.62% * 100;
 Minibatch[ 201- 300]: loss = 0.472792 * 100, metric = 7.56% * 100;
 Minibatch[ 301- 400]: loss = 0.450962 * 100, metric = 6.94% * 100;
 Minibatch[ 401- 500]: loss = 0.445907 * 100, metric = 6.86% * 100;
 Minibatch[ 501- 600]: loss = 0.457075 * 100, metric = 6.90% * 100;
 Minibatch[ 601- 700]: loss = 0.467010 * 100, metric = 7.20% * 100;
 Minibatch[ 701- 800]: loss = 0.438512 * 100, metric = 6.64% * 100;
 Minibatch[ 801- 900]: loss = 0.447152 * 100, metric = 6.92% * 100;
 Minibatch[ 901-1000]: loss = 0.455698 * 100, metric = 7.04% * 100;
 Minibatch[1001-1100]: loss = 0.465393 * 100, metric = 7.24% * 100;
 Minibatch[1101-1200]: loss = 0.453466 * 100, metric = 6.96% * 100;
 Minibatch[1201-1300]: loss = 0.456073 * 100, metric = 6.95% * 100;
 Minibatch[1301-1400]: loss = 0.431875 * 100, metric = 6.49% * 100;
 Minibatch[1401-1500]: loss = 0.442573 * 100, metric = 6.60% * 100;
 Minibatch[1501-1600]: loss = 0.445466 * 100, metric = 6.85% * 100;
 Minibatch[1601-1700]: loss = 0.465497 * 100, metric = 7.46% * 100;
 Minibatch[1701-1800]: loss = 0.462451 * 100, metric = 7.10% * 100;
 Minibatch[1801-1900]: loss = 0.456052 * 100, metric = 7.05% * 100;
 Minibatch[1901-2000]: loss = 0.446643 * 100, metric = 6.78% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.452545 * 2000, metric = 6.95% * 2000 856.697s (  2.3 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.88% * 2000;
 Minibatch[   1- 100]: loss = 0.456450 * 100, metric = 6.98% * 100;
 Minibatch[ 101- 200]: loss = 0.457157 * 100, metric = 7.23% * 100;
 Minibatch[ 201- 300]: loss = 0.449004 * 100, metric = 6.90% * 100;
 Minibatch[ 301- 400]: loss = 0.457162 * 100, metric = 7.26% * 100;
 Minibatch[ 401- 500]: loss = 0.454725 * 100, metric = 7.39% * 100;
 Minibatch[ 501- 600]: loss = 0.448218 * 100, metric = 6.97% * 100;
 Minibatch[ 601- 700]: loss = 0.453539 * 100, metric = 6.90% * 100;
 Minibatch[ 701- 800]: loss = 0.465976 * 100, metric = 7.45% * 100;
 Minibatch[ 801- 900]: loss = 0.451694 * 100, metric = 6.94% * 100;
 Minibatch[ 901-1000]: loss = 0.430670 * 100, metric = 6.42% * 100;
 Minibatch[1001-1100]: loss = 0.446754 * 100, metric = 6.99% * 100;
 Minibatch[1101-1200]: loss = 0.465416 * 100, metric = 7.40% * 100;
 Minibatch[1201-1300]: loss = 0.461320 * 100, metric = 7.10% * 100;
 Minibatch[1301-1400]: loss = 0.450020 * 100, metric = 6.83% * 100;
 Minibatch[1401-1500]: loss = 0.456261 * 100, metric = 7.13% * 100;
 Minibatch[1501-1600]: loss = 0.439044 * 100, metric = 6.56% * 100;
 Minibatch[1601-1700]: loss = 0.442286 * 100, metric = 6.87% * 100;
 Minibatch[1701-1800]: loss = 0.446096 * 100, metric = 6.81% * 100;
 Minibatch[1801-1900]: loss = 0.445386 * 100, metric = 6.92% * 100;
 Minibatch[1901-2000]: loss = 0.443641 * 100, metric = 6.61% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.451041 * 2000, metric = 6.98% * 2000 853.394s (  2.3 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.54% * 2000;
 Minibatch[   1- 100]: loss = 0.458390 * 100, metric = 6.96% * 100;
 Minibatch[ 101- 200]: loss = 0.452156 * 100, metric = 7.09% * 100;
 Minibatch[ 201- 300]: loss = 0.433255 * 100, metric = 6.46% * 100;
 Minibatch[ 301- 400]: loss = 0.438818 * 100, metric = 6.52% * 100;
 Minibatch[ 401- 500]: loss = 0.443480 * 100, metric = 6.72% * 100;
 Minibatch[ 501- 600]: loss = 0.435436 * 100, metric = 6.67% * 100;
 Minibatch[ 601- 700]: loss = 0.449122 * 100, metric = 7.09% * 100;
 Minibatch[ 701- 800]: loss = 0.437963 * 100, metric = 6.87% * 100;
 Minibatch[ 801- 900]: loss = 0.450925 * 100, metric = 6.93% * 100;
 Minibatch[ 901-1000]: loss = 0.442404 * 100, metric = 6.72% * 100;
 Minibatch[1001-1100]: loss = 0.454293 * 100, metric = 6.96% * 100;
 Minibatch[1101-1200]: loss = 0.432292 * 100, metric = 6.57% * 100;
 Minibatch[1201-1300]: loss = 0.440527 * 100, metric = 6.84% * 100;
 Minibatch[1301-1400]: loss = 0.452827 * 100, metric = 6.80% * 100;
 Minibatch[1401-1500]: loss = 0.454039 * 100, metric = 7.01% * 100;
 Minibatch[1501-1600]: loss = 0.457703 * 100, metric = 7.00% * 100;
 Minibatch[1601-1700]: loss = 0.443070 * 100, metric = 6.66% * 100;
 Minibatch[1701-1800]: loss = 0.433991 * 100, metric = 6.71% * 100;
 Minibatch[1801-1900]: loss = 0.452233 * 100, metric = 6.74% * 100;
 Minibatch[1901-2000]: loss = 0.457099 * 100, metric = 7.07% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.446001 * 2000, metric = 6.82% * 2000 859.812s (  2.3 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 13.56% * 2000;
 Minibatch[   1- 100]: loss = 0.437224 * 100, metric = 6.62% * 100;
 Minibatch[ 101- 200]: loss = 0.447840 * 100, metric = 6.89% * 100;
 Minibatch[ 201- 300]: loss = 0.440455 * 100, metric = 6.72% * 100;
 Minibatch[ 301- 400]: loss = 0.439761 * 100, metric = 6.87% * 100;
 Minibatch[ 401- 500]: loss = 0.439484 * 100, metric = 6.91% * 100;
 Minibatch[ 501- 600]: loss = 0.445808 * 100, metric = 6.75% * 100;
 Minibatch[ 601- 700]: loss = 0.443906 * 100, metric = 6.81% * 100;
 Minibatch[ 701- 800]: loss = 0.454302 * 100, metric = 6.98% * 100;
 Minibatch[ 801- 900]: loss = 0.427031 * 100, metric = 6.37% * 100;
 Minibatch[ 901-1000]: loss = 0.438100 * 100, metric = 6.66% * 100;
 Minibatch[1001-1100]: loss = 0.449674 * 100, metric = 6.95% * 100;
 Minibatch[1101-1200]: loss = 0.446128 * 100, metric = 7.00% * 100;
 Minibatch[1201-1300]: loss = 0.442690 * 100, metric = 6.42% * 100;
 Minibatch[1301-1400]: loss = 0.456509 * 100, metric = 7.16% * 100;
 Minibatch[1401-1500]: loss = 0.457041 * 100, metric = 6.96% * 100;
 Minibatch[1501-1600]: loss = 0.445270 * 100, metric = 6.78% * 100;
 Minibatch[1601-1700]: loss = 0.441041 * 100, metric = 6.84% * 100;
 Minibatch[1701-1800]: loss = 0.457364 * 100, metric = 6.96% * 100;
 Minibatch[1801-1900]: loss = 0.439897 * 100, metric = 6.75% * 100;
 Minibatch[1901-2000]: loss = 0.441302 * 100, metric = 6.72% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.444541 * 2000, metric = 6.80% * 2000 848.595s (  2.4 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.53% * 2000;
 Minibatch[   1- 100]: loss = 0.435228 * 100, metric = 6.65% * 100;
 Minibatch[ 101- 200]: loss = 0.438909 * 100, metric = 6.53% * 100;
 Minibatch[ 201- 300]: loss = 0.448249 * 100, metric = 6.83% * 100;
 Minibatch[ 301- 400]: loss = 0.446887 * 100, metric = 6.84% * 100;
 Minibatch[ 401- 500]: loss = 0.447017 * 100, metric = 6.90% * 100;
 Minibatch[ 501- 600]: loss = 0.427618 * 100, metric = 6.51% * 100;
 Minibatch[ 601- 700]: loss = 0.454292 * 100, metric = 6.91% * 100;
 Minibatch[ 701- 800]: loss = 0.440354 * 100, metric = 6.50% * 100;
 Minibatch[ 801- 900]: loss = 0.440575 * 100, metric = 6.62% * 100;
 Minibatch[ 901-1000]: loss = 0.443914 * 100, metric = 6.75% * 100;
 Minibatch[1001-1100]: loss = 0.453799 * 100, metric = 6.88% * 100;
 Minibatch[1101-1200]: loss = 0.445490 * 100, metric = 6.94% * 100;
 Minibatch[1201-1300]: loss = 0.432114 * 100, metric = 6.52% * 100;
 Minibatch[1301-1400]: loss = 0.439210 * 100, metric = 6.85% * 100;
 Minibatch[1401-1500]: loss = 0.432982 * 100, metric = 6.47% * 100;
 Minibatch[1501-1600]: loss = 0.444331 * 100, metric = 6.84% * 100;
 Minibatch[1601-1700]: loss = 0.439987 * 100, metric = 6.74% * 100;
 Minibatch[1701-1800]: loss = 0.432435 * 100, metric = 6.57% * 100;
 Minibatch[1801-1900]: loss = 0.431639 * 100, metric = 6.50% * 100;
 Minibatch[1901-2000]: loss = 0.444402 * 100, metric = 6.97% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.440972 * 2000, metric = 6.72% * 2000 845.321s (  2.4 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 13.45% * 2000;
 Minibatch[   1- 100]: loss = 0.431609 * 100, metric = 6.74% * 100;
 Minibatch[ 101- 200]: loss = 0.434191 * 100, metric = 6.65% * 100;
 Minibatch[ 201- 300]: loss = 0.451059 * 100, metric = 7.01% * 100;
 Minibatch[ 301- 400]: loss = 0.443192 * 100, metric = 6.97% * 100;
 Minibatch[ 401- 500]: loss = 0.432506 * 100, metric = 6.67% * 100;
 Minibatch[ 501- 600]: loss = 0.438143 * 100, metric = 6.44% * 100;
 Minibatch[ 601- 700]: loss = 0.447685 * 100, metric = 6.87% * 100;
 Minibatch[ 701- 800]: loss = 0.437763 * 100, metric = 6.79% * 100;
 Minibatch[ 801- 900]: loss = 0.433704 * 100, metric = 6.94% * 100;
 Minibatch[ 901-1000]: loss = 0.437290 * 100, metric = 6.83% * 100;
 Minibatch[1001-1100]: loss = 0.447605 * 100, metric = 6.79% * 100;
 Minibatch[1101-1200]: loss = 0.453603 * 100, metric = 6.92% * 100;
 Minibatch[1201-1300]: loss = 0.448898 * 100, metric = 6.58% * 100;
 Minibatch[1301-1400]: loss = 0.429847 * 100, metric = 6.44% * 100;
 Minibatch[1401-1500]: loss = 0.436002 * 100, metric = 6.76% * 100;
 Minibatch[1501-1600]: loss = 0.443759 * 100, metric = 6.61% * 100;
 Minibatch[1601-1700]: loss = 0.438353 * 100, metric = 6.62% * 100;
 Minibatch[1701-1800]: loss = 0.443461 * 100, metric = 6.87% * 100;
 Minibatch[1801-1900]: loss = 0.437864 * 100, metric = 6.81% * 100;
 Minibatch[1901-2000]: loss = 0.432516 * 100, metric = 6.30% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.439953 * 2000, metric = 6.73% * 2000 850.513s (  2.4 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 14.12% * 2000;
 Minibatch[   1- 100]: loss = 0.433484 * 100, metric = 6.53% * 100;
 Minibatch[ 101- 200]: loss = 0.433288 * 100, metric = 6.62% * 100;
 Minibatch[ 201- 300]: loss = 0.429692 * 100, metric = 6.44% * 100;
 Minibatch[ 301- 400]: loss = 0.431917 * 100, metric = 6.48% * 100;
 Minibatch[ 401- 500]: loss = 0.431812 * 100, metric = 6.50% * 100;
 Minibatch[ 501- 600]: loss = 0.437847 * 100, metric = 6.56% * 100;
 Minibatch[ 601- 700]: loss = 0.441460 * 100, metric = 6.89% * 100;
 Minibatch[ 701- 800]: loss = 0.428735 * 100, metric = 6.57% * 100;
 Minibatch[ 801- 900]: loss = 0.418872 * 100, metric = 6.42% * 100;
 Minibatch[ 901-1000]: loss = 0.447530 * 100, metric = 6.90% * 100;
 Minibatch[1001-1100]: loss = 0.429486 * 100, metric = 6.62% * 100;
 Minibatch[1101-1200]: loss = 0.433834 * 100, metric = 6.59% * 100;
 Minibatch[1201-1300]: loss = 0.433715 * 100, metric = 6.54% * 100;
 Minibatch[1301-1400]: loss = 0.435262 * 100, metric = 6.38% * 100;
 Minibatch[1401-1500]: loss = 0.427860 * 100, metric = 6.52% * 100;
 Minibatch[1501-1600]: loss = 0.438292 * 100, metric = 6.69% * 100;
 Minibatch[1601-1700]: loss = 0.439869 * 100, metric = 6.91% * 100;
 Minibatch[1701-1800]: loss = 0.437654 * 100, metric = 6.64% * 100;
 Minibatch[1801-1900]: loss = 0.432601 * 100, metric = 6.70% * 100;
 Minibatch[1901-2000]: loss = 0.426774 * 100, metric = 6.38% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.433499 * 2000, metric = 6.60% * 2000 844.980s (  2.4 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 13.27% * 2000;
 Minibatch[   1- 100]: loss = 0.454507 * 100, metric = 7.04% * 100;
 Minibatch[ 101- 200]: loss = 0.422950 * 100, metric = 6.18% * 100;
 Minibatch[ 201- 300]: loss = 0.433369 * 100, metric = 6.69% * 100;
 Minibatch[ 301- 400]: loss = 0.433787 * 100, metric = 6.62% * 100;
 Minibatch[ 401- 500]: loss = 0.430399 * 100, metric = 6.44% * 100;
 Minibatch[ 501- 600]: loss = 0.428952 * 100, metric = 6.52% * 100;
 Minibatch[ 601- 700]: loss = 0.439804 * 100, metric = 6.83% * 100;
 Minibatch[ 701- 800]: loss = 0.422580 * 100, metric = 6.55% * 100;
 Minibatch[ 801- 900]: loss = 0.423857 * 100, metric = 6.63% * 100;
 Minibatch[ 901-1000]: loss = 0.431952 * 100, metric = 6.37% * 100;
 Minibatch[1001-1100]: loss = 0.427793 * 100, metric = 6.69% * 100;
 Minibatch[1101-1200]: loss = 0.418344 * 100, metric = 6.49% * 100;
 Minibatch[1201-1300]: loss = 0.438271 * 100, metric = 6.90% * 100;
 Minibatch[1301-1400]: loss = 0.427827 * 100, metric = 6.51% * 100;
 Minibatch[1401-1500]: loss = 0.404344 * 100, metric = 5.96% * 100;
 Minibatch[1501-1600]: loss = 0.437495 * 100, metric = 6.66% * 100;
 Minibatch[1601-1700]: loss = 0.422546 * 100, metric = 6.49% * 100;
 Minibatch[1701-1800]: loss = 0.429871 * 100, metric = 6.60% * 100;
 Minibatch[1801-1900]: loss = 0.433384 * 100, metric = 6.82% * 100;
 Minibatch[1901-2000]: loss = 0.429183 * 100, metric = 6.34% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.429561 * 2000, metric = 6.57% * 2000 845.653s (  2.4 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 13.97% * 2000;
 Minibatch[   1- 100]: loss = 0.418727 * 100, metric = 6.51% * 100;
 Minibatch[ 101- 200]: loss = 0.426509 * 100, metric = 6.46% * 100;
 Minibatch[ 201- 300]: loss = 0.427661 * 100, metric = 6.59% * 100;
 Minibatch[ 301- 400]: loss = 0.435914 * 100, metric = 6.53% * 100;
 Minibatch[ 401- 500]: loss = 0.430721 * 100, metric = 6.33% * 100;
 Minibatch[ 501- 600]: loss = 0.416198 * 100, metric = 6.32% * 100;
 Minibatch[ 601- 700]: loss = 0.436391 * 100, metric = 6.77% * 100;
 Minibatch[ 701- 800]: loss = 0.411465 * 100, metric = 6.02% * 100;
 Minibatch[ 801- 900]: loss = 0.420768 * 100, metric = 6.26% * 100;
 Minibatch[ 901-1000]: loss = 0.416379 * 100, metric = 6.18% * 100;
 Minibatch[1001-1100]: loss = 0.414116 * 100, metric = 6.13% * 100;
 Minibatch[1101-1200]: loss = 0.409035 * 100, metric = 5.97% * 100;
 Minibatch[1201-1300]: loss = 0.425708 * 100, metric = 6.27% * 100;
 Minibatch[1301-1400]: loss = 0.417148 * 100, metric = 6.05% * 100;
 Minibatch[1401-1500]: loss = 0.420291 * 100, metric = 6.32% * 100;
 Minibatch[1501-1600]: loss = 0.411585 * 100, metric = 6.14% * 100;
 Minibatch[1601-1700]: loss = 0.429163 * 100, metric = 6.33% * 100;
 Minibatch[1701-1800]: loss = 0.430275 * 100, metric = 6.52% * 100;
 Minibatch[1801-1900]: loss = 0.418094 * 100, metric = 6.25% * 100;
 Minibatch[1901-2000]: loss = 0.420988 * 100, metric = 6.30% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.421857 * 2000, metric = 6.31% * 2000 846.392s (  2.4 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 13.34% * 2000;
 Minibatch[   1- 100]: loss = 0.433739 * 100, metric = 6.53% * 100;
 Minibatch[ 101- 200]: loss = 0.418988 * 100, metric = 6.18% * 100;
 Minibatch[ 201- 300]: loss = 0.421475 * 100, metric = 6.25% * 100;
 Minibatch[ 301- 400]: loss = 0.436190 * 100, metric = 6.73% * 100;
 Minibatch[ 401- 500]: loss = 0.422153 * 100, metric = 6.38% * 100;
 Minibatch[ 501- 600]: loss = 0.406487 * 100, metric = 5.76% * 100;
 Minibatch[ 601- 700]: loss = 0.406387 * 100, metric = 5.98% * 100;
 Minibatch[ 701- 800]: loss = 0.401199 * 100, metric = 6.11% * 100;
 Minibatch[ 801- 900]: loss = 0.431584 * 100, metric = 6.51% * 100;
 Minibatch[ 901-1000]: loss = 0.417110 * 100, metric = 6.24% * 100;
 Minibatch[1001-1100]: loss = 0.410363 * 100, metric = 6.08% * 100;
 Minibatch[1101-1200]: loss = 0.424959 * 100, metric = 6.37% * 100;
 Minibatch[1201-1300]: loss = 0.418523 * 100, metric = 6.27% * 100;
 Minibatch[1301-1400]: loss = 0.412314 * 100, metric = 6.18% * 100;
 Minibatch[1401-1500]: loss = 0.423765 * 100, metric = 6.46% * 100;
 Minibatch[1501-1600]: loss = 0.413533 * 100, metric = 6.22% * 100;
 Minibatch[1601-1700]: loss = 0.408600 * 100, metric = 6.09% * 100;
 Minibatch[1701-1800]: loss = 0.416450 * 100, metric = 6.40% * 100;
 Minibatch[1801-1900]: loss = 0.428024 * 100, metric = 6.65% * 100;
 Minibatch[1901-2000]: loss = 0.419463 * 100, metric = 6.15% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.418565 * 2000, metric = 6.28% * 2000 844.453s (  2.4 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 13.35% * 2000;
 Minibatch[   1- 100]: loss = 0.410478 * 100, metric = 6.41% * 100;
 Minibatch[ 101- 200]: loss = 0.427327 * 100, metric = 6.57% * 100;
 Minibatch[ 201- 300]: loss = 0.405764 * 100, metric = 6.05% * 100;
 Minibatch[ 301- 400]: loss = 0.424982 * 100, metric = 6.51% * 100;
 Minibatch[ 401- 500]: loss = 0.420626 * 100, metric = 5.99% * 100;
 Minibatch[ 501- 600]: loss = 0.413966 * 100, metric = 6.18% * 100;
 Minibatch[ 601- 700]: loss = 0.397753 * 100, metric = 5.82% * 100;
 Minibatch[ 701- 800]: loss = 0.399159 * 100, metric = 5.93% * 100;
 Minibatch[ 801- 900]: loss = 0.403642 * 100, metric = 6.13% * 100;
 Minibatch[ 901-1000]: loss = 0.415101 * 100, metric = 6.21% * 100;
 Minibatch[1001-1100]: loss = 0.407927 * 100, metric = 6.21% * 100;
 Minibatch[1101-1200]: loss = 0.422568 * 100, metric = 6.49% * 100;
 Minibatch[1201-1300]: loss = 0.419902 * 100, metric = 6.15% * 100;
 Minibatch[1301-1400]: loss = 0.413380 * 100, metric = 6.21% * 100;
 Minibatch[1401-1500]: loss = 0.413074 * 100, metric = 6.24% * 100;
 Minibatch[1501-1600]: loss = 0.410807 * 100, metric = 6.13% * 100;
 Minibatch[1601-1700]: loss = 0.402563 * 100, metric = 6.05% * 100;
 Minibatch[1701-1800]: loss = 0.415693 * 100, metric = 6.39% * 100;
 Minibatch[1801-1900]: loss = 0.398214 * 100, metric = 5.93% * 100;
 Minibatch[1901-2000]: loss = 0.407263 * 100, metric = 5.98% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.411509 * 2000, metric = 6.18% * 2000 841.933s (  2.4 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 13.39% * 2000;
 Minibatch[   1- 100]: loss = 0.416914 * 100, metric = 6.08% * 100;
 Minibatch[ 101- 200]: loss = 0.406489 * 100, metric = 6.10% * 100;
 Minibatch[ 201- 300]: loss = 0.416619 * 100, metric = 6.38% * 100;
 Minibatch[ 301- 400]: loss = 0.414465 * 100, metric = 6.19% * 100;
 Minibatch[ 401- 500]: loss = 0.412878 * 100, metric = 6.26% * 100;
 Minibatch[ 501- 600]: loss = 0.407288 * 100, metric = 6.07% * 100;
 Minibatch[ 601- 700]: loss = 0.421691 * 100, metric = 6.48% * 100;
 Minibatch[ 701- 800]: loss = 0.424213 * 100, metric = 6.57% * 100;
 Minibatch[ 801- 900]: loss = 0.409914 * 100, metric = 6.23% * 100;
 Minibatch[ 901-1000]: loss = 0.418595 * 100, metric = 6.33% * 100;
 Minibatch[1001-1100]: loss = 0.423120 * 100, metric = 6.52% * 100;
 Minibatch[1101-1200]: loss = 0.415841 * 100, metric = 6.22% * 100;
 Minibatch[1201-1300]: loss = 0.395381 * 100, metric = 5.82% * 100;
 Minibatch[1301-1400]: loss = 0.400217 * 100, metric = 6.14% * 100;
 Minibatch[1401-1500]: loss = 0.413636 * 100, metric = 6.12% * 100;
 Minibatch[1501-1600]: loss = 0.411743 * 100, metric = 6.18% * 100;
 Minibatch[1601-1700]: loss = 0.400656 * 100, metric = 6.01% * 100;
 Minibatch[1701-1800]: loss = 0.424707 * 100, metric = 6.70% * 100;
 Minibatch[1801-1900]: loss = 0.411362 * 100, metric = 6.15% * 100;
 Minibatch[1901-2000]: loss = 0.421071 * 100, metric = 6.48% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.413340 * 2000, metric = 6.25% * 2000 840.403s (  2.4 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 13.42% * 2000;
 Minibatch[   1- 100]: loss = 0.413346 * 100, metric = 6.27% * 100;
 Minibatch[ 101- 200]: loss = 0.415393 * 100, metric = 6.25% * 100;
 Minibatch[ 201- 300]: loss = 0.401515 * 100, metric = 6.05% * 100;
 Minibatch[ 301- 400]: loss = 0.404173 * 100, metric = 5.93% * 100;
 Minibatch[ 401- 500]: loss = 0.417153 * 100, metric = 6.22% * 100;
 Minibatch[ 501- 600]: loss = 0.422617 * 100, metric = 6.50% * 100;
 Minibatch[ 601- 700]: loss = 0.432161 * 100, metric = 6.54% * 100;
 Minibatch[ 701- 800]: loss = 0.398586 * 100, metric = 5.93% * 100;
 Minibatch[ 801- 900]: loss = 0.407595 * 100, metric = 5.88% * 100;
 Minibatch[ 901-1000]: loss = 0.412012 * 100, metric = 6.27% * 100;
 Minibatch[1001-1100]: loss = 0.401814 * 100, metric = 6.02% * 100;
 Minibatch[1101-1200]: loss = 0.413143 * 100, metric = 6.01% * 100;
 Minibatch[1201-1300]: loss = 0.408027 * 100, metric = 6.16% * 100;
 Minibatch[1301-1400]: loss = 0.403452 * 100, metric = 6.21% * 100;
 Minibatch[1401-1500]: loss = 0.403938 * 100, metric = 5.97% * 100;
 Minibatch[1501-1600]: loss = 0.404798 * 100, metric = 6.13% * 100;
 Minibatch[1601-1700]: loss = 0.399952 * 100, metric = 5.81% * 100;
 Minibatch[1701-1800]: loss = 0.407328 * 100, metric = 5.94% * 100;
 Minibatch[1801-1900]: loss = 0.409993 * 100, metric = 6.14% * 100;
 Minibatch[1901-2000]: loss = 0.392308 * 100, metric = 5.72% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.408465 * 2000, metric = 6.10% * 2000 838.274s (  2.4 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 13.74% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
