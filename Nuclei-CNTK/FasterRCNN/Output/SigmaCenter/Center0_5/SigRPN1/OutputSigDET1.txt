Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.043943 * 100, metric = 25.41% * 100;
 Minibatch[ 101- 200]: loss = 0.827061 * 100, metric = 22.82% * 100;
 Minibatch[ 201- 300]: loss = 0.732214 * 100, metric = 21.88% * 100;
 Minibatch[ 301- 400]: loss = 0.726684 * 100, metric = 21.43% * 100;
 Minibatch[ 401- 500]: loss = 0.672537 * 100, metric = 20.68% * 100;
 Minibatch[ 501- 600]: loss = 0.652466 * 100, metric = 19.40% * 100;
 Minibatch[ 601- 700]: loss = 0.626377 * 100, metric = 18.17% * 100;
 Minibatch[ 701- 800]: loss = 0.588918 * 100, metric = 17.22% * 100;
 Minibatch[ 801- 900]: loss = 0.605325 * 100, metric = 17.85% * 100;
 Minibatch[ 901-1000]: loss = 0.610619 * 100, metric = 18.31% * 100;
 Minibatch[1001-1100]: loss = 0.594897 * 100, metric = 17.67% * 100;
 Minibatch[1101-1200]: loss = 0.579876 * 100, metric = 17.29% * 100;
 Minibatch[1201-1300]: loss = 0.583812 * 100, metric = 17.71% * 100;
 Minibatch[1301-1400]: loss = 0.556303 * 100, metric = 16.68% * 100;
 Minibatch[1401-1500]: loss = 0.573230 * 100, metric = 17.32% * 100;
 Minibatch[1501-1600]: loss = 0.544322 * 100, metric = 16.48% * 100;
 Minibatch[1601-1700]: loss = 0.539663 * 100, metric = 16.49% * 100;
 Minibatch[1701-1800]: loss = 0.543361 * 100, metric = 16.39% * 100;
 Minibatch[1801-1900]: loss = 0.539219 * 100, metric = 16.21% * 100;
 Minibatch[1901-2000]: loss = 0.520364 * 100, metric = 15.55% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.633060 * 2000, metric = 18.55% * 2000 948.728s (  2.1 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 22.54% * 2000;
0.5819313599988818
 Minibatch[   1- 100]: loss = 0.508313 * 100, metric = 15.43% * 100;
 Minibatch[ 101- 200]: loss = 0.528363 * 100, metric = 16.28% * 100;
 Minibatch[ 201- 300]: loss = 0.506354 * 100, metric = 14.60% * 100;
 Minibatch[ 301- 400]: loss = 0.516794 * 100, metric = 15.42% * 100;
 Minibatch[ 401- 500]: loss = 0.501031 * 100, metric = 15.21% * 100;
 Minibatch[ 501- 600]: loss = 0.516795 * 100, metric = 15.12% * 100;
 Minibatch[ 601- 700]: loss = 0.483191 * 100, metric = 14.54% * 100;
 Minibatch[ 701- 800]: loss = 0.499097 * 100, metric = 15.26% * 100;
 Minibatch[ 801- 900]: loss = 0.481702 * 100, metric = 14.96% * 100;
 Minibatch[ 901-1000]: loss = 0.466279 * 100, metric = 14.05% * 100;
 Minibatch[1001-1100]: loss = 0.478645 * 100, metric = 14.44% * 100;
 Minibatch[1101-1200]: loss = 0.476116 * 100, metric = 14.25% * 100;
 Minibatch[1201-1300]: loss = 0.468285 * 100, metric = 14.30% * 100;
 Minibatch[1301-1400]: loss = 0.473776 * 100, metric = 14.07% * 100;
 Minibatch[1401-1500]: loss = 0.448089 * 100, metric = 13.44% * 100;
 Minibatch[1501-1600]: loss = 0.443643 * 100, metric = 13.42% * 100;
 Minibatch[1601-1700]: loss = 0.464993 * 100, metric = 13.62% * 100;
 Minibatch[1701-1800]: loss = 0.468558 * 100, metric = 14.49% * 100;
 Minibatch[1801-1900]: loss = 0.464548 * 100, metric = 14.13% * 100;
 Minibatch[1901-2000]: loss = 0.448004 * 100, metric = 13.68% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.482129 * 2000, metric = 14.54% * 2000 881.662s (  2.3 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 21.20% * 2000;
0.5348063318282366
 Minibatch[   1- 100]: loss = 0.458002 * 100, metric = 14.00% * 100;
 Minibatch[ 101- 200]: loss = 0.469247 * 100, metric = 14.37% * 100;
 Minibatch[ 201- 300]: loss = 0.447030 * 100, metric = 13.80% * 100;
 Minibatch[ 301- 400]: loss = 0.464030 * 100, metric = 14.16% * 100;
 Minibatch[ 401- 500]: loss = 0.471183 * 100, metric = 14.39% * 100;
 Minibatch[ 501- 600]: loss = 0.456122 * 100, metric = 13.97% * 100;
 Minibatch[ 601- 700]: loss = 0.467420 * 100, metric = 13.90% * 100;
 Minibatch[ 701- 800]: loss = 0.434843 * 100, metric = 12.85% * 100;
 Minibatch[ 801- 900]: loss = 0.457922 * 100, metric = 14.06% * 100;
 Minibatch[ 901-1000]: loss = 0.444131 * 100, metric = 13.68% * 100;
 Minibatch[1001-1100]: loss = 0.446945 * 100, metric = 13.79% * 100;
 Minibatch[1101-1200]: loss = 0.435008 * 100, metric = 13.60% * 100;
 Minibatch[1201-1300]: loss = 0.436714 * 100, metric = 13.49% * 100;
 Minibatch[1301-1400]: loss = 0.446027 * 100, metric = 13.75% * 100;
 Minibatch[1401-1500]: loss = 0.440545 * 100, metric = 13.40% * 100;
 Minibatch[1501-1600]: loss = 0.426437 * 100, metric = 12.87% * 100;
 Minibatch[1601-1700]: loss = 0.420558 * 100, metric = 12.55% * 100;
 Minibatch[1701-1800]: loss = 0.444852 * 100, metric = 13.63% * 100;
 Minibatch[1801-1900]: loss = 0.428411 * 100, metric = 12.83% * 100;
 Minibatch[1901-2000]: loss = 0.426089 * 100, metric = 13.01% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.446076 * 2000, metric = 13.61% * 2000 902.739s (  2.2 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 19.57% * 2000;
0.5103440340310336
 Minibatch[   1- 100]: loss = 0.444330 * 100, metric = 13.32% * 100;
 Minibatch[ 101- 200]: loss = 0.418845 * 100, metric = 12.78% * 100;
 Minibatch[ 201- 300]: loss = 0.426993 * 100, metric = 12.95% * 100;
 Minibatch[ 301- 400]: loss = 0.405216 * 100, metric = 12.47% * 100;
 Minibatch[ 401- 500]: loss = 0.427980 * 100, metric = 12.94% * 100;
 Minibatch[ 501- 600]: loss = 0.407757 * 100, metric = 12.36% * 100;
 Minibatch[ 601- 700]: loss = 0.416790 * 100, metric = 12.92% * 100;
 Minibatch[ 701- 800]: loss = 0.421226 * 100, metric = 13.03% * 100;
 Minibatch[ 801- 900]: loss = 0.418690 * 100, metric = 12.58% * 100;
 Minibatch[ 901-1000]: loss = 0.420315 * 100, metric = 12.93% * 100;
 Minibatch[1001-1100]: loss = 0.434071 * 100, metric = 13.38% * 100;
 Minibatch[1101-1200]: loss = 0.411699 * 100, metric = 12.69% * 100;
 Minibatch[1201-1300]: loss = 0.409598 * 100, metric = 12.54% * 100;
 Minibatch[1301-1400]: loss = 0.430912 * 100, metric = 13.37% * 100;
 Minibatch[1401-1500]: loss = 0.419858 * 100, metric = 12.82% * 100;
 Minibatch[1501-1600]: loss = 0.395527 * 100, metric = 12.13% * 100;
 Minibatch[1601-1700]: loss = 0.413708 * 100, metric = 12.92% * 100;
 Minibatch[1701-1800]: loss = 0.415132 * 100, metric = 12.95% * 100;
 Minibatch[1801-1900]: loss = 0.405158 * 100, metric = 12.33% * 100;
 Minibatch[1901-2000]: loss = 0.398192 * 100, metric = 12.14% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.417100 * 2000, metric = 12.78% * 2000 875.766s (  2.3 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 22.40% * 2000;
 Minibatch[   1- 100]: loss = 0.417738 * 100, metric = 12.83% * 100;
 Minibatch[ 101- 200]: loss = 0.400571 * 100, metric = 12.45% * 100;
 Minibatch[ 201- 300]: loss = 0.404045 * 100, metric = 12.31% * 100;
 Minibatch[ 301- 400]: loss = 0.418521 * 100, metric = 13.09% * 100;
 Minibatch[ 401- 500]: loss = 0.391194 * 100, metric = 11.77% * 100;
 Minibatch[ 501- 600]: loss = 0.396001 * 100, metric = 11.94% * 100;
 Minibatch[ 601- 700]: loss = 0.399199 * 100, metric = 12.07% * 100;
 Minibatch[ 701- 800]: loss = 0.411261 * 100, metric = 12.54% * 100;
 Minibatch[ 801- 900]: loss = 0.391702 * 100, metric = 11.86% * 100;
 Minibatch[ 901-1000]: loss = 0.398060 * 100, metric = 12.19% * 100;
 Minibatch[1001-1100]: loss = 0.406033 * 100, metric = 12.23% * 100;
 Minibatch[1101-1200]: loss = 0.387052 * 100, metric = 11.75% * 100;
 Minibatch[1201-1300]: loss = 0.399165 * 100, metric = 11.96% * 100;
 Minibatch[1301-1400]: loss = 0.411314 * 100, metric = 12.69% * 100;
 Minibatch[1401-1500]: loss = 0.392054 * 100, metric = 11.97% * 100;
 Minibatch[1501-1600]: loss = 0.394952 * 100, metric = 11.94% * 100;
 Minibatch[1601-1700]: loss = 0.407651 * 100, metric = 12.90% * 100;
 Minibatch[1701-1800]: loss = 0.396834 * 100, metric = 12.27% * 100;
 Minibatch[1801-1900]: loss = 0.403416 * 100, metric = 12.52% * 100;
 Minibatch[1901-2000]: loss = 0.394906 * 100, metric = 11.96% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.401083 * 2000, metric = 12.26% * 2000 865.166s (  2.3 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 22.81% * 2000;
 Minibatch[   1- 100]: loss = 0.385600 * 100, metric = 11.81% * 100;
 Minibatch[ 101- 200]: loss = 0.384208 * 100, metric = 11.74% * 100;
 Minibatch[ 201- 300]: loss = 0.390145 * 100, metric = 11.96% * 100;
 Minibatch[ 301- 400]: loss = 0.392099 * 100, metric = 11.81% * 100;
 Minibatch[ 401- 500]: loss = 0.373033 * 100, metric = 11.44% * 100;
 Minibatch[ 501- 600]: loss = 0.381528 * 100, metric = 11.80% * 100;
 Minibatch[ 601- 700]: loss = 0.383441 * 100, metric = 12.18% * 100;
 Minibatch[ 701- 800]: loss = 0.384168 * 100, metric = 11.80% * 100;
 Minibatch[ 801- 900]: loss = 0.382965 * 100, metric = 11.86% * 100;
 Minibatch[ 901-1000]: loss = 0.376252 * 100, metric = 11.38% * 100;
 Minibatch[1001-1100]: loss = 0.379405 * 100, metric = 11.05% * 100;
 Minibatch[1101-1200]: loss = 0.387845 * 100, metric = 11.66% * 100;
 Minibatch[1201-1300]: loss = 0.397043 * 100, metric = 12.16% * 100;
 Minibatch[1301-1400]: loss = 0.378368 * 100, metric = 11.60% * 100;
 Minibatch[1401-1500]: loss = 0.381665 * 100, metric = 11.78% * 100;
 Minibatch[1501-1600]: loss = 0.362097 * 100, metric = 10.97% * 100;
 Minibatch[1601-1700]: loss = 0.362498 * 100, metric = 10.98% * 100;
 Minibatch[1701-1800]: loss = 0.367336 * 100, metric = 11.02% * 100;
 Minibatch[1801-1900]: loss = 0.386581 * 100, metric = 11.94% * 100;
 Minibatch[1901-2000]: loss = 0.370263 * 100, metric = 11.32% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.380327 * 2000, metric = 11.61% * 2000 873.975s (  2.3 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 22.34% * 2000;
 Minibatch[   1- 100]: loss = 0.367260 * 100, metric = 11.14% * 100;
 Minibatch[ 101- 200]: loss = 0.384218 * 100, metric = 11.40% * 100;
 Minibatch[ 201- 300]: loss = 0.381753 * 100, metric = 11.51% * 100;
 Minibatch[ 301- 400]: loss = 0.363371 * 100, metric = 11.05% * 100;
 Minibatch[ 401- 500]: loss = 0.376007 * 100, metric = 11.29% * 100;
 Minibatch[ 501- 600]: loss = 0.359548 * 100, metric = 10.98% * 100;
 Minibatch[ 601- 700]: loss = 0.364873 * 100, metric = 11.10% * 100;
 Minibatch[ 701- 800]: loss = 0.368376 * 100, metric = 11.22% * 100;
 Minibatch[ 801- 900]: loss = 0.367607 * 100, metric = 11.22% * 100;
 Minibatch[ 901-1000]: loss = 0.365811 * 100, metric = 11.30% * 100;
 Minibatch[1001-1100]: loss = 0.372823 * 100, metric = 11.41% * 100;
 Minibatch[1101-1200]: loss = 0.365216 * 100, metric = 11.09% * 100;
 Minibatch[1201-1300]: loss = 0.369454 * 100, metric = 11.42% * 100;
 Minibatch[1301-1400]: loss = 0.356354 * 100, metric = 10.83% * 100;
 Minibatch[1401-1500]: loss = 0.355647 * 100, metric = 10.72% * 100;
 Minibatch[1501-1600]: loss = 0.368928 * 100, metric = 11.54% * 100;
 Minibatch[1601-1700]: loss = 0.368164 * 100, metric = 11.36% * 100;
 Minibatch[1701-1800]: loss = 0.358403 * 100, metric = 10.88% * 100;
 Minibatch[1801-1900]: loss = 0.363038 * 100, metric = 11.13% * 100;
 Minibatch[1901-2000]: loss = 0.364333 * 100, metric = 11.02% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.367059 * 2000, metric = 11.18% * 2000 911.012s (  2.2 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 19.63% * 2000;
0.5005258414447308
 Minibatch[   1- 100]: loss = 0.366961 * 100, metric = 11.29% * 100;
 Minibatch[ 101- 200]: loss = 0.355817 * 100, metric = 10.79% * 100;
 Minibatch[ 201- 300]: loss = 0.346360 * 100, metric = 10.71% * 100;
 Minibatch[ 301- 400]: loss = 0.358914 * 100, metric = 11.12% * 100;
 Minibatch[ 401- 500]: loss = 0.367567 * 100, metric = 11.35% * 100;
 Minibatch[ 501- 600]: loss = 0.377181 * 100, metric = 11.70% * 100;
 Minibatch[ 601- 700]: loss = 0.345966 * 100, metric = 10.76% * 100;
 Minibatch[ 701- 800]: loss = 0.363516 * 100, metric = 11.05% * 100;
 Minibatch[ 801- 900]: loss = 0.342816 * 100, metric = 10.32% * 100;
 Minibatch[ 901-1000]: loss = 0.338666 * 100, metric = 10.41% * 100;
 Minibatch[1001-1100]: loss = 0.337236 * 100, metric = 10.32% * 100;
 Minibatch[1101-1200]: loss = 0.345139 * 100, metric = 10.45% * 100;
 Minibatch[1201-1300]: loss = 0.360323 * 100, metric = 10.88% * 100;
 Minibatch[1301-1400]: loss = 0.354920 * 100, metric = 10.96% * 100;
 Minibatch[1401-1500]: loss = 0.346139 * 100, metric = 10.72% * 100;
 Minibatch[1501-1600]: loss = 0.354396 * 100, metric = 10.88% * 100;
 Minibatch[1601-1700]: loss = 0.349481 * 100, metric = 10.49% * 100;
 Minibatch[1701-1800]: loss = 0.349584 * 100, metric = 10.41% * 100;
 Minibatch[1801-1900]: loss = 0.347437 * 100, metric = 10.73% * 100;
 Minibatch[1901-2000]: loss = 0.349083 * 100, metric = 10.81% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.352875 * 2000, metric = 10.81% * 2000 883.458s (  2.3 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 18.85% * 2000;
0.48064375982433555
 Minibatch[   1- 100]: loss = 0.329474 * 100, metric = 9.96% * 100;
 Minibatch[ 101- 200]: loss = 0.359033 * 100, metric = 10.79% * 100;
 Minibatch[ 201- 300]: loss = 0.348322 * 100, metric = 10.71% * 100;
 Minibatch[ 301- 400]: loss = 0.363621 * 100, metric = 11.00% * 100;
 Minibatch[ 401- 500]: loss = 0.348524 * 100, metric = 10.54% * 100;
 Minibatch[ 501- 600]: loss = 0.340274 * 100, metric = 10.34% * 100;
 Minibatch[ 601- 700]: loss = 0.344293 * 100, metric = 10.33% * 100;
 Minibatch[ 701- 800]: loss = 0.326458 * 100, metric = 9.91% * 100;
 Minibatch[ 801- 900]: loss = 0.339790 * 100, metric = 10.39% * 100;
 Minibatch[ 901-1000]: loss = 0.343753 * 100, metric = 10.52% * 100;
 Minibatch[1001-1100]: loss = 0.321086 * 100, metric = 9.67% * 100;
 Minibatch[1101-1200]: loss = 0.339966 * 100, metric = 10.68% * 100;
 Minibatch[1201-1300]: loss = 0.331830 * 100, metric = 10.27% * 100;
 Minibatch[1301-1400]: loss = 0.328979 * 100, metric = 9.69% * 100;
 Minibatch[1401-1500]: loss = 0.336461 * 100, metric = 10.17% * 100;
 Minibatch[1501-1600]: loss = 0.339685 * 100, metric = 10.32% * 100;
 Minibatch[1601-1700]: loss = 0.341592 * 100, metric = 10.36% * 100;
 Minibatch[1701-1800]: loss = 0.328367 * 100, metric = 9.71% * 100;
 Minibatch[1801-1900]: loss = 0.330023 * 100, metric = 9.90% * 100;
 Minibatch[1901-2000]: loss = 0.340606 * 100, metric = 10.32% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.339107 * 2000, metric = 10.28% * 2000 881.025s (  2.3 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 17.51% * 2000;
0.4593143340945244
 Minibatch[   1- 100]: loss = 0.352756 * 100, metric = 11.11% * 100;
 Minibatch[ 101- 200]: loss = 0.336085 * 100, metric = 10.42% * 100;
 Minibatch[ 201- 300]: loss = 0.336162 * 100, metric = 10.26% * 100;
 Minibatch[ 301- 400]: loss = 0.324103 * 100, metric = 9.81% * 100;
 Minibatch[ 401- 500]: loss = 0.337093 * 100, metric = 10.23% * 100;
 Minibatch[ 501- 600]: loss = 0.326585 * 100, metric = 10.06% * 100;
 Minibatch[ 601- 700]: loss = 0.324789 * 100, metric = 9.80% * 100;
 Minibatch[ 701- 800]: loss = 0.313927 * 100, metric = 9.26% * 100;
 Minibatch[ 801- 900]: loss = 0.326154 * 100, metric = 10.15% * 100;
 Minibatch[ 901-1000]: loss = 0.333040 * 100, metric = 10.22% * 100;
 Minibatch[1001-1100]: loss = 0.333692 * 100, metric = 10.19% * 100;
 Minibatch[1101-1200]: loss = 0.337528 * 100, metric = 10.22% * 100;
 Minibatch[1201-1300]: loss = 0.328798 * 100, metric = 9.98% * 100;
 Minibatch[1301-1400]: loss = 0.329919 * 100, metric = 9.98% * 100;
 Minibatch[1401-1500]: loss = 0.317841 * 100, metric = 9.67% * 100;
 Minibatch[1501-1600]: loss = 0.329438 * 100, metric = 10.12% * 100;
 Minibatch[1601-1700]: loss = 0.324815 * 100, metric = 9.83% * 100;
 Minibatch[1701-1800]: loss = 0.333528 * 100, metric = 9.91% * 100;
 Minibatch[1801-1900]: loss = 0.334521 * 100, metric = 10.21% * 100;
 Minibatch[1901-2000]: loss = 0.313885 * 100, metric = 9.46% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.329733 * 2000, metric = 10.04% * 2000 875.877s (  2.3 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 17.65% * 2000;
 Minibatch[   1- 100]: loss = 0.314847 * 100, metric = 9.54% * 100;
 Minibatch[ 101- 200]: loss = 0.327471 * 100, metric = 9.92% * 100;
 Minibatch[ 201- 300]: loss = 0.328612 * 100, metric = 10.05% * 100;
 Minibatch[ 301- 400]: loss = 0.321737 * 100, metric = 10.02% * 100;
 Minibatch[ 401- 500]: loss = 0.327948 * 100, metric = 10.10% * 100;
 Minibatch[ 501- 600]: loss = 0.325380 * 100, metric = 9.93% * 100;
 Minibatch[ 601- 700]: loss = 0.318553 * 100, metric = 9.67% * 100;
 Minibatch[ 701- 800]: loss = 0.330582 * 100, metric = 10.07% * 100;
 Minibatch[ 801- 900]: loss = 0.325480 * 100, metric = 9.69% * 100;
 Minibatch[ 901-1000]: loss = 0.332155 * 100, metric = 10.22% * 100;
 Minibatch[1001-1100]: loss = 0.326057 * 100, metric = 9.83% * 100;
 Minibatch[1101-1200]: loss = 0.324662 * 100, metric = 9.83% * 100;
 Minibatch[1201-1300]: loss = 0.318321 * 100, metric = 9.73% * 100;
 Minibatch[1301-1400]: loss = 0.306682 * 100, metric = 9.40% * 100;
 Minibatch[1401-1500]: loss = 0.329342 * 100, metric = 10.13% * 100;
 Minibatch[1501-1600]: loss = 0.316551 * 100, metric = 9.80% * 100;
 Minibatch[1601-1700]: loss = 0.317013 * 100, metric = 9.65% * 100;
 Minibatch[1701-1800]: loss = 0.332224 * 100, metric = 10.26% * 100;
 Minibatch[1801-1900]: loss = 0.322574 * 100, metric = 9.81% * 100;
 Minibatch[1901-2000]: loss = 0.321412 * 100, metric = 9.97% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.323380 * 2000, metric = 9.88% * 2000 874.293s (  2.3 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 18.11% * 2000;
 Minibatch[   1- 100]: loss = 0.309987 * 100, metric = 9.36% * 100;
 Minibatch[ 101- 200]: loss = 0.307457 * 100, metric = 9.13% * 100;
 Minibatch[ 201- 300]: loss = 0.313764 * 100, metric = 9.74% * 100;
 Minibatch[ 301- 400]: loss = 0.332387 * 100, metric = 10.18% * 100;
 Minibatch[ 401- 500]: loss = 0.304144 * 100, metric = 9.35% * 100;
 Minibatch[ 501- 600]: loss = 0.297186 * 100, metric = 8.89% * 100;
 Minibatch[ 601- 700]: loss = 0.300332 * 100, metric = 9.18% * 100;
 Minibatch[ 701- 800]: loss = 0.315943 * 100, metric = 9.55% * 100;
 Minibatch[ 801- 900]: loss = 0.307153 * 100, metric = 9.32% * 100;
 Minibatch[ 901-1000]: loss = 0.317490 * 100, metric = 9.77% * 100;
 Minibatch[1001-1100]: loss = 0.317215 * 100, metric = 9.92% * 100;
 Minibatch[1101-1200]: loss = 0.317230 * 100, metric = 9.73% * 100;
 Minibatch[1201-1300]: loss = 0.319179 * 100, metric = 9.76% * 100;
 Minibatch[1301-1400]: loss = 0.305488 * 100, metric = 9.33% * 100;
 Minibatch[1401-1500]: loss = 0.315277 * 100, metric = 9.59% * 100;
 Minibatch[1501-1600]: loss = 0.294894 * 100, metric = 8.99% * 100;
 Minibatch[1601-1700]: loss = 0.315331 * 100, metric = 9.86% * 100;
 Minibatch[1701-1800]: loss = 0.303049 * 100, metric = 9.22% * 100;
 Minibatch[1801-1900]: loss = 0.302003 * 100, metric = 9.06% * 100;
 Minibatch[1901-2000]: loss = 0.311849 * 100, metric = 9.35% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.310368 * 2000, metric = 9.46% * 2000 878.351s (  2.3 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 18.42% * 2000;
 Minibatch[   1- 100]: loss = 0.308805 * 100, metric = 9.26% * 100;
 Minibatch[ 101- 200]: loss = 0.312036 * 100, metric = 9.67% * 100;
 Minibatch[ 201- 300]: loss = 0.301519 * 100, metric = 9.42% * 100;
 Minibatch[ 301- 400]: loss = 0.312088 * 100, metric = 9.49% * 100;
 Minibatch[ 401- 500]: loss = 0.315441 * 100, metric = 9.81% * 100;
 Minibatch[ 501- 600]: loss = 0.317319 * 100, metric = 9.65% * 100;
 Minibatch[ 601- 700]: loss = 0.300382 * 100, metric = 8.82% * 100;
 Minibatch[ 701- 800]: loss = 0.293236 * 100, metric = 8.96% * 100;
 Minibatch[ 801- 900]: loss = 0.298155 * 100, metric = 9.05% * 100;
 Minibatch[ 901-1000]: loss = 0.310440 * 100, metric = 9.41% * 100;
 Minibatch[1001-1100]: loss = 0.312455 * 100, metric = 9.45% * 100;
 Minibatch[1101-1200]: loss = 0.303308 * 100, metric = 9.32% * 100;
 Minibatch[1201-1300]: loss = 0.308669 * 100, metric = 9.47% * 100;
 Minibatch[1301-1400]: loss = 0.308059 * 100, metric = 9.37% * 100;
 Minibatch[1401-1500]: loss = 0.295440 * 100, metric = 8.98% * 100;
 Minibatch[1501-1600]: loss = 0.294132 * 100, metric = 8.75% * 100;
 Minibatch[1601-1700]: loss = 0.296077 * 100, metric = 8.96% * 100;
 Minibatch[1701-1800]: loss = 0.301359 * 100, metric = 8.93% * 100;
 Minibatch[1801-1900]: loss = 0.286901 * 100, metric = 8.65% * 100;
 Minibatch[1901-2000]: loss = 0.303476 * 100, metric = 9.27% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.303965 * 2000, metric = 9.23% * 2000 868.153s (  2.3 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 19.34% * 2000;
 Minibatch[   1- 100]: loss = 0.296165 * 100, metric = 8.88% * 100;
 Minibatch[ 101- 200]: loss = 0.289701 * 100, metric = 8.68% * 100;
 Minibatch[ 201- 300]: loss = 0.305853 * 100, metric = 9.36% * 100;
 Minibatch[ 301- 400]: loss = 0.301977 * 100, metric = 9.32% * 100;
 Minibatch[ 401- 500]: loss = 0.296882 * 100, metric = 9.08% * 100;
 Minibatch[ 501- 600]: loss = 0.296166 * 100, metric = 9.06% * 100;
 Minibatch[ 601- 700]: loss = 0.299034 * 100, metric = 8.97% * 100;
 Minibatch[ 701- 800]: loss = 0.309932 * 100, metric = 9.64% * 100;
 Minibatch[ 801- 900]: loss = 0.312515 * 100, metric = 9.76% * 100;
 Minibatch[ 901-1000]: loss = 0.299033 * 100, metric = 9.21% * 100;
 Minibatch[1001-1100]: loss = 0.304245 * 100, metric = 9.29% * 100;
 Minibatch[1101-1200]: loss = 0.298459 * 100, metric = 9.11% * 100;
 Minibatch[1201-1300]: loss = 0.282963 * 100, metric = 8.70% * 100;
 Minibatch[1301-1400]: loss = 0.299467 * 100, metric = 9.36% * 100;
 Minibatch[1401-1500]: loss = 0.298612 * 100, metric = 9.18% * 100;
 Minibatch[1501-1600]: loss = 0.291200 * 100, metric = 8.99% * 100;
 Minibatch[1601-1700]: loss = 0.295784 * 100, metric = 9.06% * 100;
 Minibatch[1701-1800]: loss = 0.289517 * 100, metric = 8.87% * 100;
 Minibatch[1801-1900]: loss = 0.298301 * 100, metric = 9.11% * 100;
 Minibatch[1901-2000]: loss = 0.297512 * 100, metric = 9.09% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.298166 * 2000, metric = 9.14% * 2000 868.149s (  2.3 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 19.32% * 2000;
 Minibatch[   1- 100]: loss = 0.285750 * 100, metric = 8.70% * 100;
 Minibatch[ 101- 200]: loss = 0.294334 * 100, metric = 9.01% * 100;
 Minibatch[ 201- 300]: loss = 0.298899 * 100, metric = 9.30% * 100;
 Minibatch[ 301- 400]: loss = 0.282167 * 100, metric = 8.45% * 100;
 Minibatch[ 401- 500]: loss = 0.288729 * 100, metric = 8.78% * 100;
 Minibatch[ 501- 600]: loss = 0.284390 * 100, metric = 8.59% * 100;
 Minibatch[ 601- 700]: loss = 0.276475 * 100, metric = 8.35% * 100;
 Minibatch[ 701- 800]: loss = 0.298159 * 100, metric = 9.26% * 100;
 Minibatch[ 801- 900]: loss = 0.302694 * 100, metric = 9.39% * 100;
 Minibatch[ 901-1000]: loss = 0.291976 * 100, metric = 9.05% * 100;
 Minibatch[1001-1100]: loss = 0.293314 * 100, metric = 8.99% * 100;
 Minibatch[1101-1200]: loss = 0.291373 * 100, metric = 8.83% * 100;
 Minibatch[1201-1300]: loss = 0.280769 * 100, metric = 8.65% * 100;
 Minibatch[1301-1400]: loss = 0.302693 * 100, metric = 9.38% * 100;
 Minibatch[1401-1500]: loss = 0.271801 * 100, metric = 8.26% * 100;
 Minibatch[1501-1600]: loss = 0.285804 * 100, metric = 8.80% * 100;
 Minibatch[1601-1700]: loss = 0.287345 * 100, metric = 8.83% * 100;
 Minibatch[1701-1800]: loss = 0.275428 * 100, metric = 8.21% * 100;
 Minibatch[1801-1900]: loss = 0.291572 * 100, metric = 8.93% * 100;
 Minibatch[1901-2000]: loss = 0.286706 * 100, metric = 8.64% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.288519 * 2000, metric = 8.82% * 2000 870.115s (  2.3 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 16.85% * 2000;
 Minibatch[   1- 100]: loss = 0.298776 * 100, metric = 9.33% * 100;
 Minibatch[ 101- 200]: loss = 0.290042 * 100, metric = 8.94% * 100;
 Minibatch[ 201- 300]: loss = 0.288768 * 100, metric = 8.81% * 100;
 Minibatch[ 301- 400]: loss = 0.295037 * 100, metric = 9.01% * 100;
 Minibatch[ 401- 500]: loss = 0.276693 * 100, metric = 8.44% * 100;
 Minibatch[ 501- 600]: loss = 0.290724 * 100, metric = 8.69% * 100;
 Minibatch[ 601- 700]: loss = 0.281896 * 100, metric = 8.66% * 100;
 Minibatch[ 701- 800]: loss = 0.284870 * 100, metric = 8.73% * 100;
 Minibatch[ 801- 900]: loss = 0.272572 * 100, metric = 8.27% * 100;
 Minibatch[ 901-1000]: loss = 0.284843 * 100, metric = 8.81% * 100;
 Minibatch[1001-1100]: loss = 0.274857 * 100, metric = 8.44% * 100;
 Minibatch[1101-1200]: loss = 0.284382 * 100, metric = 8.84% * 100;
 Minibatch[1201-1300]: loss = 0.272629 * 100, metric = 8.40% * 100;
 Minibatch[1301-1400]: loss = 0.277751 * 100, metric = 8.56% * 100;
 Minibatch[1401-1500]: loss = 0.277683 * 100, metric = 8.44% * 100;
 Minibatch[1501-1600]: loss = 0.277263 * 100, metric = 8.63% * 100;
 Minibatch[1601-1700]: loss = 0.281714 * 100, metric = 8.50% * 100;
 Minibatch[1701-1800]: loss = 0.294171 * 100, metric = 8.95% * 100;
 Minibatch[1801-1900]: loss = 0.288161 * 100, metric = 8.94% * 100;
 Minibatch[1901-2000]: loss = 0.274678 * 100, metric = 8.60% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.283376 * 2000, metric = 8.70% * 2000 871.740s (  2.3 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 16.34% * 2000;
0.4542543864957988
 Minibatch[   1- 100]: loss = 0.268661 * 100, metric = 8.01% * 100;
 Minibatch[ 101- 200]: loss = 0.288751 * 100, metric = 8.79% * 100;
 Minibatch[ 201- 300]: loss = 0.287200 * 100, metric = 8.70% * 100;
 Minibatch[ 301- 400]: loss = 0.278044 * 100, metric = 8.49% * 100;
 Minibatch[ 401- 500]: loss = 0.283924 * 100, metric = 8.55% * 100;
 Minibatch[ 501- 600]: loss = 0.275081 * 100, metric = 8.47% * 100;
 Minibatch[ 601- 700]: loss = 0.263931 * 100, metric = 7.95% * 100;
 Minibatch[ 701- 800]: loss = 0.275828 * 100, metric = 8.26% * 100;
 Minibatch[ 801- 900]: loss = 0.280207 * 100, metric = 8.49% * 100;
 Minibatch[ 901-1000]: loss = 0.273856 * 100, metric = 8.28% * 100;
 Minibatch[1001-1100]: loss = 0.266465 * 100, metric = 8.07% * 100;
 Minibatch[1101-1200]: loss = 0.280609 * 100, metric = 8.57% * 100;
 Minibatch[1201-1300]: loss = 0.271960 * 100, metric = 8.37% * 100;
 Minibatch[1301-1400]: loss = 0.263074 * 100, metric = 8.18% * 100;
 Minibatch[1401-1500]: loss = 0.274975 * 100, metric = 8.47% * 100;
 Minibatch[1501-1600]: loss = 0.274662 * 100, metric = 8.37% * 100;
 Minibatch[1601-1700]: loss = 0.271729 * 100, metric = 8.25% * 100;
 Minibatch[1701-1800]: loss = 0.266378 * 100, metric = 8.03% * 100;
 Minibatch[1801-1900]: loss = 0.280085 * 100, metric = 8.67% * 100;
 Minibatch[1901-2000]: loss = 0.283009 * 100, metric = 8.71% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.275422 * 2000, metric = 8.38% * 2000 852.719s (  2.3 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 16.16% * 2000;
 Minibatch[   1- 100]: loss = 0.265152 * 100, metric = 8.14% * 100;
 Minibatch[ 101- 200]: loss = 0.280540 * 100, metric = 8.53% * 100;
 Minibatch[ 201- 300]: loss = 0.265050 * 100, metric = 8.22% * 100;
 Minibatch[ 301- 400]: loss = 0.272147 * 100, metric = 8.38% * 100;
 Minibatch[ 401- 500]: loss = 0.259485 * 100, metric = 7.81% * 100;
 Minibatch[ 501- 600]: loss = 0.265902 * 100, metric = 8.02% * 100;
 Minibatch[ 601- 700]: loss = 0.269682 * 100, metric = 8.25% * 100;
 Minibatch[ 701- 800]: loss = 0.260954 * 100, metric = 8.08% * 100;
 Minibatch[ 801- 900]: loss = 0.274048 * 100, metric = 8.52% * 100;
 Minibatch[ 901-1000]: loss = 0.267261 * 100, metric = 8.09% * 100;
 Minibatch[1001-1100]: loss = 0.278137 * 100, metric = 8.60% * 100;
 Minibatch[1101-1200]: loss = 0.268179 * 100, metric = 8.27% * 100;
 Minibatch[1201-1300]: loss = 0.282726 * 100, metric = 8.61% * 100;
 Minibatch[1301-1400]: loss = 0.277195 * 100, metric = 8.37% * 100;
 Minibatch[1401-1500]: loss = 0.256876 * 100, metric = 7.83% * 100;
 Minibatch[1501-1600]: loss = 0.261124 * 100, metric = 7.73% * 100;
 Minibatch[1601-1700]: loss = 0.254936 * 100, metric = 7.78% * 100;
 Minibatch[1701-1800]: loss = 0.265150 * 100, metric = 8.27% * 100;
 Minibatch[1801-1900]: loss = 0.255616 * 100, metric = 7.90% * 100;
 Minibatch[1901-2000]: loss = 0.252186 * 100, metric = 7.66% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.266617 * 2000, metric = 8.15% * 2000 848.992s (  2.4 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 16.66% * 2000;
 Minibatch[   1- 100]: loss = 0.271986 * 100, metric = 8.33% * 100;
 Minibatch[ 101- 200]: loss = 0.275252 * 100, metric = 8.45% * 100;
 Minibatch[ 201- 300]: loss = 0.252205 * 100, metric = 7.53% * 100;
 Minibatch[ 301- 400]: loss = 0.271107 * 100, metric = 8.17% * 100;
 Minibatch[ 401- 500]: loss = 0.265207 * 100, metric = 8.00% * 100;
 Minibatch[ 501- 600]: loss = 0.255642 * 100, metric = 7.69% * 100;
 Minibatch[ 601- 700]: loss = 0.267666 * 100, metric = 8.22% * 100;
 Minibatch[ 701- 800]: loss = 0.257265 * 100, metric = 7.89% * 100;
 Minibatch[ 801- 900]: loss = 0.285935 * 100, metric = 8.71% * 100;
 Minibatch[ 901-1000]: loss = 0.253649 * 100, metric = 7.61% * 100;
 Minibatch[1001-1100]: loss = 0.266759 * 100, metric = 8.24% * 100;
 Minibatch[1101-1200]: loss = 0.263646 * 100, metric = 8.25% * 100;
 Minibatch[1201-1300]: loss = 0.258104 * 100, metric = 7.92% * 100;
 Minibatch[1301-1400]: loss = 0.257284 * 100, metric = 7.95% * 100;
 Minibatch[1401-1500]: loss = 0.263389 * 100, metric = 8.26% * 100;
 Minibatch[1501-1600]: loss = 0.260514 * 100, metric = 7.90% * 100;
 Minibatch[1601-1700]: loss = 0.255988 * 100, metric = 7.82% * 100;
 Minibatch[1701-1800]: loss = 0.245370 * 100, metric = 7.39% * 100;
 Minibatch[1801-1900]: loss = 0.251142 * 100, metric = 7.74% * 100;
 Minibatch[1901-2000]: loss = 0.246090 * 100, metric = 7.39% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.261210 * 2000, metric = 7.97% * 2000 1131.172s (  1.8 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 16.43% * 2000;
 Minibatch[   1- 100]: loss = 0.253775 * 100, metric = 7.77% * 100;
 Minibatch[ 101- 200]: loss = 0.253798 * 100, metric = 7.83% * 100;
 Minibatch[ 201- 300]: loss = 0.250274 * 100, metric = 7.67% * 100;
 Minibatch[ 301- 400]: loss = 0.264514 * 100, metric = 7.84% * 100;
 Minibatch[ 401- 500]: loss = 0.254553 * 100, metric = 7.69% * 100;
 Minibatch[ 501- 600]: loss = 0.251824 * 100, metric = 7.76% * 100;
 Minibatch[ 601- 700]: loss = 0.260509 * 100, metric = 8.06% * 100;
 Minibatch[ 701- 800]: loss = 0.253150 * 100, metric = 7.74% * 100;
 Minibatch[ 801- 900]: loss = 0.260480 * 100, metric = 8.02% * 100;
 Minibatch[ 901-1000]: loss = 0.259429 * 100, metric = 7.80% * 100;
 Minibatch[1001-1100]: loss = 0.239376 * 100, metric = 7.25% * 100;
 Minibatch[1101-1200]: loss = 0.247099 * 100, metric = 7.46% * 100;
 Minibatch[1201-1300]: loss = 0.255442 * 100, metric = 7.79% * 100;
 Minibatch[1301-1400]: loss = 0.260073 * 100, metric = 8.16% * 100;
 Minibatch[1401-1500]: loss = 0.251986 * 100, metric = 7.74% * 100;
 Minibatch[1501-1600]: loss = 0.261019 * 100, metric = 7.86% * 100;
 Minibatch[1601-1700]: loss = 0.251345 * 100, metric = 7.80% * 100;
 Minibatch[1701-1800]: loss = 0.256714 * 100, metric = 8.00% * 100;
 Minibatch[1801-1900]: loss = 0.251853 * 100, metric = 7.70% * 100;
 Minibatch[1901-2000]: loss = 0.252051 * 100, metric = 7.80% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.254463 * 2000, metric = 7.79% * 2000 1141.991s (  1.8 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 17.42% * 2000;
 Minibatch[   1- 100]: loss = 0.254015 * 100, metric = 7.69% * 100;
 Minibatch[ 101- 200]: loss = 0.251471 * 100, metric = 7.72% * 100;
 Minibatch[ 201- 300]: loss = 0.246340 * 100, metric = 7.48% * 100;
 Minibatch[ 301- 400]: loss = 0.251769 * 100, metric = 7.68% * 100;
 Minibatch[ 401- 500]: loss = 0.242081 * 100, metric = 7.35% * 100;
 Minibatch[ 501- 600]: loss = 0.241764 * 100, metric = 7.40% * 100;
 Minibatch[ 601- 700]: loss = 0.242081 * 100, metric = 7.26% * 100;
 Minibatch[ 701- 800]: loss = 0.226362 * 100, metric = 6.82% * 100;
 Minibatch[ 801- 900]: loss = 0.246851 * 100, metric = 7.36% * 100;
 Minibatch[ 901-1000]: loss = 0.237152 * 100, metric = 7.14% * 100;
 Minibatch[1001-1100]: loss = 0.242969 * 100, metric = 7.39% * 100;
 Minibatch[1101-1200]: loss = 0.242291 * 100, metric = 7.18% * 100;
 Minibatch[1201-1300]: loss = 0.247650 * 100, metric = 7.62% * 100;
 Minibatch[1301-1400]: loss = 0.234333 * 100, metric = 7.05% * 100;
 Minibatch[1401-1500]: loss = 0.247543 * 100, metric = 7.46% * 100;
 Minibatch[1501-1600]: loss = 0.257632 * 100, metric = 7.94% * 100;
 Minibatch[1601-1700]: loss = 0.243315 * 100, metric = 7.42% * 100;
 Minibatch[1701-1800]: loss = 0.241070 * 100, metric = 7.39% * 100;
 Minibatch[1801-1900]: loss = 0.258087 * 100, metric = 7.99% * 100;
 Minibatch[1901-2000]: loss = 0.239488 * 100, metric = 7.07% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.244713 * 2000, metric = 7.42% * 2000 925.269s (  2.2 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 15.23% * 2000;
0.45135533725097776
 Minibatch[   1- 100]: loss = 0.246578 * 100, metric = 7.43% * 100;
 Minibatch[ 101- 200]: loss = 0.243192 * 100, metric = 7.25% * 100;
 Minibatch[ 201- 300]: loss = 0.251773 * 100, metric = 7.83% * 100;
 Minibatch[ 301- 400]: loss = 0.236081 * 100, metric = 7.15% * 100;
 Minibatch[ 401- 500]: loss = 0.237836 * 100, metric = 7.09% * 100;
 Minibatch[ 501- 600]: loss = 0.248654 * 100, metric = 7.49% * 100;
 Minibatch[ 601- 700]: loss = 0.235212 * 100, metric = 7.08% * 100;
 Minibatch[ 701- 800]: loss = 0.237020 * 100, metric = 7.31% * 100;
 Minibatch[ 801- 900]: loss = 0.247955 * 100, metric = 7.51% * 100;
 Minibatch[ 901-1000]: loss = 0.249019 * 100, metric = 7.60% * 100;
 Minibatch[1001-1100]: loss = 0.236145 * 100, metric = 6.98% * 100;
 Minibatch[1101-1200]: loss = 0.222444 * 100, metric = 6.78% * 100;
 Minibatch[1201-1300]: loss = 0.234706 * 100, metric = 6.91% * 100;
 Minibatch[1301-1400]: loss = 0.241491 * 100, metric = 7.31% * 100;
 Minibatch[1401-1500]: loss = 0.238424 * 100, metric = 7.21% * 100;
 Minibatch[1501-1600]: loss = 0.232448 * 100, metric = 6.95% * 100;
 Minibatch[1601-1700]: loss = 0.231798 * 100, metric = 6.89% * 100;
 Minibatch[1701-1800]: loss = 0.235825 * 100, metric = 7.05% * 100;
 Minibatch[1801-1900]: loss = 0.235726 * 100, metric = 7.08% * 100;
 Minibatch[1901-2000]: loss = 0.235935 * 100, metric = 6.93% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.238913 * 2000, metric = 7.19% * 2000 904.041s (  2.2 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 16.11% * 2000;
 Minibatch[   1- 100]: loss = 0.241114 * 100, metric = 7.23% * 100;
 Minibatch[ 101- 200]: loss = 0.249490 * 100, metric = 7.68% * 100;
 Minibatch[ 201- 300]: loss = 0.235588 * 100, metric = 7.17% * 100;
 Minibatch[ 301- 400]: loss = 0.241395 * 100, metric = 7.16% * 100;
 Minibatch[ 401- 500]: loss = 0.242811 * 100, metric = 7.41% * 100;
 Minibatch[ 501- 600]: loss = 0.237995 * 100, metric = 7.21% * 100;
 Minibatch[ 601- 700]: loss = 0.234307 * 100, metric = 6.93% * 100;
 Minibatch[ 701- 800]: loss = 0.225574 * 100, metric = 6.78% * 100;
 Minibatch[ 801- 900]: loss = 0.225283 * 100, metric = 6.90% * 100;
 Minibatch[ 901-1000]: loss = 0.239776 * 100, metric = 7.32% * 100;
 Minibatch[1001-1100]: loss = 0.235173 * 100, metric = 6.91% * 100;
 Minibatch[1101-1200]: loss = 0.234852 * 100, metric = 7.27% * 100;
 Minibatch[1201-1300]: loss = 0.233674 * 100, metric = 7.19% * 100;
 Minibatch[1301-1400]: loss = 0.240195 * 100, metric = 7.43% * 100;
 Minibatch[1401-1500]: loss = 0.232981 * 100, metric = 7.17% * 100;
 Minibatch[1501-1600]: loss = 0.230398 * 100, metric = 7.02% * 100;
 Minibatch[1601-1700]: loss = 0.230868 * 100, metric = 7.11% * 100;
 Minibatch[1701-1800]: loss = 0.239806 * 100, metric = 7.26% * 100;
 Minibatch[1801-1900]: loss = 0.239156 * 100, metric = 7.47% * 100;
 Minibatch[1901-2000]: loss = 0.236424 * 100, metric = 7.35% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.236343 * 2000, metric = 7.20% * 2000 813.099s (  2.5 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 16.24% * 2000;
 Minibatch[   1- 100]: loss = 0.225060 * 100, metric = 6.80% * 100;
 Minibatch[ 101- 200]: loss = 0.236593 * 100, metric = 7.45% * 100;
 Minibatch[ 201- 300]: loss = 0.231612 * 100, metric = 7.16% * 100;
 Minibatch[ 301- 400]: loss = 0.226947 * 100, metric = 7.01% * 100;
 Minibatch[ 401- 500]: loss = 0.232552 * 100, metric = 7.13% * 100;
 Minibatch[ 501- 600]: loss = 0.225607 * 100, metric = 6.92% * 100;
 Minibatch[ 601- 700]: loss = 0.233250 * 100, metric = 7.01% * 100;
 Minibatch[ 701- 800]: loss = 0.224574 * 100, metric = 6.91% * 100;
 Minibatch[ 801- 900]: loss = 0.234403 * 100, metric = 7.39% * 100;
 Minibatch[ 901-1000]: loss = 0.225023 * 100, metric = 6.84% * 100;
 Minibatch[1001-1100]: loss = 0.232258 * 100, metric = 7.18% * 100;
 Minibatch[1101-1200]: loss = 0.244339 * 100, metric = 7.31% * 100;
 Minibatch[1201-1300]: loss = 0.236111 * 100, metric = 7.38% * 100;
 Minibatch[1301-1400]: loss = 0.228220 * 100, metric = 6.98% * 100;
 Minibatch[1401-1500]: loss = 0.224629 * 100, metric = 6.69% * 100;
 Minibatch[1501-1600]: loss = 0.237751 * 100, metric = 7.24% * 100;
 Minibatch[1601-1700]: loss = 0.222239 * 100, metric = 6.61% * 100;
 Minibatch[1701-1800]: loss = 0.229432 * 100, metric = 6.89% * 100;
 Minibatch[1801-1900]: loss = 0.230443 * 100, metric = 7.06% * 100;
 Minibatch[1901-2000]: loss = 0.236182 * 100, metric = 7.36% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.230861 * 2000, metric = 7.07% * 2000 814.481s (  2.5 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 15.51% * 2000;
0.4496303282305598
 Minibatch[   1- 100]: loss = 0.228859 * 100, metric = 6.89% * 100;
 Minibatch[ 101- 200]: loss = 0.231251 * 100, metric = 7.04% * 100;
 Minibatch[ 201- 300]: loss = 0.228008 * 100, metric = 6.93% * 100;
 Minibatch[ 301- 400]: loss = 0.231785 * 100, metric = 6.97% * 100;
 Minibatch[ 401- 500]: loss = 0.229576 * 100, metric = 6.74% * 100;
 Minibatch[ 501- 600]: loss = 0.230928 * 100, metric = 7.09% * 100;
 Minibatch[ 601- 700]: loss = 0.231385 * 100, metric = 7.07% * 100;
 Minibatch[ 701- 800]: loss = 0.225727 * 100, metric = 6.75% * 100;
 Minibatch[ 801- 900]: loss = 0.221171 * 100, metric = 6.65% * 100;
 Minibatch[ 901-1000]: loss = 0.230439 * 100, metric = 7.07% * 100;
 Minibatch[1001-1100]: loss = 0.231899 * 100, metric = 7.08% * 100;
 Minibatch[1101-1200]: loss = 0.230299 * 100, metric = 7.03% * 100;
 Minibatch[1201-1300]: loss = 0.243022 * 100, metric = 7.45% * 100;
 Minibatch[1301-1400]: loss = 0.224990 * 100, metric = 6.83% * 100;
 Minibatch[1401-1500]: loss = 0.218864 * 100, metric = 6.52% * 100;
 Minibatch[1501-1600]: loss = 0.233979 * 100, metric = 7.16% * 100;
 Minibatch[1601-1700]: loss = 0.224016 * 100, metric = 6.80% * 100;
 Minibatch[1701-1800]: loss = 0.227196 * 100, metric = 6.92% * 100;
 Minibatch[1801-1900]: loss = 0.218843 * 100, metric = 6.56% * 100;
 Minibatch[1901-2000]: loss = 0.215298 * 100, metric = 6.55% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.227877 * 2000, metric = 6.91% * 2000 805.597s (  2.5 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 15.87% * 2000;
 Minibatch[   1- 100]: loss = 0.226227 * 100, metric = 6.73% * 100;
 Minibatch[ 101- 200]: loss = 0.215263 * 100, metric = 6.51% * 100;
 Minibatch[ 201- 300]: loss = 0.224478 * 100, metric = 6.85% * 100;
 Minibatch[ 301- 400]: loss = 0.216514 * 100, metric = 6.61% * 100;
 Minibatch[ 401- 500]: loss = 0.225098 * 100, metric = 6.72% * 100;
 Minibatch[ 501- 600]: loss = 0.218839 * 100, metric = 6.55% * 100;
 Minibatch[ 601- 700]: loss = 0.232238 * 100, metric = 6.92% * 100;
 Minibatch[ 701- 800]: loss = 0.216529 * 100, metric = 6.69% * 100;
 Minibatch[ 801- 900]: loss = 0.209453 * 100, metric = 6.34% * 100;
 Minibatch[ 901-1000]: loss = 0.221189 * 100, metric = 6.72% * 100;
 Minibatch[1001-1100]: loss = 0.229549 * 100, metric = 7.18% * 100;
 Minibatch[1101-1200]: loss = 0.225775 * 100, metric = 6.90% * 100;
 Minibatch[1201-1300]: loss = 0.223151 * 100, metric = 6.81% * 100;
 Minibatch[1301-1400]: loss = 0.211608 * 100, metric = 6.31% * 100;
 Minibatch[1401-1500]: loss = 0.221898 * 100, metric = 6.75% * 100;
 Minibatch[1501-1600]: loss = 0.212491 * 100, metric = 6.35% * 100;
 Minibatch[1601-1700]: loss = 0.231627 * 100, metric = 7.01% * 100;
 Minibatch[1701-1800]: loss = 0.226073 * 100, metric = 6.96% * 100;
 Minibatch[1801-1900]: loss = 0.216184 * 100, metric = 6.54% * 100;
 Minibatch[1901-2000]: loss = 0.219984 * 100, metric = 6.62% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.221208 * 2000, metric = 6.70% * 2000 992.065s (  2.0 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 16.44% * 2000;
 Minibatch[   1- 100]: loss = 0.220706 * 100, metric = 6.58% * 100;
 Minibatch[ 101- 200]: loss = 0.228659 * 100, metric = 6.69% * 100;
 Minibatch[ 201- 300]: loss = 0.214603 * 100, metric = 6.55% * 100;
 Minibatch[ 301- 400]: loss = 0.212256 * 100, metric = 6.50% * 100;
 Minibatch[ 401- 500]: loss = 0.216634 * 100, metric = 6.48% * 100;
 Minibatch[ 501- 600]: loss = 0.216653 * 100, metric = 6.47% * 100;
 Minibatch[ 601- 700]: loss = 0.209735 * 100, metric = 6.43% * 100;
 Minibatch[ 701- 800]: loss = 0.216357 * 100, metric = 6.54% * 100;
 Minibatch[ 801- 900]: loss = 0.225673 * 100, metric = 6.83% * 100;
 Minibatch[ 901-1000]: loss = 0.221049 * 100, metric = 6.91% * 100;
 Minibatch[1001-1100]: loss = 0.216230 * 100, metric = 6.59% * 100;
 Minibatch[1101-1200]: loss = 0.227428 * 100, metric = 6.95% * 100;
 Minibatch[1201-1300]: loss = 0.218256 * 100, metric = 6.59% * 100;
 Minibatch[1301-1400]: loss = 0.225234 * 100, metric = 7.00% * 100;
 Minibatch[1401-1500]: loss = 0.212703 * 100, metric = 6.51% * 100;
 Minibatch[1501-1600]: loss = 0.215348 * 100, metric = 6.56% * 100;
 Minibatch[1601-1700]: loss = 0.204976 * 100, metric = 6.03% * 100;
 Minibatch[1701-1800]: loss = 0.215337 * 100, metric = 6.38% * 100;
 Minibatch[1801-1900]: loss = 0.214345 * 100, metric = 6.46% * 100;
 Minibatch[1901-2000]: loss = 0.220237 * 100, metric = 6.63% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.217621 * 2000, metric = 6.58% * 2000 808.276s (  2.5 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 15.13% * 2000;
 Minibatch[   1- 100]: loss = 0.221876 * 100, metric = 6.92% * 100;
 Minibatch[ 101- 200]: loss = 0.210397 * 100, metric = 6.37% * 100;
 Minibatch[ 201- 300]: loss = 0.223601 * 100, metric = 6.74% * 100;
 Minibatch[ 301- 400]: loss = 0.219043 * 100, metric = 6.59% * 100;
 Minibatch[ 401- 500]: loss = 0.214652 * 100, metric = 6.43% * 100;
 Minibatch[ 501- 600]: loss = 0.225764 * 100, metric = 7.05% * 100;
 Minibatch[ 601- 700]: loss = 0.210416 * 100, metric = 6.33% * 100;
 Minibatch[ 701- 800]: loss = 0.202254 * 100, metric = 6.11% * 100;
 Minibatch[ 801- 900]: loss = 0.215678 * 100, metric = 6.61% * 100;
 Minibatch[ 901-1000]: loss = 0.224010 * 100, metric = 6.84% * 100;
 Minibatch[1001-1100]: loss = 0.215303 * 100, metric = 6.54% * 100;
 Minibatch[1101-1200]: loss = 0.209161 * 100, metric = 6.30% * 100;
 Minibatch[1201-1300]: loss = 0.214396 * 100, metric = 6.51% * 100;
 Minibatch[1301-1400]: loss = 0.204605 * 100, metric = 6.25% * 100;
 Minibatch[1401-1500]: loss = 0.216433 * 100, metric = 6.54% * 100;
 Minibatch[1501-1600]: loss = 0.209595 * 100, metric = 6.29% * 100;
 Minibatch[1601-1700]: loss = 0.211300 * 100, metric = 6.34% * 100;
 Minibatch[1701-1800]: loss = 0.202212 * 100, metric = 6.23% * 100;
 Minibatch[1801-1900]: loss = 0.216258 * 100, metric = 6.64% * 100;
 Minibatch[1901-2000]: loss = 0.209843 * 100, metric = 6.38% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.213840 * 2000, metric = 6.50% * 2000 802.843s (  2.5 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 14.76% * 2000;
0.44596044697612525
 Minibatch[   1- 100]: loss = 0.199506 * 100, metric = 6.00% * 100;
 Minibatch[ 101- 200]: loss = 0.209753 * 100, metric = 6.34% * 100;
 Minibatch[ 201- 300]: loss = 0.210630 * 100, metric = 6.57% * 100;
 Minibatch[ 301- 400]: loss = 0.222282 * 100, metric = 6.84% * 100;
 Minibatch[ 401- 500]: loss = 0.199635 * 100, metric = 6.16% * 100;
 Minibatch[ 501- 600]: loss = 0.207708 * 100, metric = 6.18% * 100;
 Minibatch[ 601- 700]: loss = 0.215495 * 100, metric = 6.66% * 100;
 Minibatch[ 701- 800]: loss = 0.219428 * 100, metric = 6.83% * 100;
 Minibatch[ 801- 900]: loss = 0.211234 * 100, metric = 6.47% * 100;
 Minibatch[ 901-1000]: loss = 0.214841 * 100, metric = 6.62% * 100;
 Minibatch[1001-1100]: loss = 0.213729 * 100, metric = 6.56% * 100;
 Minibatch[1101-1200]: loss = 0.205694 * 100, metric = 6.30% * 100;
 Minibatch[1201-1300]: loss = 0.210277 * 100, metric = 6.29% * 100;
 Minibatch[1301-1400]: loss = 0.202563 * 100, metric = 6.26% * 100;
 Minibatch[1401-1500]: loss = 0.214411 * 100, metric = 6.48% * 100;
 Minibatch[1501-1600]: loss = 0.204884 * 100, metric = 6.20% * 100;
 Minibatch[1601-1700]: loss = 0.216165 * 100, metric = 6.79% * 100;
 Minibatch[1701-1800]: loss = 0.205638 * 100, metric = 6.39% * 100;
 Minibatch[1801-1900]: loss = 0.214352 * 100, metric = 6.57% * 100;
 Minibatch[1901-2000]: loss = 0.212072 * 100, metric = 6.52% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.210515 * 2000, metric = 6.45% * 2000 803.739s (  2.5 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 16.11% * 2000;
 Minibatch[   1- 100]: loss = 0.217319 * 100, metric = 6.64% * 100;
 Minibatch[ 101- 200]: loss = 0.198501 * 100, metric = 6.01% * 100;
 Minibatch[ 201- 300]: loss = 0.206395 * 100, metric = 6.24% * 100;
 Minibatch[ 301- 400]: loss = 0.209067 * 100, metric = 6.56% * 100;
 Minibatch[ 401- 500]: loss = 0.208451 * 100, metric = 6.38% * 100;
 Minibatch[ 501- 600]: loss = 0.190135 * 100, metric = 5.80% * 100;
 Minibatch[ 601- 700]: loss = 0.206861 * 100, metric = 6.36% * 100;
 Minibatch[ 701- 800]: loss = 0.201339 * 100, metric = 6.14% * 100;
 Minibatch[ 801- 900]: loss = 0.212698 * 100, metric = 6.36% * 100;
 Minibatch[ 901-1000]: loss = 0.196482 * 100, metric = 5.99% * 100;
 Minibatch[1001-1100]: loss = 0.208870 * 100, metric = 6.27% * 100;
 Minibatch[1101-1200]: loss = 0.210117 * 100, metric = 6.46% * 100;
 Minibatch[1201-1300]: loss = 0.203547 * 100, metric = 6.15% * 100;
 Minibatch[1301-1400]: loss = 0.205840 * 100, metric = 6.26% * 100;
 Minibatch[1401-1500]: loss = 0.207047 * 100, metric = 6.31% * 100;
 Minibatch[1501-1600]: loss = 0.208384 * 100, metric = 6.37% * 100;
 Minibatch[1601-1700]: loss = 0.202835 * 100, metric = 6.08% * 100;
 Minibatch[1701-1800]: loss = 0.207379 * 100, metric = 6.40% * 100;
 Minibatch[1801-1900]: loss = 0.206934 * 100, metric = 6.28% * 100;
 Minibatch[1901-2000]: loss = 0.219373 * 100, metric = 6.79% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.206379 * 2000, metric = 6.29% * 2000 797.755s (  2.5 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 15.54% * 2000;
 Minibatch[   1- 100]: loss = 0.202795 * 100, metric = 6.21% * 100;
 Minibatch[ 101- 200]: loss = 0.217303 * 100, metric = 6.72% * 100;
 Minibatch[ 201- 300]: loss = 0.206900 * 100, metric = 6.35% * 100;
 Minibatch[ 301- 400]: loss = 0.200140 * 100, metric = 6.08% * 100;
 Minibatch[ 401- 500]: loss = 0.208340 * 100, metric = 6.36% * 100;
 Minibatch[ 501- 600]: loss = 0.201987 * 100, metric = 6.09% * 100;
 Minibatch[ 601- 700]: loss = 0.213310 * 100, metric = 6.64% * 100;
 Minibatch[ 701- 800]: loss = 0.210327 * 100, metric = 6.44% * 100;
 Minibatch[ 801- 900]: loss = 0.206327 * 100, metric = 6.40% * 100;
 Minibatch[ 901-1000]: loss = 0.203977 * 100, metric = 6.30% * 100;
 Minibatch[1001-1100]: loss = 0.198069 * 100, metric = 6.14% * 100;
 Minibatch[1101-1200]: loss = 0.206708 * 100, metric = 6.57% * 100;
 Minibatch[1201-1300]: loss = 0.200289 * 100, metric = 6.21% * 100;
 Minibatch[1301-1400]: loss = 0.205665 * 100, metric = 6.30% * 100;
 Minibatch[1401-1500]: loss = 0.209244 * 100, metric = 6.42% * 100;
 Minibatch[1501-1600]: loss = 0.197858 * 100, metric = 6.00% * 100;
 Minibatch[1601-1700]: loss = 0.204670 * 100, metric = 6.32% * 100;
 Minibatch[1701-1800]: loss = 0.199175 * 100, metric = 6.12% * 100;
 Minibatch[1801-1900]: loss = 0.206025 * 100, metric = 6.23% * 100;
 Minibatch[1901-2000]: loss = 0.205500 * 100, metric = 6.38% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.205230 * 2000, metric = 6.31% * 2000 793.154s (  2.5 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 15.27% * 2000;
 Minibatch[   1- 100]: loss = 0.199929 * 100, metric = 6.06% * 100;
 Minibatch[ 101- 200]: loss = 0.203156 * 100, metric = 6.17% * 100;
 Minibatch[ 201- 300]: loss = 0.213194 * 100, metric = 6.62% * 100;
 Minibatch[ 301- 400]: loss = 0.209351 * 100, metric = 6.34% * 100;
 Minibatch[ 401- 500]: loss = 0.210396 * 100, metric = 6.54% * 100;
 Minibatch[ 501- 600]: loss = 0.204175 * 100, metric = 6.28% * 100;
 Minibatch[ 601- 700]: loss = 0.202512 * 100, metric = 6.22% * 100;
 Minibatch[ 701- 800]: loss = 0.198827 * 100, metric = 6.04% * 100;
 Minibatch[ 801- 900]: loss = 0.203737 * 100, metric = 6.34% * 100;
 Minibatch[ 901-1000]: loss = 0.193572 * 100, metric = 5.74% * 100;
 Minibatch[1001-1100]: loss = 0.190212 * 100, metric = 5.72% * 100;
 Minibatch[1101-1200]: loss = 0.204139 * 100, metric = 6.25% * 100;
 Minibatch[1201-1300]: loss = 0.209931 * 100, metric = 6.50% * 100;
 Minibatch[1301-1400]: loss = 0.203291 * 100, metric = 6.18% * 100;
 Minibatch[1401-1500]: loss = 0.207465 * 100, metric = 6.40% * 100;
 Minibatch[1501-1600]: loss = 0.207771 * 100, metric = 6.32% * 100;
 Minibatch[1601-1700]: loss = 0.198824 * 100, metric = 6.09% * 100;
 Minibatch[1701-1800]: loss = 0.207923 * 100, metric = 6.44% * 100;
 Minibatch[1801-1900]: loss = 0.199025 * 100, metric = 6.16% * 100;
 Minibatch[1901-2000]: loss = 0.202835 * 100, metric = 6.45% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.203513 * 2000, metric = 6.24% * 2000 795.686s (  2.5 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 14.59% * 2000;
 Minibatch[   1- 100]: loss = 0.213737 * 100, metric = 6.41% * 100;
 Minibatch[ 101- 200]: loss = 0.199723 * 100, metric = 6.06% * 100;
 Minibatch[ 201- 300]: loss = 0.195242 * 100, metric = 5.94% * 100;
 Minibatch[ 301- 400]: loss = 0.207096 * 100, metric = 6.50% * 100;
 Minibatch[ 401- 500]: loss = 0.195394 * 100, metric = 6.01% * 100;
 Minibatch[ 501- 600]: loss = 0.203483 * 100, metric = 6.21% * 100;
 Minibatch[ 601- 700]: loss = 0.204158 * 100, metric = 6.24% * 100;
 Minibatch[ 701- 800]: loss = 0.195954 * 100, metric = 6.10% * 100;
 Minibatch[ 801- 900]: loss = 0.197102 * 100, metric = 6.05% * 100;
 Minibatch[ 901-1000]: loss = 0.189052 * 100, metric = 5.77% * 100;
 Minibatch[1001-1100]: loss = 0.196808 * 100, metric = 6.06% * 100;
 Minibatch[1101-1200]: loss = 0.195436 * 100, metric = 6.11% * 100;
 Minibatch[1201-1300]: loss = 0.211935 * 100, metric = 6.47% * 100;
 Minibatch[1301-1400]: loss = 0.189264 * 100, metric = 5.73% * 100;
 Minibatch[1401-1500]: loss = 0.216905 * 100, metric = 6.57% * 100;
 Minibatch[1501-1600]: loss = 0.206422 * 100, metric = 6.30% * 100;
 Minibatch[1601-1700]: loss = 0.194359 * 100, metric = 5.87% * 100;
 Minibatch[1701-1800]: loss = 0.190099 * 100, metric = 5.75% * 100;
 Minibatch[1801-1900]: loss = 0.188465 * 100, metric = 5.67% * 100;
 Minibatch[1901-2000]: loss = 0.207652 * 100, metric = 6.35% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.199914 * 2000, metric = 6.11% * 2000 795.942s (  2.5 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 14.89% * 2000;
 Minibatch[   1- 100]: loss = 0.194771 * 100, metric = 6.05% * 100;
 Minibatch[ 101- 200]: loss = 0.199700 * 100, metric = 6.06% * 100;
 Minibatch[ 201- 300]: loss = 0.190519 * 100, metric = 5.82% * 100;
 Minibatch[ 301- 400]: loss = 0.201470 * 100, metric = 6.12% * 100;
 Minibatch[ 401- 500]: loss = 0.197997 * 100, metric = 6.00% * 100;
 Minibatch[ 501- 600]: loss = 0.195408 * 100, metric = 5.87% * 100;
 Minibatch[ 601- 700]: loss = 0.196229 * 100, metric = 6.02% * 100;
 Minibatch[ 701- 800]: loss = 0.196694 * 100, metric = 6.14% * 100;
 Minibatch[ 801- 900]: loss = 0.183226 * 100, metric = 5.41% * 100;
 Minibatch[ 901-1000]: loss = 0.191498 * 100, metric = 5.93% * 100;
 Minibatch[1001-1100]: loss = 0.200343 * 100, metric = 6.18% * 100;
 Minibatch[1101-1200]: loss = 0.190935 * 100, metric = 5.92% * 100;
 Minibatch[1201-1300]: loss = 0.193399 * 100, metric = 5.96% * 100;
 Minibatch[1301-1400]: loss = 0.191782 * 100, metric = 5.88% * 100;
 Minibatch[1401-1500]: loss = 0.198801 * 100, metric = 6.09% * 100;
 Minibatch[1501-1600]: loss = 0.192338 * 100, metric = 5.93% * 100;
 Minibatch[1601-1700]: loss = 0.201657 * 100, metric = 6.30% * 100;
 Minibatch[1701-1800]: loss = 0.195728 * 100, metric = 6.15% * 100;
 Minibatch[1801-1900]: loss = 0.195675 * 100, metric = 6.06% * 100;
 Minibatch[1901-2000]: loss = 0.195838 * 100, metric = 5.94% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.195200 * 2000, metric = 5.99% * 2000 797.244s (  2.5 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.67% * 2000;
 Minibatch[   1- 100]: loss = 0.183554 * 100, metric = 5.61% * 100;
 Minibatch[ 101- 200]: loss = 0.195727 * 100, metric = 6.11% * 100;
 Minibatch[ 201- 300]: loss = 0.192719 * 100, metric = 5.88% * 100;
 Minibatch[ 301- 400]: loss = 0.180635 * 100, metric = 5.44% * 100;
 Minibatch[ 401- 500]: loss = 0.187954 * 100, metric = 5.76% * 100;
 Minibatch[ 501- 600]: loss = 0.181217 * 100, metric = 5.42% * 100;
 Minibatch[ 601- 700]: loss = 0.194540 * 100, metric = 6.08% * 100;
 Minibatch[ 701- 800]: loss = 0.182892 * 100, metric = 5.61% * 100;
 Minibatch[ 801- 900]: loss = 0.197158 * 100, metric = 6.09% * 100;
 Minibatch[ 901-1000]: loss = 0.184352 * 100, metric = 5.56% * 100;
 Minibatch[1001-1100]: loss = 0.198062 * 100, metric = 6.07% * 100;
 Minibatch[1101-1200]: loss = 0.187889 * 100, metric = 5.72% * 100;
 Minibatch[1201-1300]: loss = 0.193808 * 100, metric = 6.05% * 100;
 Minibatch[1301-1400]: loss = 0.191341 * 100, metric = 5.85% * 100;
 Minibatch[1401-1500]: loss = 0.180999 * 100, metric = 5.44% * 100;
 Minibatch[1501-1600]: loss = 0.192038 * 100, metric = 5.99% * 100;
 Minibatch[1601-1700]: loss = 0.191299 * 100, metric = 5.84% * 100;
 Minibatch[1701-1800]: loss = 0.185669 * 100, metric = 5.61% * 100;
 Minibatch[1801-1900]: loss = 0.198187 * 100, metric = 6.12% * 100;
 Minibatch[1901-2000]: loss = 0.183323 * 100, metric = 5.70% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.189168 * 2000, metric = 5.80% * 2000 788.682s (  2.5 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 14.28% * 2000;
 Minibatch[   1- 100]: loss = 0.185207 * 100, metric = 5.53% * 100;
 Minibatch[ 101- 200]: loss = 0.179717 * 100, metric = 5.48% * 100;
 Minibatch[ 201- 300]: loss = 0.196661 * 100, metric = 6.05% * 100;
 Minibatch[ 301- 400]: loss = 0.184923 * 100, metric = 5.62% * 100;
 Minibatch[ 401- 500]: loss = 0.181269 * 100, metric = 5.43% * 100;
 Minibatch[ 501- 600]: loss = 0.182080 * 100, metric = 5.74% * 100;
 Minibatch[ 601- 700]: loss = 0.186481 * 100, metric = 5.54% * 100;
 Minibatch[ 701- 800]: loss = 0.173133 * 100, metric = 5.20% * 100;
 Minibatch[ 801- 900]: loss = 0.181400 * 100, metric = 5.53% * 100;
 Minibatch[ 901-1000]: loss = 0.187197 * 100, metric = 5.78% * 100;
 Minibatch[1001-1100]: loss = 0.197744 * 100, metric = 6.13% * 100;
 Minibatch[1101-1200]: loss = 0.185393 * 100, metric = 5.80% * 100;
 Minibatch[1201-1300]: loss = 0.189265 * 100, metric = 5.90% * 100;
 Minibatch[1301-1400]: loss = 0.175356 * 100, metric = 5.48% * 100;
 Minibatch[1401-1500]: loss = 0.185655 * 100, metric = 5.72% * 100;
 Minibatch[1501-1600]: loss = 0.186583 * 100, metric = 5.73% * 100;
 Minibatch[1601-1700]: loss = 0.193713 * 100, metric = 6.04% * 100;
 Minibatch[1701-1800]: loss = 0.188719 * 100, metric = 5.87% * 100;
 Minibatch[1801-1900]: loss = 0.186356 * 100, metric = 5.67% * 100;
 Minibatch[1901-2000]: loss = 0.183532 * 100, metric = 5.60% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.185519 * 2000, metric = 5.69% * 2000 793.533s (  2.5 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 14.21% * 2000;
 Minibatch[   1- 100]: loss = 0.188493 * 100, metric = 5.69% * 100;
 Minibatch[ 101- 200]: loss = 0.192912 * 100, metric = 6.02% * 100;
 Minibatch[ 201- 300]: loss = 0.187329 * 100, metric = 5.73% * 100;
 Minibatch[ 301- 400]: loss = 0.185385 * 100, metric = 5.69% * 100;
 Minibatch[ 401- 500]: loss = 0.188959 * 100, metric = 5.77% * 100;
 Minibatch[ 501- 600]: loss = 0.182020 * 100, metric = 5.58% * 100;
 Minibatch[ 601- 700]: loss = 0.182779 * 100, metric = 5.71% * 100;
 Minibatch[ 701- 800]: loss = 0.193421 * 100, metric = 6.10% * 100;
 Minibatch[ 801- 900]: loss = 0.182383 * 100, metric = 5.60% * 100;
 Minibatch[ 901-1000]: loss = 0.176310 * 100, metric = 5.37% * 100;
 Minibatch[1001-1100]: loss = 0.177988 * 100, metric = 5.62% * 100;
 Minibatch[1101-1200]: loss = 0.198733 * 100, metric = 6.28% * 100;
 Minibatch[1201-1300]: loss = 0.194506 * 100, metric = 5.94% * 100;
 Minibatch[1301-1400]: loss = 0.182448 * 100, metric = 5.59% * 100;
 Minibatch[1401-1500]: loss = 0.186462 * 100, metric = 5.78% * 100;
 Minibatch[1501-1600]: loss = 0.182677 * 100, metric = 5.47% * 100;
 Minibatch[1601-1700]: loss = 0.187444 * 100, metric = 5.81% * 100;
 Minibatch[1701-1800]: loss = 0.180332 * 100, metric = 5.56% * 100;
 Minibatch[1801-1900]: loss = 0.184994 * 100, metric = 5.76% * 100;
 Minibatch[1901-2000]: loss = 0.184711 * 100, metric = 5.61% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.186014 * 2000, metric = 5.73% * 2000 789.752s (  2.5 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 14.23% * 2000;
 Minibatch[   1- 100]: loss = 0.187480 * 100, metric = 5.71% * 100;
 Minibatch[ 101- 200]: loss = 0.185869 * 100, metric = 5.80% * 100;
 Minibatch[ 201- 300]: loss = 0.172632 * 100, metric = 5.18% * 100;
 Minibatch[ 301- 400]: loss = 0.178207 * 100, metric = 5.66% * 100;
 Minibatch[ 401- 500]: loss = 0.181462 * 100, metric = 5.64% * 100;
 Minibatch[ 501- 600]: loss = 0.182256 * 100, metric = 5.59% * 100;
 Minibatch[ 601- 700]: loss = 0.187418 * 100, metric = 5.89% * 100;
 Minibatch[ 701- 800]: loss = 0.182712 * 100, metric = 5.66% * 100;
 Minibatch[ 801- 900]: loss = 0.182383 * 100, metric = 5.57% * 100;
 Minibatch[ 901-1000]: loss = 0.177572 * 100, metric = 5.45% * 100;
 Minibatch[1001-1100]: loss = 0.186208 * 100, metric = 5.81% * 100;
 Minibatch[1101-1200]: loss = 0.176387 * 100, metric = 5.41% * 100;
 Minibatch[1201-1300]: loss = 0.179790 * 100, metric = 5.69% * 100;
 Minibatch[1301-1400]: loss = 0.187524 * 100, metric = 5.72% * 100;
 Minibatch[1401-1500]: loss = 0.185728 * 100, metric = 5.71% * 100;
 Minibatch[1501-1600]: loss = 0.178318 * 100, metric = 5.60% * 100;
 Minibatch[1601-1700]: loss = 0.174525 * 100, metric = 5.41% * 100;
 Minibatch[1701-1800]: loss = 0.183531 * 100, metric = 5.65% * 100;
 Minibatch[1801-1900]: loss = 0.181711 * 100, metric = 5.70% * 100;
 Minibatch[1901-2000]: loss = 0.183850 * 100, metric = 5.80% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.181778 * 2000, metric = 5.63% * 2000 788.003s (  2.5 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 13.80% * 2000;
 Minibatch[   1- 100]: loss = 0.176647 * 100, metric = 5.44% * 100;
 Minibatch[ 101- 200]: loss = 0.185392 * 100, metric = 5.59% * 100;
 Minibatch[ 201- 300]: loss = 0.180638 * 100, metric = 5.55% * 100;
 Minibatch[ 301- 400]: loss = 0.177493 * 100, metric = 5.39% * 100;
 Minibatch[ 401- 500]: loss = 0.178197 * 100, metric = 5.45% * 100;
 Minibatch[ 501- 600]: loss = 0.182673 * 100, metric = 5.62% * 100;
 Minibatch[ 601- 700]: loss = 0.183244 * 100, metric = 5.73% * 100;
 Minibatch[ 701- 800]: loss = 0.181971 * 100, metric = 5.54% * 100;
 Minibatch[ 801- 900]: loss = 0.171063 * 100, metric = 5.26% * 100;
 Minibatch[ 901-1000]: loss = 0.174686 * 100, metric = 5.38% * 100;
 Minibatch[1001-1100]: loss = 0.187645 * 100, metric = 5.78% * 100;
 Minibatch[1101-1200]: loss = 0.183712 * 100, metric = 5.66% * 100;
 Minibatch[1201-1300]: loss = 0.181766 * 100, metric = 5.47% * 100;
 Minibatch[1301-1400]: loss = 0.197194 * 100, metric = 5.98% * 100;
 Minibatch[1401-1500]: loss = 0.186254 * 100, metric = 5.74% * 100;
 Minibatch[1501-1600]: loss = 0.179053 * 100, metric = 5.34% * 100;
 Minibatch[1601-1700]: loss = 0.176753 * 100, metric = 5.49% * 100;
 Minibatch[1701-1800]: loss = 0.182036 * 100, metric = 5.66% * 100;
 Minibatch[1801-1900]: loss = 0.182513 * 100, metric = 5.56% * 100;
 Minibatch[1901-2000]: loss = 0.180221 * 100, metric = 5.54% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.181458 * 2000, metric = 5.56% * 2000 781.078s (  2.6 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.82% * 2000;
0.4360012275278568
 Minibatch[   1- 100]: loss = 0.179862 * 100, metric = 5.66% * 100;
 Minibatch[ 101- 200]: loss = 0.177148 * 100, metric = 5.56% * 100;
 Minibatch[ 201- 300]: loss = 0.181438 * 100, metric = 5.55% * 100;
 Minibatch[ 301- 400]: loss = 0.182929 * 100, metric = 5.75% * 100;
 Minibatch[ 401- 500]: loss = 0.176453 * 100, metric = 5.52% * 100;
 Minibatch[ 501- 600]: loss = 0.181124 * 100, metric = 5.60% * 100;
 Minibatch[ 601- 700]: loss = 0.183868 * 100, metric = 5.74% * 100;
 Minibatch[ 701- 800]: loss = 0.177680 * 100, metric = 5.48% * 100;
 Minibatch[ 801- 900]: loss = 0.177720 * 100, metric = 5.53% * 100;
 Minibatch[ 901-1000]: loss = 0.181354 * 100, metric = 5.61% * 100;
 Minibatch[1001-1100]: loss = 0.189053 * 100, metric = 5.83% * 100;
 Minibatch[1101-1200]: loss = 0.178994 * 100, metric = 5.54% * 100;
 Minibatch[1201-1300]: loss = 0.176237 * 100, metric = 5.35% * 100;
 Minibatch[1301-1400]: loss = 0.180310 * 100, metric = 5.56% * 100;
 Minibatch[1401-1500]: loss = 0.171751 * 100, metric = 5.24% * 100;
 Minibatch[1501-1600]: loss = 0.178781 * 100, metric = 5.60% * 100;
 Minibatch[1601-1700]: loss = 0.179363 * 100, metric = 5.56% * 100;
 Minibatch[1701-1800]: loss = 0.175542 * 100, metric = 5.41% * 100;
 Minibatch[1801-1900]: loss = 0.173621 * 100, metric = 5.42% * 100;
 Minibatch[1901-2000]: loss = 0.182997 * 100, metric = 5.64% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.179311 * 2000, metric = 5.56% * 2000 780.975s (  2.6 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 14.35% * 2000;
 Minibatch[   1- 100]: loss = 0.179440 * 100, metric = 5.56% * 100;
 Minibatch[ 101- 200]: loss = 0.171305 * 100, metric = 5.22% * 100;
 Minibatch[ 201- 300]: loss = 0.185170 * 100, metric = 5.58% * 100;
 Minibatch[ 301- 400]: loss = 0.184922 * 100, metric = 5.87% * 100;
 Minibatch[ 401- 500]: loss = 0.176111 * 100, metric = 5.57% * 100;
 Minibatch[ 501- 600]: loss = 0.173636 * 100, metric = 5.23% * 100;
 Minibatch[ 601- 700]: loss = 0.185182 * 100, metric = 5.74% * 100;
 Minibatch[ 701- 800]: loss = 0.178724 * 100, metric = 5.38% * 100;
 Minibatch[ 801- 900]: loss = 0.172359 * 100, metric = 5.39% * 100;
 Minibatch[ 901-1000]: loss = 0.177296 * 100, metric = 5.35% * 100;
 Minibatch[1001-1100]: loss = 0.176560 * 100, metric = 5.58% * 100;
 Minibatch[1101-1200]: loss = 0.183970 * 100, metric = 5.71% * 100;
 Minibatch[1201-1300]: loss = 0.184804 * 100, metric = 5.54% * 100;
 Minibatch[1301-1400]: loss = 0.167579 * 100, metric = 5.10% * 100;
 Minibatch[1401-1500]: loss = 0.174959 * 100, metric = 5.43% * 100;
 Minibatch[1501-1600]: loss = 0.171874 * 100, metric = 5.31% * 100;
 Minibatch[1601-1700]: loss = 0.175101 * 100, metric = 5.26% * 100;
 Minibatch[1701-1800]: loss = 0.178383 * 100, metric = 5.63% * 100;
 Minibatch[1801-1900]: loss = 0.177773 * 100, metric = 5.59% * 100;
 Minibatch[1901-2000]: loss = 0.173213 * 100, metric = 5.35% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.177418 * 2000, metric = 5.47% * 2000 782.095s (  2.6 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 14.20% * 2000;
 Minibatch[   1- 100]: loss = 0.173258 * 100, metric = 5.44% * 100;
 Minibatch[ 101- 200]: loss = 0.174565 * 100, metric = 5.36% * 100;
 Minibatch[ 201- 300]: loss = 0.173721 * 100, metric = 5.44% * 100;
 Minibatch[ 301- 400]: loss = 0.174990 * 100, metric = 5.23% * 100;
 Minibatch[ 401- 500]: loss = 0.175409 * 100, metric = 5.48% * 100;
 Minibatch[ 501- 600]: loss = 0.176958 * 100, metric = 5.50% * 100;
 Minibatch[ 601- 700]: loss = 0.177692 * 100, metric = 5.36% * 100;
 Minibatch[ 701- 800]: loss = 0.172562 * 100, metric = 5.36% * 100;
 Minibatch[ 801- 900]: loss = 0.173615 * 100, metric = 5.34% * 100;
 Minibatch[ 901-1000]: loss = 0.183867 * 100, metric = 5.71% * 100;
 Minibatch[1001-1100]: loss = 0.179313 * 100, metric = 5.58% * 100;
 Minibatch[1101-1200]: loss = 0.176907 * 100, metric = 5.34% * 100;
 Minibatch[1201-1300]: loss = 0.169579 * 100, metric = 5.31% * 100;
 Minibatch[1301-1400]: loss = 0.175901 * 100, metric = 5.54% * 100;
 Minibatch[1401-1500]: loss = 0.168769 * 100, metric = 5.33% * 100;
 Minibatch[1501-1600]: loss = 0.173469 * 100, metric = 5.36% * 100;
 Minibatch[1601-1700]: loss = 0.177747 * 100, metric = 5.55% * 100;
 Minibatch[1701-1800]: loss = 0.174380 * 100, metric = 5.54% * 100;
 Minibatch[1801-1900]: loss = 0.172744 * 100, metric = 5.40% * 100;
 Minibatch[1901-2000]: loss = 0.173706 * 100, metric = 5.38% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.174958 * 2000, metric = 5.43% * 2000 775.823s (  2.6 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 13.81% * 2000;
 Minibatch[   1- 100]: loss = 0.184881 * 100, metric = 5.82% * 100;
 Minibatch[ 101- 200]: loss = 0.171862 * 100, metric = 5.31% * 100;
 Minibatch[ 201- 300]: loss = 0.178845 * 100, metric = 5.70% * 100;
 Minibatch[ 301- 400]: loss = 0.176625 * 100, metric = 5.52% * 100;
 Minibatch[ 401- 500]: loss = 0.171787 * 100, metric = 5.34% * 100;
 Minibatch[ 501- 600]: loss = 0.176334 * 100, metric = 5.53% * 100;
 Minibatch[ 601- 700]: loss = 0.178109 * 100, metric = 5.49% * 100;
 Minibatch[ 701- 800]: loss = 0.169512 * 100, metric = 5.35% * 100;
 Minibatch[ 801- 900]: loss = 0.170809 * 100, metric = 5.33% * 100;
 Minibatch[ 901-1000]: loss = 0.173180 * 100, metric = 5.41% * 100;
 Minibatch[1001-1100]: loss = 0.167281 * 100, metric = 5.39% * 100;
 Minibatch[1101-1200]: loss = 0.165770 * 100, metric = 5.22% * 100;
 Minibatch[1201-1300]: loss = 0.182717 * 100, metric = 5.92% * 100;
 Minibatch[1301-1400]: loss = 0.179733 * 100, metric = 5.69% * 100;
 Minibatch[1401-1500]: loss = 0.164384 * 100, metric = 5.12% * 100;
 Minibatch[1501-1600]: loss = 0.177199 * 100, metric = 5.47% * 100;
 Minibatch[1601-1700]: loss = 0.173886 * 100, metric = 5.50% * 100;
 Minibatch[1701-1800]: loss = 0.171908 * 100, metric = 5.49% * 100;
 Minibatch[1801-1900]: loss = 0.175960 * 100, metric = 5.47% * 100;
 Minibatch[1901-2000]: loss = 0.165633 * 100, metric = 5.11% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.173821 * 2000, metric = 5.46% * 2000 843.307s (  2.4 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 13.95% * 2000;
 Minibatch[   1- 100]: loss = 0.170808 * 100, metric = 5.41% * 100;
 Minibatch[ 101- 200]: loss = 0.175758 * 100, metric = 5.61% * 100;
 Minibatch[ 201- 300]: loss = 0.174273 * 100, metric = 5.33% * 100;
 Minibatch[ 301- 400]: loss = 0.171311 * 100, metric = 5.35% * 100;
 Minibatch[ 401- 500]: loss = 0.169437 * 100, metric = 5.18% * 100;
 Minibatch[ 501- 600]: loss = 0.170496 * 100, metric = 5.38% * 100;
 Minibatch[ 601- 700]: loss = 0.181017 * 100, metric = 5.78% * 100;
 Minibatch[ 701- 800]: loss = 0.153668 * 100, metric = 4.93% * 100;
 Minibatch[ 801- 900]: loss = 0.161695 * 100, metric = 5.00% * 100;
 Minibatch[ 901-1000]: loss = 0.172668 * 100, metric = 5.42% * 100;
 Minibatch[1001-1100]: loss = 0.169003 * 100, metric = 5.17% * 100;
 Minibatch[1101-1200]: loss = 0.159979 * 100, metric = 4.95% * 100;
 Minibatch[1201-1300]: loss = 0.166330 * 100, metric = 5.09% * 100;
 Minibatch[1301-1400]: loss = 0.165685 * 100, metric = 5.12% * 100;
 Minibatch[1401-1500]: loss = 0.161270 * 100, metric = 5.10% * 100;
 Minibatch[1501-1600]: loss = 0.158450 * 100, metric = 4.99% * 100;
 Minibatch[1601-1700]: loss = 0.168983 * 100, metric = 5.18% * 100;
 Minibatch[1701-1800]: loss = 0.174435 * 100, metric = 5.49% * 100;
 Minibatch[1801-1900]: loss = 0.172524 * 100, metric = 5.31% * 100;
 Minibatch[1901-2000]: loss = 0.163897 * 100, metric = 5.08% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.168084 * 2000, metric = 5.24% * 2000 863.000s (  2.3 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 14.76% * 2000;
 Minibatch[   1- 100]: loss = 0.172413 * 100, metric = 5.35% * 100;
 Minibatch[ 101- 200]: loss = 0.168673 * 100, metric = 5.04% * 100;
 Minibatch[ 201- 300]: loss = 0.168295 * 100, metric = 5.25% * 100;
 Minibatch[ 301- 400]: loss = 0.174387 * 100, metric = 5.57% * 100;
 Minibatch[ 401- 500]: loss = 0.169258 * 100, metric = 5.30% * 100;
 Minibatch[ 501- 600]: loss = 0.159961 * 100, metric = 4.89% * 100;
 Minibatch[ 601- 700]: loss = 0.157493 * 100, metric = 4.88% * 100;
 Minibatch[ 701- 800]: loss = 0.162209 * 100, metric = 5.06% * 100;
 Minibatch[ 801- 900]: loss = 0.172766 * 100, metric = 5.38% * 100;
 Minibatch[ 901-1000]: loss = 0.165996 * 100, metric = 5.16% * 100;
 Minibatch[1001-1100]: loss = 0.158909 * 100, metric = 4.81% * 100;
 Minibatch[1101-1200]: loss = 0.170511 * 100, metric = 5.11% * 100;
 Minibatch[1201-1300]: loss = 0.167752 * 100, metric = 5.20% * 100;
 Minibatch[1301-1400]: loss = 0.161410 * 100, metric = 4.97% * 100;
 Minibatch[1401-1500]: loss = 0.166758 * 100, metric = 5.27% * 100;
 Minibatch[1501-1600]: loss = 0.165680 * 100, metric = 5.22% * 100;
 Minibatch[1601-1700]: loss = 0.162535 * 100, metric = 5.04% * 100;
 Minibatch[1701-1800]: loss = 0.168471 * 100, metric = 5.30% * 100;
 Minibatch[1801-1900]: loss = 0.166841 * 100, metric = 5.34% * 100;
 Minibatch[1901-2000]: loss = 0.163093 * 100, metric = 5.00% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.166171 * 2000, metric = 5.16% * 2000 865.813s (  2.3 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 13.95% * 2000;
 Minibatch[   1- 100]: loss = 0.166451 * 100, metric = 5.18% * 100;
 Minibatch[ 101- 200]: loss = 0.173317 * 100, metric = 5.35% * 100;
 Minibatch[ 201- 300]: loss = 0.162634 * 100, metric = 5.02% * 100;
 Minibatch[ 301- 400]: loss = 0.175444 * 100, metric = 5.21% * 100;
 Minibatch[ 401- 500]: loss = 0.164431 * 100, metric = 5.16% * 100;
 Minibatch[ 501- 600]: loss = 0.165796 * 100, metric = 5.10% * 100;
 Minibatch[ 601- 700]: loss = 0.157932 * 100, metric = 4.96% * 100;
 Minibatch[ 701- 800]: loss = 0.160355 * 100, metric = 5.07% * 100;
 Minibatch[ 801- 900]: loss = 0.159416 * 100, metric = 4.90% * 100;
 Minibatch[ 901-1000]: loss = 0.170521 * 100, metric = 5.34% * 100;
 Minibatch[1001-1100]: loss = 0.161800 * 100, metric = 5.06% * 100;
 Minibatch[1101-1200]: loss = 0.167260 * 100, metric = 5.25% * 100;
 Minibatch[1201-1300]: loss = 0.166089 * 100, metric = 5.16% * 100;
 Minibatch[1301-1400]: loss = 0.164432 * 100, metric = 5.10% * 100;
 Minibatch[1401-1500]: loss = 0.160968 * 100, metric = 5.06% * 100;
 Minibatch[1501-1600]: loss = 0.165195 * 100, metric = 5.08% * 100;
 Minibatch[1601-1700]: loss = 0.157801 * 100, metric = 4.89% * 100;
 Minibatch[1701-1800]: loss = 0.172508 * 100, metric = 5.34% * 100;
 Minibatch[1801-1900]: loss = 0.159609 * 100, metric = 4.90% * 100;
 Minibatch[1901-2000]: loss = 0.161732 * 100, metric = 4.95% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.164685 * 2000, metric = 5.10% * 2000 862.767s (  2.3 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 14.00% * 2000;
 Minibatch[   1- 100]: loss = 0.158534 * 100, metric = 4.90% * 100;
 Minibatch[ 101- 200]: loss = 0.160450 * 100, metric = 4.98% * 100;
 Minibatch[ 201- 300]: loss = 0.167785 * 100, metric = 5.18% * 100;
 Minibatch[ 301- 400]: loss = 0.159920 * 100, metric = 4.94% * 100;
 Minibatch[ 401- 500]: loss = 0.160582 * 100, metric = 5.14% * 100;
 Minibatch[ 501- 600]: loss = 0.166570 * 100, metric = 5.21% * 100;
 Minibatch[ 601- 700]: loss = 0.170037 * 100, metric = 5.40% * 100;
 Minibatch[ 701- 800]: loss = 0.168587 * 100, metric = 5.36% * 100;
 Minibatch[ 801- 900]: loss = 0.158232 * 100, metric = 4.90% * 100;
 Minibatch[ 901-1000]: loss = 0.164571 * 100, metric = 5.03% * 100;
 Minibatch[1001-1100]: loss = 0.173896 * 100, metric = 5.46% * 100;
 Minibatch[1101-1200]: loss = 0.163914 * 100, metric = 5.17% * 100;
 Minibatch[1201-1300]: loss = 0.156285 * 100, metric = 4.83% * 100;
 Minibatch[1301-1400]: loss = 0.163800 * 100, metric = 4.95% * 100;
 Minibatch[1401-1500]: loss = 0.169390 * 100, metric = 5.27% * 100;
 Minibatch[1501-1600]: loss = 0.164013 * 100, metric = 4.99% * 100;
 Minibatch[1601-1700]: loss = 0.161187 * 100, metric = 5.16% * 100;
 Minibatch[1701-1800]: loss = 0.167502 * 100, metric = 5.15% * 100;
 Minibatch[1801-1900]: loss = 0.162155 * 100, metric = 5.10% * 100;
 Minibatch[1901-2000]: loss = 0.170863 * 100, metric = 5.36% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.164414 * 2000, metric = 5.12% * 2000 866.336s (  2.3 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 13.55% * 2000;
 Minibatch[   1- 100]: loss = 0.163921 * 100, metric = 5.12% * 100;
 Minibatch[ 101- 200]: loss = 0.165454 * 100, metric = 5.25% * 100;
 Minibatch[ 201- 300]: loss = 0.170690 * 100, metric = 5.29% * 100;
 Minibatch[ 301- 400]: loss = 0.157841 * 100, metric = 4.91% * 100;
 Minibatch[ 401- 500]: loss = 0.164355 * 100, metric = 5.02% * 100;
 Minibatch[ 501- 600]: loss = 0.176208 * 100, metric = 5.39% * 100;
 Minibatch[ 601- 700]: loss = 0.174231 * 100, metric = 5.35% * 100;
 Minibatch[ 701- 800]: loss = 0.160988 * 100, metric = 4.98% * 100;
 Minibatch[ 801- 900]: loss = 0.157876 * 100, metric = 4.94% * 100;
 Minibatch[ 901-1000]: loss = 0.165920 * 100, metric = 5.25% * 100;
 Minibatch[1001-1100]: loss = 0.163200 * 100, metric = 5.21% * 100;
 Minibatch[1101-1200]: loss = 0.167110 * 100, metric = 5.17% * 100;
 Minibatch[1201-1300]: loss = 0.160280 * 100, metric = 4.98% * 100;
 Minibatch[1301-1400]: loss = 0.159904 * 100, metric = 5.10% * 100;
 Minibatch[1401-1500]: loss = 0.160348 * 100, metric = 5.06% * 100;
 Minibatch[1501-1600]: loss = 0.163876 * 100, metric = 5.20% * 100;
 Minibatch[1601-1700]: loss = 0.155869 * 100, metric = 4.92% * 100;
 Minibatch[1701-1800]: loss = 0.160338 * 100, metric = 4.92% * 100;
 Minibatch[1801-1900]: loss = 0.164373 * 100, metric = 5.15% * 100;
 Minibatch[1901-2000]: loss = 0.156387 * 100, metric = 4.85% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.163458 * 2000, metric = 5.10% * 2000 853.344s (  2.3 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 13.65% * 2000;
 Minibatch[   1- 100]: loss = 0.169016 * 100, metric = 5.43% * 100;
 Minibatch[ 101- 200]: loss = 0.164387 * 100, metric = 5.21% * 100;
 Minibatch[ 201- 300]: loss = 0.165809 * 100, metric = 5.24% * 100;
 Minibatch[ 301- 400]: loss = 0.160161 * 100, metric = 4.95% * 100;
 Minibatch[ 401- 500]: loss = 0.166977 * 100, metric = 5.31% * 100;
 Minibatch[ 501- 600]: loss = 0.160263 * 100, metric = 4.96% * 100;
 Minibatch[ 601- 700]: loss = 0.161493 * 100, metric = 5.06% * 100;
 Minibatch[ 701- 800]: loss = 0.161426 * 100, metric = 5.06% * 100;
 Minibatch[ 801- 900]: loss = 0.155924 * 100, metric = 4.87% * 100;
 Minibatch[ 901-1000]: loss = 0.170062 * 100, metric = 5.34% * 100;
 Minibatch[1001-1100]: loss = 0.161643 * 100, metric = 4.96% * 100;
 Minibatch[1101-1200]: loss = 0.165306 * 100, metric = 5.26% * 100;
 Minibatch[1201-1300]: loss = 0.152762 * 100, metric = 4.81% * 100;
 Minibatch[1301-1400]: loss = 0.166099 * 100, metric = 5.09% * 100;
 Minibatch[1401-1500]: loss = 0.161311 * 100, metric = 5.11% * 100;
 Minibatch[1501-1600]: loss = 0.151239 * 100, metric = 4.66% * 100;
 Minibatch[1601-1700]: loss = 0.172194 * 100, metric = 5.43% * 100;
 Minibatch[1701-1800]: loss = 0.163692 * 100, metric = 5.10% * 100;
 Minibatch[1801-1900]: loss = 0.162573 * 100, metric = 5.15% * 100;
 Minibatch[1901-2000]: loss = 0.158162 * 100, metric = 4.92% * 100;
Finished Epoch[49 of 200]: [Training] loss = 0.162525 * 2000, metric = 5.09% * 2000 858.418s (  2.3 samples/s);
Finished Evaluation [49]: Minibatch[1-2000]: metric = 13.71% * 2000;
 Minibatch[   1- 100]: loss = 0.163753 * 100, metric = 5.17% * 100;
 Minibatch[ 101- 200]: loss = 0.155940 * 100, metric = 4.89% * 100;
 Minibatch[ 201- 300]: loss = 0.160954 * 100, metric = 4.94% * 100;
 Minibatch[ 301- 400]: loss = 0.156806 * 100, metric = 4.81% * 100;
 Minibatch[ 401- 500]: loss = 0.167005 * 100, metric = 5.23% * 100;
 Minibatch[ 501- 600]: loss = 0.171423 * 100, metric = 5.50% * 100;
 Minibatch[ 601- 700]: loss = 0.157482 * 100, metric = 4.95% * 100;
 Minibatch[ 701- 800]: loss = 0.155883 * 100, metric = 4.93% * 100;
 Minibatch[ 801- 900]: loss = 0.160588 * 100, metric = 5.06% * 100;
 Minibatch[ 901-1000]: loss = 0.156875 * 100, metric = 4.86% * 100;
 Minibatch[1001-1100]: loss = 0.158487 * 100, metric = 5.12% * 100;
 Minibatch[1101-1200]: loss = 0.161491 * 100, metric = 5.01% * 100;
 Minibatch[1201-1300]: loss = 0.163056 * 100, metric = 5.25% * 100;
 Minibatch[1301-1400]: loss = 0.152704 * 100, metric = 4.79% * 100;
 Minibatch[1401-1500]: loss = 0.161223 * 100, metric = 5.10% * 100;
 Minibatch[1501-1600]: loss = 0.149782 * 100, metric = 4.65% * 100;
 Minibatch[1601-1700]: loss = 0.156894 * 100, metric = 4.90% * 100;
 Minibatch[1701-1800]: loss = 0.161602 * 100, metric = 5.18% * 100;
 Minibatch[1801-1900]: loss = 0.165645 * 100, metric = 5.16% * 100;
 Minibatch[1901-2000]: loss = 0.160960 * 100, metric = 5.06% * 100;
Finished Epoch[50 of 200]: [Training] loss = 0.159928 * 2000, metric = 5.03% * 2000 859.658s (  2.3 samples/s);
Finished Evaluation [50]: Minibatch[1-2000]: metric = 14.20% * 2000;
 Minibatch[   1- 100]: loss = 0.152915 * 100, metric = 4.65% * 100;
 Minibatch[ 101- 200]: loss = 0.167369 * 100, metric = 5.29% * 100;
 Minibatch[ 201- 300]: loss = 0.159848 * 100, metric = 4.94% * 100;
 Minibatch[ 301- 400]: loss = 0.158857 * 100, metric = 5.00% * 100;
 Minibatch[ 401- 500]: loss = 0.156313 * 100, metric = 4.84% * 100;
 Minibatch[ 501- 600]: loss = 0.168051 * 100, metric = 5.36% * 100;
 Minibatch[ 601- 700]: loss = 0.156972 * 100, metric = 5.01% * 100;
 Minibatch[ 701- 800]: loss = 0.154459 * 100, metric = 4.77% * 100;
 Minibatch[ 801- 900]: loss = 0.159151 * 100, metric = 4.79% * 100;
 Minibatch[ 901-1000]: loss = 0.161629 * 100, metric = 5.09% * 100;
 Minibatch[1001-1100]: loss = 0.160621 * 100, metric = 5.06% * 100;
 Minibatch[1101-1200]: loss = 0.161418 * 100, metric = 5.04% * 100;
 Minibatch[1201-1300]: loss = 0.168050 * 100, metric = 5.26% * 100;
 Minibatch[1301-1400]: loss = 0.162749 * 100, metric = 5.08% * 100;
 Minibatch[1401-1500]: loss = 0.157011 * 100, metric = 4.90% * 100;
 Minibatch[1501-1600]: loss = 0.165632 * 100, metric = 5.07% * 100;
 Minibatch[1601-1700]: loss = 0.156205 * 100, metric = 4.97% * 100;
 Minibatch[1701-1800]: loss = 0.159453 * 100, metric = 5.01% * 100;
 Minibatch[1801-1900]: loss = 0.152832 * 100, metric = 4.74% * 100;
 Minibatch[1901-2000]: loss = 0.159718 * 100, metric = 4.97% * 100;
Finished Epoch[51 of 200]: [Training] loss = 0.159963 * 2000, metric = 4.99% * 2000 852.822s (  2.3 samples/s);
Finished Evaluation [51]: Minibatch[1-2000]: metric = 14.44% * 2000;
 Minibatch[   1- 100]: loss = 0.149694 * 100, metric = 4.71% * 100;
 Minibatch[ 101- 200]: loss = 0.154197 * 100, metric = 4.74% * 100;
 Minibatch[ 201- 300]: loss = 0.160524 * 100, metric = 5.01% * 100;
 Minibatch[ 301- 400]: loss = 0.153681 * 100, metric = 4.84% * 100;
 Minibatch[ 401- 500]: loss = 0.162315 * 100, metric = 5.04% * 100;
 Minibatch[ 501- 600]: loss = 0.160136 * 100, metric = 5.02% * 100;
 Minibatch[ 601- 700]: loss = 0.158618 * 100, metric = 4.78% * 100;
 Minibatch[ 701- 800]: loss = 0.167494 * 100, metric = 5.22% * 100;
 Minibatch[ 801- 900]: loss = 0.160796 * 100, metric = 5.15% * 100;
 Minibatch[ 901-1000]: loss = 0.163449 * 100, metric = 5.09% * 100;
 Minibatch[1001-1100]: loss = 0.162513 * 100, metric = 5.12% * 100;
 Minibatch[1101-1200]: loss = 0.143853 * 100, metric = 4.36% * 100;
 Minibatch[1201-1300]: loss = 0.155057 * 100, metric = 4.99% * 100;
 Minibatch[1301-1400]: loss = 0.159986 * 100, metric = 4.71% * 100;
 Minibatch[1401-1500]: loss = 0.150657 * 100, metric = 4.57% * 100;
 Minibatch[1501-1600]: loss = 0.146383 * 100, metric = 4.49% * 100;
 Minibatch[1601-1700]: loss = 0.159133 * 100, metric = 4.96% * 100;
 Minibatch[1701-1800]: loss = 0.153343 * 100, metric = 4.71% * 100;
 Minibatch[1801-1900]: loss = 0.149469 * 100, metric = 4.58% * 100;
 Minibatch[1901-2000]: loss = 0.156943 * 100, metric = 4.96% * 100;
Finished Epoch[52 of 200]: [Training] loss = 0.156412 * 2000, metric = 4.85% * 2000 850.874s (  2.4 samples/s);
Finished Evaluation [52]: Minibatch[1-2000]: metric = 15.19% * 2000;
 Minibatch[   1- 100]: loss = 0.160632 * 100, metric = 4.87% * 100;
 Minibatch[ 101- 200]: loss = 0.147104 * 100, metric = 4.60% * 100;
 Minibatch[ 201- 300]: loss = 0.153449 * 100, metric = 4.79% * 100;
 Minibatch[ 301- 400]: loss = 0.157370 * 100, metric = 4.94% * 100;
 Minibatch[ 401- 500]: loss = 0.155640 * 100, metric = 4.69% * 100;
 Minibatch[ 501- 600]: loss = 0.156535 * 100, metric = 4.89% * 100;
 Minibatch[ 601- 700]: loss = 0.151802 * 100, metric = 4.62% * 100;
 Minibatch[ 701- 800]: loss = 0.147822 * 100, metric = 4.57% * 100;
 Minibatch[ 801- 900]: loss = 0.152805 * 100, metric = 4.79% * 100;
 Minibatch[ 901-1000]: loss = 0.151404 * 100, metric = 4.75% * 100;
 Minibatch[1001-1100]: loss = 0.155951 * 100, metric = 4.90% * 100;
 Minibatch[1101-1200]: loss = 0.151044 * 100, metric = 4.70% * 100;
 Minibatch[1201-1300]: loss = 0.148840 * 100, metric = 4.60% * 100;
 Minibatch[1301-1400]: loss = 0.150001 * 100, metric = 4.63% * 100;
 Minibatch[1401-1500]: loss = 0.150969 * 100, metric = 4.65% * 100;
 Minibatch[1501-1600]: loss = 0.156386 * 100, metric = 4.91% * 100;
 Minibatch[1601-1700]: loss = 0.150525 * 100, metric = 4.64% * 100;
 Minibatch[1701-1800]: loss = 0.161776 * 100, metric = 5.15% * 100;
 Minibatch[1801-1900]: loss = 0.166302 * 100, metric = 5.21% * 100;
 Minibatch[1901-2000]: loss = 0.145587 * 100, metric = 4.65% * 100;
Finished Epoch[53 of 200]: [Training] loss = 0.153597 * 2000, metric = 4.78% * 2000 860.711s (  2.3 samples/s);
Finished Evaluation [53]: Minibatch[1-2000]: metric = 14.50% * 2000;
 Minibatch[   1- 100]: loss = 0.151334 * 100, metric = 4.71% * 100;
 Minibatch[ 101- 200]: loss = 0.151376 * 100, metric = 4.67% * 100;
 Minibatch[ 201- 300]: loss = 0.156689 * 100, metric = 5.03% * 100;
 Minibatch[ 301- 400]: loss = 0.146725 * 100, metric = 4.60% * 100;
 Minibatch[ 401- 500]: loss = 0.153672 * 100, metric = 4.86% * 100;
 Minibatch[ 501- 600]: loss = 0.148682 * 100, metric = 4.64% * 100;
 Minibatch[ 601- 700]: loss = 0.153106 * 100, metric = 4.66% * 100;
 Minibatch[ 701- 800]: loss = 0.153049 * 100, metric = 4.89% * 100;
 Minibatch[ 801- 900]: loss = 0.144134 * 100, metric = 4.44% * 100;
 Minibatch[ 901-1000]: loss = 0.158199 * 100, metric = 4.96% * 100;
 Minibatch[1001-1100]: loss = 0.147433 * 100, metric = 4.59% * 100;
 Minibatch[1101-1200]: loss = 0.147128 * 100, metric = 4.50% * 100;
 Minibatch[1201-1300]: loss = 0.153017 * 100, metric = 4.82% * 100;
 Minibatch[1301-1400]: loss = 0.151825 * 100, metric = 4.86% * 100;
 Minibatch[1401-1500]: loss = 0.158643 * 100, metric = 5.02% * 100;
 Minibatch[1501-1600]: loss = 0.156455 * 100, metric = 4.86% * 100;
 Minibatch[1601-1700]: loss = 0.154671 * 100, metric = 4.87% * 100;
 Minibatch[1701-1800]: loss = 0.159102 * 100, metric = 4.88% * 100;
 Minibatch[1801-1900]: loss = 0.160560 * 100, metric = 5.02% * 100;
 Minibatch[1901-2000]: loss = 0.161464 * 100, metric = 5.08% * 100;
Finished Epoch[54 of 200]: [Training] loss = 0.153363 * 2000, metric = 4.80% * 2000 851.401s (  2.3 samples/s);
Finished Evaluation [54]: Minibatch[1-2000]: metric = 13.54% * 2000;
 Minibatch[   1- 100]: loss = 0.159941 * 100, metric = 4.92% * 100;
 Minibatch[ 101- 200]: loss = 0.158798 * 100, metric = 4.96% * 100;
 Minibatch[ 201- 300]: loss = 0.158909 * 100, metric = 5.02% * 100;
 Minibatch[ 301- 400]: loss = 0.148162 * 100, metric = 4.80% * 100;
 Minibatch[ 401- 500]: loss = 0.151373 * 100, metric = 4.74% * 100;
 Minibatch[ 501- 600]: loss = 0.158996 * 100, metric = 5.08% * 100;
 Minibatch[ 601- 700]: loss = 0.156767 * 100, metric = 4.90% * 100;
 Minibatch[ 701- 800]: loss = 0.160315 * 100, metric = 5.06% * 100;
 Minibatch[ 801- 900]: loss = 0.159179 * 100, metric = 5.05% * 100;
 Minibatch[ 901-1000]: loss = 0.150532 * 100, metric = 4.70% * 100;
 Minibatch[1001-1100]: loss = 0.156403 * 100, metric = 4.82% * 100;
 Minibatch[1101-1200]: loss = 0.158498 * 100, metric = 4.98% * 100;
 Minibatch[1201-1300]: loss = 0.148703 * 100, metric = 4.58% * 100;
 Minibatch[1301-1400]: loss = 0.146180 * 100, metric = 4.54% * 100;
 Minibatch[1401-1500]: loss = 0.148853 * 100, metric = 4.52% * 100;
 Minibatch[1501-1600]: loss = 0.151016 * 100, metric = 4.82% * 100;
 Minibatch[1601-1700]: loss = 0.156182 * 100, metric = 5.08% * 100;
 Minibatch[1701-1800]: loss = 0.157108 * 100, metric = 5.05% * 100;
 Minibatch[1801-1900]: loss = 0.150643 * 100, metric = 4.62% * 100;
 Minibatch[1901-2000]: loss = 0.155914 * 100, metric = 4.89% * 100;
Finished Epoch[55 of 200]: [Training] loss = 0.154624 * 2000, metric = 4.86% * 2000 847.309s (  2.4 samples/s);
Finished Evaluation [55]: Minibatch[1-2000]: metric = 13.87% * 2000;
 Minibatch[   1- 100]: loss = 0.159306 * 100, metric = 4.95% * 100;
 Minibatch[ 101- 200]: loss = 0.150172 * 100, metric = 4.66% * 100;
 Minibatch[ 201- 300]: loss = 0.161746 * 100, metric = 5.03% * 100;
 Minibatch[ 301- 400]: loss = 0.156136 * 100, metric = 5.05% * 100;
 Minibatch[ 401- 500]: loss = 0.161618 * 100, metric = 5.17% * 100;
 Minibatch[ 501- 600]: loss = 0.161862 * 100, metric = 4.98% * 100;
 Minibatch[ 601- 700]: loss = 0.151780 * 100, metric = 4.73% * 100;
 Minibatch[ 701- 800]: loss = 0.154654 * 100, metric = 4.85% * 100;
 Minibatch[ 801- 900]: loss = 0.152282 * 100, metric = 4.73% * 100;
 Minibatch[ 901-1000]: loss = 0.158072 * 100, metric = 5.00% * 100;
 Minibatch[1001-1100]: loss = 0.156675 * 100, metric = 4.85% * 100;
 Minibatch[1101-1200]: loss = 0.158173 * 100, metric = 5.06% * 100;
 Minibatch[1201-1300]: loss = 0.153796 * 100, metric = 4.82% * 100;
 Minibatch[1301-1400]: loss = 0.147547 * 100, metric = 4.48% * 100;
 Minibatch[1401-1500]: loss = 0.156887 * 100, metric = 4.91% * 100;
 Minibatch[1501-1600]: loss = 0.150710 * 100, metric = 4.72% * 100;
 Minibatch[1601-1700]: loss = 0.153225 * 100, metric = 4.74% * 100;
 Minibatch[1701-1800]: loss = 0.149109 * 100, metric = 4.70% * 100;
 Minibatch[1801-1900]: loss = 0.147951 * 100, metric = 4.63% * 100;
 Minibatch[1901-2000]: loss = 0.161088 * 100, metric = 4.98% * 100;
Finished Epoch[56 of 200]: [Training] loss = 0.155139 * 2000, metric = 4.85% * 2000 846.175s (  2.4 samples/s);
Finished Evaluation [56]: Minibatch[1-2000]: metric = 14.37% * 2000;
 Minibatch[   1- 100]: loss = 0.152052 * 100, metric = 4.75% * 100;
 Minibatch[ 101- 200]: loss = 0.151018 * 100, metric = 4.75% * 100;
 Minibatch[ 201- 300]: loss = 0.150014 * 100, metric = 4.69% * 100;
 Minibatch[ 301- 400]: loss = 0.157405 * 100, metric = 4.93% * 100;
 Minibatch[ 401- 500]: loss = 0.151963 * 100, metric = 4.69% * 100;
 Minibatch[ 501- 600]: loss = 0.142133 * 100, metric = 4.46% * 100;
 Minibatch[ 601- 700]: loss = 0.152196 * 100, metric = 4.83% * 100;
 Minibatch[ 701- 800]: loss = 0.145396 * 100, metric = 4.67% * 100;
 Minibatch[ 801- 900]: loss = 0.149629 * 100, metric = 4.72% * 100;
 Minibatch[ 901-1000]: loss = 0.148639 * 100, metric = 4.71% * 100;
 Minibatch[1001-1100]: loss = 0.152531 * 100, metric = 4.81% * 100;
 Minibatch[1101-1200]: loss = 0.152769 * 100, metric = 4.65% * 100;
 Minibatch[1201-1300]: loss = 0.156545 * 100, metric = 4.96% * 100;
 Minibatch[1301-1400]: loss = 0.148926 * 100, metric = 4.64% * 100;
 Minibatch[1401-1500]: loss = 0.154358 * 100, metric = 4.77% * 100;
 Minibatch[1501-1600]: loss = 0.144380 * 100, metric = 4.43% * 100;
 Minibatch[1601-1700]: loss = 0.150916 * 100, metric = 4.65% * 100;
 Minibatch[1701-1800]: loss = 0.151875 * 100, metric = 4.89% * 100;
 Minibatch[1801-1900]: loss = 0.155627 * 100, metric = 4.90% * 100;
 Minibatch[1901-2000]: loss = 0.157272 * 100, metric = 5.08% * 100;
Finished Epoch[57 of 200]: [Training] loss = 0.151282 * 2000, metric = 4.75% * 2000 846.857s (  2.4 samples/s);
Finished Evaluation [57]: Minibatch[1-2000]: metric = 13.60% * 2000;
 Minibatch[   1- 100]: loss = 0.147810 * 100, metric = 4.63% * 100;
 Minibatch[ 101- 200]: loss = 0.153700 * 100, metric = 4.97% * 100;
 Minibatch[ 201- 300]: loss = 0.153167 * 100, metric = 4.82% * 100;
 Minibatch[ 301- 400]: loss = 0.158115 * 100, metric = 5.03% * 100;
 Minibatch[ 401- 500]: loss = 0.160943 * 100, metric = 5.19% * 100;
 Minibatch[ 501- 600]: loss = 0.148837 * 100, metric = 4.53% * 100;
 Minibatch[ 601- 700]: loss = 0.149252 * 100, metric = 4.63% * 100;
 Minibatch[ 701- 800]: loss = 0.158054 * 100, metric = 4.98% * 100;
 Minibatch[ 801- 900]: loss = 0.145011 * 100, metric = 4.64% * 100;
 Minibatch[ 901-1000]: loss = 0.148294 * 100, metric = 4.66% * 100;
 Minibatch[1001-1100]: loss = 0.150281 * 100, metric = 4.78% * 100;
 Minibatch[1101-1200]: loss = 0.157693 * 100, metric = 5.01% * 100;
 Minibatch[1201-1300]: loss = 0.151288 * 100, metric = 4.81% * 100;
 Minibatch[1301-1400]: loss = 0.152690 * 100, metric = 4.89% * 100;
 Minibatch[1401-1500]: loss = 0.142022 * 100, metric = 4.31% * 100;
 Minibatch[1501-1600]: loss = 0.153227 * 100, metric = 4.77% * 100;
 Minibatch[1601-1700]: loss = 0.156371 * 100, metric = 4.94% * 100;
 Minibatch[1701-1800]: loss = 0.150578 * 100, metric = 4.63% * 100;
 Minibatch[1801-1900]: loss = 0.156495 * 100, metric = 4.85% * 100;
 Minibatch[1901-2000]: loss = 0.144614 * 100, metric = 4.40% * 100;
Finished Epoch[58 of 200]: [Training] loss = 0.151922 * 2000, metric = 4.77% * 2000 845.334s (  2.4 samples/s);
Finished Evaluation [58]: Minibatch[1-2000]: metric = 14.13% * 2000;
 Minibatch[   1- 100]: loss = 0.159957 * 100, metric = 5.10% * 100;
 Minibatch[ 101- 200]: loss = 0.162195 * 100, metric = 5.17% * 100;
 Minibatch[ 201- 300]: loss = 0.153410 * 100, metric = 4.63% * 100;
 Minibatch[ 301- 400]: loss = 0.148068 * 100, metric = 4.62% * 100;
 Minibatch[ 401- 500]: loss = 0.150952 * 100, metric = 4.74% * 100;
 Minibatch[ 501- 600]: loss = 0.149851 * 100, metric = 4.82% * 100;
 Minibatch[ 601- 700]: loss = 0.147488 * 100, metric = 4.63% * 100;
 Minibatch[ 701- 800]: loss = 0.146598 * 100, metric = 4.57% * 100;
 Minibatch[ 801- 900]: loss = 0.147509 * 100, metric = 4.67% * 100;
 Minibatch[ 901-1000]: loss = 0.149785 * 100, metric = 4.79% * 100;
 Minibatch[1001-1100]: loss = 0.144427 * 100, metric = 4.50% * 100;
 Minibatch[1101-1200]: loss = 0.152731 * 100, metric = 4.79% * 100;
 Minibatch[1201-1300]: loss = 0.148831 * 100, metric = 4.79% * 100;
 Minibatch[1301-1400]: loss = 0.147797 * 100, metric = 4.52% * 100;
 Minibatch[1401-1500]: loss = 0.150134 * 100, metric = 4.72% * 100;
 Minibatch[1501-1600]: loss = 0.149291 * 100, metric = 4.72% * 100;
 Minibatch[1601-1700]: loss = 0.149701 * 100, metric = 4.77% * 100;
 Minibatch[1701-1800]: loss = 0.146706 * 100, metric = 4.67% * 100;
 Minibatch[1801-1900]: loss = 0.152920 * 100, metric = 4.77% * 100;
 Minibatch[1901-2000]: loss = 0.151346 * 100, metric = 4.75% * 100;
Finished Epoch[59 of 200]: [Training] loss = 0.150485 * 2000, metric = 4.74% * 2000 853.253s (  2.3 samples/s);
Finished Evaluation [59]: Minibatch[1-2000]: metric = 14.20% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
