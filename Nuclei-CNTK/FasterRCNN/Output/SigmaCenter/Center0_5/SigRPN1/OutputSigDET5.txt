Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.339606 * 100, metric = 25.15% * 100;
 Minibatch[ 101- 200]: loss = 1.131972 * 100, metric = 22.73% * 100;
 Minibatch[ 201- 300]: loss = 1.030143 * 100, metric = 21.70% * 100;
 Minibatch[ 301- 400]: loss = 1.028374 * 100, metric = 20.83% * 100;
 Minibatch[ 401- 500]: loss = 0.953733 * 100, metric = 19.32% * 100;
 Minibatch[ 501- 600]: loss = 0.942167 * 100, metric = 18.58% * 100;
 Minibatch[ 601- 700]: loss = 0.924489 * 100, metric = 17.58% * 100;
 Minibatch[ 701- 800]: loss = 0.861111 * 100, metric = 16.23% * 100;
 Minibatch[ 801- 900]: loss = 0.880328 * 100, metric = 16.74% * 100;
 Minibatch[ 901-1000]: loss = 0.891845 * 100, metric = 16.70% * 100;
 Minibatch[1001-1100]: loss = 0.876346 * 100, metric = 16.62% * 100;
 Minibatch[1101-1200]: loss = 0.869374 * 100, metric = 16.06% * 100;
 Minibatch[1201-1300]: loss = 0.864948 * 100, metric = 16.15% * 100;
 Minibatch[1301-1400]: loss = 0.828209 * 100, metric = 15.69% * 100;
 Minibatch[1401-1500]: loss = 0.856914 * 100, metric = 15.97% * 100;
 Minibatch[1501-1600]: loss = 0.824967 * 100, metric = 15.46% * 100;
 Minibatch[1601-1700]: loss = 0.816785 * 100, metric = 15.63% * 100;
 Minibatch[1701-1800]: loss = 0.827759 * 100, metric = 15.44% * 100;
 Minibatch[1801-1900]: loss = 0.835830 * 100, metric = 15.73% * 100;
 Minibatch[1901-2000]: loss = 0.814413 * 100, metric = 15.08% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.919966 * 2000, metric = 17.67% * 2000 937.411s (  2.1 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 24.42% * 2000;
0.849986874975264
 Minibatch[   1- 100]: loss = 0.803520 * 100, metric = 14.43% * 100;
 Minibatch[ 101- 200]: loss = 0.818477 * 100, metric = 15.48% * 100;
 Minibatch[ 201- 300]: loss = 0.809760 * 100, metric = 14.59% * 100;
 Minibatch[ 301- 400]: loss = 0.816082 * 100, metric = 14.90% * 100;
 Minibatch[ 401- 500]: loss = 0.813555 * 100, metric = 15.18% * 100;
 Minibatch[ 501- 600]: loss = 0.824709 * 100, metric = 14.67% * 100;
 Minibatch[ 601- 700]: loss = 0.773498 * 100, metric = 13.88% * 100;
 Minibatch[ 701- 800]: loss = 0.797026 * 100, metric = 14.57% * 100;
 Minibatch[ 801- 900]: loss = 0.772697 * 100, metric = 14.03% * 100;
 Minibatch[ 901-1000]: loss = 0.769938 * 100, metric = 13.71% * 100;
 Minibatch[1001-1100]: loss = 0.788179 * 100, metric = 14.68% * 100;
 Minibatch[1101-1200]: loss = 0.789191 * 100, metric = 14.20% * 100;
 Minibatch[1201-1300]: loss = 0.773704 * 100, metric = 14.12% * 100;
 Minibatch[1301-1400]: loss = 0.783694 * 100, metric = 14.06% * 100;
 Minibatch[1401-1500]: loss = 0.765015 * 100, metric = 13.70% * 100;
 Minibatch[1501-1600]: loss = 0.756835 * 100, metric = 13.46% * 100;
 Minibatch[1601-1700]: loss = 0.769324 * 100, metric = 13.74% * 100;
 Minibatch[1701-1800]: loss = 0.763834 * 100, metric = 13.98% * 100;
 Minibatch[1801-1900]: loss = 0.774803 * 100, metric = 13.77% * 100;
 Minibatch[1901-2000]: loss = 0.746848 * 100, metric = 13.45% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.785534 * 2000, metric = 14.23% * 2000 872.778s (  2.3 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 20.73% * 2000;
0.7814061363190412
 Minibatch[   1- 100]: loss = 0.753941 * 100, metric = 13.61% * 100;
 Minibatch[ 101- 200]: loss = 0.760703 * 100, metric = 14.01% * 100;
 Minibatch[ 201- 300]: loss = 0.748649 * 100, metric = 13.24% * 100;
 Minibatch[ 301- 400]: loss = 0.770269 * 100, metric = 13.81% * 100;
 Minibatch[ 401- 500]: loss = 0.777905 * 100, metric = 14.29% * 100;
 Minibatch[ 501- 600]: loss = 0.770971 * 100, metric = 13.89% * 100;
 Minibatch[ 601- 700]: loss = 0.772416 * 100, metric = 13.75% * 100;
 Minibatch[ 701- 800]: loss = 0.748447 * 100, metric = 13.15% * 100;
 Minibatch[ 801- 900]: loss = 0.769807 * 100, metric = 13.92% * 100;
 Minibatch[ 901-1000]: loss = 0.741015 * 100, metric = 13.55% * 100;
 Minibatch[1001-1100]: loss = 0.753293 * 100, metric = 13.63% * 100;
 Minibatch[1101-1200]: loss = 0.745277 * 100, metric = 13.39% * 100;
 Minibatch[1201-1300]: loss = 0.742717 * 100, metric = 13.16% * 100;
 Minibatch[1301-1400]: loss = 0.756828 * 100, metric = 13.29% * 100;
 Minibatch[1401-1500]: loss = 0.748242 * 100, metric = 13.35% * 100;
 Minibatch[1501-1600]: loss = 0.734559 * 100, metric = 13.10% * 100;
 Minibatch[1601-1700]: loss = 0.725989 * 100, metric = 12.66% * 100;
 Minibatch[1701-1800]: loss = 0.740183 * 100, metric = 13.09% * 100;
 Minibatch[1801-1900]: loss = 0.735659 * 100, metric = 12.89% * 100;
 Minibatch[1901-2000]: loss = 0.733513 * 100, metric = 13.01% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.751519 * 2000, metric = 13.44% * 2000 873.835s (  2.3 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 20.21% * 2000;
0.7706144444197416
 Minibatch[   1- 100]: loss = 0.756884 * 100, metric = 13.17% * 100;
 Minibatch[ 101- 200]: loss = 0.717680 * 100, metric = 12.42% * 100;
 Minibatch[ 201- 300]: loss = 0.743504 * 100, metric = 13.36% * 100;
 Minibatch[ 301- 400]: loss = 0.705387 * 100, metric = 12.41% * 100;
 Minibatch[ 401- 500]: loss = 0.734104 * 100, metric = 12.87% * 100;
 Minibatch[ 501- 600]: loss = 0.721307 * 100, metric = 12.89% * 100;
 Minibatch[ 601- 700]: loss = 0.725390 * 100, metric = 13.02% * 100;
 Minibatch[ 701- 800]: loss = 0.750553 * 100, metric = 13.32% * 100;
 Minibatch[ 801- 900]: loss = 0.742327 * 100, metric = 13.41% * 100;
 Minibatch[ 901-1000]: loss = 0.732064 * 100, metric = 13.24% * 100;
 Minibatch[1001-1100]: loss = 0.753162 * 100, metric = 13.73% * 100;
 Minibatch[1101-1200]: loss = 0.725216 * 100, metric = 13.09% * 100;
 Minibatch[1201-1300]: loss = 0.732725 * 100, metric = 13.16% * 100;
 Minibatch[1301-1400]: loss = 0.751926 * 100, metric = 13.57% * 100;
 Minibatch[1401-1500]: loss = 0.754274 * 100, metric = 13.48% * 100;
 Minibatch[1501-1600]: loss = 0.714618 * 100, metric = 12.64% * 100;
 Minibatch[1601-1700]: loss = 0.747639 * 100, metric = 13.43% * 100;
 Minibatch[1701-1800]: loss = 0.734325 * 100, metric = 13.02% * 100;
 Minibatch[1801-1900]: loss = 0.723860 * 100, metric = 12.85% * 100;
 Minibatch[1901-2000]: loss = 0.717462 * 100, metric = 12.70% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.734220 * 2000, metric = 13.09% * 2000 873.203s (  2.3 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 22.59% * 2000;
 Minibatch[   1- 100]: loss = 0.751928 * 100, metric = 13.01% * 100;
 Minibatch[ 101- 200]: loss = 0.728430 * 100, metric = 12.82% * 100;
 Minibatch[ 201- 300]: loss = 0.707359 * 100, metric = 12.65% * 100;
 Minibatch[ 301- 400]: loss = 0.745639 * 100, metric = 13.36% * 100;
 Minibatch[ 401- 500]: loss = 0.702596 * 100, metric = 12.37% * 100;
 Minibatch[ 501- 600]: loss = 0.700381 * 100, metric = 12.13% * 100;
 Minibatch[ 601- 700]: loss = 0.709969 * 100, metric = 12.30% * 100;
 Minibatch[ 701- 800]: loss = 0.728333 * 100, metric = 12.78% * 100;
 Minibatch[ 801- 900]: loss = 0.711650 * 100, metric = 12.42% * 100;
 Minibatch[ 901-1000]: loss = 0.690663 * 100, metric = 12.30% * 100;
 Minibatch[1001-1100]: loss = 0.706801 * 100, metric = 12.09% * 100;
 Minibatch[1101-1200]: loss = 0.694268 * 100, metric = 11.92% * 100;
 Minibatch[1201-1300]: loss = 0.707761 * 100, metric = 12.28% * 100;
 Minibatch[1301-1400]: loss = 0.734531 * 100, metric = 12.98% * 100;
 Minibatch[1401-1500]: loss = 0.705371 * 100, metric = 12.29% * 100;
 Minibatch[1501-1600]: loss = 0.710045 * 100, metric = 12.65% * 100;
 Minibatch[1601-1700]: loss = 0.728037 * 100, metric = 13.18% * 100;
 Minibatch[1701-1800]: loss = 0.726044 * 100, metric = 12.97% * 100;
 Minibatch[1801-1900]: loss = 0.724999 * 100, metric = 12.88% * 100;
 Minibatch[1901-2000]: loss = 0.700408 * 100, metric = 12.35% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.715761 * 2000, metric = 12.59% * 2000 877.944s (  2.3 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 21.62% * 2000;
 Minibatch[   1- 100]: loss = 0.704530 * 100, metric = 12.49% * 100;
 Minibatch[ 101- 200]: loss = 0.698366 * 100, metric = 12.37% * 100;
 Minibatch[ 201- 300]: loss = 0.716684 * 100, metric = 12.58% * 100;
 Minibatch[ 301- 400]: loss = 0.708761 * 100, metric = 12.32% * 100;
 Minibatch[ 401- 500]: loss = 0.686883 * 100, metric = 11.94% * 100;
 Minibatch[ 501- 600]: loss = 0.703266 * 100, metric = 12.57% * 100;
 Minibatch[ 601- 700]: loss = 0.689865 * 100, metric = 12.07% * 100;
 Minibatch[ 701- 800]: loss = 0.706133 * 100, metric = 12.62% * 100;
 Minibatch[ 801- 900]: loss = 0.706462 * 100, metric = 12.48% * 100;
 Minibatch[ 901-1000]: loss = 0.690624 * 100, metric = 12.35% * 100;
 Minibatch[1001-1100]: loss = 0.699445 * 100, metric = 11.85% * 100;
 Minibatch[1101-1200]: loss = 0.709751 * 100, metric = 12.34% * 100;
 Minibatch[1201-1300]: loss = 0.719512 * 100, metric = 12.67% * 100;
 Minibatch[1301-1400]: loss = 0.697215 * 100, metric = 12.25% * 100;
 Minibatch[1401-1500]: loss = 0.699420 * 100, metric = 12.23% * 100;
 Minibatch[1501-1600]: loss = 0.691650 * 100, metric = 12.00% * 100;
 Minibatch[1601-1700]: loss = 0.682406 * 100, metric = 11.76% * 100;
 Minibatch[1701-1800]: loss = 0.673164 * 100, metric = 11.68% * 100;
 Minibatch[1801-1900]: loss = 0.697943 * 100, metric = 12.27% * 100;
 Minibatch[1901-2000]: loss = 0.686691 * 100, metric = 12.15% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.698439 * 2000, metric = 12.25% * 2000 874.562s (  2.3 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.83% * 2000;
0.758663331605494
 Minibatch[   1- 100]: loss = 0.688237 * 100, metric = 12.20% * 100;
 Minibatch[ 101- 200]: loss = 0.685680 * 100, metric = 11.62% * 100;
 Minibatch[ 201- 300]: loss = 0.686243 * 100, metric = 11.94% * 100;
 Minibatch[ 301- 400]: loss = 0.676050 * 100, metric = 11.50% * 100;
 Minibatch[ 401- 500]: loss = 0.692388 * 100, metric = 11.96% * 100;
 Minibatch[ 501- 600]: loss = 0.666241 * 100, metric = 11.37% * 100;
 Minibatch[ 601- 700]: loss = 0.685201 * 100, metric = 11.66% * 100;
 Minibatch[ 701- 800]: loss = 0.686568 * 100, metric = 11.63% * 100;
 Minibatch[ 801- 900]: loss = 0.687598 * 100, metric = 12.07% * 100;
 Minibatch[ 901-1000]: loss = 0.680885 * 100, metric = 11.74% * 100;
 Minibatch[1001-1100]: loss = 0.687648 * 100, metric = 12.28% * 100;
 Minibatch[1101-1200]: loss = 0.668782 * 100, metric = 11.58% * 100;
 Minibatch[1201-1300]: loss = 0.681982 * 100, metric = 11.67% * 100;
 Minibatch[1301-1400]: loss = 0.658748 * 100, metric = 11.17% * 100;
 Minibatch[1401-1500]: loss = 0.662268 * 100, metric = 11.15% * 100;
 Minibatch[1501-1600]: loss = 0.683201 * 100, metric = 11.71% * 100;
 Minibatch[1601-1700]: loss = 0.683516 * 100, metric = 11.79% * 100;
 Minibatch[1701-1800]: loss = 0.665585 * 100, metric = 11.43% * 100;
 Minibatch[1801-1900]: loss = 0.674390 * 100, metric = 11.75% * 100;
 Minibatch[1901-2000]: loss = 0.672419 * 100, metric = 11.77% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.678682 * 2000, metric = 11.70% * 2000 880.319s (  2.3 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.27% * 2000;
0.7187821742519737
 Minibatch[   1- 100]: loss = 0.685094 * 100, metric = 11.66% * 100;
 Minibatch[ 101- 200]: loss = 0.671749 * 100, metric = 11.81% * 100;
 Minibatch[ 201- 300]: loss = 0.654847 * 100, metric = 11.25% * 100;
 Minibatch[ 301- 400]: loss = 0.666683 * 100, metric = 11.69% * 100;
 Minibatch[ 401- 500]: loss = 0.674141 * 100, metric = 11.71% * 100;
 Minibatch[ 501- 600]: loss = 0.696712 * 100, metric = 12.60% * 100;
 Minibatch[ 601- 700]: loss = 0.654261 * 100, metric = 11.28% * 100;
 Minibatch[ 701- 800]: loss = 0.671553 * 100, metric = 11.37% * 100;
 Minibatch[ 801- 900]: loss = 0.648923 * 100, metric = 10.80% * 100;
 Minibatch[ 901-1000]: loss = 0.644937 * 100, metric = 10.76% * 100;
 Minibatch[1001-1100]: loss = 0.645709 * 100, metric = 11.00% * 100;
 Minibatch[1101-1200]: loss = 0.647280 * 100, metric = 11.04% * 100;
 Minibatch[1201-1300]: loss = 0.664990 * 100, metric = 11.55% * 100;
 Minibatch[1301-1400]: loss = 0.668525 * 100, metric = 11.68% * 100;
 Minibatch[1401-1500]: loss = 0.665584 * 100, metric = 11.52% * 100;
 Minibatch[1501-1600]: loss = 0.663008 * 100, metric = 11.43% * 100;
 Minibatch[1601-1700]: loss = 0.654633 * 100, metric = 11.10% * 100;
 Minibatch[1701-1800]: loss = 0.663026 * 100, metric = 11.28% * 100;
 Minibatch[1801-1900]: loss = 0.664628 * 100, metric = 11.53% * 100;
 Minibatch[1901-2000]: loss = 0.664309 * 100, metric = 11.38% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.663530 * 2000, metric = 11.42% * 2000 876.371s (  2.3 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 18.13% * 2000;
0.7029373517334461
 Minibatch[   1- 100]: loss = 0.637019 * 100, metric = 10.73% * 100;
 Minibatch[ 101- 200]: loss = 0.675873 * 100, metric = 11.61% * 100;
 Minibatch[ 201- 300]: loss = 0.665836 * 100, metric = 11.33% * 100;
 Minibatch[ 301- 400]: loss = 0.679747 * 100, metric = 11.94% * 100;
 Minibatch[ 401- 500]: loss = 0.666756 * 100, metric = 11.44% * 100;
 Minibatch[ 501- 600]: loss = 0.652206 * 100, metric = 11.25% * 100;
 Minibatch[ 601- 700]: loss = 0.648068 * 100, metric = 11.11% * 100;
 Minibatch[ 701- 800]: loss = 0.638768 * 100, metric = 10.95% * 100;
 Minibatch[ 801- 900]: loss = 0.635167 * 100, metric = 10.74% * 100;
 Minibatch[ 901-1000]: loss = 0.643502 * 100, metric = 11.24% * 100;
 Minibatch[1001-1100]: loss = 0.628279 * 100, metric = 10.41% * 100;
 Minibatch[1101-1200]: loss = 0.651909 * 100, metric = 11.24% * 100;
 Minibatch[1201-1300]: loss = 0.648846 * 100, metric = 11.00% * 100;
 Minibatch[1301-1400]: loss = 0.631616 * 100, metric = 10.41% * 100;
 Minibatch[1401-1500]: loss = 0.643957 * 100, metric = 11.09% * 100;
 Minibatch[1501-1600]: loss = 0.647546 * 100, metric = 11.22% * 100;
 Minibatch[1601-1700]: loss = 0.639142 * 100, metric = 10.90% * 100;
 Minibatch[1701-1800]: loss = 0.629978 * 100, metric = 10.59% * 100;
 Minibatch[1801-1900]: loss = 0.634291 * 100, metric = 10.73% * 100;
 Minibatch[1901-2000]: loss = 0.641259 * 100, metric = 10.92% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.646988 * 2000, metric = 11.04% * 2000 883.662s (  2.3 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 17.60% * 2000;
0.6926692912057042
 Minibatch[   1- 100]: loss = 0.660900 * 100, metric = 11.94% * 100;
 Minibatch[ 101- 200]: loss = 0.624582 * 100, metric = 10.94% * 100;
 Minibatch[ 201- 300]: loss = 0.637643 * 100, metric = 10.72% * 100;
 Minibatch[ 301- 400]: loss = 0.625285 * 100, metric = 10.51% * 100;
 Minibatch[ 401- 500]: loss = 0.641403 * 100, metric = 10.98% * 100;
 Minibatch[ 501- 600]: loss = 0.625756 * 100, metric = 10.41% * 100;
 Minibatch[ 601- 700]: loss = 0.613712 * 100, metric = 10.14% * 100;
 Minibatch[ 701- 800]: loss = 0.616966 * 100, metric = 10.22% * 100;
 Minibatch[ 801- 900]: loss = 0.637340 * 100, metric = 10.60% * 100;
 Minibatch[ 901-1000]: loss = 0.644194 * 100, metric = 10.76% * 100;
 Minibatch[1001-1100]: loss = 0.633515 * 100, metric = 10.81% * 100;
 Minibatch[1101-1200]: loss = 0.626437 * 100, metric = 10.46% * 100;
 Minibatch[1201-1300]: loss = 0.632220 * 100, metric = 11.09% * 100;
 Minibatch[1301-1400]: loss = 0.629963 * 100, metric = 10.69% * 100;
 Minibatch[1401-1500]: loss = 0.620955 * 100, metric = 10.30% * 100;
 Minibatch[1501-1600]: loss = 0.621731 * 100, metric = 10.73% * 100;
 Minibatch[1601-1700]: loss = 0.627232 * 100, metric = 10.50% * 100;
 Minibatch[1701-1800]: loss = 0.633671 * 100, metric = 10.71% * 100;
 Minibatch[1801-1900]: loss = 0.635325 * 100, metric = 10.83% * 100;
 Minibatch[1901-2000]: loss = 0.614661 * 100, metric = 10.42% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.630174 * 2000, metric = 10.69% * 2000 894.487s (  2.2 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 17.31% * 2000;
0.6841037027388811
 Minibatch[   1- 100]: loss = 0.607330 * 100, metric = 9.86% * 100;
 Minibatch[ 101- 200]: loss = 0.621258 * 100, metric = 10.48% * 100;
 Minibatch[ 201- 300]: loss = 0.629178 * 100, metric = 10.75% * 100;
 Minibatch[ 301- 400]: loss = 0.622228 * 100, metric = 10.63% * 100;
 Minibatch[ 401- 500]: loss = 0.622627 * 100, metric = 10.64% * 100;
 Minibatch[ 501- 600]: loss = 0.628290 * 100, metric = 10.64% * 100;
 Minibatch[ 601- 700]: loss = 0.616677 * 100, metric = 10.26% * 100;
 Minibatch[ 701- 800]: loss = 0.624607 * 100, metric = 10.48% * 100;
 Minibatch[ 801- 900]: loss = 0.616523 * 100, metric = 10.27% * 100;
 Minibatch[ 901-1000]: loss = 0.623661 * 100, metric = 10.55% * 100;
 Minibatch[1001-1100]: loss = 0.623893 * 100, metric = 10.38% * 100;
 Minibatch[1101-1200]: loss = 0.621689 * 100, metric = 10.60% * 100;
 Minibatch[1201-1300]: loss = 0.607630 * 100, metric = 10.22% * 100;
 Minibatch[1301-1400]: loss = 0.588594 * 100, metric = 9.68% * 100;
 Minibatch[1401-1500]: loss = 0.617205 * 100, metric = 10.73% * 100;
 Minibatch[1501-1600]: loss = 0.592057 * 100, metric = 9.71% * 100;
 Minibatch[1601-1700]: loss = 0.605696 * 100, metric = 10.16% * 100;
 Minibatch[1701-1800]: loss = 0.618953 * 100, metric = 10.38% * 100;
 Minibatch[1801-1900]: loss = 0.604340 * 100, metric = 10.23% * 100;
 Minibatch[1901-2000]: loss = 0.595469 * 100, metric = 10.16% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.614395 * 2000, metric = 10.34% * 2000 901.391s (  2.2 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 17.66% * 2000;
 Minibatch[   1- 100]: loss = 0.586928 * 100, metric = 9.55% * 100;
 Minibatch[ 101- 200]: loss = 0.590238 * 100, metric = 9.51% * 100;
 Minibatch[ 201- 300]: loss = 0.598372 * 100, metric = 9.93% * 100;
 Minibatch[ 301- 400]: loss = 0.628106 * 100, metric = 10.82% * 100;
 Minibatch[ 401- 500]: loss = 0.588504 * 100, metric = 9.77% * 100;
 Minibatch[ 501- 600]: loss = 0.573611 * 100, metric = 9.39% * 100;
 Minibatch[ 601- 700]: loss = 0.589017 * 100, metric = 9.64% * 100;
 Minibatch[ 701- 800]: loss = 0.599388 * 100, metric = 10.10% * 100;
 Minibatch[ 801- 900]: loss = 0.593267 * 100, metric = 9.71% * 100;
 Minibatch[ 901-1000]: loss = 0.594949 * 100, metric = 9.97% * 100;
 Minibatch[1001-1100]: loss = 0.593438 * 100, metric = 10.04% * 100;
 Minibatch[1101-1200]: loss = 0.595813 * 100, metric = 9.87% * 100;
 Minibatch[1201-1300]: loss = 0.594675 * 100, metric = 9.86% * 100;
 Minibatch[1301-1400]: loss = 0.581869 * 100, metric = 9.33% * 100;
 Minibatch[1401-1500]: loss = 0.602664 * 100, metric = 10.21% * 100;
 Minibatch[1501-1600]: loss = 0.568577 * 100, metric = 9.33% * 100;
 Minibatch[1601-1700]: loss = 0.601785 * 100, metric = 10.04% * 100;
 Minibatch[1701-1800]: loss = 0.581270 * 100, metric = 9.37% * 100;
 Minibatch[1801-1900]: loss = 0.585798 * 100, metric = 9.69% * 100;
 Minibatch[1901-2000]: loss = 0.597109 * 100, metric = 10.01% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.592269 * 2000, metric = 9.81% * 2000 921.300s (  2.2 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 18.93% * 2000;
 Minibatch[   1- 100]: loss = 0.595267 * 100, metric = 10.05% * 100;
 Minibatch[ 101- 200]: loss = 0.592465 * 100, metric = 9.89% * 100;
 Minibatch[ 201- 300]: loss = 0.588151 * 100, metric = 10.01% * 100;
 Minibatch[ 301- 400]: loss = 0.596786 * 100, metric = 9.84% * 100;
 Minibatch[ 401- 500]: loss = 0.590043 * 100, metric = 10.08% * 100;
 Minibatch[ 501- 600]: loss = 0.607374 * 100, metric = 10.33% * 100;
 Minibatch[ 601- 700]: loss = 0.571012 * 100, metric = 9.08% * 100;
 Minibatch[ 701- 800]: loss = 0.574327 * 100, metric = 9.33% * 100;
 Minibatch[ 801- 900]: loss = 0.580667 * 100, metric = 9.66% * 100;
 Minibatch[ 901-1000]: loss = 0.596306 * 100, metric = 9.97% * 100;
 Minibatch[1001-1100]: loss = 0.600172 * 100, metric = 10.21% * 100;
 Minibatch[1101-1200]: loss = 0.586820 * 100, metric = 9.53% * 100;
 Minibatch[1201-1300]: loss = 0.589097 * 100, metric = 9.88% * 100;
 Minibatch[1301-1400]: loss = 0.571773 * 100, metric = 9.43% * 100;
 Minibatch[1401-1500]: loss = 0.577183 * 100, metric = 9.59% * 100;
 Minibatch[1501-1600]: loss = 0.567993 * 100, metric = 9.18% * 100;
 Minibatch[1601-1700]: loss = 0.569202 * 100, metric = 9.37% * 100;
 Minibatch[1701-1800]: loss = 0.579836 * 100, metric = 9.49% * 100;
 Minibatch[1801-1900]: loss = 0.570681 * 100, metric = 9.32% * 100;
 Minibatch[1901-2000]: loss = 0.590046 * 100, metric = 9.62% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.584760 * 2000, metric = 9.69% * 2000 893.275s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 19.99% * 2000;
 Minibatch[   1- 100]: loss = 0.564586 * 100, metric = 9.10% * 100;
 Minibatch[ 101- 200]: loss = 0.563749 * 100, metric = 9.09% * 100;
 Minibatch[ 201- 300]: loss = 0.583309 * 100, metric = 9.64% * 100;
 Minibatch[ 301- 400]: loss = 0.584362 * 100, metric = 9.65% * 100;
 Minibatch[ 401- 500]: loss = 0.576621 * 100, metric = 9.45% * 100;
 Minibatch[ 501- 600]: loss = 0.576913 * 100, metric = 9.69% * 100;
 Minibatch[ 601- 700]: loss = 0.573758 * 100, metric = 9.52% * 100;
 Minibatch[ 701- 800]: loss = 0.589319 * 100, metric = 9.98% * 100;
 Minibatch[ 801- 900]: loss = 0.593858 * 100, metric = 10.16% * 100;
 Minibatch[ 901-1000]: loss = 0.582546 * 100, metric = 9.86% * 100;
 Minibatch[1001-1100]: loss = 0.577724 * 100, metric = 9.81% * 100;
 Minibatch[1101-1200]: loss = 0.561866 * 100, metric = 9.23% * 100;
 Minibatch[1201-1300]: loss = 0.555175 * 100, metric = 8.83% * 100;
 Minibatch[1301-1400]: loss = 0.576303 * 100, metric = 9.70% * 100;
 Minibatch[1401-1500]: loss = 0.573676 * 100, metric = 9.65% * 100;
 Minibatch[1501-1600]: loss = 0.557965 * 100, metric = 9.04% * 100;
 Minibatch[1601-1700]: loss = 0.568376 * 100, metric = 9.22% * 100;
 Minibatch[1701-1800]: loss = 0.562885 * 100, metric = 9.08% * 100;
 Minibatch[1801-1900]: loss = 0.567052 * 100, metric = 9.17% * 100;
 Minibatch[1901-2000]: loss = 0.568528 * 100, metric = 9.15% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.572928 * 2000, metric = 9.45% * 2000 896.701s (  2.2 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 17.91% * 2000;
 Minibatch[   1- 100]: loss = 0.567229 * 100, metric = 9.29% * 100;
 Minibatch[ 101- 200]: loss = 0.571543 * 100, metric = 9.20% * 100;
 Minibatch[ 201- 300]: loss = 0.571527 * 100, metric = 9.29% * 100;
 Minibatch[ 301- 400]: loss = 0.547303 * 100, metric = 8.70% * 100;
 Minibatch[ 401- 500]: loss = 0.557235 * 100, metric = 9.12% * 100;
 Minibatch[ 501- 600]: loss = 0.558683 * 100, metric = 8.91% * 100;
 Minibatch[ 601- 700]: loss = 0.544721 * 100, metric = 8.74% * 100;
 Minibatch[ 701- 800]: loss = 0.573372 * 100, metric = 9.60% * 100;
 Minibatch[ 801- 900]: loss = 0.578074 * 100, metric = 9.93% * 100;
 Minibatch[ 901-1000]: loss = 0.557427 * 100, metric = 9.09% * 100;
 Minibatch[1001-1100]: loss = 0.559274 * 100, metric = 9.00% * 100;
 Minibatch[1101-1200]: loss = 0.551042 * 100, metric = 8.97% * 100;
 Minibatch[1201-1300]: loss = 0.546262 * 100, metric = 8.64% * 100;
 Minibatch[1301-1400]: loss = 0.572345 * 100, metric = 9.79% * 100;
 Minibatch[1401-1500]: loss = 0.525885 * 100, metric = 8.39% * 100;
 Minibatch[1501-1600]: loss = 0.542112 * 100, metric = 8.74% * 100;
 Minibatch[1601-1700]: loss = 0.549681 * 100, metric = 8.64% * 100;
 Minibatch[1701-1800]: loss = 0.531915 * 100, metric = 8.35% * 100;
 Minibatch[1801-1900]: loss = 0.538160 * 100, metric = 8.73% * 100;
 Minibatch[1901-2000]: loss = 0.544307 * 100, metric = 8.87% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.554405 * 2000, metric = 9.00% * 2000 938.225s (  2.1 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 16.58% * 2000;
0.6701969589143991
 Minibatch[   1- 100]: loss = 0.564427 * 100, metric = 9.50% * 100;
 Minibatch[ 101- 200]: loss = 0.553667 * 100, metric = 9.06% * 100;
 Minibatch[ 201- 300]: loss = 0.548071 * 100, metric = 8.78% * 100;
 Minibatch[ 301- 400]: loss = 0.544055 * 100, metric = 8.72% * 100;
 Minibatch[ 401- 500]: loss = 0.519554 * 100, metric = 8.07% * 100;
 Minibatch[ 501- 600]: loss = 0.541456 * 100, metric = 8.85% * 100;
 Minibatch[ 601- 700]: loss = 0.536639 * 100, metric = 8.63% * 100;
 Minibatch[ 701- 800]: loss = 0.531516 * 100, metric = 8.53% * 100;
 Minibatch[ 801- 900]: loss = 0.526967 * 100, metric = 8.27% * 100;
 Minibatch[ 901-1000]: loss = 0.543952 * 100, metric = 8.87% * 100;
 Minibatch[1001-1100]: loss = 0.526553 * 100, metric = 8.46% * 100;
 Minibatch[1101-1200]: loss = 0.541175 * 100, metric = 8.71% * 100;
 Minibatch[1201-1300]: loss = 0.528102 * 100, metric = 8.41% * 100;
 Minibatch[1301-1400]: loss = 0.535103 * 100, metric = 8.60% * 100;
 Minibatch[1401-1500]: loss = 0.531353 * 100, metric = 8.64% * 100;
 Minibatch[1501-1600]: loss = 0.538458 * 100, metric = 8.70% * 100;
 Minibatch[1601-1700]: loss = 0.539137 * 100, metric = 8.85% * 100;
 Minibatch[1701-1800]: loss = 0.556387 * 100, metric = 9.02% * 100;
 Minibatch[1801-1900]: loss = 0.557632 * 100, metric = 9.16% * 100;
 Minibatch[1901-2000]: loss = 0.529166 * 100, metric = 8.81% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.539668 * 2000, metric = 8.73% * 2000 895.785s (  2.2 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 15.93% * 2000;
0.6605787407457828
 Minibatch[   1- 100]: loss = 0.520786 * 100, metric = 7.99% * 100;
 Minibatch[ 101- 200]: loss = 0.549224 * 100, metric = 8.76% * 100;
 Minibatch[ 201- 300]: loss = 0.544369 * 100, metric = 8.94% * 100;
 Minibatch[ 301- 400]: loss = 0.544416 * 100, metric = 8.73% * 100;
 Minibatch[ 401- 500]: loss = 0.544713 * 100, metric = 8.78% * 100;
 Minibatch[ 501- 600]: loss = 0.532048 * 100, metric = 8.22% * 100;
 Minibatch[ 601- 700]: loss = 0.519211 * 100, metric = 8.22% * 100;
 Minibatch[ 701- 800]: loss = 0.536192 * 100, metric = 8.42% * 100;
 Minibatch[ 801- 900]: loss = 0.536847 * 100, metric = 8.75% * 100;
 Minibatch[ 901-1000]: loss = 0.530591 * 100, metric = 8.26% * 100;
 Minibatch[1001-1100]: loss = 0.520477 * 100, metric = 8.39% * 100;
 Minibatch[1101-1200]: loss = 0.546207 * 100, metric = 8.82% * 100;
 Minibatch[1201-1300]: loss = 0.535865 * 100, metric = 8.73% * 100;
 Minibatch[1301-1400]: loss = 0.522817 * 100, metric = 8.22% * 100;
 Minibatch[1401-1500]: loss = 0.536783 * 100, metric = 8.76% * 100;
 Minibatch[1501-1600]: loss = 0.532977 * 100, metric = 8.53% * 100;
 Minibatch[1601-1700]: loss = 0.532836 * 100, metric = 8.33% * 100;
 Minibatch[1701-1800]: loss = 0.526183 * 100, metric = 8.50% * 100;
 Minibatch[1801-1900]: loss = 0.550107 * 100, metric = 9.04% * 100;
 Minibatch[1901-2000]: loss = 0.553386 * 100, metric = 9.20% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.535802 * 2000, metric = 8.58% * 2000 863.128s (  2.3 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 15.66% * 2000;
0.6418539567738771
 Minibatch[   1- 100]: loss = 0.519687 * 100, metric = 8.18% * 100;
 Minibatch[ 101- 200]: loss = 0.544894 * 100, metric = 8.80% * 100;
 Minibatch[ 201- 300]: loss = 0.526258 * 100, metric = 8.33% * 100;
 Minibatch[ 301- 400]: loss = 0.541118 * 100, metric = 8.78% * 100;
 Minibatch[ 401- 500]: loss = 0.514528 * 100, metric = 7.98% * 100;
 Minibatch[ 501- 600]: loss = 0.523874 * 100, metric = 8.34% * 100;
 Minibatch[ 601- 700]: loss = 0.528962 * 100, metric = 8.46% * 100;
 Minibatch[ 701- 800]: loss = 0.513254 * 100, metric = 8.31% * 100;
 Minibatch[ 801- 900]: loss = 0.528478 * 100, metric = 8.41% * 100;
 Minibatch[ 901-1000]: loss = 0.531723 * 100, metric = 8.44% * 100;
 Minibatch[1001-1100]: loss = 0.533015 * 100, metric = 8.65% * 100;
 Minibatch[1101-1200]: loss = 0.523903 * 100, metric = 8.41% * 100;
 Minibatch[1201-1300]: loss = 0.535024 * 100, metric = 8.86% * 100;
 Minibatch[1301-1400]: loss = 0.532964 * 100, metric = 8.67% * 100;
 Minibatch[1401-1500]: loss = 0.503253 * 100, metric = 7.83% * 100;
 Minibatch[1501-1600]: loss = 0.526960 * 100, metric = 8.21% * 100;
 Minibatch[1601-1700]: loss = 0.497099 * 100, metric = 7.59% * 100;
 Minibatch[1701-1800]: loss = 0.513505 * 100, metric = 8.01% * 100;
 Minibatch[1801-1900]: loss = 0.499274 * 100, metric = 7.84% * 100;
 Minibatch[1901-2000]: loss = 0.511556 * 100, metric = 7.88% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.522466 * 2000, metric = 8.30% * 2000 884.508s (  2.3 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 16.75% * 2000;
 Minibatch[   1- 100]: loss = 0.530887 * 100, metric = 8.73% * 100;
 Minibatch[ 101- 200]: loss = 0.535682 * 100, metric = 8.67% * 100;
 Minibatch[ 201- 300]: loss = 0.498500 * 100, metric = 7.61% * 100;
 Minibatch[ 301- 400]: loss = 0.525910 * 100, metric = 8.45% * 100;
 Minibatch[ 401- 500]: loss = 0.517505 * 100, metric = 8.11% * 100;
 Minibatch[ 501- 600]: loss = 0.505681 * 100, metric = 7.76% * 100;
 Minibatch[ 601- 700]: loss = 0.512670 * 100, metric = 8.04% * 100;
 Minibatch[ 701- 800]: loss = 0.495093 * 100, metric = 7.96% * 100;
 Minibatch[ 801- 900]: loss = 0.539821 * 100, metric = 8.68% * 100;
 Minibatch[ 901-1000]: loss = 0.516033 * 100, metric = 8.27% * 100;
 Minibatch[1001-1100]: loss = 0.528217 * 100, metric = 8.31% * 100;
 Minibatch[1101-1200]: loss = 0.523859 * 100, metric = 8.47% * 100;
 Minibatch[1201-1300]: loss = 0.508162 * 100, metric = 7.90% * 100;
 Minibatch[1301-1400]: loss = 0.500906 * 100, metric = 7.77% * 100;
 Minibatch[1401-1500]: loss = 0.517191 * 100, metric = 8.39% * 100;
 Minibatch[1501-1600]: loss = 0.519062 * 100, metric = 8.28% * 100;
 Minibatch[1601-1700]: loss = 0.503700 * 100, metric = 7.79% * 100;
 Minibatch[1701-1800]: loss = 0.492334 * 100, metric = 7.58% * 100;
 Minibatch[1801-1900]: loss = 0.499864 * 100, metric = 7.83% * 100;
 Minibatch[1901-2000]: loss = 0.492627 * 100, metric = 7.69% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.513185 * 2000, metric = 8.12% * 2000 885.606s (  2.3 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 16.03% * 2000;
 Minibatch[   1- 100]: loss = 0.506373 * 100, metric = 7.90% * 100;
 Minibatch[ 101- 200]: loss = 0.505819 * 100, metric = 7.87% * 100;
 Minibatch[ 201- 300]: loss = 0.501974 * 100, metric = 7.85% * 100;
 Minibatch[ 301- 400]: loss = 0.517366 * 100, metric = 8.04% * 100;
 Minibatch[ 401- 500]: loss = 0.501962 * 100, metric = 7.75% * 100;
 Minibatch[ 501- 600]: loss = 0.501884 * 100, metric = 8.04% * 100;
 Minibatch[ 601- 700]: loss = 0.514636 * 100, metric = 8.23% * 100;
 Minibatch[ 701- 800]: loss = 0.507691 * 100, metric = 7.88% * 100;
 Minibatch[ 801- 900]: loss = 0.509798 * 100, metric = 8.11% * 100;
 Minibatch[ 901-1000]: loss = 0.509738 * 100, metric = 8.03% * 100;
 Minibatch[1001-1100]: loss = 0.480285 * 100, metric = 7.31% * 100;
 Minibatch[1101-1200]: loss = 0.499576 * 100, metric = 7.89% * 100;
 Minibatch[1201-1300]: loss = 0.503135 * 100, metric = 7.89% * 100;
 Minibatch[1301-1400]: loss = 0.501411 * 100, metric = 7.89% * 100;
 Minibatch[1401-1500]: loss = 0.494292 * 100, metric = 7.90% * 100;
 Minibatch[1501-1600]: loss = 0.512307 * 100, metric = 8.21% * 100;
 Minibatch[1601-1700]: loss = 0.492593 * 100, metric = 7.77% * 100;
 Minibatch[1701-1800]: loss = 0.501077 * 100, metric = 8.03% * 100;
 Minibatch[1801-1900]: loss = 0.489998 * 100, metric = 7.50% * 100;
 Minibatch[1901-2000]: loss = 0.490924 * 100, metric = 7.66% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.502142 * 2000, metric = 7.89% * 2000 878.974s (  2.3 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 15.93% * 2000;
 Minibatch[   1- 100]: loss = 0.510078 * 100, metric = 8.10% * 100;
 Minibatch[ 101- 200]: loss = 0.496576 * 100, metric = 7.69% * 100;
 Minibatch[ 201- 300]: loss = 0.496523 * 100, metric = 7.75% * 100;
 Minibatch[ 301- 400]: loss = 0.507054 * 100, metric = 8.22% * 100;
 Minibatch[ 401- 500]: loss = 0.493389 * 100, metric = 7.77% * 100;
 Minibatch[ 501- 600]: loss = 0.490285 * 100, metric = 7.34% * 100;
 Minibatch[ 601- 700]: loss = 0.491620 * 100, metric = 7.58% * 100;
 Minibatch[ 701- 800]: loss = 0.470481 * 100, metric = 7.12% * 100;
 Minibatch[ 801- 900]: loss = 0.503096 * 100, metric = 7.86% * 100;
 Minibatch[ 901-1000]: loss = 0.481685 * 100, metric = 7.39% * 100;
 Minibatch[1001-1100]: loss = 0.486364 * 100, metric = 7.43% * 100;
 Minibatch[1101-1200]: loss = 0.482759 * 100, metric = 7.46% * 100;
 Minibatch[1201-1300]: loss = 0.494210 * 100, metric = 7.70% * 100;
 Minibatch[1301-1400]: loss = 0.478054 * 100, metric = 7.21% * 100;
 Minibatch[1401-1500]: loss = 0.504805 * 100, metric = 7.99% * 100;
 Minibatch[1501-1600]: loss = 0.506329 * 100, metric = 8.38% * 100;
 Minibatch[1601-1700]: loss = 0.487437 * 100, metric = 7.76% * 100;
 Minibatch[1701-1800]: loss = 0.480626 * 100, metric = 7.34% * 100;
 Minibatch[1801-1900]: loss = 0.503092 * 100, metric = 7.97% * 100;
 Minibatch[1901-2000]: loss = 0.473207 * 100, metric = 7.38% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.491884 * 2000, metric = 7.67% * 2000 867.722s (  2.3 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 15.02% * 2000;
0.6280114890187979
 Minibatch[   1- 100]: loss = 0.501235 * 100, metric = 7.93% * 100;
 Minibatch[ 101- 200]: loss = 0.490660 * 100, metric = 7.60% * 100;
 Minibatch[ 201- 300]: loss = 0.504237 * 100, metric = 8.04% * 100;
 Minibatch[ 301- 400]: loss = 0.483447 * 100, metric = 7.44% * 100;
 Minibatch[ 401- 500]: loss = 0.481361 * 100, metric = 7.44% * 100;
 Minibatch[ 501- 600]: loss = 0.489007 * 100, metric = 7.41% * 100;
 Minibatch[ 601- 700]: loss = 0.474096 * 100, metric = 7.28% * 100;
 Minibatch[ 701- 800]: loss = 0.484217 * 100, metric = 7.50% * 100;
 Minibatch[ 801- 900]: loss = 0.497393 * 100, metric = 7.81% * 100;
 Minibatch[ 901-1000]: loss = 0.495158 * 100, metric = 7.49% * 100;
 Minibatch[1001-1100]: loss = 0.472019 * 100, metric = 7.15% * 100;
 Minibatch[1101-1200]: loss = 0.461735 * 100, metric = 6.85% * 100;
 Minibatch[1201-1300]: loss = 0.480068 * 100, metric = 7.34% * 100;
 Minibatch[1301-1400]: loss = 0.484374 * 100, metric = 7.53% * 100;
 Minibatch[1401-1500]: loss = 0.475464 * 100, metric = 7.36% * 100;
 Minibatch[1501-1600]: loss = 0.469070 * 100, metric = 7.07% * 100;
 Minibatch[1601-1700]: loss = 0.472111 * 100, metric = 7.32% * 100;
 Minibatch[1701-1800]: loss = 0.485410 * 100, metric = 7.38% * 100;
 Minibatch[1801-1900]: loss = 0.481761 * 100, metric = 7.57% * 100;
 Minibatch[1901-2000]: loss = 0.479042 * 100, metric = 7.23% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.483093 * 2000, metric = 7.44% * 2000 870.560s (  2.3 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 16.17% * 2000;
 Minibatch[   1- 100]: loss = 0.501141 * 100, metric = 7.68% * 100;
 Minibatch[ 101- 200]: loss = 0.494793 * 100, metric = 7.96% * 100;
 Minibatch[ 201- 300]: loss = 0.478168 * 100, metric = 7.19% * 100;
 Minibatch[ 301- 400]: loss = 0.489928 * 100, metric = 7.41% * 100;
 Minibatch[ 401- 500]: loss = 0.493347 * 100, metric = 7.58% * 100;
 Minibatch[ 501- 600]: loss = 0.475299 * 100, metric = 7.30% * 100;
 Minibatch[ 601- 700]: loss = 0.487495 * 100, metric = 7.27% * 100;
 Minibatch[ 701- 800]: loss = 0.459924 * 100, metric = 6.91% * 100;
 Minibatch[ 801- 900]: loss = 0.453637 * 100, metric = 7.11% * 100;
 Minibatch[ 901-1000]: loss = 0.479258 * 100, metric = 7.43% * 100;
 Minibatch[1001-1100]: loss = 0.472765 * 100, metric = 7.33% * 100;
 Minibatch[1101-1200]: loss = 0.475164 * 100, metric = 7.12% * 100;
 Minibatch[1201-1300]: loss = 0.478848 * 100, metric = 7.38% * 100;
 Minibatch[1301-1400]: loss = 0.479354 * 100, metric = 7.49% * 100;
 Minibatch[1401-1500]: loss = 0.458975 * 100, metric = 6.97% * 100;
 Minibatch[1501-1600]: loss = 0.477668 * 100, metric = 7.20% * 100;
 Minibatch[1601-1700]: loss = 0.472418 * 100, metric = 7.35% * 100;
 Minibatch[1701-1800]: loss = 0.478752 * 100, metric = 7.37% * 100;
 Minibatch[1801-1900]: loss = 0.473790 * 100, metric = 7.43% * 100;
 Minibatch[1901-2000]: loss = 0.478523 * 100, metric = 7.17% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.477962 * 2000, metric = 7.33% * 2000 870.040s (  2.3 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 16.17% * 2000;
 Minibatch[   1- 100]: loss = 0.449542 * 100, metric = 6.90% * 100;
 Minibatch[ 101- 200]: loss = 0.475568 * 100, metric = 7.48% * 100;
 Minibatch[ 201- 300]: loss = 0.459895 * 100, metric = 7.06% * 100;
 Minibatch[ 301- 400]: loss = 0.475745 * 100, metric = 7.31% * 100;
 Minibatch[ 401- 500]: loss = 0.468001 * 100, metric = 7.30% * 100;
 Minibatch[ 501- 600]: loss = 0.461157 * 100, metric = 6.98% * 100;
 Minibatch[ 601- 700]: loss = 0.472580 * 100, metric = 7.20% * 100;
 Minibatch[ 701- 800]: loss = 0.463981 * 100, metric = 6.95% * 100;
 Minibatch[ 801- 900]: loss = 0.479535 * 100, metric = 7.53% * 100;
 Minibatch[ 901-1000]: loss = 0.471998 * 100, metric = 7.26% * 100;
 Minibatch[1001-1100]: loss = 0.475311 * 100, metric = 7.33% * 100;
 Minibatch[1101-1200]: loss = 0.487879 * 100, metric = 7.61% * 100;
 Minibatch[1201-1300]: loss = 0.475978 * 100, metric = 7.39% * 100;
 Minibatch[1301-1400]: loss = 0.462396 * 100, metric = 6.98% * 100;
 Minibatch[1401-1500]: loss = 0.463183 * 100, metric = 7.04% * 100;
 Minibatch[1501-1600]: loss = 0.485414 * 100, metric = 7.41% * 100;
 Minibatch[1601-1700]: loss = 0.463065 * 100, metric = 7.04% * 100;
 Minibatch[1701-1800]: loss = 0.460038 * 100, metric = 7.08% * 100;
 Minibatch[1801-1900]: loss = 0.486920 * 100, metric = 7.77% * 100;
 Minibatch[1901-2000]: loss = 0.476985 * 100, metric = 7.48% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.470759 * 2000, metric = 7.25% * 2000 866.461s (  2.3 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 15.18% * 2000;
 Minibatch[   1- 100]: loss = 0.475294 * 100, metric = 7.25% * 100;
 Minibatch[ 101- 200]: loss = 0.465813 * 100, metric = 7.33% * 100;
 Minibatch[ 201- 300]: loss = 0.464661 * 100, metric = 7.26% * 100;
 Minibatch[ 301- 400]: loss = 0.466774 * 100, metric = 7.13% * 100;
 Minibatch[ 401- 500]: loss = 0.471851 * 100, metric = 7.22% * 100;
 Minibatch[ 501- 600]: loss = 0.463003 * 100, metric = 6.95% * 100;
 Minibatch[ 601- 700]: loss = 0.465399 * 100, metric = 7.14% * 100;
 Minibatch[ 701- 800]: loss = 0.453104 * 100, metric = 6.80% * 100;
 Minibatch[ 801- 900]: loss = 0.459942 * 100, metric = 7.00% * 100;
 Minibatch[ 901-1000]: loss = 0.465185 * 100, metric = 7.12% * 100;
 Minibatch[1001-1100]: loss = 0.475667 * 100, metric = 7.29% * 100;
 Minibatch[1101-1200]: loss = 0.473162 * 100, metric = 7.30% * 100;
 Minibatch[1201-1300]: loss = 0.483906 * 100, metric = 7.43% * 100;
 Minibatch[1301-1400]: loss = 0.470211 * 100, metric = 7.11% * 100;
 Minibatch[1401-1500]: loss = 0.452836 * 100, metric = 6.51% * 100;
 Minibatch[1501-1600]: loss = 0.471049 * 100, metric = 7.21% * 100;
 Minibatch[1601-1700]: loss = 0.459609 * 100, metric = 6.89% * 100;
 Minibatch[1701-1800]: loss = 0.458131 * 100, metric = 6.82% * 100;
 Minibatch[1801-1900]: loss = 0.455128 * 100, metric = 6.82% * 100;
 Minibatch[1901-2000]: loss = 0.446212 * 100, metric = 6.68% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.464847 * 2000, metric = 7.06% * 2000 861.537s (  2.3 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 15.19% * 2000;
 Minibatch[   1- 100]: loss = 0.460190 * 100, metric = 7.00% * 100;
 Minibatch[ 101- 200]: loss = 0.451224 * 100, metric = 6.73% * 100;
 Minibatch[ 201- 300]: loss = 0.463603 * 100, metric = 7.19% * 100;
 Minibatch[ 301- 400]: loss = 0.450939 * 100, metric = 6.67% * 100;
 Minibatch[ 401- 500]: loss = 0.459663 * 100, metric = 6.93% * 100;
 Minibatch[ 501- 600]: loss = 0.451130 * 100, metric = 6.55% * 100;
 Minibatch[ 601- 700]: loss = 0.473914 * 100, metric = 7.31% * 100;
 Minibatch[ 701- 800]: loss = 0.457097 * 100, metric = 7.15% * 100;
 Minibatch[ 801- 900]: loss = 0.445913 * 100, metric = 6.60% * 100;
 Minibatch[ 901-1000]: loss = 0.441058 * 100, metric = 6.56% * 100;
 Minibatch[1001-1100]: loss = 0.461474 * 100, metric = 7.26% * 100;
 Minibatch[1101-1200]: loss = 0.468891 * 100, metric = 7.07% * 100;
 Minibatch[1201-1300]: loss = 0.455579 * 100, metric = 7.00% * 100;
 Minibatch[1301-1400]: loss = 0.442336 * 100, metric = 6.49% * 100;
 Minibatch[1401-1500]: loss = 0.452302 * 100, metric = 7.03% * 100;
 Minibatch[1501-1600]: loss = 0.441895 * 100, metric = 6.44% * 100;
 Minibatch[1601-1700]: loss = 0.474567 * 100, metric = 7.39% * 100;
 Minibatch[1701-1800]: loss = 0.468766 * 100, metric = 7.18% * 100;
 Minibatch[1801-1900]: loss = 0.457083 * 100, metric = 6.89% * 100;
 Minibatch[1901-2000]: loss = 0.461967 * 100, metric = 6.90% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.456980 * 2000, metric = 6.92% * 2000 859.127s (  2.3 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 16.22% * 2000;
 Minibatch[   1- 100]: loss = 0.455665 * 100, metric = 6.84% * 100;
 Minibatch[ 101- 200]: loss = 0.466555 * 100, metric = 6.99% * 100;
 Minibatch[ 201- 300]: loss = 0.451226 * 100, metric = 6.81% * 100;
 Minibatch[ 301- 400]: loss = 0.445784 * 100, metric = 6.70% * 100;
 Minibatch[ 401- 500]: loss = 0.453888 * 100, metric = 6.86% * 100;
 Minibatch[ 501- 600]: loss = 0.446333 * 100, metric = 6.64% * 100;
 Minibatch[ 601- 700]: loss = 0.450327 * 100, metric = 6.83% * 100;
 Minibatch[ 701- 800]: loss = 0.457174 * 100, metric = 7.00% * 100;
 Minibatch[ 801- 900]: loss = 0.465642 * 100, metric = 7.02% * 100;
 Minibatch[ 901-1000]: loss = 0.457506 * 100, metric = 7.15% * 100;
 Minibatch[1001-1100]: loss = 0.445941 * 100, metric = 6.63% * 100;
 Minibatch[1101-1200]: loss = 0.463921 * 100, metric = 7.05% * 100;
 Minibatch[1201-1300]: loss = 0.451936 * 100, metric = 6.88% * 100;
 Minibatch[1301-1400]: loss = 0.461708 * 100, metric = 7.01% * 100;
 Minibatch[1401-1500]: loss = 0.447260 * 100, metric = 6.87% * 100;
 Minibatch[1501-1600]: loss = 0.450071 * 100, metric = 6.85% * 100;
 Minibatch[1601-1700]: loss = 0.432541 * 100, metric = 6.27% * 100;
 Minibatch[1701-1800]: loss = 0.443296 * 100, metric = 6.65% * 100;
 Minibatch[1801-1900]: loss = 0.450219 * 100, metric = 6.81% * 100;
 Minibatch[1901-2000]: loss = 0.462001 * 100, metric = 7.03% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.452950 * 2000, metric = 6.84% * 2000 865.044s (  2.3 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 14.69% * 2000;
 Minibatch[   1- 100]: loss = 0.453929 * 100, metric = 6.89% * 100;
 Minibatch[ 101- 200]: loss = 0.444117 * 100, metric = 6.72% * 100;
 Minibatch[ 201- 300]: loss = 0.454855 * 100, metric = 6.96% * 100;
 Minibatch[ 301- 400]: loss = 0.454592 * 100, metric = 6.79% * 100;
 Minibatch[ 401- 500]: loss = 0.452993 * 100, metric = 6.92% * 100;
 Minibatch[ 501- 600]: loss = 0.465850 * 100, metric = 7.38% * 100;
 Minibatch[ 601- 700]: loss = 0.436244 * 100, metric = 6.30% * 100;
 Minibatch[ 701- 800]: loss = 0.435309 * 100, metric = 6.34% * 100;
 Minibatch[ 801- 900]: loss = 0.454316 * 100, metric = 6.86% * 100;
 Minibatch[ 901-1000]: loss = 0.458905 * 100, metric = 7.12% * 100;
 Minibatch[1001-1100]: loss = 0.450256 * 100, metric = 6.73% * 100;
 Minibatch[1101-1200]: loss = 0.440383 * 100, metric = 6.43% * 100;
 Minibatch[1201-1300]: loss = 0.450006 * 100, metric = 6.95% * 100;
 Minibatch[1301-1400]: loss = 0.438831 * 100, metric = 6.55% * 100;
 Minibatch[1401-1500]: loss = 0.459818 * 100, metric = 6.98% * 100;
 Minibatch[1501-1600]: loss = 0.441223 * 100, metric = 6.56% * 100;
 Minibatch[1601-1700]: loss = 0.451234 * 100, metric = 6.58% * 100;
 Minibatch[1701-1800]: loss = 0.439581 * 100, metric = 6.49% * 100;
 Minibatch[1801-1900]: loss = 0.444685 * 100, metric = 6.62% * 100;
 Minibatch[1901-2000]: loss = 0.439161 * 100, metric = 6.46% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.448314 * 2000, metric = 6.73% * 2000 866.584s (  2.3 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.72% * 2000;
0.6112050299495458
 Minibatch[   1- 100]: loss = 0.430185 * 100, metric = 6.10% * 100;
 Minibatch[ 101- 200]: loss = 0.445191 * 100, metric = 6.80% * 100;
 Minibatch[ 201- 300]: loss = 0.452376 * 100, metric = 6.84% * 100;
 Minibatch[ 301- 400]: loss = 0.464816 * 100, metric = 7.08% * 100;
 Minibatch[ 401- 500]: loss = 0.440629 * 100, metric = 6.32% * 100;
 Minibatch[ 501- 600]: loss = 0.453196 * 100, metric = 6.92% * 100;
 Minibatch[ 601- 700]: loss = 0.443542 * 100, metric = 6.75% * 100;
 Minibatch[ 701- 800]: loss = 0.451673 * 100, metric = 6.91% * 100;
 Minibatch[ 801- 900]: loss = 0.444372 * 100, metric = 6.80% * 100;
 Minibatch[ 901-1000]: loss = 0.450753 * 100, metric = 6.90% * 100;
 Minibatch[1001-1100]: loss = 0.448505 * 100, metric = 6.85% * 100;
 Minibatch[1101-1200]: loss = 0.438004 * 100, metric = 6.54% * 100;
 Minibatch[1201-1300]: loss = 0.447723 * 100, metric = 6.69% * 100;
 Minibatch[1301-1400]: loss = 0.433661 * 100, metric = 6.53% * 100;
 Minibatch[1401-1500]: loss = 0.457711 * 100, metric = 7.04% * 100;
 Minibatch[1501-1600]: loss = 0.418535 * 100, metric = 6.12% * 100;
 Minibatch[1601-1700]: loss = 0.450568 * 100, metric = 6.80% * 100;
 Minibatch[1701-1800]: loss = 0.426470 * 100, metric = 6.20% * 100;
 Minibatch[1801-1900]: loss = 0.459325 * 100, metric = 7.02% * 100;
 Minibatch[1901-2000]: loss = 0.442421 * 100, metric = 6.75% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.444983 * 2000, metric = 6.70% * 2000 872.391s (  2.3 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 15.59% * 2000;
 Minibatch[   1- 100]: loss = 0.459271 * 100, metric = 6.93% * 100;
 Minibatch[ 101- 200]: loss = 0.421798 * 100, metric = 6.00% * 100;
 Minibatch[ 201- 300]: loss = 0.429077 * 100, metric = 6.41% * 100;
 Minibatch[ 301- 400]: loss = 0.438305 * 100, metric = 6.49% * 100;
 Minibatch[ 401- 500]: loss = 0.442028 * 100, metric = 6.71% * 100;
 Minibatch[ 501- 600]: loss = 0.420172 * 100, metric = 6.10% * 100;
 Minibatch[ 601- 700]: loss = 0.438574 * 100, metric = 6.64% * 100;
 Minibatch[ 701- 800]: loss = 0.431991 * 100, metric = 6.19% * 100;
 Minibatch[ 801- 900]: loss = 0.444152 * 100, metric = 6.61% * 100;
 Minibatch[ 901-1000]: loss = 0.417516 * 100, metric = 6.14% * 100;
 Minibatch[1001-1100]: loss = 0.438481 * 100, metric = 6.36% * 100;
 Minibatch[1101-1200]: loss = 0.451633 * 100, metric = 6.77% * 100;
 Minibatch[1201-1300]: loss = 0.427234 * 100, metric = 6.27% * 100;
 Minibatch[1301-1400]: loss = 0.436479 * 100, metric = 6.50% * 100;
 Minibatch[1401-1500]: loss = 0.442505 * 100, metric = 6.72% * 100;
 Minibatch[1501-1600]: loss = 0.442890 * 100, metric = 6.55% * 100;
 Minibatch[1601-1700]: loss = 0.441674 * 100, metric = 6.67% * 100;
 Minibatch[1701-1800]: loss = 0.441873 * 100, metric = 6.60% * 100;
 Minibatch[1801-1900]: loss = 0.434020 * 100, metric = 6.63% * 100;
 Minibatch[1901-2000]: loss = 0.450751 * 100, metric = 6.94% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.437521 * 2000, metric = 6.51% * 2000 862.193s (  2.3 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.92% * 2000;
 Minibatch[   1- 100]: loss = 0.434472 * 100, metric = 6.18% * 100;
 Minibatch[ 101- 200]: loss = 0.452388 * 100, metric = 6.95% * 100;
 Minibatch[ 201- 300]: loss = 0.429357 * 100, metric = 6.26% * 100;
 Minibatch[ 301- 400]: loss = 0.430698 * 100, metric = 6.21% * 100;
 Minibatch[ 401- 500]: loss = 0.434164 * 100, metric = 6.45% * 100;
 Minibatch[ 501- 600]: loss = 0.421687 * 100, metric = 6.06% * 100;
 Minibatch[ 601- 700]: loss = 0.450007 * 100, metric = 6.96% * 100;
 Minibatch[ 701- 800]: loss = 0.443972 * 100, metric = 6.69% * 100;
 Minibatch[ 801- 900]: loss = 0.436991 * 100, metric = 6.51% * 100;
 Minibatch[ 901-1000]: loss = 0.425843 * 100, metric = 6.50% * 100;
 Minibatch[1001-1100]: loss = 0.425905 * 100, metric = 6.14% * 100;
 Minibatch[1101-1200]: loss = 0.441134 * 100, metric = 6.67% * 100;
 Minibatch[1201-1300]: loss = 0.437468 * 100, metric = 6.54% * 100;
 Minibatch[1301-1400]: loss = 0.435727 * 100, metric = 6.51% * 100;
 Minibatch[1401-1500]: loss = 0.440187 * 100, metric = 6.62% * 100;
 Minibatch[1501-1600]: loss = 0.419507 * 100, metric = 6.16% * 100;
 Minibatch[1601-1700]: loss = 0.436157 * 100, metric = 6.53% * 100;
 Minibatch[1701-1800]: loss = 0.428434 * 100, metric = 6.44% * 100;
 Minibatch[1801-1900]: loss = 0.440345 * 100, metric = 6.74% * 100;
 Minibatch[1901-2000]: loss = 0.436656 * 100, metric = 6.50% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.435055 * 2000, metric = 6.48% * 2000 860.121s (  2.3 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 14.80% * 2000;
 Minibatch[   1- 100]: loss = 0.434220 * 100, metric = 6.48% * 100;
 Minibatch[ 101- 200]: loss = 0.433361 * 100, metric = 6.28% * 100;
 Minibatch[ 201- 300]: loss = 0.445586 * 100, metric = 6.78% * 100;
 Minibatch[ 301- 400]: loss = 0.454846 * 100, metric = 6.77% * 100;
 Minibatch[ 401- 500]: loss = 0.436004 * 100, metric = 6.59% * 100;
 Minibatch[ 501- 600]: loss = 0.436914 * 100, metric = 6.66% * 100;
 Minibatch[ 601- 700]: loss = 0.425381 * 100, metric = 6.33% * 100;
 Minibatch[ 701- 800]: loss = 0.428640 * 100, metric = 6.31% * 100;
 Minibatch[ 801- 900]: loss = 0.429693 * 100, metric = 6.36% * 100;
 Minibatch[ 901-1000]: loss = 0.420629 * 100, metric = 6.13% * 100;
 Minibatch[1001-1100]: loss = 0.419115 * 100, metric = 6.13% * 100;
 Minibatch[1101-1200]: loss = 0.430871 * 100, metric = 6.49% * 100;
 Minibatch[1201-1300]: loss = 0.441400 * 100, metric = 6.64% * 100;
 Minibatch[1301-1400]: loss = 0.434877 * 100, metric = 6.65% * 100;
 Minibatch[1401-1500]: loss = 0.427477 * 100, metric = 6.60% * 100;
 Minibatch[1501-1600]: loss = 0.430309 * 100, metric = 6.46% * 100;
 Minibatch[1601-1700]: loss = 0.418530 * 100, metric = 6.15% * 100;
 Minibatch[1701-1800]: loss = 0.441203 * 100, metric = 6.67% * 100;
 Minibatch[1801-1900]: loss = 0.424859 * 100, metric = 6.21% * 100;
 Minibatch[1901-2000]: loss = 0.425269 * 100, metric = 6.58% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.431959 * 2000, metric = 6.46% * 2000 864.141s (  2.3 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 14.41% * 2000;
 Minibatch[   1- 100]: loss = 0.441533 * 100, metric = 6.61% * 100;
 Minibatch[ 101- 200]: loss = 0.427092 * 100, metric = 6.42% * 100;
 Minibatch[ 201- 300]: loss = 0.423870 * 100, metric = 6.42% * 100;
 Minibatch[ 301- 400]: loss = 0.433255 * 100, metric = 6.66% * 100;
 Minibatch[ 401- 500]: loss = 0.422681 * 100, metric = 6.38% * 100;
 Minibatch[ 501- 600]: loss = 0.437193 * 100, metric = 6.52% * 100;
 Minibatch[ 601- 700]: loss = 0.437222 * 100, metric = 6.67% * 100;
 Minibatch[ 701- 800]: loss = 0.424452 * 100, metric = 6.38% * 100;
 Minibatch[ 801- 900]: loss = 0.421166 * 100, metric = 5.86% * 100;
 Minibatch[ 901-1000]: loss = 0.413183 * 100, metric = 5.95% * 100;
 Minibatch[1001-1100]: loss = 0.423231 * 100, metric = 6.29% * 100;
 Minibatch[1101-1200]: loss = 0.409753 * 100, metric = 6.08% * 100;
 Minibatch[1201-1300]: loss = 0.429858 * 100, metric = 6.24% * 100;
 Minibatch[1301-1400]: loss = 0.407256 * 100, metric = 5.57% * 100;
 Minibatch[1401-1500]: loss = 0.443560 * 100, metric = 6.43% * 100;
 Minibatch[1501-1600]: loss = 0.437230 * 100, metric = 6.52% * 100;
 Minibatch[1601-1700]: loss = 0.426385 * 100, metric = 5.93% * 100;
 Minibatch[1701-1800]: loss = 0.426546 * 100, metric = 6.13% * 100;
 Minibatch[1801-1900]: loss = 0.417496 * 100, metric = 5.77% * 100;
 Minibatch[1901-2000]: loss = 0.439151 * 100, metric = 6.73% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.427106 * 2000, metric = 6.28% * 2000 852.419s (  2.3 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 14.38% * 2000;
 Minibatch[   1- 100]: loss = 0.422320 * 100, metric = 6.13% * 100;
 Minibatch[ 101- 200]: loss = 0.430329 * 100, metric = 6.28% * 100;
 Minibatch[ 201- 300]: loss = 0.418084 * 100, metric = 6.25% * 100;
 Minibatch[ 301- 400]: loss = 0.424292 * 100, metric = 6.30% * 100;
 Minibatch[ 401- 500]: loss = 0.417692 * 100, metric = 5.98% * 100;
 Minibatch[ 501- 600]: loss = 0.433192 * 100, metric = 6.33% * 100;
 Minibatch[ 601- 700]: loss = 0.434842 * 100, metric = 6.53% * 100;
 Minibatch[ 701- 800]: loss = 0.419836 * 100, metric = 6.16% * 100;
 Minibatch[ 801- 900]: loss = 0.408095 * 100, metric = 5.83% * 100;
 Minibatch[ 901-1000]: loss = 0.415222 * 100, metric = 6.27% * 100;
 Minibatch[1001-1100]: loss = 0.429575 * 100, metric = 6.34% * 100;
 Minibatch[1101-1200]: loss = 0.421136 * 100, metric = 6.24% * 100;
 Minibatch[1201-1300]: loss = 0.431185 * 100, metric = 6.29% * 100;
 Minibatch[1301-1400]: loss = 0.418767 * 100, metric = 6.27% * 100;
 Minibatch[1401-1500]: loss = 0.427437 * 100, metric = 6.28% * 100;
 Minibatch[1501-1600]: loss = 0.423235 * 100, metric = 6.07% * 100;
 Minibatch[1601-1700]: loss = 0.433301 * 100, metric = 6.62% * 100;
 Minibatch[1701-1800]: loss = 0.419082 * 100, metric = 6.06% * 100;
 Minibatch[1801-1900]: loss = 0.412726 * 100, metric = 5.95% * 100;
 Minibatch[1901-2000]: loss = 0.419253 * 100, metric = 6.06% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.422980 * 2000, metric = 6.21% * 2000 859.727s (  2.3 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.05% * 2000;
 Minibatch[   1- 100]: loss = 0.400426 * 100, metric = 5.75% * 100;
 Minibatch[ 101- 200]: loss = 0.421058 * 100, metric = 6.42% * 100;
 Minibatch[ 201- 300]: loss = 0.419213 * 100, metric = 6.11% * 100;
 Minibatch[ 301- 400]: loss = 0.404817 * 100, metric = 5.71% * 100;
 Minibatch[ 401- 500]: loss = 0.415576 * 100, metric = 6.15% * 100;
 Minibatch[ 501- 600]: loss = 0.391902 * 100, metric = 5.58% * 100;
 Minibatch[ 601- 700]: loss = 0.430029 * 100, metric = 6.28% * 100;
 Minibatch[ 701- 800]: loss = 0.400105 * 100, metric = 5.93% * 100;
 Minibatch[ 801- 900]: loss = 0.428038 * 100, metric = 6.45% * 100;
 Minibatch[ 901-1000]: loss = 0.403077 * 100, metric = 5.89% * 100;
 Minibatch[1001-1100]: loss = 0.428526 * 100, metric = 6.42% * 100;
 Minibatch[1101-1200]: loss = 0.408891 * 100, metric = 5.89% * 100;
 Minibatch[1201-1300]: loss = 0.423439 * 100, metric = 6.30% * 100;
 Minibatch[1301-1400]: loss = 0.422717 * 100, metric = 6.29% * 100;
 Minibatch[1401-1500]: loss = 0.405186 * 100, metric = 6.03% * 100;
 Minibatch[1501-1600]: loss = 0.418577 * 100, metric = 6.21% * 100;
 Minibatch[1601-1700]: loss = 0.418381 * 100, metric = 6.23% * 100;
 Minibatch[1701-1800]: loss = 0.401342 * 100, metric = 5.74% * 100;
 Minibatch[1801-1900]: loss = 0.421758 * 100, metric = 6.44% * 100;
 Minibatch[1901-2000]: loss = 0.405273 * 100, metric = 5.83% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.413416 * 2000, metric = 6.08% * 2000 852.871s (  2.3 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.92% * 2000;
 Minibatch[   1- 100]: loss = 0.407109 * 100, metric = 5.94% * 100;
 Minibatch[ 101- 200]: loss = 0.392004 * 100, metric = 5.41% * 100;
 Minibatch[ 201- 300]: loss = 0.420118 * 100, metric = 6.37% * 100;
 Minibatch[ 301- 400]: loss = 0.405849 * 100, metric = 5.95% * 100;
 Minibatch[ 401- 500]: loss = 0.408113 * 100, metric = 5.94% * 100;
 Minibatch[ 501- 600]: loss = 0.412055 * 100, metric = 6.03% * 100;
 Minibatch[ 601- 700]: loss = 0.418287 * 100, metric = 5.84% * 100;
 Minibatch[ 701- 800]: loss = 0.391223 * 100, metric = 5.60% * 100;
 Minibatch[ 801- 900]: loss = 0.401313 * 100, metric = 5.90% * 100;
 Minibatch[ 901-1000]: loss = 0.423577 * 100, metric = 6.24% * 100;
 Minibatch[1001-1100]: loss = 0.421404 * 100, metric = 6.20% * 100;
 Minibatch[1101-1200]: loss = 0.416451 * 100, metric = 6.14% * 100;
 Minibatch[1201-1300]: loss = 0.420218 * 100, metric = 6.26% * 100;
 Minibatch[1301-1400]: loss = 0.392152 * 100, metric = 5.68% * 100;
 Minibatch[1401-1500]: loss = 0.402830 * 100, metric = 5.77% * 100;
 Minibatch[1501-1600]: loss = 0.402432 * 100, metric = 5.98% * 100;
 Minibatch[1601-1700]: loss = 0.422701 * 100, metric = 6.39% * 100;
 Minibatch[1701-1800]: loss = 0.412645 * 100, metric = 5.85% * 100;
 Minibatch[1801-1900]: loss = 0.414611 * 100, metric = 6.00% * 100;
 Minibatch[1901-2000]: loss = 0.405625 * 100, metric = 5.81% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.409536 * 2000, metric = 5.96% * 2000 852.164s (  2.3 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.60% * 2000;
 Minibatch[   1- 100]: loss = 0.405357 * 100, metric = 5.90% * 100;
 Minibatch[ 101- 200]: loss = 0.419330 * 100, metric = 6.19% * 100;
 Minibatch[ 201- 300]: loss = 0.408926 * 100, metric = 6.06% * 100;
 Minibatch[ 301- 400]: loss = 0.411820 * 100, metric = 6.04% * 100;
 Minibatch[ 401- 500]: loss = 0.407489 * 100, metric = 6.16% * 100;
 Minibatch[ 501- 600]: loss = 0.394786 * 100, metric = 5.59% * 100;
 Minibatch[ 601- 700]: loss = 0.400707 * 100, metric = 5.73% * 100;
 Minibatch[ 701- 800]: loss = 0.416696 * 100, metric = 6.21% * 100;
 Minibatch[ 801- 900]: loss = 0.414713 * 100, metric = 5.95% * 100;
 Minibatch[ 901-1000]: loss = 0.395137 * 100, metric = 5.55% * 100;
 Minibatch[1001-1100]: loss = 0.391101 * 100, metric = 5.53% * 100;
 Minibatch[1101-1200]: loss = 0.425720 * 100, metric = 6.24% * 100;
 Minibatch[1201-1300]: loss = 0.417821 * 100, metric = 6.15% * 100;
 Minibatch[1301-1400]: loss = 0.401877 * 100, metric = 5.66% * 100;
 Minibatch[1401-1500]: loss = 0.414399 * 100, metric = 5.94% * 100;
 Minibatch[1501-1600]: loss = 0.401608 * 100, metric = 5.69% * 100;
 Minibatch[1601-1700]: loss = 0.405795 * 100, metric = 5.78% * 100;
 Minibatch[1701-1800]: loss = 0.410036 * 100, metric = 5.82% * 100;
 Minibatch[1801-1900]: loss = 0.418912 * 100, metric = 6.03% * 100;
 Minibatch[1901-2000]: loss = 0.404985 * 100, metric = 5.80% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.408361 * 2000, metric = 5.90% * 2000 852.499s (  2.3 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.54% * 2000;
 Minibatch[   1- 100]: loss = 0.406366 * 100, metric = 5.81% * 100;
 Minibatch[ 101- 200]: loss = 0.403278 * 100, metric = 5.84% * 100;
 Minibatch[ 201- 300]: loss = 0.387375 * 100, metric = 5.45% * 100;
 Minibatch[ 301- 400]: loss = 0.398017 * 100, metric = 5.72% * 100;
 Minibatch[ 401- 500]: loss = 0.409398 * 100, metric = 5.84% * 100;
 Minibatch[ 501- 600]: loss = 0.399203 * 100, metric = 5.70% * 100;
 Minibatch[ 601- 700]: loss = 0.406936 * 100, metric = 5.92% * 100;
 Minibatch[ 701- 800]: loss = 0.394988 * 100, metric = 5.63% * 100;
 Minibatch[ 801- 900]: loss = 0.402831 * 100, metric = 5.71% * 100;
 Minibatch[ 901-1000]: loss = 0.403859 * 100, metric = 5.75% * 100;
 Minibatch[1001-1100]: loss = 0.414830 * 100, metric = 6.10% * 100;
 Minibatch[1101-1200]: loss = 0.384269 * 100, metric = 5.38% * 100;
 Minibatch[1201-1300]: loss = 0.392898 * 100, metric = 5.68% * 100;
 Minibatch[1301-1400]: loss = 0.413619 * 100, metric = 5.92% * 100;
 Minibatch[1401-1500]: loss = 0.410275 * 100, metric = 5.87% * 100;
 Minibatch[1501-1600]: loss = 0.411765 * 100, metric = 6.01% * 100;
 Minibatch[1601-1700]: loss = 0.392410 * 100, metric = 5.68% * 100;
 Minibatch[1701-1800]: loss = 0.401465 * 100, metric = 5.86% * 100;
 Minibatch[1801-1900]: loss = 0.407894 * 100, metric = 6.05% * 100;
 Minibatch[1901-2000]: loss = 0.399466 * 100, metric = 5.74% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.402057 * 2000, metric = 5.78% * 2000 855.056s (  2.3 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 13.00% * 2000;
 Minibatch[   1- 100]: loss = 0.397477 * 100, metric = 5.79% * 100;
 Minibatch[ 101- 200]: loss = 0.408681 * 100, metric = 5.93% * 100;
 Minibatch[ 201- 300]: loss = 0.399681 * 100, metric = 5.62% * 100;
 Minibatch[ 301- 400]: loss = 0.390499 * 100, metric = 5.55% * 100;
 Minibatch[ 401- 500]: loss = 0.396326 * 100, metric = 5.76% * 100;
 Minibatch[ 501- 600]: loss = 0.404344 * 100, metric = 5.83% * 100;
 Minibatch[ 601- 700]: loss = 0.402265 * 100, metric = 5.92% * 100;
 Minibatch[ 701- 800]: loss = 0.400203 * 100, metric = 5.62% * 100;
 Minibatch[ 801- 900]: loss = 0.387520 * 100, metric = 5.42% * 100;
 Minibatch[ 901-1000]: loss = 0.397439 * 100, metric = 5.67% * 100;
 Minibatch[1001-1100]: loss = 0.417672 * 100, metric = 6.24% * 100;
 Minibatch[1101-1200]: loss = 0.396579 * 100, metric = 5.79% * 100;
 Minibatch[1201-1300]: loss = 0.401073 * 100, metric = 5.55% * 100;
 Minibatch[1301-1400]: loss = 0.406219 * 100, metric = 5.93% * 100;
 Minibatch[1401-1500]: loss = 0.399172 * 100, metric = 5.72% * 100;
 Minibatch[1501-1600]: loss = 0.399958 * 100, metric = 5.69% * 100;
 Minibatch[1601-1700]: loss = 0.392835 * 100, metric = 5.67% * 100;
 Minibatch[1701-1800]: loss = 0.406390 * 100, metric = 5.85% * 100;
 Minibatch[1801-1900]: loss = 0.387947 * 100, metric = 5.57% * 100;
 Minibatch[1901-2000]: loss = 0.391021 * 100, metric = 5.51% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.399165 * 2000, metric = 5.73% * 2000 845.481s (  2.4 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.42% * 2000;
 Minibatch[   1- 100]: loss = 0.393084 * 100, metric = 5.65% * 100;
 Minibatch[ 101- 200]: loss = 0.383824 * 100, metric = 5.47% * 100;
 Minibatch[ 201- 300]: loss = 0.406572 * 100, metric = 5.79% * 100;
 Minibatch[ 301- 400]: loss = 0.391054 * 100, metric = 5.53% * 100;
 Minibatch[ 401- 500]: loss = 0.396601 * 100, metric = 5.66% * 100;
 Minibatch[ 501- 600]: loss = 0.385538 * 100, metric = 5.72% * 100;
 Minibatch[ 601- 700]: loss = 0.403002 * 100, metric = 5.65% * 100;
 Minibatch[ 701- 800]: loss = 0.394706 * 100, metric = 5.46% * 100;
 Minibatch[ 801- 900]: loss = 0.391919 * 100, metric = 5.65% * 100;
 Minibatch[ 901-1000]: loss = 0.390873 * 100, metric = 5.61% * 100;
 Minibatch[1001-1100]: loss = 0.409547 * 100, metric = 5.94% * 100;
 Minibatch[1101-1200]: loss = 0.406542 * 100, metric = 5.91% * 100;
 Minibatch[1201-1300]: loss = 0.396447 * 100, metric = 5.66% * 100;
 Minibatch[1301-1400]: loss = 0.396233 * 100, metric = 5.79% * 100;
 Minibatch[1401-1500]: loss = 0.387490 * 100, metric = 5.50% * 100;
 Minibatch[1501-1600]: loss = 0.403604 * 100, metric = 5.63% * 100;
 Minibatch[1601-1700]: loss = 0.396648 * 100, metric = 5.80% * 100;
 Minibatch[1701-1800]: loss = 0.386965 * 100, metric = 5.55% * 100;
 Minibatch[1801-1900]: loss = 0.391778 * 100, metric = 5.61% * 100;
 Minibatch[1901-2000]: loss = 0.396496 * 100, metric = 5.69% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.395446 * 2000, metric = 5.66% * 2000 845.759s (  2.4 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 13.48% * 2000;
 Minibatch[   1- 100]: loss = 0.395129 * 100, metric = 5.85% * 100;
 Minibatch[ 101- 200]: loss = 0.387597 * 100, metric = 5.46% * 100;
 Minibatch[ 201- 300]: loss = 0.393931 * 100, metric = 5.62% * 100;
 Minibatch[ 301- 400]: loss = 0.404026 * 100, metric = 5.95% * 100;
 Minibatch[ 401- 500]: loss = 0.395940 * 100, metric = 5.71% * 100;
 Minibatch[ 501- 600]: loss = 0.390025 * 100, metric = 5.38% * 100;
 Minibatch[ 601- 700]: loss = 0.403998 * 100, metric = 5.96% * 100;
 Minibatch[ 701- 800]: loss = 0.396941 * 100, metric = 5.59% * 100;
 Minibatch[ 801- 900]: loss = 0.386378 * 100, metric = 5.66% * 100;
 Minibatch[ 901-1000]: loss = 0.394663 * 100, metric = 5.78% * 100;
 Minibatch[1001-1100]: loss = 0.400549 * 100, metric = 5.68% * 100;
 Minibatch[1101-1200]: loss = 0.408518 * 100, metric = 5.93% * 100;
 Minibatch[1201-1300]: loss = 0.408058 * 100, metric = 5.83% * 100;
 Minibatch[1301-1400]: loss = 0.384355 * 100, metric = 5.58% * 100;
 Minibatch[1401-1500]: loss = 0.383008 * 100, metric = 5.35% * 100;
 Minibatch[1501-1600]: loss = 0.389474 * 100, metric = 5.36% * 100;
 Minibatch[1601-1700]: loss = 0.396094 * 100, metric = 5.75% * 100;
 Minibatch[1701-1800]: loss = 0.388956 * 100, metric = 5.59% * 100;
 Minibatch[1801-1900]: loss = 0.391219 * 100, metric = 5.83% * 100;
 Minibatch[1901-2000]: loss = 0.380103 * 100, metric = 5.14% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.393948 * 2000, metric = 5.65% * 2000 842.344s (  2.4 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 14.42% * 2000;
 Minibatch[   1- 100]: loss = 0.382733 * 100, metric = 5.45% * 100;
 Minibatch[ 101- 200]: loss = 0.383778 * 100, metric = 5.55% * 100;
 Minibatch[ 201- 300]: loss = 0.380097 * 100, metric = 5.26% * 100;
 Minibatch[ 301- 400]: loss = 0.377093 * 100, metric = 5.18% * 100;
 Minibatch[ 401- 500]: loss = 0.378419 * 100, metric = 5.12% * 100;
 Minibatch[ 501- 600]: loss = 0.393930 * 100, metric = 5.52% * 100;
 Minibatch[ 601- 700]: loss = 0.385669 * 100, metric = 5.65% * 100;
 Minibatch[ 701- 800]: loss = 0.380009 * 100, metric = 5.52% * 100;
 Minibatch[ 801- 900]: loss = 0.372695 * 100, metric = 5.47% * 100;
 Minibatch[ 901-1000]: loss = 0.392733 * 100, metric = 5.75% * 100;
 Minibatch[1001-1100]: loss = 0.380536 * 100, metric = 5.39% * 100;
 Minibatch[1101-1200]: loss = 0.379976 * 100, metric = 5.42% * 100;
 Minibatch[1201-1300]: loss = 0.376505 * 100, metric = 5.26% * 100;
 Minibatch[1301-1400]: loss = 0.388498 * 100, metric = 5.61% * 100;
 Minibatch[1401-1500]: loss = 0.378339 * 100, metric = 5.30% * 100;
 Minibatch[1501-1600]: loss = 0.381767 * 100, metric = 5.39% * 100;
 Minibatch[1601-1700]: loss = 0.385926 * 100, metric = 5.39% * 100;
 Minibatch[1701-1800]: loss = 0.379680 * 100, metric = 5.34% * 100;
 Minibatch[1801-1900]: loss = 0.384821 * 100, metric = 5.38% * 100;
 Minibatch[1901-2000]: loss = 0.387548 * 100, metric = 5.58% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.382538 * 2000, metric = 5.43% * 2000 840.542s (  2.4 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 12.70% * 2000;
 Minibatch[   1- 100]: loss = 0.399959 * 100, metric = 5.88% * 100;
 Minibatch[ 101- 200]: loss = 0.374013 * 100, metric = 5.12% * 100;
 Minibatch[ 201- 300]: loss = 0.387789 * 100, metric = 5.59% * 100;
 Minibatch[ 301- 400]: loss = 0.388625 * 100, metric = 5.55% * 100;
 Minibatch[ 401- 500]: loss = 0.379491 * 100, metric = 5.23% * 100;
 Minibatch[ 501- 600]: loss = 0.386186 * 100, metric = 5.56% * 100;
 Minibatch[ 601- 700]: loss = 0.401217 * 100, metric = 5.77% * 100;
 Minibatch[ 701- 800]: loss = 0.376834 * 100, metric = 5.54% * 100;
 Minibatch[ 801- 900]: loss = 0.381750 * 100, metric = 5.41% * 100;
 Minibatch[ 901-1000]: loss = 0.389938 * 100, metric = 5.53% * 100;
 Minibatch[1001-1100]: loss = 0.385586 * 100, metric = 5.56% * 100;
 Minibatch[1101-1200]: loss = 0.373206 * 100, metric = 5.22% * 100;
 Minibatch[1201-1300]: loss = 0.396357 * 100, metric = 5.88% * 100;
 Minibatch[1301-1400]: loss = 0.384515 * 100, metric = 5.64% * 100;
 Minibatch[1401-1500]: loss = 0.369545 * 100, metric = 5.02% * 100;
 Minibatch[1501-1600]: loss = 0.398038 * 100, metric = 5.83% * 100;
 Minibatch[1601-1700]: loss = 0.374495 * 100, metric = 5.34% * 100;
 Minibatch[1701-1800]: loss = 0.380104 * 100, metric = 5.56% * 100;
 Minibatch[1801-1900]: loss = 0.388855 * 100, metric = 5.71% * 100;
 Minibatch[1901-2000]: loss = 0.375981 * 100, metric = 5.34% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.384624 * 2000, metric = 5.51% * 2000 845.290s (  2.4 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 13.70% * 2000;
 Minibatch[   1- 100]: loss = 0.382153 * 100, metric = 5.63% * 100;
 Minibatch[ 101- 200]: loss = 0.381470 * 100, metric = 5.25% * 100;
 Minibatch[ 201- 300]: loss = 0.386079 * 100, metric = 5.40% * 100;
 Minibatch[ 301- 400]: loss = 0.388026 * 100, metric = 5.43% * 100;
 Minibatch[ 401- 500]: loss = 0.381551 * 100, metric = 5.26% * 100;
 Minibatch[ 501- 600]: loss = 0.375798 * 100, metric = 5.32% * 100;
 Minibatch[ 601- 700]: loss = 0.389455 * 100, metric = 5.76% * 100;
 Minibatch[ 701- 800]: loss = 0.361226 * 100, metric = 4.85% * 100;
 Minibatch[ 801- 900]: loss = 0.374201 * 100, metric = 5.16% * 100;
 Minibatch[ 901-1000]: loss = 0.373403 * 100, metric = 5.29% * 100;
 Minibatch[1001-1100]: loss = 0.373760 * 100, metric = 5.12% * 100;
 Minibatch[1101-1200]: loss = 0.365864 * 100, metric = 5.06% * 100;
 Minibatch[1201-1300]: loss = 0.375348 * 100, metric = 5.31% * 100;
 Minibatch[1301-1400]: loss = 0.368089 * 100, metric = 5.07% * 100;
 Minibatch[1401-1500]: loss = 0.369216 * 100, metric = 5.12% * 100;
 Minibatch[1501-1600]: loss = 0.363456 * 100, metric = 5.16% * 100;
 Minibatch[1601-1700]: loss = 0.376063 * 100, metric = 5.22% * 100;
 Minibatch[1701-1800]: loss = 0.388682 * 100, metric = 5.69% * 100;
 Minibatch[1801-1900]: loss = 0.374579 * 100, metric = 5.15% * 100;
 Minibatch[1901-2000]: loss = 0.361815 * 100, metric = 4.95% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.375512 * 2000, metric = 5.26% * 2000 846.312s (  2.4 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 13.61% * 2000;
 Minibatch[   1- 100]: loss = 0.383822 * 100, metric = 5.52% * 100;
 Minibatch[ 101- 200]: loss = 0.375444 * 100, metric = 5.17% * 100;
 Minibatch[ 201- 300]: loss = 0.367676 * 100, metric = 5.09% * 100;
 Minibatch[ 301- 400]: loss = 0.380627 * 100, metric = 5.39% * 100;
 Minibatch[ 401- 500]: loss = 0.376285 * 100, metric = 5.25% * 100;
 Minibatch[ 501- 600]: loss = 0.366765 * 100, metric = 4.90% * 100;
 Minibatch[ 601- 700]: loss = 0.367280 * 100, metric = 5.02% * 100;
 Minibatch[ 701- 800]: loss = 0.362933 * 100, metric = 5.20% * 100;
 Minibatch[ 801- 900]: loss = 0.390735 * 100, metric = 5.64% * 100;
 Minibatch[ 901-1000]: loss = 0.370402 * 100, metric = 5.22% * 100;
 Minibatch[1001-1100]: loss = 0.376356 * 100, metric = 5.32% * 100;
 Minibatch[1101-1200]: loss = 0.389796 * 100, metric = 5.48% * 100;
 Minibatch[1201-1300]: loss = 0.378380 * 100, metric = 5.31% * 100;
 Minibatch[1301-1400]: loss = 0.369500 * 100, metric = 5.08% * 100;
 Minibatch[1401-1500]: loss = 0.387987 * 100, metric = 5.66% * 100;
 Minibatch[1501-1600]: loss = 0.374966 * 100, metric = 5.30% * 100;
 Minibatch[1601-1700]: loss = 0.362897 * 100, metric = 5.10% * 100;
 Minibatch[1701-1800]: loss = 0.383040 * 100, metric = 5.48% * 100;
 Minibatch[1801-1900]: loss = 0.376561 * 100, metric = 5.47% * 100;
 Minibatch[1901-2000]: loss = 0.374905 * 100, metric = 5.07% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.375818 * 2000, metric = 5.28% * 2000 841.998s (  2.4 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 13.53% * 2000;
 Minibatch[   1- 100]: loss = 0.363391 * 100, metric = 5.28% * 100;
 Minibatch[ 101- 200]: loss = 0.384749 * 100, metric = 5.46% * 100;
 Minibatch[ 201- 300]: loss = 0.365941 * 100, metric = 5.14% * 100;
 Minibatch[ 301- 400]: loss = 0.383713 * 100, metric = 5.47% * 100;
 Minibatch[ 401- 500]: loss = 0.372859 * 100, metric = 5.11% * 100;
 Minibatch[ 501- 600]: loss = 0.371028 * 100, metric = 5.09% * 100;
 Minibatch[ 601- 700]: loss = 0.358010 * 100, metric = 4.85% * 100;
 Minibatch[ 701- 800]: loss = 0.364301 * 100, metric = 4.98% * 100;
 Minibatch[ 801- 900]: loss = 0.369697 * 100, metric = 5.25% * 100;
 Minibatch[ 901-1000]: loss = 0.373320 * 100, metric = 5.21% * 100;
 Minibatch[1001-1100]: loss = 0.368032 * 100, metric = 5.07% * 100;
 Minibatch[1101-1200]: loss = 0.379816 * 100, metric = 5.39% * 100;
 Minibatch[1201-1300]: loss = 0.368633 * 100, metric = 5.02% * 100;
 Minibatch[1301-1400]: loss = 0.376984 * 100, metric = 5.31% * 100;
 Minibatch[1401-1500]: loss = 0.362531 * 100, metric = 4.88% * 100;
 Minibatch[1501-1600]: loss = 0.375266 * 100, metric = 5.38% * 100;
 Minibatch[1601-1700]: loss = 0.359257 * 100, metric = 4.85% * 100;
 Minibatch[1701-1800]: loss = 0.383605 * 100, metric = 5.42% * 100;
 Minibatch[1801-1900]: loss = 0.357062 * 100, metric = 4.83% * 100;
 Minibatch[1901-2000]: loss = 0.369749 * 100, metric = 5.10% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.370397 * 2000, metric = 5.15% * 2000 841.035s (  2.4 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 12.95% * 2000;
 Minibatch[   1- 100]: loss = 0.370851 * 100, metric = 5.07% * 100;
 Minibatch[ 101- 200]: loss = 0.362028 * 100, metric = 5.00% * 100;
 Minibatch[ 201- 300]: loss = 0.368049 * 100, metric = 4.96% * 100;
 Minibatch[ 301- 400]: loss = 0.359967 * 100, metric = 4.93% * 100;
 Minibatch[ 401- 500]: loss = 0.352825 * 100, metric = 4.75% * 100;
 Minibatch[ 501- 600]: loss = 0.361652 * 100, metric = 5.18% * 100;
 Minibatch[ 601- 700]: loss = 0.370744 * 100, metric = 5.04% * 100;
 Minibatch[ 701- 800]: loss = 0.371413 * 100, metric = 5.13% * 100;
 Minibatch[ 801- 900]: loss = 0.367105 * 100, metric = 4.88% * 100;
 Minibatch[ 901-1000]: loss = 0.366494 * 100, metric = 4.98% * 100;
 Minibatch[1001-1100]: loss = 0.378768 * 100, metric = 5.35% * 100;
 Minibatch[1101-1200]: loss = 0.371520 * 100, metric = 4.97% * 100;
 Minibatch[1201-1300]: loss = 0.354218 * 100, metric = 4.87% * 100;
 Minibatch[1301-1400]: loss = 0.362422 * 100, metric = 5.09% * 100;
 Minibatch[1401-1500]: loss = 0.378227 * 100, metric = 5.45% * 100;
 Minibatch[1501-1600]: loss = 0.376749 * 100, metric = 5.13% * 100;
 Minibatch[1601-1700]: loss = 0.365729 * 100, metric = 4.98% * 100;
 Minibatch[1701-1800]: loss = 0.379306 * 100, metric = 5.23% * 100;
 Minibatch[1801-1900]: loss = 0.369916 * 100, metric = 5.20% * 100;
 Minibatch[1901-2000]: loss = 0.377132 * 100, metric = 5.34% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.368256 * 2000, metric = 5.08% * 2000 835.796s (  2.4 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 13.28% * 2000;
 Minibatch[   1- 100]: loss = 0.376932 * 100, metric = 5.28% * 100;
 Minibatch[ 101- 200]: loss = 0.371744 * 100, metric = 5.25% * 100;
 Minibatch[ 201- 300]: loss = 0.363741 * 100, metric = 5.21% * 100;
 Minibatch[ 301- 400]: loss = 0.359649 * 100, metric = 5.01% * 100;
 Minibatch[ 401- 500]: loss = 0.368967 * 100, metric = 5.32% * 100;
 Minibatch[ 501- 600]: loss = 0.383661 * 100, metric = 5.53% * 100;
 Minibatch[ 601- 700]: loss = 0.381691 * 100, metric = 5.26% * 100;
 Minibatch[ 701- 800]: loss = 0.363019 * 100, metric = 4.93% * 100;
 Minibatch[ 801- 900]: loss = 0.364472 * 100, metric = 4.90% * 100;
 Minibatch[ 901-1000]: loss = 0.371685 * 100, metric = 5.29% * 100;
 Minibatch[1001-1100]: loss = 0.368358 * 100, metric = 5.13% * 100;
 Minibatch[1101-1200]: loss = 0.372574 * 100, metric = 5.27% * 100;
 Minibatch[1201-1300]: loss = 0.358589 * 100, metric = 4.97% * 100;
 Minibatch[1301-1400]: loss = 0.358942 * 100, metric = 5.01% * 100;
 Minibatch[1401-1500]: loss = 0.362658 * 100, metric = 5.10% * 100;
 Minibatch[1501-1600]: loss = 0.367781 * 100, metric = 5.21% * 100;
 Minibatch[1601-1700]: loss = 0.356702 * 100, metric = 4.98% * 100;
 Minibatch[1701-1800]: loss = 0.359731 * 100, metric = 4.80% * 100;
 Minibatch[1801-1900]: loss = 0.369898 * 100, metric = 5.16% * 100;
 Minibatch[1901-2000]: loss = 0.359984 * 100, metric = 4.99% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.367039 * 2000, metric = 5.13% * 2000 835.434s (  2.4 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 13.50% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
