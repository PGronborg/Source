Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.251676 * 100, metric = 24.88% * 100;
 Minibatch[ 101- 200]: loss = 1.059351 * 100, metric = 23.11% * 100;
 Minibatch[ 201- 300]: loss = 0.968871 * 100, metric = 21.92% * 100;
 Minibatch[ 301- 400]: loss = 0.986307 * 100, metric = 21.60% * 100;
 Minibatch[ 401- 500]: loss = 0.914881 * 100, metric = 20.40% * 100;
 Minibatch[ 501- 600]: loss = 0.899089 * 100, metric = 19.90% * 100;
 Minibatch[ 601- 700]: loss = 0.861748 * 100, metric = 18.43% * 100;
 Minibatch[ 701- 800]: loss = 0.817974 * 100, metric = 17.56% * 100;
 Minibatch[ 801- 900]: loss = 0.838322 * 100, metric = 17.79% * 100;
 Minibatch[ 901-1000]: loss = 0.835626 * 100, metric = 17.72% * 100;
 Minibatch[1001-1100]: loss = 0.829598 * 100, metric = 17.66% * 100;
 Minibatch[1101-1200]: loss = 0.806155 * 100, metric = 16.53% * 100;
 Minibatch[1201-1300]: loss = 0.804924 * 100, metric = 17.25% * 100;
 Minibatch[1301-1400]: loss = 0.775997 * 100, metric = 16.50% * 100;
 Minibatch[1401-1500]: loss = 0.788796 * 100, metric = 16.46% * 100;
 Minibatch[1501-1600]: loss = 0.759287 * 100, metric = 16.06% * 100;
 Minibatch[1601-1700]: loss = 0.750784 * 100, metric = 15.79% * 100;
 Minibatch[1701-1800]: loss = 0.766003 * 100, metric = 15.71% * 100;
 Minibatch[1801-1900]: loss = 0.762704 * 100, metric = 15.96% * 100;
 Minibatch[1901-2000]: loss = 0.733506 * 100, metric = 14.93% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.860580 * 2000, metric = 18.31% * 2000 1025.414s (  2.0 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 22.50% * 2000;
0.7434893542230129
 Minibatch[   1- 100]: loss = 0.740375 * 100, metric = 15.39% * 100;
 Minibatch[ 101- 200]: loss = 0.749309 * 100, metric = 16.10% * 100;
 Minibatch[ 201- 300]: loss = 0.727412 * 100, metric = 14.88% * 100;
 Minibatch[ 301- 400]: loss = 0.743473 * 100, metric = 15.44% * 100;
 Minibatch[ 401- 500]: loss = 0.734488 * 100, metric = 15.51% * 100;
 Minibatch[ 501- 600]: loss = 0.754180 * 100, metric = 15.41% * 100;
 Minibatch[ 601- 700]: loss = 0.701895 * 100, metric = 14.71% * 100;
 Minibatch[ 701- 800]: loss = 0.735709 * 100, metric = 15.64% * 100;
 Minibatch[ 801- 900]: loss = 0.706859 * 100, metric = 14.90% * 100;
 Minibatch[ 901-1000]: loss = 0.697402 * 100, metric = 14.29% * 100;
 Minibatch[1001-1100]: loss = 0.704319 * 100, metric = 14.86% * 100;
 Minibatch[1101-1200]: loss = 0.710137 * 100, metric = 14.35% * 100;
 Minibatch[1201-1300]: loss = 0.695054 * 100, metric = 14.70% * 100;
 Minibatch[1301-1400]: loss = 0.704352 * 100, metric = 14.51% * 100;
 Minibatch[1401-1500]: loss = 0.688335 * 100, metric = 13.99% * 100;
 Minibatch[1501-1600]: loss = 0.671172 * 100, metric = 13.83% * 100;
 Minibatch[1601-1700]: loss = 0.687103 * 100, metric = 14.09% * 100;
 Minibatch[1701-1800]: loss = 0.689984 * 100, metric = 14.64% * 100;
 Minibatch[1801-1900]: loss = 0.694869 * 100, metric = 14.44% * 100;
 Minibatch[1901-2000]: loss = 0.661322 * 100, metric = 13.84% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.709888 * 2000, metric = 14.78% * 2000 974.175s (  2.1 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 21.97% * 2000;
0.7155982140153646
 Minibatch[   1- 100]: loss = 0.684593 * 100, metric = 14.39% * 100;
 Minibatch[ 101- 200]: loss = 0.687174 * 100, metric = 14.25% * 100;
 Minibatch[ 201- 300]: loss = 0.675814 * 100, metric = 14.00% * 100;
 Minibatch[ 301- 400]: loss = 0.696384 * 100, metric = 14.57% * 100;
 Minibatch[ 401- 500]: loss = 0.694748 * 100, metric = 14.75% * 100;
 Minibatch[ 501- 600]: loss = 0.683034 * 100, metric = 14.10% * 100;
 Minibatch[ 601- 700]: loss = 0.696197 * 100, metric = 14.30% * 100;
 Minibatch[ 701- 800]: loss = 0.675717 * 100, metric = 13.51% * 100;
 Minibatch[ 801- 900]: loss = 0.684198 * 100, metric = 14.34% * 100;
 Minibatch[ 901-1000]: loss = 0.658492 * 100, metric = 13.96% * 100;
 Minibatch[1001-1100]: loss = 0.676899 * 100, metric = 14.18% * 100;
 Minibatch[1101-1200]: loss = 0.660283 * 100, metric = 13.55% * 100;
 Minibatch[1201-1300]: loss = 0.658866 * 100, metric = 13.18% * 100;
 Minibatch[1301-1400]: loss = 0.671885 * 100, metric = 13.94% * 100;
 Minibatch[1401-1500]: loss = 0.674291 * 100, metric = 13.97% * 100;
 Minibatch[1501-1600]: loss = 0.658796 * 100, metric = 13.37% * 100;
 Minibatch[1601-1700]: loss = 0.653409 * 100, metric = 13.06% * 100;
 Minibatch[1701-1800]: loss = 0.671431 * 100, metric = 13.82% * 100;
 Minibatch[1801-1900]: loss = 0.652565 * 100, metric = 13.17% * 100;
 Minibatch[1901-2000]: loss = 0.659851 * 100, metric = 13.72% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.673731 * 2000, metric = 13.91% * 2000 977.763s (  2.0 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 19.90% * 2000;
0.6975304144695401
 Minibatch[   1- 100]: loss = 0.680284 * 100, metric = 13.80% * 100;
 Minibatch[ 101- 200]: loss = 0.646948 * 100, metric = 13.15% * 100;
 Minibatch[ 201- 300]: loss = 0.658776 * 100, metric = 13.73% * 100;
 Minibatch[ 301- 400]: loss = 0.622571 * 100, metric = 12.67% * 100;
 Minibatch[ 401- 500]: loss = 0.654951 * 100, metric = 13.46% * 100;
 Minibatch[ 501- 600]: loss = 0.640406 * 100, metric = 13.05% * 100;
 Minibatch[ 601- 700]: loss = 0.639088 * 100, metric = 12.94% * 100;
 Minibatch[ 701- 800]: loss = 0.660349 * 100, metric = 13.41% * 100;
 Minibatch[ 801- 900]: loss = 0.648833 * 100, metric = 13.39% * 100;
 Minibatch[ 901-1000]: loss = 0.648671 * 100, metric = 13.35% * 100;
 Minibatch[1001-1100]: loss = 0.662508 * 100, metric = 13.77% * 100;
 Minibatch[1101-1200]: loss = 0.632396 * 100, metric = 12.95% * 100;
 Minibatch[1201-1300]: loss = 0.644575 * 100, metric = 13.27% * 100;
 Minibatch[1301-1400]: loss = 0.656730 * 100, metric = 13.43% * 100;
 Minibatch[1401-1500]: loss = 0.653528 * 100, metric = 13.17% * 100;
 Minibatch[1501-1600]: loss = 0.625323 * 100, metric = 12.68% * 100;
 Minibatch[1601-1700]: loss = 0.650343 * 100, metric = 13.28% * 100;
 Minibatch[1701-1800]: loss = 0.649686 * 100, metric = 13.58% * 100;
 Minibatch[1801-1900]: loss = 0.630830 * 100, metric = 12.87% * 100;
 Minibatch[1901-2000]: loss = 0.630997 * 100, metric = 12.67% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.646890 * 2000, metric = 13.23% * 2000 985.180s (  2.0 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 21.09% * 2000;
 Minibatch[   1- 100]: loss = 0.653484 * 100, metric = 13.26% * 100;
 Minibatch[ 101- 200]: loss = 0.636110 * 100, metric = 13.03% * 100;
 Minibatch[ 201- 300]: loss = 0.629073 * 100, metric = 12.66% * 100;
 Minibatch[ 301- 400]: loss = 0.656706 * 100, metric = 13.86% * 100;
 Minibatch[ 401- 500]: loss = 0.616358 * 100, metric = 12.11% * 100;
 Minibatch[ 501- 600]: loss = 0.616488 * 100, metric = 12.21% * 100;
 Minibatch[ 601- 700]: loss = 0.623608 * 100, metric = 12.15% * 100;
 Minibatch[ 701- 800]: loss = 0.629492 * 100, metric = 12.39% * 100;
 Minibatch[ 801- 900]: loss = 0.613442 * 100, metric = 12.11% * 100;
 Minibatch[ 901-1000]: loss = 0.610631 * 100, metric = 12.40% * 100;
 Minibatch[1001-1100]: loss = 0.623461 * 100, metric = 12.53% * 100;
 Minibatch[1101-1200]: loss = 0.605968 * 100, metric = 12.37% * 100;
 Minibatch[1201-1300]: loss = 0.617695 * 100, metric = 12.19% * 100;
 Minibatch[1301-1400]: loss = 0.637227 * 100, metric = 13.02% * 100;
 Minibatch[1401-1500]: loss = 0.614576 * 100, metric = 12.64% * 100;
 Minibatch[1501-1600]: loss = 0.619589 * 100, metric = 12.45% * 100;
 Minibatch[1601-1700]: loss = 0.630654 * 100, metric = 13.01% * 100;
 Minibatch[1701-1800]: loss = 0.626180 * 100, metric = 12.61% * 100;
 Minibatch[1801-1900]: loss = 0.633940 * 100, metric = 13.10% * 100;
 Minibatch[1901-2000]: loss = 0.610016 * 100, metric = 12.40% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.625235 * 2000, metric = 12.62% * 2000 985.591s (  2.0 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.13% * 2000;
0.683561214827001
 Minibatch[   1- 100]: loss = 0.612234 * 100, metric = 12.52% * 100;
 Minibatch[ 101- 200]: loss = 0.603565 * 100, metric = 12.29% * 100;
 Minibatch[ 201- 300]: loss = 0.615384 * 100, metric = 12.35% * 100;
 Minibatch[ 301- 400]: loss = 0.624335 * 100, metric = 12.33% * 100;
 Minibatch[ 401- 500]: loss = 0.592547 * 100, metric = 11.81% * 100;
 Minibatch[ 501- 600]: loss = 0.611987 * 100, metric = 12.43% * 100;
 Minibatch[ 601- 700]: loss = 0.604739 * 100, metric = 12.21% * 100;
 Minibatch[ 701- 800]: loss = 0.607861 * 100, metric = 12.25% * 100;
 Minibatch[ 801- 900]: loss = 0.613460 * 100, metric = 12.46% * 100;
 Minibatch[ 901-1000]: loss = 0.594294 * 100, metric = 11.88% * 100;
 Minibatch[1001-1100]: loss = 0.608810 * 100, metric = 11.74% * 100;
 Minibatch[1101-1200]: loss = 0.609901 * 100, metric = 11.97% * 100;
 Minibatch[1201-1300]: loss = 0.628840 * 100, metric = 12.86% * 100;
 Minibatch[1301-1400]: loss = 0.596155 * 100, metric = 12.00% * 100;
 Minibatch[1401-1500]: loss = 0.610024 * 100, metric = 12.28% * 100;
 Minibatch[1501-1600]: loss = 0.593193 * 100, metric = 11.68% * 100;
 Minibatch[1601-1700]: loss = 0.597576 * 100, metric = 11.71% * 100;
 Minibatch[1701-1800]: loss = 0.581724 * 100, metric = 11.65% * 100;
 Minibatch[1801-1900]: loss = 0.605149 * 100, metric = 12.18% * 100;
 Minibatch[1901-2000]: loss = 0.590267 * 100, metric = 11.74% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.605102 * 2000, metric = 12.12% * 2000 988.105s (  2.0 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 21.03% * 2000;
 Minibatch[   1- 100]: loss = 0.587855 * 100, metric = 11.65% * 100;
 Minibatch[ 101- 200]: loss = 0.598903 * 100, metric = 11.80% * 100;
 Minibatch[ 201- 300]: loss = 0.601712 * 100, metric = 11.85% * 100;
 Minibatch[ 301- 400]: loss = 0.586632 * 100, metric = 11.53% * 100;
 Minibatch[ 401- 500]: loss = 0.599164 * 100, metric = 11.93% * 100;
 Minibatch[ 501- 600]: loss = 0.581346 * 100, metric = 11.61% * 100;
 Minibatch[ 601- 700]: loss = 0.594625 * 100, metric = 11.51% * 100;
 Minibatch[ 701- 800]: loss = 0.594537 * 100, metric = 11.77% * 100;
 Minibatch[ 801- 900]: loss = 0.602318 * 100, metric = 12.16% * 100;
 Minibatch[ 901-1000]: loss = 0.590389 * 100, metric = 11.77% * 100;
 Minibatch[1001-1100]: loss = 0.601249 * 100, metric = 12.09% * 100;
 Minibatch[1101-1200]: loss = 0.576318 * 100, metric = 11.42% * 100;
 Minibatch[1201-1300]: loss = 0.595587 * 100, metric = 11.86% * 100;
 Minibatch[1301-1400]: loss = 0.569457 * 100, metric = 11.23% * 100;
 Minibatch[1401-1500]: loss = 0.574985 * 100, metric = 11.32% * 100;
 Minibatch[1501-1600]: loss = 0.587745 * 100, metric = 11.69% * 100;
 Minibatch[1601-1700]: loss = 0.593077 * 100, metric = 11.86% * 100;
 Minibatch[1701-1800]: loss = 0.581888 * 100, metric = 11.59% * 100;
 Minibatch[1801-1900]: loss = 0.590051 * 100, metric = 11.84% * 100;
 Minibatch[1901-2000]: loss = 0.589231 * 100, metric = 11.96% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.589854 * 2000, metric = 11.72% * 2000 989.526s (  2.0 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 19.67% * 2000;
0.6665438302531839
 Minibatch[   1- 100]: loss = 0.590884 * 100, metric = 11.91% * 100;
 Minibatch[ 101- 200]: loss = 0.581498 * 100, metric = 11.92% * 100;
 Minibatch[ 201- 300]: loss = 0.567944 * 100, metric = 11.46% * 100;
 Minibatch[ 301- 400]: loss = 0.573957 * 100, metric = 11.80% * 100;
 Minibatch[ 401- 500]: loss = 0.575764 * 100, metric = 11.58% * 100;
 Minibatch[ 501- 600]: loss = 0.591896 * 100, metric = 11.96% * 100;
 Minibatch[ 601- 700]: loss = 0.561232 * 100, metric = 11.16% * 100;
 Minibatch[ 701- 800]: loss = 0.581651 * 100, metric = 11.52% * 100;
 Minibatch[ 801- 900]: loss = 0.558699 * 100, metric = 10.74% * 100;
 Minibatch[ 901-1000]: loss = 0.549716 * 100, metric = 10.73% * 100;
 Minibatch[1001-1100]: loss = 0.551483 * 100, metric = 10.83% * 100;
 Minibatch[1101-1200]: loss = 0.553420 * 100, metric = 10.70% * 100;
 Minibatch[1201-1300]: loss = 0.565864 * 100, metric = 11.14% * 100;
 Minibatch[1301-1400]: loss = 0.581905 * 100, metric = 11.75% * 100;
 Minibatch[1401-1500]: loss = 0.565816 * 100, metric = 11.19% * 100;
 Minibatch[1501-1600]: loss = 0.569109 * 100, metric = 11.17% * 100;
 Minibatch[1601-1700]: loss = 0.553899 * 100, metric = 10.83% * 100;
 Minibatch[1701-1800]: loss = 0.564764 * 100, metric = 10.97% * 100;
 Minibatch[1801-1900]: loss = 0.555994 * 100, metric = 10.93% * 100;
 Minibatch[1901-2000]: loss = 0.560364 * 100, metric = 10.97% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.567793 * 2000, metric = 11.26% * 2000 984.907s (  2.0 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 18.23% * 2000;
0.6238327763974667
 Minibatch[   1- 100]: loss = 0.533035 * 100, metric = 10.31% * 100;
 Minibatch[ 101- 200]: loss = 0.567826 * 100, metric = 11.18% * 100;
 Minibatch[ 201- 300]: loss = 0.559169 * 100, metric = 11.00% * 100;
 Minibatch[ 301- 400]: loss = 0.572314 * 100, metric = 11.39% * 100;
 Minibatch[ 401- 500]: loss = 0.554673 * 100, metric = 10.76% * 100;
 Minibatch[ 501- 600]: loss = 0.542317 * 100, metric = 10.61% * 100;
 Minibatch[ 601- 700]: loss = 0.547924 * 100, metric = 10.57% * 100;
 Minibatch[ 701- 800]: loss = 0.532391 * 100, metric = 10.35% * 100;
 Minibatch[ 801- 900]: loss = 0.539676 * 100, metric = 10.71% * 100;
 Minibatch[ 901-1000]: loss = 0.555886 * 100, metric = 11.05% * 100;
 Minibatch[1001-1100]: loss = 0.527426 * 100, metric = 10.18% * 100;
 Minibatch[1101-1200]: loss = 0.553748 * 100, metric = 10.86% * 100;
 Minibatch[1201-1300]: loss = 0.541314 * 100, metric = 10.59% * 100;
 Minibatch[1301-1400]: loss = 0.537677 * 100, metric = 10.14% * 100;
 Minibatch[1401-1500]: loss = 0.559642 * 100, metric = 11.03% * 100;
 Minibatch[1501-1600]: loss = 0.550543 * 100, metric = 10.79% * 100;
 Minibatch[1601-1700]: loss = 0.546772 * 100, metric = 10.88% * 100;
 Minibatch[1701-1800]: loss = 0.529923 * 100, metric = 10.17% * 100;
 Minibatch[1801-1900]: loss = 0.541252 * 100, metric = 10.53% * 100;
 Minibatch[1901-2000]: loss = 0.551108 * 100, metric = 10.78% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.547231 * 2000, metric = 10.69% * 2000 980.643s (  2.0 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 17.54% * 2000;
0.6133016797304154
 Minibatch[   1- 100]: loss = 0.568184 * 100, metric = 11.52% * 100;
 Minibatch[ 101- 200]: loss = 0.531672 * 100, metric = 10.49% * 100;
 Minibatch[ 201- 300]: loss = 0.542093 * 100, metric = 10.59% * 100;
 Minibatch[ 301- 400]: loss = 0.534694 * 100, metric = 10.44% * 100;
 Minibatch[ 401- 500]: loss = 0.543639 * 100, metric = 10.59% * 100;
 Minibatch[ 501- 600]: loss = 0.519429 * 100, metric = 10.15% * 100;
 Minibatch[ 601- 700]: loss = 0.513005 * 100, metric = 9.72% * 100;
 Minibatch[ 701- 800]: loss = 0.508501 * 100, metric = 9.38% * 100;
 Minibatch[ 801- 900]: loss = 0.532849 * 100, metric = 10.26% * 100;
 Minibatch[ 901-1000]: loss = 0.531015 * 100, metric = 10.14% * 100;
 Minibatch[1001-1100]: loss = 0.533642 * 100, metric = 10.47% * 100;
 Minibatch[1101-1200]: loss = 0.536256 * 100, metric = 10.24% * 100;
 Minibatch[1201-1300]: loss = 0.527609 * 100, metric = 10.19% * 100;
 Minibatch[1301-1400]: loss = 0.527878 * 100, metric = 10.54% * 100;
 Minibatch[1401-1500]: loss = 0.516301 * 100, metric = 9.53% * 100;
 Minibatch[1501-1600]: loss = 0.522990 * 100, metric = 10.24% * 100;
 Minibatch[1601-1700]: loss = 0.524485 * 100, metric = 10.09% * 100;
 Minibatch[1701-1800]: loss = 0.538236 * 100, metric = 10.41% * 100;
 Minibatch[1801-1900]: loss = 0.535283 * 100, metric = 10.51% * 100;
 Minibatch[1901-2000]: loss = 0.512042 * 100, metric = 9.99% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.529990 * 2000, metric = 10.28% * 2000 982.013s (  2.0 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 16.96% * 2000;
0.605183321468532
 Minibatch[   1- 100]: loss = 0.512887 * 100, metric = 9.83% * 100;
 Minibatch[ 101- 200]: loss = 0.520492 * 100, metric = 10.14% * 100;
 Minibatch[ 201- 300]: loss = 0.527831 * 100, metric = 10.31% * 100;
 Minibatch[ 301- 400]: loss = 0.521871 * 100, metric = 10.23% * 100;
 Minibatch[ 401- 500]: loss = 0.518602 * 100, metric = 9.70% * 100;
 Minibatch[ 501- 600]: loss = 0.531767 * 100, metric = 10.40% * 100;
 Minibatch[ 601- 700]: loss = 0.510657 * 100, metric = 9.91% * 100;
 Minibatch[ 701- 800]: loss = 0.527193 * 100, metric = 10.36% * 100;
 Minibatch[ 801- 900]: loss = 0.530777 * 100, metric = 10.24% * 100;
 Minibatch[ 901-1000]: loss = 0.527842 * 100, metric = 10.42% * 100;
 Minibatch[1001-1100]: loss = 0.520456 * 100, metric = 10.04% * 100;
 Minibatch[1101-1200]: loss = 0.525955 * 100, metric = 10.48% * 100;
 Minibatch[1201-1300]: loss = 0.512598 * 100, metric = 10.02% * 100;
 Minibatch[1301-1400]: loss = 0.501099 * 100, metric = 9.88% * 100;
 Minibatch[1401-1500]: loss = 0.521839 * 100, metric = 10.16% * 100;
 Minibatch[1501-1600]: loss = 0.508092 * 100, metric = 9.79% * 100;
 Minibatch[1601-1700]: loss = 0.508424 * 100, metric = 9.79% * 100;
 Minibatch[1701-1800]: loss = 0.523718 * 100, metric = 10.28% * 100;
 Minibatch[1801-1900]: loss = 0.517255 * 100, metric = 10.12% * 100;
 Minibatch[1901-2000]: loss = 0.505809 * 100, metric = 9.85% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.518758 * 2000, metric = 10.10% * 2000 980.602s (  2.0 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 17.55% * 2000;
 Minibatch[   1- 100]: loss = 0.493269 * 100, metric = 9.55% * 100;
 Minibatch[ 101- 200]: loss = 0.493249 * 100, metric = 9.21% * 100;
 Minibatch[ 201- 300]: loss = 0.504675 * 100, metric = 9.79% * 100;
 Minibatch[ 301- 400]: loss = 0.532699 * 100, metric = 10.52% * 100;
 Minibatch[ 401- 500]: loss = 0.499058 * 100, metric = 9.59% * 100;
 Minibatch[ 501- 600]: loss = 0.483078 * 100, metric = 9.00% * 100;
 Minibatch[ 601- 700]: loss = 0.491911 * 100, metric = 9.27% * 100;
 Minibatch[ 701- 800]: loss = 0.502037 * 100, metric = 9.73% * 100;
 Minibatch[ 801- 900]: loss = 0.502154 * 100, metric = 9.59% * 100;
 Minibatch[ 901-1000]: loss = 0.510189 * 100, metric = 9.94% * 100;
 Minibatch[1001-1100]: loss = 0.508897 * 100, metric = 10.07% * 100;
 Minibatch[1101-1200]: loss = 0.512592 * 100, metric = 9.98% * 100;
 Minibatch[1201-1300]: loss = 0.511862 * 100, metric = 10.12% * 100;
 Minibatch[1301-1400]: loss = 0.499004 * 100, metric = 9.62% * 100;
 Minibatch[1401-1500]: loss = 0.518776 * 100, metric = 10.13% * 100;
 Minibatch[1501-1600]: loss = 0.490497 * 100, metric = 9.36% * 100;
 Minibatch[1601-1700]: loss = 0.508482 * 100, metric = 9.92% * 100;
 Minibatch[1701-1800]: loss = 0.492841 * 100, metric = 9.40% * 100;
 Minibatch[1801-1900]: loss = 0.496943 * 100, metric = 9.52% * 100;
 Minibatch[1901-2000]: loss = 0.511411 * 100, metric = 9.86% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.503181 * 2000, metric = 9.71% * 2000 980.226s (  2.0 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 18.28% * 2000;
 Minibatch[   1- 100]: loss = 0.501784 * 100, metric = 9.83% * 100;
 Minibatch[ 101- 200]: loss = 0.506021 * 100, metric = 10.19% * 100;
 Minibatch[ 201- 300]: loss = 0.500585 * 100, metric = 9.74% * 100;
 Minibatch[ 301- 400]: loss = 0.511105 * 100, metric = 9.91% * 100;
 Minibatch[ 401- 500]: loss = 0.504548 * 100, metric = 10.08% * 100;
 Minibatch[ 501- 600]: loss = 0.509979 * 100, metric = 10.22% * 100;
 Minibatch[ 601- 700]: loss = 0.490148 * 100, metric = 9.17% * 100;
 Minibatch[ 701- 800]: loss = 0.488999 * 100, metric = 9.44% * 100;
 Minibatch[ 801- 900]: loss = 0.500982 * 100, metric = 9.75% * 100;
 Minibatch[ 901-1000]: loss = 0.511991 * 100, metric = 10.10% * 100;
 Minibatch[1001-1100]: loss = 0.509591 * 100, metric = 9.95% * 100;
 Minibatch[1101-1200]: loss = 0.507575 * 100, metric = 9.84% * 100;
 Minibatch[1201-1300]: loss = 0.505579 * 100, metric = 10.04% * 100;
 Minibatch[1301-1400]: loss = 0.492635 * 100, metric = 9.74% * 100;
 Minibatch[1401-1500]: loss = 0.486970 * 100, metric = 9.33% * 100;
 Minibatch[1501-1600]: loss = 0.485016 * 100, metric = 9.52% * 100;
 Minibatch[1601-1700]: loss = 0.477532 * 100, metric = 9.20% * 100;
 Minibatch[1701-1800]: loss = 0.498864 * 100, metric = 9.55% * 100;
 Minibatch[1801-1900]: loss = 0.490266 * 100, metric = 9.30% * 100;
 Minibatch[1901-2000]: loss = 0.502067 * 100, metric = 9.90% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.499112 * 2000, metric = 9.74% * 2000 998.259s (  2.0 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 18.76% * 2000;
 Minibatch[   1- 100]: loss = 0.487347 * 100, metric = 9.25% * 100;
 Minibatch[ 101- 200]: loss = 0.485421 * 100, metric = 9.52% * 100;
 Minibatch[ 201- 300]: loss = 0.497493 * 100, metric = 9.84% * 100;
 Minibatch[ 301- 400]: loss = 0.490483 * 100, metric = 9.75% * 100;
 Minibatch[ 401- 500]: loss = 0.486537 * 100, metric = 9.59% * 100;
 Minibatch[ 501- 600]: loss = 0.490513 * 100, metric = 9.56% * 100;
 Minibatch[ 601- 700]: loss = 0.486407 * 100, metric = 9.44% * 100;
 Minibatch[ 701- 800]: loss = 0.504745 * 100, metric = 10.10% * 100;
 Minibatch[ 801- 900]: loss = 0.511219 * 100, metric = 10.27% * 100;
 Minibatch[ 901-1000]: loss = 0.499236 * 100, metric = 9.89% * 100;
 Minibatch[1001-1100]: loss = 0.496661 * 100, metric = 9.81% * 100;
 Minibatch[1101-1200]: loss = 0.484942 * 100, metric = 9.32% * 100;
 Minibatch[1201-1300]: loss = 0.481769 * 100, metric = 9.20% * 100;
 Minibatch[1301-1400]: loss = 0.497486 * 100, metric = 9.95% * 100;
 Minibatch[1401-1500]: loss = 0.495517 * 100, metric = 9.76% * 100;
 Minibatch[1501-1600]: loss = 0.480088 * 100, metric = 9.34% * 100;
 Minibatch[1601-1700]: loss = 0.482842 * 100, metric = 9.27% * 100;
 Minibatch[1701-1800]: loss = 0.483245 * 100, metric = 9.32% * 100;
 Minibatch[1801-1900]: loss = 0.486779 * 100, metric = 9.50% * 100;
 Minibatch[1901-2000]: loss = 0.495164 * 100, metric = 9.53% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.491195 * 2000, metric = 9.61% * 2000 973.472s (  2.1 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 19.51% * 2000;
 Minibatch[   1- 100]: loss = 0.479133 * 100, metric = 9.31% * 100;
 Minibatch[ 101- 200]: loss = 0.489512 * 100, metric = 9.52% * 100;
 Minibatch[ 201- 300]: loss = 0.484308 * 100, metric = 9.47% * 100;
 Minibatch[ 301- 400]: loss = 0.474186 * 100, metric = 9.09% * 100;
 Minibatch[ 401- 500]: loss = 0.483615 * 100, metric = 9.35% * 100;
 Minibatch[ 501- 600]: loss = 0.475400 * 100, metric = 8.98% * 100;
 Minibatch[ 601- 700]: loss = 0.457715 * 100, metric = 8.79% * 100;
 Minibatch[ 701- 800]: loss = 0.483586 * 100, metric = 9.52% * 100;
 Minibatch[ 801- 900]: loss = 0.492632 * 100, metric = 10.00% * 100;
 Minibatch[ 901-1000]: loss = 0.485400 * 100, metric = 9.49% * 100;
 Minibatch[1001-1100]: loss = 0.492968 * 100, metric = 9.45% * 100;
 Minibatch[1101-1200]: loss = 0.475545 * 100, metric = 9.33% * 100;
 Minibatch[1201-1300]: loss = 0.461509 * 100, metric = 8.63% * 100;
 Minibatch[1301-1400]: loss = 0.490098 * 100, metric = 9.89% * 100;
 Minibatch[1401-1500]: loss = 0.447562 * 100, metric = 8.52% * 100;
 Minibatch[1501-1600]: loss = 0.469106 * 100, metric = 9.00% * 100;
 Minibatch[1601-1700]: loss = 0.472728 * 100, metric = 9.31% * 100;
 Minibatch[1701-1800]: loss = 0.459159 * 100, metric = 8.54% * 100;
 Minibatch[1801-1900]: loss = 0.470189 * 100, metric = 9.23% * 100;
 Minibatch[1901-2000]: loss = 0.472827 * 100, metric = 9.18% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.475859 * 2000, metric = 9.23% * 2000 967.856s (  2.1 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 16.95% * 2000;
0.5964775234311819
 Minibatch[   1- 100]: loss = 0.494194 * 100, metric = 9.75% * 100;
 Minibatch[ 101- 200]: loss = 0.475143 * 100, metric = 9.24% * 100;
 Minibatch[ 201- 300]: loss = 0.476717 * 100, metric = 9.17% * 100;
 Minibatch[ 301- 400]: loss = 0.480997 * 100, metric = 9.32% * 100;
 Minibatch[ 401- 500]: loss = 0.459461 * 100, metric = 8.85% * 100;
 Minibatch[ 501- 600]: loss = 0.461476 * 100, metric = 8.93% * 100;
 Minibatch[ 601- 700]: loss = 0.470139 * 100, metric = 9.07% * 100;
 Minibatch[ 701- 800]: loss = 0.466563 * 100, metric = 9.02% * 100;
 Minibatch[ 801- 900]: loss = 0.451200 * 100, metric = 8.60% * 100;
 Minibatch[ 901-1000]: loss = 0.476637 * 100, metric = 9.37% * 100;
 Minibatch[1001-1100]: loss = 0.461087 * 100, metric = 8.81% * 100;
 Minibatch[1101-1200]: loss = 0.460911 * 100, metric = 8.89% * 100;
 Minibatch[1201-1300]: loss = 0.450194 * 100, metric = 8.56% * 100;
 Minibatch[1301-1400]: loss = 0.456115 * 100, metric = 8.76% * 100;
 Minibatch[1401-1500]: loss = 0.460084 * 100, metric = 9.04% * 100;
 Minibatch[1501-1600]: loss = 0.463126 * 100, metric = 9.24% * 100;
 Minibatch[1601-1700]: loss = 0.466908 * 100, metric = 9.07% * 100;
 Minibatch[1701-1800]: loss = 0.473610 * 100, metric = 9.10% * 100;
 Minibatch[1801-1900]: loss = 0.470877 * 100, metric = 9.49% * 100;
 Minibatch[1901-2000]: loss = 0.454207 * 100, metric = 8.99% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.466482 * 2000, metric = 9.06% * 2000 978.477s (  2.0 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 16.15% * 2000;
0.5928208663910627
 Minibatch[   1- 100]: loss = 0.449967 * 100, metric = 8.52% * 100;
 Minibatch[ 101- 200]: loss = 0.469630 * 100, metric = 9.22% * 100;
 Minibatch[ 201- 300]: loss = 0.460258 * 100, metric = 8.97% * 100;
 Minibatch[ 301- 400]: loss = 0.454357 * 100, metric = 8.75% * 100;
 Minibatch[ 401- 500]: loss = 0.467866 * 100, metric = 9.02% * 100;
 Minibatch[ 501- 600]: loss = 0.455654 * 100, metric = 8.87% * 100;
 Minibatch[ 601- 700]: loss = 0.436866 * 100, metric = 8.04% * 100;
 Minibatch[ 701- 800]: loss = 0.452625 * 100, metric = 8.59% * 100;
 Minibatch[ 801- 900]: loss = 0.452304 * 100, metric = 8.82% * 100;
 Minibatch[ 901-1000]: loss = 0.451627 * 100, metric = 8.74% * 100;
 Minibatch[1001-1100]: loss = 0.437756 * 100, metric = 8.46% * 100;
 Minibatch[1101-1200]: loss = 0.465941 * 100, metric = 9.04% * 100;
 Minibatch[1201-1300]: loss = 0.463067 * 100, metric = 8.90% * 100;
 Minibatch[1301-1400]: loss = 0.440809 * 100, metric = 8.19% * 100;
 Minibatch[1401-1500]: loss = 0.455291 * 100, metric = 8.70% * 100;
 Minibatch[1501-1600]: loss = 0.455405 * 100, metric = 8.62% * 100;
 Minibatch[1601-1700]: loss = 0.451463 * 100, metric = 8.56% * 100;
 Minibatch[1701-1800]: loss = 0.442609 * 100, metric = 8.42% * 100;
 Minibatch[1801-1900]: loss = 0.467618 * 100, metric = 9.30% * 100;
 Minibatch[1901-2000]: loss = 0.471438 * 100, metric = 9.12% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.455128 * 2000, metric = 8.74% * 2000 973.215s (  2.1 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 16.58% * 2000;
 Minibatch[   1- 100]: loss = 0.436742 * 100, metric = 8.22% * 100;
 Minibatch[ 101- 200]: loss = 0.462138 * 100, metric = 9.21% * 100;
 Minibatch[ 201- 300]: loss = 0.442572 * 100, metric = 8.57% * 100;
 Minibatch[ 301- 400]: loss = 0.455862 * 100, metric = 8.89% * 100;
 Minibatch[ 401- 500]: loss = 0.431982 * 100, metric = 8.15% * 100;
 Minibatch[ 501- 600]: loss = 0.445842 * 100, metric = 8.46% * 100;
 Minibatch[ 601- 700]: loss = 0.447737 * 100, metric = 8.68% * 100;
 Minibatch[ 701- 800]: loss = 0.440541 * 100, metric = 8.76% * 100;
 Minibatch[ 801- 900]: loss = 0.455398 * 100, metric = 8.83% * 100;
 Minibatch[ 901-1000]: loss = 0.449886 * 100, metric = 8.70% * 100;
 Minibatch[1001-1100]: loss = 0.457108 * 100, metric = 8.85% * 100;
 Minibatch[1101-1200]: loss = 0.450901 * 100, metric = 8.66% * 100;
 Minibatch[1201-1300]: loss = 0.461498 * 100, metric = 9.17% * 100;
 Minibatch[1301-1400]: loss = 0.461166 * 100, metric = 8.76% * 100;
 Minibatch[1401-1500]: loss = 0.431353 * 100, metric = 8.26% * 100;
 Minibatch[1501-1600]: loss = 0.444152 * 100, metric = 8.50% * 100;
 Minibatch[1601-1700]: loss = 0.428689 * 100, metric = 7.97% * 100;
 Minibatch[1701-1800]: loss = 0.429749 * 100, metric = 8.30% * 100;
 Minibatch[1801-1900]: loss = 0.424843 * 100, metric = 8.25% * 100;
 Minibatch[1901-2000]: loss = 0.434478 * 100, metric = 8.17% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.444632 * 2000, metric = 8.57% * 2000 958.227s (  2.1 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 17.44% * 2000;
 Minibatch[   1- 100]: loss = 0.458758 * 100, metric = 9.21% * 100;
 Minibatch[ 101- 200]: loss = 0.458003 * 100, metric = 8.90% * 100;
 Minibatch[ 201- 300]: loss = 0.429511 * 100, metric = 8.07% * 100;
 Minibatch[ 301- 400]: loss = 0.452044 * 100, metric = 8.46% * 100;
 Minibatch[ 401- 500]: loss = 0.446290 * 100, metric = 8.46% * 100;
 Minibatch[ 501- 600]: loss = 0.427985 * 100, metric = 7.77% * 100;
 Minibatch[ 601- 700]: loss = 0.443094 * 100, metric = 8.28% * 100;
 Minibatch[ 701- 800]: loss = 0.433006 * 100, metric = 8.23% * 100;
 Minibatch[ 801- 900]: loss = 0.466808 * 100, metric = 9.24% * 100;
 Minibatch[ 901-1000]: loss = 0.435248 * 100, metric = 8.10% * 100;
 Minibatch[1001-1100]: loss = 0.448345 * 100, metric = 8.62% * 100;
 Minibatch[1101-1200]: loss = 0.441765 * 100, metric = 8.60% * 100;
 Minibatch[1201-1300]: loss = 0.440186 * 100, metric = 8.43% * 100;
 Minibatch[1301-1400]: loss = 0.428972 * 100, metric = 8.16% * 100;
 Minibatch[1401-1500]: loss = 0.439772 * 100, metric = 8.51% * 100;
 Minibatch[1501-1600]: loss = 0.440693 * 100, metric = 8.54% * 100;
 Minibatch[1601-1700]: loss = 0.423706 * 100, metric = 8.09% * 100;
 Minibatch[1701-1800]: loss = 0.412461 * 100, metric = 7.75% * 100;
 Minibatch[1801-1900]: loss = 0.430222 * 100, metric = 8.16% * 100;
 Minibatch[1901-2000]: loss = 0.425776 * 100, metric = 8.11% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.439132 * 2000, metric = 8.38% * 2000 962.498s (  2.1 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 15.89% * 2000;
0.5869514901861549
 Minibatch[   1- 100]: loss = 0.428123 * 100, metric = 7.99% * 100;
 Minibatch[ 101- 200]: loss = 0.431453 * 100, metric = 8.15% * 100;
 Minibatch[ 201- 300]: loss = 0.423085 * 100, metric = 8.07% * 100;
 Minibatch[ 301- 400]: loss = 0.450822 * 100, metric = 8.52% * 100;
 Minibatch[ 401- 500]: loss = 0.429839 * 100, metric = 8.19% * 100;
 Minibatch[ 501- 600]: loss = 0.439034 * 100, metric = 8.32% * 100;
 Minibatch[ 601- 700]: loss = 0.442262 * 100, metric = 8.63% * 100;
 Minibatch[ 701- 800]: loss = 0.432945 * 100, metric = 8.24% * 100;
 Minibatch[ 801- 900]: loss = 0.439335 * 100, metric = 8.50% * 100;
 Minibatch[ 901-1000]: loss = 0.443048 * 100, metric = 8.37% * 100;
 Minibatch[1001-1100]: loss = 0.417068 * 100, metric = 8.02% * 100;
 Minibatch[1101-1200]: loss = 0.429482 * 100, metric = 8.22% * 100;
 Minibatch[1201-1300]: loss = 0.435656 * 100, metric = 8.26% * 100;
 Minibatch[1301-1400]: loss = 0.436627 * 100, metric = 8.42% * 100;
 Minibatch[1401-1500]: loss = 0.422839 * 100, metric = 8.16% * 100;
 Minibatch[1501-1600]: loss = 0.443741 * 100, metric = 8.51% * 100;
 Minibatch[1601-1700]: loss = 0.434304 * 100, metric = 8.32% * 100;
 Minibatch[1701-1800]: loss = 0.437693 * 100, metric = 8.45% * 100;
 Minibatch[1801-1900]: loss = 0.427772 * 100, metric = 8.22% * 100;
 Minibatch[1901-2000]: loss = 0.431958 * 100, metric = 8.20% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.433854 * 2000, metric = 8.29% * 2000 951.954s (  2.1 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 16.91% * 2000;
 Minibatch[   1- 100]: loss = 0.435079 * 100, metric = 8.37% * 100;
 Minibatch[ 101- 200]: loss = 0.430452 * 100, metric = 8.35% * 100;
 Minibatch[ 201- 300]: loss = 0.429561 * 100, metric = 8.24% * 100;
 Minibatch[ 301- 400]: loss = 0.434420 * 100, metric = 8.62% * 100;
 Minibatch[ 401- 500]: loss = 0.422743 * 100, metric = 7.91% * 100;
 Minibatch[ 501- 600]: loss = 0.421040 * 100, metric = 8.01% * 100;
 Minibatch[ 601- 700]: loss = 0.421235 * 100, metric = 8.11% * 100;
 Minibatch[ 701- 800]: loss = 0.404522 * 100, metric = 7.46% * 100;
 Minibatch[ 801- 900]: loss = 0.429659 * 100, metric = 8.14% * 100;
 Minibatch[ 901-1000]: loss = 0.416818 * 100, metric = 8.06% * 100;
 Minibatch[1001-1100]: loss = 0.418370 * 100, metric = 7.91% * 100;
 Minibatch[1101-1200]: loss = 0.419353 * 100, metric = 7.98% * 100;
 Minibatch[1201-1300]: loss = 0.422221 * 100, metric = 8.02% * 100;
 Minibatch[1301-1400]: loss = 0.406783 * 100, metric = 7.70% * 100;
 Minibatch[1401-1500]: loss = 0.427148 * 100, metric = 8.03% * 100;
 Minibatch[1501-1600]: loss = 0.430079 * 100, metric = 8.48% * 100;
 Minibatch[1601-1700]: loss = 0.413773 * 100, metric = 7.87% * 100;
 Minibatch[1701-1800]: loss = 0.412408 * 100, metric = 7.82% * 100;
 Minibatch[1801-1900]: loss = 0.427153 * 100, metric = 8.24% * 100;
 Minibatch[1901-2000]: loss = 0.408179 * 100, metric = 7.72% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.421550 * 2000, metric = 8.05% * 2000 948.046s (  2.1 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 16.08% * 2000;
0.575218413464725
 Minibatch[   1- 100]: loss = 0.426255 * 100, metric = 8.06% * 100;
 Minibatch[ 101- 200]: loss = 0.423885 * 100, metric = 8.14% * 100;
 Minibatch[ 201- 300]: loss = 0.424424 * 100, metric = 8.18% * 100;
 Minibatch[ 301- 400]: loss = 0.417486 * 100, metric = 8.12% * 100;
 Minibatch[ 401- 500]: loss = 0.420650 * 100, metric = 8.09% * 100;
 Minibatch[ 501- 600]: loss = 0.419611 * 100, metric = 7.81% * 100;
 Minibatch[ 601- 700]: loss = 0.409781 * 100, metric = 7.86% * 100;
 Minibatch[ 701- 800]: loss = 0.408954 * 100, metric = 7.82% * 100;
 Minibatch[ 801- 900]: loss = 0.417547 * 100, metric = 8.01% * 100;
 Minibatch[ 901-1000]: loss = 0.420659 * 100, metric = 8.06% * 100;
 Minibatch[1001-1100]: loss = 0.404282 * 100, metric = 7.49% * 100;
 Minibatch[1101-1200]: loss = 0.395844 * 100, metric = 7.38% * 100;
 Minibatch[1201-1300]: loss = 0.407708 * 100, metric = 7.59% * 100;
 Minibatch[1301-1400]: loss = 0.410294 * 100, metric = 7.75% * 100;
 Minibatch[1401-1500]: loss = 0.404525 * 100, metric = 7.57% * 100;
 Minibatch[1501-1600]: loss = 0.398864 * 100, metric = 7.44% * 100;
 Minibatch[1601-1700]: loss = 0.402162 * 100, metric = 7.54% * 100;
 Minibatch[1701-1800]: loss = 0.400610 * 100, metric = 7.31% * 100;
 Minibatch[1801-1900]: loss = 0.402870 * 100, metric = 7.53% * 100;
 Minibatch[1901-2000]: loss = 0.405928 * 100, metric = 7.48% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.411117 * 2000, metric = 7.76% * 2000 941.985s (  2.1 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 16.18% * 2000;
 Minibatch[   1- 100]: loss = 0.410948 * 100, metric = 7.66% * 100;
 Minibatch[ 101- 200]: loss = 0.421826 * 100, metric = 8.01% * 100;
 Minibatch[ 201- 300]: loss = 0.404363 * 100, metric = 7.55% * 100;
 Minibatch[ 301- 400]: loss = 0.417296 * 100, metric = 8.06% * 100;
 Minibatch[ 401- 500]: loss = 0.419024 * 100, metric = 7.91% * 100;
 Minibatch[ 501- 600]: loss = 0.411326 * 100, metric = 7.80% * 100;
 Minibatch[ 601- 700]: loss = 0.410852 * 100, metric = 7.63% * 100;
 Minibatch[ 701- 800]: loss = 0.395131 * 100, metric = 7.25% * 100;
 Minibatch[ 801- 900]: loss = 0.397959 * 100, metric = 7.70% * 100;
 Minibatch[ 901-1000]: loss = 0.415226 * 100, metric = 7.66% * 100;
 Minibatch[1001-1100]: loss = 0.405907 * 100, metric = 7.66% * 100;
 Minibatch[1101-1200]: loss = 0.405446 * 100, metric = 7.56% * 100;
 Minibatch[1201-1300]: loss = 0.411299 * 100, metric = 7.68% * 100;
 Minibatch[1301-1400]: loss = 0.415510 * 100, metric = 7.91% * 100;
 Minibatch[1401-1500]: loss = 0.394548 * 100, metric = 7.32% * 100;
 Minibatch[1501-1600]: loss = 0.411334 * 100, metric = 7.77% * 100;
 Minibatch[1601-1700]: loss = 0.398693 * 100, metric = 7.49% * 100;
 Minibatch[1701-1800]: loss = 0.406182 * 100, metric = 7.75% * 100;
 Minibatch[1801-1900]: loss = 0.407284 * 100, metric = 7.83% * 100;
 Minibatch[1901-2000]: loss = 0.410509 * 100, metric = 7.78% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.408533 * 2000, metric = 7.70% * 2000 938.910s (  2.1 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 17.30% * 2000;
 Minibatch[   1- 100]: loss = 0.391879 * 100, metric = 7.37% * 100;
 Minibatch[ 101- 200]: loss = 0.410288 * 100, metric = 7.95% * 100;
 Minibatch[ 201- 300]: loss = 0.392456 * 100, metric = 7.34% * 100;
 Minibatch[ 301- 400]: loss = 0.405647 * 100, metric = 7.56% * 100;
 Minibatch[ 401- 500]: loss = 0.400176 * 100, metric = 7.47% * 100;
 Minibatch[ 501- 600]: loss = 0.393594 * 100, metric = 7.56% * 100;
 Minibatch[ 601- 700]: loss = 0.411492 * 100, metric = 7.60% * 100;
 Minibatch[ 701- 800]: loss = 0.399635 * 100, metric = 7.55% * 100;
 Minibatch[ 801- 900]: loss = 0.411688 * 100, metric = 7.94% * 100;
 Minibatch[ 901-1000]: loss = 0.400782 * 100, metric = 7.72% * 100;
 Minibatch[1001-1100]: loss = 0.408690 * 100, metric = 7.84% * 100;
 Minibatch[1101-1200]: loss = 0.420732 * 100, metric = 7.95% * 100;
 Minibatch[1201-1300]: loss = 0.408125 * 100, metric = 7.71% * 100;
 Minibatch[1301-1400]: loss = 0.397738 * 100, metric = 7.51% * 100;
 Minibatch[1401-1500]: loss = 0.390247 * 100, metric = 7.19% * 100;
 Minibatch[1501-1600]: loss = 0.406066 * 100, metric = 7.92% * 100;
 Minibatch[1601-1700]: loss = 0.387888 * 100, metric = 7.06% * 100;
 Minibatch[1701-1800]: loss = 0.391503 * 100, metric = 7.15% * 100;
 Minibatch[1801-1900]: loss = 0.403369 * 100, metric = 7.80% * 100;
 Minibatch[1901-2000]: loss = 0.408171 * 100, metric = 7.74% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.402008 * 2000, metric = 7.60% * 2000 945.318s (  2.1 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 15.45% * 2000;
 Minibatch[   1- 100]: loss = 0.405688 * 100, metric = 7.74% * 100;
 Minibatch[ 101- 200]: loss = 0.396720 * 100, metric = 7.38% * 100;
 Minibatch[ 201- 300]: loss = 0.405176 * 100, metric = 7.83% * 100;
 Minibatch[ 301- 400]: loss = 0.403319 * 100, metric = 7.53% * 100;
 Minibatch[ 401- 500]: loss = 0.396645 * 100, metric = 7.57% * 100;
 Minibatch[ 501- 600]: loss = 0.404311 * 100, metric = 7.73% * 100;
 Minibatch[ 601- 700]: loss = 0.401521 * 100, metric = 7.65% * 100;
 Minibatch[ 701- 800]: loss = 0.389722 * 100, metric = 7.03% * 100;
 Minibatch[ 801- 900]: loss = 0.382907 * 100, metric = 7.08% * 100;
 Minibatch[ 901-1000]: loss = 0.395389 * 100, metric = 7.47% * 100;
 Minibatch[1001-1100]: loss = 0.398046 * 100, metric = 7.53% * 100;
 Minibatch[1101-1200]: loss = 0.402491 * 100, metric = 7.52% * 100;
 Minibatch[1201-1300]: loss = 0.418970 * 100, metric = 8.01% * 100;
 Minibatch[1301-1400]: loss = 0.392714 * 100, metric = 7.30% * 100;
 Minibatch[1401-1500]: loss = 0.382789 * 100, metric = 6.95% * 100;
 Minibatch[1501-1600]: loss = 0.408106 * 100, metric = 7.83% * 100;
 Minibatch[1601-1700]: loss = 0.394756 * 100, metric = 7.38% * 100;
 Minibatch[1701-1800]: loss = 0.390849 * 100, metric = 7.35% * 100;
 Minibatch[1801-1900]: loss = 0.382798 * 100, metric = 6.88% * 100;
 Minibatch[1901-2000]: loss = 0.373931 * 100, metric = 6.96% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.396342 * 2000, metric = 7.44% * 2000 942.594s (  2.1 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 15.73% * 2000;
 Minibatch[   1- 100]: loss = 0.393798 * 100, metric = 7.46% * 100;
 Minibatch[ 101- 200]: loss = 0.377610 * 100, metric = 6.91% * 100;
 Minibatch[ 201- 300]: loss = 0.395641 * 100, metric = 7.57% * 100;
 Minibatch[ 301- 400]: loss = 0.383349 * 100, metric = 6.93% * 100;
 Minibatch[ 401- 500]: loss = 0.387357 * 100, metric = 7.23% * 100;
 Minibatch[ 501- 600]: loss = 0.384283 * 100, metric = 7.09% * 100;
 Minibatch[ 601- 700]: loss = 0.397017 * 100, metric = 7.47% * 100;
 Minibatch[ 701- 800]: loss = 0.382498 * 100, metric = 7.08% * 100;
 Minibatch[ 801- 900]: loss = 0.374065 * 100, metric = 6.73% * 100;
 Minibatch[ 901-1000]: loss = 0.374689 * 100, metric = 6.80% * 100;
 Minibatch[1001-1100]: loss = 0.391358 * 100, metric = 7.52% * 100;
 Minibatch[1101-1200]: loss = 0.397981 * 100, metric = 7.48% * 100;
 Minibatch[1201-1300]: loss = 0.386237 * 100, metric = 6.95% * 100;
 Minibatch[1301-1400]: loss = 0.369270 * 100, metric = 6.77% * 100;
 Minibatch[1401-1500]: loss = 0.383745 * 100, metric = 7.08% * 100;
 Minibatch[1501-1600]: loss = 0.385291 * 100, metric = 6.94% * 100;
 Minibatch[1601-1700]: loss = 0.401121 * 100, metric = 7.66% * 100;
 Minibatch[1701-1800]: loss = 0.392512 * 100, metric = 7.34% * 100;
 Minibatch[1801-1900]: loss = 0.391291 * 100, metric = 7.47% * 100;
 Minibatch[1901-2000]: loss = 0.386403 * 100, metric = 7.11% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.386776 * 2000, metric = 7.18% * 2000 932.466s (  2.1 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 16.88% * 2000;
 Minibatch[   1- 100]: loss = 0.389908 * 100, metric = 7.18% * 100;
 Minibatch[ 101- 200]: loss = 0.396837 * 100, metric = 7.39% * 100;
 Minibatch[ 201- 300]: loss = 0.381508 * 100, metric = 7.14% * 100;
 Minibatch[ 301- 400]: loss = 0.378028 * 100, metric = 7.13% * 100;
 Minibatch[ 401- 500]: loss = 0.381383 * 100, metric = 7.07% * 100;
 Minibatch[ 501- 600]: loss = 0.373161 * 100, metric = 6.80% * 100;
 Minibatch[ 601- 700]: loss = 0.369599 * 100, metric = 6.66% * 100;
 Minibatch[ 701- 800]: loss = 0.376235 * 100, metric = 6.79% * 100;
 Minibatch[ 801- 900]: loss = 0.391253 * 100, metric = 7.28% * 100;
 Minibatch[ 901-1000]: loss = 0.379810 * 100, metric = 7.22% * 100;
 Minibatch[1001-1100]: loss = 0.374421 * 100, metric = 6.74% * 100;
 Minibatch[1101-1200]: loss = 0.386625 * 100, metric = 7.16% * 100;
 Minibatch[1201-1300]: loss = 0.375882 * 100, metric = 6.79% * 100;
 Minibatch[1301-1400]: loss = 0.389045 * 100, metric = 7.44% * 100;
 Minibatch[1401-1500]: loss = 0.375328 * 100, metric = 6.82% * 100;
 Minibatch[1501-1600]: loss = 0.380321 * 100, metric = 7.11% * 100;
 Minibatch[1601-1700]: loss = 0.365338 * 100, metric = 6.55% * 100;
 Minibatch[1701-1800]: loss = 0.373598 * 100, metric = 6.78% * 100;
 Minibatch[1801-1900]: loss = 0.374031 * 100, metric = 6.87% * 100;
 Minibatch[1901-2000]: loss = 0.390490 * 100, metric = 7.04% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.380140 * 2000, metric = 7.00% * 2000 938.466s (  2.1 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 14.65% * 2000;
0.5610241289585829
 Minibatch[   1- 100]: loss = 0.385792 * 100, metric = 7.14% * 100;
 Minibatch[ 101- 200]: loss = 0.371833 * 100, metric = 6.79% * 100;
 Minibatch[ 201- 300]: loss = 0.386953 * 100, metric = 7.25% * 100;
 Minibatch[ 301- 400]: loss = 0.376443 * 100, metric = 6.83% * 100;
 Minibatch[ 401- 500]: loss = 0.379130 * 100, metric = 7.24% * 100;
 Minibatch[ 501- 600]: loss = 0.395799 * 100, metric = 7.70% * 100;
 Minibatch[ 601- 700]: loss = 0.371344 * 100, metric = 6.90% * 100;
 Minibatch[ 701- 800]: loss = 0.363497 * 100, metric = 6.74% * 100;
 Minibatch[ 801- 900]: loss = 0.377177 * 100, metric = 7.16% * 100;
 Minibatch[ 901-1000]: loss = 0.381005 * 100, metric = 7.15% * 100;
 Minibatch[1001-1100]: loss = 0.376709 * 100, metric = 6.94% * 100;
 Minibatch[1101-1200]: loss = 0.365454 * 100, metric = 6.61% * 100;
 Minibatch[1201-1300]: loss = 0.377012 * 100, metric = 6.94% * 100;
 Minibatch[1301-1400]: loss = 0.364755 * 100, metric = 6.64% * 100;
 Minibatch[1401-1500]: loss = 0.381481 * 100, metric = 7.05% * 100;
 Minibatch[1501-1600]: loss = 0.370937 * 100, metric = 6.76% * 100;
 Minibatch[1601-1700]: loss = 0.371873 * 100, metric = 6.65% * 100;
 Minibatch[1701-1800]: loss = 0.367776 * 100, metric = 6.64% * 100;
 Minibatch[1801-1900]: loss = 0.370240 * 100, metric = 6.89% * 100;
 Minibatch[1901-2000]: loss = 0.374018 * 100, metric = 6.81% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.375461 * 2000, metric = 6.94% * 2000 938.051s (  2.1 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 14.97% * 2000;
 Minibatch[   1- 100]: loss = 0.360865 * 100, metric = 6.57% * 100;
 Minibatch[ 101- 200]: loss = 0.366097 * 100, metric = 6.89% * 100;
 Minibatch[ 201- 300]: loss = 0.375394 * 100, metric = 7.04% * 100;
 Minibatch[ 301- 400]: loss = 0.389493 * 100, metric = 7.29% * 100;
 Minibatch[ 401- 500]: loss = 0.357774 * 100, metric = 6.42% * 100;
 Minibatch[ 501- 600]: loss = 0.373168 * 100, metric = 6.94% * 100;
 Minibatch[ 601- 700]: loss = 0.369345 * 100, metric = 7.06% * 100;
 Minibatch[ 701- 800]: loss = 0.371856 * 100, metric = 7.02% * 100;
 Minibatch[ 801- 900]: loss = 0.366308 * 100, metric = 6.84% * 100;
 Minibatch[ 901-1000]: loss = 0.371832 * 100, metric = 6.90% * 100;
 Minibatch[1001-1100]: loss = 0.371446 * 100, metric = 6.90% * 100;
 Minibatch[1101-1200]: loss = 0.367702 * 100, metric = 6.77% * 100;
 Minibatch[1201-1300]: loss = 0.370883 * 100, metric = 6.74% * 100;
 Minibatch[1301-1400]: loss = 0.362227 * 100, metric = 6.72% * 100;
 Minibatch[1401-1500]: loss = 0.388705 * 100, metric = 7.20% * 100;
 Minibatch[1501-1600]: loss = 0.359694 * 100, metric = 6.58% * 100;
 Minibatch[1601-1700]: loss = 0.377679 * 100, metric = 6.98% * 100;
 Minibatch[1701-1800]: loss = 0.351287 * 100, metric = 6.42% * 100;
 Minibatch[1801-1900]: loss = 0.382657 * 100, metric = 7.24% * 100;
 Minibatch[1901-2000]: loss = 0.370056 * 100, metric = 6.77% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.370223 * 2000, metric = 6.86% * 2000 924.489s (  2.2 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 16.29% * 2000;
 Minibatch[   1- 100]: loss = 0.382234 * 100, metric = 7.16% * 100;
 Minibatch[ 101- 200]: loss = 0.350762 * 100, metric = 6.19% * 100;
 Minibatch[ 201- 300]: loss = 0.358707 * 100, metric = 6.46% * 100;
 Minibatch[ 301- 400]: loss = 0.371883 * 100, metric = 6.75% * 100;
 Minibatch[ 401- 500]: loss = 0.362510 * 100, metric = 6.71% * 100;
 Minibatch[ 501- 600]: loss = 0.346259 * 100, metric = 6.14% * 100;
 Minibatch[ 601- 700]: loss = 0.364334 * 100, metric = 6.73% * 100;
 Minibatch[ 701- 800]: loss = 0.359662 * 100, metric = 6.63% * 100;
 Minibatch[ 801- 900]: loss = 0.371055 * 100, metric = 6.88% * 100;
 Minibatch[ 901-1000]: loss = 0.345493 * 100, metric = 6.31% * 100;
 Minibatch[1001-1100]: loss = 0.357724 * 100, metric = 6.30% * 100;
 Minibatch[1101-1200]: loss = 0.368723 * 100, metric = 6.85% * 100;
 Minibatch[1201-1300]: loss = 0.361141 * 100, metric = 6.49% * 100;
 Minibatch[1301-1400]: loss = 0.364712 * 100, metric = 6.83% * 100;
 Minibatch[1401-1500]: loss = 0.359235 * 100, metric = 6.46% * 100;
 Minibatch[1501-1600]: loss = 0.364049 * 100, metric = 6.78% * 100;
 Minibatch[1601-1700]: loss = 0.365944 * 100, metric = 6.76% * 100;
 Minibatch[1701-1800]: loss = 0.368337 * 100, metric = 6.88% * 100;
 Minibatch[1801-1900]: loss = 0.364537 * 100, metric = 6.91% * 100;
 Minibatch[1901-2000]: loss = 0.377849 * 100, metric = 6.95% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.363258 * 2000, metric = 6.66% * 2000 925.801s (  2.2 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 15.23% * 2000;
 Minibatch[   1- 100]: loss = 0.358724 * 100, metric = 6.35% * 100;
 Minibatch[ 101- 200]: loss = 0.367419 * 100, metric = 6.80% * 100;
 Minibatch[ 201- 300]: loss = 0.355322 * 100, metric = 6.48% * 100;
 Minibatch[ 301- 400]: loss = 0.360181 * 100, metric = 6.68% * 100;
 Minibatch[ 401- 500]: loss = 0.355493 * 100, metric = 6.50% * 100;
 Minibatch[ 501- 600]: loss = 0.354098 * 100, metric = 6.38% * 100;
 Minibatch[ 601- 700]: loss = 0.369501 * 100, metric = 6.90% * 100;
 Minibatch[ 701- 800]: loss = 0.365370 * 100, metric = 6.83% * 100;
 Minibatch[ 801- 900]: loss = 0.360834 * 100, metric = 6.46% * 100;
 Minibatch[ 901-1000]: loss = 0.351377 * 100, metric = 6.57% * 100;
 Minibatch[1001-1100]: loss = 0.346135 * 100, metric = 6.19% * 100;
 Minibatch[1101-1200]: loss = 0.356531 * 100, metric = 6.55% * 100;
 Minibatch[1201-1300]: loss = 0.355187 * 100, metric = 6.59% * 100;
 Minibatch[1301-1400]: loss = 0.350587 * 100, metric = 6.35% * 100;
 Minibatch[1401-1500]: loss = 0.365250 * 100, metric = 6.75% * 100;
 Minibatch[1501-1600]: loss = 0.345211 * 100, metric = 6.34% * 100;
 Minibatch[1601-1700]: loss = 0.352986 * 100, metric = 6.49% * 100;
 Minibatch[1701-1800]: loss = 0.349407 * 100, metric = 6.42% * 100;
 Minibatch[1801-1900]: loss = 0.356796 * 100, metric = 6.45% * 100;
 Minibatch[1901-2000]: loss = 0.356917 * 100, metric = 6.53% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.356666 * 2000, metric = 6.53% * 2000 922.984s (  2.2 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 15.39% * 2000;
 Minibatch[   1- 100]: loss = 0.363056 * 100, metric = 6.77% * 100;
 Minibatch[ 101- 200]: loss = 0.354528 * 100, metric = 6.52% * 100;
 Minibatch[ 201- 300]: loss = 0.359951 * 100, metric = 6.63% * 100;
 Minibatch[ 301- 400]: loss = 0.368920 * 100, metric = 6.79% * 100;
 Minibatch[ 401- 500]: loss = 0.360434 * 100, metric = 6.72% * 100;
 Minibatch[ 501- 600]: loss = 0.363690 * 100, metric = 6.83% * 100;
 Minibatch[ 601- 700]: loss = 0.351406 * 100, metric = 6.44% * 100;
 Minibatch[ 701- 800]: loss = 0.347807 * 100, metric = 6.41% * 100;
 Minibatch[ 801- 900]: loss = 0.351018 * 100, metric = 6.52% * 100;
 Minibatch[ 901-1000]: loss = 0.338312 * 100, metric = 6.07% * 100;
 Minibatch[1001-1100]: loss = 0.343554 * 100, metric = 6.17% * 100;
 Minibatch[1101-1200]: loss = 0.359167 * 100, metric = 6.70% * 100;
 Minibatch[1201-1300]: loss = 0.361042 * 100, metric = 6.77% * 100;
 Minibatch[1301-1400]: loss = 0.348840 * 100, metric = 6.39% * 100;
 Minibatch[1401-1500]: loss = 0.348238 * 100, metric = 6.27% * 100;
 Minibatch[1501-1600]: loss = 0.347039 * 100, metric = 6.27% * 100;
 Minibatch[1601-1700]: loss = 0.346162 * 100, metric = 6.09% * 100;
 Minibatch[1701-1800]: loss = 0.360000 * 100, metric = 6.49% * 100;
 Minibatch[1801-1900]: loss = 0.347897 * 100, metric = 6.36% * 100;
 Minibatch[1901-2000]: loss = 0.362964 * 100, metric = 6.84% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.354201 * 2000, metric = 6.50% * 2000 924.429s (  2.2 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 14.67% * 2000;
 Minibatch[   1- 100]: loss = 0.365233 * 100, metric = 6.77% * 100;
 Minibatch[ 101- 200]: loss = 0.356942 * 100, metric = 6.54% * 100;
 Minibatch[ 201- 300]: loss = 0.345190 * 100, metric = 6.38% * 100;
 Minibatch[ 301- 400]: loss = 0.350455 * 100, metric = 6.56% * 100;
 Minibatch[ 401- 500]: loss = 0.348273 * 100, metric = 6.42% * 100;
 Minibatch[ 501- 600]: loss = 0.361214 * 100, metric = 6.66% * 100;
 Minibatch[ 601- 700]: loss = 0.358443 * 100, metric = 6.60% * 100;
 Minibatch[ 701- 800]: loss = 0.354880 * 100, metric = 6.54% * 100;
 Minibatch[ 801- 900]: loss = 0.352566 * 100, metric = 6.18% * 100;
 Minibatch[ 901-1000]: loss = 0.338464 * 100, metric = 6.03% * 100;
 Minibatch[1001-1100]: loss = 0.348739 * 100, metric = 6.40% * 100;
 Minibatch[1101-1200]: loss = 0.341536 * 100, metric = 6.17% * 100;
 Minibatch[1201-1300]: loss = 0.354992 * 100, metric = 6.30% * 100;
 Minibatch[1301-1400]: loss = 0.338904 * 100, metric = 5.99% * 100;
 Minibatch[1401-1500]: loss = 0.371628 * 100, metric = 6.71% * 100;
 Minibatch[1501-1600]: loss = 0.368923 * 100, metric = 6.67% * 100;
 Minibatch[1601-1700]: loss = 0.360689 * 100, metric = 6.28% * 100;
 Minibatch[1701-1800]: loss = 0.352222 * 100, metric = 6.46% * 100;
 Minibatch[1801-1900]: loss = 0.352444 * 100, metric = 6.37% * 100;
 Minibatch[1901-2000]: loss = 0.362042 * 100, metric = 6.95% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.354189 * 2000, metric = 6.45% * 2000 923.312s (  2.2 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 14.38% * 2000;
 Minibatch[   1- 100]: loss = 0.347693 * 100, metric = 6.46% * 100;
 Minibatch[ 101- 200]: loss = 0.360075 * 100, metric = 6.61% * 100;
 Minibatch[ 201- 300]: loss = 0.343641 * 100, metric = 6.04% * 100;
 Minibatch[ 301- 400]: loss = 0.360025 * 100, metric = 6.53% * 100;
 Minibatch[ 401- 500]: loss = 0.342668 * 100, metric = 6.13% * 100;
 Minibatch[ 501- 600]: loss = 0.355213 * 100, metric = 6.35% * 100;
 Minibatch[ 601- 700]: loss = 0.350361 * 100, metric = 6.44% * 100;
 Minibatch[ 701- 800]: loss = 0.347101 * 100, metric = 6.40% * 100;
 Minibatch[ 801- 900]: loss = 0.336155 * 100, metric = 6.03% * 100;
 Minibatch[ 901-1000]: loss = 0.340381 * 100, metric = 6.23% * 100;
 Minibatch[1001-1100]: loss = 0.351754 * 100, metric = 6.59% * 100;
 Minibatch[1101-1200]: loss = 0.346861 * 100, metric = 6.38% * 100;
 Minibatch[1201-1300]: loss = 0.344167 * 100, metric = 6.18% * 100;
 Minibatch[1301-1400]: loss = 0.347476 * 100, metric = 6.28% * 100;
 Minibatch[1401-1500]: loss = 0.361128 * 100, metric = 6.86% * 100;
 Minibatch[1501-1600]: loss = 0.358074 * 100, metric = 6.58% * 100;
 Minibatch[1601-1700]: loss = 0.361915 * 100, metric = 6.90% * 100;
 Minibatch[1701-1800]: loss = 0.352783 * 100, metric = 6.48% * 100;
 Minibatch[1801-1900]: loss = 0.347358 * 100, metric = 6.44% * 100;
 Minibatch[1901-2000]: loss = 0.349930 * 100, metric = 6.46% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.350238 * 2000, metric = 6.42% * 2000 928.837s (  2.2 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 15.13% * 2000;
 Minibatch[   1- 100]: loss = 0.330070 * 100, metric = 5.96% * 100;
 Minibatch[ 101- 200]: loss = 0.340398 * 100, metric = 6.23% * 100;
 Minibatch[ 201- 300]: loss = 0.345348 * 100, metric = 6.30% * 100;
 Minibatch[ 301- 400]: loss = 0.331088 * 100, metric = 6.01% * 100;
 Minibatch[ 401- 500]: loss = 0.341496 * 100, metric = 6.25% * 100;
 Minibatch[ 501- 600]: loss = 0.327427 * 100, metric = 5.75% * 100;
 Minibatch[ 601- 700]: loss = 0.347205 * 100, metric = 6.31% * 100;
 Minibatch[ 701- 800]: loss = 0.328124 * 100, metric = 5.96% * 100;
 Minibatch[ 801- 900]: loss = 0.344221 * 100, metric = 6.33% * 100;
 Minibatch[ 901-1000]: loss = 0.331836 * 100, metric = 6.01% * 100;
 Minibatch[1001-1100]: loss = 0.355665 * 100, metric = 6.60% * 100;
 Minibatch[1101-1200]: loss = 0.344301 * 100, metric = 6.35% * 100;
 Minibatch[1201-1300]: loss = 0.346638 * 100, metric = 6.43% * 100;
 Minibatch[1301-1400]: loss = 0.351901 * 100, metric = 6.57% * 100;
 Minibatch[1401-1500]: loss = 0.334630 * 100, metric = 5.97% * 100;
 Minibatch[1501-1600]: loss = 0.341454 * 100, metric = 6.43% * 100;
 Minibatch[1601-1700]: loss = 0.341077 * 100, metric = 6.34% * 100;
 Minibatch[1701-1800]: loss = 0.329958 * 100, metric = 5.96% * 100;
 Minibatch[1801-1900]: loss = 0.348419 * 100, metric = 6.54% * 100;
 Minibatch[1901-2000]: loss = 0.334966 * 100, metric = 6.13% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.339811 * 2000, metric = 6.22% * 2000 929.201s (  2.2 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 14.55% * 2000;
 Minibatch[   1- 100]: loss = 0.332863 * 100, metric = 5.91% * 100;
 Minibatch[ 101- 200]: loss = 0.324823 * 100, metric = 5.86% * 100;
 Minibatch[ 201- 300]: loss = 0.345740 * 100, metric = 6.46% * 100;
 Minibatch[ 301- 400]: loss = 0.338411 * 100, metric = 6.32% * 100;
 Minibatch[ 401- 500]: loss = 0.327951 * 100, metric = 6.03% * 100;
 Minibatch[ 501- 600]: loss = 0.339672 * 100, metric = 6.35% * 100;
 Minibatch[ 601- 700]: loss = 0.345478 * 100, metric = 6.20% * 100;
 Minibatch[ 701- 800]: loss = 0.318782 * 100, metric = 5.69% * 100;
 Minibatch[ 801- 900]: loss = 0.326553 * 100, metric = 5.96% * 100;
 Minibatch[ 901-1000]: loss = 0.351281 * 100, metric = 6.56% * 100;
 Minibatch[1001-1100]: loss = 0.351928 * 100, metric = 6.44% * 100;
 Minibatch[1101-1200]: loss = 0.335938 * 100, metric = 6.08% * 100;
 Minibatch[1201-1300]: loss = 0.347870 * 100, metric = 6.60% * 100;
 Minibatch[1301-1400]: loss = 0.319225 * 100, metric = 5.70% * 100;
 Minibatch[1401-1500]: loss = 0.330591 * 100, metric = 6.00% * 100;
 Minibatch[1501-1600]: loss = 0.335272 * 100, metric = 5.99% * 100;
 Minibatch[1601-1700]: loss = 0.352605 * 100, metric = 6.52% * 100;
 Minibatch[1701-1800]: loss = 0.343815 * 100, metric = 6.30% * 100;
 Minibatch[1801-1900]: loss = 0.339763 * 100, metric = 6.24% * 100;
 Minibatch[1901-2000]: loss = 0.331898 * 100, metric = 6.06% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.337023 * 2000, metric = 6.16% * 2000 928.403s (  2.2 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 14.24% * 2000;
0.5585415898486972
 Minibatch[   1- 100]: loss = 0.336166 * 100, metric = 5.99% * 100;
 Minibatch[ 101- 200]: loss = 0.338890 * 100, metric = 6.32% * 100;
 Minibatch[ 201- 300]: loss = 0.336806 * 100, metric = 6.09% * 100;
 Minibatch[ 301- 400]: loss = 0.329222 * 100, metric = 5.91% * 100;
 Minibatch[ 401- 500]: loss = 0.333319 * 100, metric = 6.20% * 100;
 Minibatch[ 501- 600]: loss = 0.325391 * 100, metric = 5.96% * 100;
 Minibatch[ 601- 700]: loss = 0.333618 * 100, metric = 6.07% * 100;
 Minibatch[ 701- 800]: loss = 0.342173 * 100, metric = 6.52% * 100;
 Minibatch[ 801- 900]: loss = 0.339343 * 100, metric = 6.19% * 100;
 Minibatch[ 901-1000]: loss = 0.326376 * 100, metric = 5.74% * 100;
 Minibatch[1001-1100]: loss = 0.337082 * 100, metric = 6.18% * 100;
 Minibatch[1101-1200]: loss = 0.350963 * 100, metric = 6.64% * 100;
 Minibatch[1201-1300]: loss = 0.347025 * 100, metric = 6.40% * 100;
 Minibatch[1301-1400]: loss = 0.327646 * 100, metric = 5.88% * 100;
 Minibatch[1401-1500]: loss = 0.340313 * 100, metric = 6.31% * 100;
 Minibatch[1501-1600]: loss = 0.330157 * 100, metric = 6.10% * 100;
 Minibatch[1601-1700]: loss = 0.338430 * 100, metric = 6.29% * 100;
 Minibatch[1701-1800]: loss = 0.329533 * 100, metric = 5.88% * 100;
 Minibatch[1801-1900]: loss = 0.334229 * 100, metric = 5.99% * 100;
 Minibatch[1901-2000]: loss = 0.333394 * 100, metric = 6.08% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.335504 * 2000, metric = 6.14% * 2000 891.500s (  2.2 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.79% * 2000;
0.5577888681516051
 Minibatch[   1- 100]: loss = 0.334717 * 100, metric = 6.02% * 100;
 Minibatch[ 101- 200]: loss = 0.330304 * 100, metric = 6.03% * 100;
 Minibatch[ 201- 300]: loss = 0.317896 * 100, metric = 5.76% * 100;
 Minibatch[ 301- 400]: loss = 0.321355 * 100, metric = 5.83% * 100;
 Minibatch[ 401- 500]: loss = 0.332186 * 100, metric = 6.04% * 100;
 Minibatch[ 501- 600]: loss = 0.330461 * 100, metric = 5.97% * 100;
 Minibatch[ 601- 700]: loss = 0.330054 * 100, metric = 6.01% * 100;
 Minibatch[ 701- 800]: loss = 0.327279 * 100, metric = 5.95% * 100;
 Minibatch[ 801- 900]: loss = 0.339940 * 100, metric = 6.26% * 100;
 Minibatch[ 901-1000]: loss = 0.332672 * 100, metric = 5.92% * 100;
 Minibatch[1001-1100]: loss = 0.336685 * 100, metric = 6.24% * 100;
 Minibatch[1101-1200]: loss = 0.326852 * 100, metric = 5.88% * 100;
 Minibatch[1201-1300]: loss = 0.331494 * 100, metric = 6.24% * 100;
 Minibatch[1301-1400]: loss = 0.342740 * 100, metric = 6.19% * 100;
 Minibatch[1401-1500]: loss = 0.339285 * 100, metric = 6.20% * 100;
 Minibatch[1501-1600]: loss = 0.342903 * 100, metric = 6.37% * 100;
 Minibatch[1601-1700]: loss = 0.328392 * 100, metric = 6.00% * 100;
 Minibatch[1701-1800]: loss = 0.336238 * 100, metric = 6.49% * 100;
 Minibatch[1801-1900]: loss = 0.343386 * 100, metric = 6.32% * 100;
 Minibatch[1901-2000]: loss = 0.335610 * 100, metric = 6.35% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.333022 * 2000, metric = 6.10% * 2000 906.121s (  2.2 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 13.80% * 2000;
0.5570204076766968
 Minibatch[   1- 100]: loss = 0.325800 * 100, metric = 5.98% * 100;
 Minibatch[ 101- 200]: loss = 0.339462 * 100, metric = 6.13% * 100;
 Minibatch[ 201- 300]: loss = 0.328856 * 100, metric = 5.84% * 100;
 Minibatch[ 301- 400]: loss = 0.330310 * 100, metric = 6.02% * 100;
 Minibatch[ 401- 500]: loss = 0.322192 * 100, metric = 5.88% * 100;
 Minibatch[ 501- 600]: loss = 0.344127 * 100, metric = 6.27% * 100;
 Minibatch[ 601- 700]: loss = 0.333825 * 100, metric = 6.03% * 100;
 Minibatch[ 701- 800]: loss = 0.336232 * 100, metric = 6.11% * 100;
 Minibatch[ 801- 900]: loss = 0.322722 * 100, metric = 5.82% * 100;
 Minibatch[ 901-1000]: loss = 0.322346 * 100, metric = 5.75% * 100;
 Minibatch[1001-1100]: loss = 0.339098 * 100, metric = 6.28% * 100;
 Minibatch[1101-1200]: loss = 0.331834 * 100, metric = 6.14% * 100;
 Minibatch[1201-1300]: loss = 0.326459 * 100, metric = 5.91% * 100;
 Minibatch[1301-1400]: loss = 0.338683 * 100, metric = 6.26% * 100;
 Minibatch[1401-1500]: loss = 0.335435 * 100, metric = 6.21% * 100;
 Minibatch[1501-1600]: loss = 0.332185 * 100, metric = 5.95% * 100;
 Minibatch[1601-1700]: loss = 0.320472 * 100, metric = 5.77% * 100;
 Minibatch[1701-1800]: loss = 0.340461 * 100, metric = 6.27% * 100;
 Minibatch[1801-1900]: loss = 0.325215 * 100, metric = 5.89% * 100;
 Minibatch[1901-2000]: loss = 0.327246 * 100, metric = 5.95% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.331148 * 2000, metric = 6.02% * 2000 909.379s (  2.2 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 14.26% * 2000;
 Minibatch[   1- 100]: loss = 0.326206 * 100, metric = 6.02% * 100;
 Minibatch[ 101- 200]: loss = 0.320058 * 100, metric = 5.88% * 100;
 Minibatch[ 201- 300]: loss = 0.339584 * 100, metric = 6.08% * 100;
 Minibatch[ 301- 400]: loss = 0.337554 * 100, metric = 6.34% * 100;
 Minibatch[ 401- 500]: loss = 0.323752 * 100, metric = 5.86% * 100;
 Minibatch[ 501- 600]: loss = 0.326239 * 100, metric = 5.94% * 100;
 Minibatch[ 601- 700]: loss = 0.337120 * 100, metric = 6.27% * 100;
 Minibatch[ 701- 800]: loss = 0.325082 * 100, metric = 5.81% * 100;
 Minibatch[ 801- 900]: loss = 0.329696 * 100, metric = 6.04% * 100;
 Minibatch[ 901-1000]: loss = 0.328615 * 100, metric = 5.92% * 100;
 Minibatch[1001-1100]: loss = 0.340364 * 100, metric = 6.41% * 100;
 Minibatch[1101-1200]: loss = 0.331972 * 100, metric = 6.20% * 100;
 Minibatch[1201-1300]: loss = 0.328057 * 100, metric = 6.00% * 100;
 Minibatch[1301-1400]: loss = 0.327493 * 100, metric = 5.96% * 100;
 Minibatch[1401-1500]: loss = 0.324275 * 100, metric = 6.08% * 100;
 Minibatch[1501-1600]: loss = 0.335345 * 100, metric = 6.11% * 100;
 Minibatch[1601-1700]: loss = 0.330363 * 100, metric = 6.02% * 100;
 Minibatch[1701-1800]: loss = 0.317637 * 100, metric = 5.67% * 100;
 Minibatch[1801-1900]: loss = 0.320577 * 100, metric = 5.65% * 100;
 Minibatch[1901-2000]: loss = 0.333962 * 100, metric = 6.16% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.329197 * 2000, metric = 6.02% * 2000 905.031s (  2.2 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 14.56% * 2000;
 Minibatch[   1- 100]: loss = 0.324217 * 100, metric = 6.02% * 100;
 Minibatch[ 101- 200]: loss = 0.318160 * 100, metric = 5.75% * 100;
 Minibatch[ 201- 300]: loss = 0.333869 * 100, metric = 6.25% * 100;
 Minibatch[ 301- 400]: loss = 0.335305 * 100, metric = 6.16% * 100;
 Minibatch[ 401- 500]: loss = 0.326873 * 100, metric = 6.03% * 100;
 Minibatch[ 501- 600]: loss = 0.323571 * 100, metric = 5.70% * 100;
 Minibatch[ 601- 700]: loss = 0.329585 * 100, metric = 5.91% * 100;
 Minibatch[ 701- 800]: loss = 0.325280 * 100, metric = 5.83% * 100;
 Minibatch[ 801- 900]: loss = 0.318870 * 100, metric = 5.76% * 100;
 Minibatch[ 901-1000]: loss = 0.321544 * 100, metric = 5.87% * 100;
 Minibatch[1001-1100]: loss = 0.322913 * 100, metric = 5.84% * 100;
 Minibatch[1101-1200]: loss = 0.333162 * 100, metric = 6.15% * 100;
 Minibatch[1201-1300]: loss = 0.329531 * 100, metric = 6.08% * 100;
 Minibatch[1301-1400]: loss = 0.319657 * 100, metric = 5.97% * 100;
 Minibatch[1401-1500]: loss = 0.319310 * 100, metric = 5.84% * 100;
 Minibatch[1501-1600]: loss = 0.323791 * 100, metric = 5.79% * 100;
 Minibatch[1601-1700]: loss = 0.327449 * 100, metric = 6.15% * 100;
 Minibatch[1701-1800]: loss = 0.329899 * 100, metric = 6.13% * 100;
 Minibatch[1801-1900]: loss = 0.324792 * 100, metric = 6.07% * 100;
 Minibatch[1901-2000]: loss = 0.322117 * 100, metric = 5.80% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.325495 * 2000, metric = 5.96% * 2000 909.585s (  2.2 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 14.36% * 2000;
 Minibatch[   1- 100]: loss = 0.317608 * 100, metric = 5.68% * 100;
 Minibatch[ 101- 200]: loss = 0.315896 * 100, metric = 5.90% * 100;
 Minibatch[ 201- 300]: loss = 0.323745 * 100, metric = 5.88% * 100;
 Minibatch[ 301- 400]: loss = 0.317689 * 100, metric = 5.73% * 100;
 Minibatch[ 401- 500]: loss = 0.325550 * 100, metric = 5.92% * 100;
 Minibatch[ 501- 600]: loss = 0.325443 * 100, metric = 5.85% * 100;
 Minibatch[ 601- 700]: loss = 0.326746 * 100, metric = 5.84% * 100;
 Minibatch[ 701- 800]: loss = 0.314037 * 100, metric = 5.77% * 100;
 Minibatch[ 801- 900]: loss = 0.318367 * 100, metric = 5.68% * 100;
 Minibatch[ 901-1000]: loss = 0.331020 * 100, metric = 6.21% * 100;
 Minibatch[1001-1100]: loss = 0.328373 * 100, metric = 6.09% * 100;
 Minibatch[1101-1200]: loss = 0.317331 * 100, metric = 5.78% * 100;
 Minibatch[1201-1300]: loss = 0.324449 * 100, metric = 5.83% * 100;
 Minibatch[1301-1400]: loss = 0.323804 * 100, metric = 5.92% * 100;
 Minibatch[1401-1500]: loss = 0.316366 * 100, metric = 5.78% * 100;
 Minibatch[1501-1600]: loss = 0.319689 * 100, metric = 5.80% * 100;
 Minibatch[1601-1700]: loss = 0.321416 * 100, metric = 5.71% * 100;
 Minibatch[1701-1800]: loss = 0.325475 * 100, metric = 5.82% * 100;
 Minibatch[1801-1900]: loss = 0.326753 * 100, metric = 6.03% * 100;
 Minibatch[1901-2000]: loss = 0.320099 * 100, metric = 5.92% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.321993 * 2000, metric = 5.86% * 2000 906.820s (  2.2 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 13.69% * 2000;
 Minibatch[   1- 100]: loss = 0.334423 * 100, metric = 6.29% * 100;
 Minibatch[ 101- 200]: loss = 0.312853 * 100, metric = 5.62% * 100;
 Minibatch[ 201- 300]: loss = 0.330249 * 100, metric = 6.15% * 100;
 Minibatch[ 301- 400]: loss = 0.322731 * 100, metric = 6.02% * 100;
 Minibatch[ 401- 500]: loss = 0.320840 * 100, metric = 5.76% * 100;
 Minibatch[ 501- 600]: loss = 0.313639 * 100, metric = 5.68% * 100;
 Minibatch[ 601- 700]: loss = 0.332689 * 100, metric = 6.14% * 100;
 Minibatch[ 701- 800]: loss = 0.318616 * 100, metric = 5.92% * 100;
 Minibatch[ 801- 900]: loss = 0.314342 * 100, metric = 5.78% * 100;
 Minibatch[ 901-1000]: loss = 0.323502 * 100, metric = 6.07% * 100;
 Minibatch[1001-1100]: loss = 0.321308 * 100, metric = 5.91% * 100;
 Minibatch[1101-1200]: loss = 0.325298 * 100, metric = 6.08% * 100;
 Minibatch[1201-1300]: loss = 0.323026 * 100, metric = 6.12% * 100;
 Minibatch[1301-1400]: loss = 0.322180 * 100, metric = 5.91% * 100;
 Minibatch[1401-1500]: loss = 0.302637 * 100, metric = 5.44% * 100;
 Minibatch[1501-1600]: loss = 0.330109 * 100, metric = 6.00% * 100;
 Minibatch[1601-1700]: loss = 0.316915 * 100, metric = 5.71% * 100;
 Minibatch[1701-1800]: loss = 0.313201 * 100, metric = 5.87% * 100;
 Minibatch[1801-1900]: loss = 0.322473 * 100, metric = 6.03% * 100;
 Minibatch[1901-2000]: loss = 0.314189 * 100, metric = 5.71% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.320761 * 2000, metric = 5.91% * 2000 904.035s (  2.2 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 14.12% * 2000;
 Minibatch[   1- 100]: loss = 0.312022 * 100, metric = 5.72% * 100;
 Minibatch[ 101- 200]: loss = 0.316622 * 100, metric = 5.71% * 100;
 Minibatch[ 201- 300]: loss = 0.313967 * 100, metric = 5.66% * 100;
 Minibatch[ 301- 400]: loss = 0.320594 * 100, metric = 5.86% * 100;
 Minibatch[ 401- 500]: loss = 0.314312 * 100, metric = 5.56% * 100;
 Minibatch[ 501- 600]: loss = 0.309100 * 100, metric = 5.54% * 100;
 Minibatch[ 601- 700]: loss = 0.321966 * 100, metric = 5.81% * 100;
 Minibatch[ 701- 800]: loss = 0.298150 * 100, metric = 5.16% * 100;
 Minibatch[ 801- 900]: loss = 0.304545 * 100, metric = 5.29% * 100;
 Minibatch[ 901-1000]: loss = 0.310525 * 100, metric = 5.53% * 100;
 Minibatch[1001-1100]: loss = 0.315721 * 100, metric = 5.53% * 100;
 Minibatch[1101-1200]: loss = 0.299534 * 100, metric = 4.99% * 100;
 Minibatch[1201-1300]: loss = 0.312984 * 100, metric = 5.69% * 100;
 Minibatch[1301-1400]: loss = 0.308938 * 100, metric = 5.42% * 100;
 Minibatch[1401-1500]: loss = 0.297871 * 100, metric = 5.05% * 100;
 Minibatch[1501-1600]: loss = 0.302069 * 100, metric = 5.45% * 100;
 Minibatch[1601-1700]: loss = 0.310120 * 100, metric = 5.41% * 100;
 Minibatch[1701-1800]: loss = 0.323710 * 100, metric = 6.01% * 100;
 Minibatch[1801-1900]: loss = 0.311937 * 100, metric = 5.47% * 100;
 Minibatch[1901-2000]: loss = 0.304178 * 100, metric = 5.26% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.310443 * 2000, metric = 5.51% * 2000 901.588s (  2.2 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 15.17% * 2000;
 Minibatch[   1- 100]: loss = 0.314623 * 100, metric = 5.48% * 100;
 Minibatch[ 101- 200]: loss = 0.309685 * 100, metric = 5.28% * 100;
 Minibatch[ 201- 300]: loss = 0.306800 * 100, metric = 5.40% * 100;
 Minibatch[ 301- 400]: loss = 0.310751 * 100, metric = 5.66% * 100;
 Minibatch[ 401- 500]: loss = 0.303537 * 100, metric = 5.49% * 100;
 Minibatch[ 501- 600]: loss = 0.298783 * 100, metric = 5.14% * 100;
 Minibatch[ 601- 700]: loss = 0.299415 * 100, metric = 5.31% * 100;
 Minibatch[ 701- 800]: loss = 0.296746 * 100, metric = 5.43% * 100;
 Minibatch[ 801- 900]: loss = 0.327186 * 100, metric = 6.05% * 100;
 Minibatch[ 901-1000]: loss = 0.305240 * 100, metric = 5.46% * 100;
 Minibatch[1001-1100]: loss = 0.298887 * 100, metric = 5.33% * 100;
 Minibatch[1101-1200]: loss = 0.313932 * 100, metric = 5.57% * 100;
 Minibatch[1201-1300]: loss = 0.303917 * 100, metric = 5.48% * 100;
 Minibatch[1301-1400]: loss = 0.300628 * 100, metric = 5.57% * 100;
 Minibatch[1401-1500]: loss = 0.308667 * 100, metric = 5.47% * 100;
 Minibatch[1501-1600]: loss = 0.300528 * 100, metric = 5.52% * 100;
 Minibatch[1601-1700]: loss = 0.299478 * 100, metric = 5.49% * 100;
 Minibatch[1701-1800]: loss = 0.311230 * 100, metric = 5.64% * 100;
 Minibatch[1801-1900]: loss = 0.308069 * 100, metric = 5.64% * 100;
 Minibatch[1901-2000]: loss = 0.298660 * 100, metric = 5.21% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.305838 * 2000, metric = 5.48% * 2000 903.539s (  2.2 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 14.17% * 2000;
 Minibatch[   1- 100]: loss = 0.299065 * 100, metric = 5.42% * 100;
 Minibatch[ 101- 200]: loss = 0.312573 * 100, metric = 5.73% * 100;
 Minibatch[ 201- 300]: loss = 0.300482 * 100, metric = 5.30% * 100;
 Minibatch[ 301- 400]: loss = 0.322136 * 100, metric = 5.95% * 100;
 Minibatch[ 401- 500]: loss = 0.305732 * 100, metric = 5.37% * 100;
 Minibatch[ 501- 600]: loss = 0.302945 * 100, metric = 5.41% * 100;
 Minibatch[ 601- 700]: loss = 0.293297 * 100, metric = 5.20% * 100;
 Minibatch[ 701- 800]: loss = 0.293018 * 100, metric = 5.11% * 100;
 Minibatch[ 801- 900]: loss = 0.296091 * 100, metric = 5.22% * 100;
 Minibatch[ 901-1000]: loss = 0.300145 * 100, metric = 5.26% * 100;
 Minibatch[1001-1100]: loss = 0.299416 * 100, metric = 5.37% * 100;
 Minibatch[1101-1200]: loss = 0.310847 * 100, metric = 5.62% * 100;
 Minibatch[1201-1300]: loss = 0.303326 * 100, metric = 5.37% * 100;
 Minibatch[1301-1400]: loss = 0.305146 * 100, metric = 5.47% * 100;
 Minibatch[1401-1500]: loss = 0.299506 * 100, metric = 5.41% * 100;
 Minibatch[1501-1600]: loss = 0.300371 * 100, metric = 5.45% * 100;
 Minibatch[1601-1700]: loss = 0.294054 * 100, metric = 5.26% * 100;
 Minibatch[1701-1800]: loss = 0.310724 * 100, metric = 5.64% * 100;
 Minibatch[1801-1900]: loss = 0.293608 * 100, metric = 5.00% * 100;
 Minibatch[1901-2000]: loss = 0.301490 * 100, metric = 5.31% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.302199 * 2000, metric = 5.39% * 2000 901.916s (  2.2 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 13.68% * 2000;
 Minibatch[   1- 100]: loss = 0.305493 * 100, metric = 5.23% * 100;
 Minibatch[ 101- 200]: loss = 0.295953 * 100, metric = 5.26% * 100;
 Minibatch[ 201- 300]: loss = 0.302218 * 100, metric = 5.61% * 100;
 Minibatch[ 301- 400]: loss = 0.291466 * 100, metric = 5.06% * 100;
 Minibatch[ 401- 500]: loss = 0.295254 * 100, metric = 5.38% * 100;
 Minibatch[ 501- 600]: loss = 0.299342 * 100, metric = 5.43% * 100;
 Minibatch[ 601- 700]: loss = 0.308777 * 100, metric = 5.62% * 100;
 Minibatch[ 701- 800]: loss = 0.314354 * 100, metric = 5.90% * 100;
 Minibatch[ 801- 900]: loss = 0.302439 * 100, metric = 5.37% * 100;
 Minibatch[ 901-1000]: loss = 0.303367 * 100, metric = 5.52% * 100;
 Minibatch[1001-1100]: loss = 0.314161 * 100, metric = 5.83% * 100;
 Minibatch[1101-1200]: loss = 0.309422 * 100, metric = 5.48% * 100;
 Minibatch[1201-1300]: loss = 0.285706 * 100, metric = 5.07% * 100;
 Minibatch[1301-1400]: loss = 0.297485 * 100, metric = 5.28% * 100;
 Minibatch[1401-1500]: loss = 0.311297 * 100, metric = 5.46% * 100;
 Minibatch[1501-1600]: loss = 0.304796 * 100, metric = 5.38% * 100;
 Minibatch[1601-1700]: loss = 0.297951 * 100, metric = 5.30% * 100;
 Minibatch[1701-1800]: loss = 0.305547 * 100, metric = 5.57% * 100;
 Minibatch[1801-1900]: loss = 0.299479 * 100, metric = 5.58% * 100;
 Minibatch[1901-2000]: loss = 0.306574 * 100, metric = 5.55% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.302554 * 2000, metric = 5.44% * 2000 901.289s (  2.2 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 13.12% * 2000;
0.5486916827149689
 Minibatch[   1- 100]: loss = 0.302295 * 100, metric = 5.51% * 100;
 Minibatch[ 101- 200]: loss = 0.305168 * 100, metric = 5.42% * 100;
 Minibatch[ 201- 300]: loss = 0.299571 * 100, metric = 5.39% * 100;
 Minibatch[ 301- 400]: loss = 0.292265 * 100, metric = 5.30% * 100;
 Minibatch[ 401- 500]: loss = 0.306592 * 100, metric = 5.61% * 100;
 Minibatch[ 501- 600]: loss = 0.312513 * 100, metric = 5.66% * 100;
 Minibatch[ 601- 700]: loss = 0.317145 * 100, metric = 5.56% * 100;
 Minibatch[ 701- 800]: loss = 0.299176 * 100, metric = 5.23% * 100;
 Minibatch[ 801- 900]: loss = 0.297748 * 100, metric = 5.25% * 100;
 Minibatch[ 901-1000]: loss = 0.303121 * 100, metric = 5.71% * 100;
 Minibatch[1001-1100]: loss = 0.301081 * 100, metric = 5.49% * 100;
 Minibatch[1101-1200]: loss = 0.296310 * 100, metric = 5.25% * 100;
 Minibatch[1201-1300]: loss = 0.293623 * 100, metric = 5.30% * 100;
 Minibatch[1301-1400]: loss = 0.292588 * 100, metric = 5.28% * 100;
 Minibatch[1401-1500]: loss = 0.295977 * 100, metric = 5.27% * 100;
 Minibatch[1501-1600]: loss = 0.295225 * 100, metric = 5.46% * 100;
 Minibatch[1601-1700]: loss = 0.297379 * 100, metric = 5.38% * 100;
 Minibatch[1701-1800]: loss = 0.296747 * 100, metric = 5.07% * 100;
 Minibatch[1801-1900]: loss = 0.303990 * 100, metric = 5.48% * 100;
 Minibatch[1901-2000]: loss = 0.284747 * 100, metric = 4.90% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.299663 * 2000, metric = 5.38% * 2000 914.015s (  2.2 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 13.44% * 2000;
 Minibatch[   1- 100]: loss = 0.307503 * 100, metric = 5.38% * 100;
 Minibatch[ 101- 200]: loss = 0.298348 * 100, metric = 5.27% * 100;
 Minibatch[ 201- 300]: loss = 0.302552 * 100, metric = 5.46% * 100;
 Minibatch[ 301- 400]: loss = 0.300820 * 100, metric = 5.48% * 100;
 Minibatch[ 401- 500]: loss = 0.308286 * 100, metric = 5.45% * 100;
 Minibatch[ 501- 600]: loss = 0.292651 * 100, metric = 5.26% * 100;
 Minibatch[ 601- 700]: loss = 0.297407 * 100, metric = 5.30% * 100;
 Minibatch[ 701- 800]: loss = 0.295293 * 100, metric = 5.38% * 100;
 Minibatch[ 801- 900]: loss = 0.291308 * 100, metric = 5.10% * 100;
 Minibatch[ 901-1000]: loss = 0.310591 * 100, metric = 5.72% * 100;
 Minibatch[1001-1100]: loss = 0.297777 * 100, metric = 5.26% * 100;
 Minibatch[1101-1200]: loss = 0.297190 * 100, metric = 5.35% * 100;
 Minibatch[1201-1300]: loss = 0.284273 * 100, metric = 5.04% * 100;
 Minibatch[1301-1400]: loss = 0.302454 * 100, metric = 5.41% * 100;
 Minibatch[1401-1500]: loss = 0.295757 * 100, metric = 5.41% * 100;
 Minibatch[1501-1600]: loss = 0.280724 * 100, metric = 4.89% * 100;
 Minibatch[1601-1700]: loss = 0.313667 * 100, metric = 5.94% * 100;
 Minibatch[1701-1800]: loss = 0.297231 * 100, metric = 5.26% * 100;
 Minibatch[1801-1900]: loss = 0.297401 * 100, metric = 5.40% * 100;
 Minibatch[1901-2000]: loss = 0.296822 * 100, metric = 5.31% * 100;
Finished Epoch[49 of 200]: [Training] loss = 0.298403 * 2000, metric = 5.35% * 2000 906.932s (  2.2 samples/s);
Finished Evaluation [49]: Minibatch[1-2000]: metric = 13.04% * 2000;
 Minibatch[   1- 100]: loss = 0.307061 * 100, metric = 5.64% * 100;
 Minibatch[ 101- 200]: loss = 0.291121 * 100, metric = 5.03% * 100;
 Minibatch[ 201- 300]: loss = 0.288051 * 100, metric = 5.10% * 100;
 Minibatch[ 301- 400]: loss = 0.297721 * 100, metric = 5.21% * 100;
 Minibatch[ 401- 500]: loss = 0.297671 * 100, metric = 5.36% * 100;
 Minibatch[ 501- 600]: loss = 0.309225 * 100, metric = 5.53% * 100;
 Minibatch[ 601- 700]: loss = 0.289157 * 100, metric = 5.26% * 100;
 Minibatch[ 701- 800]: loss = 0.293016 * 100, metric = 5.26% * 100;
 Minibatch[ 801- 900]: loss = 0.300356 * 100, metric = 5.40% * 100;
 Minibatch[ 901-1000]: loss = 0.293610 * 100, metric = 5.14% * 100;
 Minibatch[1001-1100]: loss = 0.289180 * 100, metric = 5.20% * 100;
 Minibatch[1101-1200]: loss = 0.292076 * 100, metric = 5.34% * 100;
 Minibatch[1201-1300]: loss = 0.297754 * 100, metric = 5.55% * 100;
 Minibatch[1301-1400]: loss = 0.282576 * 100, metric = 5.18% * 100;
 Minibatch[1401-1500]: loss = 0.292352 * 100, metric = 5.40% * 100;
 Minibatch[1501-1600]: loss = 0.285672 * 100, metric = 4.95% * 100;
 Minibatch[1601-1700]: loss = 0.287365 * 100, metric = 5.02% * 100;
 Minibatch[1701-1800]: loss = 0.297980 * 100, metric = 5.38% * 100;
 Minibatch[1801-1900]: loss = 0.301453 * 100, metric = 5.21% * 100;
 Minibatch[1901-2000]: loss = 0.291775 * 100, metric = 5.28% * 100;
Finished Epoch[50 of 200]: [Training] loss = 0.294259 * 2000, metric = 5.27% * 2000 899.241s (  2.2 samples/s);
Finished Evaluation [50]: Minibatch[1-2000]: metric = 14.16% * 2000;
 Minibatch[   1- 100]: loss = 0.281122 * 100, metric = 4.90% * 100;
 Minibatch[ 101- 200]: loss = 0.298880 * 100, metric = 5.46% * 100;
 Minibatch[ 201- 300]: loss = 0.300067 * 100, metric = 5.28% * 100;
 Minibatch[ 301- 400]: loss = 0.288370 * 100, metric = 5.07% * 100;
 Minibatch[ 401- 500]: loss = 0.290942 * 100, metric = 5.27% * 100;
 Minibatch[ 501- 600]: loss = 0.296485 * 100, metric = 5.41% * 100;
 Minibatch[ 601- 700]: loss = 0.283906 * 100, metric = 5.10% * 100;
 Minibatch[ 701- 800]: loss = 0.290652 * 100, metric = 5.18% * 100;
 Minibatch[ 801- 900]: loss = 0.294340 * 100, metric = 5.18% * 100;
 Minibatch[ 901-1000]: loss = 0.287987 * 100, metric = 5.13% * 100;
 Minibatch[1001-1100]: loss = 0.296158 * 100, metric = 5.19% * 100;
 Minibatch[1101-1200]: loss = 0.293771 * 100, metric = 5.36% * 100;
 Minibatch[1201-1300]: loss = 0.301541 * 100, metric = 5.30% * 100;
 Minibatch[1301-1400]: loss = 0.291936 * 100, metric = 5.09% * 100;
 Minibatch[1401-1500]: loss = 0.290042 * 100, metric = 5.15% * 100;
 Minibatch[1501-1600]: loss = 0.302159 * 100, metric = 5.31% * 100;
 Minibatch[1601-1700]: loss = 0.283127 * 100, metric = 5.01% * 100;
 Minibatch[1701-1800]: loss = 0.298237 * 100, metric = 5.55% * 100;
 Minibatch[1801-1900]: loss = 0.277603 * 100, metric = 5.00% * 100;
 Minibatch[1901-2000]: loss = 0.287782 * 100, metric = 5.09% * 100;
Finished Epoch[51 of 200]: [Training] loss = 0.291755 * 2000, metric = 5.20% * 2000 899.613s (  2.2 samples/s);
Finished Evaluation [51]: Minibatch[1-2000]: metric = 12.81% * 2000;
 Minibatch[   1- 100]: loss = 0.285191 * 100, metric = 5.21% * 100;
 Minibatch[ 101- 200]: loss = 0.287412 * 100, metric = 5.17% * 100;
 Minibatch[ 201- 300]: loss = 0.296700 * 100, metric = 5.42% * 100;
 Minibatch[ 301- 400]: loss = 0.283947 * 100, metric = 5.11% * 100;
 Minibatch[ 401- 500]: loss = 0.292758 * 100, metric = 5.15% * 100;
 Minibatch[ 501- 600]: loss = 0.292011 * 100, metric = 5.38% * 100;
 Minibatch[ 601- 700]: loss = 0.291477 * 100, metric = 4.98% * 100;
 Minibatch[ 701- 800]: loss = 0.292781 * 100, metric = 5.27% * 100;
 Minibatch[ 801- 900]: loss = 0.294923 * 100, metric = 5.34% * 100;
 Minibatch[ 901-1000]: loss = 0.301375 * 100, metric = 5.58% * 100;
 Minibatch[1001-1100]: loss = 0.288828 * 100, metric = 5.13% * 100;
 Minibatch[1101-1200]: loss = 0.276523 * 100, metric = 4.57% * 100;
 Minibatch[1201-1300]: loss = 0.280327 * 100, metric = 4.87% * 100;
 Minibatch[1301-1400]: loss = 0.295602 * 100, metric = 5.10% * 100;
 Minibatch[1401-1500]: loss = 0.280790 * 100, metric = 4.90% * 100;
 Minibatch[1501-1600]: loss = 0.275043 * 100, metric = 4.84% * 100;
 Minibatch[1601-1700]: loss = 0.293981 * 100, metric = 5.33% * 100;
 Minibatch[1701-1800]: loss = 0.279460 * 100, metric = 4.99% * 100;
 Minibatch[1801-1900]: loss = 0.276802 * 100, metric = 4.82% * 100;
 Minibatch[1901-2000]: loss = 0.291446 * 100, metric = 5.14% * 100;
Finished Epoch[52 of 200]: [Training] loss = 0.287869 * 2000, metric = 5.11% * 2000 887.614s (  2.3 samples/s);
Finished Evaluation [52]: Minibatch[1-2000]: metric = 14.16% * 2000;
 Minibatch[   1- 100]: loss = 0.282752 * 100, metric = 5.04% * 100;
 Minibatch[ 101- 200]: loss = 0.275452 * 100, metric = 4.73% * 100;
 Minibatch[ 201- 300]: loss = 0.282226 * 100, metric = 5.00% * 100;
 Minibatch[ 301- 400]: loss = 0.289933 * 100, metric = 5.25% * 100;
 Minibatch[ 401- 500]: loss = 0.285606 * 100, metric = 5.08% * 100;
 Minibatch[ 501- 600]: loss = 0.287794 * 100, metric = 5.07% * 100;
 Minibatch[ 601- 700]: loss = 0.280152 * 100, metric = 4.86% * 100;
 Minibatch[ 701- 800]: loss = 0.285435 * 100, metric = 4.90% * 100;
 Minibatch[ 801- 900]: loss = 0.284955 * 100, metric = 5.09% * 100;
 Minibatch[ 901-1000]: loss = 0.280846 * 100, metric = 4.94% * 100;
 Minibatch[1001-1100]: loss = 0.284231 * 100, metric = 5.05% * 100;
 Minibatch[1101-1200]: loss = 0.275534 * 100, metric = 5.01% * 100;
 Minibatch[1201-1300]: loss = 0.272915 * 100, metric = 4.77% * 100;
 Minibatch[1301-1400]: loss = 0.280633 * 100, metric = 4.73% * 100;
 Minibatch[1401-1500]: loss = 0.280849 * 100, metric = 4.97% * 100;
 Minibatch[1501-1600]: loss = 0.289849 * 100, metric = 5.27% * 100;
 Minibatch[1601-1700]: loss = 0.285894 * 100, metric = 4.97% * 100;
 Minibatch[1701-1800]: loss = 0.289522 * 100, metric = 5.22% * 100;
 Minibatch[1801-1900]: loss = 0.297101 * 100, metric = 5.39% * 100;
 Minibatch[1901-2000]: loss = 0.273887 * 100, metric = 4.87% * 100;
Finished Epoch[53 of 200]: [Training] loss = 0.283278 * 2000, metric = 5.01% * 2000 895.938s (  2.2 samples/s);
Finished Evaluation [53]: Minibatch[1-2000]: metric = 13.58% * 2000;
 Minibatch[   1- 100]: loss = 0.284403 * 100, metric = 4.90% * 100;
 Minibatch[ 101- 200]: loss = 0.291834 * 100, metric = 5.31% * 100;
 Minibatch[ 201- 300]: loss = 0.282567 * 100, metric = 4.96% * 100;
 Minibatch[ 301- 400]: loss = 0.279628 * 100, metric = 4.68% * 100;
 Minibatch[ 401- 500]: loss = 0.283140 * 100, metric = 5.09% * 100;
 Minibatch[ 501- 600]: loss = 0.275724 * 100, metric = 4.81% * 100;
 Minibatch[ 601- 700]: loss = 0.286979 * 100, metric = 4.99% * 100;
 Minibatch[ 701- 800]: loss = 0.285493 * 100, metric = 4.96% * 100;
 Minibatch[ 801- 900]: loss = 0.262478 * 100, metric = 4.56% * 100;
 Minibatch[ 901-1000]: loss = 0.288690 * 100, metric = 5.08% * 100;
 Minibatch[1001-1100]: loss = 0.272926 * 100, metric = 4.75% * 100;
 Minibatch[1101-1200]: loss = 0.272366 * 100, metric = 4.81% * 100;
 Minibatch[1201-1300]: loss = 0.281616 * 100, metric = 4.89% * 100;
 Minibatch[1301-1400]: loss = 0.275808 * 100, metric = 4.94% * 100;
 Minibatch[1401-1500]: loss = 0.290017 * 100, metric = 5.11% * 100;
 Minibatch[1501-1600]: loss = 0.291063 * 100, metric = 5.25% * 100;
 Minibatch[1601-1700]: loss = 0.280068 * 100, metric = 4.98% * 100;
 Minibatch[1701-1800]: loss = 0.285222 * 100, metric = 5.13% * 100;
 Minibatch[1801-1900]: loss = 0.289127 * 100, metric = 5.11% * 100;
 Minibatch[1901-2000]: loss = 0.292576 * 100, metric = 5.22% * 100;
Finished Epoch[54 of 200]: [Training] loss = 0.282586 * 2000, metric = 4.98% * 2000 896.922s (  2.2 samples/s);
Finished Evaluation [54]: Minibatch[1-2000]: metric = 12.80% * 2000;
 Minibatch[   1- 100]: loss = 0.295663 * 100, metric = 5.25% * 100;
 Minibatch[ 101- 200]: loss = 0.285752 * 100, metric = 4.98% * 100;
 Minibatch[ 201- 300]: loss = 0.288341 * 100, metric = 5.16% * 100;
 Minibatch[ 301- 400]: loss = 0.273319 * 100, metric = 4.75% * 100;
 Minibatch[ 401- 500]: loss = 0.283026 * 100, metric = 5.01% * 100;
 Minibatch[ 501- 600]: loss = 0.288098 * 100, metric = 5.05% * 100;
 Minibatch[ 601- 700]: loss = 0.289288 * 100, metric = 5.22% * 100;
 Minibatch[ 701- 800]: loss = 0.298245 * 100, metric = 5.48% * 100;
 Minibatch[ 801- 900]: loss = 0.284583 * 100, metric = 5.19% * 100;
 Minibatch[ 901-1000]: loss = 0.281253 * 100, metric = 5.09% * 100;
 Minibatch[1001-1100]: loss = 0.283308 * 100, metric = 5.06% * 100;
 Minibatch[1101-1200]: loss = 0.283259 * 100, metric = 5.06% * 100;
 Minibatch[1201-1300]: loss = 0.282849 * 100, metric = 5.05% * 100;
 Minibatch[1301-1400]: loss = 0.274041 * 100, metric = 4.64% * 100;
 Minibatch[1401-1500]: loss = 0.279694 * 100, metric = 4.82% * 100;
 Minibatch[1501-1600]: loss = 0.287606 * 100, metric = 5.17% * 100;
 Minibatch[1601-1700]: loss = 0.284225 * 100, metric = 5.16% * 100;
 Minibatch[1701-1800]: loss = 0.288333 * 100, metric = 5.18% * 100;
 Minibatch[1801-1900]: loss = 0.268030 * 100, metric = 4.62% * 100;
 Minibatch[1901-2000]: loss = 0.280060 * 100, metric = 4.90% * 100;
Finished Epoch[55 of 200]: [Training] loss = 0.283949 * 2000, metric = 5.04% * 2000 899.932s (  2.2 samples/s);
Finished Evaluation [55]: Minibatch[1-2000]: metric = 12.84% * 2000;
 Minibatch[   1- 100]: loss = 0.289712 * 100, metric = 5.39% * 100;
 Minibatch[ 101- 200]: loss = 0.278058 * 100, metric = 4.67% * 100;
 Minibatch[ 201- 300]: loss = 0.289593 * 100, metric = 5.21% * 100;
 Minibatch[ 301- 400]: loss = 0.286447 * 100, metric = 5.05% * 100;
 Minibatch[ 401- 500]: loss = 0.289907 * 100, metric = 5.41% * 100;
 Minibatch[ 501- 600]: loss = 0.291818 * 100, metric = 5.14% * 100;
 Minibatch[ 601- 700]: loss = 0.281575 * 100, metric = 4.96% * 100;
 Minibatch[ 701- 800]: loss = 0.277419 * 100, metric = 4.90% * 100;
 Minibatch[ 801- 900]: loss = 0.277545 * 100, metric = 4.93% * 100;
 Minibatch[ 901-1000]: loss = 0.286971 * 100, metric = 5.20% * 100;
 Minibatch[1001-1100]: loss = 0.290030 * 100, metric = 5.23% * 100;
 Minibatch[1101-1200]: loss = 0.287712 * 100, metric = 5.14% * 100;
 Minibatch[1201-1300]: loss = 0.281082 * 100, metric = 4.89% * 100;
 Minibatch[1301-1400]: loss = 0.272991 * 100, metric = 4.77% * 100;
 Minibatch[1401-1500]: loss = 0.281812 * 100, metric = 5.00% * 100;
 Minibatch[1501-1600]: loss = 0.274467 * 100, metric = 4.81% * 100;
 Minibatch[1601-1700]: loss = 0.276458 * 100, metric = 4.73% * 100;
 Minibatch[1701-1800]: loss = 0.273650 * 100, metric = 4.86% * 100;
 Minibatch[1801-1900]: loss = 0.270281 * 100, metric = 4.75% * 100;
 Minibatch[1901-2000]: loss = 0.290547 * 100, metric = 5.32% * 100;
Finished Epoch[56 of 200]: [Training] loss = 0.282404 * 2000, metric = 5.02% * 2000 896.868s (  2.2 samples/s);
Finished Evaluation [56]: Minibatch[1-2000]: metric = 12.93% * 2000;
 Minibatch[   1- 100]: loss = 0.281574 * 100, metric = 4.98% * 100;
 Minibatch[ 101- 200]: loss = 0.277651 * 100, metric = 5.02% * 100;
 Minibatch[ 201- 300]: loss = 0.273946 * 100, metric = 4.78% * 100;
 Minibatch[ 301- 400]: loss = 0.276442 * 100, metric = 4.75% * 100;
 Minibatch[ 401- 500]: loss = 0.274182 * 100, metric = 4.80% * 100;
 Minibatch[ 501- 600]: loss = 0.270422 * 100, metric = 4.63% * 100;
 Minibatch[ 601- 700]: loss = 0.277751 * 100, metric = 4.92% * 100;
 Minibatch[ 701- 800]: loss = 0.274605 * 100, metric = 4.93% * 100;
 Minibatch[ 801- 900]: loss = 0.284467 * 100, metric = 5.09% * 100;
 Minibatch[ 901-1000]: loss = 0.275399 * 100, metric = 4.92% * 100;
 Minibatch[1001-1100]: loss = 0.288413 * 100, metric = 5.18% * 100;
 Minibatch[1101-1200]: loss = 0.280981 * 100, metric = 5.04% * 100;
 Minibatch[1201-1300]: loss = 0.281099 * 100, metric = 5.06% * 100;
 Minibatch[1301-1400]: loss = 0.272249 * 100, metric = 4.77% * 100;
 Minibatch[1401-1500]: loss = 0.286069 * 100, metric = 5.12% * 100;
 Minibatch[1501-1600]: loss = 0.273206 * 100, metric = 4.80% * 100;
 Minibatch[1601-1700]: loss = 0.279201 * 100, metric = 5.01% * 100;
 Minibatch[1701-1800]: loss = 0.278744 * 100, metric = 5.01% * 100;
 Minibatch[1801-1900]: loss = 0.282312 * 100, metric = 4.97% * 100;
 Minibatch[1901-2000]: loss = 0.282708 * 100, metric = 5.00% * 100;
Finished Epoch[57 of 200]: [Training] loss = 0.278571 * 2000, metric = 4.94% * 2000 893.255s (  2.2 samples/s);
Finished Evaluation [57]: Minibatch[1-2000]: metric = 12.72% * 2000;
 Minibatch[   1- 100]: loss = 0.274952 * 100, metric = 4.64% * 100;
 Minibatch[ 101- 200]: loss = 0.275499 * 100, metric = 4.89% * 100;
 Minibatch[ 201- 300]: loss = 0.276363 * 100, metric = 5.00% * 100;
 Minibatch[ 301- 400]: loss = 0.282762 * 100, metric = 4.96% * 100;
 Minibatch[ 401- 500]: loss = 0.294055 * 100, metric = 5.36% * 100;
 Minibatch[ 501- 600]: loss = 0.275032 * 100, metric = 4.70% * 100;
 Minibatch[ 601- 700]: loss = 0.279947 * 100, metric = 4.85% * 100;
 Minibatch[ 701- 800]: loss = 0.281668 * 100, metric = 5.12% * 100;
 Minibatch[ 801- 900]: loss = 0.276024 * 100, metric = 4.81% * 100;
 Minibatch[ 901-1000]: loss = 0.276991 * 100, metric = 4.99% * 100;
 Minibatch[1001-1100]: loss = 0.279296 * 100, metric = 5.10% * 100;
 Minibatch[1101-1200]: loss = 0.284529 * 100, metric = 4.99% * 100;
 Minibatch[1201-1300]: loss = 0.275549 * 100, metric = 4.98% * 100;
 Minibatch[1301-1400]: loss = 0.278423 * 100, metric = 5.07% * 100;
 Minibatch[1401-1500]: loss = 0.269292 * 100, metric = 4.68% * 100;
 Minibatch[1501-1600]: loss = 0.280657 * 100, metric = 4.97% * 100;
 Minibatch[1601-1700]: loss = 0.283764 * 100, metric = 4.90% * 100;
 Minibatch[1701-1800]: loss = 0.274639 * 100, metric = 4.93% * 100;
 Minibatch[1801-1900]: loss = 0.272924 * 100, metric = 4.84% * 100;
 Minibatch[1901-2000]: loss = 0.262634 * 100, metric = 4.45% * 100;
Finished Epoch[58 of 200]: [Training] loss = 0.277750 * 2000, metric = 4.91% * 2000 892.493s (  2.2 samples/s);
Finished Evaluation [58]: Minibatch[1-2000]: metric = 12.86% * 2000;
 Minibatch[   1- 100]: loss = 0.283793 * 100, metric = 5.20% * 100;
 Minibatch[ 101- 200]: loss = 0.287170 * 100, metric = 5.36% * 100;
 Minibatch[ 201- 300]: loss = 0.271417 * 100, metric = 4.68% * 100;
 Minibatch[ 301- 400]: loss = 0.268117 * 100, metric = 4.56% * 100;
 Minibatch[ 401- 500]: loss = 0.272286 * 100, metric = 4.74% * 100;
 Minibatch[ 501- 600]: loss = 0.263950 * 100, metric = 4.70% * 100;
 Minibatch[ 601- 700]: loss = 0.264821 * 100, metric = 4.74% * 100;
 Minibatch[ 701- 800]: loss = 0.277339 * 100, metric = 4.70% * 100;
 Minibatch[ 801- 900]: loss = 0.266582 * 100, metric = 4.77% * 100;
 Minibatch[ 901-1000]: loss = 0.273053 * 100, metric = 4.89% * 100;
 Minibatch[1001-1100]: loss = 0.261857 * 100, metric = 4.67% * 100;
 Minibatch[1101-1200]: loss = 0.274215 * 100, metric = 4.86% * 100;
 Minibatch[1201-1300]: loss = 0.276437 * 100, metric = 4.89% * 100;
 Minibatch[1301-1400]: loss = 0.267980 * 100, metric = 4.75% * 100;
 Minibatch[1401-1500]: loss = 0.271376 * 100, metric = 4.78% * 100;
 Minibatch[1501-1600]: loss = 0.268643 * 100, metric = 4.65% * 100;
 Minibatch[1601-1700]: loss = 0.274520 * 100, metric = 4.89% * 100;
 Minibatch[1701-1800]: loss = 0.273557 * 100, metric = 4.80% * 100;
 Minibatch[1801-1900]: loss = 0.274916 * 100, metric = 4.78% * 100;
 Minibatch[1901-2000]: loss = 0.274001 * 100, metric = 4.81% * 100;
Finished Epoch[59 of 200]: [Training] loss = 0.272302 * 2000, metric = 4.81% * 2000 896.230s (  2.2 samples/s);
Finished Evaluation [59]: Minibatch[1-2000]: metric = 12.93% * 2000;
 Minibatch[   1- 100]: loss = 0.271592 * 100, metric = 4.81% * 100;
 Minibatch[ 101- 200]: loss = 0.258836 * 100, metric = 4.48% * 100;
 Minibatch[ 201- 300]: loss = 0.257922 * 100, metric = 4.39% * 100;
 Minibatch[ 301- 400]: loss = 0.274608 * 100, metric = 4.68% * 100;
 Minibatch[ 401- 500]: loss = 0.277722 * 100, metric = 4.95% * 100;
 Minibatch[ 501- 600]: loss = 0.283339 * 100, metric = 5.23% * 100;
 Minibatch[ 601- 700]: loss = 0.257432 * 100, metric = 4.42% * 100;
 Minibatch[ 701- 800]: loss = 0.273150 * 100, metric = 4.67% * 100;
 Minibatch[ 801- 900]: loss = 0.273448 * 100, metric = 5.00% * 100;
 Minibatch[ 901-1000]: loss = 0.275696 * 100, metric = 4.84% * 100;
 Minibatch[1001-1100]: loss = 0.282495 * 100, metric = 5.10% * 100;
 Minibatch[1101-1200]: loss = 0.277993 * 100, metric = 4.96% * 100;
 Minibatch[1201-1300]: loss = 0.273251 * 100, metric = 4.83% * 100;
 Minibatch[1301-1400]: loss = 0.271833 * 100, metric = 4.81% * 100;
 Minibatch[1401-1500]: loss = 0.260321 * 100, metric = 4.49% * 100;
 Minibatch[1501-1600]: loss = 0.275483 * 100, metric = 4.82% * 100;
 Minibatch[1601-1700]: loss = 0.272339 * 100, metric = 4.81% * 100;
 Minibatch[1701-1800]: loss = 0.274429 * 100, metric = 4.71% * 100;
 Minibatch[1801-1900]: loss = 0.275733 * 100, metric = 4.87% * 100;
 Minibatch[1901-2000]: loss = 0.263362 * 100, metric = 4.54% * 100;
Finished Epoch[60 of 200]: [Training] loss = 0.271549 * 2000, metric = 4.77% * 2000 868.159s (  2.3 samples/s);
Finished Evaluation [60]: Minibatch[1-2000]: metric = 13.40% * 2000;
 Minibatch[   1- 100]: loss = 0.275934 * 100, metric = 4.79% * 100;
 Minibatch[ 101- 200]: loss = 0.256389 * 100, metric = 4.41% * 100;
 Minibatch[ 201- 300]: loss = 0.268818 * 100, metric = 4.81% * 100;
 Minibatch[ 301- 400]: loss = 0.273074 * 100, metric = 4.84% * 100;
 Minibatch[ 401- 500]: loss = 0.266702 * 100, metric = 4.78% * 100;
 Minibatch[ 501- 600]: loss = 0.255139 * 100, metric = 4.48% * 100;
 Minibatch[ 601- 700]: loss = 0.271516 * 100, metric = 4.61% * 100;
 Minibatch[ 701- 800]: loss = 0.268810 * 100, metric = 4.76% * 100;
 Minibatch[ 801- 900]: loss = 0.263075 * 100, metric = 4.54% * 100;
 Minibatch[ 901-1000]: loss = 0.261712 * 100, metric = 4.62% * 100;
 Minibatch[1001-1100]: loss = 0.269724 * 100, metric = 4.81% * 100;
 Minibatch[1101-1200]: loss = 0.272581 * 100, metric = 4.92% * 100;
 Minibatch[1201-1300]: loss = 0.258467 * 100, metric = 4.57% * 100;
 Minibatch[1301-1400]: loss = 0.250710 * 100, metric = 4.07% * 100;
 Minibatch[1401-1500]: loss = 0.272352 * 100, metric = 4.76% * 100;
 Minibatch[1501-1600]: loss = 0.280780 * 100, metric = 5.12% * 100;
 Minibatch[1601-1700]: loss = 0.278843 * 100, metric = 4.91% * 100;
 Minibatch[1701-1800]: loss = 0.270062 * 100, metric = 4.54% * 100;
 Minibatch[1801-1900]: loss = 0.265083 * 100, metric = 4.69% * 100;
 Minibatch[1901-2000]: loss = 0.261437 * 100, metric = 4.47% * 100;
Finished Epoch[61 of 200]: [Training] loss = 0.267060 * 2000, metric = 4.67% * 2000 843.865s (  2.4 samples/s);
Finished Evaluation [61]: Minibatch[1-2000]: metric = 12.68% * 2000;
 Minibatch[   1- 100]: loss = 0.261855 * 100, metric = 4.52% * 100;
 Minibatch[ 101- 200]: loss = 0.257760 * 100, metric = 4.38% * 100;
 Minibatch[ 201- 300]: loss = 0.266959 * 100, metric = 4.53% * 100;
 Minibatch[ 301- 400]: loss = 0.265206 * 100, metric = 4.65% * 100;
 Minibatch[ 401- 500]: loss = 0.268653 * 100, metric = 4.51% * 100;
 Minibatch[ 501- 600]: loss = 0.274472 * 100, metric = 4.82% * 100;
 Minibatch[ 601- 700]: loss = 0.272411 * 100, metric = 4.86% * 100;
 Minibatch[ 701- 800]: loss = 0.262186 * 100, metric = 4.58% * 100;
 Minibatch[ 801- 900]: loss = 0.268612 * 100, metric = 4.94% * 100;
 Minibatch[ 901-1000]: loss = 0.274573 * 100, metric = 4.87% * 100;
 Minibatch[1001-1100]: loss = 0.250077 * 100, metric = 4.45% * 100;
 Minibatch[1101-1200]: loss = 0.278739 * 100, metric = 4.96% * 100;
 Minibatch[1201-1300]: loss = 0.273135 * 100, metric = 4.82% * 100;
 Minibatch[1301-1400]: loss = 0.282398 * 100, metric = 4.89% * 100;
 Minibatch[1401-1500]: loss = 0.255619 * 100, metric = 4.47% * 100;
 Minibatch[1501-1600]: loss = 0.260823 * 100, metric = 4.40% * 100;
 Minibatch[1601-1700]: loss = 0.264822 * 100, metric = 4.65% * 100;
 Minibatch[1701-1800]: loss = 0.270540 * 100, metric = 4.81% * 100;
 Minibatch[1801-1900]: loss = 0.271305 * 100, metric = 4.70% * 100;
 Minibatch[1901-2000]: loss = 0.266040 * 100, metric = 4.59% * 100;
Finished Epoch[62 of 200]: [Training] loss = 0.267309 * 2000, metric = 4.67% * 2000 862.744s (  2.3 samples/s);
Finished Evaluation [62]: Minibatch[1-2000]: metric = 12.89% * 2000;
 Minibatch[   1- 100]: loss = 0.269092 * 100, metric = 4.69% * 100;
 Minibatch[ 101- 200]: loss = 0.256462 * 100, metric = 4.31% * 100;
 Minibatch[ 201- 300]: loss = 0.270676 * 100, metric = 4.66% * 100;
 Minibatch[ 301- 400]: loss = 0.250989 * 100, metric = 4.41% * 100;
 Minibatch[ 401- 500]: loss = 0.253120 * 100, metric = 4.31% * 100;
 Minibatch[ 501- 600]: loss = 0.260805 * 100, metric = 4.45% * 100;
 Minibatch[ 601- 700]: loss = 0.267836 * 100, metric = 4.82% * 100;
 Minibatch[ 701- 800]: loss = 0.265903 * 100, metric = 4.70% * 100;
 Minibatch[ 801- 900]: loss = 0.259411 * 100, metric = 4.45% * 100;
 Minibatch[ 901-1000]: loss = 0.254548 * 100, metric = 4.27% * 100;
 Minibatch[1001-1100]: loss = 0.267711 * 100, metric = 4.71% * 100;
 Minibatch[1101-1200]: loss = 0.260129 * 100, metric = 4.62% * 100;
 Minibatch[1201-1300]: loss = 0.263678 * 100, metric = 4.48% * 100;
 Minibatch[1301-1400]: loss = 0.265622 * 100, metric = 4.69% * 100;
 Minibatch[1401-1500]: loss = 0.249808 * 100, metric = 4.29% * 100;
 Minibatch[1501-1600]: loss = 0.261118 * 100, metric = 4.60% * 100;
 Minibatch[1601-1700]: loss = 0.254973 * 100, metric = 4.48% * 100;
 Minibatch[1701-1800]: loss = 0.251023 * 100, metric = 4.36% * 100;
 Minibatch[1801-1900]: loss = 0.264183 * 100, metric = 4.40% * 100;
 Minibatch[1901-2000]: loss = 0.263083 * 100, metric = 4.62% * 100;
Finished Epoch[63 of 200]: [Training] loss = 0.260508 * 2000, metric = 4.52% * 2000 889.804s (  2.2 samples/s);
Finished Evaluation [63]: Minibatch[1-2000]: metric = 12.82% * 2000;
 Minibatch[   1- 100]: loss = 0.262506 * 100, metric = 4.51% * 100;
 Minibatch[ 101- 200]: loss = 0.269138 * 100, metric = 4.67% * 100;
 Minibatch[ 201- 300]: loss = 0.263458 * 100, metric = 4.58% * 100;
 Minibatch[ 301- 400]: loss = 0.264158 * 100, metric = 4.58% * 100;
 Minibatch[ 401- 500]: loss = 0.258548 * 100, metric = 4.51% * 100;
 Minibatch[ 501- 600]: loss = 0.253452 * 100, metric = 4.27% * 100;
 Minibatch[ 601- 700]: loss = 0.256945 * 100, metric = 4.44% * 100;
 Minibatch[ 701- 800]: loss = 0.269708 * 100, metric = 4.73% * 100;
 Minibatch[ 801- 900]: loss = 0.268469 * 100, metric = 4.63% * 100;
 Minibatch[ 901-1000]: loss = 0.255154 * 100, metric = 4.27% * 100;
 Minibatch[1001-1100]: loss = 0.258288 * 100, metric = 4.58% * 100;
 Minibatch[1101-1200]: loss = 0.263061 * 100, metric = 4.55% * 100;
 Minibatch[1201-1300]: loss = 0.256899 * 100, metric = 4.39% * 100;
 Minibatch[1301-1400]: loss = 0.269959 * 100, metric = 4.88% * 100;
 Minibatch[1401-1500]: loss = 0.271572 * 100, metric = 4.76% * 100;
 Minibatch[1501-1600]: loss = 0.268941 * 100, metric = 4.84% * 100;
 Minibatch[1601-1700]: loss = 0.253345 * 100, metric = 4.32% * 100;
 Minibatch[1701-1800]: loss = 0.261431 * 100, metric = 4.51% * 100;
 Minibatch[1801-1900]: loss = 0.267490 * 100, metric = 4.72% * 100;
 Minibatch[1901-2000]: loss = 0.254759 * 100, metric = 4.30% * 100;
Finished Epoch[64 of 200]: [Training] loss = 0.262364 * 2000, metric = 4.55% * 2000 812.261s (  2.5 samples/s);
Finished Evaluation [64]: Minibatch[1-2000]: metric = 13.68% * 2000;
 Minibatch[   1- 100]: loss = 0.260081 * 100, metric = 4.57% * 100;
 Minibatch[ 101- 200]: loss = 0.256327 * 100, metric = 4.42% * 100;
 Minibatch[ 201- 300]: loss = 0.265446 * 100, metric = 4.57% * 100;
 Minibatch[ 301- 400]: loss = 0.267129 * 100, metric = 4.67% * 100;
 Minibatch[ 401- 500]: loss = 0.253412 * 100, metric = 4.38% * 100;
 Minibatch[ 501- 600]: loss = 0.258841 * 100, metric = 4.55% * 100;
 Minibatch[ 601- 700]: loss = 0.262773 * 100, metric = 4.70% * 100;
 Minibatch[ 701- 800]: loss = 0.272816 * 100, metric = 4.91% * 100;
 Minibatch[ 801- 900]: loss = 0.258937 * 100, metric = 4.60% * 100;
 Minibatch[ 901-1000]: loss = 0.262628 * 100, metric = 4.64% * 100;
 Minibatch[1001-1100]: loss = 0.260809 * 100, metric = 4.71% * 100;
 Minibatch[1101-1200]: loss = 0.263309 * 100, metric = 4.63% * 100;
 Minibatch[1201-1300]: loss = 0.268448 * 100, metric = 4.58% * 100;
 Minibatch[1301-1400]: loss = 0.255872 * 100, metric = 4.38% * 100;
 Minibatch[1401-1500]: loss = 0.254260 * 100, metric = 4.30% * 100;
 Minibatch[1501-1600]: loss = 0.257698 * 100, metric = 4.59% * 100;
 Minibatch[1601-1700]: loss = 0.260427 * 100, metric = 4.55% * 100;
 Minibatch[1701-1800]: loss = 0.262466 * 100, metric = 4.64% * 100;
 Minibatch[1801-1900]: loss = 0.260768 * 100, metric = 4.49% * 100;
 Minibatch[1901-2000]: loss = 0.257812 * 100, metric = 4.55% * 100;
Finished Epoch[65 of 200]: [Training] loss = 0.261013 * 2000, metric = 4.57% * 2000 807.821s (  2.5 samples/s);
Finished Evaluation [65]: Minibatch[1-2000]: metric = 12.91% * 2000;
 Minibatch[   1- 100]: loss = 0.254076 * 100, metric = 4.50% * 100;
 Minibatch[ 101- 200]: loss = 0.268260 * 100, metric = 4.71% * 100;
 Minibatch[ 201- 300]: loss = 0.256249 * 100, metric = 4.46% * 100;
 Minibatch[ 301- 400]: loss = 0.252531 * 100, metric = 4.41% * 100;
 Minibatch[ 401- 500]: loss = 0.261013 * 100, metric = 4.65% * 100;
 Minibatch[ 501- 600]: loss = 0.250261 * 100, metric = 4.19% * 100;
 Minibatch[ 601- 700]: loss = 0.247771 * 100, metric = 4.14% * 100;
 Minibatch[ 701- 800]: loss = 0.259956 * 100, metric = 4.66% * 100;
 Minibatch[ 801- 900]: loss = 0.241201 * 100, metric = 3.98% * 100;
 Minibatch[ 901-1000]: loss = 0.250540 * 100, metric = 4.26% * 100;
 Minibatch[1001-1100]: loss = 0.260472 * 100, metric = 4.60% * 100;
 Minibatch[1101-1200]: loss = 0.249065 * 100, metric = 4.48% * 100;
 Minibatch[1201-1300]: loss = 0.267068 * 100, metric = 4.76% * 100;
 Minibatch[1301-1400]: loss = 0.255757 * 100, metric = 4.34% * 100;
 Minibatch[1401-1500]: loss = 0.243719 * 100, metric = 4.27% * 100;
 Minibatch[1501-1600]: loss = 0.255254 * 100, metric = 4.36% * 100;
 Minibatch[1601-1700]: loss = 0.258207 * 100, metric = 4.41% * 100;
 Minibatch[1701-1800]: loss = 0.261821 * 100, metric = 4.62% * 100;
 Minibatch[1801-1900]: loss = 0.254198 * 100, metric = 4.41% * 100;
 Minibatch[1901-2000]: loss = 0.256293 * 100, metric = 4.53% * 100;
Finished Epoch[66 of 200]: [Training] loss = 0.255186 * 2000, metric = 4.44% * 2000 800.723s (  2.5 samples/s);
Finished Evaluation [66]: Minibatch[1-2000]: metric = 13.16% * 2000;
 Minibatch[   1- 100]: loss = 0.257074 * 100, metric = 4.64% * 100;
 Minibatch[ 101- 200]: loss = 0.253337 * 100, metric = 4.46% * 100;
 Minibatch[ 201- 300]: loss = 0.260949 * 100, metric = 4.38% * 100;
 Minibatch[ 301- 400]: loss = 0.261475 * 100, metric = 4.82% * 100;
 Minibatch[ 401- 500]: loss = 0.256124 * 100, metric = 4.46% * 100;
 Minibatch[ 501- 600]: loss = 0.260906 * 100, metric = 4.52% * 100;
 Minibatch[ 601- 700]: loss = 0.248661 * 100, metric = 4.41% * 100;
 Minibatch[ 701- 800]: loss = 0.259510 * 100, metric = 4.62% * 100;
 Minibatch[ 801- 900]: loss = 0.256855 * 100, metric = 4.38% * 100;
 Minibatch[ 901-1000]: loss = 0.260651 * 100, metric = 4.42% * 100;
 Minibatch[1001-1100]: loss = 0.257104 * 100, metric = 4.55% * 100;
 Minibatch[1101-1200]: loss = 0.262837 * 100, metric = 4.48% * 100;
 Minibatch[1201-1300]: loss = 0.262987 * 100, metric = 4.58% * 100;
 Minibatch[1301-1400]: loss = 0.257330 * 100, metric = 4.44% * 100;
 Minibatch[1401-1500]: loss = 0.245246 * 100, metric = 4.22% * 100;
 Minibatch[1501-1600]: loss = 0.250899 * 100, metric = 4.39% * 100;
 Minibatch[1601-1700]: loss = 0.248262 * 100, metric = 4.34% * 100;
 Minibatch[1701-1800]: loss = 0.267729 * 100, metric = 4.79% * 100;
 Minibatch[1801-1900]: loss = 0.251834 * 100, metric = 4.42% * 100;
 Minibatch[1901-2000]: loss = 0.264836 * 100, metric = 4.79% * 100;
Finished Epoch[67 of 200]: [Training] loss = 0.257230 * 2000, metric = 4.51% * 2000 785.597s (  2.5 samples/s);
Finished Evaluation [67]: Minibatch[1-2000]: metric = 12.41% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
