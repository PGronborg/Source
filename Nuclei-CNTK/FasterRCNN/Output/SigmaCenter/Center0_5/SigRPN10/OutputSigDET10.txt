Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.423331 * 100, metric = 25.43% * 100;
 Minibatch[ 101- 200]: loss = 1.142008 * 100, metric = 23.50% * 100;
 Minibatch[ 201- 300]: loss = 1.019547 * 100, metric = 21.32% * 100;
 Minibatch[ 301- 400]: loss = 0.999743 * 100, metric = 20.10% * 100;
 Minibatch[ 401- 500]: loss = 0.924727 * 100, metric = 18.78% * 100;
 Minibatch[ 501- 600]: loss = 0.907906 * 100, metric = 18.14% * 100;
 Minibatch[ 601- 700]: loss = 0.874277 * 100, metric = 16.64% * 100;
 Minibatch[ 701- 800]: loss = 0.831605 * 100, metric = 15.97% * 100;
 Minibatch[ 801- 900]: loss = 0.851082 * 100, metric = 16.25% * 100;
 Minibatch[ 901-1000]: loss = 0.849406 * 100, metric = 16.39% * 100;
 Minibatch[1001-1100]: loss = 0.815219 * 100, metric = 15.65% * 100;
 Minibatch[1101-1200]: loss = 0.817971 * 100, metric = 15.07% * 100;
 Minibatch[1201-1300]: loss = 0.800317 * 100, metric = 15.04% * 100;
 Minibatch[1301-1400]: loss = 0.787554 * 100, metric = 14.08% * 100;
 Minibatch[1401-1500]: loss = 0.790925 * 100, metric = 14.58% * 100;
 Minibatch[1501-1600]: loss = 0.775741 * 100, metric = 14.10% * 100;
 Minibatch[1601-1700]: loss = 0.755099 * 100, metric = 13.67% * 100;
 Minibatch[1701-1800]: loss = 0.782078 * 100, metric = 14.28% * 100;
 Minibatch[1801-1900]: loss = 0.760745 * 100, metric = 13.84% * 100;
 Minibatch[1901-2000]: loss = 0.737278 * 100, metric = 13.15% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.882328 * 2000, metric = 16.80% * 2000 1055.426s (  1.9 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 25.16% * 2000;
0.8748246563747525
 Minibatch[   1- 100]: loss = 0.737197 * 100, metric = 13.20% * 100;
 Minibatch[ 101- 200]: loss = 0.764551 * 100, metric = 13.76% * 100;
 Minibatch[ 201- 300]: loss = 0.753904 * 100, metric = 13.01% * 100;
 Minibatch[ 301- 400]: loss = 0.733969 * 100, metric = 13.11% * 100;
 Minibatch[ 401- 500]: loss = 0.730696 * 100, metric = 12.71% * 100;
 Minibatch[ 501- 600]: loss = 0.740029 * 100, metric = 12.57% * 100;
 Minibatch[ 601- 700]: loss = 0.696050 * 100, metric = 12.17% * 100;
 Minibatch[ 701- 800]: loss = 0.721730 * 100, metric = 12.97% * 100;
 Minibatch[ 801- 900]: loss = 0.688472 * 100, metric = 11.98% * 100;
 Minibatch[ 901-1000]: loss = 0.689253 * 100, metric = 11.98% * 100;
 Minibatch[1001-1100]: loss = 0.711855 * 100, metric = 12.43% * 100;
 Minibatch[1101-1200]: loss = 0.702492 * 100, metric = 12.09% * 100;
 Minibatch[1201-1300]: loss = 0.688949 * 100, metric = 11.97% * 100;
 Minibatch[1301-1400]: loss = 0.696837 * 100, metric = 12.13% * 100;
 Minibatch[1401-1500]: loss = 0.672454 * 100, metric = 11.66% * 100;
 Minibatch[1501-1600]: loss = 0.677656 * 100, metric = 11.22% * 100;
 Minibatch[1601-1700]: loss = 0.698875 * 100, metric = 12.13% * 100;
 Minibatch[1701-1800]: loss = 0.696827 * 100, metric = 11.83% * 100;
 Minibatch[1801-1900]: loss = 0.681312 * 100, metric = 11.59% * 100;
 Minibatch[1901-2000]: loss = 0.648359 * 100, metric = 10.96% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.706573 * 2000, metric = 12.27% * 2000 995.090s (  2.0 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 21.47% * 2000;
0.7835390593707562
 Minibatch[   1- 100]: loss = 0.677803 * 100, metric = 11.74% * 100;
 Minibatch[ 101- 200]: loss = 0.681380 * 100, metric = 11.69% * 100;
 Minibatch[ 201- 300]: loss = 0.668993 * 100, metric = 11.44% * 100;
 Minibatch[ 301- 400]: loss = 0.682212 * 100, metric = 11.79% * 100;
 Minibatch[ 401- 500]: loss = 0.684926 * 100, metric = 12.07% * 100;
 Minibatch[ 501- 600]: loss = 0.677207 * 100, metric = 11.35% * 100;
 Minibatch[ 601- 700]: loss = 0.674909 * 100, metric = 11.34% * 100;
 Minibatch[ 701- 800]: loss = 0.640985 * 100, metric = 10.66% * 100;
 Minibatch[ 801- 900]: loss = 0.669054 * 100, metric = 11.50% * 100;
 Minibatch[ 901-1000]: loss = 0.644681 * 100, metric = 11.11% * 100;
 Minibatch[1001-1100]: loss = 0.682711 * 100, metric = 11.52% * 100;
 Minibatch[1101-1200]: loss = 0.648948 * 100, metric = 10.88% * 100;
 Minibatch[1201-1300]: loss = 0.641403 * 100, metric = 10.85% * 100;
 Minibatch[1301-1400]: loss = 0.652750 * 100, metric = 11.01% * 100;
 Minibatch[1401-1500]: loss = 0.655972 * 100, metric = 11.04% * 100;
 Minibatch[1501-1600]: loss = 0.639614 * 100, metric = 10.28% * 100;
 Minibatch[1601-1700]: loss = 0.622979 * 100, metric = 10.27% * 100;
 Minibatch[1701-1800]: loss = 0.647336 * 100, metric = 10.89% * 100;
 Minibatch[1801-1900]: loss = 0.639363 * 100, metric = 10.25% * 100;
 Minibatch[1901-2000]: loss = 0.630526 * 100, metric = 10.59% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.658188 * 2000, metric = 11.11% * 2000 992.179s (  2.0 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 20.07% * 2000;
0.7517064803391695
 Minibatch[   1- 100]: loss = 0.653812 * 100, metric = 10.65% * 100;
 Minibatch[ 101- 200]: loss = 0.613639 * 100, metric = 10.29% * 100;
 Minibatch[ 201- 300]: loss = 0.619869 * 100, metric = 10.46% * 100;
 Minibatch[ 301- 400]: loss = 0.603282 * 100, metric = 9.94% * 100;
 Minibatch[ 401- 500]: loss = 0.628680 * 100, metric = 10.56% * 100;
 Minibatch[ 501- 600]: loss = 0.615066 * 100, metric = 9.95% * 100;
 Minibatch[ 601- 700]: loss = 0.616880 * 100, metric = 10.15% * 100;
 Minibatch[ 701- 800]: loss = 0.631089 * 100, metric = 10.46% * 100;
 Minibatch[ 801- 900]: loss = 0.628293 * 100, metric = 10.51% * 100;
 Minibatch[ 901-1000]: loss = 0.627079 * 100, metric = 10.56% * 100;
 Minibatch[1001-1100]: loss = 0.633582 * 100, metric = 10.65% * 100;
 Minibatch[1101-1200]: loss = 0.620081 * 100, metric = 10.09% * 100;
 Minibatch[1201-1300]: loss = 0.621677 * 100, metric = 10.28% * 100;
 Minibatch[1301-1400]: loss = 0.644558 * 100, metric = 10.91% * 100;
 Minibatch[1401-1500]: loss = 0.630671 * 100, metric = 10.49% * 100;
 Minibatch[1501-1600]: loss = 0.601660 * 100, metric = 10.00% * 100;
 Minibatch[1601-1700]: loss = 0.630834 * 100, metric = 10.40% * 100;
 Minibatch[1701-1800]: loss = 0.629279 * 100, metric = 10.49% * 100;
 Minibatch[1801-1900]: loss = 0.610682 * 100, metric = 10.01% * 100;
 Minibatch[1901-2000]: loss = 0.601010 * 100, metric = 9.95% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.623086 * 2000, metric = 10.34% * 2000 996.994s (  2.0 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 20.58% * 2000;
 Minibatch[   1- 100]: loss = 0.617514 * 100, metric = 10.26% * 100;
 Minibatch[ 101- 200]: loss = 0.607520 * 100, metric = 9.90% * 100;
 Minibatch[ 201- 300]: loss = 0.591172 * 100, metric = 9.70% * 100;
 Minibatch[ 301- 400]: loss = 0.632651 * 100, metric = 10.62% * 100;
 Minibatch[ 401- 500]: loss = 0.578959 * 100, metric = 9.18% * 100;
 Minibatch[ 501- 600]: loss = 0.583290 * 100, metric = 9.46% * 100;
 Minibatch[ 601- 700]: loss = 0.585620 * 100, metric = 9.21% * 100;
 Minibatch[ 701- 800]: loss = 0.607301 * 100, metric = 9.83% * 100;
 Minibatch[ 801- 900]: loss = 0.587078 * 100, metric = 9.54% * 100;
 Minibatch[ 901-1000]: loss = 0.591607 * 100, metric = 9.79% * 100;
 Minibatch[1001-1100]: loss = 0.598168 * 100, metric = 9.57% * 100;
 Minibatch[1101-1200]: loss = 0.580217 * 100, metric = 9.34% * 100;
 Minibatch[1201-1300]: loss = 0.597299 * 100, metric = 9.32% * 100;
 Minibatch[1301-1400]: loss = 0.611708 * 100, metric = 10.03% * 100;
 Minibatch[1401-1500]: loss = 0.590117 * 100, metric = 9.77% * 100;
 Minibatch[1501-1600]: loss = 0.592203 * 100, metric = 9.73% * 100;
 Minibatch[1601-1700]: loss = 0.602993 * 100, metric = 10.06% * 100;
 Minibatch[1701-1800]: loss = 0.605217 * 100, metric = 9.85% * 100;
 Minibatch[1801-1900]: loss = 0.590675 * 100, metric = 9.95% * 100;
 Minibatch[1901-2000]: loss = 0.572659 * 100, metric = 9.24% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.596198 * 2000, metric = 9.72% * 2000 964.099s (  2.1 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 17.60% * 2000;
0.6895546297580004
 Minibatch[   1- 100]: loss = 0.571825 * 100, metric = 9.25% * 100;
 Minibatch[ 101- 200]: loss = 0.570357 * 100, metric = 9.37% * 100;
 Minibatch[ 201- 300]: loss = 0.585146 * 100, metric = 9.30% * 100;
 Minibatch[ 301- 400]: loss = 0.585850 * 100, metric = 9.16% * 100;
 Minibatch[ 401- 500]: loss = 0.561974 * 100, metric = 9.12% * 100;
 Minibatch[ 501- 600]: loss = 0.582090 * 100, metric = 9.62% * 100;
 Minibatch[ 601- 700]: loss = 0.567129 * 100, metric = 9.41% * 100;
 Minibatch[ 701- 800]: loss = 0.580899 * 100, metric = 9.22% * 100;
 Minibatch[ 801- 900]: loss = 0.582607 * 100, metric = 9.64% * 100;
 Minibatch[ 901-1000]: loss = 0.566422 * 100, metric = 9.31% * 100;
 Minibatch[1001-1100]: loss = 0.571644 * 100, metric = 9.07% * 100;
 Minibatch[1101-1200]: loss = 0.590004 * 100, metric = 9.47% * 100;
 Minibatch[1201-1300]: loss = 0.595004 * 100, metric = 9.78% * 100;
 Minibatch[1301-1400]: loss = 0.573696 * 100, metric = 9.40% * 100;
 Minibatch[1401-1500]: loss = 0.592188 * 100, metric = 9.56% * 100;
 Minibatch[1501-1600]: loss = 0.562888 * 100, metric = 8.58% * 100;
 Minibatch[1601-1700]: loss = 0.565392 * 100, metric = 9.03% * 100;
 Minibatch[1701-1800]: loss = 0.559661 * 100, metric = 8.76% * 100;
 Minibatch[1801-1900]: loss = 0.579218 * 100, metric = 9.36% * 100;
 Minibatch[1901-2000]: loss = 0.568556 * 100, metric = 9.09% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.575627 * 2000, metric = 9.28% * 2000 976.254s (  2.0 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 18.17% * 2000;
 Minibatch[   1- 100]: loss = 0.567529 * 100, metric = 8.89% * 100;
 Minibatch[ 101- 200]: loss = 0.571089 * 100, metric = 9.05% * 100;
 Minibatch[ 201- 300]: loss = 0.573279 * 100, metric = 9.46% * 100;
 Minibatch[ 301- 400]: loss = 0.556800 * 100, metric = 9.01% * 100;
 Minibatch[ 401- 500]: loss = 0.571241 * 100, metric = 9.13% * 100;
 Minibatch[ 501- 600]: loss = 0.539581 * 100, metric = 8.47% * 100;
 Minibatch[ 601- 700]: loss = 0.572543 * 100, metric = 9.23% * 100;
 Minibatch[ 701- 800]: loss = 0.574377 * 100, metric = 9.16% * 100;
 Minibatch[ 801- 900]: loss = 0.579125 * 100, metric = 9.51% * 100;
 Minibatch[ 901-1000]: loss = 0.568411 * 100, metric = 9.22% * 100;
 Minibatch[1001-1100]: loss = 0.572965 * 100, metric = 9.47% * 100;
 Minibatch[1101-1200]: loss = 0.554488 * 100, metric = 8.84% * 100;
 Minibatch[1201-1300]: loss = 0.566028 * 100, metric = 9.43% * 100;
 Minibatch[1301-1400]: loss = 0.557912 * 100, metric = 8.96% * 100;
 Minibatch[1401-1500]: loss = 0.550815 * 100, metric = 8.55% * 100;
 Minibatch[1501-1600]: loss = 0.565796 * 100, metric = 9.25% * 100;
 Minibatch[1601-1700]: loss = 0.568951 * 100, metric = 8.98% * 100;
 Minibatch[1701-1800]: loss = 0.545616 * 100, metric = 8.82% * 100;
 Minibatch[1801-1900]: loss = 0.555516 * 100, metric = 9.15% * 100;
 Minibatch[1901-2000]: loss = 0.559375 * 100, metric = 9.04% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.563572 * 2000, metric = 9.08% * 2000 969.134s (  2.1 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 16.81% * 2000;
0.6669514251351356
 Minibatch[   1- 100]: loss = 0.570660 * 100, metric = 9.38% * 100;
 Minibatch[ 101- 200]: loss = 0.553771 * 100, metric = 8.97% * 100;
 Minibatch[ 201- 300]: loss = 0.543936 * 100, metric = 8.83% * 100;
 Minibatch[ 301- 400]: loss = 0.554170 * 100, metric = 9.15% * 100;
 Minibatch[ 401- 500]: loss = 0.568925 * 100, metric = 9.38% * 100;
 Minibatch[ 501- 600]: loss = 0.580694 * 100, metric = 9.61% * 100;
 Minibatch[ 601- 700]: loss = 0.537366 * 100, metric = 8.52% * 100;
 Minibatch[ 701- 800]: loss = 0.555644 * 100, metric = 8.92% * 100;
 Minibatch[ 801- 900]: loss = 0.542315 * 100, metric = 8.69% * 100;
 Minibatch[ 901-1000]: loss = 0.523579 * 100, metric = 8.06% * 100;
 Minibatch[1001-1100]: loss = 0.532361 * 100, metric = 8.26% * 100;
 Minibatch[1101-1200]: loss = 0.531113 * 100, metric = 8.33% * 100;
 Minibatch[1201-1300]: loss = 0.544219 * 100, metric = 8.64% * 100;
 Minibatch[1301-1400]: loss = 0.560414 * 100, metric = 9.01% * 100;
 Minibatch[1401-1500]: loss = 0.548508 * 100, metric = 8.58% * 100;
 Minibatch[1501-1600]: loss = 0.561939 * 100, metric = 8.94% * 100;
 Minibatch[1601-1700]: loss = 0.551880 * 100, metric = 8.57% * 100;
 Minibatch[1701-1800]: loss = 0.549362 * 100, metric = 8.65% * 100;
 Minibatch[1801-1900]: loss = 0.555172 * 100, metric = 8.76% * 100;
 Minibatch[1901-2000]: loss = 0.557137 * 100, metric = 8.83% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.551158 * 2000, metric = 8.80% * 2000 961.635s (  2.1 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 15.62% * 2000;
0.6330725571885705
 Minibatch[   1- 100]: loss = 0.533720 * 100, metric = 8.29% * 100;
 Minibatch[ 101- 200]: loss = 0.551497 * 100, metric = 8.69% * 100;
 Minibatch[ 201- 300]: loss = 0.554213 * 100, metric = 8.69% * 100;
 Minibatch[ 301- 400]: loss = 0.555753 * 100, metric = 8.71% * 100;
 Minibatch[ 401- 500]: loss = 0.550243 * 100, metric = 8.46% * 100;
 Minibatch[ 501- 600]: loss = 0.543164 * 100, metric = 8.63% * 100;
 Minibatch[ 601- 700]: loss = 0.535167 * 100, metric = 8.58% * 100;
 Minibatch[ 701- 800]: loss = 0.517303 * 100, metric = 8.04% * 100;
 Minibatch[ 801- 900]: loss = 0.521381 * 100, metric = 8.17% * 100;
 Minibatch[ 901-1000]: loss = 0.536124 * 100, metric = 8.63% * 100;
 Minibatch[1001-1100]: loss = 0.510951 * 100, metric = 7.73% * 100;
 Minibatch[1101-1200]: loss = 0.539208 * 100, metric = 8.46% * 100;
 Minibatch[1201-1300]: loss = 0.532797 * 100, metric = 8.54% * 100;
 Minibatch[1301-1400]: loss = 0.520552 * 100, metric = 7.95% * 100;
 Minibatch[1401-1500]: loss = 0.540916 * 100, metric = 8.63% * 100;
 Minibatch[1501-1600]: loss = 0.528466 * 100, metric = 7.96% * 100;
 Minibatch[1601-1700]: loss = 0.537425 * 100, metric = 8.50% * 100;
 Minibatch[1701-1800]: loss = 0.524391 * 100, metric = 8.05% * 100;
 Minibatch[1801-1900]: loss = 0.513473 * 100, metric = 7.73% * 100;
 Minibatch[1901-2000]: loss = 0.537275 * 100, metric = 8.52% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.534201 * 2000, metric = 8.35% * 2000 952.880s (  2.1 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 14.84% * 2000;
0.6077584535107017
 Minibatch[   1- 100]: loss = 0.547986 * 100, metric = 8.91% * 100;
 Minibatch[ 101- 200]: loss = 0.515187 * 100, metric = 8.07% * 100;
 Minibatch[ 201- 300]: loss = 0.523828 * 100, metric = 8.00% * 100;
 Minibatch[ 301- 400]: loss = 0.520235 * 100, metric = 8.10% * 100;
 Minibatch[ 401- 500]: loss = 0.527825 * 100, metric = 8.37% * 100;
 Minibatch[ 501- 600]: loss = 0.505335 * 100, metric = 7.84% * 100;
 Minibatch[ 601- 700]: loss = 0.495481 * 100, metric = 7.59% * 100;
 Minibatch[ 701- 800]: loss = 0.499576 * 100, metric = 7.38% * 100;
 Minibatch[ 801- 900]: loss = 0.516858 * 100, metric = 7.93% * 100;
 Minibatch[ 901-1000]: loss = 0.522774 * 100, metric = 8.27% * 100;
 Minibatch[1001-1100]: loss = 0.521917 * 100, metric = 8.26% * 100;
 Minibatch[1101-1200]: loss = 0.514926 * 100, metric = 7.93% * 100;
 Minibatch[1201-1300]: loss = 0.514265 * 100, metric = 7.97% * 100;
 Minibatch[1301-1400]: loss = 0.509741 * 100, metric = 7.88% * 100;
 Minibatch[1401-1500]: loss = 0.500966 * 100, metric = 7.67% * 100;
 Minibatch[1501-1600]: loss = 0.509037 * 100, metric = 7.88% * 100;
 Minibatch[1601-1700]: loss = 0.504717 * 100, metric = 7.40% * 100;
 Minibatch[1701-1800]: loss = 0.515070 * 100, metric = 7.87% * 100;
 Minibatch[1801-1900]: loss = 0.522823 * 100, metric = 8.01% * 100;
 Minibatch[1901-2000]: loss = 0.500801 * 100, metric = 7.79% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.514467 * 2000, metric = 7.96% * 2000 943.944s (  2.1 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 15.35% * 2000;
 Minibatch[   1- 100]: loss = 0.495930 * 100, metric = 7.42% * 100;
 Minibatch[ 101- 200]: loss = 0.503375 * 100, metric = 7.47% * 100;
 Minibatch[ 201- 300]: loss = 0.517852 * 100, metric = 8.06% * 100;
 Minibatch[ 301- 400]: loss = 0.510051 * 100, metric = 7.83% * 100;
 Minibatch[ 401- 500]: loss = 0.496509 * 100, metric = 7.55% * 100;
 Minibatch[ 501- 600]: loss = 0.518355 * 100, metric = 8.16% * 100;
 Minibatch[ 601- 700]: loss = 0.501487 * 100, metric = 7.57% * 100;
 Minibatch[ 701- 800]: loss = 0.519150 * 100, metric = 8.03% * 100;
 Minibatch[ 801- 900]: loss = 0.509464 * 100, metric = 7.76% * 100;
 Minibatch[ 901-1000]: loss = 0.525169 * 100, metric = 8.26% * 100;
 Minibatch[1001-1100]: loss = 0.517823 * 100, metric = 8.01% * 100;
 Minibatch[1101-1200]: loss = 0.525506 * 100, metric = 8.23% * 100;
 Minibatch[1201-1300]: loss = 0.505908 * 100, metric = 7.89% * 100;
 Minibatch[1301-1400]: loss = 0.491171 * 100, metric = 7.69% * 100;
 Minibatch[1401-1500]: loss = 0.526878 * 100, metric = 8.56% * 100;
 Minibatch[1501-1600]: loss = 0.506753 * 100, metric = 7.79% * 100;
 Minibatch[1601-1700]: loss = 0.510862 * 100, metric = 7.79% * 100;
 Minibatch[1701-1800]: loss = 0.524477 * 100, metric = 8.20% * 100;
 Minibatch[1801-1900]: loss = 0.508023 * 100, metric = 7.88% * 100;
 Minibatch[1901-2000]: loss = 0.510123 * 100, metric = 8.14% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.511243 * 2000, metric = 7.91% * 2000 966.728s (  2.1 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 15.08% * 2000;
 Minibatch[   1- 100]: loss = 0.483554 * 100, metric = 7.41% * 100;
 Minibatch[ 101- 200]: loss = 0.498386 * 100, metric = 7.27% * 100;
 Minibatch[ 201- 300]: loss = 0.500552 * 100, metric = 7.53% * 100;
 Minibatch[ 301- 400]: loss = 0.530812 * 100, metric = 8.31% * 100;
 Minibatch[ 401- 500]: loss = 0.496804 * 100, metric = 7.54% * 100;
 Minibatch[ 501- 600]: loss = 0.488173 * 100, metric = 7.24% * 100;
 Minibatch[ 601- 700]: loss = 0.489659 * 100, metric = 7.27% * 100;
 Minibatch[ 701- 800]: loss = 0.501621 * 100, metric = 7.69% * 100;
 Minibatch[ 801- 900]: loss = 0.499180 * 100, metric = 7.59% * 100;
 Minibatch[ 901-1000]: loss = 0.508988 * 100, metric = 8.11% * 100;
 Minibatch[1001-1100]: loss = 0.509556 * 100, metric = 7.95% * 100;
 Minibatch[1101-1200]: loss = 0.507670 * 100, metric = 7.76% * 100;
 Minibatch[1201-1300]: loss = 0.506475 * 100, metric = 7.97% * 100;
 Minibatch[1301-1400]: loss = 0.499830 * 100, metric = 7.53% * 100;
 Minibatch[1401-1500]: loss = 0.515062 * 100, metric = 7.97% * 100;
 Minibatch[1501-1600]: loss = 0.476700 * 100, metric = 7.32% * 100;
 Minibatch[1601-1700]: loss = 0.507132 * 100, metric = 7.62% * 100;
 Minibatch[1701-1800]: loss = 0.488479 * 100, metric = 7.34% * 100;
 Minibatch[1801-1900]: loss = 0.490948 * 100, metric = 7.40% * 100;
 Minibatch[1901-2000]: loss = 0.513848 * 100, metric = 7.85% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.500671 * 2000, metric = 7.63% * 2000 955.626s (  2.1 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 15.94% * 2000;
 Minibatch[   1- 100]: loss = 0.510879 * 100, metric = 7.75% * 100;
 Minibatch[ 101- 200]: loss = 0.499315 * 100, metric = 7.67% * 100;
 Minibatch[ 201- 300]: loss = 0.491999 * 100, metric = 7.51% * 100;
 Minibatch[ 301- 400]: loss = 0.503266 * 100, metric = 7.48% * 100;
 Minibatch[ 401- 500]: loss = 0.502104 * 100, metric = 8.04% * 100;
 Minibatch[ 501- 600]: loss = 0.508165 * 100, metric = 8.01% * 100;
 Minibatch[ 601- 700]: loss = 0.487840 * 100, metric = 7.42% * 100;
 Minibatch[ 701- 800]: loss = 0.482550 * 100, metric = 7.29% * 100;
 Minibatch[ 801- 900]: loss = 0.484266 * 100, metric = 7.10% * 100;
 Minibatch[ 901-1000]: loss = 0.502628 * 100, metric = 7.68% * 100;
 Minibatch[1001-1100]: loss = 0.498219 * 100, metric = 7.54% * 100;
 Minibatch[1101-1200]: loss = 0.489187 * 100, metric = 7.49% * 100;
 Minibatch[1201-1300]: loss = 0.490577 * 100, metric = 7.63% * 100;
 Minibatch[1301-1400]: loss = 0.484099 * 100, metric = 7.28% * 100;
 Minibatch[1401-1500]: loss = 0.484498 * 100, metric = 7.18% * 100;
 Minibatch[1501-1600]: loss = 0.476328 * 100, metric = 7.02% * 100;
 Minibatch[1601-1700]: loss = 0.475788 * 100, metric = 7.35% * 100;
 Minibatch[1701-1800]: loss = 0.490225 * 100, metric = 7.42% * 100;
 Minibatch[1801-1900]: loss = 0.484132 * 100, metric = 7.27% * 100;
 Minibatch[1901-2000]: loss = 0.496351 * 100, metric = 7.56% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.492121 * 2000, metric = 7.48% * 2000 950.866s (  2.1 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 16.63% * 2000;
 Minibatch[   1- 100]: loss = 0.480457 * 100, metric = 7.14% * 100;
 Minibatch[ 101- 200]: loss = 0.475887 * 100, metric = 6.98% * 100;
 Minibatch[ 201- 300]: loss = 0.495240 * 100, metric = 7.39% * 100;
 Minibatch[ 301- 400]: loss = 0.486027 * 100, metric = 7.33% * 100;
 Minibatch[ 401- 500]: loss = 0.484198 * 100, metric = 7.42% * 100;
 Minibatch[ 501- 600]: loss = 0.485365 * 100, metric = 7.21% * 100;
 Minibatch[ 601- 700]: loss = 0.482865 * 100, metric = 7.29% * 100;
 Minibatch[ 701- 800]: loss = 0.504260 * 100, metric = 7.79% * 100;
 Minibatch[ 801- 900]: loss = 0.496884 * 100, metric = 7.79% * 100;
 Minibatch[ 901-1000]: loss = 0.494310 * 100, metric = 7.63% * 100;
 Minibatch[1001-1100]: loss = 0.492615 * 100, metric = 7.59% * 100;
 Minibatch[1101-1200]: loss = 0.485070 * 100, metric = 7.36% * 100;
 Minibatch[1201-1300]: loss = 0.465322 * 100, metric = 6.89% * 100;
 Minibatch[1301-1400]: loss = 0.483480 * 100, metric = 7.54% * 100;
 Minibatch[1401-1500]: loss = 0.488051 * 100, metric = 7.47% * 100;
 Minibatch[1501-1600]: loss = 0.470177 * 100, metric = 7.21% * 100;
 Minibatch[1601-1700]: loss = 0.475164 * 100, metric = 6.97% * 100;
 Minibatch[1701-1800]: loss = 0.476602 * 100, metric = 7.17% * 100;
 Minibatch[1801-1900]: loss = 0.479935 * 100, metric = 7.10% * 100;
 Minibatch[1901-2000]: loss = 0.484543 * 100, metric = 7.13% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.484323 * 2000, metric = 7.32% * 2000 951.218s (  2.1 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 16.24% * 2000;
 Minibatch[   1- 100]: loss = 0.472518 * 100, metric = 7.08% * 100;
 Minibatch[ 101- 200]: loss = 0.490723 * 100, metric = 7.41% * 100;
 Minibatch[ 201- 300]: loss = 0.486930 * 100, metric = 7.22% * 100;
 Minibatch[ 301- 400]: loss = 0.474487 * 100, metric = 7.03% * 100;
 Minibatch[ 401- 500]: loss = 0.474093 * 100, metric = 7.05% * 100;
 Minibatch[ 501- 600]: loss = 0.470137 * 100, metric = 6.84% * 100;
 Minibatch[ 601- 700]: loss = 0.449240 * 100, metric = 6.61% * 100;
 Minibatch[ 701- 800]: loss = 0.480176 * 100, metric = 7.17% * 100;
 Minibatch[ 801- 900]: loss = 0.490099 * 100, metric = 7.49% * 100;
 Minibatch[ 901-1000]: loss = 0.478799 * 100, metric = 7.11% * 100;
 Minibatch[1001-1100]: loss = 0.478338 * 100, metric = 7.14% * 100;
 Minibatch[1101-1200]: loss = 0.472903 * 100, metric = 7.12% * 100;
 Minibatch[1201-1300]: loss = 0.466328 * 100, metric = 6.74% * 100;
 Minibatch[1301-1400]: loss = 0.493190 * 100, metric = 7.57% * 100;
 Minibatch[1401-1500]: loss = 0.453369 * 100, metric = 6.67% * 100;
 Minibatch[1501-1600]: loss = 0.453709 * 100, metric = 6.61% * 100;
 Minibatch[1601-1700]: loss = 0.474869 * 100, metric = 7.18% * 100;
 Minibatch[1701-1800]: loss = 0.455867 * 100, metric = 6.76% * 100;
 Minibatch[1801-1900]: loss = 0.465858 * 100, metric = 7.08% * 100;
 Minibatch[1901-2000]: loss = 0.458015 * 100, metric = 6.74% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.471982 * 2000, metric = 7.03% * 2000 948.598s (  2.1 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 13.96% * 2000;
0.5979106884673238
 Minibatch[   1- 100]: loss = 0.484821 * 100, metric = 7.55% * 100;
 Minibatch[ 101- 200]: loss = 0.472618 * 100, metric = 6.85% * 100;
 Minibatch[ 201- 300]: loss = 0.477850 * 100, metric = 7.00% * 100;
 Minibatch[ 301- 400]: loss = 0.474734 * 100, metric = 6.95% * 100;
 Minibatch[ 401- 500]: loss = 0.453372 * 100, metric = 6.50% * 100;
 Minibatch[ 501- 600]: loss = 0.467288 * 100, metric = 7.20% * 100;
 Minibatch[ 601- 700]: loss = 0.471762 * 100, metric = 6.97% * 100;
 Minibatch[ 701- 800]: loss = 0.460247 * 100, metric = 6.79% * 100;
 Minibatch[ 801- 900]: loss = 0.457574 * 100, metric = 6.68% * 100;
 Minibatch[ 901-1000]: loss = 0.470914 * 100, metric = 7.25% * 100;
 Minibatch[1001-1100]: loss = 0.453862 * 100, metric = 6.75% * 100;
 Minibatch[1101-1200]: loss = 0.461664 * 100, metric = 6.92% * 100;
 Minibatch[1201-1300]: loss = 0.461395 * 100, metric = 6.75% * 100;
 Minibatch[1301-1400]: loss = 0.464523 * 100, metric = 6.71% * 100;
 Minibatch[1401-1500]: loss = 0.464363 * 100, metric = 6.89% * 100;
 Minibatch[1501-1600]: loss = 0.466945 * 100, metric = 6.79% * 100;
 Minibatch[1601-1700]: loss = 0.474427 * 100, metric = 7.21% * 100;
 Minibatch[1701-1800]: loss = 0.485413 * 100, metric = 7.15% * 100;
 Minibatch[1801-1900]: loss = 0.484303 * 100, metric = 6.99% * 100;
 Minibatch[1901-2000]: loss = 0.455516 * 100, metric = 6.68% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.468180 * 2000, metric = 6.93% * 2000 956.954s (  2.1 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.70% * 2000;
 Minibatch[   1- 100]: loss = 0.455175 * 100, metric = 6.72% * 100;
 Minibatch[ 101- 200]: loss = 0.470894 * 100, metric = 6.98% * 100;
 Minibatch[ 201- 300]: loss = 0.472753 * 100, metric = 7.04% * 100;
 Minibatch[ 301- 400]: loss = 0.467550 * 100, metric = 6.69% * 100;
 Minibatch[ 401- 500]: loss = 0.481980 * 100, metric = 7.01% * 100;
 Minibatch[ 501- 600]: loss = 0.463289 * 100, metric = 6.61% * 100;
 Minibatch[ 601- 700]: loss = 0.442224 * 100, metric = 6.33% * 100;
 Minibatch[ 701- 800]: loss = 0.464630 * 100, metric = 6.94% * 100;
 Minibatch[ 801- 900]: loss = 0.459764 * 100, metric = 6.82% * 100;
 Minibatch[ 901-1000]: loss = 0.450563 * 100, metric = 6.58% * 100;
 Minibatch[1001-1100]: loss = 0.449922 * 100, metric = 6.65% * 100;
 Minibatch[1101-1200]: loss = 0.470093 * 100, metric = 7.05% * 100;
 Minibatch[1201-1300]: loss = 0.472511 * 100, metric = 7.00% * 100;
 Minibatch[1301-1400]: loss = 0.445371 * 100, metric = 6.39% * 100;
 Minibatch[1401-1500]: loss = 0.461249 * 100, metric = 6.95% * 100;
 Minibatch[1501-1600]: loss = 0.457787 * 100, metric = 6.92% * 100;
 Minibatch[1601-1700]: loss = 0.462177 * 100, metric = 6.81% * 100;
 Minibatch[1701-1800]: loss = 0.445654 * 100, metric = 6.79% * 100;
 Minibatch[1801-1900]: loss = 0.469606 * 100, metric = 7.04% * 100;
 Minibatch[1901-2000]: loss = 0.480673 * 100, metric = 7.33% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.462193 * 2000, metric = 6.83% * 2000 948.272s (  2.1 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.25% * 2000;
 Minibatch[   1- 100]: loss = 0.451498 * 100, metric = 6.38% * 100;
 Minibatch[ 101- 200]: loss = 0.477786 * 100, metric = 7.03% * 100;
 Minibatch[ 201- 300]: loss = 0.454798 * 100, metric = 6.74% * 100;
 Minibatch[ 301- 400]: loss = 0.463217 * 100, metric = 6.76% * 100;
 Minibatch[ 401- 500]: loss = 0.443847 * 100, metric = 6.48% * 100;
 Minibatch[ 501- 600]: loss = 0.451149 * 100, metric = 6.56% * 100;
 Minibatch[ 601- 700]: loss = 0.460646 * 100, metric = 6.71% * 100;
 Minibatch[ 701- 800]: loss = 0.446235 * 100, metric = 6.53% * 100;
 Minibatch[ 801- 900]: loss = 0.460073 * 100, metric = 6.77% * 100;
 Minibatch[ 901-1000]: loss = 0.467022 * 100, metric = 6.90% * 100;
 Minibatch[1001-1100]: loss = 0.473443 * 100, metric = 6.98% * 100;
 Minibatch[1101-1200]: loss = 0.469406 * 100, metric = 7.06% * 100;
 Minibatch[1201-1300]: loss = 0.480332 * 100, metric = 7.32% * 100;
 Minibatch[1301-1400]: loss = 0.478616 * 100, metric = 7.08% * 100;
 Minibatch[1401-1500]: loss = 0.451304 * 100, metric = 6.33% * 100;
 Minibatch[1501-1600]: loss = 0.475038 * 100, metric = 6.75% * 100;
 Minibatch[1601-1700]: loss = 0.439177 * 100, metric = 6.19% * 100;
 Minibatch[1701-1800]: loss = 0.460914 * 100, metric = 6.47% * 100;
 Minibatch[1801-1900]: loss = 0.451328 * 100, metric = 6.46% * 100;
 Minibatch[1901-2000]: loss = 0.454333 * 100, metric = 6.29% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.460508 * 2000, metric = 6.69% * 2000 942.530s (  2.1 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.53% * 2000;
 Minibatch[   1- 100]: loss = 0.461392 * 100, metric = 6.80% * 100;
 Minibatch[ 101- 200]: loss = 0.472950 * 100, metric = 6.75% * 100;
 Minibatch[ 201- 300]: loss = 0.444587 * 100, metric = 6.20% * 100;
 Minibatch[ 301- 400]: loss = 0.462749 * 100, metric = 6.77% * 100;
 Minibatch[ 401- 500]: loss = 0.451164 * 100, metric = 6.35% * 100;
 Minibatch[ 501- 600]: loss = 0.440634 * 100, metric = 5.99% * 100;
 Minibatch[ 601- 700]: loss = 0.460121 * 100, metric = 6.66% * 100;
 Minibatch[ 701- 800]: loss = 0.438932 * 100, metric = 6.36% * 100;
 Minibatch[ 801- 900]: loss = 0.466739 * 100, metric = 6.92% * 100;
 Minibatch[ 901-1000]: loss = 0.444655 * 100, metric = 6.42% * 100;
 Minibatch[1001-1100]: loss = 0.462649 * 100, metric = 6.62% * 100;
 Minibatch[1101-1200]: loss = 0.451053 * 100, metric = 6.66% * 100;
 Minibatch[1201-1300]: loss = 0.449648 * 100, metric = 6.51% * 100;
 Minibatch[1301-1400]: loss = 0.446638 * 100, metric = 6.54% * 100;
 Minibatch[1401-1500]: loss = 0.455358 * 100, metric = 6.61% * 100;
 Minibatch[1501-1600]: loss = 0.453831 * 100, metric = 6.62% * 100;
 Minibatch[1601-1700]: loss = 0.436305 * 100, metric = 6.36% * 100;
 Minibatch[1701-1800]: loss = 0.430403 * 100, metric = 6.23% * 100;
 Minibatch[1801-1900]: loss = 0.434186 * 100, metric = 6.13% * 100;
 Minibatch[1901-2000]: loss = 0.436902 * 100, metric = 6.15% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.450045 * 2000, metric = 6.48% * 2000 956.065s (  2.1 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 14.82% * 2000;
 Minibatch[   1- 100]: loss = 0.445296 * 100, metric = 6.26% * 100;
 Minibatch[ 101- 200]: loss = 0.442609 * 100, metric = 6.48% * 100;
 Minibatch[ 201- 300]: loss = 0.449314 * 100, metric = 6.37% * 100;
 Minibatch[ 301- 400]: loss = 0.462168 * 100, metric = 6.55% * 100;
 Minibatch[ 401- 500]: loss = 0.454512 * 100, metric = 6.61% * 100;
 Minibatch[ 501- 600]: loss = 0.454479 * 100, metric = 6.71% * 100;
 Minibatch[ 601- 700]: loss = 0.461708 * 100, metric = 6.91% * 100;
 Minibatch[ 701- 800]: loss = 0.451574 * 100, metric = 6.67% * 100;
 Minibatch[ 801- 900]: loss = 0.459709 * 100, metric = 6.75% * 100;
 Minibatch[ 901-1000]: loss = 0.455558 * 100, metric = 6.68% * 100;
 Minibatch[1001-1100]: loss = 0.436798 * 100, metric = 6.24% * 100;
 Minibatch[1101-1200]: loss = 0.444906 * 100, metric = 6.26% * 100;
 Minibatch[1201-1300]: loss = 0.456232 * 100, metric = 6.57% * 100;
 Minibatch[1301-1400]: loss = 0.455829 * 100, metric = 6.85% * 100;
 Minibatch[1401-1500]: loss = 0.439926 * 100, metric = 6.53% * 100;
 Minibatch[1501-1600]: loss = 0.460975 * 100, metric = 6.87% * 100;
 Minibatch[1601-1700]: loss = 0.447450 * 100, metric = 6.62% * 100;
 Minibatch[1701-1800]: loss = 0.451848 * 100, metric = 6.69% * 100;
 Minibatch[1801-1900]: loss = 0.451077 * 100, metric = 6.65% * 100;
 Minibatch[1901-2000]: loss = 0.440334 * 100, metric = 6.41% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.451115 * 2000, metric = 6.58% * 2000 944.162s (  2.1 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 15.00% * 2000;
 Minibatch[   1- 100]: loss = 0.452891 * 100, metric = 6.40% * 100;
 Minibatch[ 101- 200]: loss = 0.448472 * 100, metric = 6.40% * 100;
 Minibatch[ 201- 300]: loss = 0.444065 * 100, metric = 6.48% * 100;
 Minibatch[ 301- 400]: loss = 0.444992 * 100, metric = 6.49% * 100;
 Minibatch[ 401- 500]: loss = 0.437986 * 100, metric = 6.48% * 100;
 Minibatch[ 501- 600]: loss = 0.429568 * 100, metric = 6.08% * 100;
 Minibatch[ 601- 700]: loss = 0.432884 * 100, metric = 6.16% * 100;
 Minibatch[ 701- 800]: loss = 0.412736 * 100, metric = 5.96% * 100;
 Minibatch[ 801- 900]: loss = 0.441375 * 100, metric = 6.36% * 100;
 Minibatch[ 901-1000]: loss = 0.428822 * 100, metric = 6.20% * 100;
 Minibatch[1001-1100]: loss = 0.441329 * 100, metric = 6.50% * 100;
 Minibatch[1101-1200]: loss = 0.434190 * 100, metric = 6.25% * 100;
 Minibatch[1201-1300]: loss = 0.439443 * 100, metric = 6.32% * 100;
 Minibatch[1301-1400]: loss = 0.430058 * 100, metric = 6.16% * 100;
 Minibatch[1401-1500]: loss = 0.443593 * 100, metric = 6.44% * 100;
 Minibatch[1501-1600]: loss = 0.441160 * 100, metric = 6.61% * 100;
 Minibatch[1601-1700]: loss = 0.434696 * 100, metric = 6.22% * 100;
 Minibatch[1701-1800]: loss = 0.438860 * 100, metric = 6.09% * 100;
 Minibatch[1801-1900]: loss = 0.446804 * 100, metric = 6.32% * 100;
 Minibatch[1901-2000]: loss = 0.419723 * 100, metric = 5.94% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.437182 * 2000, metric = 6.29% * 2000 933.958s (  2.1 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 13.38% * 2000;
0.5870396222248674
 Minibatch[   1- 100]: loss = 0.441243 * 100, metric = 6.13% * 100;
 Minibatch[ 101- 200]: loss = 0.436840 * 100, metric = 6.12% * 100;
 Minibatch[ 201- 300]: loss = 0.447541 * 100, metric = 6.37% * 100;
 Minibatch[ 301- 400]: loss = 0.431421 * 100, metric = 6.26% * 100;
 Minibatch[ 401- 500]: loss = 0.432268 * 100, metric = 6.04% * 100;
 Minibatch[ 501- 600]: loss = 0.444588 * 100, metric = 6.27% * 100;
 Minibatch[ 601- 700]: loss = 0.430659 * 100, metric = 6.12% * 100;
 Minibatch[ 701- 800]: loss = 0.439082 * 100, metric = 6.35% * 100;
 Minibatch[ 801- 900]: loss = 0.442121 * 100, metric = 6.40% * 100;
 Minibatch[ 901-1000]: loss = 0.445477 * 100, metric = 6.27% * 100;
 Minibatch[1001-1100]: loss = 0.425807 * 100, metric = 6.00% * 100;
 Minibatch[1101-1200]: loss = 0.420944 * 100, metric = 5.75% * 100;
 Minibatch[1201-1300]: loss = 0.439947 * 100, metric = 6.28% * 100;
 Minibatch[1301-1400]: loss = 0.445814 * 100, metric = 6.40% * 100;
 Minibatch[1401-1500]: loss = 0.426317 * 100, metric = 6.12% * 100;
 Minibatch[1501-1600]: loss = 0.426277 * 100, metric = 5.81% * 100;
 Minibatch[1601-1700]: loss = 0.422927 * 100, metric = 5.93% * 100;
 Minibatch[1701-1800]: loss = 0.427123 * 100, metric = 6.01% * 100;
 Minibatch[1801-1900]: loss = 0.433476 * 100, metric = 6.12% * 100;
 Minibatch[1901-2000]: loss = 0.426768 * 100, metric = 5.91% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.434332 * 2000, metric = 6.13% * 2000 956.671s (  2.1 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 14.56% * 2000;
 Minibatch[   1- 100]: loss = 0.438332 * 100, metric = 6.20% * 100;
 Minibatch[ 101- 200]: loss = 0.445990 * 100, metric = 6.46% * 100;
 Minibatch[ 201- 300]: loss = 0.428067 * 100, metric = 5.93% * 100;
 Minibatch[ 301- 400]: loss = 0.445319 * 100, metric = 6.33% * 100;
 Minibatch[ 401- 500]: loss = 0.441768 * 100, metric = 6.46% * 100;
 Minibatch[ 501- 600]: loss = 0.432638 * 100, metric = 6.17% * 100;
 Minibatch[ 601- 700]: loss = 0.438987 * 100, metric = 6.04% * 100;
 Minibatch[ 701- 800]: loss = 0.421147 * 100, metric = 5.82% * 100;
 Minibatch[ 801- 900]: loss = 0.417927 * 100, metric = 6.11% * 100;
 Minibatch[ 901-1000]: loss = 0.441673 * 100, metric = 6.17% * 100;
 Minibatch[1001-1100]: loss = 0.424559 * 100, metric = 5.79% * 100;
 Minibatch[1101-1200]: loss = 0.425076 * 100, metric = 5.90% * 100;
 Minibatch[1201-1300]: loss = 0.432184 * 100, metric = 5.97% * 100;
 Minibatch[1301-1400]: loss = 0.438251 * 100, metric = 6.19% * 100;
 Minibatch[1401-1500]: loss = 0.425059 * 100, metric = 6.03% * 100;
 Minibatch[1501-1600]: loss = 0.422460 * 100, metric = 5.85% * 100;
 Minibatch[1601-1700]: loss = 0.428594 * 100, metric = 6.08% * 100;
 Minibatch[1701-1800]: loss = 0.434243 * 100, metric = 6.15% * 100;
 Minibatch[1801-1900]: loss = 0.418091 * 100, metric = 6.12% * 100;
 Minibatch[1901-2000]: loss = 0.421669 * 100, metric = 5.81% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.431102 * 2000, metric = 6.08% * 2000 945.385s (  2.1 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 15.48% * 2000;
 Minibatch[   1- 100]: loss = 0.410562 * 100, metric = 5.78% * 100;
 Minibatch[ 101- 200]: loss = 0.427625 * 100, metric = 6.02% * 100;
 Minibatch[ 201- 300]: loss = 0.417072 * 100, metric = 5.97% * 100;
 Minibatch[ 301- 400]: loss = 0.423774 * 100, metric = 5.89% * 100;
 Minibatch[ 401- 500]: loss = 0.429159 * 100, metric = 6.08% * 100;
 Minibatch[ 501- 600]: loss = 0.414610 * 100, metric = 5.76% * 100;
 Minibatch[ 601- 700]: loss = 0.431735 * 100, metric = 6.09% * 100;
 Minibatch[ 701- 800]: loss = 0.420697 * 100, metric = 5.89% * 100;
 Minibatch[ 801- 900]: loss = 0.436360 * 100, metric = 6.19% * 100;
 Minibatch[ 901-1000]: loss = 0.425998 * 100, metric = 5.98% * 100;
 Minibatch[1001-1100]: loss = 0.421971 * 100, metric = 5.92% * 100;
 Minibatch[1101-1200]: loss = 0.437347 * 100, metric = 6.14% * 100;
 Minibatch[1201-1300]: loss = 0.430425 * 100, metric = 6.08% * 100;
 Minibatch[1301-1400]: loss = 0.422886 * 100, metric = 5.91% * 100;
 Minibatch[1401-1500]: loss = 0.417623 * 100, metric = 5.76% * 100;
 Minibatch[1501-1600]: loss = 0.427505 * 100, metric = 6.07% * 100;
 Minibatch[1601-1700]: loss = 0.411978 * 100, metric = 5.74% * 100;
 Minibatch[1701-1800]: loss = 0.412607 * 100, metric = 5.80% * 100;
 Minibatch[1801-1900]: loss = 0.422079 * 100, metric = 6.07% * 100;
 Minibatch[1901-2000]: loss = 0.430018 * 100, metric = 6.11% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.423602 * 2000, metric = 5.96% * 2000 958.743s (  2.1 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.69% * 2000;
 Minibatch[   1- 100]: loss = 0.436316 * 100, metric = 6.20% * 100;
 Minibatch[ 101- 200]: loss = 0.429393 * 100, metric = 6.24% * 100;
 Minibatch[ 201- 300]: loss = 0.426613 * 100, metric = 6.20% * 100;
 Minibatch[ 301- 400]: loss = 0.429356 * 100, metric = 6.09% * 100;
 Minibatch[ 401- 500]: loss = 0.425945 * 100, metric = 6.07% * 100;
 Minibatch[ 501- 600]: loss = 0.422829 * 100, metric = 6.05% * 100;
 Minibatch[ 601- 700]: loss = 0.434313 * 100, metric = 6.29% * 100;
 Minibatch[ 701- 800]: loss = 0.410539 * 100, metric = 5.67% * 100;
 Minibatch[ 801- 900]: loss = 0.414025 * 100, metric = 5.84% * 100;
 Minibatch[ 901-1000]: loss = 0.428595 * 100, metric = 6.08% * 100;
 Minibatch[1001-1100]: loss = 0.433247 * 100, metric = 6.17% * 100;
 Minibatch[1101-1200]: loss = 0.440309 * 100, metric = 6.34% * 100;
 Minibatch[1201-1300]: loss = 0.449936 * 100, metric = 6.63% * 100;
 Minibatch[1301-1400]: loss = 0.418911 * 100, metric = 5.67% * 100;
 Minibatch[1401-1500]: loss = 0.417205 * 100, metric = 5.68% * 100;
 Minibatch[1501-1600]: loss = 0.436781 * 100, metric = 6.34% * 100;
 Minibatch[1601-1700]: loss = 0.420363 * 100, metric = 5.89% * 100;
 Minibatch[1701-1800]: loss = 0.429448 * 100, metric = 6.09% * 100;
 Minibatch[1801-1900]: loss = 0.417092 * 100, metric = 5.77% * 100;
 Minibatch[1901-2000]: loss = 0.408421 * 100, metric = 5.53% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.426482 * 2000, metric = 6.04% * 2000 950.282s (  2.1 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.41% * 2000;
 Minibatch[   1- 100]: loss = 0.414508 * 100, metric = 5.80% * 100;
 Minibatch[ 101- 200]: loss = 0.403938 * 100, metric = 5.44% * 100;
 Minibatch[ 201- 300]: loss = 0.420091 * 100, metric = 5.89% * 100;
 Minibatch[ 301- 400]: loss = 0.414822 * 100, metric = 5.74% * 100;
 Minibatch[ 401- 500]: loss = 0.423979 * 100, metric = 6.10% * 100;
 Minibatch[ 501- 600]: loss = 0.407576 * 100, metric = 5.61% * 100;
 Minibatch[ 601- 700]: loss = 0.426800 * 100, metric = 6.05% * 100;
 Minibatch[ 701- 800]: loss = 0.408990 * 100, metric = 5.74% * 100;
 Minibatch[ 801- 900]: loss = 0.406895 * 100, metric = 5.55% * 100;
 Minibatch[ 901-1000]: loss = 0.404524 * 100, metric = 5.62% * 100;
 Minibatch[1001-1100]: loss = 0.417319 * 100, metric = 6.00% * 100;
 Minibatch[1101-1200]: loss = 0.430090 * 100, metric = 6.07% * 100;
 Minibatch[1201-1300]: loss = 0.414055 * 100, metric = 5.67% * 100;
 Minibatch[1301-1400]: loss = 0.406040 * 100, metric = 5.46% * 100;
 Minibatch[1401-1500]: loss = 0.411362 * 100, metric = 5.87% * 100;
 Minibatch[1501-1600]: loss = 0.416534 * 100, metric = 5.53% * 100;
 Minibatch[1601-1700]: loss = 0.439568 * 100, metric = 6.37% * 100;
 Minibatch[1701-1800]: loss = 0.431868 * 100, metric = 6.17% * 100;
 Minibatch[1801-1900]: loss = 0.418561 * 100, metric = 5.84% * 100;
 Minibatch[1901-2000]: loss = 0.425549 * 100, metric = 5.99% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.417153 * 2000, metric = 5.83% * 2000 944.348s (  2.1 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.20% * 2000;
 Minibatch[   1- 100]: loss = 0.411468 * 100, metric = 5.52% * 100;
 Minibatch[ 101- 200]: loss = 0.429102 * 100, metric = 6.08% * 100;
 Minibatch[ 201- 300]: loss = 0.416726 * 100, metric = 6.00% * 100;
 Minibatch[ 301- 400]: loss = 0.409249 * 100, metric = 5.58% * 100;
 Minibatch[ 401- 500]: loss = 0.420026 * 100, metric = 5.96% * 100;
 Minibatch[ 501- 600]: loss = 0.409996 * 100, metric = 5.71% * 100;
 Minibatch[ 601- 700]: loss = 0.414851 * 100, metric = 5.78% * 100;
 Minibatch[ 701- 800]: loss = 0.413616 * 100, metric = 5.77% * 100;
 Minibatch[ 801- 900]: loss = 0.426846 * 100, metric = 5.96% * 100;
 Minibatch[ 901-1000]: loss = 0.427527 * 100, metric = 6.32% * 100;
 Minibatch[1001-1100]: loss = 0.407726 * 100, metric = 5.46% * 100;
 Minibatch[1101-1200]: loss = 0.424253 * 100, metric = 5.99% * 100;
 Minibatch[1201-1300]: loss = 0.412328 * 100, metric = 5.85% * 100;
 Minibatch[1301-1400]: loss = 0.417709 * 100, metric = 6.05% * 100;
 Minibatch[1401-1500]: loss = 0.410629 * 100, metric = 5.84% * 100;
 Minibatch[1501-1600]: loss = 0.411466 * 100, metric = 5.82% * 100;
 Minibatch[1601-1700]: loss = 0.388666 * 100, metric = 5.24% * 100;
 Minibatch[1701-1800]: loss = 0.409526 * 100, metric = 5.66% * 100;
 Minibatch[1801-1900]: loss = 0.411705 * 100, metric = 5.72% * 100;
 Minibatch[1901-2000]: loss = 0.413947 * 100, metric = 5.51% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.414368 * 2000, metric = 5.79% * 2000 934.764s (  2.1 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 14.03% * 2000;
 Minibatch[   1- 100]: loss = 0.419469 * 100, metric = 6.07% * 100;
 Minibatch[ 101- 200]: loss = 0.405822 * 100, metric = 5.57% * 100;
 Minibatch[ 201- 300]: loss = 0.417613 * 100, metric = 6.02% * 100;
 Minibatch[ 301- 400]: loss = 0.415072 * 100, metric = 5.92% * 100;
 Minibatch[ 401- 500]: loss = 0.413564 * 100, metric = 5.85% * 100;
 Minibatch[ 501- 600]: loss = 0.432976 * 100, metric = 6.20% * 100;
 Minibatch[ 601- 700]: loss = 0.411192 * 100, metric = 5.82% * 100;
 Minibatch[ 701- 800]: loss = 0.395085 * 100, metric = 5.42% * 100;
 Minibatch[ 801- 900]: loss = 0.411696 * 100, metric = 5.84% * 100;
 Minibatch[ 901-1000]: loss = 0.416076 * 100, metric = 5.94% * 100;
 Minibatch[1001-1100]: loss = 0.409889 * 100, metric = 5.63% * 100;
 Minibatch[1101-1200]: loss = 0.399794 * 100, metric = 5.33% * 100;
 Minibatch[1201-1300]: loss = 0.412281 * 100, metric = 5.81% * 100;
 Minibatch[1301-1400]: loss = 0.404412 * 100, metric = 5.61% * 100;
 Minibatch[1401-1500]: loss = 0.415758 * 100, metric = 5.62% * 100;
 Minibatch[1501-1600]: loss = 0.404325 * 100, metric = 5.47% * 100;
 Minibatch[1601-1700]: loss = 0.404418 * 100, metric = 5.37% * 100;
 Minibatch[1701-1800]: loss = 0.402195 * 100, metric = 5.45% * 100;
 Minibatch[1801-1900]: loss = 0.408796 * 100, metric = 5.79% * 100;
 Minibatch[1901-2000]: loss = 0.411332 * 100, metric = 5.71% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.410588 * 2000, metric = 5.72% * 2000 936.059s (  2.1 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.46% * 2000;
 Minibatch[   1- 100]: loss = 0.392484 * 100, metric = 5.21% * 100;
 Minibatch[ 101- 200]: loss = 0.399615 * 100, metric = 5.68% * 100;
 Minibatch[ 201- 300]: loss = 0.408839 * 100, metric = 5.80% * 100;
 Minibatch[ 301- 400]: loss = 0.430883 * 100, metric = 6.18% * 100;
 Minibatch[ 401- 500]: loss = 0.405033 * 100, metric = 5.49% * 100;
 Minibatch[ 501- 600]: loss = 0.411434 * 100, metric = 5.87% * 100;
 Minibatch[ 601- 700]: loss = 0.403889 * 100, metric = 5.79% * 100;
 Minibatch[ 701- 800]: loss = 0.410716 * 100, metric = 5.87% * 100;
 Minibatch[ 801- 900]: loss = 0.414450 * 100, metric = 5.90% * 100;
 Minibatch[ 901-1000]: loss = 0.415902 * 100, metric = 5.70% * 100;
 Minibatch[1001-1100]: loss = 0.408351 * 100, metric = 5.57% * 100;
 Minibatch[1101-1200]: loss = 0.398947 * 100, metric = 5.59% * 100;
 Minibatch[1201-1300]: loss = 0.411208 * 100, metric = 5.76% * 100;
 Minibatch[1301-1400]: loss = 0.398585 * 100, metric = 5.44% * 100;
 Minibatch[1401-1500]: loss = 0.419973 * 100, metric = 5.76% * 100;
 Minibatch[1501-1600]: loss = 0.390336 * 100, metric = 5.31% * 100;
 Minibatch[1601-1700]: loss = 0.412350 * 100, metric = 5.72% * 100;
 Minibatch[1701-1800]: loss = 0.400446 * 100, metric = 5.42% * 100;
 Minibatch[1801-1900]: loss = 0.419866 * 100, metric = 5.68% * 100;
 Minibatch[1901-2000]: loss = 0.403751 * 100, metric = 5.39% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.407853 * 2000, metric = 5.66% * 2000 946.716s (  2.1 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 15.16% * 2000;
 Minibatch[   1- 100]: loss = 0.414630 * 100, metric = 5.67% * 100;
 Minibatch[ 101- 200]: loss = 0.393081 * 100, metric = 5.28% * 100;
 Minibatch[ 201- 300]: loss = 0.395625 * 100, metric = 5.30% * 100;
 Minibatch[ 301- 400]: loss = 0.409215 * 100, metric = 5.62% * 100;
 Minibatch[ 401- 500]: loss = 0.402379 * 100, metric = 5.52% * 100;
 Minibatch[ 501- 600]: loss = 0.381632 * 100, metric = 5.04% * 100;
 Minibatch[ 601- 700]: loss = 0.409322 * 100, metric = 5.70% * 100;
 Minibatch[ 701- 800]: loss = 0.400188 * 100, metric = 5.38% * 100;
 Minibatch[ 801- 900]: loss = 0.406380 * 100, metric = 5.62% * 100;
 Minibatch[ 901-1000]: loss = 0.381968 * 100, metric = 5.14% * 100;
 Minibatch[1001-1100]: loss = 0.407195 * 100, metric = 5.65% * 100;
 Minibatch[1101-1200]: loss = 0.404431 * 100, metric = 5.50% * 100;
 Minibatch[1201-1300]: loss = 0.393506 * 100, metric = 5.27% * 100;
 Minibatch[1301-1400]: loss = 0.403220 * 100, metric = 5.63% * 100;
 Minibatch[1401-1500]: loss = 0.405138 * 100, metric = 5.63% * 100;
 Minibatch[1501-1600]: loss = 0.409667 * 100, metric = 5.62% * 100;
 Minibatch[1601-1700]: loss = 0.410562 * 100, metric = 5.71% * 100;
 Minibatch[1701-1800]: loss = 0.404449 * 100, metric = 5.39% * 100;
 Minibatch[1801-1900]: loss = 0.401082 * 100, metric = 5.65% * 100;
 Minibatch[1901-2000]: loss = 0.418460 * 100, metric = 5.88% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.402607 * 2000, metric = 5.51% * 2000 945.864s (  2.1 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 15.15% * 2000;
 Minibatch[   1- 100]: loss = 0.395332 * 100, metric = 5.37% * 100;
 Minibatch[ 101- 200]: loss = 0.410748 * 100, metric = 5.74% * 100;
 Minibatch[ 201- 300]: loss = 0.405030 * 100, metric = 5.46% * 100;
 Minibatch[ 301- 400]: loss = 0.395032 * 100, metric = 5.52% * 100;
 Minibatch[ 401- 500]: loss = 0.388787 * 100, metric = 5.27% * 100;
 Minibatch[ 501- 600]: loss = 0.394212 * 100, metric = 5.48% * 100;
 Minibatch[ 601- 700]: loss = 0.407715 * 100, metric = 5.75% * 100;
 Minibatch[ 701- 800]: loss = 0.410522 * 100, metric = 5.63% * 100;
 Minibatch[ 801- 900]: loss = 0.404574 * 100, metric = 5.50% * 100;
 Minibatch[ 901-1000]: loss = 0.396435 * 100, metric = 5.33% * 100;
 Minibatch[1001-1100]: loss = 0.390925 * 100, metric = 5.27% * 100;
 Minibatch[1101-1200]: loss = 0.400438 * 100, metric = 5.65% * 100;
 Minibatch[1201-1300]: loss = 0.404430 * 100, metric = 5.55% * 100;
 Minibatch[1301-1400]: loss = 0.408712 * 100, metric = 5.71% * 100;
 Minibatch[1401-1500]: loss = 0.409984 * 100, metric = 5.77% * 100;
 Minibatch[1501-1600]: loss = 0.394479 * 100, metric = 5.46% * 100;
 Minibatch[1601-1700]: loss = 0.397871 * 100, metric = 5.49% * 100;
 Minibatch[1701-1800]: loss = 0.401107 * 100, metric = 5.66% * 100;
 Minibatch[1801-1900]: loss = 0.409855 * 100, metric = 5.96% * 100;
 Minibatch[1901-2000]: loss = 0.404870 * 100, metric = 5.74% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.401553 * 2000, metric = 5.57% * 2000 951.501s (  2.1 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 14.02% * 2000;
 Minibatch[   1- 100]: loss = 0.404437 * 100, metric = 5.54% * 100;
 Minibatch[ 101- 200]: loss = 0.399512 * 100, metric = 5.39% * 100;
 Minibatch[ 201- 300]: loss = 0.407429 * 100, metric = 5.83% * 100;
 Minibatch[ 301- 400]: loss = 0.416256 * 100, metric = 5.89% * 100;
 Minibatch[ 401- 500]: loss = 0.403930 * 100, metric = 5.67% * 100;
 Minibatch[ 501- 600]: loss = 0.400864 * 100, metric = 5.69% * 100;
 Minibatch[ 601- 700]: loss = 0.395901 * 100, metric = 5.53% * 100;
 Minibatch[ 701- 800]: loss = 0.399395 * 100, metric = 5.47% * 100;
 Minibatch[ 801- 900]: loss = 0.392176 * 100, metric = 5.39% * 100;
 Minibatch[ 901-1000]: loss = 0.384552 * 100, metric = 5.35% * 100;
 Minibatch[1001-1100]: loss = 0.390040 * 100, metric = 5.18% * 100;
 Minibatch[1101-1200]: loss = 0.402815 * 100, metric = 5.52% * 100;
 Minibatch[1201-1300]: loss = 0.415514 * 100, metric = 5.83% * 100;
 Minibatch[1301-1400]: loss = 0.397231 * 100, metric = 5.59% * 100;
 Minibatch[1401-1500]: loss = 0.397536 * 100, metric = 5.75% * 100;
 Minibatch[1501-1600]: loss = 0.404081 * 100, metric = 5.62% * 100;
 Minibatch[1601-1700]: loss = 0.393557 * 100, metric = 5.50% * 100;
 Minibatch[1701-1800]: loss = 0.404565 * 100, metric = 5.58% * 100;
 Minibatch[1801-1900]: loss = 0.384379 * 100, metric = 5.09% * 100;
 Minibatch[1901-2000]: loss = 0.403842 * 100, metric = 5.85% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.399901 * 2000, metric = 5.56% * 2000 942.094s (  2.1 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.93% * 2000;
 Minibatch[   1- 100]: loss = 0.411487 * 100, metric = 5.79% * 100;
 Minibatch[ 101- 200]: loss = 0.399889 * 100, metric = 5.74% * 100;
 Minibatch[ 201- 300]: loss = 0.384159 * 100, metric = 5.27% * 100;
 Minibatch[ 301- 400]: loss = 0.401423 * 100, metric = 5.70% * 100;
 Minibatch[ 401- 500]: loss = 0.390132 * 100, metric = 5.32% * 100;
 Minibatch[ 501- 600]: loss = 0.401570 * 100, metric = 5.52% * 100;
 Minibatch[ 601- 700]: loss = 0.404201 * 100, metric = 5.75% * 100;
 Minibatch[ 701- 800]: loss = 0.400291 * 100, metric = 5.49% * 100;
 Minibatch[ 801- 900]: loss = 0.390026 * 100, metric = 5.10% * 100;
 Minibatch[ 901-1000]: loss = 0.379236 * 100, metric = 5.10% * 100;
 Minibatch[1001-1100]: loss = 0.391721 * 100, metric = 5.39% * 100;
 Minibatch[1101-1200]: loss = 0.380812 * 100, metric = 5.12% * 100;
 Minibatch[1201-1300]: loss = 0.404507 * 100, metric = 5.48% * 100;
 Minibatch[1301-1400]: loss = 0.384340 * 100, metric = 4.97% * 100;
 Minibatch[1401-1500]: loss = 0.402236 * 100, metric = 5.59% * 100;
 Minibatch[1501-1600]: loss = 0.401616 * 100, metric = 5.55% * 100;
 Minibatch[1601-1700]: loss = 0.392243 * 100, metric = 5.30% * 100;
 Minibatch[1701-1800]: loss = 0.394568 * 100, metric = 5.42% * 100;
 Minibatch[1801-1900]: loss = 0.382045 * 100, metric = 5.02% * 100;
 Minibatch[1901-2000]: loss = 0.399451 * 100, metric = 5.81% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.394798 * 2000, metric = 5.42% * 2000 938.549s (  2.1 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.89% * 2000;
 Minibatch[   1- 100]: loss = 0.391220 * 100, metric = 5.55% * 100;
 Minibatch[ 101- 200]: loss = 0.398634 * 100, metric = 5.47% * 100;
 Minibatch[ 201- 300]: loss = 0.382065 * 100, metric = 5.21% * 100;
 Minibatch[ 301- 400]: loss = 0.393830 * 100, metric = 5.49% * 100;
 Minibatch[ 401- 500]: loss = 0.374133 * 100, metric = 4.99% * 100;
 Minibatch[ 501- 600]: loss = 0.389258 * 100, metric = 5.24% * 100;
 Minibatch[ 601- 700]: loss = 0.392047 * 100, metric = 5.46% * 100;
 Minibatch[ 701- 800]: loss = 0.389095 * 100, metric = 5.28% * 100;
 Minibatch[ 801- 900]: loss = 0.375485 * 100, metric = 4.91% * 100;
 Minibatch[ 901-1000]: loss = 0.385173 * 100, metric = 5.41% * 100;
 Minibatch[1001-1100]: loss = 0.389827 * 100, metric = 5.42% * 100;
 Minibatch[1101-1200]: loss = 0.384236 * 100, metric = 5.38% * 100;
 Minibatch[1201-1300]: loss = 0.402497 * 100, metric = 5.55% * 100;
 Minibatch[1301-1400]: loss = 0.392683 * 100, metric = 5.61% * 100;
 Minibatch[1401-1500]: loss = 0.400691 * 100, metric = 5.50% * 100;
 Minibatch[1501-1600]: loss = 0.395067 * 100, metric = 5.18% * 100;
 Minibatch[1601-1700]: loss = 0.405302 * 100, metric = 5.83% * 100;
 Minibatch[1701-1800]: loss = 0.387727 * 100, metric = 5.20% * 100;
 Minibatch[1801-1900]: loss = 0.390227 * 100, metric = 5.35% * 100;
 Minibatch[1901-2000]: loss = 0.387732 * 100, metric = 5.13% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.390346 * 2000, metric = 5.36% * 2000 938.777s (  2.1 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.77% * 2000;
 Minibatch[   1- 100]: loss = 0.365592 * 100, metric = 4.64% * 100;
 Minibatch[ 101- 200]: loss = 0.386746 * 100, metric = 5.18% * 100;
 Minibatch[ 201- 300]: loss = 0.390154 * 100, metric = 5.32% * 100;
 Minibatch[ 301- 400]: loss = 0.367146 * 100, metric = 4.89% * 100;
 Minibatch[ 401- 500]: loss = 0.379660 * 100, metric = 5.07% * 100;
 Minibatch[ 501- 600]: loss = 0.357315 * 100, metric = 4.59% * 100;
 Minibatch[ 601- 700]: loss = 0.387945 * 100, metric = 5.18% * 100;
 Minibatch[ 701- 800]: loss = 0.364035 * 100, metric = 4.72% * 100;
 Minibatch[ 801- 900]: loss = 0.391726 * 100, metric = 5.28% * 100;
 Minibatch[ 901-1000]: loss = 0.376159 * 100, metric = 5.08% * 100;
 Minibatch[1001-1100]: loss = 0.397446 * 100, metric = 5.34% * 100;
 Minibatch[1101-1200]: loss = 0.387166 * 100, metric = 5.28% * 100;
 Minibatch[1201-1300]: loss = 0.385099 * 100, metric = 5.29% * 100;
 Minibatch[1301-1400]: loss = 0.384855 * 100, metric = 5.29% * 100;
 Minibatch[1401-1500]: loss = 0.381227 * 100, metric = 4.98% * 100;
 Minibatch[1501-1600]: loss = 0.384743 * 100, metric = 5.23% * 100;
 Minibatch[1601-1700]: loss = 0.386599 * 100, metric = 5.32% * 100;
 Minibatch[1701-1800]: loss = 0.373519 * 100, metric = 4.94% * 100;
 Minibatch[1801-1900]: loss = 0.392521 * 100, metric = 5.16% * 100;
 Minibatch[1901-2000]: loss = 0.380389 * 100, metric = 5.06% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.381002 * 2000, metric = 5.09% * 2000 934.779s (  2.1 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 14.58% * 2000;
 Minibatch[   1- 100]: loss = 0.381629 * 100, metric = 5.14% * 100;
 Minibatch[ 101- 200]: loss = 0.368548 * 100, metric = 4.84% * 100;
 Minibatch[ 201- 300]: loss = 0.402894 * 100, metric = 5.68% * 100;
 Minibatch[ 301- 400]: loss = 0.374988 * 100, metric = 5.01% * 100;
 Minibatch[ 401- 500]: loss = 0.379659 * 100, metric = 5.11% * 100;
 Minibatch[ 501- 600]: loss = 0.380994 * 100, metric = 4.93% * 100;
 Minibatch[ 601- 700]: loss = 0.387460 * 100, metric = 4.95% * 100;
 Minibatch[ 701- 800]: loss = 0.367835 * 100, metric = 4.81% * 100;
 Minibatch[ 801- 900]: loss = 0.372746 * 100, metric = 5.00% * 100;
 Minibatch[ 901-1000]: loss = 0.394175 * 100, metric = 5.44% * 100;
 Minibatch[1001-1100]: loss = 0.391519 * 100, metric = 5.56% * 100;
 Minibatch[1101-1200]: loss = 0.378672 * 100, metric = 5.16% * 100;
 Minibatch[1201-1300]: loss = 0.387852 * 100, metric = 5.23% * 100;
 Minibatch[1301-1400]: loss = 0.365309 * 100, metric = 4.72% * 100;
 Minibatch[1401-1500]: loss = 0.382539 * 100, metric = 5.13% * 100;
 Minibatch[1501-1600]: loss = 0.379132 * 100, metric = 4.96% * 100;
 Minibatch[1601-1700]: loss = 0.390977 * 100, metric = 5.27% * 100;
 Minibatch[1701-1800]: loss = 0.380604 * 100, metric = 5.11% * 100;
 Minibatch[1801-1900]: loss = 0.380833 * 100, metric = 5.04% * 100;
 Minibatch[1901-2000]: loss = 0.381683 * 100, metric = 5.05% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.381502 * 2000, metric = 5.11% * 2000 935.063s (  2.1 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.83% * 2000;
 Minibatch[   1- 100]: loss = 0.383665 * 100, metric = 5.11% * 100;
 Minibatch[ 101- 200]: loss = 0.379826 * 100, metric = 5.15% * 100;
 Minibatch[ 201- 300]: loss = 0.386079 * 100, metric = 5.33% * 100;
 Minibatch[ 301- 400]: loss = 0.381347 * 100, metric = 5.05% * 100;
 Minibatch[ 401- 500]: loss = 0.377200 * 100, metric = 5.17% * 100;
 Minibatch[ 501- 600]: loss = 0.367283 * 100, metric = 4.87% * 100;
 Minibatch[ 601- 700]: loss = 0.382664 * 100, metric = 5.17% * 100;
 Minibatch[ 701- 800]: loss = 0.394216 * 100, metric = 5.43% * 100;
 Minibatch[ 801- 900]: loss = 0.385437 * 100, metric = 5.21% * 100;
 Minibatch[ 901-1000]: loss = 0.368367 * 100, metric = 4.68% * 100;
 Minibatch[1001-1100]: loss = 0.375539 * 100, metric = 5.06% * 100;
 Minibatch[1101-1200]: loss = 0.394506 * 100, metric = 5.42% * 100;
 Minibatch[1201-1300]: loss = 0.390645 * 100, metric = 5.29% * 100;
 Minibatch[1301-1400]: loss = 0.382475 * 100, metric = 4.91% * 100;
 Minibatch[1401-1500]: loss = 0.380105 * 100, metric = 5.10% * 100;
 Minibatch[1501-1600]: loss = 0.374990 * 100, metric = 4.90% * 100;
 Minibatch[1601-1700]: loss = 0.375159 * 100, metric = 5.06% * 100;
 Minibatch[1701-1800]: loss = 0.377930 * 100, metric = 4.87% * 100;
 Minibatch[1801-1900]: loss = 0.384272 * 100, metric = 5.14% * 100;
 Minibatch[1901-2000]: loss = 0.382654 * 100, metric = 5.02% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.381218 * 2000, metric = 5.10% * 2000 944.151s (  2.1 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 14.27% * 2000;
 Minibatch[   1- 100]: loss = 0.392806 * 100, metric = 5.26% * 100;
 Minibatch[ 101- 200]: loss = 0.386513 * 100, metric = 5.18% * 100;
 Minibatch[ 201- 300]: loss = 0.375328 * 100, metric = 4.97% * 100;
 Minibatch[ 301- 400]: loss = 0.375594 * 100, metric = 4.99% * 100;
 Minibatch[ 401- 500]: loss = 0.386824 * 100, metric = 5.09% * 100;
 Minibatch[ 501- 600]: loss = 0.386690 * 100, metric = 5.10% * 100;
 Minibatch[ 601- 700]: loss = 0.381214 * 100, metric = 4.98% * 100;
 Minibatch[ 701- 800]: loss = 0.381278 * 100, metric = 4.96% * 100;
 Minibatch[ 801- 900]: loss = 0.381269 * 100, metric = 5.12% * 100;
 Minibatch[ 901-1000]: loss = 0.391848 * 100, metric = 5.23% * 100;
 Minibatch[1001-1100]: loss = 0.393608 * 100, metric = 5.36% * 100;
 Minibatch[1101-1200]: loss = 0.366489 * 100, metric = 4.75% * 100;
 Minibatch[1201-1300]: loss = 0.378484 * 100, metric = 5.08% * 100;
 Minibatch[1301-1400]: loss = 0.389715 * 100, metric = 5.13% * 100;
 Minibatch[1401-1500]: loss = 0.389879 * 100, metric = 5.31% * 100;
 Minibatch[1501-1600]: loss = 0.376656 * 100, metric = 4.93% * 100;
 Minibatch[1601-1700]: loss = 0.370543 * 100, metric = 4.72% * 100;
 Minibatch[1701-1800]: loss = 0.375048 * 100, metric = 5.03% * 100;
 Minibatch[1801-1900]: loss = 0.374404 * 100, metric = 4.84% * 100;
 Minibatch[1901-2000]: loss = 0.387460 * 100, metric = 5.16% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.382082 * 2000, metric = 5.06% * 2000 950.231s (  2.1 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 13.43% * 2000;
 Minibatch[   1- 100]: loss = 0.370172 * 100, metric = 4.88% * 100;
 Minibatch[ 101- 200]: loss = 0.376610 * 100, metric = 5.06% * 100;
 Minibatch[ 201- 300]: loss = 0.365963 * 100, metric = 4.68% * 100;
 Minibatch[ 301- 400]: loss = 0.363364 * 100, metric = 4.68% * 100;
 Minibatch[ 401- 500]: loss = 0.378864 * 100, metric = 5.00% * 100;
 Minibatch[ 501- 600]: loss = 0.383519 * 100, metric = 4.97% * 100;
 Minibatch[ 601- 700]: loss = 0.372926 * 100, metric = 4.92% * 100;
 Minibatch[ 701- 800]: loss = 0.380338 * 100, metric = 4.88% * 100;
 Minibatch[ 801- 900]: loss = 0.359608 * 100, metric = 4.61% * 100;
 Minibatch[ 901-1000]: loss = 0.378268 * 100, metric = 4.70% * 100;
 Minibatch[1001-1100]: loss = 0.380403 * 100, metric = 4.99% * 100;
 Minibatch[1101-1200]: loss = 0.372963 * 100, metric = 4.96% * 100;
 Minibatch[1201-1300]: loss = 0.372243 * 100, metric = 4.43% * 100;
 Minibatch[1301-1400]: loss = 0.378807 * 100, metric = 4.91% * 100;
 Minibatch[1401-1500]: loss = 0.377421 * 100, metric = 4.92% * 100;
 Minibatch[1501-1600]: loss = 0.368795 * 100, metric = 4.80% * 100;
 Minibatch[1601-1700]: loss = 0.361943 * 100, metric = 4.56% * 100;
 Minibatch[1701-1800]: loss = 0.376199 * 100, metric = 4.97% * 100;
 Minibatch[1801-1900]: loss = 0.365339 * 100, metric = 4.67% * 100;
 Minibatch[1901-2000]: loss = 0.368652 * 100, metric = 4.74% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.372620 * 2000, metric = 4.82% * 2000 940.012s (  2.1 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.24% * 2000;
 Minibatch[   1- 100]: loss = 0.369937 * 100, metric = 4.85% * 100;
 Minibatch[ 101- 200]: loss = 0.361636 * 100, metric = 4.54% * 100;
 Minibatch[ 201- 300]: loss = 0.374235 * 100, metric = 4.76% * 100;
 Minibatch[ 301- 400]: loss = 0.364706 * 100, metric = 4.67% * 100;
 Minibatch[ 401- 500]: loss = 0.359833 * 100, metric = 4.75% * 100;
 Minibatch[ 501- 600]: loss = 0.366725 * 100, metric = 4.96% * 100;
 Minibatch[ 601- 700]: loss = 0.380841 * 100, metric = 5.07% * 100;
 Minibatch[ 701- 800]: loss = 0.371711 * 100, metric = 4.95% * 100;
 Minibatch[ 801- 900]: loss = 0.372167 * 100, metric = 4.71% * 100;
 Minibatch[ 901-1000]: loss = 0.365112 * 100, metric = 4.67% * 100;
 Minibatch[1001-1100]: loss = 0.379410 * 100, metric = 5.11% * 100;
 Minibatch[1101-1200]: loss = 0.375150 * 100, metric = 4.74% * 100;
 Minibatch[1201-1300]: loss = 0.371494 * 100, metric = 4.87% * 100;
 Minibatch[1301-1400]: loss = 0.373566 * 100, metric = 4.90% * 100;
 Minibatch[1401-1500]: loss = 0.370938 * 100, metric = 4.70% * 100;
 Minibatch[1501-1600]: loss = 0.379653 * 100, metric = 5.03% * 100;
 Minibatch[1601-1700]: loss = 0.371956 * 100, metric = 4.77% * 100;
 Minibatch[1701-1800]: loss = 0.358189 * 100, metric = 4.44% * 100;
 Minibatch[1801-1900]: loss = 0.361201 * 100, metric = 4.50% * 100;
 Minibatch[1901-2000]: loss = 0.371344 * 100, metric = 4.88% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.369990 * 2000, metric = 4.79% * 2000 939.187s (  2.1 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 13.52% * 2000;
 Minibatch[   1- 100]: loss = 0.374966 * 100, metric = 5.08% * 100;
 Minibatch[ 101- 200]: loss = 0.371627 * 100, metric = 4.95% * 100;
 Minibatch[ 201- 300]: loss = 0.370251 * 100, metric = 4.76% * 100;
 Minibatch[ 301- 400]: loss = 0.385056 * 100, metric = 5.30% * 100;
 Minibatch[ 401- 500]: loss = 0.376443 * 100, metric = 4.79% * 100;
 Minibatch[ 501- 600]: loss = 0.370276 * 100, metric = 4.77% * 100;
 Minibatch[ 601- 700]: loss = 0.374846 * 100, metric = 4.95% * 100;
 Minibatch[ 701- 800]: loss = 0.374687 * 100, metric = 5.04% * 100;
 Minibatch[ 801- 900]: loss = 0.369114 * 100, metric = 4.91% * 100;
 Minibatch[ 901-1000]: loss = 0.365179 * 100, metric = 4.82% * 100;
 Minibatch[1001-1100]: loss = 0.369612 * 100, metric = 4.80% * 100;
 Minibatch[1101-1200]: loss = 0.383009 * 100, metric = 4.99% * 100;
 Minibatch[1201-1300]: loss = 0.381935 * 100, metric = 5.10% * 100;
 Minibatch[1301-1400]: loss = 0.352050 * 100, metric = 4.46% * 100;
 Minibatch[1401-1500]: loss = 0.371154 * 100, metric = 4.80% * 100;
 Minibatch[1501-1600]: loss = 0.369095 * 100, metric = 4.70% * 100;
 Minibatch[1601-1700]: loss = 0.374188 * 100, metric = 4.74% * 100;
 Minibatch[1701-1800]: loss = 0.365085 * 100, metric = 4.67% * 100;
 Minibatch[1801-1900]: loss = 0.370652 * 100, metric = 4.83% * 100;
 Minibatch[1901-2000]: loss = 0.364286 * 100, metric = 4.73% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.371676 * 2000, metric = 4.86% * 2000 939.178s (  2.1 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 13.66% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
