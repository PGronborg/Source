Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.322487 * 100, metric = 26.22% * 100;
 Minibatch[ 101- 200]: loss = 0.956508 * 100, metric = 22.62% * 100;
 Minibatch[ 201- 300]: loss = 0.863869 * 100, metric = 21.42% * 100;
 Minibatch[ 301- 400]: loss = 0.857021 * 100, metric = 20.22% * 100;
 Minibatch[ 401- 500]: loss = 0.786558 * 100, metric = 19.09% * 100;
 Minibatch[ 501- 600]: loss = 0.765897 * 100, metric = 17.91% * 100;
 Minibatch[ 601- 700]: loss = 0.727822 * 100, metric = 16.76% * 100;
 Minibatch[ 701- 800]: loss = 0.681752 * 100, metric = 15.41% * 100;
 Minibatch[ 801- 900]: loss = 0.688348 * 100, metric = 15.58% * 100;
 Minibatch[ 901-1000]: loss = 0.707563 * 100, metric = 16.25% * 100;
 Minibatch[1001-1100]: loss = 0.682956 * 100, metric = 15.85% * 100;
 Minibatch[1101-1200]: loss = 0.665477 * 100, metric = 15.33% * 100;
 Minibatch[1201-1300]: loss = 0.667999 * 100, metric = 15.53% * 100;
 Minibatch[1301-1400]: loss = 0.648649 * 100, metric = 14.43% * 100;
 Minibatch[1401-1500]: loss = 0.647837 * 100, metric = 15.08% * 100;
 Minibatch[1501-1600]: loss = 0.625752 * 100, metric = 14.39% * 100;
 Minibatch[1601-1700]: loss = 0.607535 * 100, metric = 13.88% * 100;
 Minibatch[1701-1800]: loss = 0.622909 * 100, metric = 14.01% * 100;
 Minibatch[1801-1900]: loss = 0.612885 * 100, metric = 14.00% * 100;
 Minibatch[1901-2000]: loss = 0.579180 * 100, metric = 13.14% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.735950 * 2000, metric = 16.86% * 2000 1004.123s (  2.0 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 27.63% * 2000;
0.7640074275881052
 Minibatch[   1- 100]: loss = 0.596958 * 100, metric = 13.31% * 100;
 Minibatch[ 101- 200]: loss = 0.609691 * 100, metric = 13.65% * 100;
 Minibatch[ 201- 300]: loss = 0.585271 * 100, metric = 13.05% * 100;
 Minibatch[ 301- 400]: loss = 0.600916 * 100, metric = 13.38% * 100;
 Minibatch[ 401- 500]: loss = 0.581062 * 100, metric = 13.06% * 100;
 Minibatch[ 501- 600]: loss = 0.594288 * 100, metric = 13.06% * 100;
 Minibatch[ 601- 700]: loss = 0.563253 * 100, metric = 12.87% * 100;
 Minibatch[ 701- 800]: loss = 0.573454 * 100, metric = 13.09% * 100;
 Minibatch[ 801- 900]: loss = 0.548833 * 100, metric = 12.74% * 100;
 Minibatch[ 901-1000]: loss = 0.551772 * 100, metric = 12.46% * 100;
 Minibatch[1001-1100]: loss = 0.569758 * 100, metric = 12.97% * 100;
 Minibatch[1101-1200]: loss = 0.559459 * 100, metric = 12.77% * 100;
 Minibatch[1201-1300]: loss = 0.546574 * 100, metric = 12.59% * 100;
 Minibatch[1301-1400]: loss = 0.555410 * 100, metric = 12.57% * 100;
 Minibatch[1401-1500]: loss = 0.537514 * 100, metric = 11.89% * 100;
 Minibatch[1501-1600]: loss = 0.535377 * 100, metric = 12.08% * 100;
 Minibatch[1601-1700]: loss = 0.535235 * 100, metric = 11.97% * 100;
 Minibatch[1701-1800]: loss = 0.547700 * 100, metric = 12.16% * 100;
 Minibatch[1801-1900]: loss = 0.539067 * 100, metric = 12.32% * 100;
 Minibatch[1901-2000]: loss = 0.508655 * 100, metric = 11.25% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.562012 * 2000, metric = 12.66% * 2000 936.087s (  2.1 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 19.81% * 2000;
0.621264884762466
 Minibatch[   1- 100]: loss = 0.536233 * 100, metric = 12.19% * 100;
 Minibatch[ 101- 200]: loss = 0.534249 * 100, metric = 11.95% * 100;
 Minibatch[ 201- 300]: loss = 0.517918 * 100, metric = 11.70% * 100;
 Minibatch[ 301- 400]: loss = 0.533276 * 100, metric = 12.23% * 100;
 Minibatch[ 401- 500]: loss = 0.534106 * 100, metric = 12.18% * 100;
 Minibatch[ 501- 600]: loss = 0.524886 * 100, metric = 11.80% * 100;
 Minibatch[ 601- 700]: loss = 0.522392 * 100, metric = 11.58% * 100;
 Minibatch[ 701- 800]: loss = 0.503313 * 100, metric = 11.16% * 100;
 Minibatch[ 801- 900]: loss = 0.518401 * 100, metric = 11.65% * 100;
 Minibatch[ 901-1000]: loss = 0.497694 * 100, metric = 11.33% * 100;
 Minibatch[1001-1100]: loss = 0.527092 * 100, metric = 11.59% * 100;
 Minibatch[1101-1200]: loss = 0.500103 * 100, metric = 11.39% * 100;
 Minibatch[1201-1300]: loss = 0.512781 * 100, metric = 11.45% * 100;
 Minibatch[1301-1400]: loss = 0.509316 * 100, metric = 11.40% * 100;
 Minibatch[1401-1500]: loss = 0.516045 * 100, metric = 11.80% * 100;
 Minibatch[1501-1600]: loss = 0.495677 * 100, metric = 10.82% * 100;
 Minibatch[1601-1700]: loss = 0.486652 * 100, metric = 10.53% * 100;
 Minibatch[1701-1800]: loss = 0.509752 * 100, metric = 11.55% * 100;
 Minibatch[1801-1900]: loss = 0.497192 * 100, metric = 10.99% * 100;
 Minibatch[1901-2000]: loss = 0.491086 * 100, metric = 10.98% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.513408 * 2000, metric = 11.51% * 2000 917.195s (  2.2 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 19.95% * 2000;
0.6040176531970501
 Minibatch[   1- 100]: loss = 0.512813 * 100, metric = 11.14% * 100;
 Minibatch[ 101- 200]: loss = 0.474841 * 100, metric = 10.36% * 100;
 Minibatch[ 201- 300]: loss = 0.501437 * 100, metric = 11.21% * 100;
 Minibatch[ 301- 400]: loss = 0.473177 * 100, metric = 10.55% * 100;
 Minibatch[ 401- 500]: loss = 0.495175 * 100, metric = 10.95% * 100;
 Minibatch[ 501- 600]: loss = 0.473032 * 100, metric = 10.36% * 100;
 Minibatch[ 601- 700]: loss = 0.477644 * 100, metric = 10.59% * 100;
 Minibatch[ 701- 800]: loss = 0.498992 * 100, metric = 11.18% * 100;
 Minibatch[ 801- 900]: loss = 0.494652 * 100, metric = 10.91% * 100;
 Minibatch[ 901-1000]: loss = 0.475943 * 100, metric = 10.48% * 100;
 Minibatch[1001-1100]: loss = 0.488700 * 100, metric = 10.89% * 100;
 Minibatch[1101-1200]: loss = 0.475733 * 100, metric = 10.50% * 100;
 Minibatch[1201-1300]: loss = 0.480933 * 100, metric = 10.68% * 100;
 Minibatch[1301-1400]: loss = 0.487239 * 100, metric = 10.61% * 100;
 Minibatch[1401-1500]: loss = 0.486073 * 100, metric = 10.94% * 100;
 Minibatch[1501-1600]: loss = 0.455667 * 100, metric = 10.17% * 100;
 Minibatch[1601-1700]: loss = 0.481426 * 100, metric = 10.81% * 100;
 Minibatch[1701-1800]: loss = 0.479078 * 100, metric = 10.64% * 100;
 Minibatch[1801-1900]: loss = 0.463217 * 100, metric = 10.13% * 100;
 Minibatch[1901-2000]: loss = 0.458301 * 100, metric = 9.96% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.481704 * 2000, metric = 10.65% * 2000 924.836s (  2.2 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 20.22% * 2000;
 Minibatch[   1- 100]: loss = 0.474796 * 100, metric = 10.36% * 100;
 Minibatch[ 101- 200]: loss = 0.464003 * 100, metric = 10.24% * 100;
 Minibatch[ 201- 300]: loss = 0.452471 * 100, metric = 9.94% * 100;
 Minibatch[ 301- 400]: loss = 0.479467 * 100, metric = 10.68% * 100;
 Minibatch[ 401- 500]: loss = 0.439777 * 100, metric = 9.15% * 100;
 Minibatch[ 501- 600]: loss = 0.450473 * 100, metric = 9.65% * 100;
 Minibatch[ 601- 700]: loss = 0.458026 * 100, metric = 9.72% * 100;
 Minibatch[ 701- 800]: loss = 0.460132 * 100, metric = 9.93% * 100;
 Minibatch[ 801- 900]: loss = 0.446809 * 100, metric = 9.51% * 100;
 Minibatch[ 901-1000]: loss = 0.456097 * 100, metric = 10.31% * 100;
 Minibatch[1001-1100]: loss = 0.456089 * 100, metric = 9.94% * 100;
 Minibatch[1101-1200]: loss = 0.439195 * 100, metric = 9.71% * 100;
 Minibatch[1201-1300]: loss = 0.459871 * 100, metric = 10.01% * 100;
 Minibatch[1301-1400]: loss = 0.462432 * 100, metric = 10.19% * 100;
 Minibatch[1401-1500]: loss = 0.447211 * 100, metric = 9.87% * 100;
 Minibatch[1501-1600]: loss = 0.449301 * 100, metric = 9.91% * 100;
 Minibatch[1601-1700]: loss = 0.464630 * 100, metric = 10.53% * 100;
 Minibatch[1701-1800]: loss = 0.458637 * 100, metric = 10.19% * 100;
 Minibatch[1801-1900]: loss = 0.457591 * 100, metric = 10.11% * 100;
 Minibatch[1901-2000]: loss = 0.443036 * 100, metric = 9.71% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.456002 * 2000, metric = 9.98% * 2000 917.533s (  2.2 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 18.46% * 2000;
0.5761427393555641
 Minibatch[   1- 100]: loss = 0.445880 * 100, metric = 9.82% * 100;
 Minibatch[ 101- 200]: loss = 0.432501 * 100, metric = 9.52% * 100;
 Minibatch[ 201- 300]: loss = 0.444673 * 100, metric = 9.62% * 100;
 Minibatch[ 301- 400]: loss = 0.441619 * 100, metric = 9.58% * 100;
 Minibatch[ 401- 500]: loss = 0.430993 * 100, metric = 9.62% * 100;
 Minibatch[ 501- 600]: loss = 0.436264 * 100, metric = 9.84% * 100;
 Minibatch[ 601- 700]: loss = 0.431323 * 100, metric = 9.50% * 100;
 Minibatch[ 701- 800]: loss = 0.433753 * 100, metric = 9.48% * 100;
 Minibatch[ 801- 900]: loss = 0.449498 * 100, metric = 10.13% * 100;
 Minibatch[ 901-1000]: loss = 0.432094 * 100, metric = 9.35% * 100;
 Minibatch[1001-1100]: loss = 0.429043 * 100, metric = 9.29% * 100;
 Minibatch[1101-1200]: loss = 0.443759 * 100, metric = 9.59% * 100;
 Minibatch[1201-1300]: loss = 0.455859 * 100, metric = 9.89% * 100;
 Minibatch[1301-1400]: loss = 0.434711 * 100, metric = 9.63% * 100;
 Minibatch[1401-1500]: loss = 0.445720 * 100, metric = 9.72% * 100;
 Minibatch[1501-1600]: loss = 0.424962 * 100, metric = 9.16% * 100;
 Minibatch[1601-1700]: loss = 0.431774 * 100, metric = 9.35% * 100;
 Minibatch[1701-1800]: loss = 0.427906 * 100, metric = 9.24% * 100;
 Minibatch[1801-1900]: loss = 0.443275 * 100, metric = 9.89% * 100;
 Minibatch[1901-2000]: loss = 0.427957 * 100, metric = 9.08% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.437178 * 2000, metric = 9.56% * 2000 909.292s (  2.2 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 18.89% * 2000;
 Minibatch[   1- 100]: loss = 0.429912 * 100, metric = 9.57% * 100;
 Minibatch[ 101- 200]: loss = 0.431866 * 100, metric = 9.41% * 100;
 Minibatch[ 201- 300]: loss = 0.435190 * 100, metric = 9.68% * 100;
 Minibatch[ 301- 400]: loss = 0.426367 * 100, metric = 9.35% * 100;
 Minibatch[ 401- 500]: loss = 0.432737 * 100, metric = 9.22% * 100;
 Minibatch[ 501- 600]: loss = 0.415753 * 100, metric = 9.08% * 100;
 Minibatch[ 601- 700]: loss = 0.429489 * 100, metric = 9.26% * 100;
 Minibatch[ 701- 800]: loss = 0.436401 * 100, metric = 9.52% * 100;
 Minibatch[ 801- 900]: loss = 0.439354 * 100, metric = 9.61% * 100;
 Minibatch[ 901-1000]: loss = 0.437127 * 100, metric = 9.74% * 100;
 Minibatch[1001-1100]: loss = 0.432413 * 100, metric = 9.52% * 100;
 Minibatch[1101-1200]: loss = 0.422090 * 100, metric = 9.22% * 100;
 Minibatch[1201-1300]: loss = 0.437394 * 100, metric = 9.87% * 100;
 Minibatch[1301-1400]: loss = 0.425003 * 100, metric = 9.37% * 100;
 Minibatch[1401-1500]: loss = 0.420453 * 100, metric = 9.26% * 100;
 Minibatch[1501-1600]: loss = 0.437618 * 100, metric = 9.62% * 100;
 Minibatch[1601-1700]: loss = 0.436804 * 100, metric = 9.66% * 100;
 Minibatch[1701-1800]: loss = 0.416007 * 100, metric = 8.92% * 100;
 Minibatch[1801-1900]: loss = 0.427610 * 100, metric = 9.45% * 100;
 Minibatch[1901-2000]: loss = 0.425881 * 100, metric = 9.36% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.429773 * 2000, metric = 9.43% * 2000 910.314s (  2.2 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 15.56% * 2000;
0.5046695410236717
 Minibatch[   1- 100]: loss = 0.439190 * 100, metric = 9.91% * 100;
 Minibatch[ 101- 200]: loss = 0.425714 * 100, metric = 9.56% * 100;
 Minibatch[ 201- 300]: loss = 0.417149 * 100, metric = 9.39% * 100;
 Minibatch[ 301- 400]: loss = 0.418060 * 100, metric = 9.17% * 100;
 Minibatch[ 401- 500]: loss = 0.428280 * 100, metric = 9.53% * 100;
 Minibatch[ 501- 600]: loss = 0.438346 * 100, metric = 9.79% * 100;
 Minibatch[ 601- 700]: loss = 0.402432 * 100, metric = 8.63% * 100;
 Minibatch[ 701- 800]: loss = 0.428443 * 100, metric = 9.26% * 100;
 Minibatch[ 801- 900]: loss = 0.397987 * 100, metric = 8.68% * 100;
 Minibatch[ 901-1000]: loss = 0.397206 * 100, metric = 8.56% * 100;
 Minibatch[1001-1100]: loss = 0.404369 * 100, metric = 8.84% * 100;
 Minibatch[1101-1200]: loss = 0.407136 * 100, metric = 8.80% * 100;
 Minibatch[1201-1300]: loss = 0.422602 * 100, metric = 9.39% * 100;
 Minibatch[1301-1400]: loss = 0.424122 * 100, metric = 9.28% * 100;
 Minibatch[1401-1500]: loss = 0.424147 * 100, metric = 9.23% * 100;
 Minibatch[1501-1600]: loss = 0.419450 * 100, metric = 9.22% * 100;
 Minibatch[1601-1700]: loss = 0.406962 * 100, metric = 8.92% * 100;
 Minibatch[1701-1800]: loss = 0.408765 * 100, metric = 8.78% * 100;
 Minibatch[1801-1900]: loss = 0.408717 * 100, metric = 8.82% * 100;
 Minibatch[1901-2000]: loss = 0.417429 * 100, metric = 9.01% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.416825 * 2000, metric = 9.14% * 2000 890.276s (  2.2 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 15.51% * 2000;
0.4995343255624175
 Minibatch[   1- 100]: loss = 0.389748 * 100, metric = 8.47% * 100;
 Minibatch[ 101- 200]: loss = 0.420787 * 100, metric = 9.29% * 100;
 Minibatch[ 201- 300]: loss = 0.406811 * 100, metric = 9.01% * 100;
 Minibatch[ 301- 400]: loss = 0.415572 * 100, metric = 8.98% * 100;
 Minibatch[ 401- 500]: loss = 0.398628 * 100, metric = 8.44% * 100;
 Minibatch[ 501- 600]: loss = 0.397353 * 100, metric = 8.57% * 100;
 Minibatch[ 601- 700]: loss = 0.395978 * 100, metric = 8.42% * 100;
 Minibatch[ 701- 800]: loss = 0.387335 * 100, metric = 8.33% * 100;
 Minibatch[ 801- 900]: loss = 0.392717 * 100, metric = 8.39% * 100;
 Minibatch[ 901-1000]: loss = 0.398452 * 100, metric = 8.72% * 100;
 Minibatch[1001-1100]: loss = 0.377242 * 100, metric = 8.06% * 100;
 Minibatch[1101-1200]: loss = 0.400588 * 100, metric = 8.67% * 100;
 Minibatch[1201-1300]: loss = 0.393887 * 100, metric = 8.47% * 100;
 Minibatch[1301-1400]: loss = 0.390597 * 100, metric = 8.09% * 100;
 Minibatch[1401-1500]: loss = 0.404294 * 100, metric = 8.68% * 100;
 Minibatch[1501-1600]: loss = 0.405281 * 100, metric = 8.59% * 100;
 Minibatch[1601-1700]: loss = 0.406459 * 100, metric = 8.62% * 100;
 Minibatch[1701-1800]: loss = 0.388667 * 100, metric = 8.23% * 100;
 Minibatch[1801-1900]: loss = 0.390189 * 100, metric = 8.14% * 100;
 Minibatch[1901-2000]: loss = 0.403311 * 100, metric = 8.60% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.398195 * 2000, metric = 8.54% * 2000 894.105s (  2.2 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 15.58% * 2000;
 Minibatch[   1- 100]: loss = 0.407736 * 100, metric = 8.95% * 100;
 Minibatch[ 101- 200]: loss = 0.385662 * 100, metric = 8.04% * 100;
 Minibatch[ 201- 300]: loss = 0.395338 * 100, metric = 8.59% * 100;
 Minibatch[ 301- 400]: loss = 0.390903 * 100, metric = 8.29% * 100;
 Minibatch[ 401- 500]: loss = 0.395159 * 100, metric = 8.52% * 100;
 Minibatch[ 501- 600]: loss = 0.383811 * 100, metric = 8.34% * 100;
 Minibatch[ 601- 700]: loss = 0.385267 * 100, metric = 8.31% * 100;
 Minibatch[ 701- 800]: loss = 0.371427 * 100, metric = 8.02% * 100;
 Minibatch[ 801- 900]: loss = 0.389156 * 100, metric = 8.46% * 100;
 Minibatch[ 901-1000]: loss = 0.394139 * 100, metric = 8.56% * 100;
 Minibatch[1001-1100]: loss = 0.388522 * 100, metric = 8.47% * 100;
 Minibatch[1101-1200]: loss = 0.396171 * 100, metric = 8.63% * 100;
 Minibatch[1201-1300]: loss = 0.395805 * 100, metric = 8.71% * 100;
 Minibatch[1301-1400]: loss = 0.392409 * 100, metric = 8.55% * 100;
 Minibatch[1401-1500]: loss = 0.380051 * 100, metric = 7.96% * 100;
 Minibatch[1501-1600]: loss = 0.383459 * 100, metric = 8.22% * 100;
 Minibatch[1601-1700]: loss = 0.384495 * 100, metric = 8.14% * 100;
 Minibatch[1701-1800]: loss = 0.404902 * 100, metric = 8.49% * 100;
 Minibatch[1801-1900]: loss = 0.408654 * 100, metric = 8.59% * 100;
 Minibatch[1901-2000]: loss = 0.385176 * 100, metric = 8.43% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.390912 * 2000, metric = 8.41% * 2000 880.132s (  2.3 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 15.37% * 2000;
 Minibatch[   1- 100]: loss = 0.373576 * 100, metric = 8.02% * 100;
 Minibatch[ 101- 200]: loss = 0.385483 * 100, metric = 8.18% * 100;
 Minibatch[ 201- 300]: loss = 0.389579 * 100, metric = 8.61% * 100;
 Minibatch[ 301- 400]: loss = 0.382732 * 100, metric = 8.12% * 100;
 Minibatch[ 401- 500]: loss = 0.391218 * 100, metric = 8.21% * 100;
 Minibatch[ 501- 600]: loss = 0.389221 * 100, metric = 8.23% * 100;
 Minibatch[ 601- 700]: loss = 0.376948 * 100, metric = 8.06% * 100;
 Minibatch[ 701- 800]: loss = 0.385573 * 100, metric = 8.34% * 100;
 Minibatch[ 801- 900]: loss = 0.378543 * 100, metric = 7.83% * 100;
 Minibatch[ 901-1000]: loss = 0.390765 * 100, metric = 8.25% * 100;
 Minibatch[1001-1100]: loss = 0.386028 * 100, metric = 8.16% * 100;
 Minibatch[1101-1200]: loss = 0.391868 * 100, metric = 8.47% * 100;
 Minibatch[1201-1300]: loss = 0.379376 * 100, metric = 8.19% * 100;
 Minibatch[1301-1400]: loss = 0.366045 * 100, metric = 7.90% * 100;
 Minibatch[1401-1500]: loss = 0.391487 * 100, metric = 8.29% * 100;
 Minibatch[1501-1600]: loss = 0.378436 * 100, metric = 8.14% * 100;
 Minibatch[1601-1700]: loss = 0.376211 * 100, metric = 8.04% * 100;
 Minibatch[1701-1800]: loss = 0.395710 * 100, metric = 8.52% * 100;
 Minibatch[1801-1900]: loss = 0.380895 * 100, metric = 8.22% * 100;
 Minibatch[1901-2000]: loss = 0.380936 * 100, metric = 8.23% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.383532 * 2000, metric = 8.20% * 2000 892.155s (  2.2 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 14.75% * 2000;
0.4931349147558212
 Minibatch[   1- 100]: loss = 0.360450 * 100, metric = 7.54% * 100;
 Minibatch[ 101- 200]: loss = 0.367582 * 100, metric = 7.62% * 100;
 Minibatch[ 201- 300]: loss = 0.370772 * 100, metric = 8.04% * 100;
 Minibatch[ 301- 400]: loss = 0.393534 * 100, metric = 8.46% * 100;
 Minibatch[ 401- 500]: loss = 0.370529 * 100, metric = 7.92% * 100;
 Minibatch[ 501- 600]: loss = 0.363499 * 100, metric = 7.62% * 100;
 Minibatch[ 601- 700]: loss = 0.369476 * 100, metric = 7.79% * 100;
 Minibatch[ 701- 800]: loss = 0.367412 * 100, metric = 7.76% * 100;
 Minibatch[ 801- 900]: loss = 0.367497 * 100, metric = 7.78% * 100;
 Minibatch[ 901-1000]: loss = 0.372422 * 100, metric = 8.17% * 100;
 Minibatch[1001-1100]: loss = 0.379737 * 100, metric = 8.23% * 100;
 Minibatch[1101-1200]: loss = 0.381700 * 100, metric = 8.20% * 100;
 Minibatch[1201-1300]: loss = 0.381927 * 100, metric = 8.22% * 100;
 Minibatch[1301-1400]: loss = 0.368540 * 100, metric = 7.78% * 100;
 Minibatch[1401-1500]: loss = 0.384662 * 100, metric = 8.24% * 100;
 Minibatch[1501-1600]: loss = 0.361448 * 100, metric = 7.72% * 100;
 Minibatch[1601-1700]: loss = 0.383297 * 100, metric = 8.28% * 100;
 Minibatch[1701-1800]: loss = 0.365493 * 100, metric = 7.74% * 100;
 Minibatch[1801-1900]: loss = 0.372156 * 100, metric = 8.11% * 100;
 Minibatch[1901-2000]: loss = 0.388918 * 100, metric = 8.32% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.373553 * 2000, metric = 7.98% * 2000 884.080s (  2.3 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 15.72% * 2000;
 Minibatch[   1- 100]: loss = 0.379697 * 100, metric = 8.16% * 100;
 Minibatch[ 101- 200]: loss = 0.372728 * 100, metric = 8.05% * 100;
 Minibatch[ 201- 300]: loss = 0.367686 * 100, metric = 7.90% * 100;
 Minibatch[ 301- 400]: loss = 0.367900 * 100, metric = 7.86% * 100;
 Minibatch[ 401- 500]: loss = 0.373533 * 100, metric = 8.07% * 100;
 Minibatch[ 501- 600]: loss = 0.383121 * 100, metric = 8.33% * 100;
 Minibatch[ 601- 700]: loss = 0.362805 * 100, metric = 7.46% * 100;
 Minibatch[ 701- 800]: loss = 0.364180 * 100, metric = 7.75% * 100;
 Minibatch[ 801- 900]: loss = 0.360431 * 100, metric = 7.70% * 100;
 Minibatch[ 901-1000]: loss = 0.368367 * 100, metric = 7.93% * 100;
 Minibatch[1001-1100]: loss = 0.374234 * 100, metric = 8.12% * 100;
 Minibatch[1101-1200]: loss = 0.357905 * 100, metric = 7.45% * 100;
 Minibatch[1201-1300]: loss = 0.365829 * 100, metric = 7.89% * 100;
 Minibatch[1301-1400]: loss = 0.359608 * 100, metric = 7.51% * 100;
 Minibatch[1401-1500]: loss = 0.365305 * 100, metric = 7.75% * 100;
 Minibatch[1501-1600]: loss = 0.350767 * 100, metric = 7.33% * 100;
 Minibatch[1601-1700]: loss = 0.351841 * 100, metric = 7.45% * 100;
 Minibatch[1701-1800]: loss = 0.360820 * 100, metric = 7.65% * 100;
 Minibatch[1801-1900]: loss = 0.352013 * 100, metric = 7.52% * 100;
 Minibatch[1901-2000]: loss = 0.363784 * 100, metric = 7.69% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.365128 * 2000, metric = 7.78% * 2000 881.683s (  2.3 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 17.31% * 2000;
 Minibatch[   1- 100]: loss = 0.357182 * 100, metric = 7.63% * 100;
 Minibatch[ 101- 200]: loss = 0.345298 * 100, metric = 7.26% * 100;
 Minibatch[ 201- 300]: loss = 0.370322 * 100, metric = 8.22% * 100;
 Minibatch[ 301- 400]: loss = 0.365648 * 100, metric = 8.04% * 100;
 Minibatch[ 401- 500]: loss = 0.360556 * 100, metric = 7.77% * 100;
 Minibatch[ 501- 600]: loss = 0.359603 * 100, metric = 7.84% * 100;
 Minibatch[ 601- 700]: loss = 0.360797 * 100, metric = 7.79% * 100;
 Minibatch[ 701- 800]: loss = 0.378330 * 100, metric = 8.19% * 100;
 Minibatch[ 801- 900]: loss = 0.365887 * 100, metric = 8.11% * 100;
 Minibatch[ 901-1000]: loss = 0.366899 * 100, metric = 7.97% * 100;
 Minibatch[1001-1100]: loss = 0.369653 * 100, metric = 7.89% * 100;
 Minibatch[1101-1200]: loss = 0.355654 * 100, metric = 7.55% * 100;
 Minibatch[1201-1300]: loss = 0.342365 * 100, metric = 7.18% * 100;
 Minibatch[1301-1400]: loss = 0.358996 * 100, metric = 7.83% * 100;
 Minibatch[1401-1500]: loss = 0.358629 * 100, metric = 7.70% * 100;
 Minibatch[1501-1600]: loss = 0.348681 * 100, metric = 7.52% * 100;
 Minibatch[1601-1700]: loss = 0.354600 * 100, metric = 7.62% * 100;
 Minibatch[1701-1800]: loss = 0.352701 * 100, metric = 7.48% * 100;
 Minibatch[1801-1900]: loss = 0.353163 * 100, metric = 7.62% * 100;
 Minibatch[1901-2000]: loss = 0.356082 * 100, metric = 7.57% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.359052 * 2000, metric = 7.74% * 2000 881.993s (  2.3 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 15.91% * 2000;
 Minibatch[   1- 100]: loss = 0.346319 * 100, metric = 7.22% * 100;
 Minibatch[ 101- 200]: loss = 0.350295 * 100, metric = 7.62% * 100;
 Minibatch[ 201- 300]: loss = 0.351286 * 100, metric = 7.41% * 100;
 Minibatch[ 301- 400]: loss = 0.343696 * 100, metric = 7.35% * 100;
 Minibatch[ 401- 500]: loss = 0.346258 * 100, metric = 7.28% * 100;
 Minibatch[ 501- 600]: loss = 0.338793 * 100, metric = 7.19% * 100;
 Minibatch[ 601- 700]: loss = 0.330808 * 100, metric = 6.94% * 100;
 Minibatch[ 701- 800]: loss = 0.354310 * 100, metric = 7.52% * 100;
 Minibatch[ 801- 900]: loss = 0.365244 * 100, metric = 8.04% * 100;
 Minibatch[ 901-1000]: loss = 0.346007 * 100, metric = 7.33% * 100;
 Minibatch[1001-1100]: loss = 0.348878 * 100, metric = 7.18% * 100;
 Minibatch[1101-1200]: loss = 0.350278 * 100, metric = 7.41% * 100;
 Minibatch[1201-1300]: loss = 0.336473 * 100, metric = 6.98% * 100;
 Minibatch[1301-1400]: loss = 0.362280 * 100, metric = 7.93% * 100;
 Minibatch[1401-1500]: loss = 0.327917 * 100, metric = 6.80% * 100;
 Minibatch[1501-1600]: loss = 0.338561 * 100, metric = 7.12% * 100;
 Minibatch[1601-1700]: loss = 0.352523 * 100, metric = 7.59% * 100;
 Minibatch[1701-1800]: loss = 0.328248 * 100, metric = 6.76% * 100;
 Minibatch[1801-1900]: loss = 0.347584 * 100, metric = 7.32% * 100;
 Minibatch[1901-2000]: loss = 0.341077 * 100, metric = 7.34% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.345342 * 2000, metric = 7.32% * 2000 884.269s (  2.3 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 14.10% * 2000;
0.4731391857564449
 Minibatch[   1- 100]: loss = 0.355819 * 100, metric = 7.70% * 100;
 Minibatch[ 101- 200]: loss = 0.345133 * 100, metric = 7.16% * 100;
 Minibatch[ 201- 300]: loss = 0.349887 * 100, metric = 7.46% * 100;
 Minibatch[ 301- 400]: loss = 0.340647 * 100, metric = 6.95% * 100;
 Minibatch[ 401- 500]: loss = 0.329234 * 100, metric = 6.81% * 100;
 Minibatch[ 501- 600]: loss = 0.347020 * 100, metric = 7.41% * 100;
 Minibatch[ 601- 700]: loss = 0.344931 * 100, metric = 7.31% * 100;
 Minibatch[ 701- 800]: loss = 0.341264 * 100, metric = 7.19% * 100;
 Minibatch[ 801- 900]: loss = 0.331511 * 100, metric = 6.94% * 100;
 Minibatch[ 901-1000]: loss = 0.342960 * 100, metric = 7.45% * 100;
 Minibatch[1001-1100]: loss = 0.333321 * 100, metric = 7.13% * 100;
 Minibatch[1101-1200]: loss = 0.342144 * 100, metric = 7.30% * 100;
 Minibatch[1201-1300]: loss = 0.337493 * 100, metric = 6.99% * 100;
 Minibatch[1301-1400]: loss = 0.339623 * 100, metric = 7.04% * 100;
 Minibatch[1401-1500]: loss = 0.345357 * 100, metric = 7.49% * 100;
 Minibatch[1501-1600]: loss = 0.336885 * 100, metric = 7.23% * 100;
 Minibatch[1601-1700]: loss = 0.339089 * 100, metric = 7.22% * 100;
 Minibatch[1701-1800]: loss = 0.347000 * 100, metric = 7.35% * 100;
 Minibatch[1801-1900]: loss = 0.338799 * 100, metric = 7.26% * 100;
 Minibatch[1901-2000]: loss = 0.334957 * 100, metric = 7.30% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.341154 * 2000, metric = 7.23% * 2000 881.806s (  2.3 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.25% * 2000;
 Minibatch[   1- 100]: loss = 0.325170 * 100, metric = 6.87% * 100;
 Minibatch[ 101- 200]: loss = 0.349216 * 100, metric = 7.49% * 100;
 Minibatch[ 201- 300]: loss = 0.344017 * 100, metric = 7.29% * 100;
 Minibatch[ 301- 400]: loss = 0.337436 * 100, metric = 7.14% * 100;
 Minibatch[ 401- 500]: loss = 0.345617 * 100, metric = 7.22% * 100;
 Minibatch[ 501- 600]: loss = 0.338281 * 100, metric = 7.14% * 100;
 Minibatch[ 601- 700]: loss = 0.322282 * 100, metric = 6.77% * 100;
 Minibatch[ 701- 800]: loss = 0.333969 * 100, metric = 7.05% * 100;
 Minibatch[ 801- 900]: loss = 0.346609 * 100, metric = 7.56% * 100;
 Minibatch[ 901-1000]: loss = 0.333806 * 100, metric = 6.98% * 100;
 Minibatch[1001-1100]: loss = 0.331824 * 100, metric = 7.01% * 100;
 Minibatch[1101-1200]: loss = 0.340826 * 100, metric = 7.21% * 100;
 Minibatch[1201-1300]: loss = 0.339924 * 100, metric = 7.34% * 100;
 Minibatch[1301-1400]: loss = 0.323109 * 100, metric = 6.93% * 100;
 Minibatch[1401-1500]: loss = 0.338103 * 100, metric = 7.27% * 100;
 Minibatch[1501-1600]: loss = 0.335400 * 100, metric = 7.12% * 100;
 Minibatch[1601-1700]: loss = 0.342662 * 100, metric = 7.01% * 100;
 Minibatch[1701-1800]: loss = 0.326406 * 100, metric = 6.87% * 100;
 Minibatch[1801-1900]: loss = 0.340721 * 100, metric = 7.19% * 100;
 Minibatch[1901-2000]: loss = 0.344934 * 100, metric = 7.53% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.337016 * 2000, metric = 7.15% * 2000 878.258s (  2.3 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.02% * 2000;
 Minibatch[   1- 100]: loss = 0.325045 * 100, metric = 6.80% * 100;
 Minibatch[ 101- 200]: loss = 0.341647 * 100, metric = 7.18% * 100;
 Minibatch[ 201- 300]: loss = 0.325600 * 100, metric = 7.02% * 100;
 Minibatch[ 301- 400]: loss = 0.333123 * 100, metric = 6.96% * 100;
 Minibatch[ 401- 500]: loss = 0.318066 * 100, metric = 6.72% * 100;
 Minibatch[ 501- 600]: loss = 0.318998 * 100, metric = 6.80% * 100;
 Minibatch[ 601- 700]: loss = 0.328904 * 100, metric = 6.91% * 100;
 Minibatch[ 701- 800]: loss = 0.320329 * 100, metric = 6.81% * 100;
 Minibatch[ 801- 900]: loss = 0.327567 * 100, metric = 6.83% * 100;
 Minibatch[ 901-1000]: loss = 0.328985 * 100, metric = 7.11% * 100;
 Minibatch[1001-1100]: loss = 0.337859 * 100, metric = 7.32% * 100;
 Minibatch[1101-1200]: loss = 0.332442 * 100, metric = 7.03% * 100;
 Minibatch[1201-1300]: loss = 0.340938 * 100, metric = 7.41% * 100;
 Minibatch[1301-1400]: loss = 0.331241 * 100, metric = 7.07% * 100;
 Minibatch[1401-1500]: loss = 0.315933 * 100, metric = 6.65% * 100;
 Minibatch[1501-1600]: loss = 0.330577 * 100, metric = 7.07% * 100;
 Minibatch[1601-1700]: loss = 0.307872 * 100, metric = 6.50% * 100;
 Minibatch[1701-1800]: loss = 0.314815 * 100, metric = 6.57% * 100;
 Minibatch[1801-1900]: loss = 0.308886 * 100, metric = 6.60% * 100;
 Minibatch[1901-2000]: loss = 0.311263 * 100, metric = 6.40% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.325004 * 2000, metric = 6.89% * 2000 869.987s (  2.3 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.51% * 2000;
 Minibatch[   1- 100]: loss = 0.335550 * 100, metric = 7.28% * 100;
 Minibatch[ 101- 200]: loss = 0.334616 * 100, metric = 7.07% * 100;
 Minibatch[ 201- 300]: loss = 0.314594 * 100, metric = 6.48% * 100;
 Minibatch[ 301- 400]: loss = 0.330492 * 100, metric = 6.76% * 100;
 Minibatch[ 401- 500]: loss = 0.328089 * 100, metric = 6.86% * 100;
 Minibatch[ 501- 600]: loss = 0.315004 * 100, metric = 6.43% * 100;
 Minibatch[ 601- 700]: loss = 0.324988 * 100, metric = 6.89% * 100;
 Minibatch[ 701- 800]: loss = 0.321116 * 100, metric = 6.80% * 100;
 Minibatch[ 801- 900]: loss = 0.339191 * 100, metric = 7.29% * 100;
 Minibatch[ 901-1000]: loss = 0.306482 * 100, metric = 6.37% * 100;
 Minibatch[1001-1100]: loss = 0.327699 * 100, metric = 6.84% * 100;
 Minibatch[1101-1200]: loss = 0.324194 * 100, metric = 6.99% * 100;
 Minibatch[1201-1300]: loss = 0.315112 * 100, metric = 6.77% * 100;
 Minibatch[1301-1400]: loss = 0.319105 * 100, metric = 6.79% * 100;
 Minibatch[1401-1500]: loss = 0.324095 * 100, metric = 6.97% * 100;
 Minibatch[1501-1600]: loss = 0.325818 * 100, metric = 7.11% * 100;
 Minibatch[1601-1700]: loss = 0.307709 * 100, metric = 6.46% * 100;
 Minibatch[1701-1800]: loss = 0.306603 * 100, metric = 6.38% * 100;
 Minibatch[1801-1900]: loss = 0.316169 * 100, metric = 6.63% * 100;
 Minibatch[1901-2000]: loss = 0.314602 * 100, metric = 6.72% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.321561 * 2000, metric = 6.79% * 2000 883.872s (  2.3 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 14.89% * 2000;
 Minibatch[   1- 100]: loss = 0.320152 * 100, metric = 6.63% * 100;
 Minibatch[ 101- 200]: loss = 0.320019 * 100, metric = 6.75% * 100;
 Minibatch[ 201- 300]: loss = 0.313875 * 100, metric = 6.43% * 100;
 Minibatch[ 301- 400]: loss = 0.332859 * 100, metric = 6.86% * 100;
 Minibatch[ 401- 500]: loss = 0.324358 * 100, metric = 6.92% * 100;
 Minibatch[ 501- 600]: loss = 0.329418 * 100, metric = 7.13% * 100;
 Minibatch[ 601- 700]: loss = 0.332302 * 100, metric = 7.27% * 100;
 Minibatch[ 701- 800]: loss = 0.320670 * 100, metric = 6.75% * 100;
 Minibatch[ 801- 900]: loss = 0.340917 * 100, metric = 7.17% * 100;
 Minibatch[ 901-1000]: loss = 0.329030 * 100, metric = 7.05% * 100;
 Minibatch[1001-1100]: loss = 0.311270 * 100, metric = 6.39% * 100;
 Minibatch[1101-1200]: loss = 0.321979 * 100, metric = 6.93% * 100;
 Minibatch[1201-1300]: loss = 0.330497 * 100, metric = 7.03% * 100;
 Minibatch[1301-1400]: loss = 0.325365 * 100, metric = 6.83% * 100;
 Minibatch[1401-1500]: loss = 0.317095 * 100, metric = 6.89% * 100;
 Minibatch[1501-1600]: loss = 0.331724 * 100, metric = 6.88% * 100;
 Minibatch[1601-1700]: loss = 0.319134 * 100, metric = 6.89% * 100;
 Minibatch[1701-1800]: loss = 0.325697 * 100, metric = 6.87% * 100;
 Minibatch[1801-1900]: loss = 0.314965 * 100, metric = 6.71% * 100;
 Minibatch[1901-2000]: loss = 0.315397 * 100, metric = 6.66% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.323836 * 2000, metric = 6.85% * 2000 883.294s (  2.3 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 14.71% * 2000;
 Minibatch[   1- 100]: loss = 0.318106 * 100, metric = 6.72% * 100;
 Minibatch[ 101- 200]: loss = 0.316670 * 100, metric = 6.72% * 100;
 Minibatch[ 201- 300]: loss = 0.318494 * 100, metric = 6.74% * 100;
 Minibatch[ 301- 400]: loss = 0.323870 * 100, metric = 6.98% * 100;
 Minibatch[ 401- 500]: loss = 0.308699 * 100, metric = 6.43% * 100;
 Minibatch[ 501- 600]: loss = 0.307815 * 100, metric = 6.41% * 100;
 Minibatch[ 601- 700]: loss = 0.313608 * 100, metric = 6.61% * 100;
 Minibatch[ 701- 800]: loss = 0.288976 * 100, metric = 5.90% * 100;
 Minibatch[ 801- 900]: loss = 0.313103 * 100, metric = 6.54% * 100;
 Minibatch[ 901-1000]: loss = 0.310926 * 100, metric = 6.42% * 100;
 Minibatch[1001-1100]: loss = 0.309019 * 100, metric = 6.40% * 100;
 Minibatch[1101-1200]: loss = 0.306169 * 100, metric = 6.32% * 100;
 Minibatch[1201-1300]: loss = 0.309760 * 100, metric = 6.41% * 100;
 Minibatch[1301-1400]: loss = 0.302507 * 100, metric = 6.36% * 100;
 Minibatch[1401-1500]: loss = 0.320760 * 100, metric = 6.72% * 100;
 Minibatch[1501-1600]: loss = 0.320599 * 100, metric = 6.91% * 100;
 Minibatch[1601-1700]: loss = 0.306829 * 100, metric = 6.48% * 100;
 Minibatch[1701-1800]: loss = 0.313331 * 100, metric = 6.69% * 100;
 Minibatch[1801-1900]: loss = 0.325578 * 100, metric = 7.00% * 100;
 Minibatch[1901-2000]: loss = 0.305632 * 100, metric = 6.39% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.312022 * 2000, metric = 6.56% * 2000 875.255s (  2.3 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 13.91% * 2000;
 Minibatch[   1- 100]: loss = 0.315278 * 100, metric = 6.64% * 100;
 Minibatch[ 101- 200]: loss = 0.315571 * 100, metric = 6.53% * 100;
 Minibatch[ 201- 300]: loss = 0.324339 * 100, metric = 7.00% * 100;
 Minibatch[ 301- 400]: loss = 0.306981 * 100, metric = 6.52% * 100;
 Minibatch[ 401- 500]: loss = 0.306099 * 100, metric = 6.33% * 100;
 Minibatch[ 501- 600]: loss = 0.314749 * 100, metric = 6.62% * 100;
 Minibatch[ 601- 700]: loss = 0.308953 * 100, metric = 6.32% * 100;
 Minibatch[ 701- 800]: loss = 0.310074 * 100, metric = 6.71% * 100;
 Minibatch[ 801- 900]: loss = 0.316723 * 100, metric = 6.73% * 100;
 Minibatch[ 901-1000]: loss = 0.322737 * 100, metric = 6.75% * 100;
 Minibatch[1001-1100]: loss = 0.303862 * 100, metric = 6.13% * 100;
 Minibatch[1101-1200]: loss = 0.290770 * 100, metric = 5.90% * 100;
 Minibatch[1201-1300]: loss = 0.302046 * 100, metric = 6.31% * 100;
 Minibatch[1301-1400]: loss = 0.310510 * 100, metric = 6.46% * 100;
 Minibatch[1401-1500]: loss = 0.306547 * 100, metric = 6.54% * 100;
 Minibatch[1501-1600]: loss = 0.299852 * 100, metric = 6.19% * 100;
 Minibatch[1601-1700]: loss = 0.303892 * 100, metric = 6.46% * 100;
 Minibatch[1701-1800]: loss = 0.300865 * 100, metric = 6.15% * 100;
 Minibatch[1801-1900]: loss = 0.304738 * 100, metric = 6.34% * 100;
 Minibatch[1901-2000]: loss = 0.301266 * 100, metric = 6.19% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.308293 * 2000, metric = 6.44% * 2000 876.198s (  2.3 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 15.16% * 2000;
 Minibatch[   1- 100]: loss = 0.306041 * 100, metric = 6.33% * 100;
 Minibatch[ 101- 200]: loss = 0.316670 * 100, metric = 6.67% * 100;
 Minibatch[ 201- 300]: loss = 0.300684 * 100, metric = 6.32% * 100;
 Minibatch[ 301- 400]: loss = 0.312633 * 100, metric = 6.64% * 100;
 Minibatch[ 401- 500]: loss = 0.308187 * 100, metric = 6.56% * 100;
 Minibatch[ 501- 600]: loss = 0.307221 * 100, metric = 6.49% * 100;
 Minibatch[ 601- 700]: loss = 0.307244 * 100, metric = 6.51% * 100;
 Minibatch[ 701- 800]: loss = 0.290541 * 100, metric = 5.79% * 100;
 Minibatch[ 801- 900]: loss = 0.292281 * 100, metric = 6.24% * 100;
 Minibatch[ 901-1000]: loss = 0.306453 * 100, metric = 6.36% * 100;
 Minibatch[1001-1100]: loss = 0.300064 * 100, metric = 6.03% * 100;
 Minibatch[1101-1200]: loss = 0.301062 * 100, metric = 6.22% * 100;
 Minibatch[1201-1300]: loss = 0.303802 * 100, metric = 6.35% * 100;
 Minibatch[1301-1400]: loss = 0.315031 * 100, metric = 6.70% * 100;
 Minibatch[1401-1500]: loss = 0.291535 * 100, metric = 5.96% * 100;
 Minibatch[1501-1600]: loss = 0.296179 * 100, metric = 6.02% * 100;
 Minibatch[1601-1700]: loss = 0.297361 * 100, metric = 6.17% * 100;
 Minibatch[1701-1800]: loss = 0.307883 * 100, metric = 6.50% * 100;
 Minibatch[1801-1900]: loss = 0.299036 * 100, metric = 6.25% * 100;
 Minibatch[1901-2000]: loss = 0.299133 * 100, metric = 6.05% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.302952 * 2000, metric = 6.31% * 2000 881.054s (  2.3 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 14.72% * 2000;
 Minibatch[   1- 100]: loss = 0.286252 * 100, metric = 5.98% * 100;
 Minibatch[ 101- 200]: loss = 0.302814 * 100, metric = 6.31% * 100;
 Minibatch[ 201- 300]: loss = 0.294469 * 100, metric = 6.08% * 100;
 Minibatch[ 301- 400]: loss = 0.300117 * 100, metric = 6.25% * 100;
 Minibatch[ 401- 500]: loss = 0.300124 * 100, metric = 6.31% * 100;
 Minibatch[ 501- 600]: loss = 0.292940 * 100, metric = 6.19% * 100;
 Minibatch[ 601- 700]: loss = 0.309647 * 100, metric = 6.37% * 100;
 Minibatch[ 701- 800]: loss = 0.294572 * 100, metric = 6.22% * 100;
 Minibatch[ 801- 900]: loss = 0.305061 * 100, metric = 6.55% * 100;
 Minibatch[ 901-1000]: loss = 0.300583 * 100, metric = 6.26% * 100;
 Minibatch[1001-1100]: loss = 0.294360 * 100, metric = 6.13% * 100;
 Minibatch[1101-1200]: loss = 0.308571 * 100, metric = 6.44% * 100;
 Minibatch[1201-1300]: loss = 0.293629 * 100, metric = 6.15% * 100;
 Minibatch[1301-1400]: loss = 0.293135 * 100, metric = 6.00% * 100;
 Minibatch[1401-1500]: loss = 0.287982 * 100, metric = 5.96% * 100;
 Minibatch[1501-1600]: loss = 0.298631 * 100, metric = 6.30% * 100;
 Minibatch[1601-1700]: loss = 0.289026 * 100, metric = 5.97% * 100;
 Minibatch[1701-1800]: loss = 0.296526 * 100, metric = 6.08% * 100;
 Minibatch[1801-1900]: loss = 0.300009 * 100, metric = 6.21% * 100;
 Minibatch[1901-2000]: loss = 0.300092 * 100, metric = 6.12% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.297427 * 2000, metric = 6.19% * 2000 876.530s (  2.3 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.41% * 2000;
 Minibatch[   1- 100]: loss = 0.299865 * 100, metric = 6.27% * 100;
 Minibatch[ 101- 200]: loss = 0.295626 * 100, metric = 6.05% * 100;
 Minibatch[ 201- 300]: loss = 0.302105 * 100, metric = 6.35% * 100;
 Minibatch[ 301- 400]: loss = 0.296098 * 100, metric = 6.07% * 100;
 Minibatch[ 401- 500]: loss = 0.296715 * 100, metric = 6.17% * 100;
 Minibatch[ 501- 600]: loss = 0.297936 * 100, metric = 6.22% * 100;
 Minibatch[ 601- 700]: loss = 0.298110 * 100, metric = 6.05% * 100;
 Minibatch[ 701- 800]: loss = 0.282010 * 100, metric = 5.73% * 100;
 Minibatch[ 801- 900]: loss = 0.284507 * 100, metric = 5.98% * 100;
 Minibatch[ 901-1000]: loss = 0.297462 * 100, metric = 6.37% * 100;
 Minibatch[1001-1100]: loss = 0.298216 * 100, metric = 6.09% * 100;
 Minibatch[1101-1200]: loss = 0.307046 * 100, metric = 6.55% * 100;
 Minibatch[1201-1300]: loss = 0.307265 * 100, metric = 6.44% * 100;
 Minibatch[1301-1400]: loss = 0.299505 * 100, metric = 6.29% * 100;
 Minibatch[1401-1500]: loss = 0.293788 * 100, metric = 5.80% * 100;
 Minibatch[1501-1600]: loss = 0.298595 * 100, metric = 6.12% * 100;
 Minibatch[1601-1700]: loss = 0.287907 * 100, metric = 6.00% * 100;
 Minibatch[1701-1800]: loss = 0.291419 * 100, metric = 5.92% * 100;
 Minibatch[1801-1900]: loss = 0.282531 * 100, metric = 5.61% * 100;
 Minibatch[1901-2000]: loss = 0.283780 * 100, metric = 5.72% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.295024 * 2000, metric = 6.09% * 2000 883.173s (  2.3 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.32% * 2000;
 Minibatch[   1- 100]: loss = 0.286395 * 100, metric = 5.88% * 100;
 Minibatch[ 101- 200]: loss = 0.271583 * 100, metric = 5.45% * 100;
 Minibatch[ 201- 300]: loss = 0.287043 * 100, metric = 5.88% * 100;
 Minibatch[ 301- 400]: loss = 0.279019 * 100, metric = 5.68% * 100;
 Minibatch[ 401- 500]: loss = 0.288015 * 100, metric = 6.13% * 100;
 Minibatch[ 501- 600]: loss = 0.277807 * 100, metric = 5.60% * 100;
 Minibatch[ 601- 700]: loss = 0.299602 * 100, metric = 6.18% * 100;
 Minibatch[ 701- 800]: loss = 0.290901 * 100, metric = 6.16% * 100;
 Minibatch[ 801- 900]: loss = 0.275135 * 100, metric = 5.78% * 100;
 Minibatch[ 901-1000]: loss = 0.288334 * 100, metric = 5.91% * 100;
 Minibatch[1001-1100]: loss = 0.297152 * 100, metric = 6.32% * 100;
 Minibatch[1101-1200]: loss = 0.298571 * 100, metric = 5.95% * 100;
 Minibatch[1201-1300]: loss = 0.297585 * 100, metric = 6.12% * 100;
 Minibatch[1301-1400]: loss = 0.279197 * 100, metric = 5.68% * 100;
 Minibatch[1401-1500]: loss = 0.287121 * 100, metric = 5.95% * 100;
 Minibatch[1501-1600]: loss = 0.280092 * 100, metric = 5.62% * 100;
 Minibatch[1601-1700]: loss = 0.307117 * 100, metric = 6.47% * 100;
 Minibatch[1701-1800]: loss = 0.298178 * 100, metric = 6.04% * 100;
 Minibatch[1801-1900]: loss = 0.286086 * 100, metric = 5.97% * 100;
 Minibatch[1901-2000]: loss = 0.291033 * 100, metric = 6.11% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.288298 * 2000, metric = 5.94% * 2000 873.326s (  2.3 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.43% * 2000;
 Minibatch[   1- 100]: loss = 0.283346 * 100, metric = 5.79% * 100;
 Minibatch[ 101- 200]: loss = 0.296108 * 100, metric = 6.09% * 100;
 Minibatch[ 201- 300]: loss = 0.283608 * 100, metric = 5.71% * 100;
 Minibatch[ 301- 400]: loss = 0.286858 * 100, metric = 6.00% * 100;
 Minibatch[ 401- 500]: loss = 0.283165 * 100, metric = 5.66% * 100;
 Minibatch[ 501- 600]: loss = 0.284953 * 100, metric = 5.96% * 100;
 Minibatch[ 601- 700]: loss = 0.282862 * 100, metric = 5.82% * 100;
 Minibatch[ 701- 800]: loss = 0.286433 * 100, metric = 5.85% * 100;
 Minibatch[ 801- 900]: loss = 0.292555 * 100, metric = 5.90% * 100;
 Minibatch[ 901-1000]: loss = 0.289367 * 100, metric = 5.93% * 100;
 Minibatch[1001-1100]: loss = 0.280852 * 100, metric = 5.63% * 100;
 Minibatch[1101-1200]: loss = 0.291217 * 100, metric = 5.88% * 100;
 Minibatch[1201-1300]: loss = 0.283862 * 100, metric = 5.81% * 100;
 Minibatch[1301-1400]: loss = 0.292232 * 100, metric = 6.28% * 100;
 Minibatch[1401-1500]: loss = 0.283266 * 100, metric = 6.00% * 100;
 Minibatch[1501-1600]: loss = 0.282154 * 100, metric = 5.77% * 100;
 Minibatch[1601-1700]: loss = 0.268017 * 100, metric = 5.50% * 100;
 Minibatch[1701-1800]: loss = 0.281399 * 100, metric = 5.88% * 100;
 Minibatch[1801-1900]: loss = 0.276379 * 100, metric = 5.64% * 100;
 Minibatch[1901-2000]: loss = 0.285189 * 100, metric = 5.75% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.284691 * 2000, metric = 5.84% * 2000 877.084s (  2.3 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 14.04% * 2000;
 Minibatch[   1- 100]: loss = 0.289448 * 100, metric = 6.00% * 100;
 Minibatch[ 101- 200]: loss = 0.281486 * 100, metric = 5.74% * 100;
 Minibatch[ 201- 300]: loss = 0.290815 * 100, metric = 6.00% * 100;
 Minibatch[ 301- 400]: loss = 0.287819 * 100, metric = 5.99% * 100;
 Minibatch[ 401- 500]: loss = 0.286059 * 100, metric = 6.07% * 100;
 Minibatch[ 501- 600]: loss = 0.294846 * 100, metric = 6.37% * 100;
 Minibatch[ 601- 700]: loss = 0.281072 * 100, metric = 5.80% * 100;
 Minibatch[ 701- 800]: loss = 0.274913 * 100, metric = 5.73% * 100;
 Minibatch[ 801- 900]: loss = 0.286029 * 100, metric = 5.97% * 100;
 Minibatch[ 901-1000]: loss = 0.290428 * 100, metric = 6.15% * 100;
 Minibatch[1001-1100]: loss = 0.284413 * 100, metric = 6.03% * 100;
 Minibatch[1101-1200]: loss = 0.277338 * 100, metric = 5.52% * 100;
 Minibatch[1201-1300]: loss = 0.283048 * 100, metric = 5.91% * 100;
 Minibatch[1301-1400]: loss = 0.282544 * 100, metric = 5.94% * 100;
 Minibatch[1401-1500]: loss = 0.291444 * 100, metric = 6.08% * 100;
 Minibatch[1501-1600]: loss = 0.279369 * 100, metric = 5.86% * 100;
 Minibatch[1601-1700]: loss = 0.279117 * 100, metric = 5.71% * 100;
 Minibatch[1701-1800]: loss = 0.276913 * 100, metric = 5.58% * 100;
 Minibatch[1801-1900]: loss = 0.284051 * 100, metric = 6.02% * 100;
 Minibatch[1901-2000]: loss = 0.282139 * 100, metric = 5.80% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.284164 * 2000, metric = 5.91% * 2000 871.808s (  2.3 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 14.07% * 2000;
 Minibatch[   1- 100]: loss = 0.271937 * 100, metric = 5.39% * 100;
 Minibatch[ 101- 200]: loss = 0.275953 * 100, metric = 5.63% * 100;
 Minibatch[ 201- 300]: loss = 0.279660 * 100, metric = 5.92% * 100;
 Minibatch[ 301- 400]: loss = 0.295063 * 100, metric = 6.17% * 100;
 Minibatch[ 401- 500]: loss = 0.274754 * 100, metric = 5.53% * 100;
 Minibatch[ 501- 600]: loss = 0.285096 * 100, metric = 5.91% * 100;
 Minibatch[ 601- 700]: loss = 0.276775 * 100, metric = 5.75% * 100;
 Minibatch[ 701- 800]: loss = 0.284507 * 100, metric = 6.01% * 100;
 Minibatch[ 801- 900]: loss = 0.276523 * 100, metric = 5.81% * 100;
 Minibatch[ 901-1000]: loss = 0.286535 * 100, metric = 5.85% * 100;
 Minibatch[1001-1100]: loss = 0.274091 * 100, metric = 5.72% * 100;
 Minibatch[1101-1200]: loss = 0.276723 * 100, metric = 5.73% * 100;
 Minibatch[1201-1300]: loss = 0.280532 * 100, metric = 5.78% * 100;
 Minibatch[1301-1400]: loss = 0.265554 * 100, metric = 5.42% * 100;
 Minibatch[1401-1500]: loss = 0.284138 * 100, metric = 5.80% * 100;
 Minibatch[1501-1600]: loss = 0.270143 * 100, metric = 5.58% * 100;
 Minibatch[1601-1700]: loss = 0.277064 * 100, metric = 5.57% * 100;
 Minibatch[1701-1800]: loss = 0.270172 * 100, metric = 5.62% * 100;
 Minibatch[1801-1900]: loss = 0.282020 * 100, metric = 5.74% * 100;
 Minibatch[1901-2000]: loss = 0.273493 * 100, metric = 5.51% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.278037 * 2000, metric = 5.72% * 2000 871.492s (  2.3 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 14.15% * 2000;
 Minibatch[   1- 100]: loss = 0.287837 * 100, metric = 6.03% * 100;
 Minibatch[ 101- 200]: loss = 0.265720 * 100, metric = 5.34% * 100;
 Minibatch[ 201- 300]: loss = 0.275590 * 100, metric = 5.68% * 100;
 Minibatch[ 301- 400]: loss = 0.279987 * 100, metric = 5.67% * 100;
 Minibatch[ 401- 500]: loss = 0.279550 * 100, metric = 5.78% * 100;
 Minibatch[ 501- 600]: loss = 0.259662 * 100, metric = 5.21% * 100;
 Minibatch[ 601- 700]: loss = 0.281557 * 100, metric = 5.61% * 100;
 Minibatch[ 701- 800]: loss = 0.264086 * 100, metric = 5.09% * 100;
 Minibatch[ 801- 900]: loss = 0.280961 * 100, metric = 5.53% * 100;
 Minibatch[ 901-1000]: loss = 0.258447 * 100, metric = 5.31% * 100;
 Minibatch[1001-1100]: loss = 0.277055 * 100, metric = 5.55% * 100;
 Minibatch[1101-1200]: loss = 0.287092 * 100, metric = 5.87% * 100;
 Minibatch[1201-1300]: loss = 0.274105 * 100, metric = 5.53% * 100;
 Minibatch[1301-1400]: loss = 0.278560 * 100, metric = 5.79% * 100;
 Minibatch[1401-1500]: loss = 0.267105 * 100, metric = 5.34% * 100;
 Minibatch[1501-1600]: loss = 0.281077 * 100, metric = 5.84% * 100;
 Minibatch[1601-1700]: loss = 0.279080 * 100, metric = 5.55% * 100;
 Minibatch[1701-1800]: loss = 0.276357 * 100, metric = 5.64% * 100;
 Minibatch[1801-1900]: loss = 0.277914 * 100, metric = 5.83% * 100;
 Minibatch[1901-2000]: loss = 0.287684 * 100, metric = 5.90% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.275971 * 2000, metric = 5.60% * 2000 869.105s (  2.3 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.57% * 2000;
 Minibatch[   1- 100]: loss = 0.271339 * 100, metric = 5.61% * 100;
 Minibatch[ 101- 200]: loss = 0.283902 * 100, metric = 6.09% * 100;
 Minibatch[ 201- 300]: loss = 0.269994 * 100, metric = 5.45% * 100;
 Minibatch[ 301- 400]: loss = 0.272208 * 100, metric = 5.60% * 100;
 Minibatch[ 401- 500]: loss = 0.269827 * 100, metric = 5.47% * 100;
 Minibatch[ 501- 600]: loss = 0.268169 * 100, metric = 5.43% * 100;
 Minibatch[ 601- 700]: loss = 0.279369 * 100, metric = 5.81% * 100;
 Minibatch[ 701- 800]: loss = 0.286504 * 100, metric = 6.03% * 100;
 Minibatch[ 801- 900]: loss = 0.283009 * 100, metric = 5.67% * 100;
 Minibatch[ 901-1000]: loss = 0.268260 * 100, metric = 5.27% * 100;
 Minibatch[1001-1100]: loss = 0.266048 * 100, metric = 5.47% * 100;
 Minibatch[1101-1200]: loss = 0.274373 * 100, metric = 5.66% * 100;
 Minibatch[1201-1300]: loss = 0.269153 * 100, metric = 5.46% * 100;
 Minibatch[1301-1400]: loss = 0.277713 * 100, metric = 5.79% * 100;
 Minibatch[1401-1500]: loss = 0.280192 * 100, metric = 5.84% * 100;
 Minibatch[1501-1600]: loss = 0.265470 * 100, metric = 5.34% * 100;
 Minibatch[1601-1700]: loss = 0.273932 * 100, metric = 5.72% * 100;
 Minibatch[1701-1800]: loss = 0.269421 * 100, metric = 5.51% * 100;
 Minibatch[1801-1900]: loss = 0.281523 * 100, metric = 5.89% * 100;
 Minibatch[1901-2000]: loss = 0.275488 * 100, metric = 5.57% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.274295 * 2000, metric = 5.63% * 2000 874.794s (  2.3 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 14.09% * 2000;
 Minibatch[   1- 100]: loss = 0.268746 * 100, metric = 5.45% * 100;
 Minibatch[ 101- 200]: loss = 0.274687 * 100, metric = 5.76% * 100;
 Minibatch[ 201- 300]: loss = 0.277596 * 100, metric = 5.71% * 100;
 Minibatch[ 301- 400]: loss = 0.283456 * 100, metric = 5.89% * 100;
 Minibatch[ 401- 500]: loss = 0.275149 * 100, metric = 5.76% * 100;
 Minibatch[ 501- 600]: loss = 0.274518 * 100, metric = 5.63% * 100;
 Minibatch[ 601- 700]: loss = 0.265144 * 100, metric = 5.33% * 100;
 Minibatch[ 701- 800]: loss = 0.269400 * 100, metric = 5.59% * 100;
 Minibatch[ 801- 900]: loss = 0.268561 * 100, metric = 5.58% * 100;
 Minibatch[ 901-1000]: loss = 0.259171 * 100, metric = 5.27% * 100;
 Minibatch[1001-1100]: loss = 0.260659 * 100, metric = 5.09% * 100;
 Minibatch[1101-1200]: loss = 0.270963 * 100, metric = 5.71% * 100;
 Minibatch[1201-1300]: loss = 0.282570 * 100, metric = 5.99% * 100;
 Minibatch[1301-1400]: loss = 0.267055 * 100, metric = 5.44% * 100;
 Minibatch[1401-1500]: loss = 0.260892 * 100, metric = 5.47% * 100;
 Minibatch[1501-1600]: loss = 0.273210 * 100, metric = 5.52% * 100;
 Minibatch[1601-1700]: loss = 0.261574 * 100, metric = 5.40% * 100;
 Minibatch[1701-1800]: loss = 0.273435 * 100, metric = 5.61% * 100;
 Minibatch[1801-1900]: loss = 0.261909 * 100, metric = 5.25% * 100;
 Minibatch[1901-2000]: loss = 0.276239 * 100, metric = 5.91% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.270247 * 2000, metric = 5.57% * 2000 892.081s (  2.2 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.86% * 2000;
 Minibatch[   1- 100]: loss = 0.281014 * 100, metric = 5.87% * 100;
 Minibatch[ 101- 200]: loss = 0.267500 * 100, metric = 5.54% * 100;
 Minibatch[ 201- 300]: loss = 0.264888 * 100, metric = 5.50% * 100;
 Minibatch[ 301- 400]: loss = 0.274586 * 100, metric = 5.78% * 100;
 Minibatch[ 401- 500]: loss = 0.266620 * 100, metric = 5.47% * 100;
 Minibatch[ 501- 600]: loss = 0.270638 * 100, metric = 5.39% * 100;
 Minibatch[ 601- 700]: loss = 0.277611 * 100, metric = 5.81% * 100;
 Minibatch[ 701- 800]: loss = 0.277655 * 100, metric = 5.86% * 100;
 Minibatch[ 801- 900]: loss = 0.271814 * 100, metric = 5.47% * 100;
 Minibatch[ 901-1000]: loss = 0.258434 * 100, metric = 5.12% * 100;
 Minibatch[1001-1100]: loss = 0.274246 * 100, metric = 5.66% * 100;
 Minibatch[1101-1200]: loss = 0.257375 * 100, metric = 5.13% * 100;
 Minibatch[1201-1300]: loss = 0.270010 * 100, metric = 5.43% * 100;
 Minibatch[1301-1400]: loss = 0.256306 * 100, metric = 5.14% * 100;
 Minibatch[1401-1500]: loss = 0.277983 * 100, metric = 5.55% * 100;
 Minibatch[1501-1600]: loss = 0.276544 * 100, metric = 5.50% * 100;
 Minibatch[1601-1700]: loss = 0.267291 * 100, metric = 5.24% * 100;
 Minibatch[1701-1800]: loss = 0.265933 * 100, metric = 5.15% * 100;
 Minibatch[1801-1900]: loss = 0.262648 * 100, metric = 5.26% * 100;
 Minibatch[1901-2000]: loss = 0.272534 * 100, metric = 5.51% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.269581 * 2000, metric = 5.47% * 2000 890.317s (  2.2 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.65% * 2000;
 Minibatch[   1- 100]: loss = 0.259319 * 100, metric = 5.27% * 100;
 Minibatch[ 101- 200]: loss = 0.269785 * 100, metric = 5.50% * 100;
 Minibatch[ 201- 300]: loss = 0.263518 * 100, metric = 5.41% * 100;
 Minibatch[ 301- 400]: loss = 0.272228 * 100, metric = 5.61% * 100;
 Minibatch[ 401- 500]: loss = 0.261376 * 100, metric = 5.25% * 100;
 Minibatch[ 501- 600]: loss = 0.273301 * 100, metric = 5.61% * 100;
 Minibatch[ 601- 700]: loss = 0.266694 * 100, metric = 5.37% * 100;
 Minibatch[ 701- 800]: loss = 0.261508 * 100, metric = 5.15% * 100;
 Minibatch[ 801- 900]: loss = 0.256427 * 100, metric = 4.96% * 100;
 Minibatch[ 901-1000]: loss = 0.262916 * 100, metric = 5.37% * 100;
 Minibatch[1001-1100]: loss = 0.268338 * 100, metric = 5.43% * 100;
 Minibatch[1101-1200]: loss = 0.258241 * 100, metric = 5.32% * 100;
 Minibatch[1201-1300]: loss = 0.273315 * 100, metric = 5.51% * 100;
 Minibatch[1301-1400]: loss = 0.267341 * 100, metric = 5.40% * 100;
 Minibatch[1401-1500]: loss = 0.274682 * 100, metric = 5.60% * 100;
 Minibatch[1501-1600]: loss = 0.268211 * 100, metric = 5.46% * 100;
 Minibatch[1601-1700]: loss = 0.282471 * 100, metric = 5.87% * 100;
 Minibatch[1701-1800]: loss = 0.265963 * 100, metric = 5.36% * 100;
 Minibatch[1801-1900]: loss = 0.267647 * 100, metric = 5.51% * 100;
 Minibatch[1901-2000]: loss = 0.266114 * 100, metric = 5.29% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.266970 * 2000, metric = 5.41% * 2000 869.547s (  2.3 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.57% * 2000;
 Minibatch[   1- 100]: loss = 0.259654 * 100, metric = 5.17% * 100;
 Minibatch[ 101- 200]: loss = 0.264375 * 100, metric = 5.39% * 100;
 Minibatch[ 201- 300]: loss = 0.260882 * 100, metric = 5.21% * 100;
 Minibatch[ 301- 400]: loss = 0.250253 * 100, metric = 5.01% * 100;
 Minibatch[ 401- 500]: loss = 0.264682 * 100, metric = 5.28% * 100;
 Minibatch[ 501- 600]: loss = 0.244048 * 100, metric = 4.91% * 100;
 Minibatch[ 601- 700]: loss = 0.267815 * 100, metric = 5.53% * 100;
 Minibatch[ 701- 800]: loss = 0.260204 * 100, metric = 5.21% * 100;
 Minibatch[ 801- 900]: loss = 0.270761 * 100, metric = 5.60% * 100;
 Minibatch[ 901-1000]: loss = 0.260272 * 100, metric = 5.23% * 100;
 Minibatch[1001-1100]: loss = 0.270612 * 100, metric = 5.60% * 100;
 Minibatch[1101-1200]: loss = 0.259764 * 100, metric = 5.32% * 100;
 Minibatch[1201-1300]: loss = 0.270027 * 100, metric = 5.50% * 100;
 Minibatch[1301-1400]: loss = 0.262208 * 100, metric = 5.41% * 100;
 Minibatch[1401-1500]: loss = 0.262328 * 100, metric = 5.36% * 100;
 Minibatch[1501-1600]: loss = 0.259646 * 100, metric = 5.37% * 100;
 Minibatch[1601-1700]: loss = 0.258869 * 100, metric = 5.36% * 100;
 Minibatch[1701-1800]: loss = 0.255416 * 100, metric = 5.13% * 100;
 Minibatch[1801-1900]: loss = 0.269791 * 100, metric = 5.55% * 100;
 Minibatch[1901-2000]: loss = 0.262222 * 100, metric = 5.20% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.261691 * 2000, metric = 5.32% * 2000 865.702s (  2.3 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 14.21% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
