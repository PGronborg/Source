Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.374283 * 100, metric = 24.65% * 100;
 Minibatch[ 101- 200]: loss = 1.189428 * 100, metric = 23.15% * 100;
 Minibatch[ 201- 300]: loss = 1.038732 * 100, metric = 21.72% * 100;
 Minibatch[ 301- 400]: loss = 1.031276 * 100, metric = 20.39% * 100;
 Minibatch[ 401- 500]: loss = 0.950949 * 100, metric = 19.09% * 100;
 Minibatch[ 501- 600]: loss = 0.936652 * 100, metric = 18.16% * 100;
 Minibatch[ 601- 700]: loss = 0.893543 * 100, metric = 16.75% * 100;
 Minibatch[ 701- 800]: loss = 0.847386 * 100, metric = 15.78% * 100;
 Minibatch[ 801- 900]: loss = 0.864097 * 100, metric = 16.61% * 100;
 Minibatch[ 901-1000]: loss = 0.856172 * 100, metric = 16.28% * 100;
 Minibatch[1001-1100]: loss = 0.853899 * 100, metric = 16.31% * 100;
 Minibatch[1101-1200]: loss = 0.840083 * 100, metric = 15.39% * 100;
 Minibatch[1201-1300]: loss = 0.823813 * 100, metric = 15.05% * 100;
 Minibatch[1301-1400]: loss = 0.798186 * 100, metric = 14.20% * 100;
 Minibatch[1401-1500]: loss = 0.810260 * 100, metric = 14.84% * 100;
 Minibatch[1501-1600]: loss = 0.790635 * 100, metric = 14.10% * 100;
 Minibatch[1601-1700]: loss = 0.773871 * 100, metric = 14.11% * 100;
 Minibatch[1701-1800]: loss = 0.791187 * 100, metric = 13.97% * 100;
 Minibatch[1801-1900]: loss = 0.775596 * 100, metric = 14.21% * 100;
 Minibatch[1901-2000]: loss = 0.767964 * 100, metric = 13.34% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.900401 * 2000, metric = 16.91% * 2000 1039.864s (  1.9 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 25.62% * 2000;
0.8773072216138244
 Minibatch[   1- 100]: loss = 0.740660 * 100, metric = 13.34% * 100;
 Minibatch[ 101- 200]: loss = 0.763166 * 100, metric = 13.81% * 100;
 Minibatch[ 201- 300]: loss = 0.749010 * 100, metric = 12.78% * 100;
 Minibatch[ 301- 400]: loss = 0.749445 * 100, metric = 13.18% * 100;
 Minibatch[ 401- 500]: loss = 0.739419 * 100, metric = 12.76% * 100;
 Minibatch[ 501- 600]: loss = 0.740861 * 100, metric = 12.71% * 100;
 Minibatch[ 601- 700]: loss = 0.709178 * 100, metric = 12.35% * 100;
 Minibatch[ 701- 800]: loss = 0.730353 * 100, metric = 12.87% * 100;
 Minibatch[ 801- 900]: loss = 0.688563 * 100, metric = 11.71% * 100;
 Minibatch[ 901-1000]: loss = 0.699033 * 100, metric = 11.99% * 100;
 Minibatch[1001-1100]: loss = 0.692868 * 100, metric = 12.18% * 100;
 Minibatch[1101-1200]: loss = 0.702364 * 100, metric = 12.13% * 100;
 Minibatch[1201-1300]: loss = 0.689160 * 100, metric = 11.93% * 100;
 Minibatch[1301-1400]: loss = 0.706238 * 100, metric = 11.99% * 100;
 Minibatch[1401-1500]: loss = 0.670652 * 100, metric = 11.22% * 100;
 Minibatch[1501-1600]: loss = 0.664893 * 100, metric = 11.27% * 100;
 Minibatch[1601-1700]: loss = 0.693230 * 100, metric = 11.67% * 100;
 Minibatch[1701-1800]: loss = 0.694902 * 100, metric = 12.22% * 100;
 Minibatch[1801-1900]: loss = 0.703568 * 100, metric = 12.11% * 100;
 Minibatch[1901-2000]: loss = 0.667329 * 100, metric = 11.40% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.709745 * 2000, metric = 12.28% * 2000 983.798s (  2.0 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 20.77% * 2000;
0.7821629356443882
 Minibatch[   1- 100]: loss = 0.680068 * 100, metric = 11.79% * 100;
 Minibatch[ 101- 200]: loss = 0.692402 * 100, metric = 11.94% * 100;
 Minibatch[ 201- 300]: loss = 0.671506 * 100, metric = 11.59% * 100;
 Minibatch[ 301- 400]: loss = 0.683518 * 100, metric = 11.78% * 100;
 Minibatch[ 401- 500]: loss = 0.688978 * 100, metric = 11.93% * 100;
 Minibatch[ 501- 600]: loss = 0.678304 * 100, metric = 11.41% * 100;
 Minibatch[ 601- 700]: loss = 0.680966 * 100, metric = 11.79% * 100;
 Minibatch[ 701- 800]: loss = 0.658822 * 100, metric = 11.03% * 100;
 Minibatch[ 801- 900]: loss = 0.689040 * 100, metric = 12.09% * 100;
 Minibatch[ 901-1000]: loss = 0.656268 * 100, metric = 11.34% * 100;
 Minibatch[1001-1100]: loss = 0.669464 * 100, metric = 11.47% * 100;
 Minibatch[1101-1200]: loss = 0.661423 * 100, metric = 11.28% * 100;
 Minibatch[1201-1300]: loss = 0.670071 * 100, metric = 11.56% * 100;
 Minibatch[1301-1400]: loss = 0.674155 * 100, metric = 11.65% * 100;
 Minibatch[1401-1500]: loss = 0.673803 * 100, metric = 11.50% * 100;
 Minibatch[1501-1600]: loss = 0.667671 * 100, metric = 11.03% * 100;
 Minibatch[1601-1700]: loss = 0.650310 * 100, metric = 10.92% * 100;
 Minibatch[1701-1800]: loss = 0.673826 * 100, metric = 11.53% * 100;
 Minibatch[1801-1900]: loss = 0.648088 * 100, metric = 10.70% * 100;
 Minibatch[1901-2000]: loss = 0.647258 * 100, metric = 11.00% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.670797 * 2000, metric = 11.47% * 2000 972.876s (  2.1 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 19.63% * 2000;
0.740311789341271
 Minibatch[   1- 100]: loss = 0.672535 * 100, metric = 11.35% * 100;
 Minibatch[ 101- 200]: loss = 0.630321 * 100, metric = 10.70% * 100;
 Minibatch[ 201- 300]: loss = 0.648252 * 100, metric = 11.07% * 100;
 Minibatch[ 301- 400]: loss = 0.625512 * 100, metric = 10.15% * 100;
 Minibatch[ 401- 500]: loss = 0.643333 * 100, metric = 10.73% * 100;
 Minibatch[ 501- 600]: loss = 0.628339 * 100, metric = 10.15% * 100;
 Minibatch[ 601- 700]: loss = 0.626777 * 100, metric = 10.50% * 100;
 Minibatch[ 701- 800]: loss = 0.642471 * 100, metric = 10.71% * 100;
 Minibatch[ 801- 900]: loss = 0.650120 * 100, metric = 10.93% * 100;
 Minibatch[ 901-1000]: loss = 0.649975 * 100, metric = 10.83% * 100;
 Minibatch[1001-1100]: loss = 0.652570 * 100, metric = 10.99% * 100;
 Minibatch[1101-1200]: loss = 0.630649 * 100, metric = 10.33% * 100;
 Minibatch[1201-1300]: loss = 0.633929 * 100, metric = 10.31% * 100;
 Minibatch[1301-1400]: loss = 0.651270 * 100, metric = 10.93% * 100;
 Minibatch[1401-1500]: loss = 0.636856 * 100, metric = 10.61% * 100;
 Minibatch[1501-1600]: loss = 0.599193 * 100, metric = 9.92% * 100;
 Minibatch[1601-1700]: loss = 0.636621 * 100, metric = 10.47% * 100;
 Minibatch[1701-1800]: loss = 0.629504 * 100, metric = 10.48% * 100;
 Minibatch[1801-1900]: loss = 0.614220 * 100, metric = 10.00% * 100;
 Minibatch[1901-2000]: loss = 0.617634 * 100, metric = 10.04% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.636004 * 2000, metric = 10.56% * 2000 962.256s (  2.1 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 21.03% * 2000;
 Minibatch[   1- 100]: loss = 0.653175 * 100, metric = 10.61% * 100;
 Minibatch[ 101- 200]: loss = 0.625061 * 100, metric = 10.23% * 100;
 Minibatch[ 201- 300]: loss = 0.617933 * 100, metric = 10.17% * 100;
 Minibatch[ 301- 400]: loss = 0.651397 * 100, metric = 10.94% * 100;
 Minibatch[ 401- 500]: loss = 0.595094 * 100, metric = 9.64% * 100;
 Minibatch[ 501- 600]: loss = 0.606522 * 100, metric = 9.87% * 100;
 Minibatch[ 601- 700]: loss = 0.621123 * 100, metric = 9.74% * 100;
 Minibatch[ 701- 800]: loss = 0.629775 * 100, metric = 10.34% * 100;
 Minibatch[ 801- 900]: loss = 0.613876 * 100, metric = 9.82% * 100;
 Minibatch[ 901-1000]: loss = 0.615864 * 100, metric = 10.18% * 100;
 Minibatch[1001-1100]: loss = 0.628687 * 100, metric = 10.30% * 100;
 Minibatch[1101-1200]: loss = 0.613082 * 100, metric = 10.09% * 100;
 Minibatch[1201-1300]: loss = 0.627390 * 100, metric = 10.25% * 100;
 Minibatch[1301-1400]: loss = 0.639692 * 100, metric = 10.78% * 100;
 Minibatch[1401-1500]: loss = 0.625451 * 100, metric = 10.53% * 100;
 Minibatch[1501-1600]: loss = 0.626924 * 100, metric = 9.99% * 100;
 Minibatch[1601-1700]: loss = 0.626395 * 100, metric = 10.66% * 100;
 Minibatch[1701-1800]: loss = 0.624709 * 100, metric = 10.38% * 100;
 Minibatch[1801-1900]: loss = 0.623292 * 100, metric = 10.37% * 100;
 Minibatch[1901-2000]: loss = 0.605023 * 100, metric = 9.95% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.623523 * 2000, metric = 10.24% * 2000 946.093s (  2.1 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 19.09% * 2000;
0.7307522920519114
 Minibatch[   1- 100]: loss = 0.616294 * 100, metric = 10.20% * 100;
 Minibatch[ 101- 200]: loss = 0.604433 * 100, metric = 9.98% * 100;
 Minibatch[ 201- 300]: loss = 0.621888 * 100, metric = 10.35% * 100;
 Minibatch[ 301- 400]: loss = 0.617442 * 100, metric = 10.09% * 100;
 Minibatch[ 401- 500]: loss = 0.591066 * 100, metric = 9.75% * 100;
 Minibatch[ 501- 600]: loss = 0.611939 * 100, metric = 10.29% * 100;
 Minibatch[ 601- 700]: loss = 0.601479 * 100, metric = 10.02% * 100;
 Minibatch[ 701- 800]: loss = 0.610763 * 100, metric = 10.03% * 100;
 Minibatch[ 801- 900]: loss = 0.616618 * 100, metric = 10.16% * 100;
 Minibatch[ 901-1000]: loss = 0.598658 * 100, metric = 9.89% * 100;
 Minibatch[1001-1100]: loss = 0.598407 * 100, metric = 9.55% * 100;
 Minibatch[1101-1200]: loss = 0.614907 * 100, metric = 10.04% * 100;
 Minibatch[1201-1300]: loss = 0.622433 * 100, metric = 10.34% * 100;
 Minibatch[1301-1400]: loss = 0.589751 * 100, metric = 9.68% * 100;
 Minibatch[1401-1500]: loss = 0.600283 * 100, metric = 9.83% * 100;
 Minibatch[1501-1600]: loss = 0.579361 * 100, metric = 9.33% * 100;
 Minibatch[1601-1700]: loss = 0.585831 * 100, metric = 9.27% * 100;
 Minibatch[1701-1800]: loss = 0.580105 * 100, metric = 9.29% * 100;
 Minibatch[1801-1900]: loss = 0.597413 * 100, metric = 9.62% * 100;
 Minibatch[1901-2000]: loss = 0.594580 * 100, metric = 9.34% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.602683 * 2000, metric = 9.85% * 2000 953.836s (  2.1 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 18.39% * 2000;
0.7169111402034759
 Minibatch[   1- 100]: loss = 0.592640 * 100, metric = 9.70% * 100;
 Minibatch[ 101- 200]: loss = 0.603117 * 100, metric = 9.53% * 100;
 Minibatch[ 201- 300]: loss = 0.604308 * 100, metric = 9.89% * 100;
 Minibatch[ 301- 400]: loss = 0.587049 * 100, metric = 9.42% * 100;
 Minibatch[ 401- 500]: loss = 0.595097 * 100, metric = 9.70% * 100;
 Minibatch[ 501- 600]: loss = 0.576123 * 100, metric = 9.34% * 100;
 Minibatch[ 601- 700]: loss = 0.583262 * 100, metric = 9.17% * 100;
 Minibatch[ 701- 800]: loss = 0.588470 * 100, metric = 9.38% * 100;
 Minibatch[ 801- 900]: loss = 0.590301 * 100, metric = 9.64% * 100;
 Minibatch[ 901-1000]: loss = 0.582187 * 100, metric = 9.84% * 100;
 Minibatch[1001-1100]: loss = 0.592210 * 100, metric = 9.89% * 100;
 Minibatch[1101-1200]: loss = 0.582405 * 100, metric = 9.50% * 100;
 Minibatch[1201-1300]: loss = 0.593405 * 100, metric = 10.07% * 100;
 Minibatch[1301-1400]: loss = 0.575101 * 100, metric = 9.21% * 100;
 Minibatch[1401-1500]: loss = 0.572310 * 100, metric = 9.18% * 100;
 Minibatch[1501-1600]: loss = 0.590768 * 100, metric = 9.69% * 100;
 Minibatch[1601-1700]: loss = 0.592120 * 100, metric = 9.63% * 100;
 Minibatch[1701-1800]: loss = 0.571396 * 100, metric = 9.43% * 100;
 Minibatch[1801-1900]: loss = 0.583503 * 100, metric = 9.69% * 100;
 Minibatch[1901-2000]: loss = 0.590691 * 100, metric = 9.93% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.587323 * 2000, metric = 9.59% * 2000 957.051s (  2.1 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 16.81% * 2000;
0.6693218462690711
 Minibatch[   1- 100]: loss = 0.595601 * 100, metric = 9.87% * 100;
 Minibatch[ 101- 200]: loss = 0.582354 * 100, metric = 9.65% * 100;
 Minibatch[ 201- 300]: loss = 0.566263 * 100, metric = 9.30% * 100;
 Minibatch[ 301- 400]: loss = 0.574004 * 100, metric = 9.44% * 100;
 Minibatch[ 401- 500]: loss = 0.584352 * 100, metric = 9.80% * 100;
 Minibatch[ 501- 600]: loss = 0.604294 * 100, metric = 10.13% * 100;
 Minibatch[ 601- 700]: loss = 0.565694 * 100, metric = 9.26% * 100;
 Minibatch[ 701- 800]: loss = 0.587958 * 100, metric = 9.57% * 100;
 Minibatch[ 801- 900]: loss = 0.570174 * 100, metric = 9.08% * 100;
 Minibatch[ 901-1000]: loss = 0.563400 * 100, metric = 9.05% * 100;
 Minibatch[1001-1100]: loss = 0.564788 * 100, metric = 9.06% * 100;
 Minibatch[1101-1200]: loss = 0.562354 * 100, metric = 8.92% * 100;
 Minibatch[1201-1300]: loss = 0.578470 * 100, metric = 9.52% * 100;
 Minibatch[1301-1400]: loss = 0.585032 * 100, metric = 9.49% * 100;
 Minibatch[1401-1500]: loss = 0.572664 * 100, metric = 9.07% * 100;
 Minibatch[1501-1600]: loss = 0.584915 * 100, metric = 9.64% * 100;
 Minibatch[1601-1700]: loss = 0.573475 * 100, metric = 9.18% * 100;
 Minibatch[1701-1800]: loss = 0.566733 * 100, metric = 8.87% * 100;
 Minibatch[1801-1900]: loss = 0.568448 * 100, metric = 9.21% * 100;
 Minibatch[1901-2000]: loss = 0.577544 * 100, metric = 9.53% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.576426 * 2000, metric = 9.38% * 2000 944.224s (  2.1 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 15.94% * 2000;
0.6459962442815304
 Minibatch[   1- 100]: loss = 0.555019 * 100, metric = 8.79% * 100;
 Minibatch[ 101- 200]: loss = 0.580767 * 100, metric = 9.61% * 100;
 Minibatch[ 201- 300]: loss = 0.571684 * 100, metric = 9.10% * 100;
 Minibatch[ 301- 400]: loss = 0.589288 * 100, metric = 9.81% * 100;
 Minibatch[ 401- 500]: loss = 0.567892 * 100, metric = 8.95% * 100;
 Minibatch[ 501- 600]: loss = 0.552423 * 100, metric = 8.65% * 100;
 Minibatch[ 601- 700]: loss = 0.551385 * 100, metric = 8.94% * 100;
 Minibatch[ 701- 800]: loss = 0.544823 * 100, metric = 8.78% * 100;
 Minibatch[ 801- 900]: loss = 0.543430 * 100, metric = 8.73% * 100;
 Minibatch[ 901-1000]: loss = 0.553266 * 100, metric = 9.12% * 100;
 Minibatch[1001-1100]: loss = 0.523629 * 100, metric = 8.16% * 100;
 Minibatch[1101-1200]: loss = 0.546881 * 100, metric = 8.53% * 100;
 Minibatch[1201-1300]: loss = 0.539445 * 100, metric = 8.68% * 100;
 Minibatch[1301-1400]: loss = 0.535136 * 100, metric = 8.35% * 100;
 Minibatch[1401-1500]: loss = 0.551064 * 100, metric = 8.91% * 100;
 Minibatch[1501-1600]: loss = 0.555021 * 100, metric = 8.74% * 100;
 Minibatch[1601-1700]: loss = 0.563676 * 100, metric = 9.39% * 100;
 Minibatch[1701-1800]: loss = 0.544927 * 100, metric = 8.46% * 100;
 Minibatch[1801-1900]: loss = 0.553421 * 100, metric = 8.89% * 100;
 Minibatch[1901-2000]: loss = 0.566359 * 100, metric = 9.07% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.554477 * 2000, metric = 8.88% * 2000 936.896s (  2.1 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 15.17% * 2000;
0.6304206252098083
 Minibatch[   1- 100]: loss = 0.568423 * 100, metric = 9.19% * 100;
 Minibatch[ 101- 200]: loss = 0.543445 * 100, metric = 8.49% * 100;
 Minibatch[ 201- 300]: loss = 0.551930 * 100, metric = 8.96% * 100;
 Minibatch[ 301- 400]: loss = 0.536837 * 100, metric = 8.33% * 100;
 Minibatch[ 401- 500]: loss = 0.551565 * 100, metric = 8.75% * 100;
 Minibatch[ 501- 600]: loss = 0.539333 * 100, metric = 8.59% * 100;
 Minibatch[ 601- 700]: loss = 0.526113 * 100, metric = 8.25% * 100;
 Minibatch[ 701- 800]: loss = 0.520075 * 100, metric = 7.84% * 100;
 Minibatch[ 801- 900]: loss = 0.547598 * 100, metric = 8.73% * 100;
 Minibatch[ 901-1000]: loss = 0.549889 * 100, metric = 8.76% * 100;
 Minibatch[1001-1100]: loss = 0.545125 * 100, metric = 8.69% * 100;
 Minibatch[1101-1200]: loss = 0.553140 * 100, metric = 8.73% * 100;
 Minibatch[1201-1300]: loss = 0.551732 * 100, metric = 8.95% * 100;
 Minibatch[1301-1400]: loss = 0.542759 * 100, metric = 8.75% * 100;
 Minibatch[1401-1500]: loss = 0.536720 * 100, metric = 8.17% * 100;
 Minibatch[1501-1600]: loss = 0.539005 * 100, metric = 8.68% * 100;
 Minibatch[1601-1700]: loss = 0.537471 * 100, metric = 8.11% * 100;
 Minibatch[1701-1800]: loss = 0.543915 * 100, metric = 8.58% * 100;
 Minibatch[1801-1900]: loss = 0.553605 * 100, metric = 8.76% * 100;
 Minibatch[1901-2000]: loss = 0.530955 * 100, metric = 8.39% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.543482 * 2000, metric = 8.59% * 2000 940.203s (  2.1 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 14.50% * 2000;
0.620353927321732
 Minibatch[   1- 100]: loss = 0.523648 * 100, metric = 8.04% * 100;
 Minibatch[ 101- 200]: loss = 0.534626 * 100, metric = 8.37% * 100;
 Minibatch[ 201- 300]: loss = 0.545096 * 100, metric = 8.68% * 100;
 Minibatch[ 301- 400]: loss = 0.535657 * 100, metric = 8.40% * 100;
 Minibatch[ 401- 500]: loss = 0.521098 * 100, metric = 8.13% * 100;
 Minibatch[ 501- 600]: loss = 0.536381 * 100, metric = 8.50% * 100;
 Minibatch[ 601- 700]: loss = 0.528997 * 100, metric = 8.17% * 100;
 Minibatch[ 701- 800]: loss = 0.541384 * 100, metric = 8.76% * 100;
 Minibatch[ 801- 900]: loss = 0.539012 * 100, metric = 8.44% * 100;
 Minibatch[ 901-1000]: loss = 0.546053 * 100, metric = 8.48% * 100;
 Minibatch[1001-1100]: loss = 0.542379 * 100, metric = 8.45% * 100;
 Minibatch[1101-1200]: loss = 0.545995 * 100, metric = 8.67% * 100;
 Minibatch[1201-1300]: loss = 0.536442 * 100, metric = 8.63% * 100;
 Minibatch[1301-1400]: loss = 0.519735 * 100, metric = 8.22% * 100;
 Minibatch[1401-1500]: loss = 0.538588 * 100, metric = 8.67% * 100;
 Minibatch[1501-1600]: loss = 0.517951 * 100, metric = 7.91% * 100;
 Minibatch[1601-1700]: loss = 0.528469 * 100, metric = 8.20% * 100;
 Minibatch[1701-1800]: loss = 0.548240 * 100, metric = 8.66% * 100;
 Minibatch[1801-1900]: loss = 0.529180 * 100, metric = 8.48% * 100;
 Minibatch[1901-2000]: loss = 0.523398 * 100, metric = 8.44% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.534117 * 2000, metric = 8.41% * 2000 950.197s (  2.1 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 15.32% * 2000;
 Minibatch[   1- 100]: loss = 0.508399 * 100, metric = 7.92% * 100;
 Minibatch[ 101- 200]: loss = 0.516460 * 100, metric = 8.14% * 100;
 Minibatch[ 201- 300]: loss = 0.517857 * 100, metric = 8.02% * 100;
 Minibatch[ 301- 400]: loss = 0.557519 * 100, metric = 8.97% * 100;
 Minibatch[ 401- 500]: loss = 0.516165 * 100, metric = 7.84% * 100;
 Minibatch[ 501- 600]: loss = 0.502130 * 100, metric = 7.41% * 100;
 Minibatch[ 601- 700]: loss = 0.508291 * 100, metric = 7.76% * 100;
 Minibatch[ 701- 800]: loss = 0.515961 * 100, metric = 8.03% * 100;
 Minibatch[ 801- 900]: loss = 0.510824 * 100, metric = 7.66% * 100;
 Minibatch[ 901-1000]: loss = 0.514478 * 100, metric = 8.08% * 100;
 Minibatch[1001-1100]: loss = 0.521323 * 100, metric = 8.25% * 100;
 Minibatch[1101-1200]: loss = 0.526741 * 100, metric = 8.08% * 100;
 Minibatch[1201-1300]: loss = 0.535123 * 100, metric = 8.39% * 100;
 Minibatch[1301-1400]: loss = 0.517232 * 100, metric = 7.96% * 100;
 Minibatch[1401-1500]: loss = 0.537554 * 100, metric = 8.67% * 100;
 Minibatch[1501-1600]: loss = 0.500699 * 100, metric = 7.79% * 100;
 Minibatch[1601-1700]: loss = 0.534213 * 100, metric = 8.43% * 100;
 Minibatch[1701-1800]: loss = 0.525118 * 100, metric = 8.21% * 100;
 Minibatch[1801-1900]: loss = 0.518347 * 100, metric = 8.27% * 100;
 Minibatch[1901-2000]: loss = 0.533566 * 100, metric = 8.38% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.520900 * 2000, metric = 8.11% * 2000 919.592s (  2.2 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 16.30% * 2000;
 Minibatch[   1- 100]: loss = 0.531250 * 100, metric = 8.14% * 100;
 Minibatch[ 101- 200]: loss = 0.527909 * 100, metric = 8.43% * 100;
 Minibatch[ 201- 300]: loss = 0.522932 * 100, metric = 8.37% * 100;
 Minibatch[ 301- 400]: loss = 0.526202 * 100, metric = 8.26% * 100;
 Minibatch[ 401- 500]: loss = 0.533956 * 100, metric = 8.94% * 100;
 Minibatch[ 501- 600]: loss = 0.534788 * 100, metric = 8.72% * 100;
 Minibatch[ 601- 700]: loss = 0.513380 * 100, metric = 7.83% * 100;
 Minibatch[ 701- 800]: loss = 0.516967 * 100, metric = 8.04% * 100;
 Minibatch[ 801- 900]: loss = 0.520928 * 100, metric = 8.10% * 100;
 Minibatch[ 901-1000]: loss = 0.531090 * 100, metric = 8.25% * 100;
 Minibatch[1001-1100]: loss = 0.536337 * 100, metric = 8.40% * 100;
 Minibatch[1101-1200]: loss = 0.517316 * 100, metric = 8.05% * 100;
 Minibatch[1201-1300]: loss = 0.525958 * 100, metric = 8.31% * 100;
 Minibatch[1301-1400]: loss = 0.507822 * 100, metric = 7.78% * 100;
 Minibatch[1401-1500]: loss = 0.508168 * 100, metric = 7.67% * 100;
 Minibatch[1501-1600]: loss = 0.502877 * 100, metric = 7.43% * 100;
 Minibatch[1601-1700]: loss = 0.506353 * 100, metric = 7.66% * 100;
 Minibatch[1701-1800]: loss = 0.496136 * 100, metric = 7.51% * 100;
 Minibatch[1801-1900]: loss = 0.502755 * 100, metric = 7.51% * 100;
 Minibatch[1901-2000]: loss = 0.520142 * 100, metric = 8.09% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.519163 * 2000, metric = 8.07% * 2000 849.076s (  2.4 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 17.55% * 2000;
 Minibatch[   1- 100]: loss = 0.513772 * 100, metric = 7.53% * 100;
 Minibatch[ 101- 200]: loss = 0.504994 * 100, metric = 7.66% * 100;
 Minibatch[ 201- 300]: loss = 0.519742 * 100, metric = 8.06% * 100;
 Minibatch[ 301- 400]: loss = 0.503280 * 100, metric = 7.56% * 100;
 Minibatch[ 401- 500]: loss = 0.502327 * 100, metric = 7.66% * 100;
 Minibatch[ 501- 600]: loss = 0.499351 * 100, metric = 7.31% * 100;
 Minibatch[ 601- 700]: loss = 0.492161 * 100, metric = 7.36% * 100;
 Minibatch[ 701- 800]: loss = 0.525029 * 100, metric = 7.89% * 100;
 Minibatch[ 801- 900]: loss = 0.511908 * 100, metric = 7.93% * 100;
 Minibatch[ 901-1000]: loss = 0.511713 * 100, metric = 7.79% * 100;
 Minibatch[1001-1100]: loss = 0.506485 * 100, metric = 7.81% * 100;
 Minibatch[1101-1200]: loss = 0.494801 * 100, metric = 7.50% * 100;
 Minibatch[1201-1300]: loss = 0.481148 * 100, metric = 7.24% * 100;
 Minibatch[1301-1400]: loss = 0.501030 * 100, metric = 7.83% * 100;
 Minibatch[1401-1500]: loss = 0.495131 * 100, metric = 7.57% * 100;
 Minibatch[1501-1600]: loss = 0.495967 * 100, metric = 7.55% * 100;
 Minibatch[1601-1700]: loss = 0.500668 * 100, metric = 7.52% * 100;
 Minibatch[1701-1800]: loss = 0.493383 * 100, metric = 7.44% * 100;
 Minibatch[1801-1900]: loss = 0.491184 * 100, metric = 7.55% * 100;
 Minibatch[1901-2000]: loss = 0.510475 * 100, metric = 7.63% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.502727 * 2000, metric = 7.62% * 2000 857.340s (  2.3 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 17.07% * 2000;
 Minibatch[   1- 100]: loss = 0.493520 * 100, metric = 7.66% * 100;
 Minibatch[ 101- 200]: loss = 0.514278 * 100, metric = 7.95% * 100;
 Minibatch[ 201- 300]: loss = 0.506145 * 100, metric = 7.73% * 100;
 Minibatch[ 301- 400]: loss = 0.489621 * 100, metric = 7.30% * 100;
 Minibatch[ 401- 500]: loss = 0.489570 * 100, metric = 7.34% * 100;
 Minibatch[ 501- 600]: loss = 0.489215 * 100, metric = 7.30% * 100;
 Minibatch[ 601- 700]: loss = 0.467592 * 100, metric = 6.99% * 100;
 Minibatch[ 701- 800]: loss = 0.497307 * 100, metric = 7.54% * 100;
 Minibatch[ 801- 900]: loss = 0.505772 * 100, metric = 8.00% * 100;
 Minibatch[ 901-1000]: loss = 0.500268 * 100, metric = 7.58% * 100;
 Minibatch[1001-1100]: loss = 0.500681 * 100, metric = 7.75% * 100;
 Minibatch[1101-1200]: loss = 0.493771 * 100, metric = 7.41% * 100;
 Minibatch[1201-1300]: loss = 0.475906 * 100, metric = 7.06% * 100;
 Minibatch[1301-1400]: loss = 0.509869 * 100, metric = 8.09% * 100;
 Minibatch[1401-1500]: loss = 0.466842 * 100, metric = 6.82% * 100;
 Minibatch[1501-1600]: loss = 0.484409 * 100, metric = 7.45% * 100;
 Minibatch[1601-1700]: loss = 0.494666 * 100, metric = 7.46% * 100;
 Minibatch[1701-1800]: loss = 0.466780 * 100, metric = 6.94% * 100;
 Minibatch[1801-1900]: loss = 0.486531 * 100, metric = 7.41% * 100;
 Minibatch[1901-2000]: loss = 0.475139 * 100, metric = 7.15% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.490394 * 2000, metric = 7.45% * 2000 839.581s (  2.4 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 14.04% * 2000;
0.61603528419137
 Minibatch[   1- 100]: loss = 0.503960 * 100, metric = 8.07% * 100;
 Minibatch[ 101- 200]: loss = 0.494602 * 100, metric = 7.44% * 100;
 Minibatch[ 201- 300]: loss = 0.494014 * 100, metric = 7.56% * 100;
 Minibatch[ 301- 400]: loss = 0.495801 * 100, metric = 7.54% * 100;
 Minibatch[ 401- 500]: loss = 0.466555 * 100, metric = 7.00% * 100;
 Minibatch[ 501- 600]: loss = 0.483749 * 100, metric = 7.41% * 100;
 Minibatch[ 601- 700]: loss = 0.488297 * 100, metric = 7.41% * 100;
 Minibatch[ 701- 800]: loss = 0.485131 * 100, metric = 7.39% * 100;
 Minibatch[ 801- 900]: loss = 0.482105 * 100, metric = 7.26% * 100;
 Minibatch[ 901-1000]: loss = 0.497186 * 100, metric = 7.93% * 100;
 Minibatch[1001-1100]: loss = 0.476245 * 100, metric = 7.32% * 100;
 Minibatch[1101-1200]: loss = 0.483939 * 100, metric = 7.45% * 100;
 Minibatch[1201-1300]: loss = 0.457878 * 100, metric = 6.53% * 100;
 Minibatch[1301-1400]: loss = 0.476508 * 100, metric = 7.00% * 100;
 Minibatch[1401-1500]: loss = 0.480115 * 100, metric = 7.51% * 100;
 Minibatch[1501-1600]: loss = 0.481287 * 100, metric = 7.23% * 100;
 Minibatch[1601-1700]: loss = 0.490727 * 100, metric = 7.73% * 100;
 Minibatch[1701-1800]: loss = 0.502636 * 100, metric = 7.76% * 100;
 Minibatch[1801-1900]: loss = 0.496113 * 100, metric = 7.72% * 100;
 Minibatch[1901-2000]: loss = 0.481428 * 100, metric = 7.45% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.485914 * 2000, metric = 7.44% * 2000 839.573s (  2.4 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 15.25% * 2000;
 Minibatch[   1- 100]: loss = 0.471246 * 100, metric = 7.02% * 100;
 Minibatch[ 101- 200]: loss = 0.496637 * 100, metric = 7.68% * 100;
 Minibatch[ 201- 300]: loss = 0.488748 * 100, metric = 7.39% * 100;
 Minibatch[ 301- 400]: loss = 0.483419 * 100, metric = 7.34% * 100;
 Minibatch[ 401- 500]: loss = 0.489305 * 100, metric = 7.25% * 100;
 Minibatch[ 501- 600]: loss = 0.474953 * 100, metric = 7.12% * 100;
 Minibatch[ 601- 700]: loss = 0.453073 * 100, metric = 6.51% * 100;
 Minibatch[ 701- 800]: loss = 0.464294 * 100, metric = 6.74% * 100;
 Minibatch[ 801- 900]: loss = 0.478622 * 100, metric = 7.16% * 100;
 Minibatch[ 901-1000]: loss = 0.467717 * 100, metric = 6.95% * 100;
 Minibatch[1001-1100]: loss = 0.461552 * 100, metric = 6.77% * 100;
 Minibatch[1101-1200]: loss = 0.490230 * 100, metric = 7.48% * 100;
 Minibatch[1201-1300]: loss = 0.486899 * 100, metric = 7.40% * 100;
 Minibatch[1301-1400]: loss = 0.462636 * 100, metric = 6.79% * 100;
 Minibatch[1401-1500]: loss = 0.476367 * 100, metric = 7.08% * 100;
 Minibatch[1501-1600]: loss = 0.473223 * 100, metric = 7.10% * 100;
 Minibatch[1601-1700]: loss = 0.478462 * 100, metric = 7.21% * 100;
 Minibatch[1701-1800]: loss = 0.463257 * 100, metric = 6.92% * 100;
 Minibatch[1801-1900]: loss = 0.491996 * 100, metric = 7.59% * 100;
 Minibatch[1901-2000]: loss = 0.496186 * 100, metric = 7.73% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.477441 * 2000, metric = 7.16% * 2000 838.283s (  2.4 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.49% * 2000;
 Minibatch[   1- 100]: loss = 0.468831 * 100, metric = 6.97% * 100;
 Minibatch[ 101- 200]: loss = 0.491104 * 100, metric = 7.40% * 100;
 Minibatch[ 201- 300]: loss = 0.473028 * 100, metric = 7.12% * 100;
 Minibatch[ 301- 400]: loss = 0.478956 * 100, metric = 7.24% * 100;
 Minibatch[ 401- 500]: loss = 0.464220 * 100, metric = 6.87% * 100;
 Minibatch[ 501- 600]: loss = 0.467335 * 100, metric = 7.02% * 100;
 Minibatch[ 601- 700]: loss = 0.480497 * 100, metric = 7.28% * 100;
 Minibatch[ 701- 800]: loss = 0.461047 * 100, metric = 6.93% * 100;
 Minibatch[ 801- 900]: loss = 0.477649 * 100, metric = 7.12% * 100;
 Minibatch[ 901-1000]: loss = 0.475585 * 100, metric = 7.10% * 100;
 Minibatch[1001-1100]: loss = 0.484190 * 100, metric = 7.26% * 100;
 Minibatch[1101-1200]: loss = 0.475848 * 100, metric = 7.28% * 100;
 Minibatch[1201-1300]: loss = 0.488387 * 100, metric = 7.52% * 100;
 Minibatch[1301-1400]: loss = 0.489005 * 100, metric = 7.56% * 100;
 Minibatch[1401-1500]: loss = 0.456187 * 100, metric = 6.79% * 100;
 Minibatch[1501-1600]: loss = 0.477695 * 100, metric = 7.16% * 100;
 Minibatch[1601-1700]: loss = 0.456605 * 100, metric = 6.69% * 100;
 Minibatch[1701-1800]: loss = 0.473865 * 100, metric = 7.09% * 100;
 Minibatch[1801-1900]: loss = 0.465106 * 100, metric = 6.91% * 100;
 Minibatch[1901-2000]: loss = 0.469079 * 100, metric = 6.94% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.473711 * 2000, metric = 7.11% * 2000 833.628s (  2.4 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.37% * 2000;
 Minibatch[   1- 100]: loss = 0.480671 * 100, metric = 7.31% * 100;
 Minibatch[ 101- 200]: loss = 0.491046 * 100, metric = 7.40% * 100;
 Minibatch[ 201- 300]: loss = 0.473825 * 100, metric = 7.00% * 100;
 Minibatch[ 301- 400]: loss = 0.488219 * 100, metric = 7.48% * 100;
 Minibatch[ 401- 500]: loss = 0.480164 * 100, metric = 7.26% * 100;
 Minibatch[ 501- 600]: loss = 0.471877 * 100, metric = 7.00% * 100;
 Minibatch[ 601- 700]: loss = 0.485260 * 100, metric = 7.40% * 100;
 Minibatch[ 701- 800]: loss = 0.470351 * 100, metric = 6.93% * 100;
 Minibatch[ 801- 900]: loss = 0.500335 * 100, metric = 7.65% * 100;
 Minibatch[ 901-1000]: loss = 0.466294 * 100, metric = 6.93% * 100;
 Minibatch[1001-1100]: loss = 0.482531 * 100, metric = 7.15% * 100;
 Minibatch[1101-1200]: loss = 0.482476 * 100, metric = 7.49% * 100;
 Minibatch[1201-1300]: loss = 0.474077 * 100, metric = 7.19% * 100;
 Minibatch[1301-1400]: loss = 0.459530 * 100, metric = 6.87% * 100;
 Minibatch[1401-1500]: loss = 0.483061 * 100, metric = 7.46% * 100;
 Minibatch[1501-1600]: loss = 0.471158 * 100, metric = 7.01% * 100;
 Minibatch[1601-1700]: loss = 0.456187 * 100, metric = 6.74% * 100;
 Minibatch[1701-1800]: loss = 0.451617 * 100, metric = 6.70% * 100;
 Minibatch[1801-1900]: loss = 0.458870 * 100, metric = 6.82% * 100;
 Minibatch[1901-2000]: loss = 0.454986 * 100, metric = 6.63% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.474127 * 2000, metric = 7.12% * 2000 838.299s (  2.4 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 15.07% * 2000;
 Minibatch[   1- 100]: loss = 0.460668 * 100, metric = 6.65% * 100;
 Minibatch[ 101- 200]: loss = 0.463430 * 100, metric = 6.73% * 100;
 Minibatch[ 201- 300]: loss = 0.469995 * 100, metric = 6.79% * 100;
 Minibatch[ 301- 400]: loss = 0.482380 * 100, metric = 7.21% * 100;
 Minibatch[ 401- 500]: loss = 0.473235 * 100, metric = 7.00% * 100;
 Minibatch[ 501- 600]: loss = 0.477073 * 100, metric = 7.31% * 100;
 Minibatch[ 601- 700]: loss = 0.483946 * 100, metric = 7.48% * 100;
 Minibatch[ 701- 800]: loss = 0.468349 * 100, metric = 7.03% * 100;
 Minibatch[ 801- 900]: loss = 0.485437 * 100, metric = 7.31% * 100;
 Minibatch[ 901-1000]: loss = 0.479173 * 100, metric = 7.44% * 100;
 Minibatch[1001-1100]: loss = 0.458627 * 100, metric = 6.81% * 100;
 Minibatch[1101-1200]: loss = 0.468682 * 100, metric = 6.77% * 100;
 Minibatch[1201-1300]: loss = 0.477708 * 100, metric = 7.20% * 100;
 Minibatch[1301-1400]: loss = 0.470229 * 100, metric = 7.04% * 100;
 Minibatch[1401-1500]: loss = 0.456277 * 100, metric = 6.84% * 100;
 Minibatch[1501-1600]: loss = 0.479379 * 100, metric = 7.31% * 100;
 Minibatch[1601-1700]: loss = 0.464038 * 100, metric = 7.18% * 100;
 Minibatch[1701-1800]: loss = 0.471742 * 100, metric = 7.17% * 100;
 Minibatch[1801-1900]: loss = 0.475673 * 100, metric = 7.33% * 100;
 Minibatch[1901-2000]: loss = 0.463129 * 100, metric = 7.08% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.471458 * 2000, metric = 7.08% * 2000 817.027s (  2.4 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 14.08% * 2000;
 Minibatch[   1- 100]: loss = 0.470334 * 100, metric = 6.93% * 100;
 Minibatch[ 101- 200]: loss = 0.467242 * 100, metric = 7.11% * 100;
 Minibatch[ 201- 300]: loss = 0.459754 * 100, metric = 7.03% * 100;
 Minibatch[ 301- 400]: loss = 0.468173 * 100, metric = 6.98% * 100;
 Minibatch[ 401- 500]: loss = 0.453299 * 100, metric = 6.63% * 100;
 Minibatch[ 501- 600]: loss = 0.452903 * 100, metric = 6.54% * 100;
 Minibatch[ 601- 700]: loss = 0.452379 * 100, metric = 6.72% * 100;
 Minibatch[ 701- 800]: loss = 0.441591 * 100, metric = 6.58% * 100;
 Minibatch[ 801- 900]: loss = 0.467722 * 100, metric = 6.92% * 100;
 Minibatch[ 901-1000]: loss = 0.450653 * 100, metric = 6.66% * 100;
 Minibatch[1001-1100]: loss = 0.466736 * 100, metric = 6.88% * 100;
 Minibatch[1101-1200]: loss = 0.453826 * 100, metric = 6.51% * 100;
 Minibatch[1201-1300]: loss = 0.460342 * 100, metric = 6.58% * 100;
 Minibatch[1301-1400]: loss = 0.454521 * 100, metric = 6.53% * 100;
 Minibatch[1401-1500]: loss = 0.460211 * 100, metric = 6.69% * 100;
 Minibatch[1501-1600]: loss = 0.461553 * 100, metric = 6.90% * 100;
 Minibatch[1601-1700]: loss = 0.440236 * 100, metric = 6.38% * 100;
 Minibatch[1701-1800]: loss = 0.449893 * 100, metric = 6.30% * 100;
 Minibatch[1801-1900]: loss = 0.470720 * 100, metric = 6.83% * 100;
 Minibatch[1901-2000]: loss = 0.446550 * 100, metric = 6.37% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.457432 * 2000, metric = 6.70% * 2000 769.956s (  2.6 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 14.24% * 2000;
 Minibatch[   1- 100]: loss = 0.472243 * 100, metric = 6.74% * 100;
 Minibatch[ 101- 200]: loss = 0.460307 * 100, metric = 6.66% * 100;
 Minibatch[ 201- 300]: loss = 0.466222 * 100, metric = 6.76% * 100;
 Minibatch[ 301- 400]: loss = 0.450081 * 100, metric = 6.65% * 100;
 Minibatch[ 401- 500]: loss = 0.438889 * 100, metric = 6.25% * 100;
 Minibatch[ 501- 600]: loss = 0.454034 * 100, metric = 6.38% * 100;
 Minibatch[ 601- 700]: loss = 0.444188 * 100, metric = 6.37% * 100;
 Minibatch[ 701- 800]: loss = 0.453953 * 100, metric = 6.71% * 100;
 Minibatch[ 801- 900]: loss = 0.453399 * 100, metric = 6.59% * 100;
 Minibatch[ 901-1000]: loss = 0.461945 * 100, metric = 6.89% * 100;
 Minibatch[1001-1100]: loss = 0.437366 * 100, metric = 6.26% * 100;
 Minibatch[1101-1200]: loss = 0.416286 * 100, metric = 5.80% * 100;
 Minibatch[1201-1300]: loss = 0.448939 * 100, metric = 6.58% * 100;
 Minibatch[1301-1400]: loss = 0.446033 * 100, metric = 6.54% * 100;
 Minibatch[1401-1500]: loss = 0.440607 * 100, metric = 6.51% * 100;
 Minibatch[1501-1600]: loss = 0.440361 * 100, metric = 6.30% * 100;
 Minibatch[1601-1700]: loss = 0.442650 * 100, metric = 6.46% * 100;
 Minibatch[1701-1800]: loss = 0.439824 * 100, metric = 6.15% * 100;
 Minibatch[1801-1900]: loss = 0.440305 * 100, metric = 6.37% * 100;
 Minibatch[1901-2000]: loss = 0.453269 * 100, metric = 6.73% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.448045 * 2000, metric = 6.49% * 2000 768.432s (  2.6 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 15.43% * 2000;
 Minibatch[   1- 100]: loss = 0.459217 * 100, metric = 6.87% * 100;
 Minibatch[ 101- 200]: loss = 0.456951 * 100, metric = 6.98% * 100;
 Minibatch[ 201- 300]: loss = 0.447898 * 100, metric = 6.41% * 100;
 Minibatch[ 301- 400]: loss = 0.451176 * 100, metric = 6.76% * 100;
 Minibatch[ 401- 500]: loss = 0.465183 * 100, metric = 6.88% * 100;
 Minibatch[ 501- 600]: loss = 0.451327 * 100, metric = 6.58% * 100;
 Minibatch[ 601- 700]: loss = 0.455990 * 100, metric = 6.77% * 100;
 Minibatch[ 701- 800]: loss = 0.438098 * 100, metric = 6.20% * 100;
 Minibatch[ 801- 900]: loss = 0.437492 * 100, metric = 6.34% * 100;
 Minibatch[ 901-1000]: loss = 0.454029 * 100, metric = 6.57% * 100;
 Minibatch[1001-1100]: loss = 0.430704 * 100, metric = 5.96% * 100;
 Minibatch[1101-1200]: loss = 0.444773 * 100, metric = 6.46% * 100;
 Minibatch[1201-1300]: loss = 0.446187 * 100, metric = 6.27% * 100;
 Minibatch[1301-1400]: loss = 0.449630 * 100, metric = 6.57% * 100;
 Minibatch[1401-1500]: loss = 0.433000 * 100, metric = 6.11% * 100;
 Minibatch[1501-1600]: loss = 0.441041 * 100, metric = 6.18% * 100;
 Minibatch[1601-1700]: loss = 0.437133 * 100, metric = 6.25% * 100;
 Minibatch[1701-1800]: loss = 0.451328 * 100, metric = 6.48% * 100;
 Minibatch[1801-1900]: loss = 0.434686 * 100, metric = 6.42% * 100;
 Minibatch[1901-2000]: loss = 0.445021 * 100, metric = 6.39% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.446543 * 2000, metric = 6.47% * 2000 765.943s (  2.6 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 14.84% * 2000;
 Minibatch[   1- 100]: loss = 0.417923 * 100, metric = 6.02% * 100;
 Minibatch[ 101- 200]: loss = 0.440149 * 100, metric = 6.35% * 100;
 Minibatch[ 201- 300]: loss = 0.430966 * 100, metric = 6.04% * 100;
 Minibatch[ 301- 400]: loss = 0.438039 * 100, metric = 6.26% * 100;
 Minibatch[ 401- 500]: loss = 0.442727 * 100, metric = 6.52% * 100;
 Minibatch[ 501- 600]: loss = 0.428831 * 100, metric = 6.34% * 100;
 Minibatch[ 601- 700]: loss = 0.455561 * 100, metric = 6.57% * 100;
 Minibatch[ 701- 800]: loss = 0.436754 * 100, metric = 6.31% * 100;
 Minibatch[ 801- 900]: loss = 0.451160 * 100, metric = 6.67% * 100;
 Minibatch[ 901-1000]: loss = 0.441269 * 100, metric = 6.28% * 100;
 Minibatch[1001-1100]: loss = 0.440412 * 100, metric = 6.39% * 100;
 Minibatch[1101-1200]: loss = 0.452988 * 100, metric = 6.61% * 100;
 Minibatch[1201-1300]: loss = 0.438683 * 100, metric = 6.14% * 100;
 Minibatch[1301-1400]: loss = 0.430199 * 100, metric = 6.06% * 100;
 Minibatch[1401-1500]: loss = 0.441240 * 100, metric = 6.38% * 100;
 Minibatch[1501-1600]: loss = 0.444763 * 100, metric = 6.38% * 100;
 Minibatch[1601-1700]: loss = 0.431544 * 100, metric = 6.25% * 100;
 Minibatch[1701-1800]: loss = 0.430240 * 100, metric = 6.20% * 100;
 Minibatch[1801-1900]: loss = 0.442125 * 100, metric = 6.33% * 100;
 Minibatch[1901-2000]: loss = 0.439421 * 100, metric = 6.39% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.438750 * 2000, metric = 6.32% * 2000 764.651s (  2.6 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.18% * 2000;
 Minibatch[   1- 100]: loss = 0.440266 * 100, metric = 6.36% * 100;
 Minibatch[ 101- 200]: loss = 0.429526 * 100, metric = 6.14% * 100;
 Minibatch[ 201- 300]: loss = 0.432613 * 100, metric = 6.27% * 100;
 Minibatch[ 301- 400]: loss = 0.444854 * 100, metric = 6.53% * 100;
 Minibatch[ 401- 500]: loss = 0.434233 * 100, metric = 6.11% * 100;
 Minibatch[ 501- 600]: loss = 0.438044 * 100, metric = 6.16% * 100;
 Minibatch[ 601- 700]: loss = 0.443609 * 100, metric = 6.26% * 100;
 Minibatch[ 701- 800]: loss = 0.415648 * 100, metric = 5.64% * 100;
 Minibatch[ 801- 900]: loss = 0.421566 * 100, metric = 6.03% * 100;
 Minibatch[ 901-1000]: loss = 0.436482 * 100, metric = 6.29% * 100;
 Minibatch[1001-1100]: loss = 0.437306 * 100, metric = 6.25% * 100;
 Minibatch[1101-1200]: loss = 0.451973 * 100, metric = 6.37% * 100;
 Minibatch[1201-1300]: loss = 0.454671 * 100, metric = 6.37% * 100;
 Minibatch[1301-1400]: loss = 0.429094 * 100, metric = 5.95% * 100;
 Minibatch[1401-1500]: loss = 0.431315 * 100, metric = 5.98% * 100;
 Minibatch[1501-1600]: loss = 0.445142 * 100, metric = 6.37% * 100;
 Minibatch[1601-1700]: loss = 0.425038 * 100, metric = 5.86% * 100;
 Minibatch[1701-1800]: loss = 0.432735 * 100, metric = 6.15% * 100;
 Minibatch[1801-1900]: loss = 0.422827 * 100, metric = 5.83% * 100;
 Minibatch[1901-2000]: loss = 0.412245 * 100, metric = 5.76% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.433959 * 2000, metric = 6.13% * 2000 765.066s (  2.6 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.62% * 2000;
 Minibatch[   1- 100]: loss = 0.422441 * 100, metric = 6.02% * 100;
 Minibatch[ 101- 200]: loss = 0.408583 * 100, metric = 5.75% * 100;
 Minibatch[ 201- 300]: loss = 0.428376 * 100, metric = 6.13% * 100;
 Minibatch[ 301- 400]: loss = 0.417184 * 100, metric = 6.08% * 100;
 Minibatch[ 401- 500]: loss = 0.421495 * 100, metric = 5.96% * 100;
 Minibatch[ 501- 600]: loss = 0.421011 * 100, metric = 5.83% * 100;
 Minibatch[ 601- 700]: loss = 0.433165 * 100, metric = 6.22% * 100;
 Minibatch[ 701- 800]: loss = 0.420305 * 100, metric = 6.12% * 100;
 Minibatch[ 801- 900]: loss = 0.412391 * 100, metric = 5.74% * 100;
 Minibatch[ 901-1000]: loss = 0.414583 * 100, metric = 5.85% * 100;
 Minibatch[1001-1100]: loss = 0.434359 * 100, metric = 6.68% * 100;
 Minibatch[1101-1200]: loss = 0.439571 * 100, metric = 6.31% * 100;
 Minibatch[1201-1300]: loss = 0.432422 * 100, metric = 6.33% * 100;
 Minibatch[1301-1400]: loss = 0.413040 * 100, metric = 5.71% * 100;
 Minibatch[1401-1500]: loss = 0.424756 * 100, metric = 6.09% * 100;
 Minibatch[1501-1600]: loss = 0.421677 * 100, metric = 5.70% * 100;
 Minibatch[1601-1700]: loss = 0.441886 * 100, metric = 6.36% * 100;
 Minibatch[1701-1800]: loss = 0.441942 * 100, metric = 6.49% * 100;
 Minibatch[1801-1900]: loss = 0.427095 * 100, metric = 6.02% * 100;
 Minibatch[1901-2000]: loss = 0.439277 * 100, metric = 6.19% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.425778 * 2000, metric = 6.08% * 2000 747.494s (  2.7 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.17% * 2000;
 Minibatch[   1- 100]: loss = 0.431017 * 100, metric = 5.96% * 100;
 Minibatch[ 101- 200]: loss = 0.445875 * 100, metric = 6.40% * 100;
 Minibatch[ 201- 300]: loss = 0.429025 * 100, metric = 6.08% * 100;
 Minibatch[ 301- 400]: loss = 0.424597 * 100, metric = 6.03% * 100;
 Minibatch[ 401- 500]: loss = 0.427734 * 100, metric = 6.01% * 100;
 Minibatch[ 501- 600]: loss = 0.416608 * 100, metric = 6.07% * 100;
 Minibatch[ 601- 700]: loss = 0.419597 * 100, metric = 5.90% * 100;
 Minibatch[ 701- 800]: loss = 0.424415 * 100, metric = 6.07% * 100;
 Minibatch[ 801- 900]: loss = 0.434135 * 100, metric = 6.22% * 100;
 Minibatch[ 901-1000]: loss = 0.430793 * 100, metric = 6.17% * 100;
 Minibatch[1001-1100]: loss = 0.420473 * 100, metric = 5.80% * 100;
 Minibatch[1101-1200]: loss = 0.435626 * 100, metric = 6.19% * 100;
 Minibatch[1201-1300]: loss = 0.424477 * 100, metric = 6.19% * 100;
 Minibatch[1301-1400]: loss = 0.434130 * 100, metric = 6.26% * 100;
 Minibatch[1401-1500]: loss = 0.415453 * 100, metric = 6.03% * 100;
 Minibatch[1501-1600]: loss = 0.417165 * 100, metric = 5.90% * 100;
 Minibatch[1601-1700]: loss = 0.397114 * 100, metric = 5.48% * 100;
 Minibatch[1701-1800]: loss = 0.416081 * 100, metric = 5.81% * 100;
 Minibatch[1801-1900]: loss = 0.422542 * 100, metric = 6.12% * 100;
 Minibatch[1901-2000]: loss = 0.423661 * 100, metric = 5.89% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.424526 * 2000, metric = 6.03% * 2000 721.458s (  2.8 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.52% * 2000;
 Minibatch[   1- 100]: loss = 0.424743 * 100, metric = 6.10% * 100;
 Minibatch[ 101- 200]: loss = 0.415936 * 100, metric = 5.76% * 100;
 Minibatch[ 201- 300]: loss = 0.419585 * 100, metric = 5.86% * 100;
 Minibatch[ 301- 400]: loss = 0.421483 * 100, metric = 5.88% * 100;
 Minibatch[ 401- 500]: loss = 0.424622 * 100, metric = 6.19% * 100;
 Minibatch[ 501- 600]: loss = 0.442014 * 100, metric = 6.40% * 100;
 Minibatch[ 601- 700]: loss = 0.435338 * 100, metric = 6.23% * 100;
 Minibatch[ 701- 800]: loss = 0.411847 * 100, metric = 5.54% * 100;
 Minibatch[ 801- 900]: loss = 0.437960 * 100, metric = 6.32% * 100;
 Minibatch[ 901-1000]: loss = 0.437598 * 100, metric = 6.40% * 100;
 Minibatch[1001-1100]: loss = 0.428808 * 100, metric = 6.14% * 100;
 Minibatch[1101-1200]: loss = 0.424028 * 100, metric = 5.86% * 100;
 Minibatch[1201-1300]: loss = 0.427791 * 100, metric = 6.14% * 100;
 Minibatch[1301-1400]: loss = 0.424184 * 100, metric = 6.14% * 100;
 Minibatch[1401-1500]: loss = 0.441219 * 100, metric = 6.36% * 100;
 Minibatch[1501-1600]: loss = 0.420268 * 100, metric = 5.87% * 100;
 Minibatch[1601-1700]: loss = 0.429177 * 100, metric = 6.01% * 100;
 Minibatch[1701-1800]: loss = 0.422822 * 100, metric = 5.88% * 100;
 Minibatch[1801-1900]: loss = 0.420775 * 100, metric = 5.99% * 100;
 Minibatch[1901-2000]: loss = 0.422145 * 100, metric = 5.80% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.426617 * 2000, metric = 6.04% * 2000 726.505s (  2.8 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 14.30% * 2000;
 Minibatch[   1- 100]: loss = 0.417244 * 100, metric = 5.80% * 100;
 Minibatch[ 101- 200]: loss = 0.410300 * 100, metric = 5.93% * 100;
 Minibatch[ 201- 300]: loss = 0.424377 * 100, metric = 6.06% * 100;
 Minibatch[ 301- 400]: loss = 0.452884 * 100, metric = 6.61% * 100;
 Minibatch[ 401- 500]: loss = 0.417422 * 100, metric = 5.75% * 100;
 Minibatch[ 501- 600]: loss = 0.426151 * 100, metric = 5.98% * 100;
 Minibatch[ 601- 700]: loss = 0.415383 * 100, metric = 5.94% * 100;
 Minibatch[ 701- 800]: loss = 0.420873 * 100, metric = 5.93% * 100;
 Minibatch[ 801- 900]: loss = 0.420345 * 100, metric = 5.95% * 100;
 Minibatch[ 901-1000]: loss = 0.432075 * 100, metric = 6.08% * 100;
 Minibatch[1001-1100]: loss = 0.424626 * 100, metric = 6.06% * 100;
 Minibatch[1101-1200]: loss = 0.412497 * 100, metric = 5.70% * 100;
 Minibatch[1201-1300]: loss = 0.428869 * 100, metric = 5.96% * 100;
 Minibatch[1301-1400]: loss = 0.418575 * 100, metric = 5.98% * 100;
 Minibatch[1401-1500]: loss = 0.431416 * 100, metric = 6.05% * 100;
 Minibatch[1501-1600]: loss = 0.401212 * 100, metric = 5.44% * 100;
 Minibatch[1601-1700]: loss = 0.416826 * 100, metric = 5.81% * 100;
 Minibatch[1701-1800]: loss = 0.410211 * 100, metric = 5.59% * 100;
 Minibatch[1801-1900]: loss = 0.431820 * 100, metric = 6.00% * 100;
 Minibatch[1901-2000]: loss = 0.420093 * 100, metric = 5.85% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.421660 * 2000, metric = 5.92% * 2000 729.444s (  2.7 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 14.92% * 2000;
 Minibatch[   1- 100]: loss = 0.442150 * 100, metric = 6.17% * 100;
 Minibatch[ 101- 200]: loss = 0.406503 * 100, metric = 5.42% * 100;
 Minibatch[ 201- 300]: loss = 0.411984 * 100, metric = 5.46% * 100;
 Minibatch[ 301- 400]: loss = 0.423780 * 100, metric = 5.99% * 100;
 Minibatch[ 401- 500]: loss = 0.418253 * 100, metric = 5.65% * 100;
 Minibatch[ 501- 600]: loss = 0.404813 * 100, metric = 5.39% * 100;
 Minibatch[ 601- 700]: loss = 0.421353 * 100, metric = 6.02% * 100;
 Minibatch[ 701- 800]: loss = 0.408362 * 100, metric = 5.53% * 100;
 Minibatch[ 801- 900]: loss = 0.424045 * 100, metric = 5.92% * 100;
 Minibatch[ 901-1000]: loss = 0.387365 * 100, metric = 5.19% * 100;
 Minibatch[1001-1100]: loss = 0.415551 * 100, metric = 5.66% * 100;
 Minibatch[1101-1200]: loss = 0.421494 * 100, metric = 5.81% * 100;
 Minibatch[1201-1300]: loss = 0.407751 * 100, metric = 5.62% * 100;
 Minibatch[1301-1400]: loss = 0.412910 * 100, metric = 5.82% * 100;
 Minibatch[1401-1500]: loss = 0.413033 * 100, metric = 5.50% * 100;
 Minibatch[1501-1600]: loss = 0.425010 * 100, metric = 6.01% * 100;
 Minibatch[1601-1700]: loss = 0.413810 * 100, metric = 5.61% * 100;
 Minibatch[1701-1800]: loss = 0.419650 * 100, metric = 5.93% * 100;
 Minibatch[1801-1900]: loss = 0.408842 * 100, metric = 5.79% * 100;
 Minibatch[1901-2000]: loss = 0.429353 * 100, metric = 5.98% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.415801 * 2000, metric = 5.72% * 2000 728.746s (  2.7 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.66% * 2000;
 Minibatch[   1- 100]: loss = 0.415090 * 100, metric = 5.67% * 100;
 Minibatch[ 101- 200]: loss = 0.430810 * 100, metric = 6.45% * 100;
 Minibatch[ 201- 300]: loss = 0.412467 * 100, metric = 5.76% * 100;
 Minibatch[ 301- 400]: loss = 0.410956 * 100, metric = 5.74% * 100;
 Minibatch[ 401- 500]: loss = 0.414367 * 100, metric = 5.82% * 100;
 Minibatch[ 501- 600]: loss = 0.416112 * 100, metric = 5.80% * 100;
 Minibatch[ 601- 700]: loss = 0.427486 * 100, metric = 6.06% * 100;
 Minibatch[ 701- 800]: loss = 0.432822 * 100, metric = 6.16% * 100;
 Minibatch[ 801- 900]: loss = 0.413773 * 100, metric = 5.63% * 100;
 Minibatch[ 901-1000]: loss = 0.407396 * 100, metric = 5.52% * 100;
 Minibatch[1001-1100]: loss = 0.411657 * 100, metric = 5.71% * 100;
 Minibatch[1101-1200]: loss = 0.419283 * 100, metric = 5.97% * 100;
 Minibatch[1201-1300]: loss = 0.415892 * 100, metric = 5.73% * 100;
 Minibatch[1301-1400]: loss = 0.417971 * 100, metric = 5.82% * 100;
 Minibatch[1401-1500]: loss = 0.427676 * 100, metric = 6.13% * 100;
 Minibatch[1501-1600]: loss = 0.405074 * 100, metric = 5.76% * 100;
 Minibatch[1601-1700]: loss = 0.423030 * 100, metric = 6.04% * 100;
 Minibatch[1701-1800]: loss = 0.409683 * 100, metric = 5.74% * 100;
 Minibatch[1801-1900]: loss = 0.417478 * 100, metric = 5.98% * 100;
 Minibatch[1901-2000]: loss = 0.413994 * 100, metric = 5.82% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.417151 * 2000, metric = 5.87% * 2000 730.010s (  2.7 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 13.78% * 2000;
 Minibatch[   1- 100]: loss = 0.404969 * 100, metric = 5.50% * 100;
 Minibatch[ 101- 200]: loss = 0.412348 * 100, metric = 5.72% * 100;
 Minibatch[ 201- 300]: loss = 0.418054 * 100, metric = 5.78% * 100;
 Minibatch[ 301- 400]: loss = 0.419895 * 100, metric = 5.84% * 100;
 Minibatch[ 401- 500]: loss = 0.419359 * 100, metric = 6.06% * 100;
 Minibatch[ 501- 600]: loss = 0.413109 * 100, metric = 5.81% * 100;
 Minibatch[ 601- 700]: loss = 0.413846 * 100, metric = 5.56% * 100;
 Minibatch[ 701- 800]: loss = 0.405569 * 100, metric = 5.47% * 100;
 Minibatch[ 801- 900]: loss = 0.404658 * 100, metric = 5.54% * 100;
 Minibatch[ 901-1000]: loss = 0.398951 * 100, metric = 5.54% * 100;
 Minibatch[1001-1100]: loss = 0.408687 * 100, metric = 5.53% * 100;
 Minibatch[1101-1200]: loss = 0.413365 * 100, metric = 5.78% * 100;
 Minibatch[1201-1300]: loss = 0.421643 * 100, metric = 5.91% * 100;
 Minibatch[1301-1400]: loss = 0.411922 * 100, metric = 5.92% * 100;
 Minibatch[1401-1500]: loss = 0.413230 * 100, metric = 5.96% * 100;
 Minibatch[1501-1600]: loss = 0.421005 * 100, metric = 6.06% * 100;
 Minibatch[1601-1700]: loss = 0.404330 * 100, metric = 5.71% * 100;
 Minibatch[1701-1800]: loss = 0.421519 * 100, metric = 5.97% * 100;
 Minibatch[1801-1900]: loss = 0.398176 * 100, metric = 5.25% * 100;
 Minibatch[1901-2000]: loss = 0.419119 * 100, metric = 6.20% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.412188 * 2000, metric = 5.75% * 2000 738.736s (  2.7 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 14.66% * 2000;
 Minibatch[   1- 100]: loss = 0.430042 * 100, metric = 6.30% * 100;
 Minibatch[ 101- 200]: loss = 0.412464 * 100, metric = 5.90% * 100;
 Minibatch[ 201- 300]: loss = 0.405234 * 100, metric = 5.72% * 100;
 Minibatch[ 301- 400]: loss = 0.413204 * 100, metric = 6.01% * 100;
 Minibatch[ 401- 500]: loss = 0.406181 * 100, metric = 5.71% * 100;
 Minibatch[ 501- 600]: loss = 0.409652 * 100, metric = 5.60% * 100;
 Minibatch[ 601- 700]: loss = 0.418419 * 100, metric = 5.83% * 100;
 Minibatch[ 701- 800]: loss = 0.417905 * 100, metric = 5.88% * 100;
 Minibatch[ 801- 900]: loss = 0.405773 * 100, metric = 5.47% * 100;
 Minibatch[ 901-1000]: loss = 0.395146 * 100, metric = 5.45% * 100;
 Minibatch[1001-1100]: loss = 0.405671 * 100, metric = 5.50% * 100;
 Minibatch[1101-1200]: loss = 0.394427 * 100, metric = 5.36% * 100;
 Minibatch[1201-1300]: loss = 0.412063 * 100, metric = 5.54% * 100;
 Minibatch[1301-1400]: loss = 0.398034 * 100, metric = 5.43% * 100;
 Minibatch[1401-1500]: loss = 0.417956 * 100, metric = 5.86% * 100;
 Minibatch[1501-1600]: loss = 0.413945 * 100, metric = 5.76% * 100;
 Minibatch[1601-1700]: loss = 0.409837 * 100, metric = 5.61% * 100;
 Minibatch[1701-1800]: loss = 0.405826 * 100, metric = 5.56% * 100;
 Minibatch[1801-1900]: loss = 0.405077 * 100, metric = 5.55% * 100;
 Minibatch[1901-2000]: loss = 0.407630 * 100, metric = 5.89% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.409224 * 2000, metric = 5.70% * 2000 724.681s (  2.8 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.76% * 2000;
 Minibatch[   1- 100]: loss = 0.398622 * 100, metric = 5.51% * 100;
 Minibatch[ 101- 200]: loss = 0.399777 * 100, metric = 5.42% * 100;
 Minibatch[ 201- 300]: loss = 0.397746 * 100, metric = 5.41% * 100;
 Minibatch[ 301- 400]: loss = 0.410358 * 100, metric = 5.71% * 100;
 Minibatch[ 401- 500]: loss = 0.391842 * 100, metric = 5.46% * 100;
 Minibatch[ 501- 600]: loss = 0.405337 * 100, metric = 5.58% * 100;
 Minibatch[ 601- 700]: loss = 0.408825 * 100, metric = 5.61% * 100;
 Minibatch[ 701- 800]: loss = 0.407215 * 100, metric = 5.56% * 100;
 Minibatch[ 801- 900]: loss = 0.393460 * 100, metric = 5.23% * 100;
 Minibatch[ 901-1000]: loss = 0.404995 * 100, metric = 5.82% * 100;
 Minibatch[1001-1100]: loss = 0.416878 * 100, metric = 5.92% * 100;
 Minibatch[1101-1200]: loss = 0.398409 * 100, metric = 5.55% * 100;
 Minibatch[1201-1300]: loss = 0.414322 * 100, metric = 5.75% * 100;
 Minibatch[1301-1400]: loss = 0.408688 * 100, metric = 5.72% * 100;
 Minibatch[1401-1500]: loss = 0.414966 * 100, metric = 5.77% * 100;
 Minibatch[1501-1600]: loss = 0.412531 * 100, metric = 5.64% * 100;
 Minibatch[1601-1700]: loss = 0.421964 * 100, metric = 5.99% * 100;
 Minibatch[1701-1800]: loss = 0.410638 * 100, metric = 5.63% * 100;
 Minibatch[1801-1900]: loss = 0.413100 * 100, metric = 5.85% * 100;
 Minibatch[1901-2000]: loss = 0.401925 * 100, metric = 5.38% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.406580 * 2000, metric = 5.63% * 2000 752.254s (  2.7 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.70% * 2000;
 Minibatch[   1- 100]: loss = 0.390147 * 100, metric = 5.41% * 100;
 Minibatch[ 101- 200]: loss = 0.405506 * 100, metric = 5.79% * 100;
 Minibatch[ 201- 300]: loss = 0.409059 * 100, metric = 5.63% * 100;
 Minibatch[ 301- 400]: loss = 0.393422 * 100, metric = 5.33% * 100;
 Minibatch[ 401- 500]: loss = 0.400345 * 100, metric = 5.61% * 100;
 Minibatch[ 501- 600]: loss = 0.374010 * 100, metric = 5.05% * 100;
 Minibatch[ 601- 700]: loss = 0.410737 * 100, metric = 5.76% * 100;
 Minibatch[ 701- 800]: loss = 0.386040 * 100, metric = 5.35% * 100;
 Minibatch[ 801- 900]: loss = 0.409351 * 100, metric = 5.64% * 100;
 Minibatch[ 901-1000]: loss = 0.386989 * 100, metric = 5.33% * 100;
 Minibatch[1001-1100]: loss = 0.411784 * 100, metric = 5.63% * 100;
 Minibatch[1101-1200]: loss = 0.400215 * 100, metric = 5.52% * 100;
 Minibatch[1201-1300]: loss = 0.405084 * 100, metric = 5.71% * 100;
 Minibatch[1301-1400]: loss = 0.408093 * 100, metric = 5.74% * 100;
 Minibatch[1401-1500]: loss = 0.405512 * 100, metric = 5.56% * 100;
 Minibatch[1501-1600]: loss = 0.404443 * 100, metric = 5.65% * 100;
 Minibatch[1601-1700]: loss = 0.398029 * 100, metric = 5.52% * 100;
 Minibatch[1701-1800]: loss = 0.389566 * 100, metric = 5.19% * 100;
 Minibatch[1801-1900]: loss = 0.397059 * 100, metric = 5.54% * 100;
 Minibatch[1901-2000]: loss = 0.394295 * 100, metric = 5.28% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.398984 * 2000, metric = 5.51% * 2000 759.777s (  2.6 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 14.79% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
