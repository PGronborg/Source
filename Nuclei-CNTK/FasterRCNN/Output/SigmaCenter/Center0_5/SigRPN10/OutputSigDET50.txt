Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.428552 * 100, metric = 25.34% * 100;
 Minibatch[ 101- 200]: loss = 1.154942 * 100, metric = 23.25% * 100;
 Minibatch[ 201- 300]: loss = 1.042679 * 100, metric = 21.28% * 100;
 Minibatch[ 301- 400]: loss = 1.000630 * 100, metric = 19.67% * 100;
 Minibatch[ 401- 500]: loss = 0.894893 * 100, metric = 17.89% * 100;
 Minibatch[ 501- 600]: loss = 0.887684 * 100, metric = 17.06% * 100;
 Minibatch[ 601- 700]: loss = 0.856454 * 100, metric = 16.00% * 100;
 Minibatch[ 701- 800]: loss = 0.793324 * 100, metric = 14.79% * 100;
 Minibatch[ 801- 900]: loss = 0.820145 * 100, metric = 15.27% * 100;
 Minibatch[ 901-1000]: loss = 0.832199 * 100, metric = 15.69% * 100;
 Minibatch[1001-1100]: loss = 0.806962 * 100, metric = 15.00% * 100;
 Minibatch[1101-1200]: loss = 0.791313 * 100, metric = 14.39% * 100;
 Minibatch[1201-1300]: loss = 0.788064 * 100, metric = 14.53% * 100;
 Minibatch[1301-1400]: loss = 0.744814 * 100, metric = 13.63% * 100;
 Minibatch[1401-1500]: loss = 0.774749 * 100, metric = 13.89% * 100;
 Minibatch[1501-1600]: loss = 0.742604 * 100, metric = 13.55% * 100;
 Minibatch[1601-1700]: loss = 0.756437 * 100, metric = 13.46% * 100;
 Minibatch[1701-1800]: loss = 0.756024 * 100, metric = 13.05% * 100;
 Minibatch[1801-1900]: loss = 0.725183 * 100, metric = 13.07% * 100;
 Minibatch[1901-2000]: loss = 0.706343 * 100, metric = 12.14% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.865200 * 2000, metric = 16.15% * 2000 1050.375s (  1.9 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 24.61% * 2000;
0.8804029385298491
 Minibatch[   1- 100]: loss = 0.719557 * 100, metric = 12.35% * 100;
 Minibatch[ 101- 200]: loss = 0.722934 * 100, metric = 12.64% * 100;
 Minibatch[ 201- 300]: loss = 0.707452 * 100, metric = 11.99% * 100;
 Minibatch[ 301- 400]: loss = 0.714572 * 100, metric = 12.32% * 100;
 Minibatch[ 401- 500]: loss = 0.711155 * 100, metric = 12.54% * 100;
 Minibatch[ 501- 600]: loss = 0.717495 * 100, metric = 12.14% * 100;
 Minibatch[ 601- 700]: loss = 0.698079 * 100, metric = 11.90% * 100;
 Minibatch[ 701- 800]: loss = 0.716932 * 100, metric = 12.48% * 100;
 Minibatch[ 801- 900]: loss = 0.689686 * 100, metric = 11.81% * 100;
 Minibatch[ 901-1000]: loss = 0.680899 * 100, metric = 11.65% * 100;
 Minibatch[1001-1100]: loss = 0.694456 * 100, metric = 12.33% * 100;
 Minibatch[1101-1200]: loss = 0.697031 * 100, metric = 11.97% * 100;
 Minibatch[1201-1300]: loss = 0.674988 * 100, metric = 11.80% * 100;
 Minibatch[1301-1400]: loss = 0.682283 * 100, metric = 11.79% * 100;
 Minibatch[1401-1500]: loss = 0.668830 * 100, metric = 11.41% * 100;
 Minibatch[1501-1600]: loss = 0.669060 * 100, metric = 11.03% * 100;
 Minibatch[1601-1700]: loss = 0.667128 * 100, metric = 11.56% * 100;
 Minibatch[1701-1800]: loss = 0.669636 * 100, metric = 11.64% * 100;
 Minibatch[1801-1900]: loss = 0.668138 * 100, metric = 11.49% * 100;
 Minibatch[1901-2000]: loss = 0.645842 * 100, metric = 11.05% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.690808 * 2000, metric = 11.90% * 2000 987.270s (  2.0 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 20.34% * 2000;
0.7652356137260795
 Minibatch[   1- 100]: loss = 0.665062 * 100, metric = 11.67% * 100;
 Minibatch[ 101- 200]: loss = 0.675967 * 100, metric = 11.75% * 100;
 Minibatch[ 201- 300]: loss = 0.661266 * 100, metric = 11.41% * 100;
 Minibatch[ 301- 400]: loss = 0.670018 * 100, metric = 11.50% * 100;
 Minibatch[ 401- 500]: loss = 0.687871 * 100, metric = 11.64% * 100;
 Minibatch[ 501- 600]: loss = 0.666920 * 100, metric = 11.51% * 100;
 Minibatch[ 601- 700]: loss = 0.676675 * 100, metric = 11.54% * 100;
 Minibatch[ 701- 800]: loss = 0.640445 * 100, metric = 10.78% * 100;
 Minibatch[ 801- 900]: loss = 0.671810 * 100, metric = 11.52% * 100;
 Minibatch[ 901-1000]: loss = 0.634097 * 100, metric = 11.00% * 100;
 Minibatch[1001-1100]: loss = 0.649188 * 100, metric = 11.13% * 100;
 Minibatch[1101-1200]: loss = 0.656975 * 100, metric = 10.86% * 100;
 Minibatch[1201-1300]: loss = 0.652138 * 100, metric = 11.03% * 100;
 Minibatch[1301-1400]: loss = 0.653321 * 100, metric = 10.83% * 100;
 Minibatch[1401-1500]: loss = 0.651589 * 100, metric = 11.18% * 100;
 Minibatch[1501-1600]: loss = 0.638980 * 100, metric = 10.74% * 100;
 Minibatch[1601-1700]: loss = 0.628208 * 100, metric = 10.47% * 100;
 Minibatch[1701-1800]: loss = 0.642723 * 100, metric = 10.89% * 100;
 Minibatch[1801-1900]: loss = 0.630520 * 100, metric = 10.52% * 100;
 Minibatch[1901-2000]: loss = 0.637299 * 100, metric = 10.87% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.654554 * 2000, metric = 11.14% * 2000 978.103s (  2.0 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 20.18% * 2000;
0.7380582463368773
 Minibatch[   1- 100]: loss = 0.650987 * 100, metric = 10.63% * 100;
 Minibatch[ 101- 200]: loss = 0.614012 * 100, metric = 10.17% * 100;
 Minibatch[ 201- 300]: loss = 0.638843 * 100, metric = 10.85% * 100;
 Minibatch[ 301- 400]: loss = 0.602471 * 100, metric = 10.09% * 100;
 Minibatch[ 401- 500]: loss = 0.630007 * 100, metric = 10.69% * 100;
 Minibatch[ 501- 600]: loss = 0.616374 * 100, metric = 9.94% * 100;
 Minibatch[ 601- 700]: loss = 0.610828 * 100, metric = 10.28% * 100;
 Minibatch[ 701- 800]: loss = 0.616884 * 100, metric = 10.24% * 100;
 Minibatch[ 801- 900]: loss = 0.632141 * 100, metric = 10.56% * 100;
 Minibatch[ 901-1000]: loss = 0.617280 * 100, metric = 10.42% * 100;
 Minibatch[1001-1100]: loss = 0.635634 * 100, metric = 10.83% * 100;
 Minibatch[1101-1200]: loss = 0.609300 * 100, metric = 10.01% * 100;
 Minibatch[1201-1300]: loss = 0.624380 * 100, metric = 10.21% * 100;
 Minibatch[1301-1400]: loss = 0.633773 * 100, metric = 10.66% * 100;
 Minibatch[1401-1500]: loss = 0.627791 * 100, metric = 10.73% * 100;
 Minibatch[1501-1600]: loss = 0.596766 * 100, metric = 10.06% * 100;
 Minibatch[1601-1700]: loss = 0.618740 * 100, metric = 10.51% * 100;
 Minibatch[1701-1800]: loss = 0.614341 * 100, metric = 10.22% * 100;
 Minibatch[1801-1900]: loss = 0.599626 * 100, metric = 9.83% * 100;
 Minibatch[1901-2000]: loss = 0.594133 * 100, metric = 9.74% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.619216 * 2000, metric = 10.33% * 2000 976.173s (  2.0 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 21.59% * 2000;
 Minibatch[   1- 100]: loss = 0.614749 * 100, metric = 10.16% * 100;
 Minibatch[ 101- 200]: loss = 0.601611 * 100, metric = 9.71% * 100;
 Minibatch[ 201- 300]: loss = 0.582367 * 100, metric = 9.52% * 100;
 Minibatch[ 301- 400]: loss = 0.622170 * 100, metric = 10.50% * 100;
 Minibatch[ 401- 500]: loss = 0.577771 * 100, metric = 9.33% * 100;
 Minibatch[ 501- 600]: loss = 0.574851 * 100, metric = 9.25% * 100;
 Minibatch[ 601- 700]: loss = 0.587209 * 100, metric = 9.57% * 100;
 Minibatch[ 701- 800]: loss = 0.607927 * 100, metric = 10.06% * 100;
 Minibatch[ 801- 900]: loss = 0.582952 * 100, metric = 9.44% * 100;
 Minibatch[ 901-1000]: loss = 0.582480 * 100, metric = 9.56% * 100;
 Minibatch[1001-1100]: loss = 0.597922 * 100, metric = 9.71% * 100;
 Minibatch[1101-1200]: loss = 0.583665 * 100, metric = 9.29% * 100;
 Minibatch[1201-1300]: loss = 0.596395 * 100, metric = 9.50% * 100;
 Minibatch[1301-1400]: loss = 0.609872 * 100, metric = 10.34% * 100;
 Minibatch[1401-1500]: loss = 0.583582 * 100, metric = 9.66% * 100;
 Minibatch[1501-1600]: loss = 0.591279 * 100, metric = 9.61% * 100;
 Minibatch[1601-1700]: loss = 0.597562 * 100, metric = 10.24% * 100;
 Minibatch[1701-1800]: loss = 0.600800 * 100, metric = 10.03% * 100;
 Minibatch[1801-1900]: loss = 0.587440 * 100, metric = 9.75% * 100;
 Minibatch[1901-2000]: loss = 0.568422 * 100, metric = 9.21% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.592551 * 2000, metric = 9.72% * 2000 937.573s (  2.1 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 17.93% * 2000;
0.7052733814641833
 Minibatch[   1- 100]: loss = 0.582678 * 100, metric = 9.75% * 100;
 Minibatch[ 101- 200]: loss = 0.568183 * 100, metric = 9.16% * 100;
 Minibatch[ 201- 300]: loss = 0.574799 * 100, metric = 9.19% * 100;
 Minibatch[ 301- 400]: loss = 0.581058 * 100, metric = 9.29% * 100;
 Minibatch[ 401- 500]: loss = 0.561316 * 100, metric = 9.23% * 100;
 Minibatch[ 501- 600]: loss = 0.573608 * 100, metric = 9.48% * 100;
 Minibatch[ 601- 700]: loss = 0.566068 * 100, metric = 9.12% * 100;
 Minibatch[ 701- 800]: loss = 0.574702 * 100, metric = 9.18% * 100;
 Minibatch[ 801- 900]: loss = 0.589645 * 100, metric = 9.55% * 100;
 Minibatch[ 901-1000]: loss = 0.560439 * 100, metric = 9.28% * 100;
 Minibatch[1001-1100]: loss = 0.570536 * 100, metric = 8.93% * 100;
 Minibatch[1101-1200]: loss = 0.586331 * 100, metric = 9.42% * 100;
 Minibatch[1201-1300]: loss = 0.598937 * 100, metric = 9.70% * 100;
 Minibatch[1301-1400]: loss = 0.572562 * 100, metric = 9.41% * 100;
 Minibatch[1401-1500]: loss = 0.572643 * 100, metric = 9.15% * 100;
 Minibatch[1501-1600]: loss = 0.564926 * 100, metric = 8.75% * 100;
 Minibatch[1601-1700]: loss = 0.557894 * 100, metric = 8.75% * 100;
 Minibatch[1701-1800]: loss = 0.549708 * 100, metric = 8.64% * 100;
 Minibatch[1801-1900]: loss = 0.575541 * 100, metric = 9.24% * 100;
 Minibatch[1901-2000]: loss = 0.553800 * 100, metric = 8.81% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.571769 * 2000, metric = 9.20% * 2000 911.976s (  2.2 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 18.83% * 2000;
 Minibatch[   1- 100]: loss = 0.567842 * 100, metric = 8.99% * 100;
 Minibatch[ 101- 200]: loss = 0.574274 * 100, metric = 8.92% * 100;
 Minibatch[ 201- 300]: loss = 0.572428 * 100, metric = 9.37% * 100;
 Minibatch[ 301- 400]: loss = 0.550110 * 100, metric = 8.57% * 100;
 Minibatch[ 401- 500]: loss = 0.567419 * 100, metric = 9.17% * 100;
 Minibatch[ 501- 600]: loss = 0.536706 * 100, metric = 8.48% * 100;
 Minibatch[ 601- 700]: loss = 0.557120 * 100, metric = 8.63% * 100;
 Minibatch[ 701- 800]: loss = 0.568445 * 100, metric = 8.93% * 100;
 Minibatch[ 801- 900]: loss = 0.560320 * 100, metric = 9.07% * 100;
 Minibatch[ 901-1000]: loss = 0.552646 * 100, metric = 8.66% * 100;
 Minibatch[1001-1100]: loss = 0.561844 * 100, metric = 9.16% * 100;
 Minibatch[1101-1200]: loss = 0.546534 * 100, metric = 8.56% * 100;
 Minibatch[1201-1300]: loss = 0.561470 * 100, metric = 9.12% * 100;
 Minibatch[1301-1400]: loss = 0.539127 * 100, metric = 8.35% * 100;
 Minibatch[1401-1500]: loss = 0.530884 * 100, metric = 8.34% * 100;
 Minibatch[1501-1600]: loss = 0.540439 * 100, metric = 8.31% * 100;
 Minibatch[1601-1700]: loss = 0.547832 * 100, metric = 8.57% * 100;
 Minibatch[1701-1800]: loss = 0.536856 * 100, metric = 8.43% * 100;
 Minibatch[1801-1900]: loss = 0.549536 * 100, metric = 8.87% * 100;
 Minibatch[1901-2000]: loss = 0.548712 * 100, metric = 8.62% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.553527 * 2000, metric = 8.76% * 2000 905.615s (  2.2 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 16.72% * 2000;
0.6729667561799287
 Minibatch[   1- 100]: loss = 0.561467 * 100, metric = 9.04% * 100;
 Minibatch[ 101- 200]: loss = 0.548427 * 100, metric = 8.64% * 100;
 Minibatch[ 201- 300]: loss = 0.530821 * 100, metric = 8.25% * 100;
 Minibatch[ 301- 400]: loss = 0.545387 * 100, metric = 8.65% * 100;
 Minibatch[ 401- 500]: loss = 0.547417 * 100, metric = 8.79% * 100;
 Minibatch[ 501- 600]: loss = 0.568375 * 100, metric = 9.22% * 100;
 Minibatch[ 601- 700]: loss = 0.519656 * 100, metric = 8.00% * 100;
 Minibatch[ 701- 800]: loss = 0.542843 * 100, metric = 8.41% * 100;
 Minibatch[ 801- 900]: loss = 0.524960 * 100, metric = 8.12% * 100;
 Minibatch[ 901-1000]: loss = 0.519293 * 100, metric = 8.05% * 100;
 Minibatch[1001-1100]: loss = 0.530306 * 100, metric = 8.49% * 100;
 Minibatch[1101-1200]: loss = 0.521664 * 100, metric = 8.22% * 100;
 Minibatch[1201-1300]: loss = 0.535646 * 100, metric = 8.44% * 100;
 Minibatch[1301-1400]: loss = 0.549665 * 100, metric = 8.86% * 100;
 Minibatch[1401-1500]: loss = 0.536884 * 100, metric = 8.27% * 100;
 Minibatch[1501-1600]: loss = 0.546812 * 100, metric = 8.56% * 100;
 Minibatch[1601-1700]: loss = 0.532753 * 100, metric = 8.08% * 100;
 Minibatch[1701-1800]: loss = 0.521218 * 100, metric = 8.04% * 100;
 Minibatch[1801-1900]: loss = 0.529387 * 100, metric = 8.20% * 100;
 Minibatch[1901-2000]: loss = 0.529899 * 100, metric = 8.39% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.537144 * 2000, metric = 8.44% * 2000 903.588s (  2.2 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 16.46% * 2000;
0.6577977164164186
 Minibatch[   1- 100]: loss = 0.514881 * 100, metric = 7.90% * 100;
 Minibatch[ 101- 200]: loss = 0.541285 * 100, metric = 8.53% * 100;
 Minibatch[ 201- 300]: loss = 0.535312 * 100, metric = 8.25% * 100;
 Minibatch[ 301- 400]: loss = 0.543834 * 100, metric = 8.60% * 100;
 Minibatch[ 401- 500]: loss = 0.524689 * 100, metric = 7.97% * 100;
 Minibatch[ 501- 600]: loss = 0.517864 * 100, metric = 8.06% * 100;
 Minibatch[ 601- 700]: loss = 0.519329 * 100, metric = 8.18% * 100;
 Minibatch[ 701- 800]: loss = 0.517621 * 100, metric = 7.94% * 100;
 Minibatch[ 801- 900]: loss = 0.524409 * 100, metric = 8.31% * 100;
 Minibatch[ 901-1000]: loss = 0.527220 * 100, metric = 8.28% * 100;
 Minibatch[1001-1100]: loss = 0.499000 * 100, metric = 7.45% * 100;
 Minibatch[1101-1200]: loss = 0.521982 * 100, metric = 8.17% * 100;
 Minibatch[1201-1300]: loss = 0.515668 * 100, metric = 7.94% * 100;
 Minibatch[1301-1400]: loss = 0.508769 * 100, metric = 7.62% * 100;
 Minibatch[1401-1500]: loss = 0.526614 * 100, metric = 8.08% * 100;
 Minibatch[1501-1600]: loss = 0.521155 * 100, metric = 7.96% * 100;
 Minibatch[1601-1700]: loss = 0.525482 * 100, metric = 8.26% * 100;
 Minibatch[1701-1800]: loss = 0.507825 * 100, metric = 7.62% * 100;
 Minibatch[1801-1900]: loss = 0.501686 * 100, metric = 7.65% * 100;
 Minibatch[1901-2000]: loss = 0.521719 * 100, metric = 8.06% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.520817 * 2000, metric = 8.04% * 2000 895.347s (  2.2 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 15.72% * 2000;
0.6423028761297465
 Minibatch[   1- 100]: loss = 0.530062 * 100, metric = 8.61% * 100;
 Minibatch[ 101- 200]: loss = 0.500118 * 100, metric = 7.77% * 100;
 Minibatch[ 201- 300]: loss = 0.516813 * 100, metric = 7.96% * 100;
 Minibatch[ 301- 400]: loss = 0.506494 * 100, metric = 7.70% * 100;
 Minibatch[ 401- 500]: loss = 0.516066 * 100, metric = 8.04% * 100;
 Minibatch[ 501- 600]: loss = 0.500067 * 100, metric = 7.58% * 100;
 Minibatch[ 601- 700]: loss = 0.488277 * 100, metric = 7.32% * 100;
 Minibatch[ 701- 800]: loss = 0.484892 * 100, metric = 7.01% * 100;
 Minibatch[ 801- 900]: loss = 0.511345 * 100, metric = 7.73% * 100;
 Minibatch[ 901-1000]: loss = 0.506873 * 100, metric = 7.73% * 100;
 Minibatch[1001-1100]: loss = 0.508849 * 100, metric = 8.00% * 100;
 Minibatch[1101-1200]: loss = 0.515477 * 100, metric = 8.10% * 100;
 Minibatch[1201-1300]: loss = 0.511523 * 100, metric = 7.92% * 100;
 Minibatch[1301-1400]: loss = 0.517953 * 100, metric = 7.82% * 100;
 Minibatch[1401-1500]: loss = 0.506946 * 100, metric = 7.27% * 100;
 Minibatch[1501-1600]: loss = 0.504402 * 100, metric = 7.63% * 100;
 Minibatch[1601-1700]: loss = 0.505426 * 100, metric = 7.51% * 100;
 Minibatch[1701-1800]: loss = 0.507076 * 100, metric = 7.58% * 100;
 Minibatch[1801-1900]: loss = 0.513331 * 100, metric = 7.74% * 100;
 Minibatch[1901-2000]: loss = 0.490229 * 100, metric = 7.29% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.507111 * 2000, metric = 7.72% * 2000 895.333s (  2.2 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 14.72% * 2000;
0.6260390157550574
 Minibatch[   1- 100]: loss = 0.483781 * 100, metric = 7.17% * 100;
 Minibatch[ 101- 200]: loss = 0.500235 * 100, metric = 7.42% * 100;
 Minibatch[ 201- 300]: loss = 0.500919 * 100, metric = 7.62% * 100;
 Minibatch[ 301- 400]: loss = 0.490353 * 100, metric = 7.21% * 100;
 Minibatch[ 401- 500]: loss = 0.488046 * 100, metric = 7.33% * 100;
 Minibatch[ 501- 600]: loss = 0.503891 * 100, metric = 7.73% * 100;
 Minibatch[ 601- 700]: loss = 0.494821 * 100, metric = 7.44% * 100;
 Minibatch[ 701- 800]: loss = 0.501296 * 100, metric = 7.65% * 100;
 Minibatch[ 801- 900]: loss = 0.494579 * 100, metric = 7.44% * 100;
 Minibatch[ 901-1000]: loss = 0.507119 * 100, metric = 7.78% * 100;
 Minibatch[1001-1100]: loss = 0.495495 * 100, metric = 7.37% * 100;
 Minibatch[1101-1200]: loss = 0.501392 * 100, metric = 7.60% * 100;
 Minibatch[1201-1300]: loss = 0.489883 * 100, metric = 7.34% * 100;
 Minibatch[1301-1400]: loss = 0.475505 * 100, metric = 7.07% * 100;
 Minibatch[1401-1500]: loss = 0.498828 * 100, metric = 7.52% * 100;
 Minibatch[1501-1600]: loss = 0.480909 * 100, metric = 7.12% * 100;
 Minibatch[1601-1700]: loss = 0.483586 * 100, metric = 6.98% * 100;
 Minibatch[1701-1800]: loss = 0.503902 * 100, metric = 7.54% * 100;
 Minibatch[1801-1900]: loss = 0.485556 * 100, metric = 7.44% * 100;
 Minibatch[1901-2000]: loss = 0.485401 * 100, metric = 7.33% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.493275 * 2000, metric = 7.40% * 2000 902.745s (  2.2 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 15.02% * 2000;
 Minibatch[   1- 100]: loss = 0.473283 * 100, metric = 7.00% * 100;
 Minibatch[ 101- 200]: loss = 0.476774 * 100, metric = 6.97% * 100;
 Minibatch[ 201- 300]: loss = 0.478501 * 100, metric = 7.09% * 100;
 Minibatch[ 301- 400]: loss = 0.510402 * 100, metric = 7.89% * 100;
 Minibatch[ 401- 500]: loss = 0.480801 * 100, metric = 7.13% * 100;
 Minibatch[ 501- 600]: loss = 0.476177 * 100, metric = 7.09% * 100;
 Minibatch[ 601- 700]: loss = 0.471744 * 100, metric = 6.92% * 100;
 Minibatch[ 701- 800]: loss = 0.487924 * 100, metric = 7.35% * 100;
 Minibatch[ 801- 900]: loss = 0.486673 * 100, metric = 7.05% * 100;
 Minibatch[ 901-1000]: loss = 0.487520 * 100, metric = 7.52% * 100;
 Minibatch[1001-1100]: loss = 0.495391 * 100, metric = 7.49% * 100;
 Minibatch[1101-1200]: loss = 0.491619 * 100, metric = 7.30% * 100;
 Minibatch[1201-1300]: loss = 0.499772 * 100, metric = 7.69% * 100;
 Minibatch[1301-1400]: loss = 0.480085 * 100, metric = 7.06% * 100;
 Minibatch[1401-1500]: loss = 0.497515 * 100, metric = 7.60% * 100;
 Minibatch[1501-1600]: loss = 0.467945 * 100, metric = 6.84% * 100;
 Minibatch[1601-1700]: loss = 0.495129 * 100, metric = 7.33% * 100;
 Minibatch[1701-1800]: loss = 0.479099 * 100, metric = 6.91% * 100;
 Minibatch[1801-1900]: loss = 0.476655 * 100, metric = 7.04% * 100;
 Minibatch[1901-2000]: loss = 0.497917 * 100, metric = 7.49% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.485546 * 2000, metric = 7.24% * 2000 891.643s (  2.2 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 15.81% * 2000;
 Minibatch[   1- 100]: loss = 0.495900 * 100, metric = 7.46% * 100;
 Minibatch[ 101- 200]: loss = 0.489190 * 100, metric = 7.37% * 100;
 Minibatch[ 201- 300]: loss = 0.470888 * 100, metric = 6.92% * 100;
 Minibatch[ 301- 400]: loss = 0.495194 * 100, metric = 7.47% * 100;
 Minibatch[ 401- 500]: loss = 0.488274 * 100, metric = 7.46% * 100;
 Minibatch[ 501- 600]: loss = 0.490711 * 100, metric = 7.29% * 100;
 Minibatch[ 601- 700]: loss = 0.467082 * 100, metric = 6.72% * 100;
 Minibatch[ 701- 800]: loss = 0.474681 * 100, metric = 6.77% * 100;
 Minibatch[ 801- 900]: loss = 0.474754 * 100, metric = 6.96% * 100;
 Minibatch[ 901-1000]: loss = 0.490908 * 100, metric = 7.14% * 100;
 Minibatch[1001-1100]: loss = 0.488692 * 100, metric = 7.38% * 100;
 Minibatch[1101-1200]: loss = 0.470846 * 100, metric = 6.78% * 100;
 Minibatch[1201-1300]: loss = 0.477155 * 100, metric = 7.14% * 100;
 Minibatch[1301-1400]: loss = 0.462400 * 100, metric = 6.86% * 100;
 Minibatch[1401-1500]: loss = 0.469487 * 100, metric = 6.85% * 100;
 Minibatch[1501-1600]: loss = 0.466484 * 100, metric = 6.62% * 100;
 Minibatch[1601-1700]: loss = 0.456616 * 100, metric = 6.68% * 100;
 Minibatch[1701-1800]: loss = 0.466133 * 100, metric = 6.77% * 100;
 Minibatch[1801-1900]: loss = 0.458066 * 100, metric = 6.82% * 100;
 Minibatch[1901-2000]: loss = 0.475370 * 100, metric = 6.85% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.476442 * 2000, metric = 7.02% * 2000 892.727s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 17.60% * 2000;
 Minibatch[   1- 100]: loss = 0.469867 * 100, metric = 7.16% * 100;
 Minibatch[ 101- 200]: loss = 0.453209 * 100, metric = 6.58% * 100;
 Minibatch[ 201- 300]: loss = 0.483971 * 100, metric = 7.29% * 100;
 Minibatch[ 301- 400]: loss = 0.469840 * 100, metric = 6.77% * 100;
 Minibatch[ 401- 500]: loss = 0.461739 * 100, metric = 6.65% * 100;
 Minibatch[ 501- 600]: loss = 0.467072 * 100, metric = 6.80% * 100;
 Minibatch[ 601- 700]: loss = 0.464757 * 100, metric = 6.84% * 100;
 Minibatch[ 701- 800]: loss = 0.486902 * 100, metric = 7.20% * 100;
 Minibatch[ 801- 900]: loss = 0.477711 * 100, metric = 7.18% * 100;
 Minibatch[ 901-1000]: loss = 0.474859 * 100, metric = 6.92% * 100;
 Minibatch[1001-1100]: loss = 0.467139 * 100, metric = 6.91% * 100;
 Minibatch[1101-1200]: loss = 0.458197 * 100, metric = 6.61% * 100;
 Minibatch[1201-1300]: loss = 0.444857 * 100, metric = 6.08% * 100;
 Minibatch[1301-1400]: loss = 0.471054 * 100, metric = 6.92% * 100;
 Minibatch[1401-1500]: loss = 0.471281 * 100, metric = 7.07% * 100;
 Minibatch[1501-1600]: loss = 0.457579 * 100, metric = 6.75% * 100;
 Minibatch[1601-1700]: loss = 0.464506 * 100, metric = 6.63% * 100;
 Minibatch[1701-1800]: loss = 0.468942 * 100, metric = 6.58% * 100;
 Minibatch[1801-1900]: loss = 0.469461 * 100, metric = 6.72% * 100;
 Minibatch[1901-2000]: loss = 0.480370 * 100, metric = 6.97% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.468166 * 2000, metric = 6.83% * 2000 898.985s (  2.2 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 16.31% * 2000;
 Minibatch[   1- 100]: loss = 0.461924 * 100, metric = 6.71% * 100;
 Minibatch[ 101- 200]: loss = 0.474760 * 100, metric = 6.88% * 100;
 Minibatch[ 201- 300]: loss = 0.470230 * 100, metric = 6.79% * 100;
 Minibatch[ 301- 400]: loss = 0.457185 * 100, metric = 6.54% * 100;
 Minibatch[ 401- 500]: loss = 0.461931 * 100, metric = 6.74% * 100;
 Minibatch[ 501- 600]: loss = 0.452625 * 100, metric = 6.33% * 100;
 Minibatch[ 601- 700]: loss = 0.441584 * 100, metric = 6.32% * 100;
 Minibatch[ 701- 800]: loss = 0.470089 * 100, metric = 7.01% * 100;
 Minibatch[ 801- 900]: loss = 0.479449 * 100, metric = 7.12% * 100;
 Minibatch[ 901-1000]: loss = 0.460512 * 100, metric = 6.47% * 100;
 Minibatch[1001-1100]: loss = 0.469109 * 100, metric = 6.70% * 100;
 Minibatch[1101-1200]: loss = 0.459999 * 100, metric = 6.71% * 100;
 Minibatch[1201-1300]: loss = 0.447339 * 100, metric = 6.17% * 100;
 Minibatch[1301-1400]: loss = 0.475850 * 100, metric = 7.15% * 100;
 Minibatch[1401-1500]: loss = 0.438038 * 100, metric = 6.22% * 100;
 Minibatch[1501-1600]: loss = 0.444061 * 100, metric = 6.33% * 100;
 Minibatch[1601-1700]: loss = 0.459503 * 100, metric = 6.61% * 100;
 Minibatch[1701-1800]: loss = 0.444345 * 100, metric = 6.34% * 100;
 Minibatch[1801-1900]: loss = 0.451746 * 100, metric = 6.80% * 100;
 Minibatch[1901-2000]: loss = 0.440104 * 100, metric = 6.34% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.458019 * 2000, metric = 6.61% * 2000 892.041s (  2.2 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 14.12% * 2000;
 Minibatch[   1- 100]: loss = 0.468508 * 100, metric = 7.08% * 100;
 Minibatch[ 101- 200]: loss = 0.453304 * 100, metric = 6.23% * 100;
 Minibatch[ 201- 300]: loss = 0.457986 * 100, metric = 6.57% * 100;
 Minibatch[ 301- 400]: loss = 0.455948 * 100, metric = 6.66% * 100;
 Minibatch[ 401- 500]: loss = 0.438079 * 100, metric = 6.20% * 100;
 Minibatch[ 501- 600]: loss = 0.453779 * 100, metric = 6.57% * 100;
 Minibatch[ 601- 700]: loss = 0.456079 * 100, metric = 6.36% * 100;
 Minibatch[ 701- 800]: loss = 0.453934 * 100, metric = 6.50% * 100;
 Minibatch[ 801- 900]: loss = 0.438063 * 100, metric = 6.16% * 100;
 Minibatch[ 901-1000]: loss = 0.453828 * 100, metric = 6.70% * 100;
 Minibatch[1001-1100]: loss = 0.434117 * 100, metric = 6.14% * 100;
 Minibatch[1101-1200]: loss = 0.445616 * 100, metric = 6.20% * 100;
 Minibatch[1201-1300]: loss = 0.439591 * 100, metric = 6.14% * 100;
 Minibatch[1301-1400]: loss = 0.449365 * 100, metric = 6.38% * 100;
 Minibatch[1401-1500]: loss = 0.448936 * 100, metric = 6.50% * 100;
 Minibatch[1501-1600]: loss = 0.449792 * 100, metric = 6.40% * 100;
 Minibatch[1601-1700]: loss = 0.449145 * 100, metric = 6.46% * 100;
 Minibatch[1701-1800]: loss = 0.465867 * 100, metric = 6.56% * 100;
 Minibatch[1801-1900]: loss = 0.457993 * 100, metric = 6.71% * 100;
 Minibatch[1901-2000]: loss = 0.438608 * 100, metric = 6.40% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.450427 * 2000, metric = 6.45% * 2000 898.539s (  2.2 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.27% * 2000;
0.6224567762687803
 Minibatch[   1- 100]: loss = 0.436362 * 100, metric = 5.89% * 100;
 Minibatch[ 101- 200]: loss = 0.452583 * 100, metric = 6.43% * 100;
 Minibatch[ 201- 300]: loss = 0.453887 * 100, metric = 6.73% * 100;
 Minibatch[ 301- 400]: loss = 0.443975 * 100, metric = 6.15% * 100;
 Minibatch[ 401- 500]: loss = 0.457063 * 100, metric = 6.35% * 100;
 Minibatch[ 501- 600]: loss = 0.443973 * 100, metric = 6.18% * 100;
 Minibatch[ 601- 700]: loss = 0.428060 * 100, metric = 5.97% * 100;
 Minibatch[ 701- 800]: loss = 0.444598 * 100, metric = 6.16% * 100;
 Minibatch[ 801- 900]: loss = 0.446737 * 100, metric = 6.40% * 100;
 Minibatch[ 901-1000]: loss = 0.437186 * 100, metric = 6.11% * 100;
 Minibatch[1001-1100]: loss = 0.434467 * 100, metric = 6.25% * 100;
 Minibatch[1101-1200]: loss = 0.458845 * 100, metric = 6.60% * 100;
 Minibatch[1201-1300]: loss = 0.455254 * 100, metric = 6.48% * 100;
 Minibatch[1301-1400]: loss = 0.433109 * 100, metric = 6.19% * 100;
 Minibatch[1401-1500]: loss = 0.448264 * 100, metric = 6.55% * 100;
 Minibatch[1501-1600]: loss = 0.445967 * 100, metric = 6.41% * 100;
 Minibatch[1601-1700]: loss = 0.441807 * 100, metric = 6.19% * 100;
 Minibatch[1701-1800]: loss = 0.428543 * 100, metric = 6.06% * 100;
 Minibatch[1801-1900]: loss = 0.452063 * 100, metric = 6.58% * 100;
 Minibatch[1901-2000]: loss = 0.466569 * 100, metric = 6.83% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.445466 * 2000, metric = 6.33% * 2000 906.728s (  2.2 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 13.84% * 2000;
 Minibatch[   1- 100]: loss = 0.438411 * 100, metric = 6.05% * 100;
 Minibatch[ 101- 200]: loss = 0.456995 * 100, metric = 6.50% * 100;
 Minibatch[ 201- 300]: loss = 0.431214 * 100, metric = 6.09% * 100;
 Minibatch[ 301- 400]: loss = 0.437584 * 100, metric = 6.07% * 100;
 Minibatch[ 401- 500]: loss = 0.424789 * 100, metric = 5.87% * 100;
 Minibatch[ 501- 600]: loss = 0.432776 * 100, metric = 6.11% * 100;
 Minibatch[ 601- 700]: loss = 0.443223 * 100, metric = 6.26% * 100;
 Minibatch[ 701- 800]: loss = 0.431763 * 100, metric = 6.23% * 100;
 Minibatch[ 801- 900]: loss = 0.440342 * 100, metric = 6.24% * 100;
 Minibatch[ 901-1000]: loss = 0.442201 * 100, metric = 6.34% * 100;
 Minibatch[1001-1100]: loss = 0.449981 * 100, metric = 6.61% * 100;
 Minibatch[1101-1200]: loss = 0.447486 * 100, metric = 6.29% * 100;
 Minibatch[1201-1300]: loss = 0.447676 * 100, metric = 6.45% * 100;
 Minibatch[1301-1400]: loss = 0.449439 * 100, metric = 6.54% * 100;
 Minibatch[1401-1500]: loss = 0.421593 * 100, metric = 5.89% * 100;
 Minibatch[1501-1600]: loss = 0.432795 * 100, metric = 6.09% * 100;
 Minibatch[1601-1700]: loss = 0.421750 * 100, metric = 5.81% * 100;
 Minibatch[1701-1800]: loss = 0.435027 * 100, metric = 6.12% * 100;
 Minibatch[1801-1900]: loss = 0.420602 * 100, metric = 5.85% * 100;
 Minibatch[1901-2000]: loss = 0.423879 * 100, metric = 5.80% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.436476 * 2000, metric = 6.16% * 2000 880.659s (  2.3 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 16.21% * 2000;
 Minibatch[   1- 100]: loss = 0.445541 * 100, metric = 6.25% * 100;
 Minibatch[ 101- 200]: loss = 0.455776 * 100, metric = 6.53% * 100;
 Minibatch[ 201- 300]: loss = 0.432159 * 100, metric = 5.84% * 100;
 Minibatch[ 301- 400]: loss = 0.437416 * 100, metric = 6.17% * 100;
 Minibatch[ 401- 500]: loss = 0.433900 * 100, metric = 5.85% * 100;
 Minibatch[ 501- 600]: loss = 0.421664 * 100, metric = 5.67% * 100;
 Minibatch[ 601- 700]: loss = 0.439088 * 100, metric = 6.16% * 100;
 Minibatch[ 701- 800]: loss = 0.428980 * 100, metric = 6.04% * 100;
 Minibatch[ 801- 900]: loss = 0.457196 * 100, metric = 6.56% * 100;
 Minibatch[ 901-1000]: loss = 0.431539 * 100, metric = 5.95% * 100;
 Minibatch[1001-1100]: loss = 0.447231 * 100, metric = 6.48% * 100;
 Minibatch[1101-1200]: loss = 0.435899 * 100, metric = 6.16% * 100;
 Minibatch[1201-1300]: loss = 0.426281 * 100, metric = 5.91% * 100;
 Minibatch[1301-1400]: loss = 0.425573 * 100, metric = 5.95% * 100;
 Minibatch[1401-1500]: loss = 0.441837 * 100, metric = 6.33% * 100;
 Minibatch[1501-1600]: loss = 0.433322 * 100, metric = 6.10% * 100;
 Minibatch[1601-1700]: loss = 0.416440 * 100, metric = 5.81% * 100;
 Minibatch[1701-1800]: loss = 0.410638 * 100, metric = 5.74% * 100;
 Minibatch[1801-1900]: loss = 0.423357 * 100, metric = 5.82% * 100;
 Minibatch[1901-2000]: loss = 0.420297 * 100, metric = 5.72% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.433207 * 2000, metric = 6.05% * 2000 893.998s (  2.2 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 14.80% * 2000;
 Minibatch[   1- 100]: loss = 0.424210 * 100, metric = 5.75% * 100;
 Minibatch[ 101- 200]: loss = 0.420295 * 100, metric = 5.83% * 100;
 Minibatch[ 201- 300]: loss = 0.420132 * 100, metric = 5.51% * 100;
 Minibatch[ 301- 400]: loss = 0.435534 * 100, metric = 6.10% * 100;
 Minibatch[ 401- 500]: loss = 0.429248 * 100, metric = 5.99% * 100;
 Minibatch[ 501- 600]: loss = 0.431485 * 100, metric = 6.16% * 100;
 Minibatch[ 601- 700]: loss = 0.437118 * 100, metric = 6.24% * 100;
 Minibatch[ 701- 800]: loss = 0.427613 * 100, metric = 5.96% * 100;
 Minibatch[ 801- 900]: loss = 0.437468 * 100, metric = 6.23% * 100;
 Minibatch[ 901-1000]: loss = 0.432457 * 100, metric = 6.04% * 100;
 Minibatch[1001-1100]: loss = 0.412630 * 100, metric = 5.54% * 100;
 Minibatch[1101-1200]: loss = 0.432819 * 100, metric = 5.98% * 100;
 Minibatch[1201-1300]: loss = 0.439066 * 100, metric = 6.30% * 100;
 Minibatch[1301-1400]: loss = 0.441158 * 100, metric = 6.27% * 100;
 Minibatch[1401-1500]: loss = 0.428466 * 100, metric = 6.06% * 100;
 Minibatch[1501-1600]: loss = 0.436923 * 100, metric = 6.16% * 100;
 Minibatch[1601-1700]: loss = 0.424431 * 100, metric = 6.06% * 100;
 Minibatch[1701-1800]: loss = 0.438563 * 100, metric = 6.32% * 100;
 Minibatch[1801-1900]: loss = 0.429938 * 100, metric = 6.14% * 100;
 Minibatch[1901-2000]: loss = 0.427448 * 100, metric = 6.04% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.430350 * 2000, metric = 6.03% * 2000 892.043s (  2.2 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 14.76% * 2000;
 Minibatch[   1- 100]: loss = 0.433590 * 100, metric = 6.11% * 100;
 Minibatch[ 101- 200]: loss = 0.429687 * 100, metric = 5.90% * 100;
 Minibatch[ 201- 300]: loss = 0.426842 * 100, metric = 6.28% * 100;
 Minibatch[ 301- 400]: loss = 0.425161 * 100, metric = 5.93% * 100;
 Minibatch[ 401- 500]: loss = 0.418356 * 100, metric = 5.76% * 100;
 Minibatch[ 501- 600]: loss = 0.422812 * 100, metric = 5.70% * 100;
 Minibatch[ 601- 700]: loss = 0.413118 * 100, metric = 5.68% * 100;
 Minibatch[ 701- 800]: loss = 0.394841 * 100, metric = 5.30% * 100;
 Minibatch[ 801- 900]: loss = 0.426045 * 100, metric = 5.88% * 100;
 Minibatch[ 901-1000]: loss = 0.423277 * 100, metric = 6.00% * 100;
 Minibatch[1001-1100]: loss = 0.422596 * 100, metric = 5.80% * 100;
 Minibatch[1101-1200]: loss = 0.413102 * 100, metric = 5.67% * 100;
 Minibatch[1201-1300]: loss = 0.418124 * 100, metric = 5.86% * 100;
 Minibatch[1301-1400]: loss = 0.409478 * 100, metric = 5.61% * 100;
 Minibatch[1401-1500]: loss = 0.424081 * 100, metric = 5.92% * 100;
 Minibatch[1501-1600]: loss = 0.426185 * 100, metric = 6.03% * 100;
 Minibatch[1601-1700]: loss = 0.414267 * 100, metric = 5.80% * 100;
 Minibatch[1701-1800]: loss = 0.413663 * 100, metric = 5.50% * 100;
 Minibatch[1801-1900]: loss = 0.442803 * 100, metric = 6.32% * 100;
 Minibatch[1901-2000]: loss = 0.405907 * 100, metric = 5.60% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.420197 * 2000, metric = 5.83% * 2000 888.979s (  2.2 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 13.52% * 2000;
0.6221898430734872
 Minibatch[   1- 100]: loss = 0.438253 * 100, metric = 6.12% * 100;
 Minibatch[ 101- 200]: loss = 0.430683 * 100, metric = 6.11% * 100;
 Minibatch[ 201- 300]: loss = 0.427508 * 100, metric = 6.03% * 100;
 Minibatch[ 301- 400]: loss = 0.422638 * 100, metric = 6.04% * 100;
 Minibatch[ 401- 500]: loss = 0.414230 * 100, metric = 5.68% * 100;
 Minibatch[ 501- 600]: loss = 0.425684 * 100, metric = 5.97% * 100;
 Minibatch[ 601- 700]: loss = 0.415586 * 100, metric = 5.65% * 100;
 Minibatch[ 701- 800]: loss = 0.417463 * 100, metric = 5.85% * 100;
 Minibatch[ 801- 900]: loss = 0.419992 * 100, metric = 5.58% * 100;
 Minibatch[ 901-1000]: loss = 0.422153 * 100, metric = 5.81% * 100;
 Minibatch[1001-1100]: loss = 0.410380 * 100, metric = 5.58% * 100;
 Minibatch[1101-1200]: loss = 0.398015 * 100, metric = 5.33% * 100;
 Minibatch[1201-1300]: loss = 0.413552 * 100, metric = 5.72% * 100;
 Minibatch[1301-1400]: loss = 0.413270 * 100, metric = 5.69% * 100;
 Minibatch[1401-1500]: loss = 0.405034 * 100, metric = 5.53% * 100;
 Minibatch[1501-1600]: loss = 0.398917 * 100, metric = 5.37% * 100;
 Minibatch[1601-1700]: loss = 0.399584 * 100, metric = 5.50% * 100;
 Minibatch[1701-1800]: loss = 0.406193 * 100, metric = 5.41% * 100;
 Minibatch[1801-1900]: loss = 0.404186 * 100, metric = 5.40% * 100;
 Minibatch[1901-2000]: loss = 0.412540 * 100, metric = 5.50% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.414793 * 2000, metric = 5.69% * 2000 887.234s (  2.3 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 14.92% * 2000;
 Minibatch[   1- 100]: loss = 0.426485 * 100, metric = 5.89% * 100;
 Minibatch[ 101- 200]: loss = 0.419206 * 100, metric = 5.79% * 100;
 Minibatch[ 201- 300]: loss = 0.409443 * 100, metric = 5.45% * 100;
 Minibatch[ 301- 400]: loss = 0.427137 * 100, metric = 5.83% * 100;
 Minibatch[ 401- 500]: loss = 0.424305 * 100, metric = 5.79% * 100;
 Minibatch[ 501- 600]: loss = 0.415081 * 100, metric = 5.72% * 100;
 Minibatch[ 601- 700]: loss = 0.418745 * 100, metric = 5.75% * 100;
 Minibatch[ 701- 800]: loss = 0.396387 * 100, metric = 5.29% * 100;
 Minibatch[ 801- 900]: loss = 0.398310 * 100, metric = 5.29% * 100;
 Minibatch[ 901-1000]: loss = 0.419710 * 100, metric = 5.66% * 100;
 Minibatch[1001-1100]: loss = 0.411940 * 100, metric = 5.50% * 100;
 Minibatch[1101-1200]: loss = 0.415203 * 100, metric = 5.61% * 100;
 Minibatch[1201-1300]: loss = 0.411894 * 100, metric = 5.30% * 100;
 Minibatch[1301-1400]: loss = 0.420443 * 100, metric = 5.86% * 100;
 Minibatch[1401-1500]: loss = 0.408605 * 100, metric = 5.43% * 100;
 Minibatch[1501-1600]: loss = 0.420034 * 100, metric = 5.51% * 100;
 Minibatch[1601-1700]: loss = 0.415834 * 100, metric = 5.76% * 100;
 Minibatch[1701-1800]: loss = 0.415663 * 100, metric = 5.69% * 100;
 Minibatch[1801-1900]: loss = 0.415237 * 100, metric = 5.88% * 100;
 Minibatch[1901-2000]: loss = 0.419033 * 100, metric = 5.77% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.415435 * 2000, metric = 5.64% * 2000 888.517s (  2.3 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 15.17% * 2000;
 Minibatch[   1- 100]: loss = 0.394145 * 100, metric = 5.40% * 100;
 Minibatch[ 101- 200]: loss = 0.416033 * 100, metric = 5.64% * 100;
 Minibatch[ 201- 300]: loss = 0.398554 * 100, metric = 5.38% * 100;
 Minibatch[ 301- 400]: loss = 0.406344 * 100, metric = 5.54% * 100;
 Minibatch[ 401- 500]: loss = 0.415521 * 100, metric = 5.84% * 100;
 Minibatch[ 501- 600]: loss = 0.401469 * 100, metric = 5.30% * 100;
 Minibatch[ 601- 700]: loss = 0.419191 * 100, metric = 5.63% * 100;
 Minibatch[ 701- 800]: loss = 0.402139 * 100, metric = 5.57% * 100;
 Minibatch[ 801- 900]: loss = 0.420373 * 100, metric = 5.78% * 100;
 Minibatch[ 901-1000]: loss = 0.413669 * 100, metric = 5.81% * 100;
 Minibatch[1001-1100]: loss = 0.407729 * 100, metric = 5.51% * 100;
 Minibatch[1101-1200]: loss = 0.422402 * 100, metric = 5.75% * 100;
 Minibatch[1201-1300]: loss = 0.423148 * 100, metric = 5.68% * 100;
 Minibatch[1301-1400]: loss = 0.411434 * 100, metric = 5.52% * 100;
 Minibatch[1401-1500]: loss = 0.406546 * 100, metric = 5.42% * 100;
 Minibatch[1501-1600]: loss = 0.411584 * 100, metric = 5.47% * 100;
 Minibatch[1601-1700]: loss = 0.403932 * 100, metric = 5.46% * 100;
 Minibatch[1701-1800]: loss = 0.403821 * 100, metric = 5.54% * 100;
 Minibatch[1801-1900]: loss = 0.413057 * 100, metric = 5.66% * 100;
 Minibatch[1901-2000]: loss = 0.414131 * 100, metric = 5.78% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.410261 * 2000, metric = 5.58% * 2000 883.742s (  2.3 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.35% * 2000;
 Minibatch[   1- 100]: loss = 0.415466 * 100, metric = 5.78% * 100;
 Minibatch[ 101- 200]: loss = 0.409886 * 100, metric = 5.82% * 100;
 Minibatch[ 201- 300]: loss = 0.410299 * 100, metric = 5.91% * 100;
 Minibatch[ 301- 400]: loss = 0.414646 * 100, metric = 5.81% * 100;
 Minibatch[ 401- 500]: loss = 0.406439 * 100, metric = 5.59% * 100;
 Minibatch[ 501- 600]: loss = 0.408524 * 100, metric = 5.49% * 100;
 Minibatch[ 601- 700]: loss = 0.409356 * 100, metric = 5.48% * 100;
 Minibatch[ 701- 800]: loss = 0.392742 * 100, metric = 5.15% * 100;
 Minibatch[ 801- 900]: loss = 0.406222 * 100, metric = 5.63% * 100;
 Minibatch[ 901-1000]: loss = 0.406448 * 100, metric = 5.55% * 100;
 Minibatch[1001-1100]: loss = 0.409146 * 100, metric = 5.61% * 100;
 Minibatch[1101-1200]: loss = 0.416121 * 100, metric = 5.58% * 100;
 Minibatch[1201-1300]: loss = 0.422190 * 100, metric = 5.75% * 100;
 Minibatch[1301-1400]: loss = 0.405928 * 100, metric = 5.37% * 100;
 Minibatch[1401-1500]: loss = 0.408646 * 100, metric = 5.41% * 100;
 Minibatch[1501-1600]: loss = 0.415837 * 100, metric = 5.86% * 100;
 Minibatch[1601-1700]: loss = 0.396609 * 100, metric = 5.42% * 100;
 Minibatch[1701-1800]: loss = 0.405656 * 100, metric = 5.57% * 100;
 Minibatch[1801-1900]: loss = 0.395728 * 100, metric = 5.21% * 100;
 Minibatch[1901-2000]: loss = 0.396379 * 100, metric = 5.18% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.407613 * 2000, metric = 5.56% * 2000 896.641s (  2.2 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.23% * 2000;
 Minibatch[   1- 100]: loss = 0.400782 * 100, metric = 5.40% * 100;
 Minibatch[ 101- 200]: loss = 0.384514 * 100, metric = 5.00% * 100;
 Minibatch[ 201- 300]: loss = 0.409567 * 100, metric = 5.69% * 100;
 Minibatch[ 301- 400]: loss = 0.394015 * 100, metric = 5.24% * 100;
 Minibatch[ 401- 500]: loss = 0.399198 * 100, metric = 5.32% * 100;
 Minibatch[ 501- 600]: loss = 0.395695 * 100, metric = 5.16% * 100;
 Minibatch[ 601- 700]: loss = 0.417173 * 100, metric = 5.69% * 100;
 Minibatch[ 701- 800]: loss = 0.393276 * 100, metric = 5.59% * 100;
 Minibatch[ 801- 900]: loss = 0.394719 * 100, metric = 5.32% * 100;
 Minibatch[ 901-1000]: loss = 0.391071 * 100, metric = 5.21% * 100;
 Minibatch[1001-1100]: loss = 0.405820 * 100, metric = 5.78% * 100;
 Minibatch[1101-1200]: loss = 0.411984 * 100, metric = 5.67% * 100;
 Minibatch[1201-1300]: loss = 0.404106 * 100, metric = 5.55% * 100;
 Minibatch[1301-1400]: loss = 0.385858 * 100, metric = 5.07% * 100;
 Minibatch[1401-1500]: loss = 0.399666 * 100, metric = 5.44% * 100;
 Minibatch[1501-1600]: loss = 0.395640 * 100, metric = 4.91% * 100;
 Minibatch[1601-1700]: loss = 0.414178 * 100, metric = 5.51% * 100;
 Minibatch[1701-1800]: loss = 0.411866 * 100, metric = 5.54% * 100;
 Minibatch[1801-1900]: loss = 0.406803 * 100, metric = 5.46% * 100;
 Minibatch[1901-2000]: loss = 0.408825 * 100, metric = 5.62% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.401238 * 2000, metric = 5.41% * 2000 893.911s (  2.2 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.39% * 2000;
 Minibatch[   1- 100]: loss = 0.399222 * 100, metric = 5.28% * 100;
 Minibatch[ 101- 200]: loss = 0.406903 * 100, metric = 5.41% * 100;
 Minibatch[ 201- 300]: loss = 0.391542 * 100, metric = 5.24% * 100;
 Minibatch[ 301- 400]: loss = 0.388853 * 100, metric = 5.14% * 100;
 Minibatch[ 401- 500]: loss = 0.403427 * 100, metric = 5.39% * 100;
 Minibatch[ 501- 600]: loss = 0.395419 * 100, metric = 5.29% * 100;
 Minibatch[ 601- 700]: loss = 0.396556 * 100, metric = 5.26% * 100;
 Minibatch[ 701- 800]: loss = 0.401642 * 100, metric = 5.26% * 100;
 Minibatch[ 801- 900]: loss = 0.408909 * 100, metric = 5.52% * 100;
 Minibatch[ 901-1000]: loss = 0.391810 * 100, metric = 5.27% * 100;
 Minibatch[1001-1100]: loss = 0.396603 * 100, metric = 5.20% * 100;
 Minibatch[1101-1200]: loss = 0.405394 * 100, metric = 5.40% * 100;
 Minibatch[1201-1300]: loss = 0.399449 * 100, metric = 5.32% * 100;
 Minibatch[1301-1400]: loss = 0.406390 * 100, metric = 5.58% * 100;
 Minibatch[1401-1500]: loss = 0.391349 * 100, metric = 5.25% * 100;
 Minibatch[1501-1600]: loss = 0.393538 * 100, metric = 5.23% * 100;
 Minibatch[1601-1700]: loss = 0.377184 * 100, metric = 4.89% * 100;
 Minibatch[1701-1800]: loss = 0.391649 * 100, metric = 4.94% * 100;
 Minibatch[1801-1900]: loss = 0.384261 * 100, metric = 4.95% * 100;
 Minibatch[1901-2000]: loss = 0.394674 * 100, metric = 5.07% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.396239 * 2000, metric = 5.24% * 2000 883.968s (  2.3 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 14.08% * 2000;
 Minibatch[   1- 100]: loss = 0.399637 * 100, metric = 5.62% * 100;
 Minibatch[ 101- 200]: loss = 0.395549 * 100, metric = 5.21% * 100;
 Minibatch[ 201- 300]: loss = 0.395001 * 100, metric = 5.38% * 100;
 Minibatch[ 301- 400]: loss = 0.393483 * 100, metric = 5.10% * 100;
 Minibatch[ 401- 500]: loss = 0.392209 * 100, metric = 5.39% * 100;
 Minibatch[ 501- 600]: loss = 0.411590 * 100, metric = 5.69% * 100;
 Minibatch[ 601- 700]: loss = 0.389584 * 100, metric = 5.06% * 100;
 Minibatch[ 701- 800]: loss = 0.377610 * 100, metric = 4.88% * 100;
 Minibatch[ 801- 900]: loss = 0.396710 * 100, metric = 5.27% * 100;
 Minibatch[ 901-1000]: loss = 0.397209 * 100, metric = 5.42% * 100;
 Minibatch[1001-1100]: loss = 0.392321 * 100, metric = 5.30% * 100;
 Minibatch[1101-1200]: loss = 0.384253 * 100, metric = 5.06% * 100;
 Minibatch[1201-1300]: loss = 0.392650 * 100, metric = 5.28% * 100;
 Minibatch[1301-1400]: loss = 0.389820 * 100, metric = 5.01% * 100;
 Minibatch[1401-1500]: loss = 0.402451 * 100, metric = 5.32% * 100;
 Minibatch[1501-1600]: loss = 0.382792 * 100, metric = 4.96% * 100;
 Minibatch[1601-1700]: loss = 0.386952 * 100, metric = 4.92% * 100;
 Minibatch[1701-1800]: loss = 0.382083 * 100, metric = 4.90% * 100;
 Minibatch[1801-1900]: loss = 0.393819 * 100, metric = 5.33% * 100;
 Minibatch[1901-2000]: loss = 0.401473 * 100, metric = 5.41% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.392860 * 2000, metric = 5.23% * 2000 892.462s (  2.2 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 12.74% * 2000;
 Minibatch[   1- 100]: loss = 0.381226 * 100, metric = 4.76% * 100;
 Minibatch[ 101- 200]: loss = 0.380043 * 100, metric = 5.06% * 100;
 Minibatch[ 201- 300]: loss = 0.391426 * 100, metric = 5.42% * 100;
 Minibatch[ 301- 400]: loss = 0.406404 * 100, metric = 5.35% * 100;
 Minibatch[ 401- 500]: loss = 0.383415 * 100, metric = 4.94% * 100;
 Minibatch[ 501- 600]: loss = 0.394895 * 100, metric = 5.17% * 100;
 Minibatch[ 601- 700]: loss = 0.383746 * 100, metric = 5.30% * 100;
 Minibatch[ 701- 800]: loss = 0.384828 * 100, metric = 5.19% * 100;
 Minibatch[ 801- 900]: loss = 0.392021 * 100, metric = 5.24% * 100;
 Minibatch[ 901-1000]: loss = 0.402258 * 100, metric = 5.32% * 100;
 Minibatch[1001-1100]: loss = 0.398992 * 100, metric = 5.15% * 100;
 Minibatch[1101-1200]: loss = 0.393423 * 100, metric = 4.92% * 100;
 Minibatch[1201-1300]: loss = 0.389665 * 100, metric = 4.95% * 100;
 Minibatch[1301-1400]: loss = 0.382422 * 100, metric = 4.93% * 100;
 Minibatch[1401-1500]: loss = 0.401492 * 100, metric = 5.10% * 100;
 Minibatch[1501-1600]: loss = 0.385065 * 100, metric = 4.80% * 100;
 Minibatch[1601-1700]: loss = 0.395209 * 100, metric = 5.10% * 100;
 Minibatch[1701-1800]: loss = 0.377658 * 100, metric = 4.93% * 100;
 Minibatch[1801-1900]: loss = 0.392948 * 100, metric = 5.19% * 100;
 Minibatch[1901-2000]: loss = 0.377862 * 100, metric = 4.94% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.389750 * 2000, metric = 5.09% * 2000 887.847s (  2.3 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 14.68% * 2000;
 Minibatch[   1- 100]: loss = 0.400604 * 100, metric = 5.16% * 100;
 Minibatch[ 101- 200]: loss = 0.368312 * 100, metric = 4.59% * 100;
 Minibatch[ 201- 300]: loss = 0.382131 * 100, metric = 5.03% * 100;
 Minibatch[ 301- 400]: loss = 0.386322 * 100, metric = 5.18% * 100;
 Minibatch[ 401- 500]: loss = 0.381594 * 100, metric = 4.84% * 100;
 Minibatch[ 501- 600]: loss = 0.359950 * 100, metric = 4.61% * 100;
 Minibatch[ 601- 700]: loss = 0.383766 * 100, metric = 5.18% * 100;
 Minibatch[ 701- 800]: loss = 0.372680 * 100, metric = 4.83% * 100;
 Minibatch[ 801- 900]: loss = 0.386413 * 100, metric = 5.12% * 100;
 Minibatch[ 901-1000]: loss = 0.362433 * 100, metric = 4.49% * 100;
 Minibatch[1001-1100]: loss = 0.383317 * 100, metric = 4.85% * 100;
 Minibatch[1101-1200]: loss = 0.385715 * 100, metric = 5.05% * 100;
 Minibatch[1201-1300]: loss = 0.374422 * 100, metric = 4.79% * 100;
 Minibatch[1301-1400]: loss = 0.379678 * 100, metric = 4.91% * 100;
 Minibatch[1401-1500]: loss = 0.380591 * 100, metric = 4.91% * 100;
 Minibatch[1501-1600]: loss = 0.395606 * 100, metric = 5.03% * 100;
 Minibatch[1601-1700]: loss = 0.387589 * 100, metric = 4.99% * 100;
 Minibatch[1701-1800]: loss = 0.378760 * 100, metric = 4.94% * 100;
 Minibatch[1801-1900]: loss = 0.378920 * 100, metric = 4.96% * 100;
 Minibatch[1901-2000]: loss = 0.403160 * 100, metric = 5.53% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.381598 * 2000, metric = 4.95% * 2000 888.463s (  2.3 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.94% * 2000;
 Minibatch[   1- 100]: loss = 0.380787 * 100, metric = 5.06% * 100;
 Minibatch[ 101- 200]: loss = 0.393893 * 100, metric = 5.29% * 100;
 Minibatch[ 201- 300]: loss = 0.384331 * 100, metric = 4.87% * 100;
 Minibatch[ 301- 400]: loss = 0.374233 * 100, metric = 4.77% * 100;
 Minibatch[ 401- 500]: loss = 0.381632 * 100, metric = 4.92% * 100;
 Minibatch[ 501- 600]: loss = 0.374913 * 100, metric = 4.81% * 100;
 Minibatch[ 601- 700]: loss = 0.392902 * 100, metric = 5.23% * 100;
 Minibatch[ 701- 800]: loss = 0.394952 * 100, metric = 5.20% * 100;
 Minibatch[ 801- 900]: loss = 0.391718 * 100, metric = 5.15% * 100;
 Minibatch[ 901-1000]: loss = 0.378056 * 100, metric = 4.99% * 100;
 Minibatch[1001-1100]: loss = 0.376486 * 100, metric = 4.78% * 100;
 Minibatch[1101-1200]: loss = 0.379599 * 100, metric = 5.09% * 100;
 Minibatch[1201-1300]: loss = 0.375499 * 100, metric = 4.80% * 100;
 Minibatch[1301-1400]: loss = 0.381588 * 100, metric = 5.01% * 100;
 Minibatch[1401-1500]: loss = 0.381361 * 100, metric = 5.06% * 100;
 Minibatch[1501-1600]: loss = 0.371437 * 100, metric = 4.95% * 100;
 Minibatch[1601-1700]: loss = 0.379158 * 100, metric = 4.91% * 100;
 Minibatch[1701-1800]: loss = 0.374236 * 100, metric = 5.05% * 100;
 Minibatch[1801-1900]: loss = 0.380131 * 100, metric = 4.99% * 100;
 Minibatch[1901-2000]: loss = 0.374824 * 100, metric = 4.87% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.381087 * 2000, metric = 4.99% * 2000 890.295s (  2.2 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 13.08% * 2000;
 Minibatch[   1- 100]: loss = 0.376457 * 100, metric = 4.96% * 100;
 Minibatch[ 101- 200]: loss = 0.385823 * 100, metric = 4.99% * 100;
 Minibatch[ 201- 300]: loss = 0.389952 * 100, metric = 5.23% * 100;
 Minibatch[ 301- 400]: loss = 0.394992 * 100, metric = 5.25% * 100;
 Minibatch[ 401- 500]: loss = 0.374831 * 100, metric = 5.01% * 100;
 Minibatch[ 501- 600]: loss = 0.381312 * 100, metric = 5.19% * 100;
 Minibatch[ 601- 700]: loss = 0.367899 * 100, metric = 4.66% * 100;
 Minibatch[ 701- 800]: loss = 0.372691 * 100, metric = 4.69% * 100;
 Minibatch[ 801- 900]: loss = 0.377420 * 100, metric = 4.97% * 100;
 Minibatch[ 901-1000]: loss = 0.358059 * 100, metric = 4.49% * 100;
 Minibatch[1001-1100]: loss = 0.367251 * 100, metric = 4.66% * 100;
 Minibatch[1101-1200]: loss = 0.373331 * 100, metric = 4.72% * 100;
 Minibatch[1201-1300]: loss = 0.391005 * 100, metric = 5.26% * 100;
 Minibatch[1301-1400]: loss = 0.373211 * 100, metric = 4.84% * 100;
 Minibatch[1401-1500]: loss = 0.372141 * 100, metric = 5.13% * 100;
 Minibatch[1501-1600]: loss = 0.380898 * 100, metric = 5.11% * 100;
 Minibatch[1601-1700]: loss = 0.372372 * 100, metric = 4.91% * 100;
 Minibatch[1701-1800]: loss = 0.389435 * 100, metric = 5.27% * 100;
 Minibatch[1801-1900]: loss = 0.370264 * 100, metric = 4.61% * 100;
 Minibatch[1901-2000]: loss = 0.382710 * 100, metric = 5.20% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.377603 * 2000, metric = 4.96% * 2000 890.266s (  2.2 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 14.05% * 2000;
 Minibatch[   1- 100]: loss = 0.390455 * 100, metric = 5.30% * 100;
 Minibatch[ 101- 200]: loss = 0.379318 * 100, metric = 5.18% * 100;
 Minibatch[ 201- 300]: loss = 0.369053 * 100, metric = 4.84% * 100;
 Minibatch[ 301- 400]: loss = 0.377954 * 100, metric = 5.15% * 100;
 Minibatch[ 401- 500]: loss = 0.371593 * 100, metric = 4.83% * 100;
 Minibatch[ 501- 600]: loss = 0.375863 * 100, metric = 4.95% * 100;
 Minibatch[ 601- 700]: loss = 0.377559 * 100, metric = 5.03% * 100;
 Minibatch[ 701- 800]: loss = 0.381222 * 100, metric = 4.93% * 100;
 Minibatch[ 801- 900]: loss = 0.375944 * 100, metric = 4.72% * 100;
 Minibatch[ 901-1000]: loss = 0.362746 * 100, metric = 4.60% * 100;
 Minibatch[1001-1100]: loss = 0.373297 * 100, metric = 4.91% * 100;
 Minibatch[1101-1200]: loss = 0.360695 * 100, metric = 4.70% * 100;
 Minibatch[1201-1300]: loss = 0.382692 * 100, metric = 4.97% * 100;
 Minibatch[1301-1400]: loss = 0.360942 * 100, metric = 4.58% * 100;
 Minibatch[1401-1500]: loss = 0.384938 * 100, metric = 5.05% * 100;
 Minibatch[1501-1600]: loss = 0.386547 * 100, metric = 5.21% * 100;
 Minibatch[1601-1700]: loss = 0.374470 * 100, metric = 4.81% * 100;
 Minibatch[1701-1800]: loss = 0.375422 * 100, metric = 4.93% * 100;
 Minibatch[1801-1900]: loss = 0.370153 * 100, metric = 4.86% * 100;
 Minibatch[1901-2000]: loss = 0.383895 * 100, metric = 5.19% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.375738 * 2000, metric = 4.94% * 2000 873.192s (  2.3 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.96% * 2000;
 Minibatch[   1- 100]: loss = 0.373473 * 100, metric = 4.91% * 100;
 Minibatch[ 101- 200]: loss = 0.378760 * 100, metric = 4.94% * 100;
 Minibatch[ 201- 300]: loss = 0.365921 * 100, metric = 4.73% * 100;
 Minibatch[ 301- 400]: loss = 0.370475 * 100, metric = 4.90% * 100;
 Minibatch[ 401- 500]: loss = 0.363633 * 100, metric = 4.59% * 100;
 Minibatch[ 501- 600]: loss = 0.372385 * 100, metric = 4.86% * 100;
 Minibatch[ 601- 700]: loss = 0.374158 * 100, metric = 5.00% * 100;
 Minibatch[ 701- 800]: loss = 0.375759 * 100, metric = 4.94% * 100;
 Minibatch[ 801- 900]: loss = 0.358581 * 100, metric = 4.39% * 100;
 Minibatch[ 901-1000]: loss = 0.367766 * 100, metric = 4.96% * 100;
 Minibatch[1001-1100]: loss = 0.376671 * 100, metric = 4.94% * 100;
 Minibatch[1101-1200]: loss = 0.367689 * 100, metric = 4.84% * 100;
 Minibatch[1201-1300]: loss = 0.376080 * 100, metric = 4.94% * 100;
 Minibatch[1301-1400]: loss = 0.367036 * 100, metric = 4.82% * 100;
 Minibatch[1401-1500]: loss = 0.380676 * 100, metric = 5.22% * 100;
 Minibatch[1501-1600]: loss = 0.375818 * 100, metric = 4.89% * 100;
 Minibatch[1601-1700]: loss = 0.389493 * 100, metric = 5.22% * 100;
 Minibatch[1701-1800]: loss = 0.373286 * 100, metric = 4.80% * 100;
 Minibatch[1801-1900]: loss = 0.372410 * 100, metric = 4.97% * 100;
 Minibatch[1901-2000]: loss = 0.376218 * 100, metric = 4.88% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.372814 * 2000, metric = 4.89% * 2000 891.634s (  2.2 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 15.22% * 2000;
 Minibatch[   1- 100]: loss = 0.364234 * 100, metric = 4.68% * 100;
 Minibatch[ 101- 200]: loss = 0.368204 * 100, metric = 4.80% * 100;
 Minibatch[ 201- 300]: loss = 0.379369 * 100, metric = 5.18% * 100;
 Minibatch[ 301- 400]: loss = 0.358142 * 100, metric = 4.56% * 100;
 Minibatch[ 401- 500]: loss = 0.368428 * 100, metric = 4.85% * 100;
 Minibatch[ 501- 600]: loss = 0.350978 * 100, metric = 4.55% * 100;
 Minibatch[ 601- 700]: loss = 0.383171 * 100, metric = 5.25% * 100;
 Minibatch[ 701- 800]: loss = 0.355542 * 100, metric = 4.58% * 100;
 Minibatch[ 801- 900]: loss = 0.383229 * 100, metric = 5.01% * 100;
 Minibatch[ 901-1000]: loss = 0.367862 * 100, metric = 4.85% * 100;
 Minibatch[1001-1100]: loss = 0.381895 * 100, metric = 5.04% * 100;
 Minibatch[1101-1200]: loss = 0.365203 * 100, metric = 4.75% * 100;
 Minibatch[1201-1300]: loss = 0.376510 * 100, metric = 4.93% * 100;
 Minibatch[1301-1400]: loss = 0.371500 * 100, metric = 4.96% * 100;
 Minibatch[1401-1500]: loss = 0.367073 * 100, metric = 4.71% * 100;
 Minibatch[1501-1600]: loss = 0.369108 * 100, metric = 4.79% * 100;
 Minibatch[1601-1700]: loss = 0.365923 * 100, metric = 4.88% * 100;
 Minibatch[1701-1800]: loss = 0.359312 * 100, metric = 4.61% * 100;
 Minibatch[1801-1900]: loss = 0.380769 * 100, metric = 5.03% * 100;
 Minibatch[1901-2000]: loss = 0.358956 * 100, metric = 4.64% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.368770 * 2000, metric = 4.83% * 2000 881.924s (  2.3 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.99% * 2000;
 Minibatch[   1- 100]: loss = 0.358249 * 100, metric = 4.61% * 100;
 Minibatch[ 101- 200]: loss = 0.350214 * 100, metric = 4.45% * 100;
 Minibatch[ 201- 300]: loss = 0.377682 * 100, metric = 5.02% * 100;
 Minibatch[ 301- 400]: loss = 0.366133 * 100, metric = 4.82% * 100;
 Minibatch[ 401- 500]: loss = 0.358090 * 100, metric = 4.56% * 100;
 Minibatch[ 501- 600]: loss = 0.362060 * 100, metric = 4.62% * 100;
 Minibatch[ 601- 700]: loss = 0.371050 * 100, metric = 4.59% * 100;
 Minibatch[ 701- 800]: loss = 0.352566 * 100, metric = 4.53% * 100;
 Minibatch[ 801- 900]: loss = 0.350624 * 100, metric = 4.55% * 100;
 Minibatch[ 901-1000]: loss = 0.372527 * 100, metric = 4.94% * 100;
 Minibatch[1001-1100]: loss = 0.381205 * 100, metric = 5.05% * 100;
 Minibatch[1101-1200]: loss = 0.365026 * 100, metric = 4.81% * 100;
 Minibatch[1201-1300]: loss = 0.371786 * 100, metric = 4.84% * 100;
 Minibatch[1301-1400]: loss = 0.343989 * 100, metric = 4.32% * 100;
 Minibatch[1401-1500]: loss = 0.361393 * 100, metric = 4.60% * 100;
 Minibatch[1501-1600]: loss = 0.363224 * 100, metric = 4.73% * 100;
 Minibatch[1601-1700]: loss = 0.376133 * 100, metric = 4.94% * 100;
 Minibatch[1701-1800]: loss = 0.367529 * 100, metric = 4.65% * 100;
 Minibatch[1801-1900]: loss = 0.368951 * 100, metric = 4.71% * 100;
 Minibatch[1901-2000]: loss = 0.363266 * 100, metric = 4.55% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.364085 * 2000, metric = 4.69% * 2000 883.117s (  2.3 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.87% * 2000;
 Minibatch[   1- 100]: loss = 0.366805 * 100, metric = 4.57% * 100;
 Minibatch[ 101- 200]: loss = 0.375781 * 100, metric = 4.91% * 100;
 Minibatch[ 201- 300]: loss = 0.370676 * 100, metric = 4.90% * 100;
 Minibatch[ 301- 400]: loss = 0.366757 * 100, metric = 4.56% * 100;
 Minibatch[ 401- 500]: loss = 0.367563 * 100, metric = 4.74% * 100;
 Minibatch[ 501- 600]: loss = 0.349419 * 100, metric = 4.67% * 100;
 Minibatch[ 601- 700]: loss = 0.359317 * 100, metric = 4.75% * 100;
 Minibatch[ 701- 800]: loss = 0.370427 * 100, metric = 4.70% * 100;
 Minibatch[ 801- 900]: loss = 0.367915 * 100, metric = 4.69% * 100;
 Minibatch[ 901-1000]: loss = 0.351764 * 100, metric = 4.33% * 100;
 Minibatch[1001-1100]: loss = 0.360866 * 100, metric = 4.81% * 100;
 Minibatch[1101-1200]: loss = 0.383589 * 100, metric = 4.98% * 100;
 Minibatch[1201-1300]: loss = 0.369475 * 100, metric = 4.69% * 100;
 Minibatch[1301-1400]: loss = 0.359029 * 100, metric = 4.45% * 100;
 Minibatch[1401-1500]: loss = 0.364057 * 100, metric = 4.63% * 100;
 Minibatch[1501-1600]: loss = 0.358650 * 100, metric = 4.56% * 100;
 Minibatch[1601-1700]: loss = 0.364678 * 100, metric = 4.84% * 100;
 Minibatch[1701-1800]: loss = 0.357846 * 100, metric = 4.48% * 100;
 Minibatch[1801-1900]: loss = 0.362117 * 100, metric = 4.83% * 100;
 Minibatch[1901-2000]: loss = 0.367285 * 100, metric = 4.61% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.364701 * 2000, metric = 4.69% * 2000 877.264s (  2.3 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.76% * 2000;
 Minibatch[   1- 100]: loss = 0.370925 * 100, metric = 4.72% * 100;
 Minibatch[ 101- 200]: loss = 0.366278 * 100, metric = 4.73% * 100;
 Minibatch[ 201- 300]: loss = 0.350850 * 100, metric = 4.55% * 100;
 Minibatch[ 301- 400]: loss = 0.358434 * 100, metric = 4.63% * 100;
 Minibatch[ 401- 500]: loss = 0.368716 * 100, metric = 4.65% * 100;
 Minibatch[ 501- 600]: loss = 0.361402 * 100, metric = 4.28% * 100;
 Minibatch[ 601- 700]: loss = 0.366337 * 100, metric = 4.79% * 100;
 Minibatch[ 701- 800]: loss = 0.361441 * 100, metric = 4.47% * 100;
 Minibatch[ 801- 900]: loss = 0.365356 * 100, metric = 4.59% * 100;
 Minibatch[ 901-1000]: loss = 0.371656 * 100, metric = 4.58% * 100;
 Minibatch[1001-1100]: loss = 0.372006 * 100, metric = 4.75% * 100;
 Minibatch[1101-1200]: loss = 0.352125 * 100, metric = 4.36% * 100;
 Minibatch[1201-1300]: loss = 0.365230 * 100, metric = 4.59% * 100;
 Minibatch[1301-1400]: loss = 0.371716 * 100, metric = 4.72% * 100;
 Minibatch[1401-1500]: loss = 0.372726 * 100, metric = 4.73% * 100;
 Minibatch[1501-1600]: loss = 0.367894 * 100, metric = 4.75% * 100;
 Minibatch[1601-1700]: loss = 0.354354 * 100, metric = 4.47% * 100;
 Minibatch[1701-1800]: loss = 0.357627 * 100, metric = 4.44% * 100;
 Minibatch[1801-1900]: loss = 0.365316 * 100, metric = 4.64% * 100;
 Minibatch[1901-2000]: loss = 0.372095 * 100, metric = 4.74% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.364624 * 2000, metric = 4.61% * 2000 886.192s (  2.3 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 13.23% * 2000;
 Minibatch[   1- 100]: loss = 0.366164 * 100, metric = 4.70% * 100;
 Minibatch[ 101- 200]: loss = 0.368661 * 100, metric = 4.85% * 100;
 Minibatch[ 201- 300]: loss = 0.364454 * 100, metric = 4.46% * 100;
 Minibatch[ 301- 400]: loss = 0.355823 * 100, metric = 4.51% * 100;
 Minibatch[ 401- 500]: loss = 0.358491 * 100, metric = 4.53% * 100;
 Minibatch[ 501- 600]: loss = 0.370104 * 100, metric = 4.80% * 100;
 Minibatch[ 601- 700]: loss = 0.365409 * 100, metric = 4.89% * 100;
 Minibatch[ 701- 800]: loss = 0.364710 * 100, metric = 4.42% * 100;
 Minibatch[ 801- 900]: loss = 0.347870 * 100, metric = 4.30% * 100;
 Minibatch[ 901-1000]: loss = 0.360425 * 100, metric = 4.58% * 100;
 Minibatch[1001-1100]: loss = 0.370674 * 100, metric = 4.88% * 100;
 Minibatch[1101-1200]: loss = 0.368497 * 100, metric = 4.93% * 100;
 Minibatch[1201-1300]: loss = 0.364791 * 100, metric = 4.41% * 100;
 Minibatch[1301-1400]: loss = 0.383231 * 100, metric = 4.93% * 100;
 Minibatch[1401-1500]: loss = 0.372909 * 100, metric = 4.61% * 100;
 Minibatch[1501-1600]: loss = 0.368047 * 100, metric = 4.67% * 100;
 Minibatch[1601-1700]: loss = 0.362738 * 100, metric = 4.51% * 100;
 Minibatch[1701-1800]: loss = 0.369263 * 100, metric = 4.64% * 100;
 Minibatch[1801-1900]: loss = 0.361114 * 100, metric = 4.59% * 100;
 Minibatch[1901-2000]: loss = 0.368251 * 100, metric = 4.87% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.365581 * 2000, metric = 4.65% * 2000 881.994s (  2.3 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.53% * 2000;
 Minibatch[   1- 100]: loss = 0.355451 * 100, metric = 4.63% * 100;
 Minibatch[ 101- 200]: loss = 0.352791 * 100, metric = 4.49% * 100;
 Minibatch[ 201- 300]: loss = 0.372295 * 100, metric = 4.62% * 100;
 Minibatch[ 301- 400]: loss = 0.360355 * 100, metric = 4.70% * 100;
 Minibatch[ 401- 500]: loss = 0.349571 * 100, metric = 4.39% * 100;
 Minibatch[ 501- 600]: loss = 0.353407 * 100, metric = 4.54% * 100;
 Minibatch[ 601- 700]: loss = 0.364263 * 100, metric = 4.65% * 100;
 Minibatch[ 701- 800]: loss = 0.355698 * 100, metric = 4.45% * 100;
 Minibatch[ 801- 900]: loss = 0.352979 * 100, metric = 4.38% * 100;
 Minibatch[ 901-1000]: loss = 0.352451 * 100, metric = 4.43% * 100;
 Minibatch[1001-1100]: loss = 0.364006 * 100, metric = 4.79% * 100;
 Minibatch[1101-1200]: loss = 0.357518 * 100, metric = 4.52% * 100;
 Minibatch[1201-1300]: loss = 0.358273 * 100, metric = 4.33% * 100;
 Minibatch[1301-1400]: loss = 0.358103 * 100, metric = 4.57% * 100;
 Minibatch[1401-1500]: loss = 0.356494 * 100, metric = 4.36% * 100;
 Minibatch[1501-1600]: loss = 0.357653 * 100, metric = 4.50% * 100;
 Minibatch[1601-1700]: loss = 0.368584 * 100, metric = 4.71% * 100;
 Minibatch[1701-1800]: loss = 0.350244 * 100, metric = 4.37% * 100;
 Minibatch[1801-1900]: loss = 0.348373 * 100, metric = 4.25% * 100;
 Minibatch[1901-2000]: loss = 0.358231 * 100, metric = 4.80% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.357337 * 2000, metric = 4.52% * 2000 872.070s (  2.3 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 14.45% * 2000;
 Minibatch[   1- 100]: loss = 0.357531 * 100, metric = 4.66% * 100;
 Minibatch[ 101- 200]: loss = 0.350683 * 100, metric = 4.36% * 100;
 Minibatch[ 201- 300]: loss = 0.358178 * 100, metric = 4.46% * 100;
 Minibatch[ 301- 400]: loss = 0.371210 * 100, metric = 4.71% * 100;
 Minibatch[ 401- 500]: loss = 0.361192 * 100, metric = 4.51% * 100;
 Minibatch[ 501- 600]: loss = 0.355808 * 100, metric = 4.38% * 100;
 Minibatch[ 601- 700]: loss = 0.361188 * 100, metric = 4.79% * 100;
 Minibatch[ 701- 800]: loss = 0.361111 * 100, metric = 4.54% * 100;
 Minibatch[ 801- 900]: loss = 0.355170 * 100, metric = 4.50% * 100;
 Minibatch[ 901-1000]: loss = 0.359652 * 100, metric = 4.75% * 100;
 Minibatch[1001-1100]: loss = 0.357532 * 100, metric = 4.47% * 100;
 Minibatch[1101-1200]: loss = 0.367211 * 100, metric = 4.75% * 100;
 Minibatch[1201-1300]: loss = 0.364929 * 100, metric = 4.72% * 100;
 Minibatch[1301-1400]: loss = 0.344363 * 100, metric = 4.26% * 100;
 Minibatch[1401-1500]: loss = 0.350554 * 100, metric = 4.41% * 100;
 Minibatch[1501-1600]: loss = 0.360081 * 100, metric = 4.55% * 100;
 Minibatch[1601-1700]: loss = 0.361778 * 100, metric = 4.70% * 100;
 Minibatch[1701-1800]: loss = 0.351859 * 100, metric = 4.39% * 100;
 Minibatch[1801-1900]: loss = 0.356057 * 100, metric = 4.63% * 100;
 Minibatch[1901-2000]: loss = 0.347964 * 100, metric = 4.29% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.357703 * 2000, metric = 4.54% * 2000 884.528s (  2.3 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 14.31% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
