Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.310934 * 100, metric = 25.28% * 100;
 Minibatch[ 101- 200]: loss = 1.017437 * 100, metric = 22.94% * 100;
 Minibatch[ 201- 300]: loss = 0.953170 * 100, metric = 21.48% * 100;
 Minibatch[ 301- 400]: loss = 0.940875 * 100, metric = 20.90% * 100;
 Minibatch[ 401- 500]: loss = 0.870091 * 100, metric = 19.51% * 100;
 Minibatch[ 501- 600]: loss = 0.834396 * 100, metric = 18.22% * 100;
 Minibatch[ 601- 700]: loss = 0.804149 * 100, metric = 17.36% * 100;
 Minibatch[ 701- 800]: loss = 0.753267 * 100, metric = 16.21% * 100;
 Minibatch[ 801- 900]: loss = 0.784573 * 100, metric = 16.84% * 100;
 Minibatch[ 901-1000]: loss = 0.793201 * 100, metric = 16.92% * 100;
 Minibatch[1001-1100]: loss = 0.761971 * 100, metric = 15.87% * 100;
 Minibatch[1101-1200]: loss = 0.742841 * 100, metric = 15.73% * 100;
 Minibatch[1201-1300]: loss = 0.752251 * 100, metric = 16.22% * 100;
 Minibatch[1301-1400]: loss = 0.715291 * 100, metric = 14.65% * 100;
 Minibatch[1401-1500]: loss = 0.713654 * 100, metric = 15.28% * 100;
 Minibatch[1501-1600]: loss = 0.696648 * 100, metric = 14.97% * 100;
 Minibatch[1601-1700]: loss = 0.687034 * 100, metric = 14.22% * 100;
 Minibatch[1701-1800]: loss = 0.693308 * 100, metric = 14.59% * 100;
 Minibatch[1801-1900]: loss = 0.687844 * 100, metric = 14.31% * 100;
 Minibatch[1901-2000]: loss = 0.669890 * 100, metric = 13.90% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.809141 * 2000, metric = 17.27% * 2000 1003.046s (  2.0 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 30.00% * 2000;
0.8561699666082859
 Minibatch[   1- 100]: loss = 0.663350 * 100, metric = 13.71% * 100;
 Minibatch[ 101- 200]: loss = 0.673665 * 100, metric = 13.88% * 100;
 Minibatch[ 201- 300]: loss = 0.642105 * 100, metric = 12.59% * 100;
 Minibatch[ 301- 400]: loss = 0.651078 * 100, metric = 13.15% * 100;
 Minibatch[ 401- 500]: loss = 0.639902 * 100, metric = 13.25% * 100;
 Minibatch[ 501- 600]: loss = 0.647644 * 100, metric = 12.97% * 100;
 Minibatch[ 601- 700]: loss = 0.629873 * 100, metric = 12.85% * 100;
 Minibatch[ 701- 800]: loss = 0.655583 * 100, metric = 13.77% * 100;
 Minibatch[ 801- 900]: loss = 0.611766 * 100, metric = 12.49% * 100;
 Minibatch[ 901-1000]: loss = 0.606905 * 100, metric = 12.27% * 100;
 Minibatch[1001-1100]: loss = 0.618726 * 100, metric = 12.96% * 100;
 Minibatch[1101-1200]: loss = 0.616411 * 100, metric = 12.48% * 100;
 Minibatch[1201-1300]: loss = 0.603929 * 100, metric = 12.55% * 100;
 Minibatch[1301-1400]: loss = 0.612357 * 100, metric = 12.55% * 100;
 Minibatch[1401-1500]: loss = 0.601416 * 100, metric = 11.97% * 100;
 Minibatch[1501-1600]: loss = 0.588151 * 100, metric = 11.82% * 100;
 Minibatch[1601-1700]: loss = 0.596263 * 100, metric = 12.23% * 100;
 Minibatch[1701-1800]: loss = 0.602889 * 100, metric = 12.30% * 100;
 Minibatch[1801-1900]: loss = 0.596442 * 100, metric = 12.23% * 100;
 Minibatch[1901-2000]: loss = 0.576373 * 100, metric = 11.62% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.621741 * 2000, metric = 12.68% * 2000 935.897s (  2.1 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 20.37% * 2000;
0.678175422206521
 Minibatch[   1- 100]: loss = 0.589023 * 100, metric = 12.19% * 100;
 Minibatch[ 101- 200]: loss = 0.592404 * 100, metric = 12.03% * 100;
 Minibatch[ 201- 300]: loss = 0.567403 * 100, metric = 11.57% * 100;
 Minibatch[ 301- 400]: loss = 0.592710 * 100, metric = 12.37% * 100;
 Minibatch[ 401- 500]: loss = 0.593075 * 100, metric = 12.13% * 100;
 Minibatch[ 501- 600]: loss = 0.594421 * 100, metric = 11.71% * 100;
 Minibatch[ 601- 700]: loss = 0.594077 * 100, metric = 12.34% * 100;
 Minibatch[ 701- 800]: loss = 0.567838 * 100, metric = 11.24% * 100;
 Minibatch[ 801- 900]: loss = 0.588045 * 100, metric = 12.18% * 100;
 Minibatch[ 901-1000]: loss = 0.565522 * 100, metric = 11.90% * 100;
 Minibatch[1001-1100]: loss = 0.587886 * 100, metric = 11.86% * 100;
 Minibatch[1101-1200]: loss = 0.571910 * 100, metric = 11.62% * 100;
 Minibatch[1201-1300]: loss = 0.554725 * 100, metric = 11.30% * 100;
 Minibatch[1301-1400]: loss = 0.572653 * 100, metric = 11.54% * 100;
 Minibatch[1401-1500]: loss = 0.572325 * 100, metric = 11.67% * 100;
 Minibatch[1501-1600]: loss = 0.552255 * 100, metric = 11.02% * 100;
 Minibatch[1601-1700]: loss = 0.540753 * 100, metric = 10.78% * 100;
 Minibatch[1701-1800]: loss = 0.569785 * 100, metric = 11.45% * 100;
 Minibatch[1801-1900]: loss = 0.554509 * 100, metric = 11.20% * 100;
 Minibatch[1901-2000]: loss = 0.554825 * 100, metric = 11.56% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.573807 * 2000, metric = 11.68% * 2000 937.565s (  2.1 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 19.00% * 2000;
0.6397969509363175
 Minibatch[   1- 100]: loss = 0.566995 * 100, metric = 11.24% * 100;
 Minibatch[ 101- 200]: loss = 0.546144 * 100, metric = 10.97% * 100;
 Minibatch[ 201- 300]: loss = 0.559374 * 100, metric = 11.44% * 100;
 Minibatch[ 301- 400]: loss = 0.527883 * 100, metric = 10.34% * 100;
 Minibatch[ 401- 500]: loss = 0.544342 * 100, metric = 10.85% * 100;
 Minibatch[ 501- 600]: loss = 0.530125 * 100, metric = 10.54% * 100;
 Minibatch[ 601- 700]: loss = 0.546553 * 100, metric = 10.85% * 100;
 Minibatch[ 701- 800]: loss = 0.535023 * 100, metric = 10.58% * 100;
 Minibatch[ 801- 900]: loss = 0.541704 * 100, metric = 10.70% * 100;
 Minibatch[ 901-1000]: loss = 0.536450 * 100, metric = 10.75% * 100;
 Minibatch[1001-1100]: loss = 0.549647 * 100, metric = 11.02% * 100;
 Minibatch[1101-1200]: loss = 0.521753 * 100, metric = 10.21% * 100;
 Minibatch[1201-1300]: loss = 0.525605 * 100, metric = 10.60% * 100;
 Minibatch[1301-1400]: loss = 0.547681 * 100, metric = 10.80% * 100;
 Minibatch[1401-1500]: loss = 0.542027 * 100, metric = 10.83% * 100;
 Minibatch[1501-1600]: loss = 0.509749 * 100, metric = 9.96% * 100;
 Minibatch[1601-1700]: loss = 0.527954 * 100, metric = 10.62% * 100;
 Minibatch[1701-1800]: loss = 0.537571 * 100, metric = 10.51% * 100;
 Minibatch[1801-1900]: loss = 0.515939 * 100, metric = 10.04% * 100;
 Minibatch[1901-2000]: loss = 0.510403 * 100, metric = 9.82% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.536146 * 2000, metric = 10.63% * 2000 937.172s (  2.1 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 20.56% * 2000;
 Minibatch[   1- 100]: loss = 0.537234 * 100, metric = 10.50% * 100;
 Minibatch[ 101- 200]: loss = 0.515956 * 100, metric = 10.17% * 100;
 Minibatch[ 201- 300]: loss = 0.500516 * 100, metric = 9.94% * 100;
 Minibatch[ 301- 400]: loss = 0.546295 * 100, metric = 11.13% * 100;
 Minibatch[ 401- 500]: loss = 0.489756 * 100, metric = 9.45% * 100;
 Minibatch[ 501- 600]: loss = 0.495432 * 100, metric = 9.57% * 100;
 Minibatch[ 601- 700]: loss = 0.497975 * 100, metric = 9.43% * 100;
 Minibatch[ 701- 800]: loss = 0.511554 * 100, metric = 10.09% * 100;
 Minibatch[ 801- 900]: loss = 0.491375 * 100, metric = 9.59% * 100;
 Minibatch[ 901-1000]: loss = 0.501663 * 100, metric = 10.08% * 100;
 Minibatch[1001-1100]: loss = 0.503101 * 100, metric = 9.84% * 100;
 Minibatch[1101-1200]: loss = 0.494094 * 100, metric = 9.75% * 100;
 Minibatch[1201-1300]: loss = 0.511917 * 100, metric = 9.86% * 100;
 Minibatch[1301-1400]: loss = 0.512576 * 100, metric = 10.33% * 100;
 Minibatch[1401-1500]: loss = 0.497132 * 100, metric = 9.89% * 100;
 Minibatch[1501-1600]: loss = 0.506175 * 100, metric = 9.93% * 100;
 Minibatch[1601-1700]: loss = 0.521346 * 100, metric = 10.46% * 100;
 Minibatch[1701-1800]: loss = 0.520828 * 100, metric = 10.43% * 100;
 Minibatch[1801-1900]: loss = 0.505027 * 100, metric = 9.97% * 100;
 Minibatch[1901-2000]: loss = 0.490573 * 100, metric = 9.54% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.507526 * 2000, metric = 10.00% * 2000 916.531s (  2.2 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 19.03% * 2000;
 Minibatch[   1- 100]: loss = 0.484932 * 100, metric = 9.49% * 100;
 Minibatch[ 101- 200]: loss = 0.481958 * 100, metric = 9.38% * 100;
 Minibatch[ 201- 300]: loss = 0.493426 * 100, metric = 9.74% * 100;
 Minibatch[ 301- 400]: loss = 0.483699 * 100, metric = 9.25% * 100;
 Minibatch[ 401- 500]: loss = 0.470954 * 100, metric = 9.01% * 100;
 Minibatch[ 501- 600]: loss = 0.484278 * 100, metric = 9.67% * 100;
 Minibatch[ 601- 700]: loss = 0.480200 * 100, metric = 9.35% * 100;
 Minibatch[ 701- 800]: loss = 0.483607 * 100, metric = 9.32% * 100;
 Minibatch[ 801- 900]: loss = 0.486072 * 100, metric = 9.51% * 100;
 Minibatch[ 901-1000]: loss = 0.476685 * 100, metric = 9.35% * 100;
 Minibatch[1001-1100]: loss = 0.473741 * 100, metric = 8.99% * 100;
 Minibatch[1101-1200]: loss = 0.479999 * 100, metric = 9.26% * 100;
 Minibatch[1201-1300]: loss = 0.495221 * 100, metric = 9.75% * 100;
 Minibatch[1301-1400]: loss = 0.476899 * 100, metric = 9.12% * 100;
 Minibatch[1401-1500]: loss = 0.489039 * 100, metric = 9.55% * 100;
 Minibatch[1501-1600]: loss = 0.474222 * 100, metric = 9.23% * 100;
 Minibatch[1601-1700]: loss = 0.476400 * 100, metric = 9.07% * 100;
 Minibatch[1701-1800]: loss = 0.472709 * 100, metric = 9.05% * 100;
 Minibatch[1801-1900]: loss = 0.495998 * 100, metric = 9.72% * 100;
 Minibatch[1901-2000]: loss = 0.482170 * 100, metric = 9.34% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.482111 * 2000, metric = 9.36% * 2000 924.403s (  2.2 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 19.84% * 2000;
 Minibatch[   1- 100]: loss = 0.475280 * 100, metric = 9.08% * 100;
 Minibatch[ 101- 200]: loss = 0.483596 * 100, metric = 9.29% * 100;
 Minibatch[ 201- 300]: loss = 0.489955 * 100, metric = 9.55% * 100;
 Minibatch[ 301- 400]: loss = 0.469595 * 100, metric = 8.89% * 100;
 Minibatch[ 401- 500]: loss = 0.482278 * 100, metric = 9.18% * 100;
 Minibatch[ 501- 600]: loss = 0.458282 * 100, metric = 8.58% * 100;
 Minibatch[ 601- 700]: loss = 0.473474 * 100, metric = 8.91% * 100;
 Minibatch[ 701- 800]: loss = 0.468806 * 100, metric = 8.89% * 100;
 Minibatch[ 801- 900]: loss = 0.479606 * 100, metric = 9.37% * 100;
 Minibatch[ 901-1000]: loss = 0.463766 * 100, metric = 9.02% * 100;
 Minibatch[1001-1100]: loss = 0.480776 * 100, metric = 9.41% * 100;
 Minibatch[1101-1200]: loss = 0.458118 * 100, metric = 8.74% * 100;
 Minibatch[1201-1300]: loss = 0.473551 * 100, metric = 9.41% * 100;
 Minibatch[1301-1400]: loss = 0.453822 * 100, metric = 8.59% * 100;
 Minibatch[1401-1500]: loss = 0.449412 * 100, metric = 8.56% * 100;
 Minibatch[1501-1600]: loss = 0.462792 * 100, metric = 8.77% * 100;
 Minibatch[1601-1700]: loss = 0.463021 * 100, metric = 8.85% * 100;
 Minibatch[1701-1800]: loss = 0.460353 * 100, metric = 8.77% * 100;
 Minibatch[1801-1900]: loss = 0.462994 * 100, metric = 9.03% * 100;
 Minibatch[1901-2000]: loss = 0.457074 * 100, metric = 8.96% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.468327 * 2000, metric = 8.99% * 2000 922.471s (  2.2 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 17.42% * 2000;
0.5914478479847312
 Minibatch[   1- 100]: loss = 0.465148 * 100, metric = 9.01% * 100;
 Minibatch[ 101- 200]: loss = 0.454879 * 100, metric = 8.74% * 100;
 Minibatch[ 201- 300]: loss = 0.435453 * 100, metric = 8.28% * 100;
 Minibatch[ 301- 400]: loss = 0.452563 * 100, metric = 8.82% * 100;
 Minibatch[ 401- 500]: loss = 0.457693 * 100, metric = 8.95% * 100;
 Minibatch[ 501- 600]: loss = 0.475873 * 100, metric = 9.33% * 100;
 Minibatch[ 601- 700]: loss = 0.429066 * 100, metric = 8.01% * 100;
 Minibatch[ 701- 800]: loss = 0.452614 * 100, metric = 8.55% * 100;
 Minibatch[ 801- 900]: loss = 0.443587 * 100, metric = 8.26% * 100;
 Minibatch[ 901-1000]: loss = 0.428859 * 100, metric = 8.05% * 100;
 Minibatch[1001-1100]: loss = 0.435865 * 100, metric = 8.23% * 100;
 Minibatch[1101-1200]: loss = 0.434750 * 100, metric = 8.32% * 100;
 Minibatch[1201-1300]: loss = 0.450951 * 100, metric = 8.73% * 100;
 Minibatch[1301-1400]: loss = 0.461221 * 100, metric = 9.08% * 100;
 Minibatch[1401-1500]: loss = 0.442929 * 100, metric = 8.19% * 100;
 Minibatch[1501-1600]: loss = 0.458515 * 100, metric = 8.79% * 100;
 Minibatch[1601-1700]: loss = 0.449331 * 100, metric = 8.47% * 100;
 Minibatch[1701-1800]: loss = 0.445159 * 100, metric = 8.37% * 100;
 Minibatch[1801-1900]: loss = 0.444609 * 100, metric = 8.50% * 100;
 Minibatch[1901-2000]: loss = 0.456113 * 100, metric = 8.72% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.448759 * 2000, metric = 8.57% * 2000 917.389s (  2.2 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 15.60% * 2000;
0.5700198283344508
 Minibatch[   1- 100]: loss = 0.432741 * 100, metric = 8.12% * 100;
 Minibatch[ 101- 200]: loss = 0.465331 * 100, metric = 9.18% * 100;
 Minibatch[ 201- 300]: loss = 0.453384 * 100, metric = 8.76% * 100;
 Minibatch[ 301- 400]: loss = 0.465351 * 100, metric = 8.91% * 100;
 Minibatch[ 401- 500]: loss = 0.452101 * 100, metric = 8.57% * 100;
 Minibatch[ 501- 600]: loss = 0.447225 * 100, metric = 8.67% * 100;
 Minibatch[ 601- 700]: loss = 0.451140 * 100, metric = 8.81% * 100;
 Minibatch[ 701- 800]: loss = 0.431531 * 100, metric = 8.10% * 100;
 Minibatch[ 801- 900]: loss = 0.435905 * 100, metric = 8.55% * 100;
 Minibatch[ 901-1000]: loss = 0.443873 * 100, metric = 8.62% * 100;
 Minibatch[1001-1100]: loss = 0.418549 * 100, metric = 7.77% * 100;
 Minibatch[1101-1200]: loss = 0.438882 * 100, metric = 8.31% * 100;
 Minibatch[1201-1300]: loss = 0.435510 * 100, metric = 8.40% * 100;
 Minibatch[1301-1400]: loss = 0.426774 * 100, metric = 7.98% * 100;
 Minibatch[1401-1500]: loss = 0.448849 * 100, metric = 8.63% * 100;
 Minibatch[1501-1600]: loss = 0.442500 * 100, metric = 8.49% * 100;
 Minibatch[1601-1700]: loss = 0.442554 * 100, metric = 8.52% * 100;
 Minibatch[1701-1800]: loss = 0.430509 * 100, metric = 7.98% * 100;
 Minibatch[1801-1900]: loss = 0.433813 * 100, metric = 8.27% * 100;
 Minibatch[1901-2000]: loss = 0.446191 * 100, metric = 8.41% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.442136 * 2000, metric = 8.45% * 2000 902.116s (  2.2 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 14.94% * 2000;
0.5476737498641014
 Minibatch[   1- 100]: loss = 0.449182 * 100, metric = 8.74% * 100;
 Minibatch[ 101- 200]: loss = 0.422638 * 100, metric = 7.96% * 100;
 Minibatch[ 201- 300]: loss = 0.437626 * 100, metric = 8.38% * 100;
 Minibatch[ 301- 400]: loss = 0.427395 * 100, metric = 7.94% * 100;
 Minibatch[ 401- 500]: loss = 0.442633 * 100, metric = 8.38% * 100;
 Minibatch[ 501- 600]: loss = 0.413087 * 100, metric = 7.60% * 100;
 Minibatch[ 601- 700]: loss = 0.417984 * 100, metric = 7.71% * 100;
 Minibatch[ 701- 800]: loss = 0.409164 * 100, metric = 7.38% * 100;
 Minibatch[ 801- 900]: loss = 0.420529 * 100, metric = 7.67% * 100;
 Minibatch[ 901-1000]: loss = 0.432043 * 100, metric = 8.04% * 100;
 Minibatch[1001-1100]: loss = 0.427676 * 100, metric = 8.05% * 100;
 Minibatch[1101-1200]: loss = 0.433455 * 100, metric = 7.98% * 100;
 Minibatch[1201-1300]: loss = 0.428893 * 100, metric = 8.11% * 100;
 Minibatch[1301-1400]: loss = 0.427322 * 100, metric = 7.99% * 100;
 Minibatch[1401-1500]: loss = 0.420258 * 100, metric = 7.54% * 100;
 Minibatch[1501-1600]: loss = 0.424799 * 100, metric = 7.97% * 100;
 Minibatch[1601-1700]: loss = 0.420689 * 100, metric = 7.77% * 100;
 Minibatch[1701-1800]: loss = 0.429625 * 100, metric = 7.84% * 100;
 Minibatch[1801-1900]: loss = 0.435865 * 100, metric = 8.30% * 100;
 Minibatch[1901-2000]: loss = 0.423492 * 100, metric = 7.89% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.427218 * 2000, metric = 7.96% * 2000 894.305s (  2.2 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 14.50% * 2000;
 Minibatch[   1- 100]: loss = 0.408809 * 100, metric = 7.37% * 100;
 Minibatch[ 101- 200]: loss = 0.422832 * 100, metric = 7.91% * 100;
 Minibatch[ 201- 300]: loss = 0.433786 * 100, metric = 8.17% * 100;
 Minibatch[ 301- 400]: loss = 0.424517 * 100, metric = 7.89% * 100;
 Minibatch[ 401- 500]: loss = 0.420181 * 100, metric = 7.81% * 100;
 Minibatch[ 501- 600]: loss = 0.429070 * 100, metric = 7.90% * 100;
 Minibatch[ 601- 700]: loss = 0.411928 * 100, metric = 7.54% * 100;
 Minibatch[ 701- 800]: loss = 0.420097 * 100, metric = 7.92% * 100;
 Minibatch[ 801- 900]: loss = 0.420816 * 100, metric = 7.86% * 100;
 Minibatch[ 901-1000]: loss = 0.424283 * 100, metric = 7.89% * 100;
 Minibatch[1001-1100]: loss = 0.415497 * 100, metric = 7.66% * 100;
 Minibatch[1101-1200]: loss = 0.427068 * 100, metric = 8.01% * 100;
 Minibatch[1201-1300]: loss = 0.421001 * 100, metric = 7.97% * 100;
 Minibatch[1301-1400]: loss = 0.403760 * 100, metric = 7.51% * 100;
 Minibatch[1401-1500]: loss = 0.421036 * 100, metric = 8.02% * 100;
 Minibatch[1501-1600]: loss = 0.407181 * 100, metric = 7.49% * 100;
 Minibatch[1601-1700]: loss = 0.418658 * 100, metric = 7.74% * 100;
 Minibatch[1701-1800]: loss = 0.430661 * 100, metric = 8.15% * 100;
 Minibatch[1801-1900]: loss = 0.423641 * 100, metric = 8.00% * 100;
 Minibatch[1901-2000]: loss = 0.413522 * 100, metric = 7.96% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.419917 * 2000, metric = 7.84% * 2000 907.162s (  2.2 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 14.85% * 2000;
 Minibatch[   1- 100]: loss = 0.407299 * 100, metric = 7.69% * 100;
 Minibatch[ 101- 200]: loss = 0.412601 * 100, metric = 7.62% * 100;
 Minibatch[ 201- 300]: loss = 0.412866 * 100, metric = 7.62% * 100;
 Minibatch[ 301- 400]: loss = 0.439226 * 100, metric = 8.37% * 100;
 Minibatch[ 401- 500]: loss = 0.410328 * 100, metric = 7.51% * 100;
 Minibatch[ 501- 600]: loss = 0.406091 * 100, metric = 7.35% * 100;
 Minibatch[ 601- 700]: loss = 0.409785 * 100, metric = 7.56% * 100;
 Minibatch[ 701- 800]: loss = 0.412419 * 100, metric = 7.73% * 100;
 Minibatch[ 801- 900]: loss = 0.411119 * 100, metric = 7.54% * 100;
 Minibatch[ 901-1000]: loss = 0.418681 * 100, metric = 8.04% * 100;
 Minibatch[1001-1100]: loss = 0.418775 * 100, metric = 8.04% * 100;
 Minibatch[1101-1200]: loss = 0.418525 * 100, metric = 7.89% * 100;
 Minibatch[1201-1300]: loss = 0.420506 * 100, metric = 8.10% * 100;
 Minibatch[1301-1400]: loss = 0.410295 * 100, metric = 7.33% * 100;
 Minibatch[1401-1500]: loss = 0.421607 * 100, metric = 7.88% * 100;
 Minibatch[1501-1600]: loss = 0.395015 * 100, metric = 7.32% * 100;
 Minibatch[1601-1700]: loss = 0.416429 * 100, metric = 7.78% * 100;
 Minibatch[1701-1800]: loss = 0.401783 * 100, metric = 7.26% * 100;
 Minibatch[1801-1900]: loss = 0.413853 * 100, metric = 7.76% * 100;
 Minibatch[1901-2000]: loss = 0.422065 * 100, metric = 8.09% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.413963 * 2000, metric = 7.72% * 2000 892.932s (  2.2 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 15.04% * 2000;
 Minibatch[   1- 100]: loss = 0.420288 * 100, metric = 7.84% * 100;
 Minibatch[ 101- 200]: loss = 0.418159 * 100, metric = 8.02% * 100;
 Minibatch[ 201- 300]: loss = 0.403679 * 100, metric = 7.40% * 100;
 Minibatch[ 301- 400]: loss = 0.410358 * 100, metric = 7.67% * 100;
 Minibatch[ 401- 500]: loss = 0.412832 * 100, metric = 8.03% * 100;
 Minibatch[ 501- 600]: loss = 0.419230 * 100, metric = 8.02% * 100;
 Minibatch[ 601- 700]: loss = 0.401704 * 100, metric = 7.32% * 100;
 Minibatch[ 701- 800]: loss = 0.399973 * 100, metric = 7.48% * 100;
 Minibatch[ 801- 900]: loss = 0.402699 * 100, metric = 7.39% * 100;
 Minibatch[ 901-1000]: loss = 0.411977 * 100, metric = 7.57% * 100;
 Minibatch[1001-1100]: loss = 0.412651 * 100, metric = 7.70% * 100;
 Minibatch[1101-1200]: loss = 0.399314 * 100, metric = 7.18% * 100;
 Minibatch[1201-1300]: loss = 0.406668 * 100, metric = 7.65% * 100;
 Minibatch[1301-1400]: loss = 0.394162 * 100, metric = 7.23% * 100;
 Minibatch[1401-1500]: loss = 0.398984 * 100, metric = 7.40% * 100;
 Minibatch[1501-1600]: loss = 0.397814 * 100, metric = 7.25% * 100;
 Minibatch[1601-1700]: loss = 0.385670 * 100, metric = 7.03% * 100;
 Minibatch[1701-1800]: loss = 0.398560 * 100, metric = 7.27% * 100;
 Minibatch[1801-1900]: loss = 0.393916 * 100, metric = 7.29% * 100;
 Minibatch[1901-2000]: loss = 0.410054 * 100, metric = 7.50% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.404935 * 2000, metric = 7.51% * 2000 896.905s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 16.88% * 2000;
 Minibatch[   1- 100]: loss = 0.401325 * 100, metric = 7.40% * 100;
 Minibatch[ 101- 200]: loss = 0.388026 * 100, metric = 7.21% * 100;
 Minibatch[ 201- 300]: loss = 0.405302 * 100, metric = 7.63% * 100;
 Minibatch[ 301- 400]: loss = 0.404019 * 100, metric = 7.54% * 100;
 Minibatch[ 401- 500]: loss = 0.399756 * 100, metric = 7.52% * 100;
 Minibatch[ 501- 600]: loss = 0.394414 * 100, metric = 7.23% * 100;
 Minibatch[ 601- 700]: loss = 0.405460 * 100, metric = 7.67% * 100;
 Minibatch[ 701- 800]: loss = 0.427052 * 100, metric = 8.10% * 100;
 Minibatch[ 801- 900]: loss = 0.414518 * 100, metric = 8.06% * 100;
 Minibatch[ 901-1000]: loss = 0.416529 * 100, metric = 7.88% * 100;
 Minibatch[1001-1100]: loss = 0.407004 * 100, metric = 7.50% * 100;
 Minibatch[1101-1200]: loss = 0.404441 * 100, metric = 7.47% * 100;
 Minibatch[1201-1300]: loss = 0.384253 * 100, metric = 6.98% * 100;
 Minibatch[1301-1400]: loss = 0.417218 * 100, metric = 7.90% * 100;
 Minibatch[1401-1500]: loss = 0.410809 * 100, metric = 7.73% * 100;
 Minibatch[1501-1600]: loss = 0.398477 * 100, metric = 7.60% * 100;
 Minibatch[1601-1700]: loss = 0.408504 * 100, metric = 7.58% * 100;
 Minibatch[1701-1800]: loss = 0.402734 * 100, metric = 7.25% * 100;
 Minibatch[1801-1900]: loss = 0.407148 * 100, metric = 7.58% * 100;
 Minibatch[1901-2000]: loss = 0.409898 * 100, metric = 7.66% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.405344 * 2000, metric = 7.58% * 2000 900.263s (  2.2 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 16.56% * 2000;
 Minibatch[   1- 100]: loss = 0.400324 * 100, metric = 7.41% * 100;
 Minibatch[ 101- 200]: loss = 0.412728 * 100, metric = 7.74% * 100;
 Minibatch[ 201- 300]: loss = 0.408404 * 100, metric = 7.62% * 100;
 Minibatch[ 301- 400]: loss = 0.395975 * 100, metric = 7.41% * 100;
 Minibatch[ 401- 500]: loss = 0.408390 * 100, metric = 7.71% * 100;
 Minibatch[ 501- 600]: loss = 0.391474 * 100, metric = 7.29% * 100;
 Minibatch[ 601- 700]: loss = 0.387029 * 100, metric = 7.23% * 100;
 Minibatch[ 701- 800]: loss = 0.408451 * 100, metric = 7.47% * 100;
 Minibatch[ 801- 900]: loss = 0.416315 * 100, metric = 8.01% * 100;
 Minibatch[ 901-1000]: loss = 0.400186 * 100, metric = 7.38% * 100;
 Minibatch[1001-1100]: loss = 0.400905 * 100, metric = 7.33% * 100;
 Minibatch[1101-1200]: loss = 0.401494 * 100, metric = 7.67% * 100;
 Minibatch[1201-1300]: loss = 0.384926 * 100, metric = 6.86% * 100;
 Minibatch[1301-1400]: loss = 0.410696 * 100, metric = 7.79% * 100;
 Minibatch[1401-1500]: loss = 0.374741 * 100, metric = 6.67% * 100;
 Minibatch[1501-1600]: loss = 0.382280 * 100, metric = 7.16% * 100;
 Minibatch[1601-1700]: loss = 0.389211 * 100, metric = 7.17% * 100;
 Minibatch[1701-1800]: loss = 0.373391 * 100, metric = 6.70% * 100;
 Minibatch[1801-1900]: loss = 0.386619 * 100, metric = 7.18% * 100;
 Minibatch[1901-2000]: loss = 0.387780 * 100, metric = 7.16% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.396066 * 2000, metric = 7.35% * 2000 897.753s (  2.2 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 14.11% * 2000;
0.532905260372907
 Minibatch[   1- 100]: loss = 0.399220 * 100, metric = 7.49% * 100;
 Minibatch[ 101- 200]: loss = 0.388373 * 100, metric = 6.93% * 100;
 Minibatch[ 201- 300]: loss = 0.387776 * 100, metric = 7.05% * 100;
 Minibatch[ 301- 400]: loss = 0.388640 * 100, metric = 7.16% * 100;
 Minibatch[ 401- 500]: loss = 0.376766 * 100, metric = 6.80% * 100;
 Minibatch[ 501- 600]: loss = 0.385038 * 100, metric = 7.10% * 100;
 Minibatch[ 601- 700]: loss = 0.388926 * 100, metric = 7.20% * 100;
 Minibatch[ 701- 800]: loss = 0.378250 * 100, metric = 6.81% * 100;
 Minibatch[ 801- 900]: loss = 0.373808 * 100, metric = 6.77% * 100;
 Minibatch[ 901-1000]: loss = 0.388972 * 100, metric = 7.29% * 100;
 Minibatch[1001-1100]: loss = 0.378143 * 100, metric = 7.02% * 100;
 Minibatch[1101-1200]: loss = 0.372842 * 100, metric = 6.74% * 100;
 Minibatch[1201-1300]: loss = 0.367462 * 100, metric = 6.59% * 100;
 Minibatch[1301-1400]: loss = 0.378879 * 100, metric = 6.98% * 100;
 Minibatch[1401-1500]: loss = 0.379988 * 100, metric = 6.91% * 100;
 Minibatch[1501-1600]: loss = 0.378116 * 100, metric = 7.01% * 100;
 Minibatch[1601-1700]: loss = 0.382420 * 100, metric = 7.15% * 100;
 Minibatch[1701-1800]: loss = 0.385760 * 100, metric = 7.02% * 100;
 Minibatch[1801-1900]: loss = 0.386322 * 100, metric = 7.10% * 100;
 Minibatch[1901-2000]: loss = 0.370453 * 100, metric = 6.70% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.381808 * 2000, metric = 6.99% * 2000 915.412s (  2.2 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.72% * 2000;
 Minibatch[   1- 100]: loss = 0.367053 * 100, metric = 6.63% * 100;
 Minibatch[ 101- 200]: loss = 0.387706 * 100, metric = 7.28% * 100;
 Minibatch[ 201- 300]: loss = 0.382918 * 100, metric = 6.81% * 100;
 Minibatch[ 301- 400]: loss = 0.372507 * 100, metric = 6.73% * 100;
 Minibatch[ 401- 500]: loss = 0.384721 * 100, metric = 6.87% * 100;
 Minibatch[ 501- 600]: loss = 0.370176 * 100, metric = 6.57% * 100;
 Minibatch[ 601- 700]: loss = 0.361092 * 100, metric = 6.50% * 100;
 Minibatch[ 701- 800]: loss = 0.380632 * 100, metric = 6.76% * 100;
 Minibatch[ 801- 900]: loss = 0.375254 * 100, metric = 6.82% * 100;
 Minibatch[ 901-1000]: loss = 0.372830 * 100, metric = 6.72% * 100;
 Minibatch[1001-1100]: loss = 0.368617 * 100, metric = 6.65% * 100;
 Minibatch[1101-1200]: loss = 0.388125 * 100, metric = 7.35% * 100;
 Minibatch[1201-1300]: loss = 0.377694 * 100, metric = 6.76% * 100;
 Minibatch[1301-1400]: loss = 0.360151 * 100, metric = 6.54% * 100;
 Minibatch[1401-1500]: loss = 0.379300 * 100, metric = 7.07% * 100;
 Minibatch[1501-1600]: loss = 0.375287 * 100, metric = 6.81% * 100;
 Minibatch[1601-1700]: loss = 0.384532 * 100, metric = 6.85% * 100;
 Minibatch[1701-1800]: loss = 0.370612 * 100, metric = 7.00% * 100;
 Minibatch[1801-1900]: loss = 0.383251 * 100, metric = 7.20% * 100;
 Minibatch[1901-2000]: loss = 0.393760 * 100, metric = 7.38% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.376811 * 2000, metric = 6.86% * 2000 904.088s (  2.2 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.53% * 2000;
 Minibatch[   1- 100]: loss = 0.364191 * 100, metric = 6.41% * 100;
 Minibatch[ 101- 200]: loss = 0.385860 * 100, metric = 7.04% * 100;
 Minibatch[ 201- 300]: loss = 0.363658 * 100, metric = 6.64% * 100;
 Minibatch[ 301- 400]: loss = 0.368139 * 100, metric = 6.66% * 100;
 Minibatch[ 401- 500]: loss = 0.356017 * 100, metric = 6.48% * 100;
 Minibatch[ 501- 600]: loss = 0.361349 * 100, metric = 6.55% * 100;
 Minibatch[ 601- 700]: loss = 0.369162 * 100, metric = 6.67% * 100;
 Minibatch[ 701- 800]: loss = 0.355132 * 100, metric = 6.27% * 100;
 Minibatch[ 801- 900]: loss = 0.372008 * 100, metric = 6.71% * 100;
 Minibatch[ 901-1000]: loss = 0.370970 * 100, metric = 6.79% * 100;
 Minibatch[1001-1100]: loss = 0.384189 * 100, metric = 7.25% * 100;
 Minibatch[1101-1200]: loss = 0.378473 * 100, metric = 7.01% * 100;
 Minibatch[1201-1300]: loss = 0.383837 * 100, metric = 7.20% * 100;
 Minibatch[1301-1400]: loss = 0.381418 * 100, metric = 7.05% * 100;
 Minibatch[1401-1500]: loss = 0.356601 * 100, metric = 6.48% * 100;
 Minibatch[1501-1600]: loss = 0.373909 * 100, metric = 6.98% * 100;
 Minibatch[1601-1700]: loss = 0.354999 * 100, metric = 6.29% * 100;
 Minibatch[1701-1800]: loss = 0.368301 * 100, metric = 6.78% * 100;
 Minibatch[1801-1900]: loss = 0.366102 * 100, metric = 6.65% * 100;
 Minibatch[1901-2000]: loss = 0.354905 * 100, metric = 6.19% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.368461 * 2000, metric = 6.71% * 2000 888.642s (  2.3 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.25% * 2000;
 Minibatch[   1- 100]: loss = 0.370518 * 100, metric = 6.95% * 100;
 Minibatch[ 101- 200]: loss = 0.376841 * 100, metric = 6.82% * 100;
 Minibatch[ 201- 300]: loss = 0.353445 * 100, metric = 6.08% * 100;
 Minibatch[ 301- 400]: loss = 0.371146 * 100, metric = 6.61% * 100;
 Minibatch[ 401- 500]: loss = 0.368245 * 100, metric = 6.55% * 100;
 Minibatch[ 501- 600]: loss = 0.356116 * 100, metric = 6.13% * 100;
 Minibatch[ 601- 700]: loss = 0.371731 * 100, metric = 6.63% * 100;
 Minibatch[ 701- 800]: loss = 0.358560 * 100, metric = 6.55% * 100;
 Minibatch[ 801- 900]: loss = 0.382405 * 100, metric = 7.08% * 100;
 Minibatch[ 901-1000]: loss = 0.359424 * 100, metric = 6.44% * 100;
 Minibatch[1001-1100]: loss = 0.373789 * 100, metric = 6.67% * 100;
 Minibatch[1101-1200]: loss = 0.373712 * 100, metric = 6.88% * 100;
 Minibatch[1201-1300]: loss = 0.361412 * 100, metric = 6.51% * 100;
 Minibatch[1301-1400]: loss = 0.354409 * 100, metric = 6.47% * 100;
 Minibatch[1401-1500]: loss = 0.370930 * 100, metric = 6.81% * 100;
 Minibatch[1501-1600]: loss = 0.373921 * 100, metric = 6.93% * 100;
 Minibatch[1601-1700]: loss = 0.356909 * 100, metric = 6.52% * 100;
 Minibatch[1701-1800]: loss = 0.359827 * 100, metric = 6.59% * 100;
 Minibatch[1801-1900]: loss = 0.357933 * 100, metric = 6.50% * 100;
 Minibatch[1901-2000]: loss = 0.353982 * 100, metric = 6.36% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.365263 * 2000, metric = 6.60% * 2000 900.500s (  2.2 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 15.00% * 2000;
 Minibatch[   1- 100]: loss = 0.361766 * 100, metric = 6.41% * 100;
 Minibatch[ 101- 200]: loss = 0.357503 * 100, metric = 6.35% * 100;
 Minibatch[ 201- 300]: loss = 0.358438 * 100, metric = 6.22% * 100;
 Minibatch[ 301- 400]: loss = 0.372945 * 100, metric = 6.61% * 100;
 Minibatch[ 401- 500]: loss = 0.368921 * 100, metric = 6.68% * 100;
 Minibatch[ 501- 600]: loss = 0.361980 * 100, metric = 6.73% * 100;
 Minibatch[ 601- 700]: loss = 0.371410 * 100, metric = 6.94% * 100;
 Minibatch[ 701- 800]: loss = 0.358745 * 100, metric = 6.60% * 100;
 Minibatch[ 801- 900]: loss = 0.373407 * 100, metric = 6.85% * 100;
 Minibatch[ 901-1000]: loss = 0.370936 * 100, metric = 6.89% * 100;
 Minibatch[1001-1100]: loss = 0.356105 * 100, metric = 6.41% * 100;
 Minibatch[1101-1200]: loss = 0.369961 * 100, metric = 6.72% * 100;
 Minibatch[1201-1300]: loss = 0.367006 * 100, metric = 6.60% * 100;
 Minibatch[1301-1400]: loss = 0.366733 * 100, metric = 6.70% * 100;
 Minibatch[1401-1500]: loss = 0.362863 * 100, metric = 6.58% * 100;
 Minibatch[1501-1600]: loss = 0.377820 * 100, metric = 7.06% * 100;
 Minibatch[1601-1700]: loss = 0.367355 * 100, metric = 6.71% * 100;
 Minibatch[1701-1800]: loss = 0.376311 * 100, metric = 7.11% * 100;
 Minibatch[1801-1900]: loss = 0.365375 * 100, metric = 6.79% * 100;
 Minibatch[1901-2000]: loss = 0.363346 * 100, metric = 6.72% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.366446 * 2000, metric = 6.68% * 2000 902.458s (  2.2 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 14.57% * 2000;
 Minibatch[   1- 100]: loss = 0.369168 * 100, metric = 6.79% * 100;
 Minibatch[ 101- 200]: loss = 0.360535 * 100, metric = 6.42% * 100;
 Minibatch[ 201- 300]: loss = 0.351728 * 100, metric = 6.40% * 100;
 Minibatch[ 301- 400]: loss = 0.364941 * 100, metric = 6.72% * 100;
 Minibatch[ 401- 500]: loss = 0.351508 * 100, metric = 6.23% * 100;
 Minibatch[ 501- 600]: loss = 0.347187 * 100, metric = 6.24% * 100;
 Minibatch[ 601- 700]: loss = 0.353810 * 100, metric = 6.42% * 100;
 Minibatch[ 701- 800]: loss = 0.334040 * 100, metric = 5.86% * 100;
 Minibatch[ 801- 900]: loss = 0.358221 * 100, metric = 6.43% * 100;
 Minibatch[ 901-1000]: loss = 0.348245 * 100, metric = 6.31% * 100;
 Minibatch[1001-1100]: loss = 0.347568 * 100, metric = 6.09% * 100;
 Minibatch[1101-1200]: loss = 0.341473 * 100, metric = 6.07% * 100;
 Minibatch[1201-1300]: loss = 0.359377 * 100, metric = 6.40% * 100;
 Minibatch[1301-1400]: loss = 0.345602 * 100, metric = 6.11% * 100;
 Minibatch[1401-1500]: loss = 0.358157 * 100, metric = 6.51% * 100;
 Minibatch[1501-1600]: loss = 0.362878 * 100, metric = 6.69% * 100;
 Minibatch[1601-1700]: loss = 0.350682 * 100, metric = 6.30% * 100;
 Minibatch[1701-1800]: loss = 0.363025 * 100, metric = 6.54% * 100;
 Minibatch[1801-1900]: loss = 0.375012 * 100, metric = 6.90% * 100;
 Minibatch[1901-2000]: loss = 0.349190 * 100, metric = 6.22% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.354617 * 2000, metric = 6.38% * 2000 886.249s (  2.3 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 14.28% * 2000;
 Minibatch[   1- 100]: loss = 0.365942 * 100, metric = 6.62% * 100;
 Minibatch[ 101- 200]: loss = 0.357868 * 100, metric = 6.50% * 100;
 Minibatch[ 201- 300]: loss = 0.363300 * 100, metric = 6.49% * 100;
 Minibatch[ 301- 400]: loss = 0.354713 * 100, metric = 6.44% * 100;
 Minibatch[ 401- 500]: loss = 0.353714 * 100, metric = 6.30% * 100;
 Minibatch[ 501- 600]: loss = 0.371088 * 100, metric = 6.82% * 100;
 Minibatch[ 601- 700]: loss = 0.349418 * 100, metric = 6.36% * 100;
 Minibatch[ 701- 800]: loss = 0.358155 * 100, metric = 6.56% * 100;
 Minibatch[ 801- 900]: loss = 0.357201 * 100, metric = 6.40% * 100;
 Minibatch[ 901-1000]: loss = 0.360674 * 100, metric = 6.33% * 100;
 Minibatch[1001-1100]: loss = 0.343356 * 100, metric = 5.89% * 100;
 Minibatch[1101-1200]: loss = 0.329265 * 100, metric = 5.59% * 100;
 Minibatch[1201-1300]: loss = 0.345858 * 100, metric = 6.23% * 100;
 Minibatch[1301-1400]: loss = 0.348849 * 100, metric = 6.20% * 100;
 Minibatch[1401-1500]: loss = 0.340854 * 100, metric = 6.02% * 100;
 Minibatch[1501-1600]: loss = 0.334371 * 100, metric = 5.71% * 100;
 Minibatch[1601-1700]: loss = 0.343263 * 100, metric = 6.17% * 100;
 Minibatch[1701-1800]: loss = 0.341443 * 100, metric = 5.89% * 100;
 Minibatch[1801-1900]: loss = 0.344936 * 100, metric = 6.22% * 100;
 Minibatch[1901-2000]: loss = 0.346377 * 100, metric = 6.16% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.350532 * 2000, metric = 6.24% * 2000 898.321s (  2.2 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 16.78% * 2000;
 Minibatch[   1- 100]: loss = 0.358632 * 100, metric = 6.34% * 100;
 Minibatch[ 101- 200]: loss = 0.357794 * 100, metric = 6.54% * 100;
 Minibatch[ 201- 300]: loss = 0.356046 * 100, metric = 6.50% * 100;
 Minibatch[ 301- 400]: loss = 0.352106 * 100, metric = 6.36% * 100;
 Minibatch[ 401- 500]: loss = 0.356075 * 100, metric = 6.47% * 100;
 Minibatch[ 501- 600]: loss = 0.346997 * 100, metric = 6.20% * 100;
 Minibatch[ 601- 700]: loss = 0.344532 * 100, metric = 6.16% * 100;
 Minibatch[ 701- 800]: loss = 0.335385 * 100, metric = 5.78% * 100;
 Minibatch[ 801- 900]: loss = 0.340772 * 100, metric = 6.13% * 100;
 Minibatch[ 901-1000]: loss = 0.359424 * 100, metric = 6.48% * 100;
 Minibatch[1001-1100]: loss = 0.349964 * 100, metric = 6.15% * 100;
 Minibatch[1101-1200]: loss = 0.349277 * 100, metric = 6.32% * 100;
 Minibatch[1201-1300]: loss = 0.349285 * 100, metric = 6.15% * 100;
 Minibatch[1301-1400]: loss = 0.359185 * 100, metric = 6.38% * 100;
 Minibatch[1401-1500]: loss = 0.345119 * 100, metric = 6.14% * 100;
 Minibatch[1501-1600]: loss = 0.348561 * 100, metric = 6.11% * 100;
 Minibatch[1601-1700]: loss = 0.347505 * 100, metric = 6.28% * 100;
 Minibatch[1701-1800]: loss = 0.347518 * 100, metric = 6.28% * 100;
 Minibatch[1801-1900]: loss = 0.352549 * 100, metric = 6.59% * 100;
 Minibatch[1901-2000]: loss = 0.356617 * 100, metric = 6.42% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.350667 * 2000, metric = 6.29% * 2000 898.801s (  2.2 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 16.06% * 2000;
 Minibatch[   1- 100]: loss = 0.335661 * 100, metric = 6.20% * 100;
 Minibatch[ 101- 200]: loss = 0.350293 * 100, metric = 6.30% * 100;
 Minibatch[ 201- 300]: loss = 0.341723 * 100, metric = 6.16% * 100;
 Minibatch[ 301- 400]: loss = 0.342329 * 100, metric = 6.09% * 100;
 Minibatch[ 401- 500]: loss = 0.347184 * 100, metric = 6.18% * 100;
 Minibatch[ 501- 600]: loss = 0.336935 * 100, metric = 6.14% * 100;
 Minibatch[ 601- 700]: loss = 0.355683 * 100, metric = 6.34% * 100;
 Minibatch[ 701- 800]: loss = 0.337406 * 100, metric = 6.02% * 100;
 Minibatch[ 801- 900]: loss = 0.355889 * 100, metric = 6.43% * 100;
 Minibatch[ 901-1000]: loss = 0.343932 * 100, metric = 6.26% * 100;
 Minibatch[1001-1100]: loss = 0.346263 * 100, metric = 6.22% * 100;
 Minibatch[1101-1200]: loss = 0.352723 * 100, metric = 6.37% * 100;
 Minibatch[1201-1300]: loss = 0.348789 * 100, metric = 6.37% * 100;
 Minibatch[1301-1400]: loss = 0.342299 * 100, metric = 6.11% * 100;
 Minibatch[1401-1500]: loss = 0.343843 * 100, metric = 6.20% * 100;
 Minibatch[1501-1600]: loss = 0.340804 * 100, metric = 6.07% * 100;
 Minibatch[1601-1700]: loss = 0.334658 * 100, metric = 5.92% * 100;
 Minibatch[1701-1800]: loss = 0.339699 * 100, metric = 6.19% * 100;
 Minibatch[1801-1900]: loss = 0.348353 * 100, metric = 6.29% * 100;
 Minibatch[1901-2000]: loss = 0.350117 * 100, metric = 6.27% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.344729 * 2000, metric = 6.21% * 2000 893.104s (  2.2 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 15.20% * 2000;
 Minibatch[   1- 100]: loss = 0.344283 * 100, metric = 6.13% * 100;
 Minibatch[ 101- 200]: loss = 0.341267 * 100, metric = 6.20% * 100;
 Minibatch[ 201- 300]: loss = 0.338838 * 100, metric = 6.28% * 100;
 Minibatch[ 301- 400]: loss = 0.347347 * 100, metric = 6.18% * 100;
 Minibatch[ 401- 500]: loss = 0.343015 * 100, metric = 6.29% * 100;
 Minibatch[ 501- 600]: loss = 0.346902 * 100, metric = 6.45% * 100;
 Minibatch[ 601- 700]: loss = 0.341152 * 100, metric = 5.99% * 100;
 Minibatch[ 701- 800]: loss = 0.334428 * 100, metric = 5.90% * 100;
 Minibatch[ 801- 900]: loss = 0.338977 * 100, metric = 6.12% * 100;
 Minibatch[ 901-1000]: loss = 0.344064 * 100, metric = 6.33% * 100;
 Minibatch[1001-1100]: loss = 0.342883 * 100, metric = 6.32% * 100;
 Minibatch[1101-1200]: loss = 0.348553 * 100, metric = 6.31% * 100;
 Minibatch[1201-1300]: loss = 0.362722 * 100, metric = 6.73% * 100;
 Minibatch[1301-1400]: loss = 0.344429 * 100, metric = 6.15% * 100;
 Minibatch[1401-1500]: loss = 0.340938 * 100, metric = 6.09% * 100;
 Minibatch[1501-1600]: loss = 0.349426 * 100, metric = 6.45% * 100;
 Minibatch[1601-1700]: loss = 0.340756 * 100, metric = 6.26% * 100;
 Minibatch[1701-1800]: loss = 0.338605 * 100, metric = 6.04% * 100;
 Minibatch[1801-1900]: loss = 0.331352 * 100, metric = 5.83% * 100;
 Minibatch[1901-2000]: loss = 0.331827 * 100, metric = 5.90% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.342588 * 2000, metric = 6.20% * 2000 899.841s (  2.2 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.62% * 2000;
 Minibatch[   1- 100]: loss = 0.335852 * 100, metric = 5.98% * 100;
 Minibatch[ 101- 200]: loss = 0.321059 * 100, metric = 5.54% * 100;
 Minibatch[ 201- 300]: loss = 0.340366 * 100, metric = 6.19% * 100;
 Minibatch[ 301- 400]: loss = 0.331836 * 100, metric = 5.99% * 100;
 Minibatch[ 401- 500]: loss = 0.334721 * 100, metric = 5.99% * 100;
 Minibatch[ 501- 600]: loss = 0.326672 * 100, metric = 5.74% * 100;
 Minibatch[ 601- 700]: loss = 0.343282 * 100, metric = 6.17% * 100;
 Minibatch[ 701- 800]: loss = 0.331549 * 100, metric = 6.15% * 100;
 Minibatch[ 801- 900]: loss = 0.321849 * 100, metric = 5.77% * 100;
 Minibatch[ 901-1000]: loss = 0.323811 * 100, metric = 5.85% * 100;
 Minibatch[1001-1100]: loss = 0.342261 * 100, metric = 6.43% * 100;
 Minibatch[1101-1200]: loss = 0.343807 * 100, metric = 6.27% * 100;
 Minibatch[1201-1300]: loss = 0.324638 * 100, metric = 5.77% * 100;
 Minibatch[1301-1400]: loss = 0.326638 * 100, metric = 5.79% * 100;
 Minibatch[1401-1500]: loss = 0.336145 * 100, metric = 5.89% * 100;
 Minibatch[1501-1600]: loss = 0.327462 * 100, metric = 5.67% * 100;
 Minibatch[1601-1700]: loss = 0.355093 * 100, metric = 6.36% * 100;
 Minibatch[1701-1800]: loss = 0.346672 * 100, metric = 6.34% * 100;
 Minibatch[1801-1900]: loss = 0.333062 * 100, metric = 5.99% * 100;
 Minibatch[1901-2000]: loss = 0.340845 * 100, metric = 6.11% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.334381 * 2000, metric = 6.00% * 2000 895.200s (  2.2 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.70% * 2000;
 Minibatch[   1- 100]: loss = 0.331870 * 100, metric = 5.95% * 100;
 Minibatch[ 101- 200]: loss = 0.342817 * 100, metric = 6.15% * 100;
 Minibatch[ 201- 300]: loss = 0.335897 * 100, metric = 6.22% * 100;
 Minibatch[ 301- 400]: loss = 0.325404 * 100, metric = 5.71% * 100;
 Minibatch[ 401- 500]: loss = 0.328940 * 100, metric = 5.84% * 100;
 Minibatch[ 501- 600]: loss = 0.323066 * 100, metric = 5.84% * 100;
 Minibatch[ 601- 700]: loss = 0.321266 * 100, metric = 5.56% * 100;
 Minibatch[ 701- 800]: loss = 0.324856 * 100, metric = 5.67% * 100;
 Minibatch[ 801- 900]: loss = 0.339001 * 100, metric = 5.99% * 100;
 Minibatch[ 901-1000]: loss = 0.334414 * 100, metric = 6.18% * 100;
 Minibatch[1001-1100]: loss = 0.322244 * 100, metric = 5.37% * 100;
 Minibatch[1101-1200]: loss = 0.331945 * 100, metric = 5.81% * 100;
 Minibatch[1201-1300]: loss = 0.327452 * 100, metric = 5.74% * 100;
 Minibatch[1301-1400]: loss = 0.334947 * 100, metric = 6.10% * 100;
 Minibatch[1401-1500]: loss = 0.330291 * 100, metric = 5.96% * 100;
 Minibatch[1501-1600]: loss = 0.324934 * 100, metric = 5.74% * 100;
 Minibatch[1601-1700]: loss = 0.311049 * 100, metric = 5.28% * 100;
 Minibatch[1701-1800]: loss = 0.318737 * 100, metric = 5.60% * 100;
 Minibatch[1801-1900]: loss = 0.325604 * 100, metric = 5.69% * 100;
 Minibatch[1901-2000]: loss = 0.321874 * 100, metric = 5.63% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.327830 * 2000, metric = 5.80% * 2000 889.608s (  2.2 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.96% * 2000;
 Minibatch[   1- 100]: loss = 0.323584 * 100, metric = 5.63% * 100;
 Minibatch[ 101- 200]: loss = 0.322173 * 100, metric = 5.54% * 100;
 Minibatch[ 201- 300]: loss = 0.330037 * 100, metric = 6.05% * 100;
 Minibatch[ 301- 400]: loss = 0.330995 * 100, metric = 5.84% * 100;
 Minibatch[ 401- 500]: loss = 0.332626 * 100, metric = 5.95% * 100;
 Minibatch[ 501- 600]: loss = 0.337157 * 100, metric = 6.06% * 100;
 Minibatch[ 601- 700]: loss = 0.327079 * 100, metric = 5.61% * 100;
 Minibatch[ 701- 800]: loss = 0.319637 * 100, metric = 5.53% * 100;
 Minibatch[ 801- 900]: loss = 0.343039 * 100, metric = 6.12% * 100;
 Minibatch[ 901-1000]: loss = 0.336992 * 100, metric = 6.09% * 100;
 Minibatch[1001-1100]: loss = 0.331490 * 100, metric = 5.77% * 100;
 Minibatch[1101-1200]: loss = 0.318966 * 100, metric = 5.61% * 100;
 Minibatch[1201-1300]: loss = 0.337673 * 100, metric = 6.20% * 100;
 Minibatch[1301-1400]: loss = 0.328728 * 100, metric = 5.97% * 100;
 Minibatch[1401-1500]: loss = 0.340691 * 100, metric = 6.04% * 100;
 Minibatch[1501-1600]: loss = 0.326877 * 100, metric = 5.74% * 100;
 Minibatch[1601-1700]: loss = 0.335488 * 100, metric = 5.67% * 100;
 Minibatch[1701-1800]: loss = 0.330071 * 100, metric = 5.59% * 100;
 Minibatch[1801-1900]: loss = 0.329668 * 100, metric = 5.96% * 100;
 Minibatch[1901-2000]: loss = 0.327122 * 100, metric = 5.70% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.330505 * 2000, metric = 5.83% * 2000 894.271s (  2.2 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 14.18% * 2000;
 Minibatch[   1- 100]: loss = 0.320529 * 100, metric = 5.63% * 100;
 Minibatch[ 101- 200]: loss = 0.328602 * 100, metric = 5.94% * 100;
 Minibatch[ 201- 300]: loss = 0.328840 * 100, metric = 6.05% * 100;
 Minibatch[ 301- 400]: loss = 0.357944 * 100, metric = 6.54% * 100;
 Minibatch[ 401- 500]: loss = 0.326978 * 100, metric = 5.70% * 100;
 Minibatch[ 501- 600]: loss = 0.334104 * 100, metric = 6.02% * 100;
 Minibatch[ 601- 700]: loss = 0.322311 * 100, metric = 5.86% * 100;
 Minibatch[ 701- 800]: loss = 0.330926 * 100, metric = 5.90% * 100;
 Minibatch[ 801- 900]: loss = 0.319548 * 100, metric = 5.74% * 100;
 Minibatch[ 901-1000]: loss = 0.329054 * 100, metric = 5.71% * 100;
 Minibatch[1001-1100]: loss = 0.321525 * 100, metric = 5.71% * 100;
 Minibatch[1101-1200]: loss = 0.315774 * 100, metric = 5.50% * 100;
 Minibatch[1201-1300]: loss = 0.326069 * 100, metric = 5.70% * 100;
 Minibatch[1301-1400]: loss = 0.314874 * 100, metric = 5.47% * 100;
 Minibatch[1401-1500]: loss = 0.330928 * 100, metric = 5.81% * 100;
 Minibatch[1501-1600]: loss = 0.310856 * 100, metric = 5.61% * 100;
 Minibatch[1601-1700]: loss = 0.325403 * 100, metric = 5.77% * 100;
 Minibatch[1701-1800]: loss = 0.308827 * 100, metric = 5.41% * 100;
 Minibatch[1801-1900]: loss = 0.331660 * 100, metric = 5.97% * 100;
 Minibatch[1901-2000]: loss = 0.324221 * 100, metric = 5.60% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.325449 * 2000, metric = 5.78% * 2000 905.567s (  2.2 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 16.50% * 2000;
 Minibatch[   1- 100]: loss = 0.344271 * 100, metric = 6.08% * 100;
 Minibatch[ 101- 200]: loss = 0.313785 * 100, metric = 5.37% * 100;
 Minibatch[ 201- 300]: loss = 0.317491 * 100, metric = 5.63% * 100;
 Minibatch[ 301- 400]: loss = 0.324395 * 100, metric = 5.66% * 100;
 Minibatch[ 401- 500]: loss = 0.325242 * 100, metric = 5.74% * 100;
 Minibatch[ 501- 600]: loss = 0.306649 * 100, metric = 5.36% * 100;
 Minibatch[ 601- 700]: loss = 0.327249 * 100, metric = 5.89% * 100;
 Minibatch[ 701- 800]: loss = 0.323502 * 100, metric = 5.64% * 100;
 Minibatch[ 801- 900]: loss = 0.328840 * 100, metric = 5.69% * 100;
 Minibatch[ 901-1000]: loss = 0.318142 * 100, metric = 5.51% * 100;
 Minibatch[1001-1100]: loss = 0.327383 * 100, metric = 5.86% * 100;
 Minibatch[1101-1200]: loss = 0.324705 * 100, metric = 5.84% * 100;
 Minibatch[1201-1300]: loss = 0.314323 * 100, metric = 5.56% * 100;
 Minibatch[1301-1400]: loss = 0.327845 * 100, metric = 5.89% * 100;
 Minibatch[1401-1500]: loss = 0.323464 * 100, metric = 5.70% * 100;
 Minibatch[1501-1600]: loss = 0.326648 * 100, metric = 5.75% * 100;
 Minibatch[1601-1700]: loss = 0.323156 * 100, metric = 5.66% * 100;
 Minibatch[1701-1800]: loss = 0.326104 * 100, metric = 5.87% * 100;
 Minibatch[1801-1900]: loss = 0.323120 * 100, metric = 5.73% * 100;
 Minibatch[1901-2000]: loss = 0.337662 * 100, metric = 6.16% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.324199 * 2000, metric = 5.73% * 2000 902.516s (  2.2 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 16.01% * 2000;
 Minibatch[   1- 100]: loss = 0.321818 * 100, metric = 5.59% * 100;
 Minibatch[ 101- 200]: loss = 0.330146 * 100, metric = 5.97% * 100;
 Minibatch[ 201- 300]: loss = 0.324237 * 100, metric = 5.79% * 100;
 Minibatch[ 301- 400]: loss = 0.314282 * 100, metric = 5.49% * 100;
 Minibatch[ 401- 500]: loss = 0.321941 * 100, metric = 5.66% * 100;
 Minibatch[ 501- 600]: loss = 0.320399 * 100, metric = 5.61% * 100;
 Minibatch[ 601- 700]: loss = 0.327543 * 100, metric = 5.82% * 100;
 Minibatch[ 701- 800]: loss = 0.336484 * 100, metric = 5.99% * 100;
 Minibatch[ 801- 900]: loss = 0.324681 * 100, metric = 5.74% * 100;
 Minibatch[ 901-1000]: loss = 0.319055 * 100, metric = 5.67% * 100;
 Minibatch[1001-1100]: loss = 0.319696 * 100, metric = 5.66% * 100;
 Minibatch[1101-1200]: loss = 0.327555 * 100, metric = 5.87% * 100;
 Minibatch[1201-1300]: loss = 0.325344 * 100, metric = 5.92% * 100;
 Minibatch[1301-1400]: loss = 0.327123 * 100, metric = 5.86% * 100;
 Minibatch[1401-1500]: loss = 0.333533 * 100, metric = 6.00% * 100;
 Minibatch[1501-1600]: loss = 0.314218 * 100, metric = 5.41% * 100;
 Minibatch[1601-1700]: loss = 0.319008 * 100, metric = 5.71% * 100;
 Minibatch[1701-1800]: loss = 0.319160 * 100, metric = 5.66% * 100;
 Minibatch[1801-1900]: loss = 0.324761 * 100, metric = 5.76% * 100;
 Minibatch[1901-2000]: loss = 0.318947 * 100, metric = 5.69% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.323496 * 2000, metric = 5.74% * 2000 899.275s (  2.2 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 17.50% * 2000;
 Minibatch[   1- 100]: loss = 0.315039 * 100, metric = 5.66% * 100;
 Minibatch[ 101- 200]: loss = 0.319475 * 100, metric = 5.48% * 100;
 Minibatch[ 201- 300]: loss = 0.326022 * 100, metric = 5.81% * 100;
 Minibatch[ 301- 400]: loss = 0.323804 * 100, metric = 5.68% * 100;
 Minibatch[ 401- 500]: loss = 0.315183 * 100, metric = 5.63% * 100;
 Minibatch[ 501- 600]: loss = 0.314600 * 100, metric = 5.82% * 100;
 Minibatch[ 601- 700]: loss = 0.309837 * 100, metric = 5.28% * 100;
 Minibatch[ 701- 800]: loss = 0.314671 * 100, metric = 5.48% * 100;
 Minibatch[ 801- 900]: loss = 0.311460 * 100, metric = 5.55% * 100;
 Minibatch[ 901-1000]: loss = 0.305973 * 100, metric = 5.38% * 100;
 Minibatch[1001-1100]: loss = 0.304941 * 100, metric = 5.22% * 100;
 Minibatch[1101-1200]: loss = 0.316994 * 100, metric = 5.64% * 100;
 Minibatch[1201-1300]: loss = 0.328387 * 100, metric = 5.95% * 100;
 Minibatch[1301-1400]: loss = 0.318356 * 100, metric = 5.70% * 100;
 Minibatch[1401-1500]: loss = 0.311571 * 100, metric = 5.63% * 100;
 Minibatch[1501-1600]: loss = 0.322287 * 100, metric = 5.63% * 100;
 Minibatch[1601-1700]: loss = 0.307760 * 100, metric = 5.37% * 100;
 Minibatch[1701-1800]: loss = 0.322745 * 100, metric = 5.66% * 100;
 Minibatch[1801-1900]: loss = 0.310891 * 100, metric = 5.37% * 100;
 Minibatch[1901-2000]: loss = 0.317123 * 100, metric = 5.61% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.315856 * 2000, metric = 5.58% * 2000 894.486s (  2.2 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 16.10% * 2000;
 Minibatch[   1- 100]: loss = 0.324557 * 100, metric = 5.88% * 100;
 Minibatch[ 101- 200]: loss = 0.315152 * 100, metric = 5.68% * 100;
 Minibatch[ 201- 300]: loss = 0.313515 * 100, metric = 5.45% * 100;
 Minibatch[ 301- 400]: loss = 0.324633 * 100, metric = 6.01% * 100;
 Minibatch[ 401- 500]: loss = 0.316108 * 100, metric = 5.67% * 100;
 Minibatch[ 501- 600]: loss = 0.316054 * 100, metric = 5.72% * 100;
 Minibatch[ 601- 700]: loss = 0.327570 * 100, metric = 5.99% * 100;
 Minibatch[ 701- 800]: loss = 0.317680 * 100, metric = 5.76% * 100;
 Minibatch[ 801- 900]: loss = 0.313848 * 100, metric = 5.47% * 100;
 Minibatch[ 901-1000]: loss = 0.304981 * 100, metric = 5.38% * 100;
 Minibatch[1001-1100]: loss = 0.311416 * 100, metric = 5.44% * 100;
 Minibatch[1101-1200]: loss = 0.300382 * 100, metric = 5.14% * 100;
 Minibatch[1201-1300]: loss = 0.309101 * 100, metric = 5.37% * 100;
 Minibatch[1301-1400]: loss = 0.301166 * 100, metric = 5.03% * 100;
 Minibatch[1401-1500]: loss = 0.323071 * 100, metric = 5.75% * 100;
 Minibatch[1501-1600]: loss = 0.321392 * 100, metric = 5.58% * 100;
 Minibatch[1601-1700]: loss = 0.312415 * 100, metric = 5.46% * 100;
 Minibatch[1701-1800]: loss = 0.308558 * 100, metric = 5.37% * 100;
 Minibatch[1801-1900]: loss = 0.311614 * 100, metric = 5.41% * 100;
 Minibatch[1901-2000]: loss = 0.316760 * 100, metric = 5.66% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.314499 * 2000, metric = 5.56% * 2000 891.897s (  2.2 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 14.77% * 2000;
 Minibatch[   1- 100]: loss = 0.307048 * 100, metric = 5.48% * 100;
 Minibatch[ 101- 200]: loss = 0.311958 * 100, metric = 5.50% * 100;
 Minibatch[ 201- 300]: loss = 0.310284 * 100, metric = 5.35% * 100;
 Minibatch[ 301- 400]: loss = 0.315558 * 100, metric = 5.60% * 100;
 Minibatch[ 401- 500]: loss = 0.299754 * 100, metric = 5.21% * 100;
 Minibatch[ 501- 600]: loss = 0.310565 * 100, metric = 5.51% * 100;
 Minibatch[ 601- 700]: loss = 0.320159 * 100, metric = 5.76% * 100;
 Minibatch[ 701- 800]: loss = 0.302132 * 100, metric = 5.25% * 100;
 Minibatch[ 801- 900]: loss = 0.302232 * 100, metric = 4.92% * 100;
 Minibatch[ 901-1000]: loss = 0.302047 * 100, metric = 5.39% * 100;
 Minibatch[1001-1100]: loss = 0.310885 * 100, metric = 5.50% * 100;
 Minibatch[1101-1200]: loss = 0.304368 * 100, metric = 5.34% * 100;
 Minibatch[1201-1300]: loss = 0.307726 * 100, metric = 5.52% * 100;
 Minibatch[1301-1400]: loss = 0.306281 * 100, metric = 5.41% * 100;
 Minibatch[1401-1500]: loss = 0.308321 * 100, metric = 5.48% * 100;
 Minibatch[1501-1600]: loss = 0.303645 * 100, metric = 5.35% * 100;
 Minibatch[1601-1700]: loss = 0.317416 * 100, metric = 5.71% * 100;
 Minibatch[1701-1800]: loss = 0.300829 * 100, metric = 5.22% * 100;
 Minibatch[1801-1900]: loss = 0.306013 * 100, metric = 5.41% * 100;
 Minibatch[1901-2000]: loss = 0.296191 * 100, metric = 5.05% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.307171 * 2000, metric = 5.40% * 2000 908.304s (  2.2 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 16.12% * 2000;
 Minibatch[   1- 100]: loss = 0.285952 * 100, metric = 5.01% * 100;
 Minibatch[ 101- 200]: loss = 0.309387 * 100, metric = 5.52% * 100;
 Minibatch[ 201- 300]: loss = 0.299698 * 100, metric = 5.22% * 100;
 Minibatch[ 301- 400]: loss = 0.285938 * 100, metric = 4.81% * 100;
 Minibatch[ 401- 500]: loss = 0.296882 * 100, metric = 5.07% * 100;
 Minibatch[ 501- 600]: loss = 0.278596 * 100, metric = 4.76% * 100;
 Minibatch[ 601- 700]: loss = 0.304201 * 100, metric = 5.53% * 100;
 Minibatch[ 701- 800]: loss = 0.289620 * 100, metric = 5.13% * 100;
 Minibatch[ 801- 900]: loss = 0.306375 * 100, metric = 5.41% * 100;
 Minibatch[ 901-1000]: loss = 0.292098 * 100, metric = 5.05% * 100;
 Minibatch[1001-1100]: loss = 0.312961 * 100, metric = 5.56% * 100;
 Minibatch[1101-1200]: loss = 0.297932 * 100, metric = 5.33% * 100;
 Minibatch[1201-1300]: loss = 0.308727 * 100, metric = 5.57% * 100;
 Minibatch[1301-1400]: loss = 0.302794 * 100, metric = 5.32% * 100;
 Minibatch[1401-1500]: loss = 0.300380 * 100, metric = 5.24% * 100;
 Minibatch[1501-1600]: loss = 0.298759 * 100, metric = 5.23% * 100;
 Minibatch[1601-1700]: loss = 0.300081 * 100, metric = 5.36% * 100;
 Minibatch[1701-1800]: loss = 0.287663 * 100, metric = 5.07% * 100;
 Minibatch[1801-1900]: loss = 0.306747 * 100, metric = 5.57% * 100;
 Minibatch[1901-2000]: loss = 0.300258 * 100, metric = 5.39% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.298252 * 2000, metric = 5.26% * 2000 896.540s (  2.2 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 14.31% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
