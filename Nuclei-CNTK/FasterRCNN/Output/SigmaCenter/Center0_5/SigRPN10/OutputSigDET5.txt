Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.379437 * 100, metric = 24.61% * 100;
 Minibatch[ 101- 200]: loss = 1.105471 * 100, metric = 22.77% * 100;
 Minibatch[ 201- 300]: loss = 1.001488 * 100, metric = 21.19% * 100;
 Minibatch[ 301- 400]: loss = 0.974734 * 100, metric = 19.82% * 100;
 Minibatch[ 401- 500]: loss = 0.896848 * 100, metric = 18.64% * 100;
 Minibatch[ 501- 600]: loss = 0.881617 * 100, metric = 17.63% * 100;
 Minibatch[ 601- 700]: loss = 0.856475 * 100, metric = 16.55% * 100;
 Minibatch[ 701- 800]: loss = 0.794256 * 100, metric = 14.97% * 100;
 Minibatch[ 801- 900]: loss = 0.808719 * 100, metric = 15.79% * 100;
 Minibatch[ 901-1000]: loss = 0.829619 * 100, metric = 15.70% * 100;
 Minibatch[1001-1100]: loss = 0.787725 * 100, metric = 15.22% * 100;
 Minibatch[1101-1200]: loss = 0.806338 * 100, metric = 14.49% * 100;
 Minibatch[1201-1300]: loss = 0.785280 * 100, metric = 14.75% * 100;
 Minibatch[1301-1400]: loss = 0.759210 * 100, metric = 14.35% * 100;
 Minibatch[1401-1500]: loss = 0.773665 * 100, metric = 14.47% * 100;
 Minibatch[1501-1600]: loss = 0.727690 * 100, metric = 13.13% * 100;
 Minibatch[1601-1700]: loss = 0.712863 * 100, metric = 13.23% * 100;
 Minibatch[1701-1800]: loss = 0.730208 * 100, metric = 13.36% * 100;
 Minibatch[1801-1900]: loss = 0.719120 * 100, metric = 12.93% * 100;
 Minibatch[1901-2000]: loss = 0.702113 * 100, metric = 12.68% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.851644 * 2000, metric = 16.31% * 2000 1001.273s (  2.0 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 23.15% * 2000;
0.7900775364488364
 Minibatch[   1- 100]: loss = 0.701165 * 100, metric = 12.72% * 100;
 Minibatch[ 101- 200]: loss = 0.710928 * 100, metric = 13.04% * 100;
 Minibatch[ 201- 300]: loss = 0.713824 * 100, metric = 12.39% * 100;
 Minibatch[ 301- 400]: loss = 0.712097 * 100, metric = 12.66% * 100;
 Minibatch[ 401- 500]: loss = 0.690699 * 100, metric = 12.14% * 100;
 Minibatch[ 501- 600]: loss = 0.692890 * 100, metric = 12.08% * 100;
 Minibatch[ 601- 700]: loss = 0.668491 * 100, metric = 11.96% * 100;
 Minibatch[ 701- 800]: loss = 0.688147 * 100, metric = 12.58% * 100;
 Minibatch[ 801- 900]: loss = 0.661125 * 100, metric = 11.82% * 100;
 Minibatch[ 901-1000]: loss = 0.657597 * 100, metric = 11.53% * 100;
 Minibatch[1001-1100]: loss = 0.673671 * 100, metric = 12.09% * 100;
 Minibatch[1101-1200]: loss = 0.670248 * 100, metric = 11.67% * 100;
 Minibatch[1201-1300]: loss = 0.661773 * 100, metric = 11.83% * 100;
 Minibatch[1301-1400]: loss = 0.687466 * 100, metric = 12.32% * 100;
 Minibatch[1401-1500]: loss = 0.647928 * 100, metric = 11.25% * 100;
 Minibatch[1501-1600]: loss = 0.643725 * 100, metric = 11.18% * 100;
 Minibatch[1601-1700]: loss = 0.628394 * 100, metric = 11.01% * 100;
 Minibatch[1701-1800]: loss = 0.648917 * 100, metric = 11.64% * 100;
 Minibatch[1801-1900]: loss = 0.651379 * 100, metric = 11.42% * 100;
 Minibatch[1901-2000]: loss = 0.614507 * 100, metric = 10.49% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.671249 * 2000, metric = 11.89% * 2000 932.023s (  2.1 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 19.91% * 2000;
0.7553144497945905
 Minibatch[   1- 100]: loss = 0.644701 * 100, metric = 11.32% * 100;
 Minibatch[ 101- 200]: loss = 0.638288 * 100, metric = 11.17% * 100;
 Minibatch[ 201- 300]: loss = 0.621941 * 100, metric = 11.11% * 100;
 Minibatch[ 301- 400]: loss = 0.641025 * 100, metric = 11.34% * 100;
 Minibatch[ 401- 500]: loss = 0.640179 * 100, metric = 11.12% * 100;
 Minibatch[ 501- 600]: loss = 0.636912 * 100, metric = 10.71% * 100;
 Minibatch[ 601- 700]: loss = 0.634871 * 100, metric = 11.08% * 100;
 Minibatch[ 701- 800]: loss = 0.591176 * 100, metric = 9.99% * 100;
 Minibatch[ 801- 900]: loss = 0.627108 * 100, metric = 10.92% * 100;
 Minibatch[ 901-1000]: loss = 0.609073 * 100, metric = 10.88% * 100;
 Minibatch[1001-1100]: loss = 0.615468 * 100, metric = 10.68% * 100;
 Minibatch[1101-1200]: loss = 0.600561 * 100, metric = 10.36% * 100;
 Minibatch[1201-1300]: loss = 0.602049 * 100, metric = 10.18% * 100;
 Minibatch[1301-1400]: loss = 0.633130 * 100, metric = 10.83% * 100;
 Minibatch[1401-1500]: loss = 0.622200 * 100, metric = 10.75% * 100;
 Minibatch[1501-1600]: loss = 0.621307 * 100, metric = 10.31% * 100;
 Minibatch[1601-1700]: loss = 0.597137 * 100, metric = 10.01% * 100;
 Minibatch[1701-1800]: loss = 0.620836 * 100, metric = 10.41% * 100;
 Minibatch[1801-1900]: loss = 0.612179 * 100, metric = 9.98% * 100;
 Minibatch[1901-2000]: loss = 0.595671 * 100, metric = 9.99% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.620291 * 2000, metric = 10.66% * 2000 923.737s (  2.2 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 19.74% * 2000;
0.7155388149246573
 Minibatch[   1- 100]: loss = 0.616592 * 100, metric = 10.35% * 100;
 Minibatch[ 101- 200]: loss = 0.582547 * 100, metric = 9.90% * 100;
 Minibatch[ 201- 300]: loss = 0.603270 * 100, metric = 10.43% * 100;
 Minibatch[ 301- 400]: loss = 0.570756 * 100, metric = 9.64% * 100;
 Minibatch[ 401- 500]: loss = 0.596700 * 100, metric = 10.27% * 100;
 Minibatch[ 501- 600]: loss = 0.582898 * 100, metric = 9.52% * 100;
 Minibatch[ 601- 700]: loss = 0.591719 * 100, metric = 9.79% * 100;
 Minibatch[ 701- 800]: loss = 0.595471 * 100, metric = 10.16% * 100;
 Minibatch[ 801- 900]: loss = 0.591391 * 100, metric = 9.94% * 100;
 Minibatch[ 901-1000]: loss = 0.589078 * 100, metric = 10.09% * 100;
 Minibatch[1001-1100]: loss = 0.606093 * 100, metric = 10.36% * 100;
 Minibatch[1101-1200]: loss = 0.573822 * 100, metric = 9.60% * 100;
 Minibatch[1201-1300]: loss = 0.583599 * 100, metric = 9.67% * 100;
 Minibatch[1301-1400]: loss = 0.592689 * 100, metric = 10.34% * 100;
 Minibatch[1401-1500]: loss = 0.590951 * 100, metric = 10.05% * 100;
 Minibatch[1501-1600]: loss = 0.563524 * 100, metric = 9.40% * 100;
 Minibatch[1601-1700]: loss = 0.589779 * 100, metric = 9.73% * 100;
 Minibatch[1701-1800]: loss = 0.601985 * 100, metric = 9.95% * 100;
 Minibatch[1801-1900]: loss = 0.577479 * 100, metric = 9.71% * 100;
 Minibatch[1901-2000]: loss = 0.574509 * 100, metric = 9.42% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.588743 * 2000, metric = 9.92% * 2000 928.219s (  2.2 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 20.64% * 2000;
 Minibatch[   1- 100]: loss = 0.592580 * 100, metric = 9.73% * 100;
 Minibatch[ 101- 200]: loss = 0.571506 * 100, metric = 9.44% * 100;
 Minibatch[ 201- 300]: loss = 0.569247 * 100, metric = 9.28% * 100;
 Minibatch[ 301- 400]: loss = 0.593324 * 100, metric = 10.37% * 100;
 Minibatch[ 401- 500]: loss = 0.556588 * 100, metric = 9.24% * 100;
 Minibatch[ 501- 600]: loss = 0.554319 * 100, metric = 8.99% * 100;
 Minibatch[ 601- 700]: loss = 0.558428 * 100, metric = 9.22% * 100;
 Minibatch[ 701- 800]: loss = 0.578458 * 100, metric = 9.51% * 100;
 Minibatch[ 801- 900]: loss = 0.554272 * 100, metric = 8.97% * 100;
 Minibatch[ 901-1000]: loss = 0.554467 * 100, metric = 9.47% * 100;
 Minibatch[1001-1100]: loss = 0.563762 * 100, metric = 9.35% * 100;
 Minibatch[1101-1200]: loss = 0.553600 * 100, metric = 9.11% * 100;
 Minibatch[1201-1300]: loss = 0.563977 * 100, metric = 9.39% * 100;
 Minibatch[1301-1400]: loss = 0.586295 * 100, metric = 9.77% * 100;
 Minibatch[1401-1500]: loss = 0.571360 * 100, metric = 9.69% * 100;
 Minibatch[1501-1600]: loss = 0.572397 * 100, metric = 9.53% * 100;
 Minibatch[1601-1700]: loss = 0.577487 * 100, metric = 9.95% * 100;
 Minibatch[1701-1800]: loss = 0.578939 * 100, metric = 9.83% * 100;
 Minibatch[1801-1900]: loss = 0.565594 * 100, metric = 9.64% * 100;
 Minibatch[1901-2000]: loss = 0.554689 * 100, metric = 9.09% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.568564 * 2000, metric = 9.48% * 2000 910.964s (  2.2 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 18.45% * 2000;
 Minibatch[   1- 100]: loss = 0.546663 * 100, metric = 9.05% * 100;
 Minibatch[ 101- 200]: loss = 0.539787 * 100, metric = 9.00% * 100;
 Minibatch[ 201- 300]: loss = 0.565260 * 100, metric = 9.44% * 100;
 Minibatch[ 301- 400]: loss = 0.557785 * 100, metric = 9.04% * 100;
 Minibatch[ 401- 500]: loss = 0.537953 * 100, metric = 8.86% * 100;
 Minibatch[ 501- 600]: loss = 0.552408 * 100, metric = 9.15% * 100;
 Minibatch[ 601- 700]: loss = 0.551189 * 100, metric = 9.43% * 100;
 Minibatch[ 701- 800]: loss = 0.553042 * 100, metric = 9.32% * 100;
 Minibatch[ 801- 900]: loss = 0.553320 * 100, metric = 9.25% * 100;
 Minibatch[ 901-1000]: loss = 0.541004 * 100, metric = 9.15% * 100;
 Minibatch[1001-1100]: loss = 0.539902 * 100, metric = 8.56% * 100;
 Minibatch[1101-1200]: loss = 0.572388 * 100, metric = 9.34% * 100;
 Minibatch[1201-1300]: loss = 0.570999 * 100, metric = 9.44% * 100;
 Minibatch[1301-1400]: loss = 0.548969 * 100, metric = 9.07% * 100;
 Minibatch[1401-1500]: loss = 0.561424 * 100, metric = 9.42% * 100;
 Minibatch[1501-1600]: loss = 0.538204 * 100, metric = 8.71% * 100;
 Minibatch[1601-1700]: loss = 0.538907 * 100, metric = 8.74% * 100;
 Minibatch[1701-1800]: loss = 0.529155 * 100, metric = 8.79% * 100;
 Minibatch[1801-1900]: loss = 0.562535 * 100, metric = 9.21% * 100;
 Minibatch[1901-2000]: loss = 0.543632 * 100, metric = 8.91% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.550226 * 2000, metric = 9.09% * 2000 915.417s (  2.2 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 19.02% * 2000;
0.6976622047498823
 Minibatch[   1- 100]: loss = 0.546997 * 100, metric = 9.06% * 100;
 Minibatch[ 101- 200]: loss = 0.546111 * 100, metric = 8.84% * 100;
 Minibatch[ 201- 300]: loss = 0.547859 * 100, metric = 9.26% * 100;
 Minibatch[ 301- 400]: loss = 0.535031 * 100, metric = 8.77% * 100;
 Minibatch[ 401- 500]: loss = 0.548607 * 100, metric = 8.99% * 100;
 Minibatch[ 501- 600]: loss = 0.513715 * 100, metric = 8.16% * 100;
 Minibatch[ 601- 700]: loss = 0.545128 * 100, metric = 8.74% * 100;
 Minibatch[ 701- 800]: loss = 0.538425 * 100, metric = 8.56% * 100;
 Minibatch[ 801- 900]: loss = 0.542460 * 100, metric = 8.96% * 100;
 Minibatch[ 901-1000]: loss = 0.527412 * 100, metric = 8.85% * 100;
 Minibatch[1001-1100]: loss = 0.539224 * 100, metric = 9.12% * 100;
 Minibatch[1101-1200]: loss = 0.528687 * 100, metric = 8.46% * 100;
 Minibatch[1201-1300]: loss = 0.541140 * 100, metric = 9.12% * 100;
 Minibatch[1301-1400]: loss = 0.532480 * 100, metric = 8.54% * 100;
 Minibatch[1401-1500]: loss = 0.521688 * 100, metric = 8.27% * 100;
 Minibatch[1501-1600]: loss = 0.529995 * 100, metric = 8.73% * 100;
 Minibatch[1601-1700]: loss = 0.538460 * 100, metric = 8.83% * 100;
 Minibatch[1701-1800]: loss = 0.527715 * 100, metric = 8.73% * 100;
 Minibatch[1801-1900]: loss = 0.531876 * 100, metric = 8.88% * 100;
 Minibatch[1901-2000]: loss = 0.527454 * 100, metric = 8.66% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.535523 * 2000, metric = 8.78% * 2000 909.151s (  2.2 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 16.78% * 2000;
0.6481241688355803
 Minibatch[   1- 100]: loss = 0.540567 * 100, metric = 8.85% * 100;
 Minibatch[ 101- 200]: loss = 0.523702 * 100, metric = 8.69% * 100;
 Minibatch[ 201- 300]: loss = 0.509809 * 100, metric = 8.27% * 100;
 Minibatch[ 301- 400]: loss = 0.509318 * 100, metric = 8.45% * 100;
 Minibatch[ 401- 500]: loss = 0.533378 * 100, metric = 9.03% * 100;
 Minibatch[ 501- 600]: loss = 0.558359 * 100, metric = 9.31% * 100;
 Minibatch[ 601- 700]: loss = 0.516664 * 100, metric = 8.56% * 100;
 Minibatch[ 701- 800]: loss = 0.529742 * 100, metric = 8.60% * 100;
 Minibatch[ 801- 900]: loss = 0.516428 * 100, metric = 8.38% * 100;
 Minibatch[ 901-1000]: loss = 0.512013 * 100, metric = 8.12% * 100;
 Minibatch[1001-1100]: loss = 0.522557 * 100, metric = 8.63% * 100;
 Minibatch[1101-1200]: loss = 0.512247 * 100, metric = 8.24% * 100;
 Minibatch[1201-1300]: loss = 0.533260 * 100, metric = 8.77% * 100;
 Minibatch[1301-1400]: loss = 0.543821 * 100, metric = 8.89% * 100;
 Minibatch[1401-1500]: loss = 0.533614 * 100, metric = 8.64% * 100;
 Minibatch[1501-1600]: loss = 0.543862 * 100, metric = 8.86% * 100;
 Minibatch[1601-1700]: loss = 0.516572 * 100, metric = 8.15% * 100;
 Minibatch[1701-1800]: loss = 0.517213 * 100, metric = 8.05% * 100;
 Minibatch[1801-1900]: loss = 0.517432 * 100, metric = 8.30% * 100;
 Minibatch[1901-2000]: loss = 0.531752 * 100, metric = 8.43% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.526115 * 2000, metric = 8.56% * 2000 909.712s (  2.2 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 16.62% * 2000;
 Minibatch[   1- 100]: loss = 0.507695 * 100, metric = 8.08% * 100;
 Minibatch[ 101- 200]: loss = 0.537099 * 100, metric = 8.92% * 100;
 Minibatch[ 201- 300]: loss = 0.528001 * 100, metric = 8.38% * 100;
 Minibatch[ 301- 400]: loss = 0.535940 * 100, metric = 8.66% * 100;
 Minibatch[ 401- 500]: loss = 0.520278 * 100, metric = 8.13% * 100;
 Minibatch[ 501- 600]: loss = 0.528421 * 100, metric = 8.52% * 100;
 Minibatch[ 601- 700]: loss = 0.516017 * 100, metric = 8.42% * 100;
 Minibatch[ 701- 800]: loss = 0.503527 * 100, metric = 7.88% * 100;
 Minibatch[ 801- 900]: loss = 0.501490 * 100, metric = 8.02% * 100;
 Minibatch[ 901-1000]: loss = 0.521334 * 100, metric = 8.52% * 100;
 Minibatch[1001-1100]: loss = 0.497530 * 100, metric = 7.87% * 100;
 Minibatch[1101-1200]: loss = 0.519473 * 100, metric = 8.37% * 100;
 Minibatch[1201-1300]: loss = 0.504435 * 100, metric = 8.18% * 100;
 Minibatch[1301-1400]: loss = 0.501360 * 100, metric = 7.93% * 100;
 Minibatch[1401-1500]: loss = 0.519738 * 100, metric = 8.55% * 100;
 Minibatch[1501-1600]: loss = 0.521646 * 100, metric = 8.43% * 100;
 Minibatch[1601-1700]: loss = 0.514028 * 100, metric = 8.45% * 100;
 Minibatch[1701-1800]: loss = 0.503427 * 100, metric = 7.89% * 100;
 Minibatch[1801-1900]: loss = 0.495235 * 100, metric = 7.84% * 100;
 Minibatch[1901-2000]: loss = 0.518636 * 100, metric = 8.04% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.514766 * 2000, metric = 8.25% * 2000 901.872s (  2.2 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 14.99% * 2000;
0.5990967754647136
 Minibatch[   1- 100]: loss = 0.533359 * 100, metric = 8.85% * 100;
 Minibatch[ 101- 200]: loss = 0.512190 * 100, metric = 8.44% * 100;
 Minibatch[ 201- 300]: loss = 0.516226 * 100, metric = 8.49% * 100;
 Minibatch[ 301- 400]: loss = 0.507614 * 100, metric = 8.05% * 100;
 Minibatch[ 401- 500]: loss = 0.519240 * 100, metric = 8.58% * 100;
 Minibatch[ 501- 600]: loss = 0.495961 * 100, metric = 7.85% * 100;
 Minibatch[ 601- 700]: loss = 0.486286 * 100, metric = 7.74% * 100;
 Minibatch[ 701- 800]: loss = 0.492679 * 100, metric = 7.74% * 100;
 Minibatch[ 801- 900]: loss = 0.509552 * 100, metric = 8.13% * 100;
 Minibatch[ 901-1000]: loss = 0.511038 * 100, metric = 8.30% * 100;
 Minibatch[1001-1100]: loss = 0.506855 * 100, metric = 8.15% * 100;
 Minibatch[1101-1200]: loss = 0.498929 * 100, metric = 7.88% * 100;
 Minibatch[1201-1300]: loss = 0.509037 * 100, metric = 8.26% * 100;
 Minibatch[1301-1400]: loss = 0.511304 * 100, metric = 8.37% * 100;
 Minibatch[1401-1500]: loss = 0.504145 * 100, metric = 7.98% * 100;
 Minibatch[1501-1600]: loss = 0.506199 * 100, metric = 8.30% * 100;
 Minibatch[1601-1700]: loss = 0.497352 * 100, metric = 7.77% * 100;
 Minibatch[1701-1800]: loss = 0.503992 * 100, metric = 8.04% * 100;
 Minibatch[1801-1900]: loss = 0.507847 * 100, metric = 8.29% * 100;
 Minibatch[1901-2000]: loss = 0.493169 * 100, metric = 7.89% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.506149 * 2000, metric = 8.15% * 2000 903.850s (  2.2 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 14.76% * 2000;
0.5981826531887054
 Minibatch[   1- 100]: loss = 0.488269 * 100, metric = 7.68% * 100;
 Minibatch[ 101- 200]: loss = 0.502883 * 100, metric = 7.83% * 100;
 Minibatch[ 201- 300]: loss = 0.501769 * 100, metric = 8.07% * 100;
 Minibatch[ 301- 400]: loss = 0.494911 * 100, metric = 7.60% * 100;
 Minibatch[ 401- 500]: loss = 0.490632 * 100, metric = 7.75% * 100;
 Minibatch[ 501- 600]: loss = 0.502840 * 100, metric = 8.07% * 100;
 Minibatch[ 601- 700]: loss = 0.492959 * 100, metric = 7.67% * 100;
 Minibatch[ 701- 800]: loss = 0.501865 * 100, metric = 8.13% * 100;
 Minibatch[ 801- 900]: loss = 0.495376 * 100, metric = 7.82% * 100;
 Minibatch[ 901-1000]: loss = 0.512269 * 100, metric = 8.12% * 100;
 Minibatch[1001-1100]: loss = 0.498472 * 100, metric = 7.87% * 100;
 Minibatch[1101-1200]: loss = 0.505839 * 100, metric = 8.08% * 100;
 Minibatch[1201-1300]: loss = 0.501682 * 100, metric = 8.23% * 100;
 Minibatch[1301-1400]: loss = 0.477605 * 100, metric = 7.67% * 100;
 Minibatch[1401-1500]: loss = 0.502449 * 100, metric = 8.11% * 100;
 Minibatch[1501-1600]: loss = 0.488048 * 100, metric = 7.65% * 100;
 Minibatch[1601-1700]: loss = 0.492001 * 100, metric = 7.65% * 100;
 Minibatch[1701-1800]: loss = 0.508075 * 100, metric = 8.06% * 100;
 Minibatch[1801-1900]: loss = 0.489580 * 100, metric = 7.86% * 100;
 Minibatch[1901-2000]: loss = 0.488829 * 100, metric = 7.88% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.496818 * 2000, metric = 7.89% * 2000 911.153s (  2.2 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 15.08% * 2000;
 Minibatch[   1- 100]: loss = 0.476705 * 100, metric = 7.36% * 100;
 Minibatch[ 101- 200]: loss = 0.483673 * 100, metric = 7.22% * 100;
 Minibatch[ 201- 300]: loss = 0.486455 * 100, metric = 7.84% * 100;
 Minibatch[ 301- 400]: loss = 0.516383 * 100, metric = 8.48% * 100;
 Minibatch[ 401- 500]: loss = 0.488621 * 100, metric = 7.71% * 100;
 Minibatch[ 501- 600]: loss = 0.481275 * 100, metric = 7.57% * 100;
 Minibatch[ 601- 700]: loss = 0.488916 * 100, metric = 7.64% * 100;
 Minibatch[ 701- 800]: loss = 0.494897 * 100, metric = 7.90% * 100;
 Minibatch[ 801- 900]: loss = 0.482578 * 100, metric = 7.51% * 100;
 Minibatch[ 901-1000]: loss = 0.494353 * 100, metric = 7.99% * 100;
 Minibatch[1001-1100]: loss = 0.492971 * 100, metric = 7.96% * 100;
 Minibatch[1101-1200]: loss = 0.490565 * 100, metric = 7.75% * 100;
 Minibatch[1201-1300]: loss = 0.493223 * 100, metric = 7.88% * 100;
 Minibatch[1301-1400]: loss = 0.477209 * 100, metric = 7.32% * 100;
 Minibatch[1401-1500]: loss = 0.498285 * 100, metric = 7.81% * 100;
 Minibatch[1501-1600]: loss = 0.471562 * 100, metric = 7.41% * 100;
 Minibatch[1601-1700]: loss = 0.501235 * 100, metric = 7.87% * 100;
 Minibatch[1701-1800]: loss = 0.481857 * 100, metric = 7.53% * 100;
 Minibatch[1801-1900]: loss = 0.480195 * 100, metric = 7.50% * 100;
 Minibatch[1901-2000]: loss = 0.496605 * 100, metric = 7.96% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.488878 * 2000, metric = 7.71% * 2000 901.213s (  2.2 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 15.80% * 2000;
 Minibatch[   1- 100]: loss = 0.493117 * 100, metric = 7.92% * 100;
 Minibatch[ 101- 200]: loss = 0.487663 * 100, metric = 7.68% * 100;
 Minibatch[ 201- 300]: loss = 0.485991 * 100, metric = 7.76% * 100;
 Minibatch[ 301- 400]: loss = 0.496159 * 100, metric = 7.73% * 100;
 Minibatch[ 401- 500]: loss = 0.494064 * 100, metric = 8.11% * 100;
 Minibatch[ 501- 600]: loss = 0.498313 * 100, metric = 8.23% * 100;
 Minibatch[ 601- 700]: loss = 0.474516 * 100, metric = 7.18% * 100;
 Minibatch[ 701- 800]: loss = 0.473628 * 100, metric = 7.34% * 100;
 Minibatch[ 801- 900]: loss = 0.474470 * 100, metric = 7.35% * 100;
 Minibatch[ 901-1000]: loss = 0.494221 * 100, metric = 7.64% * 100;
 Minibatch[1001-1100]: loss = 0.495815 * 100, metric = 7.92% * 100;
 Minibatch[1101-1200]: loss = 0.476922 * 100, metric = 7.62% * 100;
 Minibatch[1201-1300]: loss = 0.490219 * 100, metric = 7.71% * 100;
 Minibatch[1301-1400]: loss = 0.478961 * 100, metric = 7.64% * 100;
 Minibatch[1401-1500]: loss = 0.479139 * 100, metric = 7.56% * 100;
 Minibatch[1501-1600]: loss = 0.468134 * 100, metric = 7.17% * 100;
 Minibatch[1601-1700]: loss = 0.460529 * 100, metric = 7.24% * 100;
 Minibatch[1701-1800]: loss = 0.464659 * 100, metric = 7.09% * 100;
 Minibatch[1801-1900]: loss = 0.459269 * 100, metric = 7.00% * 100;
 Minibatch[1901-2000]: loss = 0.474146 * 100, metric = 7.39% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.480997 * 2000, metric = 7.56% * 2000 900.215s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 16.97% * 2000;
 Minibatch[   1- 100]: loss = 0.464858 * 100, metric = 7.21% * 100;
 Minibatch[ 101- 200]: loss = 0.457956 * 100, metric = 7.06% * 100;
 Minibatch[ 201- 300]: loss = 0.481014 * 100, metric = 7.57% * 100;
 Minibatch[ 301- 400]: loss = 0.477639 * 100, metric = 7.42% * 100;
 Minibatch[ 401- 500]: loss = 0.475905 * 100, metric = 7.72% * 100;
 Minibatch[ 501- 600]: loss = 0.477700 * 100, metric = 7.58% * 100;
 Minibatch[ 601- 700]: loss = 0.473126 * 100, metric = 7.50% * 100;
 Minibatch[ 701- 800]: loss = 0.497227 * 100, metric = 7.99% * 100;
 Minibatch[ 801- 900]: loss = 0.493635 * 100, metric = 8.11% * 100;
 Minibatch[ 901-1000]: loss = 0.487895 * 100, metric = 7.57% * 100;
 Minibatch[1001-1100]: loss = 0.485440 * 100, metric = 7.73% * 100;
 Minibatch[1101-1200]: loss = 0.470551 * 100, metric = 7.31% * 100;
 Minibatch[1201-1300]: loss = 0.457427 * 100, metric = 6.96% * 100;
 Minibatch[1301-1400]: loss = 0.478658 * 100, metric = 7.56% * 100;
 Minibatch[1401-1500]: loss = 0.477215 * 100, metric = 7.62% * 100;
 Minibatch[1501-1600]: loss = 0.458569 * 100, metric = 7.13% * 100;
 Minibatch[1601-1700]: loss = 0.472334 * 100, metric = 7.23% * 100;
 Minibatch[1701-1800]: loss = 0.466439 * 100, metric = 7.03% * 100;
 Minibatch[1801-1900]: loss = 0.472371 * 100, metric = 7.37% * 100;
 Minibatch[1901-2000]: loss = 0.478592 * 100, metric = 7.21% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.475228 * 2000, metric = 7.44% * 2000 902.063s (  2.2 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 15.51% * 2000;
 Minibatch[   1- 100]: loss = 0.469750 * 100, metric = 7.31% * 100;
 Minibatch[ 101- 200]: loss = 0.479716 * 100, metric = 7.71% * 100;
 Minibatch[ 201- 300]: loss = 0.472565 * 100, metric = 7.36% * 100;
 Minibatch[ 301- 400]: loss = 0.460636 * 100, metric = 7.21% * 100;
 Minibatch[ 401- 500]: loss = 0.469591 * 100, metric = 7.36% * 100;
 Minibatch[ 501- 600]: loss = 0.459616 * 100, metric = 6.96% * 100;
 Minibatch[ 601- 700]: loss = 0.447507 * 100, metric = 6.86% * 100;
 Minibatch[ 701- 800]: loss = 0.473471 * 100, metric = 7.37% * 100;
 Minibatch[ 801- 900]: loss = 0.484140 * 100, metric = 7.84% * 100;
 Minibatch[ 901-1000]: loss = 0.474898 * 100, metric = 7.34% * 100;
 Minibatch[1001-1100]: loss = 0.480630 * 100, metric = 7.46% * 100;
 Minibatch[1101-1200]: loss = 0.472413 * 100, metric = 7.39% * 100;
 Minibatch[1201-1300]: loss = 0.459034 * 100, metric = 6.95% * 100;
 Minibatch[1301-1400]: loss = 0.487131 * 100, metric = 7.71% * 100;
 Minibatch[1401-1500]: loss = 0.451973 * 100, metric = 6.97% * 100;
 Minibatch[1501-1600]: loss = 0.457568 * 100, metric = 7.23% * 100;
 Minibatch[1601-1700]: loss = 0.468407 * 100, metric = 7.31% * 100;
 Minibatch[1701-1800]: loss = 0.443940 * 100, metric = 6.82% * 100;
 Minibatch[1801-1900]: loss = 0.453771 * 100, metric = 7.18% * 100;
 Minibatch[1901-2000]: loss = 0.455244 * 100, metric = 7.04% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.466100 * 2000, metric = 7.27% * 2000 897.544s (  2.2 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 14.19% * 2000;
0.594922428958118
 Minibatch[   1- 100]: loss = 0.477132 * 100, metric = 7.64% * 100;
 Minibatch[ 101- 200]: loss = 0.462799 * 100, metric = 6.93% * 100;
 Minibatch[ 201- 300]: loss = 0.469546 * 100, metric = 7.20% * 100;
 Minibatch[ 301- 400]: loss = 0.458044 * 100, metric = 7.04% * 100;
 Minibatch[ 401- 500]: loss = 0.444710 * 100, metric = 6.78% * 100;
 Minibatch[ 501- 600]: loss = 0.456497 * 100, metric = 7.02% * 100;
 Minibatch[ 601- 700]: loss = 0.455102 * 100, metric = 7.11% * 100;
 Minibatch[ 701- 800]: loss = 0.446569 * 100, metric = 6.73% * 100;
 Minibatch[ 801- 900]: loss = 0.444673 * 100, metric = 6.75% * 100;
 Minibatch[ 901-1000]: loss = 0.457448 * 100, metric = 7.01% * 100;
 Minibatch[1001-1100]: loss = 0.435093 * 100, metric = 6.49% * 100;
 Minibatch[1101-1200]: loss = 0.446118 * 100, metric = 6.74% * 100;
 Minibatch[1201-1300]: loss = 0.444340 * 100, metric = 6.63% * 100;
 Minibatch[1301-1400]: loss = 0.446059 * 100, metric = 6.72% * 100;
 Minibatch[1401-1500]: loss = 0.443555 * 100, metric = 6.81% * 100;
 Minibatch[1501-1600]: loss = 0.444219 * 100, metric = 6.72% * 100;
 Minibatch[1601-1700]: loss = 0.447574 * 100, metric = 6.90% * 100;
 Minibatch[1701-1800]: loss = 0.471783 * 100, metric = 7.30% * 100;
 Minibatch[1801-1900]: loss = 0.460951 * 100, metric = 7.20% * 100;
 Minibatch[1901-2000]: loss = 0.439106 * 100, metric = 6.73% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.452566 * 2000, metric = 6.92% * 2000 902.661s (  2.2 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.84% * 2000;
 Minibatch[   1- 100]: loss = 0.440083 * 100, metric = 6.77% * 100;
 Minibatch[ 101- 200]: loss = 0.453833 * 100, metric = 6.89% * 100;
 Minibatch[ 201- 300]: loss = 0.451128 * 100, metric = 6.91% * 100;
 Minibatch[ 301- 400]: loss = 0.447511 * 100, metric = 6.67% * 100;
 Minibatch[ 401- 500]: loss = 0.460168 * 100, metric = 6.85% * 100;
 Minibatch[ 501- 600]: loss = 0.447415 * 100, metric = 6.83% * 100;
 Minibatch[ 601- 700]: loss = 0.430225 * 100, metric = 6.23% * 100;
 Minibatch[ 701- 800]: loss = 0.440377 * 100, metric = 6.53% * 100;
 Minibatch[ 801- 900]: loss = 0.443770 * 100, metric = 6.66% * 100;
 Minibatch[ 901-1000]: loss = 0.436279 * 100, metric = 6.39% * 100;
 Minibatch[1001-1100]: loss = 0.425732 * 100, metric = 6.28% * 100;
 Minibatch[1101-1200]: loss = 0.449094 * 100, metric = 6.95% * 100;
 Minibatch[1201-1300]: loss = 0.451365 * 100, metric = 6.87% * 100;
 Minibatch[1301-1400]: loss = 0.427512 * 100, metric = 6.55% * 100;
 Minibatch[1401-1500]: loss = 0.436612 * 100, metric = 6.69% * 100;
 Minibatch[1501-1600]: loss = 0.435499 * 100, metric = 6.39% * 100;
 Minibatch[1601-1700]: loss = 0.443101 * 100, metric = 6.63% * 100;
 Minibatch[1701-1800]: loss = 0.422535 * 100, metric = 6.31% * 100;
 Minibatch[1801-1900]: loss = 0.445990 * 100, metric = 6.85% * 100;
 Minibatch[1901-2000]: loss = 0.456160 * 100, metric = 7.08% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.442219 * 2000, metric = 6.67% * 2000 896.482s (  2.2 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 13.36% * 2000;
0.5928620903119445
 Minibatch[   1- 100]: loss = 0.426649 * 100, metric = 6.29% * 100;
 Minibatch[ 101- 200]: loss = 0.446222 * 100, metric = 6.59% * 100;
 Minibatch[ 201- 300]: loss = 0.432751 * 100, metric = 6.53% * 100;
 Minibatch[ 301- 400]: loss = 0.432217 * 100, metric = 6.44% * 100;
 Minibatch[ 401- 500]: loss = 0.417608 * 100, metric = 6.21% * 100;
 Minibatch[ 501- 600]: loss = 0.429916 * 100, metric = 6.46% * 100;
 Minibatch[ 601- 700]: loss = 0.435721 * 100, metric = 6.60% * 100;
 Minibatch[ 701- 800]: loss = 0.422288 * 100, metric = 6.37% * 100;
 Minibatch[ 801- 900]: loss = 0.438224 * 100, metric = 6.48% * 100;
 Minibatch[ 901-1000]: loss = 0.436374 * 100, metric = 6.48% * 100;
 Minibatch[1001-1100]: loss = 0.447600 * 100, metric = 6.90% * 100;
 Minibatch[1101-1200]: loss = 0.440116 * 100, metric = 6.46% * 100;
 Minibatch[1201-1300]: loss = 0.449391 * 100, metric = 6.87% * 100;
 Minibatch[1301-1400]: loss = 0.452568 * 100, metric = 6.89% * 100;
 Minibatch[1401-1500]: loss = 0.423447 * 100, metric = 6.22% * 100;
 Minibatch[1501-1600]: loss = 0.440594 * 100, metric = 6.46% * 100;
 Minibatch[1601-1700]: loss = 0.417749 * 100, metric = 6.02% * 100;
 Minibatch[1701-1800]: loss = 0.438391 * 100, metric = 6.45% * 100;
 Minibatch[1801-1900]: loss = 0.420570 * 100, metric = 6.43% * 100;
 Minibatch[1901-2000]: loss = 0.425607 * 100, metric = 6.21% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.433700 * 2000, metric = 6.47% * 2000 892.379s (  2.2 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.34% * 2000;
 Minibatch[   1- 100]: loss = 0.443240 * 100, metric = 6.96% * 100;
 Minibatch[ 101- 200]: loss = 0.452462 * 100, metric = 6.79% * 100;
 Minibatch[ 201- 300]: loss = 0.422237 * 100, metric = 6.07% * 100;
 Minibatch[ 301- 400]: loss = 0.439247 * 100, metric = 6.43% * 100;
 Minibatch[ 401- 500]: loss = 0.439100 * 100, metric = 6.51% * 100;
 Minibatch[ 501- 600]: loss = 0.423235 * 100, metric = 6.09% * 100;
 Minibatch[ 601- 700]: loss = 0.445434 * 100, metric = 6.57% * 100;
 Minibatch[ 701- 800]: loss = 0.421587 * 100, metric = 6.17% * 100;
 Minibatch[ 801- 900]: loss = 0.451931 * 100, metric = 6.73% * 100;
 Minibatch[ 901-1000]: loss = 0.428482 * 100, metric = 6.33% * 100;
 Minibatch[1001-1100]: loss = 0.447520 * 100, metric = 6.80% * 100;
 Minibatch[1101-1200]: loss = 0.435289 * 100, metric = 6.63% * 100;
 Minibatch[1201-1300]: loss = 0.428417 * 100, metric = 6.38% * 100;
 Minibatch[1301-1400]: loss = 0.430166 * 100, metric = 6.20% * 100;
 Minibatch[1401-1500]: loss = 0.443078 * 100, metric = 6.85% * 100;
 Minibatch[1501-1600]: loss = 0.435071 * 100, metric = 6.50% * 100;
 Minibatch[1601-1700]: loss = 0.424225 * 100, metric = 6.39% * 100;
 Minibatch[1701-1800]: loss = 0.416039 * 100, metric = 6.22% * 100;
 Minibatch[1801-1900]: loss = 0.419443 * 100, metric = 6.03% * 100;
 Minibatch[1901-2000]: loss = 0.425448 * 100, metric = 6.10% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.433583 * 2000, metric = 6.44% * 2000 898.507s (  2.2 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 14.68% * 2000;
 Minibatch[   1- 100]: loss = 0.429330 * 100, metric = 6.20% * 100;
 Minibatch[ 101- 200]: loss = 0.427745 * 100, metric = 6.32% * 100;
 Minibatch[ 201- 300]: loss = 0.431789 * 100, metric = 6.33% * 100;
 Minibatch[ 301- 400]: loss = 0.437540 * 100, metric = 6.39% * 100;
 Minibatch[ 401- 500]: loss = 0.428279 * 100, metric = 6.28% * 100;
 Minibatch[ 501- 600]: loss = 0.433320 * 100, metric = 6.37% * 100;
 Minibatch[ 601- 700]: loss = 0.441536 * 100, metric = 6.80% * 100;
 Minibatch[ 701- 800]: loss = 0.426051 * 100, metric = 6.47% * 100;
 Minibatch[ 801- 900]: loss = 0.435750 * 100, metric = 6.24% * 100;
 Minibatch[ 901-1000]: loss = 0.437110 * 100, metric = 6.45% * 100;
 Minibatch[1001-1100]: loss = 0.417228 * 100, metric = 6.02% * 100;
 Minibatch[1101-1200]: loss = 0.437554 * 100, metric = 6.51% * 100;
 Minibatch[1201-1300]: loss = 0.435102 * 100, metric = 6.50% * 100;
 Minibatch[1301-1400]: loss = 0.436765 * 100, metric = 6.73% * 100;
 Minibatch[1401-1500]: loss = 0.420026 * 100, metric = 6.38% * 100;
 Minibatch[1501-1600]: loss = 0.434476 * 100, metric = 6.49% * 100;
 Minibatch[1601-1700]: loss = 0.422230 * 100, metric = 6.07% * 100;
 Minibatch[1701-1800]: loss = 0.431740 * 100, metric = 6.47% * 100;
 Minibatch[1801-1900]: loss = 0.422866 * 100, metric = 6.41% * 100;
 Minibatch[1901-2000]: loss = 0.427716 * 100, metric = 6.38% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.430708 * 2000, metric = 6.39% * 2000 890.466s (  2.2 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 14.79% * 2000;
 Minibatch[   1- 100]: loss = 0.429810 * 100, metric = 6.27% * 100;
 Minibatch[ 101- 200]: loss = 0.420128 * 100, metric = 6.03% * 100;
 Minibatch[ 201- 300]: loss = 0.421904 * 100, metric = 6.26% * 100;
 Minibatch[ 301- 400]: loss = 0.430386 * 100, metric = 6.31% * 100;
 Minibatch[ 401- 500]: loss = 0.417799 * 100, metric = 6.10% * 100;
 Minibatch[ 501- 600]: loss = 0.420126 * 100, metric = 6.16% * 100;
 Minibatch[ 601- 700]: loss = 0.411363 * 100, metric = 5.89% * 100;
 Minibatch[ 701- 800]: loss = 0.400273 * 100, metric = 5.81% * 100;
 Minibatch[ 801- 900]: loss = 0.428587 * 100, metric = 6.19% * 100;
 Minibatch[ 901-1000]: loss = 0.414196 * 100, metric = 6.00% * 100;
 Minibatch[1001-1100]: loss = 0.414550 * 100, metric = 5.87% * 100;
 Minibatch[1101-1200]: loss = 0.403143 * 100, metric = 5.70% * 100;
 Minibatch[1201-1300]: loss = 0.413677 * 100, metric = 5.98% * 100;
 Minibatch[1301-1400]: loss = 0.405096 * 100, metric = 5.78% * 100;
 Minibatch[1401-1500]: loss = 0.418820 * 100, metric = 6.14% * 100;
 Minibatch[1501-1600]: loss = 0.423174 * 100, metric = 6.45% * 100;
 Minibatch[1601-1700]: loss = 0.413986 * 100, metric = 6.08% * 100;
 Minibatch[1701-1800]: loss = 0.416530 * 100, metric = 6.05% * 100;
 Minibatch[1801-1900]: loss = 0.437012 * 100, metric = 6.66% * 100;
 Minibatch[1901-2000]: loss = 0.405345 * 100, metric = 5.86% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.417295 * 2000, metric = 6.08% * 2000 889.350s (  2.2 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 13.59% * 2000;
 Minibatch[   1- 100]: loss = 0.431085 * 100, metric = 6.21% * 100;
 Minibatch[ 101- 200]: loss = 0.420857 * 100, metric = 6.03% * 100;
 Minibatch[ 201- 300]: loss = 0.426987 * 100, metric = 6.18% * 100;
 Minibatch[ 301- 400]: loss = 0.423505 * 100, metric = 6.28% * 100;
 Minibatch[ 401- 500]: loss = 0.414314 * 100, metric = 6.03% * 100;
 Minibatch[ 501- 600]: loss = 0.429710 * 100, metric = 6.07% * 100;
 Minibatch[ 601- 700]: loss = 0.417849 * 100, metric = 6.02% * 100;
 Minibatch[ 701- 800]: loss = 0.424275 * 100, metric = 6.21% * 100;
 Minibatch[ 801- 900]: loss = 0.429503 * 100, metric = 6.35% * 100;
 Minibatch[ 901-1000]: loss = 0.434881 * 100, metric = 6.44% * 100;
 Minibatch[1001-1100]: loss = 0.418860 * 100, metric = 6.02% * 100;
 Minibatch[1101-1200]: loss = 0.404171 * 100, metric = 5.68% * 100;
 Minibatch[1201-1300]: loss = 0.414205 * 100, metric = 6.07% * 100;
 Minibatch[1301-1400]: loss = 0.415981 * 100, metric = 5.99% * 100;
 Minibatch[1401-1500]: loss = 0.412119 * 100, metric = 6.19% * 100;
 Minibatch[1501-1600]: loss = 0.409283 * 100, metric = 5.88% * 100;
 Minibatch[1601-1700]: loss = 0.412705 * 100, metric = 6.04% * 100;
 Minibatch[1701-1800]: loss = 0.415499 * 100, metric = 6.09% * 100;
 Minibatch[1801-1900]: loss = 0.414743 * 100, metric = 6.07% * 100;
 Minibatch[1901-2000]: loss = 0.417888 * 100, metric = 6.14% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.419421 * 2000, metric = 6.10% * 2000 895.193s (  2.2 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 14.36% * 2000;
 Minibatch[   1- 100]: loss = 0.424022 * 100, metric = 6.10% * 100;
 Minibatch[ 101- 200]: loss = 0.422823 * 100, metric = 6.19% * 100;
 Minibatch[ 201- 300]: loss = 0.416534 * 100, metric = 6.00% * 100;
 Minibatch[ 301- 400]: loss = 0.419351 * 100, metric = 6.09% * 100;
 Minibatch[ 401- 500]: loss = 0.422812 * 100, metric = 6.39% * 100;
 Minibatch[ 501- 600]: loss = 0.412382 * 100, metric = 5.90% * 100;
 Minibatch[ 601- 700]: loss = 0.416579 * 100, metric = 6.18% * 100;
 Minibatch[ 701- 800]: loss = 0.405700 * 100, metric = 5.87% * 100;
 Minibatch[ 801- 900]: loss = 0.400048 * 100, metric = 6.06% * 100;
 Minibatch[ 901-1000]: loss = 0.423099 * 100, metric = 6.11% * 100;
 Minibatch[1001-1100]: loss = 0.402606 * 100, metric = 5.67% * 100;
 Minibatch[1101-1200]: loss = 0.411501 * 100, metric = 5.86% * 100;
 Minibatch[1201-1300]: loss = 0.414633 * 100, metric = 6.04% * 100;
 Minibatch[1301-1400]: loss = 0.423104 * 100, metric = 6.17% * 100;
 Minibatch[1401-1500]: loss = 0.403818 * 100, metric = 5.80% * 100;
 Minibatch[1501-1600]: loss = 0.410872 * 100, metric = 5.82% * 100;
 Minibatch[1601-1700]: loss = 0.407603 * 100, metric = 5.86% * 100;
 Minibatch[1701-1800]: loss = 0.414464 * 100, metric = 5.90% * 100;
 Minibatch[1801-1900]: loss = 0.414760 * 100, metric = 6.10% * 100;
 Minibatch[1901-2000]: loss = 0.428373 * 100, metric = 6.30% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.414754 * 2000, metric = 6.02% * 2000 892.473s (  2.2 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 15.55% * 2000;
 Minibatch[   1- 100]: loss = 0.397589 * 100, metric = 5.72% * 100;
 Minibatch[ 101- 200]: loss = 0.421859 * 100, metric = 6.25% * 100;
 Minibatch[ 201- 300]: loss = 0.408813 * 100, metric = 6.08% * 100;
 Minibatch[ 301- 400]: loss = 0.410902 * 100, metric = 5.95% * 100;
 Minibatch[ 401- 500]: loss = 0.412481 * 100, metric = 6.13% * 100;
 Minibatch[ 501- 600]: loss = 0.398854 * 100, metric = 5.80% * 100;
 Minibatch[ 601- 700]: loss = 0.422838 * 100, metric = 6.13% * 100;
 Minibatch[ 701- 800]: loss = 0.409589 * 100, metric = 5.95% * 100;
 Minibatch[ 801- 900]: loss = 0.417379 * 100, metric = 6.12% * 100;
 Minibatch[ 901-1000]: loss = 0.416830 * 100, metric = 6.12% * 100;
 Minibatch[1001-1100]: loss = 0.407990 * 100, metric = 5.76% * 100;
 Minibatch[1101-1200]: loss = 0.417656 * 100, metric = 6.13% * 100;
 Minibatch[1201-1300]: loss = 0.411106 * 100, metric = 5.98% * 100;
 Minibatch[1301-1400]: loss = 0.404505 * 100, metric = 5.71% * 100;
 Minibatch[1401-1500]: loss = 0.403655 * 100, metric = 5.73% * 100;
 Minibatch[1501-1600]: loss = 0.407511 * 100, metric = 5.83% * 100;
 Minibatch[1601-1700]: loss = 0.400416 * 100, metric = 5.73% * 100;
 Minibatch[1701-1800]: loss = 0.402780 * 100, metric = 5.80% * 100;
 Minibatch[1801-1900]: loss = 0.408808 * 100, metric = 5.94% * 100;
 Minibatch[1901-2000]: loss = 0.405849 * 100, metric = 5.85% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.409371 * 2000, metric = 5.94% * 2000 896.861s (  2.2 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 13.51% * 2000;
 Minibatch[   1- 100]: loss = 0.413464 * 100, metric = 5.93% * 100;
 Minibatch[ 101- 200]: loss = 0.411920 * 100, metric = 5.98% * 100;
 Minibatch[ 201- 300]: loss = 0.407240 * 100, metric = 5.93% * 100;
 Minibatch[ 301- 400]: loss = 0.412836 * 100, metric = 6.12% * 100;
 Minibatch[ 401- 500]: loss = 0.413254 * 100, metric = 6.06% * 100;
 Minibatch[ 501- 600]: loss = 0.409228 * 100, metric = 5.95% * 100;
 Minibatch[ 601- 700]: loss = 0.407910 * 100, metric = 5.84% * 100;
 Minibatch[ 701- 800]: loss = 0.399585 * 100, metric = 5.62% * 100;
 Minibatch[ 801- 900]: loss = 0.405843 * 100, metric = 6.05% * 100;
 Minibatch[ 901-1000]: loss = 0.411530 * 100, metric = 6.11% * 100;
 Minibatch[1001-1100]: loss = 0.410768 * 100, metric = 5.92% * 100;
 Minibatch[1101-1200]: loss = 0.411693 * 100, metric = 6.09% * 100;
 Minibatch[1201-1300]: loss = 0.420464 * 100, metric = 6.47% * 100;
 Minibatch[1301-1400]: loss = 0.397444 * 100, metric = 5.58% * 100;
 Minibatch[1401-1500]: loss = 0.398167 * 100, metric = 5.61% * 100;
 Minibatch[1501-1600]: loss = 0.411544 * 100, metric = 6.13% * 100;
 Minibatch[1601-1700]: loss = 0.402333 * 100, metric = 5.86% * 100;
 Minibatch[1701-1800]: loss = 0.404701 * 100, metric = 5.87% * 100;
 Minibatch[1801-1900]: loss = 0.396817 * 100, metric = 5.62% * 100;
 Minibatch[1901-2000]: loss = 0.389691 * 100, metric = 5.47% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.406822 * 2000, metric = 5.91% * 2000 889.285s (  2.2 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.43% * 2000;
 Minibatch[   1- 100]: loss = 0.399698 * 100, metric = 5.59% * 100;
 Minibatch[ 101- 200]: loss = 0.386613 * 100, metric = 5.48% * 100;
 Minibatch[ 201- 300]: loss = 0.396052 * 100, metric = 5.48% * 100;
 Minibatch[ 301- 400]: loss = 0.395376 * 100, metric = 5.56% * 100;
 Minibatch[ 401- 500]: loss = 0.400350 * 100, metric = 5.83% * 100;
 Minibatch[ 501- 600]: loss = 0.398909 * 100, metric = 5.77% * 100;
 Minibatch[ 601- 700]: loss = 0.411989 * 100, metric = 5.95% * 100;
 Minibatch[ 701- 800]: loss = 0.395790 * 100, metric = 5.74% * 100;
 Minibatch[ 801- 900]: loss = 0.389557 * 100, metric = 5.48% * 100;
 Minibatch[ 901-1000]: loss = 0.395668 * 100, metric = 5.59% * 100;
 Minibatch[1001-1100]: loss = 0.407310 * 100, metric = 5.90% * 100;
 Minibatch[1101-1200]: loss = 0.411549 * 100, metric = 5.85% * 100;
 Minibatch[1201-1300]: loss = 0.398622 * 100, metric = 5.65% * 100;
 Minibatch[1301-1400]: loss = 0.385434 * 100, metric = 5.23% * 100;
 Minibatch[1401-1500]: loss = 0.396586 * 100, metric = 5.65% * 100;
 Minibatch[1501-1600]: loss = 0.399389 * 100, metric = 5.45% * 100;
 Minibatch[1601-1700]: loss = 0.413878 * 100, metric = 6.05% * 100;
 Minibatch[1701-1800]: loss = 0.409807 * 100, metric = 5.82% * 100;
 Minibatch[1801-1900]: loss = 0.397165 * 100, metric = 5.67% * 100;
 Minibatch[1901-2000]: loss = 0.401976 * 100, metric = 5.68% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.399586 * 2000, metric = 5.67% * 2000 893.247s (  2.2 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.17% * 2000;
 Minibatch[   1- 100]: loss = 0.395510 * 100, metric = 5.54% * 100;
 Minibatch[ 101- 200]: loss = 0.402114 * 100, metric = 5.70% * 100;
 Minibatch[ 201- 300]: loss = 0.386285 * 100, metric = 5.39% * 100;
 Minibatch[ 301- 400]: loss = 0.389090 * 100, metric = 5.37% * 100;
 Minibatch[ 401- 500]: loss = 0.390198 * 100, metric = 5.48% * 100;
 Minibatch[ 501- 600]: loss = 0.386730 * 100, metric = 5.56% * 100;
 Minibatch[ 601- 700]: loss = 0.390092 * 100, metric = 5.54% * 100;
 Minibatch[ 701- 800]: loss = 0.389738 * 100, metric = 5.43% * 100;
 Minibatch[ 801- 900]: loss = 0.403084 * 100, metric = 5.63% * 100;
 Minibatch[ 901-1000]: loss = 0.395513 * 100, metric = 5.66% * 100;
 Minibatch[1001-1100]: loss = 0.390522 * 100, metric = 5.21% * 100;
 Minibatch[1101-1200]: loss = 0.396605 * 100, metric = 5.49% * 100;
 Minibatch[1201-1300]: loss = 0.392529 * 100, metric = 5.53% * 100;
 Minibatch[1301-1400]: loss = 0.401083 * 100, metric = 5.79% * 100;
 Minibatch[1401-1500]: loss = 0.387189 * 100, metric = 5.53% * 100;
 Minibatch[1501-1600]: loss = 0.393173 * 100, metric = 5.62% * 100;
 Minibatch[1601-1700]: loss = 0.373136 * 100, metric = 5.01% * 100;
 Minibatch[1701-1800]: loss = 0.384462 * 100, metric = 5.43% * 100;
 Minibatch[1801-1900]: loss = 0.385494 * 100, metric = 5.35% * 100;
 Minibatch[1901-2000]: loss = 0.385978 * 100, metric = 5.20% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.390926 * 2000, metric = 5.47% * 2000 881.821s (  2.3 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.90% * 2000;
 Minibatch[   1- 100]: loss = 0.394432 * 100, metric = 5.67% * 100;
 Minibatch[ 101- 200]: loss = 0.384436 * 100, metric = 5.18% * 100;
 Minibatch[ 201- 300]: loss = 0.393704 * 100, metric = 5.49% * 100;
 Minibatch[ 301- 400]: loss = 0.392281 * 100, metric = 5.35% * 100;
 Minibatch[ 401- 500]: loss = 0.388722 * 100, metric = 5.45% * 100;
 Minibatch[ 501- 600]: loss = 0.407407 * 100, metric = 5.75% * 100;
 Minibatch[ 601- 700]: loss = 0.390280 * 100, metric = 5.56% * 100;
 Minibatch[ 701- 800]: loss = 0.376302 * 100, metric = 5.22% * 100;
 Minibatch[ 801- 900]: loss = 0.394814 * 100, metric = 5.52% * 100;
 Minibatch[ 901-1000]: loss = 0.402954 * 100, metric = 5.80% * 100;
 Minibatch[1001-1100]: loss = 0.389467 * 100, metric = 5.47% * 100;
 Minibatch[1101-1200]: loss = 0.390168 * 100, metric = 5.39% * 100;
 Minibatch[1201-1300]: loss = 0.390789 * 100, metric = 5.50% * 100;
 Minibatch[1301-1400]: loss = 0.379962 * 100, metric = 5.28% * 100;
 Minibatch[1401-1500]: loss = 0.394600 * 100, metric = 5.49% * 100;
 Minibatch[1501-1600]: loss = 0.387845 * 100, metric = 5.32% * 100;
 Minibatch[1601-1700]: loss = 0.389290 * 100, metric = 5.26% * 100;
 Minibatch[1701-1800]: loss = 0.385569 * 100, metric = 5.23% * 100;
 Minibatch[1801-1900]: loss = 0.389771 * 100, metric = 5.46% * 100;
 Minibatch[1901-2000]: loss = 0.399077 * 100, metric = 5.68% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.391093 * 2000, metric = 5.45% * 2000 885.311s (  2.3 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.20% * 2000;
0.5909496727958321
 Minibatch[   1- 100]: loss = 0.380824 * 100, metric = 5.09% * 100;
 Minibatch[ 101- 200]: loss = 0.379056 * 100, metric = 5.31% * 100;
 Minibatch[ 201- 300]: loss = 0.387628 * 100, metric = 5.62% * 100;
 Minibatch[ 301- 400]: loss = 0.402894 * 100, metric = 5.64% * 100;
 Minibatch[ 401- 500]: loss = 0.381524 * 100, metric = 5.32% * 100;
 Minibatch[ 501- 600]: loss = 0.394162 * 100, metric = 5.58% * 100;
 Minibatch[ 601- 700]: loss = 0.379957 * 100, metric = 5.25% * 100;
 Minibatch[ 701- 800]: loss = 0.384088 * 100, metric = 5.44% * 100;
 Minibatch[ 801- 900]: loss = 0.380469 * 100, metric = 5.27% * 100;
 Minibatch[ 901-1000]: loss = 0.391450 * 100, metric = 5.44% * 100;
 Minibatch[1001-1100]: loss = 0.386334 * 100, metric = 5.41% * 100;
 Minibatch[1101-1200]: loss = 0.381415 * 100, metric = 5.26% * 100;
 Minibatch[1201-1300]: loss = 0.380102 * 100, metric = 5.30% * 100;
 Minibatch[1301-1400]: loss = 0.375444 * 100, metric = 5.15% * 100;
 Minibatch[1401-1500]: loss = 0.399821 * 100, metric = 5.57% * 100;
 Minibatch[1501-1600]: loss = 0.364619 * 100, metric = 4.85% * 100;
 Minibatch[1601-1700]: loss = 0.381700 * 100, metric = 5.36% * 100;
 Minibatch[1701-1800]: loss = 0.370134 * 100, metric = 5.10% * 100;
 Minibatch[1801-1900]: loss = 0.393930 * 100, metric = 5.37% * 100;
 Minibatch[1901-2000]: loss = 0.382260 * 100, metric = 5.16% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.383891 * 2000, metric = 5.32% * 2000 884.347s (  2.3 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 15.14% * 2000;
 Minibatch[   1- 100]: loss = 0.400817 * 100, metric = 5.60% * 100;
 Minibatch[ 101- 200]: loss = 0.369037 * 100, metric = 4.95% * 100;
 Minibatch[ 201- 300]: loss = 0.382667 * 100, metric = 5.26% * 100;
 Minibatch[ 301- 400]: loss = 0.392823 * 100, metric = 5.65% * 100;
 Minibatch[ 401- 500]: loss = 0.388904 * 100, metric = 5.37% * 100;
 Minibatch[ 501- 600]: loss = 0.368114 * 100, metric = 4.85% * 100;
 Minibatch[ 601- 700]: loss = 0.380858 * 100, metric = 5.33% * 100;
 Minibatch[ 701- 800]: loss = 0.373783 * 100, metric = 5.23% * 100;
 Minibatch[ 801- 900]: loss = 0.387434 * 100, metric = 5.47% * 100;
 Minibatch[ 901-1000]: loss = 0.369767 * 100, metric = 4.99% * 100;
 Minibatch[1001-1100]: loss = 0.381687 * 100, metric = 5.33% * 100;
 Minibatch[1101-1200]: loss = 0.385577 * 100, metric = 5.30% * 100;
 Minibatch[1201-1300]: loss = 0.373224 * 100, metric = 5.15% * 100;
 Minibatch[1301-1400]: loss = 0.386473 * 100, metric = 5.54% * 100;
 Minibatch[1401-1500]: loss = 0.381694 * 100, metric = 5.25% * 100;
 Minibatch[1501-1600]: loss = 0.393233 * 100, metric = 5.48% * 100;
 Minibatch[1601-1700]: loss = 0.387332 * 100, metric = 5.37% * 100;
 Minibatch[1701-1800]: loss = 0.384778 * 100, metric = 5.43% * 100;
 Minibatch[1801-1900]: loss = 0.378714 * 100, metric = 5.33% * 100;
 Minibatch[1901-2000]: loss = 0.396022 * 100, metric = 5.69% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.383147 * 2000, metric = 5.33% * 2000 888.178s (  2.3 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 13.99% * 2000;
 Minibatch[   1- 100]: loss = 0.375415 * 100, metric = 5.08% * 100;
 Minibatch[ 101- 200]: loss = 0.386901 * 100, metric = 5.61% * 100;
 Minibatch[ 201- 300]: loss = 0.380046 * 100, metric = 5.25% * 100;
 Minibatch[ 301- 400]: loss = 0.371270 * 100, metric = 5.09% * 100;
 Minibatch[ 401- 500]: loss = 0.377869 * 100, metric = 5.20% * 100;
 Minibatch[ 501- 600]: loss = 0.376750 * 100, metric = 5.24% * 100;
 Minibatch[ 601- 700]: loss = 0.397987 * 100, metric = 5.63% * 100;
 Minibatch[ 701- 800]: loss = 0.394417 * 100, metric = 5.49% * 100;
 Minibatch[ 801- 900]: loss = 0.379209 * 100, metric = 4.95% * 100;
 Minibatch[ 901-1000]: loss = 0.371555 * 100, metric = 5.08% * 100;
 Minibatch[1001-1100]: loss = 0.376721 * 100, metric = 5.07% * 100;
 Minibatch[1101-1200]: loss = 0.375035 * 100, metric = 5.21% * 100;
 Minibatch[1201-1300]: loss = 0.374331 * 100, metric = 5.00% * 100;
 Minibatch[1301-1400]: loss = 0.378600 * 100, metric = 5.23% * 100;
 Minibatch[1401-1500]: loss = 0.388766 * 100, metric = 5.47% * 100;
 Minibatch[1501-1600]: loss = 0.371573 * 100, metric = 5.22% * 100;
 Minibatch[1601-1700]: loss = 0.377515 * 100, metric = 5.22% * 100;
 Minibatch[1701-1800]: loss = 0.374222 * 100, metric = 4.96% * 100;
 Minibatch[1801-1900]: loss = 0.375306 * 100, metric = 5.25% * 100;
 Minibatch[1901-2000]: loss = 0.375871 * 100, metric = 5.26% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.378968 * 2000, metric = 5.23% * 2000 891.436s (  2.2 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 13.53% * 2000;
 Minibatch[   1- 100]: loss = 0.380821 * 100, metric = 5.26% * 100;
 Minibatch[ 101- 200]: loss = 0.385097 * 100, metric = 5.46% * 100;
 Minibatch[ 201- 300]: loss = 0.387281 * 100, metric = 5.55% * 100;
 Minibatch[ 301- 400]: loss = 0.391933 * 100, metric = 5.41% * 100;
 Minibatch[ 401- 500]: loss = 0.378050 * 100, metric = 5.19% * 100;
 Minibatch[ 501- 600]: loss = 0.378675 * 100, metric = 5.34% * 100;
 Minibatch[ 601- 700]: loss = 0.370989 * 100, metric = 5.08% * 100;
 Minibatch[ 701- 800]: loss = 0.373059 * 100, metric = 5.10% * 100;
 Minibatch[ 801- 900]: loss = 0.373547 * 100, metric = 5.00% * 100;
 Minibatch[ 901-1000]: loss = 0.365785 * 100, metric = 5.04% * 100;
 Minibatch[1001-1100]: loss = 0.372668 * 100, metric = 5.01% * 100;
 Minibatch[1101-1200]: loss = 0.378571 * 100, metric = 5.10% * 100;
 Minibatch[1201-1300]: loss = 0.385548 * 100, metric = 5.46% * 100;
 Minibatch[1301-1400]: loss = 0.372489 * 100, metric = 5.08% * 100;
 Minibatch[1401-1500]: loss = 0.372674 * 100, metric = 5.28% * 100;
 Minibatch[1501-1600]: loss = 0.379712 * 100, metric = 5.27% * 100;
 Minibatch[1601-1700]: loss = 0.373934 * 100, metric = 5.19% * 100;
 Minibatch[1701-1800]: loss = 0.391702 * 100, metric = 5.58% * 100;
 Minibatch[1801-1900]: loss = 0.370872 * 100, metric = 5.00% * 100;
 Minibatch[1901-2000]: loss = 0.376364 * 100, metric = 5.30% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.377988 * 2000, metric = 5.24% * 2000 889.624s (  2.2 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.52% * 2000;
 Minibatch[   1- 100]: loss = 0.387970 * 100, metric = 5.43% * 100;
 Minibatch[ 101- 200]: loss = 0.377086 * 100, metric = 5.36% * 100;
 Minibatch[ 201- 300]: loss = 0.359208 * 100, metric = 4.81% * 100;
 Minibatch[ 301- 400]: loss = 0.375909 * 100, metric = 5.28% * 100;
 Minibatch[ 401- 500]: loss = 0.368879 * 100, metric = 5.00% * 100;
 Minibatch[ 501- 600]: loss = 0.374922 * 100, metric = 5.06% * 100;
 Minibatch[ 601- 700]: loss = 0.378920 * 100, metric = 5.31% * 100;
 Minibatch[ 701- 800]: loss = 0.374547 * 100, metric = 5.04% * 100;
 Minibatch[ 801- 900]: loss = 0.373420 * 100, metric = 5.06% * 100;
 Minibatch[ 901-1000]: loss = 0.358594 * 100, metric = 4.75% * 100;
 Minibatch[1001-1100]: loss = 0.371786 * 100, metric = 5.00% * 100;
 Minibatch[1101-1200]: loss = 0.353109 * 100, metric = 4.73% * 100;
 Minibatch[1201-1300]: loss = 0.381385 * 100, metric = 5.02% * 100;
 Minibatch[1301-1400]: loss = 0.361711 * 100, metric = 4.81% * 100;
 Minibatch[1401-1500]: loss = 0.378495 * 100, metric = 5.12% * 100;
 Minibatch[1501-1600]: loss = 0.383748 * 100, metric = 5.23% * 100;
 Minibatch[1601-1700]: loss = 0.371384 * 100, metric = 4.93% * 100;
 Minibatch[1701-1800]: loss = 0.362584 * 100, metric = 4.83% * 100;
 Minibatch[1801-1900]: loss = 0.361568 * 100, metric = 4.94% * 100;
 Minibatch[1901-2000]: loss = 0.378896 * 100, metric = 5.49% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.371706 * 2000, metric = 5.06% * 2000 894.782s (  2.2 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.13% * 2000;
 Minibatch[   1- 100]: loss = 0.364123 * 100, metric = 4.86% * 100;
 Minibatch[ 101- 200]: loss = 0.374793 * 100, metric = 5.16% * 100;
 Minibatch[ 201- 300]: loss = 0.363197 * 100, metric = 4.88% * 100;
 Minibatch[ 301- 400]: loss = 0.374026 * 100, metric = 5.22% * 100;
 Minibatch[ 401- 500]: loss = 0.359489 * 100, metric = 4.85% * 100;
 Minibatch[ 501- 600]: loss = 0.373348 * 100, metric = 5.15% * 100;
 Minibatch[ 601- 700]: loss = 0.374407 * 100, metric = 5.05% * 100;
 Minibatch[ 701- 800]: loss = 0.367658 * 100, metric = 4.97% * 100;
 Minibatch[ 801- 900]: loss = 0.356053 * 100, metric = 4.60% * 100;
 Minibatch[ 901-1000]: loss = 0.359696 * 100, metric = 4.96% * 100;
 Minibatch[1001-1100]: loss = 0.369543 * 100, metric = 5.01% * 100;
 Minibatch[1101-1200]: loss = 0.361937 * 100, metric = 5.06% * 100;
 Minibatch[1201-1300]: loss = 0.366110 * 100, metric = 5.02% * 100;
 Minibatch[1301-1400]: loss = 0.367433 * 100, metric = 5.09% * 100;
 Minibatch[1401-1500]: loss = 0.377723 * 100, metric = 5.47% * 100;
 Minibatch[1501-1600]: loss = 0.371534 * 100, metric = 5.02% * 100;
 Minibatch[1601-1700]: loss = 0.384012 * 100, metric = 5.27% * 100;
 Minibatch[1701-1800]: loss = 0.370952 * 100, metric = 5.12% * 100;
 Minibatch[1801-1900]: loss = 0.364612 * 100, metric = 5.10% * 100;
 Minibatch[1901-2000]: loss = 0.364539 * 100, metric = 4.84% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.368259 * 2000, metric = 5.04% * 2000 889.820s (  2.2 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.27% * 2000;
 Minibatch[   1- 100]: loss = 0.356542 * 100, metric = 4.87% * 100;
 Minibatch[ 101- 200]: loss = 0.360632 * 100, metric = 5.01% * 100;
 Minibatch[ 201- 300]: loss = 0.367920 * 100, metric = 5.00% * 100;
 Minibatch[ 301- 400]: loss = 0.349765 * 100, metric = 4.57% * 100;
 Minibatch[ 401- 500]: loss = 0.362613 * 100, metric = 4.65% * 100;
 Minibatch[ 501- 600]: loss = 0.336811 * 100, metric = 4.38% * 100;
 Minibatch[ 601- 700]: loss = 0.371623 * 100, metric = 5.19% * 100;
 Minibatch[ 701- 800]: loss = 0.350347 * 100, metric = 4.70% * 100;
 Minibatch[ 801- 900]: loss = 0.376356 * 100, metric = 5.24% * 100;
 Minibatch[ 901-1000]: loss = 0.359204 * 100, metric = 4.92% * 100;
 Minibatch[1001-1100]: loss = 0.368215 * 100, metric = 4.90% * 100;
 Minibatch[1101-1200]: loss = 0.357746 * 100, metric = 4.88% * 100;
 Minibatch[1201-1300]: loss = 0.368814 * 100, metric = 5.20% * 100;
 Minibatch[1301-1400]: loss = 0.368191 * 100, metric = 5.06% * 100;
 Minibatch[1401-1500]: loss = 0.358585 * 100, metric = 4.99% * 100;
 Minibatch[1501-1600]: loss = 0.372078 * 100, metric = 5.01% * 100;
 Minibatch[1601-1700]: loss = 0.367320 * 100, metric = 5.00% * 100;
 Minibatch[1701-1800]: loss = 0.360997 * 100, metric = 4.99% * 100;
 Minibatch[1801-1900]: loss = 0.369133 * 100, metric = 5.08% * 100;
 Minibatch[1901-2000]: loss = 0.357599 * 100, metric = 4.82% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.362025 * 2000, metric = 4.92% * 2000 894.302s (  2.2 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.58% * 2000;
 Minibatch[   1- 100]: loss = 0.357200 * 100, metric = 4.87% * 100;
 Minibatch[ 101- 200]: loss = 0.346274 * 100, metric = 4.54% * 100;
 Minibatch[ 201- 300]: loss = 0.369471 * 100, metric = 5.20% * 100;
 Minibatch[ 301- 400]: loss = 0.350793 * 100, metric = 4.68% * 100;
 Minibatch[ 401- 500]: loss = 0.347671 * 100, metric = 4.55% * 100;
 Minibatch[ 501- 600]: loss = 0.358419 * 100, metric = 4.79% * 100;
 Minibatch[ 601- 700]: loss = 0.365255 * 100, metric = 4.84% * 100;
 Minibatch[ 701- 800]: loss = 0.346123 * 100, metric = 4.60% * 100;
 Minibatch[ 801- 900]: loss = 0.345617 * 100, metric = 4.84% * 100;
 Minibatch[ 901-1000]: loss = 0.369976 * 100, metric = 4.95% * 100;
 Minibatch[1001-1100]: loss = 0.371873 * 100, metric = 5.05% * 100;
 Minibatch[1101-1200]: loss = 0.364450 * 100, metric = 4.99% * 100;
 Minibatch[1201-1300]: loss = 0.368316 * 100, metric = 5.02% * 100;
 Minibatch[1301-1400]: loss = 0.346966 * 100, metric = 4.80% * 100;
 Minibatch[1401-1500]: loss = 0.358192 * 100, metric = 4.81% * 100;
 Minibatch[1501-1600]: loss = 0.353654 * 100, metric = 4.67% * 100;
 Minibatch[1601-1700]: loss = 0.368083 * 100, metric = 5.05% * 100;
 Minibatch[1701-1800]: loss = 0.363966 * 100, metric = 4.96% * 100;
 Minibatch[1801-1900]: loss = 0.357589 * 100, metric = 4.75% * 100;
 Minibatch[1901-2000]: loss = 0.360764 * 100, metric = 4.80% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.358532 * 2000, metric = 4.84% * 2000 879.983s (  2.3 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.73% * 2000;
 Minibatch[   1- 100]: loss = 0.361714 * 100, metric = 4.75% * 100;
 Minibatch[ 101- 200]: loss = 0.369930 * 100, metric = 5.14% * 100;
 Minibatch[ 201- 300]: loss = 0.365269 * 100, metric = 5.08% * 100;
 Minibatch[ 301- 400]: loss = 0.364396 * 100, metric = 4.88% * 100;
 Minibatch[ 401- 500]: loss = 0.359882 * 100, metric = 5.06% * 100;
 Minibatch[ 501- 600]: loss = 0.348240 * 100, metric = 4.73% * 100;
 Minibatch[ 601- 700]: loss = 0.365755 * 100, metric = 5.04% * 100;
 Minibatch[ 701- 800]: loss = 0.372045 * 100, metric = 5.11% * 100;
 Minibatch[ 801- 900]: loss = 0.360048 * 100, metric = 4.84% * 100;
 Minibatch[ 901-1000]: loss = 0.342871 * 100, metric = 4.36% * 100;
 Minibatch[1001-1100]: loss = 0.354155 * 100, metric = 4.79% * 100;
 Minibatch[1101-1200]: loss = 0.370229 * 100, metric = 5.02% * 100;
 Minibatch[1201-1300]: loss = 0.364973 * 100, metric = 4.95% * 100;
 Minibatch[1301-1400]: loss = 0.361303 * 100, metric = 4.81% * 100;
 Minibatch[1401-1500]: loss = 0.367361 * 100, metric = 5.03% * 100;
 Minibatch[1501-1600]: loss = 0.352682 * 100, metric = 4.68% * 100;
 Minibatch[1601-1700]: loss = 0.356211 * 100, metric = 4.74% * 100;
 Minibatch[1701-1800]: loss = 0.356613 * 100, metric = 4.70% * 100;
 Minibatch[1801-1900]: loss = 0.358789 * 100, metric = 4.89% * 100;
 Minibatch[1901-2000]: loss = 0.359247 * 100, metric = 4.76% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.360586 * 2000, metric = 4.87% * 2000 889.532s (  2.2 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.68% * 2000;
 Minibatch[   1- 100]: loss = 0.367032 * 100, metric = 4.89% * 100;
 Minibatch[ 101- 200]: loss = 0.364689 * 100, metric = 5.00% * 100;
 Minibatch[ 201- 300]: loss = 0.342679 * 100, metric = 4.34% * 100;
 Minibatch[ 301- 400]: loss = 0.350752 * 100, metric = 4.62% * 100;
 Minibatch[ 401- 500]: loss = 0.359615 * 100, metric = 4.70% * 100;
 Minibatch[ 501- 600]: loss = 0.353840 * 100, metric = 4.53% * 100;
 Minibatch[ 601- 700]: loss = 0.359698 * 100, metric = 4.81% * 100;
 Minibatch[ 701- 800]: loss = 0.350298 * 100, metric = 4.70% * 100;
 Minibatch[ 801- 900]: loss = 0.362313 * 100, metric = 4.82% * 100;
 Minibatch[ 901-1000]: loss = 0.365183 * 100, metric = 4.73% * 100;
 Minibatch[1001-1100]: loss = 0.371958 * 100, metric = 4.95% * 100;
 Minibatch[1101-1200]: loss = 0.348599 * 100, metric = 4.58% * 100;
 Minibatch[1201-1300]: loss = 0.354030 * 100, metric = 4.81% * 100;
 Minibatch[1301-1400]: loss = 0.370809 * 100, metric = 4.93% * 100;
 Minibatch[1401-1500]: loss = 0.362372 * 100, metric = 4.76% * 100;
 Minibatch[1501-1600]: loss = 0.359261 * 100, metric = 4.79% * 100;
 Minibatch[1601-1700]: loss = 0.355294 * 100, metric = 4.76% * 100;
 Minibatch[1701-1800]: loss = 0.363755 * 100, metric = 4.98% * 100;
 Minibatch[1801-1900]: loss = 0.359402 * 100, metric = 4.90% * 100;
 Minibatch[1901-2000]: loss = 0.363448 * 100, metric = 4.81% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.359251 * 2000, metric = 4.77% * 2000 886.940s (  2.3 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 13.58% * 2000;
 Minibatch[   1- 100]: loss = 0.351046 * 100, metric = 4.68% * 100;
 Minibatch[ 101- 200]: loss = 0.357814 * 100, metric = 4.81% * 100;
 Minibatch[ 201- 300]: loss = 0.357612 * 100, metric = 4.57% * 100;
 Minibatch[ 301- 400]: loss = 0.351805 * 100, metric = 4.64% * 100;
 Minibatch[ 401- 500]: loss = 0.350317 * 100, metric = 4.59% * 100;
 Minibatch[ 501- 600]: loss = 0.366018 * 100, metric = 4.89% * 100;
 Minibatch[ 601- 700]: loss = 0.353408 * 100, metric = 4.82% * 100;
 Minibatch[ 701- 800]: loss = 0.357546 * 100, metric = 4.72% * 100;
 Minibatch[ 801- 900]: loss = 0.344334 * 100, metric = 4.57% * 100;
 Minibatch[ 901-1000]: loss = 0.356356 * 100, metric = 4.78% * 100;
 Minibatch[1001-1100]: loss = 0.360472 * 100, metric = 5.05% * 100;
 Minibatch[1101-1200]: loss = 0.359229 * 100, metric = 4.87% * 100;
 Minibatch[1201-1300]: loss = 0.364435 * 100, metric = 4.71% * 100;
 Minibatch[1301-1400]: loss = 0.370584 * 100, metric = 5.00% * 100;
 Minibatch[1401-1500]: loss = 0.363843 * 100, metric = 5.00% * 100;
 Minibatch[1501-1600]: loss = 0.362604 * 100, metric = 4.80% * 100;
 Minibatch[1601-1700]: loss = 0.358400 * 100, metric = 4.79% * 100;
 Minibatch[1701-1800]: loss = 0.362780 * 100, metric = 4.94% * 100;
 Minibatch[1801-1900]: loss = 0.360834 * 100, metric = 4.83% * 100;
 Minibatch[1901-2000]: loss = 0.353124 * 100, metric = 4.59% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.358128 * 2000, metric = 4.78% * 2000 885.020s (  2.3 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 14.14% * 2000;
 Minibatch[   1- 100]: loss = 0.348617 * 100, metric = 4.66% * 100;
 Minibatch[ 101- 200]: loss = 0.349749 * 100, metric = 4.73% * 100;
 Minibatch[ 201- 300]: loss = 0.359612 * 100, metric = 4.77% * 100;
 Minibatch[ 301- 400]: loss = 0.354502 * 100, metric = 4.82% * 100;
 Minibatch[ 401- 500]: loss = 0.351862 * 100, metric = 4.75% * 100;
 Minibatch[ 501- 600]: loss = 0.351414 * 100, metric = 4.67% * 100;
 Minibatch[ 601- 700]: loss = 0.360279 * 100, metric = 4.78% * 100;
 Minibatch[ 701- 800]: loss = 0.350999 * 100, metric = 4.53% * 100;
 Minibatch[ 801- 900]: loss = 0.357305 * 100, metric = 4.64% * 100;
 Minibatch[ 901-1000]: loss = 0.350982 * 100, metric = 4.64% * 100;
 Minibatch[1001-1100]: loss = 0.362004 * 100, metric = 4.99% * 100;
 Minibatch[1101-1200]: loss = 0.360634 * 100, metric = 4.99% * 100;
 Minibatch[1201-1300]: loss = 0.362554 * 100, metric = 4.81% * 100;
 Minibatch[1301-1400]: loss = 0.360296 * 100, metric = 4.88% * 100;
 Minibatch[1401-1500]: loss = 0.353484 * 100, metric = 4.77% * 100;
 Minibatch[1501-1600]: loss = 0.367659 * 100, metric = 4.91% * 100;
 Minibatch[1601-1700]: loss = 0.363247 * 100, metric = 4.76% * 100;
 Minibatch[1701-1800]: loss = 0.346661 * 100, metric = 4.56% * 100;
 Minibatch[1801-1900]: loss = 0.353142 * 100, metric = 4.59% * 100;
 Minibatch[1901-2000]: loss = 0.354791 * 100, metric = 4.80% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.355990 * 2000, metric = 4.75% * 2000 879.797s (  2.3 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 13.98% * 2000;
 Minibatch[   1- 100]: loss = 0.358246 * 100, metric = 4.76% * 100;
 Minibatch[ 101- 200]: loss = 0.352494 * 100, metric = 4.79% * 100;
 Minibatch[ 201- 300]: loss = 0.360743 * 100, metric = 4.80% * 100;
 Minibatch[ 301- 400]: loss = 0.364872 * 100, metric = 4.96% * 100;
 Minibatch[ 401- 500]: loss = 0.355672 * 100, metric = 4.72% * 100;
 Minibatch[ 501- 600]: loss = 0.357887 * 100, metric = 4.64% * 100;
 Minibatch[ 601- 700]: loss = 0.356657 * 100, metric = 4.72% * 100;
 Minibatch[ 701- 800]: loss = 0.359014 * 100, metric = 4.76% * 100;
 Minibatch[ 801- 900]: loss = 0.351236 * 100, metric = 4.67% * 100;
 Minibatch[ 901-1000]: loss = 0.356344 * 100, metric = 4.83% * 100;
 Minibatch[1001-1100]: loss = 0.356351 * 100, metric = 4.77% * 100;
 Minibatch[1101-1200]: loss = 0.370622 * 100, metric = 5.12% * 100;
 Minibatch[1201-1300]: loss = 0.363809 * 100, metric = 4.92% * 100;
 Minibatch[1301-1400]: loss = 0.342216 * 100, metric = 4.42% * 100;
 Minibatch[1401-1500]: loss = 0.351393 * 100, metric = 4.63% * 100;
 Minibatch[1501-1600]: loss = 0.353904 * 100, metric = 4.65% * 100;
 Minibatch[1601-1700]: loss = 0.357960 * 100, metric = 4.80% * 100;
 Minibatch[1701-1800]: loss = 0.351097 * 100, metric = 4.69% * 100;
 Minibatch[1801-1900]: loss = 0.348840 * 100, metric = 4.50% * 100;
 Minibatch[1901-2000]: loss = 0.348721 * 100, metric = 4.45% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.355904 * 2000, metric = 4.73% * 2000 890.593s (  2.2 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 14.24% * 2000;
 Minibatch[   1- 100]: loss = 0.348517 * 100, metric = 4.57% * 100;
 Minibatch[ 101- 200]: loss = 0.351107 * 100, metric = 4.68% * 100;
 Minibatch[ 201- 300]: loss = 0.354896 * 100, metric = 4.60% * 100;
 Minibatch[ 301- 400]: loss = 0.342607 * 100, metric = 4.33% * 100;
 Minibatch[ 401- 500]: loss = 0.351081 * 100, metric = 4.55% * 100;
 Minibatch[ 501- 600]: loss = 0.346365 * 100, metric = 4.56% * 100;
 Minibatch[ 601- 700]: loss = 0.351628 * 100, metric = 4.81% * 100;
 Minibatch[ 701- 800]: loss = 0.344966 * 100, metric = 4.68% * 100;
 Minibatch[ 801- 900]: loss = 0.347738 * 100, metric = 4.71% * 100;
 Minibatch[ 901-1000]: loss = 0.357421 * 100, metric = 4.57% * 100;
 Minibatch[1001-1100]: loss = 0.342733 * 100, metric = 4.68% * 100;
 Minibatch[1101-1200]: loss = 0.346054 * 100, metric = 4.66% * 100;
 Minibatch[1201-1300]: loss = 0.349749 * 100, metric = 4.64% * 100;
 Minibatch[1301-1400]: loss = 0.355791 * 100, metric = 4.75% * 100;
 Minibatch[1401-1500]: loss = 0.349677 * 100, metric = 4.45% * 100;
 Minibatch[1501-1600]: loss = 0.356107 * 100, metric = 4.62% * 100;
 Minibatch[1601-1700]: loss = 0.353972 * 100, metric = 4.72% * 100;
 Minibatch[1701-1800]: loss = 0.354844 * 100, metric = 4.72% * 100;
 Minibatch[1801-1900]: loss = 0.342778 * 100, metric = 4.52% * 100;
 Minibatch[1901-2000]: loss = 0.344705 * 100, metric = 4.42% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.349637 * 2000, metric = 4.61% * 2000 880.045s (  2.3 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 13.00% * 2000;
 Minibatch[   1- 100]: loss = 0.356739 * 100, metric = 4.81% * 100;
 Minibatch[ 101- 200]: loss = 0.335827 * 100, metric = 4.22% * 100;
 Minibatch[ 201- 300]: loss = 0.353486 * 100, metric = 4.55% * 100;
 Minibatch[ 301- 400]: loss = 0.353270 * 100, metric = 4.75% * 100;
 Minibatch[ 401- 500]: loss = 0.342257 * 100, metric = 4.42% * 100;
 Minibatch[ 501- 600]: loss = 0.341836 * 100, metric = 4.51% * 100;
 Minibatch[ 601- 700]: loss = 0.350570 * 100, metric = 4.73% * 100;
 Minibatch[ 701- 800]: loss = 0.342262 * 100, metric = 4.53% * 100;
 Minibatch[ 801- 900]: loss = 0.334874 * 100, metric = 4.41% * 100;
 Minibatch[ 901-1000]: loss = 0.340665 * 100, metric = 4.44% * 100;
 Minibatch[1001-1100]: loss = 0.347778 * 100, metric = 4.47% * 100;
 Minibatch[1101-1200]: loss = 0.335636 * 100, metric = 4.39% * 100;
 Minibatch[1201-1300]: loss = 0.351389 * 100, metric = 4.88% * 100;
 Minibatch[1301-1400]: loss = 0.349846 * 100, metric = 4.67% * 100;
 Minibatch[1401-1500]: loss = 0.337392 * 100, metric = 4.30% * 100;
 Minibatch[1501-1600]: loss = 0.348374 * 100, metric = 4.69% * 100;
 Minibatch[1601-1700]: loss = 0.335685 * 100, metric = 4.51% * 100;
 Minibatch[1701-1800]: loss = 0.347209 * 100, metric = 4.71% * 100;
 Minibatch[1801-1900]: loss = 0.342314 * 100, metric = 4.58% * 100;
 Minibatch[1901-2000]: loss = 0.346064 * 100, metric = 4.51% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.344674 * 2000, metric = 4.55% * 2000 883.523s (  2.3 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 13.54% * 2000;
 Minibatch[   1- 100]: loss = 0.342319 * 100, metric = 4.47% * 100;
 Minibatch[ 101- 200]: loss = 0.347016 * 100, metric = 4.60% * 100;
 Minibatch[ 201- 300]: loss = 0.354815 * 100, metric = 4.86% * 100;
 Minibatch[ 301- 400]: loss = 0.357055 * 100, metric = 4.66% * 100;
 Minibatch[ 401- 500]: loss = 0.342733 * 100, metric = 4.42% * 100;
 Minibatch[ 501- 600]: loss = 0.340905 * 100, metric = 4.48% * 100;
 Minibatch[ 601- 700]: loss = 0.352887 * 100, metric = 4.88% * 100;
 Minibatch[ 701- 800]: loss = 0.331132 * 100, metric = 4.30% * 100;
 Minibatch[ 801- 900]: loss = 0.347443 * 100, metric = 4.46% * 100;
 Minibatch[ 901-1000]: loss = 0.348319 * 100, metric = 4.59% * 100;
 Minibatch[1001-1100]: loss = 0.334961 * 100, metric = 4.28% * 100;
 Minibatch[1101-1200]: loss = 0.337944 * 100, metric = 4.54% * 100;
 Minibatch[1201-1300]: loss = 0.340916 * 100, metric = 4.48% * 100;
 Minibatch[1301-1400]: loss = 0.334467 * 100, metric = 4.46% * 100;
 Minibatch[1401-1500]: loss = 0.338962 * 100, metric = 4.34% * 100;
 Minibatch[1501-1600]: loss = 0.331600 * 100, metric = 4.29% * 100;
 Minibatch[1601-1700]: loss = 0.342287 * 100, metric = 4.60% * 100;
 Minibatch[1701-1800]: loss = 0.345395 * 100, metric = 4.68% * 100;
 Minibatch[1801-1900]: loss = 0.345538 * 100, metric = 4.47% * 100;
 Minibatch[1901-2000]: loss = 0.330581 * 100, metric = 4.36% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.342364 * 2000, metric = 4.51% * 2000 879.892s (  2.3 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 13.90% * 2000;
 Minibatch[   1- 100]: loss = 0.347020 * 100, metric = 4.35% * 100;
 Minibatch[ 101- 200]: loss = 0.337023 * 100, metric = 4.39% * 100;
 Minibatch[ 201- 300]: loss = 0.337158 * 100, metric = 4.57% * 100;
 Minibatch[ 301- 400]: loss = 0.342899 * 100, metric = 4.52% * 100;
 Minibatch[ 401- 500]: loss = 0.349577 * 100, metric = 4.52% * 100;
 Minibatch[ 501- 600]: loss = 0.335301 * 100, metric = 4.22% * 100;
 Minibatch[ 601- 700]: loss = 0.334109 * 100, metric = 4.20% * 100;
 Minibatch[ 701- 800]: loss = 0.323398 * 100, metric = 4.06% * 100;
 Minibatch[ 801- 900]: loss = 0.358440 * 100, metric = 4.90% * 100;
 Minibatch[ 901-1000]: loss = 0.341073 * 100, metric = 4.38% * 100;
 Minibatch[1001-1100]: loss = 0.341317 * 100, metric = 4.40% * 100;
 Minibatch[1101-1200]: loss = 0.354944 * 100, metric = 4.50% * 100;
 Minibatch[1201-1300]: loss = 0.344585 * 100, metric = 4.50% * 100;
 Minibatch[1301-1400]: loss = 0.342842 * 100, metric = 4.45% * 100;
 Minibatch[1401-1500]: loss = 0.355127 * 100, metric = 4.71% * 100;
 Minibatch[1501-1600]: loss = 0.345956 * 100, metric = 4.50% * 100;
 Minibatch[1601-1700]: loss = 0.326047 * 100, metric = 4.23% * 100;
 Minibatch[1701-1800]: loss = 0.347346 * 100, metric = 4.70% * 100;
 Minibatch[1801-1900]: loss = 0.344343 * 100, metric = 4.53% * 100;
 Minibatch[1901-2000]: loss = 0.341856 * 100, metric = 4.33% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.342518 * 2000, metric = 4.45% * 2000 880.619s (  2.3 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 13.62% * 2000;
 Minibatch[   1- 100]: loss = 0.339725 * 100, metric = 4.59% * 100;
 Minibatch[ 101- 200]: loss = 0.352408 * 100, metric = 4.78% * 100;
 Minibatch[ 201- 300]: loss = 0.339887 * 100, metric = 4.44% * 100;
 Minibatch[ 301- 400]: loss = 0.348810 * 100, metric = 4.65% * 100;
 Minibatch[ 401- 500]: loss = 0.341402 * 100, metric = 4.47% * 100;
 Minibatch[ 501- 600]: loss = 0.341339 * 100, metric = 4.62% * 100;
 Minibatch[ 601- 700]: loss = 0.327964 * 100, metric = 4.14% * 100;
 Minibatch[ 701- 800]: loss = 0.332829 * 100, metric = 4.34% * 100;
 Minibatch[ 801- 900]: loss = 0.340818 * 100, metric = 4.49% * 100;
 Minibatch[ 901-1000]: loss = 0.345546 * 100, metric = 4.49% * 100;
 Minibatch[1001-1100]: loss = 0.333268 * 100, metric = 4.37% * 100;
 Minibatch[1101-1200]: loss = 0.345754 * 100, metric = 4.55% * 100;
 Minibatch[1201-1300]: loss = 0.337466 * 100, metric = 4.34% * 100;
 Minibatch[1301-1400]: loss = 0.339026 * 100, metric = 4.39% * 100;
 Minibatch[1401-1500]: loss = 0.328333 * 100, metric = 4.29% * 100;
 Minibatch[1501-1600]: loss = 0.343663 * 100, metric = 4.51% * 100;
 Minibatch[1601-1700]: loss = 0.337377 * 100, metric = 4.48% * 100;
 Minibatch[1701-1800]: loss = 0.347924 * 100, metric = 4.57% * 100;
 Minibatch[1801-1900]: loss = 0.327850 * 100, metric = 4.01% * 100;
 Minibatch[1901-2000]: loss = 0.338228 * 100, metric = 4.49% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.339481 * 2000, metric = 4.45% * 2000 880.024s (  2.3 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 13.12% * 2000;
 Minibatch[   1- 100]: loss = 0.344940 * 100, metric = 4.52% * 100;
 Minibatch[ 101- 200]: loss = 0.333484 * 100, metric = 4.37% * 100;
 Minibatch[ 201- 300]: loss = 0.342274 * 100, metric = 4.47% * 100;
 Minibatch[ 301- 400]: loss = 0.339799 * 100, metric = 4.31% * 100;
 Minibatch[ 401- 500]: loss = 0.337462 * 100, metric = 4.29% * 100;
 Minibatch[ 501- 600]: loss = 0.336623 * 100, metric = 4.35% * 100;
 Minibatch[ 601- 700]: loss = 0.346783 * 100, metric = 4.62% * 100;
 Minibatch[ 701- 800]: loss = 0.350258 * 100, metric = 4.85% * 100;
 Minibatch[ 801- 900]: loss = 0.336494 * 100, metric = 4.24% * 100;
 Minibatch[ 901-1000]: loss = 0.342712 * 100, metric = 4.46% * 100;
 Minibatch[1001-1100]: loss = 0.356596 * 100, metric = 4.84% * 100;
 Minibatch[1101-1200]: loss = 0.343653 * 100, metric = 4.45% * 100;
 Minibatch[1201-1300]: loss = 0.331956 * 100, metric = 4.26% * 100;
 Minibatch[1301-1400]: loss = 0.334103 * 100, metric = 4.40% * 100;
 Minibatch[1401-1500]: loss = 0.341679 * 100, metric = 4.56% * 100;
 Minibatch[1501-1600]: loss = 0.349687 * 100, metric = 4.42% * 100;
 Minibatch[1601-1700]: loss = 0.344109 * 100, metric = 4.26% * 100;
 Minibatch[1701-1800]: loss = 0.341871 * 100, metric = 4.49% * 100;
 Minibatch[1801-1900]: loss = 0.345518 * 100, metric = 4.42% * 100;
 Minibatch[1901-2000]: loss = 0.346305 * 100, metric = 4.57% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.342315 * 2000, metric = 4.46% * 2000 882.736s (  2.3 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 12.55% * 2000;
 Minibatch[   1- 100]: loss = 0.348284 * 100, metric = 4.68% * 100;
 Minibatch[ 101- 200]: loss = 0.344384 * 100, metric = 4.57% * 100;
 Minibatch[ 201- 300]: loss = 0.340695 * 100, metric = 4.53% * 100;
 Minibatch[ 301- 400]: loss = 0.335180 * 100, metric = 4.45% * 100;
 Minibatch[ 401- 500]: loss = 0.342643 * 100, metric = 4.57% * 100;
 Minibatch[ 501- 600]: loss = 0.343723 * 100, metric = 4.64% * 100;
 Minibatch[ 601- 700]: loss = 0.348156 * 100, metric = 4.66% * 100;
 Minibatch[ 701- 800]: loss = 0.338955 * 100, metric = 4.45% * 100;
 Minibatch[ 801- 900]: loss = 0.335023 * 100, metric = 4.17% * 100;
 Minibatch[ 901-1000]: loss = 0.341850 * 100, metric = 4.59% * 100;
 Minibatch[1001-1100]: loss = 0.332629 * 100, metric = 4.33% * 100;
 Minibatch[1101-1200]: loss = 0.334366 * 100, metric = 4.32% * 100;
 Minibatch[1201-1300]: loss = 0.327407 * 100, metric = 4.29% * 100;
 Minibatch[1301-1400]: loss = 0.330219 * 100, metric = 4.40% * 100;
 Minibatch[1401-1500]: loss = 0.333479 * 100, metric = 4.45% * 100;
 Minibatch[1501-1600]: loss = 0.328871 * 100, metric = 4.39% * 100;
 Minibatch[1601-1700]: loss = 0.324315 * 100, metric = 4.28% * 100;
 Minibatch[1701-1800]: loss = 0.325492 * 100, metric = 4.08% * 100;
 Minibatch[1801-1900]: loss = 0.340959 * 100, metric = 4.29% * 100;
 Minibatch[1901-2000]: loss = 0.327814 * 100, metric = 4.18% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.336222 * 2000, metric = 4.42% * 2000 881.267s (  2.3 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 14.01% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
