Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.052017 * 100, metric = 25.93% * 100;
 Minibatch[ 101- 200]: loss = 0.745003 * 100, metric = 23.01% * 100;
 Minibatch[ 201- 300]: loss = 0.633035 * 100, metric = 21.20% * 100;
 Minibatch[ 301- 400]: loss = 0.594384 * 100, metric = 20.02% * 100;
 Minibatch[ 401- 500]: loss = 0.541280 * 100, metric = 18.39% * 100;
 Minibatch[ 501- 600]: loss = 0.513374 * 100, metric = 18.06% * 100;
 Minibatch[ 601- 700]: loss = 0.477426 * 100, metric = 16.47% * 100;
 Minibatch[ 701- 800]: loss = 0.446999 * 100, metric = 15.45% * 100;
 Minibatch[ 801- 900]: loss = 0.457665 * 100, metric = 15.79% * 100;
 Minibatch[ 901-1000]: loss = 0.460437 * 100, metric = 15.83% * 100;
 Minibatch[1001-1100]: loss = 0.447597 * 100, metric = 15.68% * 100;
 Minibatch[1101-1200]: loss = 0.423312 * 100, metric = 14.51% * 100;
 Minibatch[1201-1300]: loss = 0.421542 * 100, metric = 14.86% * 100;
 Minibatch[1301-1400]: loss = 0.408692 * 100, metric = 13.91% * 100;
 Minibatch[1401-1500]: loss = 0.414495 * 100, metric = 14.25% * 100;
 Minibatch[1501-1600]: loss = 0.402611 * 100, metric = 14.18% * 100;
 Minibatch[1601-1700]: loss = 0.389913 * 100, metric = 13.23% * 100;
 Minibatch[1701-1800]: loss = 0.390965 * 100, metric = 13.33% * 100;
 Minibatch[1801-1900]: loss = 0.392173 * 100, metric = 13.42% * 100;
 Minibatch[1901-2000]: loss = 0.374157 * 100, metric = 12.59% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.499354 * 2000, metric = 16.50% * 2000 1008.372s (  2.0 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 33.31% * 2000;
0.6860714594721794
 Minibatch[   1- 100]: loss = 0.377586 * 100, metric = 12.80% * 100;
 Minibatch[ 101- 200]: loss = 0.393748 * 100, metric = 13.53% * 100;
 Minibatch[ 201- 300]: loss = 0.381822 * 100, metric = 12.71% * 100;
 Minibatch[ 301- 400]: loss = 0.380300 * 100, metric = 12.73% * 100;
 Minibatch[ 401- 500]: loss = 0.363352 * 100, metric = 12.38% * 100;
 Minibatch[ 501- 600]: loss = 0.377905 * 100, metric = 12.11% * 100;
 Minibatch[ 601- 700]: loss = 0.357471 * 100, metric = 11.89% * 100;
 Minibatch[ 701- 800]: loss = 0.367514 * 100, metric = 12.68% * 100;
 Minibatch[ 801- 900]: loss = 0.344214 * 100, metric = 11.87% * 100;
 Minibatch[ 901-1000]: loss = 0.338665 * 100, metric = 11.47% * 100;
 Minibatch[1001-1100]: loss = 0.355460 * 100, metric = 11.95% * 100;
 Minibatch[1101-1200]: loss = 0.342166 * 100, metric = 11.45% * 100;
 Minibatch[1201-1300]: loss = 0.338564 * 100, metric = 11.58% * 100;
 Minibatch[1301-1400]: loss = 0.353602 * 100, metric = 11.85% * 100;
 Minibatch[1401-1500]: loss = 0.347481 * 100, metric = 11.60% * 100;
 Minibatch[1501-1600]: loss = 0.334795 * 100, metric = 11.47% * 100;
 Minibatch[1601-1700]: loss = 0.343799 * 100, metric = 11.26% * 100;
 Minibatch[1701-1800]: loss = 0.349673 * 100, metric = 11.53% * 100;
 Minibatch[1801-1900]: loss = 0.342903 * 100, metric = 11.57% * 100;
 Minibatch[1901-2000]: loss = 0.322000 * 100, metric = 10.95% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.355651 * 2000, metric = 11.97% * 2000 904.447s (  2.2 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 22.61% * 2000;
0.556732854641974
 Minibatch[   1- 100]: loss = 0.334374 * 100, metric = 11.26% * 100;
 Minibatch[ 101- 200]: loss = 0.343372 * 100, metric = 11.40% * 100;
 Minibatch[ 201- 300]: loss = 0.331098 * 100, metric = 11.40% * 100;
 Minibatch[ 301- 400]: loss = 0.338594 * 100, metric = 11.46% * 100;
 Minibatch[ 401- 500]: loss = 0.345415 * 100, metric = 11.69% * 100;
 Minibatch[ 501- 600]: loss = 0.337818 * 100, metric = 11.26% * 100;
 Minibatch[ 601- 700]: loss = 0.336926 * 100, metric = 10.91% * 100;
 Minibatch[ 701- 800]: loss = 0.315591 * 100, metric = 10.60% * 100;
 Minibatch[ 801- 900]: loss = 0.344656 * 100, metric = 11.53% * 100;
 Minibatch[ 901-1000]: loss = 0.317366 * 100, metric = 10.90% * 100;
 Minibatch[1001-1100]: loss = 0.325733 * 100, metric = 11.00% * 100;
 Minibatch[1101-1200]: loss = 0.315674 * 100, metric = 10.77% * 100;
 Minibatch[1201-1300]: loss = 0.321306 * 100, metric = 10.74% * 100;
 Minibatch[1301-1400]: loss = 0.325316 * 100, metric = 10.84% * 100;
 Minibatch[1401-1500]: loss = 0.324263 * 100, metric = 11.04% * 100;
 Minibatch[1501-1600]: loss = 0.316018 * 100, metric = 10.54% * 100;
 Minibatch[1601-1700]: loss = 0.312214 * 100, metric = 10.23% * 100;
 Minibatch[1701-1800]: loss = 0.320824 * 100, metric = 10.76% * 100;
 Minibatch[1801-1900]: loss = 0.304399 * 100, metric = 10.16% * 100;
 Minibatch[1901-2000]: loss = 0.307598 * 100, metric = 10.29% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.325928 * 2000, metric = 10.94% * 2000 915.582s (  2.2 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 20.38% * 2000;
0.5156133545413614
 Minibatch[   1- 100]: loss = 0.324744 * 100, metric = 10.55% * 100;
 Minibatch[ 101- 200]: loss = 0.306020 * 100, metric = 10.25% * 100;
 Minibatch[ 201- 300]: loss = 0.316423 * 100, metric = 10.65% * 100;
 Minibatch[ 301- 400]: loss = 0.292884 * 100, metric = 9.89% * 100;
 Minibatch[ 401- 500]: loss = 0.315341 * 100, metric = 10.66% * 100;
 Minibatch[ 501- 600]: loss = 0.293255 * 100, metric = 9.76% * 100;
 Minibatch[ 601- 700]: loss = 0.302495 * 100, metric = 10.06% * 100;
 Minibatch[ 701- 800]: loss = 0.310333 * 100, metric = 10.48% * 100;
 Minibatch[ 801- 900]: loss = 0.315188 * 100, metric = 10.38% * 100;
 Minibatch[ 901-1000]: loss = 0.302539 * 100, metric = 9.88% * 100;
 Minibatch[1001-1100]: loss = 0.311238 * 100, metric = 10.47% * 100;
 Minibatch[1101-1200]: loss = 0.296981 * 100, metric = 9.97% * 100;
 Minibatch[1201-1300]: loss = 0.298564 * 100, metric = 10.06% * 100;
 Minibatch[1301-1400]: loss = 0.309111 * 100, metric = 10.53% * 100;
 Minibatch[1401-1500]: loss = 0.312035 * 100, metric = 10.62% * 100;
 Minibatch[1501-1600]: loss = 0.293854 * 100, metric = 9.91% * 100;
 Minibatch[1601-1700]: loss = 0.299716 * 100, metric = 10.05% * 100;
 Minibatch[1701-1800]: loss = 0.303987 * 100, metric = 10.29% * 100;
 Minibatch[1801-1900]: loss = 0.299982 * 100, metric = 10.02% * 100;
 Minibatch[1901-2000]: loss = 0.288307 * 100, metric = 9.45% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.304650 * 2000, metric = 10.20% * 2000 951.462s (  2.1 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 25.20% * 2000;
 Minibatch[   1- 100]: loss = 0.308403 * 100, metric = 10.51% * 100;
 Minibatch[ 101- 200]: loss = 0.293656 * 100, metric = 10.15% * 100;
 Minibatch[ 201- 300]: loss = 0.293148 * 100, metric = 9.76% * 100;
 Minibatch[ 301- 400]: loss = 0.307895 * 100, metric = 10.37% * 100;
 Minibatch[ 401- 500]: loss = 0.280945 * 100, metric = 9.33% * 100;
 Minibatch[ 501- 600]: loss = 0.282557 * 100, metric = 9.32% * 100;
 Minibatch[ 601- 700]: loss = 0.291303 * 100, metric = 9.71% * 100;
 Minibatch[ 701- 800]: loss = 0.294376 * 100, metric = 9.69% * 100;
 Minibatch[ 801- 900]: loss = 0.284434 * 100, metric = 9.42% * 100;
 Minibatch[ 901-1000]: loss = 0.285715 * 100, metric = 9.54% * 100;
 Minibatch[1001-1100]: loss = 0.294332 * 100, metric = 9.84% * 100;
 Minibatch[1101-1200]: loss = 0.280511 * 100, metric = 9.33% * 100;
 Minibatch[1201-1300]: loss = 0.288455 * 100, metric = 9.46% * 100;
 Minibatch[1301-1400]: loss = 0.296150 * 100, metric = 9.99% * 100;
 Minibatch[1401-1500]: loss = 0.281977 * 100, metric = 9.40% * 100;
 Minibatch[1501-1600]: loss = 0.292430 * 100, metric = 9.82% * 100;
 Minibatch[1601-1700]: loss = 0.296118 * 100, metric = 9.98% * 100;
 Minibatch[1701-1800]: loss = 0.294794 * 100, metric = 9.82% * 100;
 Minibatch[1801-1900]: loss = 0.293474 * 100, metric = 9.78% * 100;
 Minibatch[1901-2000]: loss = 0.284862 * 100, metric = 9.57% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.291277 * 2000, metric = 9.74% * 2000 955.251s (  2.1 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 18.42% * 2000;
0.4902052964642644
 Minibatch[   1- 100]: loss = 0.277180 * 100, metric = 9.30% * 100;
 Minibatch[ 101- 200]: loss = 0.278512 * 100, metric = 9.33% * 100;
 Minibatch[ 201- 300]: loss = 0.290983 * 100, metric = 9.68% * 100;
 Minibatch[ 301- 400]: loss = 0.293636 * 100, metric = 9.59% * 100;
 Minibatch[ 401- 500]: loss = 0.277209 * 100, metric = 9.36% * 100;
 Minibatch[ 501- 600]: loss = 0.285210 * 100, metric = 9.70% * 100;
 Minibatch[ 601- 700]: loss = 0.279153 * 100, metric = 9.47% * 100;
 Minibatch[ 701- 800]: loss = 0.286468 * 100, metric = 9.57% * 100;
 Minibatch[ 801- 900]: loss = 0.287472 * 100, metric = 9.77% * 100;
 Minibatch[ 901-1000]: loss = 0.278414 * 100, metric = 9.33% * 100;
 Minibatch[1001-1100]: loss = 0.275641 * 100, metric = 8.98% * 100;
 Minibatch[1101-1200]: loss = 0.287027 * 100, metric = 9.50% * 100;
 Minibatch[1201-1300]: loss = 0.293166 * 100, metric = 9.91% * 100;
 Minibatch[1301-1400]: loss = 0.282158 * 100, metric = 9.60% * 100;
 Minibatch[1401-1500]: loss = 0.281827 * 100, metric = 9.62% * 100;
 Minibatch[1501-1600]: loss = 0.269427 * 100, metric = 8.89% * 100;
 Minibatch[1601-1700]: loss = 0.270728 * 100, metric = 9.14% * 100;
 Minibatch[1701-1800]: loss = 0.261301 * 100, metric = 8.63% * 100;
 Minibatch[1801-1900]: loss = 0.282236 * 100, metric = 9.61% * 100;
 Minibatch[1901-2000]: loss = 0.272349 * 100, metric = 9.19% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.280505 * 2000, metric = 9.41% * 2000 944.820s (  2.1 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 17.39% * 2000;
0.4691212698593736
 Minibatch[   1- 100]: loss = 0.269547 * 100, metric = 9.10% * 100;
 Minibatch[ 101- 200]: loss = 0.277375 * 100, metric = 9.14% * 100;
 Minibatch[ 201- 300]: loss = 0.286587 * 100, metric = 9.33% * 100;
 Minibatch[ 301- 400]: loss = 0.264373 * 100, metric = 8.86% * 100;
 Minibatch[ 401- 500]: loss = 0.278514 * 100, metric = 9.22% * 100;
 Minibatch[ 501- 600]: loss = 0.257267 * 100, metric = 8.54% * 100;
 Minibatch[ 601- 700]: loss = 0.270391 * 100, metric = 8.78% * 100;
 Minibatch[ 701- 800]: loss = 0.270536 * 100, metric = 8.94% * 100;
 Minibatch[ 801- 900]: loss = 0.276763 * 100, metric = 9.14% * 100;
 Minibatch[ 901-1000]: loss = 0.270368 * 100, metric = 9.03% * 100;
 Minibatch[1001-1100]: loss = 0.277842 * 100, metric = 9.18% * 100;
 Minibatch[1101-1200]: loss = 0.268257 * 100, metric = 8.90% * 100;
 Minibatch[1201-1300]: loss = 0.278234 * 100, metric = 9.44% * 100;
 Minibatch[1301-1400]: loss = 0.263216 * 100, metric = 8.75% * 100;
 Minibatch[1401-1500]: loss = 0.262623 * 100, metric = 8.80% * 100;
 Minibatch[1501-1600]: loss = 0.266652 * 100, metric = 9.00% * 100;
 Minibatch[1601-1700]: loss = 0.275078 * 100, metric = 9.13% * 100;
 Minibatch[1701-1800]: loss = 0.270999 * 100, metric = 8.84% * 100;
 Minibatch[1801-1900]: loss = 0.272898 * 100, metric = 9.04% * 100;
 Minibatch[1901-2000]: loss = 0.278007 * 100, metric = 9.24% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.271776 * 2000, metric = 9.02% * 2000 912.907s (  2.2 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 16.67% * 2000;
0.4531507986560464
 Minibatch[   1- 100]: loss = 0.278354 * 100, metric = 9.33% * 100;
 Minibatch[ 101- 200]: loss = 0.270237 * 100, metric = 9.04% * 100;
 Minibatch[ 201- 300]: loss = 0.253020 * 100, metric = 8.48% * 100;
 Minibatch[ 301- 400]: loss = 0.258266 * 100, metric = 8.76% * 100;
 Minibatch[ 401- 500]: loss = 0.275558 * 100, metric = 9.25% * 100;
 Minibatch[ 501- 600]: loss = 0.278846 * 100, metric = 9.30% * 100;
 Minibatch[ 601- 700]: loss = 0.249747 * 100, metric = 8.34% * 100;
 Minibatch[ 701- 800]: loss = 0.265831 * 100, metric = 8.58% * 100;
 Minibatch[ 801- 900]: loss = 0.252646 * 100, metric = 8.24% * 100;
 Minibatch[ 901-1000]: loss = 0.238769 * 100, metric = 7.86% * 100;
 Minibatch[1001-1100]: loss = 0.247811 * 100, metric = 8.21% * 100;
 Minibatch[1101-1200]: loss = 0.251552 * 100, metric = 8.29% * 100;
 Minibatch[1201-1300]: loss = 0.262971 * 100, metric = 8.59% * 100;
 Minibatch[1301-1400]: loss = 0.268754 * 100, metric = 9.04% * 100;
 Minibatch[1401-1500]: loss = 0.257710 * 100, metric = 8.57% * 100;
 Minibatch[1501-1600]: loss = 0.262069 * 100, metric = 8.73% * 100;
 Minibatch[1601-1700]: loss = 0.257121 * 100, metric = 8.43% * 100;
 Minibatch[1701-1800]: loss = 0.255493 * 100, metric = 8.27% * 100;
 Minibatch[1801-1900]: loss = 0.256251 * 100, metric = 8.35% * 100;
 Minibatch[1901-2000]: loss = 0.254439 * 100, metric = 8.43% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.259772 * 2000, metric = 8.60% * 2000 932.356s (  2.1 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 16.66% * 2000;
0.44722160418331625
 Minibatch[   1- 100]: loss = 0.236629 * 100, metric = 7.76% * 100;
 Minibatch[ 101- 200]: loss = 0.267156 * 100, metric = 8.66% * 100;
 Minibatch[ 201- 300]: loss = 0.254403 * 100, metric = 8.46% * 100;
 Minibatch[ 301- 400]: loss = 0.267344 * 100, metric = 8.77% * 100;
 Minibatch[ 401- 500]: loss = 0.258061 * 100, metric = 8.44% * 100;
 Minibatch[ 501- 600]: loss = 0.249579 * 100, metric = 8.21% * 100;
 Minibatch[ 601- 700]: loss = 0.256434 * 100, metric = 8.31% * 100;
 Minibatch[ 701- 800]: loss = 0.238260 * 100, metric = 7.98% * 100;
 Minibatch[ 801- 900]: loss = 0.248359 * 100, metric = 8.27% * 100;
 Minibatch[ 901-1000]: loss = 0.255022 * 100, metric = 8.36% * 100;
 Minibatch[1001-1100]: loss = 0.231840 * 100, metric = 7.66% * 100;
 Minibatch[1101-1200]: loss = 0.251593 * 100, metric = 8.25% * 100;
 Minibatch[1201-1300]: loss = 0.246100 * 100, metric = 8.14% * 100;
 Minibatch[1301-1400]: loss = 0.242870 * 100, metric = 7.86% * 100;
 Minibatch[1401-1500]: loss = 0.258913 * 100, metric = 8.38% * 100;
 Minibatch[1501-1600]: loss = 0.247762 * 100, metric = 8.05% * 100;
 Minibatch[1601-1700]: loss = 0.252916 * 100, metric = 8.11% * 100;
 Minibatch[1701-1800]: loss = 0.242529 * 100, metric = 7.83% * 100;
 Minibatch[1801-1900]: loss = 0.243246 * 100, metric = 7.90% * 100;
 Minibatch[1901-2000]: loss = 0.249578 * 100, metric = 8.16% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.249930 * 2000, metric = 8.18% * 2000 924.819s (  2.2 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 15.38% * 2000;
0.4334784954451025
 Minibatch[   1- 100]: loss = 0.263245 * 100, metric = 8.70% * 100;
 Minibatch[ 101- 200]: loss = 0.246076 * 100, metric = 8.09% * 100;
 Minibatch[ 201- 300]: loss = 0.246843 * 100, metric = 8.10% * 100;
 Minibatch[ 301- 400]: loss = 0.239493 * 100, metric = 7.74% * 100;
 Minibatch[ 401- 500]: loss = 0.251202 * 100, metric = 8.25% * 100;
 Minibatch[ 501- 600]: loss = 0.234702 * 100, metric = 7.70% * 100;
 Minibatch[ 601- 700]: loss = 0.234019 * 100, metric = 7.65% * 100;
 Minibatch[ 701- 800]: loss = 0.227962 * 100, metric = 7.46% * 100;
 Minibatch[ 801- 900]: loss = 0.237645 * 100, metric = 7.95% * 100;
 Minibatch[ 901-1000]: loss = 0.244142 * 100, metric = 7.90% * 100;
 Minibatch[1001-1100]: loss = 0.245880 * 100, metric = 7.93% * 100;
 Minibatch[1101-1200]: loss = 0.244375 * 100, metric = 7.97% * 100;
 Minibatch[1201-1300]: loss = 0.247507 * 100, metric = 8.09% * 100;
 Minibatch[1301-1400]: loss = 0.240590 * 100, metric = 7.87% * 100;
 Minibatch[1401-1500]: loss = 0.228922 * 100, metric = 7.49% * 100;
 Minibatch[1501-1600]: loss = 0.242051 * 100, metric = 7.88% * 100;
 Minibatch[1601-1700]: loss = 0.241026 * 100, metric = 7.82% * 100;
 Minibatch[1701-1800]: loss = 0.239054 * 100, metric = 7.53% * 100;
 Minibatch[1801-1900]: loss = 0.248752 * 100, metric = 8.32% * 100;
 Minibatch[1901-2000]: loss = 0.237953 * 100, metric = 7.83% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.242072 * 2000, metric = 7.91% * 2000 926.615s (  2.2 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 15.84% * 2000;
 Minibatch[   1- 100]: loss = 0.223542 * 100, metric = 7.29% * 100;
 Minibatch[ 101- 200]: loss = 0.231740 * 100, metric = 7.41% * 100;
 Minibatch[ 201- 300]: loss = 0.240979 * 100, metric = 7.88% * 100;
 Minibatch[ 301- 400]: loss = 0.234107 * 100, metric = 7.66% * 100;
 Minibatch[ 401- 500]: loss = 0.230867 * 100, metric = 7.56% * 100;
 Minibatch[ 501- 600]: loss = 0.242144 * 100, metric = 7.90% * 100;
 Minibatch[ 601- 700]: loss = 0.237157 * 100, metric = 7.74% * 100;
 Minibatch[ 701- 800]: loss = 0.241707 * 100, metric = 7.89% * 100;
 Minibatch[ 801- 900]: loss = 0.237472 * 100, metric = 7.65% * 100;
 Minibatch[ 901-1000]: loss = 0.242730 * 100, metric = 7.86% * 100;
 Minibatch[1001-1100]: loss = 0.233128 * 100, metric = 7.49% * 100;
 Minibatch[1101-1200]: loss = 0.246371 * 100, metric = 7.93% * 100;
 Minibatch[1201-1300]: loss = 0.230466 * 100, metric = 7.47% * 100;
 Minibatch[1301-1400]: loss = 0.218482 * 100, metric = 7.05% * 100;
 Minibatch[1401-1500]: loss = 0.238864 * 100, metric = 7.81% * 100;
 Minibatch[1501-1600]: loss = 0.226611 * 100, metric = 7.35% * 100;
 Minibatch[1601-1700]: loss = 0.231064 * 100, metric = 7.53% * 100;
 Minibatch[1701-1800]: loss = 0.243680 * 100, metric = 7.93% * 100;
 Minibatch[1801-1900]: loss = 0.229559 * 100, metric = 7.23% * 100;
 Minibatch[1901-2000]: loss = 0.233566 * 100, metric = 7.69% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.234712 * 2000, metric = 7.62% * 2000 938.848s (  2.1 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 16.23% * 2000;
 Minibatch[   1- 100]: loss = 0.224648 * 100, metric = 7.30% * 100;
 Minibatch[ 101- 200]: loss = 0.221756 * 100, metric = 7.31% * 100;
 Minibatch[ 201- 300]: loss = 0.223969 * 100, metric = 7.36% * 100;
 Minibatch[ 301- 400]: loss = 0.246134 * 100, metric = 8.11% * 100;
 Minibatch[ 401- 500]: loss = 0.220756 * 100, metric = 7.19% * 100;
 Minibatch[ 501- 600]: loss = 0.215638 * 100, metric = 6.96% * 100;
 Minibatch[ 601- 700]: loss = 0.220318 * 100, metric = 7.23% * 100;
 Minibatch[ 701- 800]: loss = 0.228493 * 100, metric = 7.38% * 100;
 Minibatch[ 801- 900]: loss = 0.228503 * 100, metric = 7.41% * 100;
 Minibatch[ 901-1000]: loss = 0.227066 * 100, metric = 7.18% * 100;
 Minibatch[1001-1100]: loss = 0.227555 * 100, metric = 7.38% * 100;
 Minibatch[1101-1200]: loss = 0.227162 * 100, metric = 7.23% * 100;
 Minibatch[1201-1300]: loss = 0.235522 * 100, metric = 7.76% * 100;
 Minibatch[1301-1400]: loss = 0.217624 * 100, metric = 6.86% * 100;
 Minibatch[1401-1500]: loss = 0.234307 * 100, metric = 7.64% * 100;
 Minibatch[1501-1600]: loss = 0.209710 * 100, metric = 6.70% * 100;
 Minibatch[1601-1700]: loss = 0.224669 * 100, metric = 7.30% * 100;
 Minibatch[1701-1800]: loss = 0.214017 * 100, metric = 6.98% * 100;
 Minibatch[1801-1900]: loss = 0.220097 * 100, metric = 7.25% * 100;
 Minibatch[1901-2000]: loss = 0.236456 * 100, metric = 7.62% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.225220 * 2000, metric = 7.31% * 2000 923.998s (  2.2 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 16.73% * 2000;
 Minibatch[   1- 100]: loss = 0.227191 * 100, metric = 7.27% * 100;
 Minibatch[ 101- 200]: loss = 0.227144 * 100, metric = 7.34% * 100;
 Minibatch[ 201- 300]: loss = 0.221895 * 100, metric = 7.15% * 100;
 Minibatch[ 301- 400]: loss = 0.226552 * 100, metric = 7.23% * 100;
 Minibatch[ 401- 500]: loss = 0.236470 * 100, metric = 7.80% * 100;
 Minibatch[ 501- 600]: loss = 0.235188 * 100, metric = 7.62% * 100;
 Minibatch[ 601- 700]: loss = 0.220077 * 100, metric = 6.99% * 100;
 Minibatch[ 701- 800]: loss = 0.218163 * 100, metric = 7.12% * 100;
 Minibatch[ 801- 900]: loss = 0.218421 * 100, metric = 6.91% * 100;
 Minibatch[ 901-1000]: loss = 0.229003 * 100, metric = 7.37% * 100;
 Minibatch[1001-1100]: loss = 0.227238 * 100, metric = 7.36% * 100;
 Minibatch[1101-1200]: loss = 0.215680 * 100, metric = 6.98% * 100;
 Minibatch[1201-1300]: loss = 0.223503 * 100, metric = 7.24% * 100;
 Minibatch[1301-1400]: loss = 0.217880 * 100, metric = 6.99% * 100;
 Minibatch[1401-1500]: loss = 0.215931 * 100, metric = 6.94% * 100;
 Minibatch[1501-1600]: loss = 0.211581 * 100, metric = 6.80% * 100;
 Minibatch[1601-1700]: loss = 0.211544 * 100, metric = 6.68% * 100;
 Minibatch[1701-1800]: loss = 0.216314 * 100, metric = 6.84% * 100;
 Minibatch[1801-1900]: loss = 0.208376 * 100, metric = 6.61% * 100;
 Minibatch[1901-2000]: loss = 0.220646 * 100, metric = 7.26% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.221440 * 2000, metric = 7.12% * 2000 914.985s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 18.16% * 2000;
 Minibatch[   1- 100]: loss = 0.216039 * 100, metric = 6.78% * 100;
 Minibatch[ 101- 200]: loss = 0.206592 * 100, metric = 6.62% * 100;
 Minibatch[ 201- 300]: loss = 0.219402 * 100, metric = 7.12% * 100;
 Minibatch[ 301- 400]: loss = 0.214368 * 100, metric = 6.78% * 100;
 Minibatch[ 401- 500]: loss = 0.214607 * 100, metric = 6.67% * 100;
 Minibatch[ 501- 600]: loss = 0.212741 * 100, metric = 6.78% * 100;
 Minibatch[ 601- 700]: loss = 0.214073 * 100, metric = 6.78% * 100;
 Minibatch[ 701- 800]: loss = 0.231589 * 100, metric = 7.44% * 100;
 Minibatch[ 801- 900]: loss = 0.222186 * 100, metric = 6.93% * 100;
 Minibatch[ 901-1000]: loss = 0.212958 * 100, metric = 6.88% * 100;
 Minibatch[1001-1100]: loss = 0.221548 * 100, metric = 6.88% * 100;
 Minibatch[1101-1200]: loss = 0.213279 * 100, metric = 6.85% * 100;
 Minibatch[1201-1300]: loss = 0.204451 * 100, metric = 6.61% * 100;
 Minibatch[1301-1400]: loss = 0.218313 * 100, metric = 7.03% * 100;
 Minibatch[1401-1500]: loss = 0.215184 * 100, metric = 6.91% * 100;
 Minibatch[1501-1600]: loss = 0.207612 * 100, metric = 6.77% * 100;
 Minibatch[1601-1700]: loss = 0.206786 * 100, metric = 6.52% * 100;
 Minibatch[1701-1800]: loss = 0.206715 * 100, metric = 6.68% * 100;
 Minibatch[1801-1900]: loss = 0.207849 * 100, metric = 6.73% * 100;
 Minibatch[1901-2000]: loss = 0.211711 * 100, metric = 6.79% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.213900 * 2000, metric = 6.83% * 2000 925.619s (  2.2 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 18.15% * 2000;
 Minibatch[   1- 100]: loss = 0.210643 * 100, metric = 6.83% * 100;
 Minibatch[ 101- 200]: loss = 0.209330 * 100, metric = 6.60% * 100;
 Minibatch[ 201- 300]: loss = 0.207594 * 100, metric = 6.58% * 100;
 Minibatch[ 301- 400]: loss = 0.204707 * 100, metric = 6.54% * 100;
 Minibatch[ 401- 500]: loss = 0.209561 * 100, metric = 6.72% * 100;
 Minibatch[ 501- 600]: loss = 0.198409 * 100, metric = 6.29% * 100;
 Minibatch[ 601- 700]: loss = 0.195046 * 100, metric = 6.28% * 100;
 Minibatch[ 701- 800]: loss = 0.213633 * 100, metric = 6.73% * 100;
 Minibatch[ 801- 900]: loss = 0.224980 * 100, metric = 7.20% * 100;
 Minibatch[ 901-1000]: loss = 0.204880 * 100, metric = 6.71% * 100;
 Minibatch[1001-1100]: loss = 0.213364 * 100, metric = 6.90% * 100;
 Minibatch[1101-1200]: loss = 0.205614 * 100, metric = 6.45% * 100;
 Minibatch[1201-1300]: loss = 0.192859 * 100, metric = 6.08% * 100;
 Minibatch[1301-1400]: loss = 0.222727 * 100, metric = 7.10% * 100;
 Minibatch[1401-1500]: loss = 0.191515 * 100, metric = 6.02% * 100;
 Minibatch[1501-1600]: loss = 0.204046 * 100, metric = 6.47% * 100;
 Minibatch[1601-1700]: loss = 0.203354 * 100, metric = 6.42% * 100;
 Minibatch[1701-1800]: loss = 0.192824 * 100, metric = 5.99% * 100;
 Minibatch[1801-1900]: loss = 0.208921 * 100, metric = 6.73% * 100;
 Minibatch[1901-2000]: loss = 0.201342 * 100, metric = 6.48% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.205767 * 2000, metric = 6.56% * 2000 935.099s (  2.1 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 15.68% * 2000;
 Minibatch[   1- 100]: loss = 0.219426 * 100, metric = 7.17% * 100;
 Minibatch[ 101- 200]: loss = 0.209224 * 100, metric = 6.74% * 100;
 Minibatch[ 201- 300]: loss = 0.205829 * 100, metric = 6.58% * 100;
 Minibatch[ 301- 400]: loss = 0.211369 * 100, metric = 6.63% * 100;
 Minibatch[ 401- 500]: loss = 0.198894 * 100, metric = 6.23% * 100;
 Minibatch[ 501- 600]: loss = 0.209068 * 100, metric = 6.46% * 100;
 Minibatch[ 601- 700]: loss = 0.197992 * 100, metric = 6.29% * 100;
 Minibatch[ 701- 800]: loss = 0.198436 * 100, metric = 6.16% * 100;
 Minibatch[ 801- 900]: loss = 0.197271 * 100, metric = 6.41% * 100;
 Minibatch[ 901-1000]: loss = 0.202741 * 100, metric = 6.61% * 100;
 Minibatch[1001-1100]: loss = 0.195932 * 100, metric = 6.25% * 100;
 Minibatch[1101-1200]: loss = 0.198738 * 100, metric = 6.32% * 100;
 Minibatch[1201-1300]: loss = 0.193092 * 100, metric = 6.23% * 100;
 Minibatch[1301-1400]: loss = 0.199869 * 100, metric = 6.37% * 100;
 Minibatch[1401-1500]: loss = 0.198590 * 100, metric = 6.41% * 100;
 Minibatch[1501-1600]: loss = 0.198369 * 100, metric = 6.43% * 100;
 Minibatch[1601-1700]: loss = 0.197069 * 100, metric = 6.34% * 100;
 Minibatch[1701-1800]: loss = 0.209404 * 100, metric = 6.65% * 100;
 Minibatch[1801-1900]: loss = 0.206937 * 100, metric = 6.45% * 100;
 Minibatch[1901-2000]: loss = 0.194780 * 100, metric = 6.38% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.202152 * 2000, metric = 6.46% * 2000 943.792s (  2.1 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 15.91% * 2000;
 Minibatch[   1- 100]: loss = 0.188925 * 100, metric = 6.18% * 100;
 Minibatch[ 101- 200]: loss = 0.202248 * 100, metric = 6.56% * 100;
 Minibatch[ 201- 300]: loss = 0.204867 * 100, metric = 6.45% * 100;
 Minibatch[ 301- 400]: loss = 0.196197 * 100, metric = 6.42% * 100;
 Minibatch[ 401- 500]: loss = 0.196289 * 100, metric = 6.23% * 100;
 Minibatch[ 501- 600]: loss = 0.191403 * 100, metric = 6.06% * 100;
 Minibatch[ 601- 700]: loss = 0.186236 * 100, metric = 5.86% * 100;
 Minibatch[ 701- 800]: loss = 0.196244 * 100, metric = 6.21% * 100;
 Minibatch[ 801- 900]: loss = 0.195439 * 100, metric = 6.16% * 100;
 Minibatch[ 901-1000]: loss = 0.194573 * 100, metric = 6.07% * 100;
 Minibatch[1001-1100]: loss = 0.192724 * 100, metric = 5.99% * 100;
 Minibatch[1101-1200]: loss = 0.206563 * 100, metric = 6.62% * 100;
 Minibatch[1201-1300]: loss = 0.199774 * 100, metric = 6.32% * 100;
 Minibatch[1301-1400]: loss = 0.185810 * 100, metric = 5.93% * 100;
 Minibatch[1401-1500]: loss = 0.198195 * 100, metric = 6.32% * 100;
 Minibatch[1501-1600]: loss = 0.196417 * 100, metric = 6.34% * 100;
 Minibatch[1601-1700]: loss = 0.198418 * 100, metric = 6.44% * 100;
 Minibatch[1701-1800]: loss = 0.183024 * 100, metric = 5.80% * 100;
 Minibatch[1801-1900]: loss = 0.202644 * 100, metric = 6.51% * 100;
 Minibatch[1901-2000]: loss = 0.203805 * 100, metric = 6.58% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.195990 * 2000, metric = 6.25% * 2000 885.443s (  2.3 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 15.50% * 2000;
 Minibatch[   1- 100]: loss = 0.182618 * 100, metric = 5.88% * 100;
 Minibatch[ 101- 200]: loss = 0.195856 * 100, metric = 6.40% * 100;
 Minibatch[ 201- 300]: loss = 0.184706 * 100, metric = 5.92% * 100;
 Minibatch[ 301- 400]: loss = 0.191219 * 100, metric = 6.09% * 100;
 Minibatch[ 401- 500]: loss = 0.182002 * 100, metric = 5.72% * 100;
 Minibatch[ 501- 600]: loss = 0.191082 * 100, metric = 6.17% * 100;
 Minibatch[ 601- 700]: loss = 0.196287 * 100, metric = 6.34% * 100;
 Minibatch[ 701- 800]: loss = 0.186360 * 100, metric = 5.97% * 100;
 Minibatch[ 801- 900]: loss = 0.193653 * 100, metric = 6.22% * 100;
 Minibatch[ 901-1000]: loss = 0.196938 * 100, metric = 6.43% * 100;
 Minibatch[1001-1100]: loss = 0.199874 * 100, metric = 6.29% * 100;
 Minibatch[1101-1200]: loss = 0.197314 * 100, metric = 6.22% * 100;
 Minibatch[1201-1300]: loss = 0.205180 * 100, metric = 6.48% * 100;
 Minibatch[1301-1400]: loss = 0.201887 * 100, metric = 6.32% * 100;
 Minibatch[1401-1500]: loss = 0.183575 * 100, metric = 5.96% * 100;
 Minibatch[1501-1600]: loss = 0.187791 * 100, metric = 5.90% * 100;
 Minibatch[1601-1700]: loss = 0.179997 * 100, metric = 5.63% * 100;
 Minibatch[1701-1800]: loss = 0.181740 * 100, metric = 5.75% * 100;
 Minibatch[1801-1900]: loss = 0.179312 * 100, metric = 5.60% * 100;
 Minibatch[1901-2000]: loss = 0.183246 * 100, metric = 5.81% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.190032 * 2000, metric = 6.05% * 2000 901.857s (  2.2 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 16.65% * 2000;
 Minibatch[   1- 100]: loss = 0.195517 * 100, metric = 6.43% * 100;
 Minibatch[ 101- 200]: loss = 0.201819 * 100, metric = 6.43% * 100;
 Minibatch[ 201- 300]: loss = 0.180431 * 100, metric = 5.72% * 100;
 Minibatch[ 301- 400]: loss = 0.192276 * 100, metric = 6.13% * 100;
 Minibatch[ 401- 500]: loss = 0.188796 * 100, metric = 6.02% * 100;
 Minibatch[ 501- 600]: loss = 0.183527 * 100, metric = 5.79% * 100;
 Minibatch[ 601- 700]: loss = 0.198270 * 100, metric = 6.43% * 100;
 Minibatch[ 701- 800]: loss = 0.182917 * 100, metric = 5.86% * 100;
 Minibatch[ 801- 900]: loss = 0.205335 * 100, metric = 6.51% * 100;
 Minibatch[ 901-1000]: loss = 0.178830 * 100, metric = 5.75% * 100;
 Minibatch[1001-1100]: loss = 0.193270 * 100, metric = 6.37% * 100;
 Minibatch[1101-1200]: loss = 0.193943 * 100, metric = 6.31% * 100;
 Minibatch[1201-1300]: loss = 0.184757 * 100, metric = 6.03% * 100;
 Minibatch[1301-1400]: loss = 0.187634 * 100, metric = 6.15% * 100;
 Minibatch[1401-1500]: loss = 0.190148 * 100, metric = 6.15% * 100;
 Minibatch[1501-1600]: loss = 0.189887 * 100, metric = 5.97% * 100;
 Minibatch[1601-1700]: loss = 0.184659 * 100, metric = 5.92% * 100;
 Minibatch[1701-1800]: loss = 0.171703 * 100, metric = 5.45% * 100;
 Minibatch[1801-1900]: loss = 0.178382 * 100, metric = 5.80% * 100;
 Minibatch[1901-2000]: loss = 0.178251 * 100, metric = 5.66% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.188018 * 2000, metric = 6.04% * 2000 922.250s (  2.2 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 17.18% * 2000;
 Minibatch[   1- 100]: loss = 0.179494 * 100, metric = 5.78% * 100;
 Minibatch[ 101- 200]: loss = 0.181100 * 100, metric = 5.79% * 100;
 Minibatch[ 201- 300]: loss = 0.180957 * 100, metric = 5.81% * 100;
 Minibatch[ 301- 400]: loss = 0.193177 * 100, metric = 5.94% * 100;
 Minibatch[ 401- 500]: loss = 0.181128 * 100, metric = 5.81% * 100;
 Minibatch[ 501- 600]: loss = 0.190544 * 100, metric = 6.17% * 100;
 Minibatch[ 601- 700]: loss = 0.190375 * 100, metric = 6.16% * 100;
 Minibatch[ 701- 800]: loss = 0.182919 * 100, metric = 5.89% * 100;
 Minibatch[ 801- 900]: loss = 0.192269 * 100, metric = 6.16% * 100;
 Minibatch[ 901-1000]: loss = 0.191899 * 100, metric = 6.27% * 100;
 Minibatch[1001-1100]: loss = 0.175271 * 100, metric = 5.56% * 100;
 Minibatch[1101-1200]: loss = 0.184858 * 100, metric = 5.87% * 100;
 Minibatch[1201-1300]: loss = 0.194373 * 100, metric = 6.28% * 100;
 Minibatch[1301-1400]: loss = 0.192254 * 100, metric = 6.21% * 100;
 Minibatch[1401-1500]: loss = 0.185827 * 100, metric = 6.07% * 100;
 Minibatch[1501-1600]: loss = 0.194313 * 100, metric = 6.05% * 100;
 Minibatch[1601-1700]: loss = 0.189227 * 100, metric = 5.90% * 100;
 Minibatch[1701-1800]: loss = 0.192714 * 100, metric = 6.13% * 100;
 Minibatch[1801-1900]: loss = 0.187228 * 100, metric = 6.02% * 100;
 Minibatch[1901-2000]: loss = 0.182007 * 100, metric = 5.87% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.187097 * 2000, metric = 5.99% * 2000 924.616s (  2.2 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 16.64% * 2000;
 Minibatch[   1- 100]: loss = 0.179871 * 100, metric = 5.69% * 100;
 Minibatch[ 101- 200]: loss = 0.180049 * 100, metric = 5.68% * 100;
 Minibatch[ 201- 300]: loss = 0.180791 * 100, metric = 5.91% * 100;
 Minibatch[ 301- 400]: loss = 0.187561 * 100, metric = 5.98% * 100;
 Minibatch[ 401- 500]: loss = 0.179499 * 100, metric = 5.70% * 100;
 Minibatch[ 501- 600]: loss = 0.175803 * 100, metric = 5.69% * 100;
 Minibatch[ 601- 700]: loss = 0.182575 * 100, metric = 5.87% * 100;
 Minibatch[ 701- 800]: loss = 0.162114 * 100, metric = 5.04% * 100;
 Minibatch[ 801- 900]: loss = 0.182220 * 100, metric = 5.74% * 100;
 Minibatch[ 901-1000]: loss = 0.173440 * 100, metric = 5.47% * 100;
 Minibatch[1001-1100]: loss = 0.177970 * 100, metric = 5.59% * 100;
 Minibatch[1101-1200]: loss = 0.179609 * 100, metric = 5.63% * 100;
 Minibatch[1201-1300]: loss = 0.180435 * 100, metric = 5.76% * 100;
 Minibatch[1301-1400]: loss = 0.170926 * 100, metric = 5.49% * 100;
 Minibatch[1401-1500]: loss = 0.186212 * 100, metric = 6.12% * 100;
 Minibatch[1501-1600]: loss = 0.186693 * 100, metric = 6.11% * 100;
 Minibatch[1601-1700]: loss = 0.181035 * 100, metric = 5.67% * 100;
 Minibatch[1701-1800]: loss = 0.174229 * 100, metric = 5.36% * 100;
 Minibatch[1801-1900]: loss = 0.192686 * 100, metric = 6.08% * 100;
 Minibatch[1901-2000]: loss = 0.177720 * 100, metric = 5.46% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.179572 * 2000, metric = 5.70% * 2000 916.525s (  2.2 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 15.36% * 2000;
 Minibatch[   1- 100]: loss = 0.188409 * 100, metric = 6.00% * 100;
 Minibatch[ 101- 200]: loss = 0.181396 * 100, metric = 5.90% * 100;
 Minibatch[ 201- 300]: loss = 0.182804 * 100, metric = 5.89% * 100;
 Minibatch[ 301- 400]: loss = 0.179718 * 100, metric = 5.89% * 100;
 Minibatch[ 401- 500]: loss = 0.178539 * 100, metric = 5.61% * 100;
 Minibatch[ 501- 600]: loss = 0.181976 * 100, metric = 5.76% * 100;
 Minibatch[ 601- 700]: loss = 0.170688 * 100, metric = 5.50% * 100;
 Minibatch[ 701- 800]: loss = 0.175822 * 100, metric = 5.65% * 100;
 Minibatch[ 801- 900]: loss = 0.180131 * 100, metric = 5.76% * 100;
 Minibatch[ 901-1000]: loss = 0.184399 * 100, metric = 5.85% * 100;
 Minibatch[1001-1100]: loss = 0.172239 * 100, metric = 5.31% * 100;
 Minibatch[1101-1200]: loss = 0.163014 * 100, metric = 5.14% * 100;
 Minibatch[1201-1300]: loss = 0.173484 * 100, metric = 5.71% * 100;
 Minibatch[1301-1400]: loss = 0.176252 * 100, metric = 5.54% * 100;
 Minibatch[1401-1500]: loss = 0.175594 * 100, metric = 5.59% * 100;
 Minibatch[1501-1600]: loss = 0.172252 * 100, metric = 5.46% * 100;
 Minibatch[1601-1700]: loss = 0.176724 * 100, metric = 5.65% * 100;
 Minibatch[1701-1800]: loss = 0.173263 * 100, metric = 5.49% * 100;
 Minibatch[1801-1900]: loss = 0.174424 * 100, metric = 5.55% * 100;
 Minibatch[1901-2000]: loss = 0.169700 * 100, metric = 5.42% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.176541 * 2000, metric = 5.63% * 2000 909.524s (  2.2 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 15.88% * 2000;
 Minibatch[   1- 100]: loss = 0.179788 * 100, metric = 5.73% * 100;
 Minibatch[ 101- 200]: loss = 0.184993 * 100, metric = 6.09% * 100;
 Minibatch[ 201- 300]: loss = 0.174148 * 100, metric = 5.65% * 100;
 Minibatch[ 301- 400]: loss = 0.183247 * 100, metric = 5.95% * 100;
 Minibatch[ 401- 500]: loss = 0.183777 * 100, metric = 5.92% * 100;
 Minibatch[ 501- 600]: loss = 0.180131 * 100, metric = 5.85% * 100;
 Minibatch[ 601- 700]: loss = 0.177043 * 100, metric = 5.55% * 100;
 Minibatch[ 701- 800]: loss = 0.164401 * 100, metric = 5.35% * 100;
 Minibatch[ 801- 900]: loss = 0.171351 * 100, metric = 5.74% * 100;
 Minibatch[ 901-1000]: loss = 0.175905 * 100, metric = 5.66% * 100;
 Minibatch[1001-1100]: loss = 0.169097 * 100, metric = 5.31% * 100;
 Minibatch[1101-1200]: loss = 0.172664 * 100, metric = 5.44% * 100;
 Minibatch[1201-1300]: loss = 0.172044 * 100, metric = 5.48% * 100;
 Minibatch[1301-1400]: loss = 0.174341 * 100, metric = 5.64% * 100;
 Minibatch[1401-1500]: loss = 0.167691 * 100, metric = 5.31% * 100;
 Minibatch[1501-1600]: loss = 0.168854 * 100, metric = 5.35% * 100;
 Minibatch[1601-1700]: loss = 0.170838 * 100, metric = 5.48% * 100;
 Minibatch[1701-1800]: loss = 0.179068 * 100, metric = 5.61% * 100;
 Minibatch[1801-1900]: loss = 0.177284 * 100, metric = 5.67% * 100;
 Minibatch[1901-2000]: loss = 0.176405 * 100, metric = 5.90% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.175153 * 2000, metric = 5.63% * 2000 929.629s (  2.2 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 16.08% * 2000;
 Minibatch[   1- 100]: loss = 0.163905 * 100, metric = 5.37% * 100;
 Minibatch[ 101- 200]: loss = 0.170102 * 100, metric = 5.40% * 100;
 Minibatch[ 201- 300]: loss = 0.171103 * 100, metric = 5.54% * 100;
 Minibatch[ 301- 400]: loss = 0.165553 * 100, metric = 5.23% * 100;
 Minibatch[ 401- 500]: loss = 0.176019 * 100, metric = 5.71% * 100;
 Minibatch[ 501- 600]: loss = 0.160715 * 100, metric = 5.21% * 100;
 Minibatch[ 601- 700]: loss = 0.178005 * 100, metric = 5.57% * 100;
 Minibatch[ 701- 800]: loss = 0.170144 * 100, metric = 5.50% * 100;
 Minibatch[ 801- 900]: loss = 0.171482 * 100, metric = 5.55% * 100;
 Minibatch[ 901-1000]: loss = 0.173159 * 100, metric = 5.60% * 100;
 Minibatch[1001-1100]: loss = 0.170157 * 100, metric = 5.38% * 100;
 Minibatch[1101-1200]: loss = 0.177216 * 100, metric = 5.36% * 100;
 Minibatch[1201-1300]: loss = 0.171935 * 100, metric = 5.47% * 100;
 Minibatch[1301-1400]: loss = 0.167160 * 100, metric = 5.38% * 100;
 Minibatch[1401-1500]: loss = 0.160770 * 100, metric = 5.10% * 100;
 Minibatch[1501-1600]: loss = 0.177024 * 100, metric = 5.78% * 100;
 Minibatch[1601-1700]: loss = 0.167390 * 100, metric = 5.34% * 100;
 Minibatch[1701-1800]: loss = 0.165997 * 100, metric = 5.34% * 100;
 Minibatch[1801-1900]: loss = 0.175291 * 100, metric = 5.68% * 100;
 Minibatch[1901-2000]: loss = 0.171415 * 100, metric = 5.52% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.170227 * 2000, metric = 5.45% * 2000 930.923s (  2.1 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 15.80% * 2000;
 Minibatch[   1- 100]: loss = 0.176763 * 100, metric = 5.62% * 100;
 Minibatch[ 101- 200]: loss = 0.172956 * 100, metric = 5.54% * 100;
 Minibatch[ 201- 300]: loss = 0.176255 * 100, metric = 5.90% * 100;
 Minibatch[ 301- 400]: loss = 0.176094 * 100, metric = 5.78% * 100;
 Minibatch[ 401- 500]: loss = 0.172841 * 100, metric = 5.49% * 100;
 Minibatch[ 501- 600]: loss = 0.167822 * 100, metric = 5.32% * 100;
 Minibatch[ 601- 700]: loss = 0.170389 * 100, metric = 5.46% * 100;
 Minibatch[ 701- 800]: loss = 0.165157 * 100, metric = 5.35% * 100;
 Minibatch[ 801- 900]: loss = 0.162646 * 100, metric = 5.12% * 100;
 Minibatch[ 901-1000]: loss = 0.169635 * 100, metric = 5.40% * 100;
 Minibatch[1001-1100]: loss = 0.166393 * 100, metric = 5.30% * 100;
 Minibatch[1101-1200]: loss = 0.177216 * 100, metric = 5.66% * 100;
 Minibatch[1201-1300]: loss = 0.184833 * 100, metric = 5.63% * 100;
 Minibatch[1301-1400]: loss = 0.161505 * 100, metric = 5.05% * 100;
 Minibatch[1401-1500]: loss = 0.162177 * 100, metric = 5.12% * 100;
 Minibatch[1501-1600]: loss = 0.177102 * 100, metric = 5.71% * 100;
 Minibatch[1601-1700]: loss = 0.164554 * 100, metric = 5.17% * 100;
 Minibatch[1701-1800]: loss = 0.167904 * 100, metric = 5.39% * 100;
 Minibatch[1801-1900]: loss = 0.167228 * 100, metric = 5.38% * 100;
 Minibatch[1901-2000]: loss = 0.157369 * 100, metric = 4.86% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.169842 * 2000, metric = 5.41% * 2000 932.675s (  2.1 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 15.54% * 2000;
 Minibatch[   1- 100]: loss = 0.168943 * 100, metric = 5.34% * 100;
 Minibatch[ 101- 200]: loss = 0.157360 * 100, metric = 4.97% * 100;
 Minibatch[ 201- 300]: loss = 0.166824 * 100, metric = 5.41% * 100;
 Minibatch[ 301- 400]: loss = 0.156620 * 100, metric = 5.00% * 100;
 Minibatch[ 401- 500]: loss = 0.165344 * 100, metric = 5.30% * 100;
 Minibatch[ 501- 600]: loss = 0.165259 * 100, metric = 5.21% * 100;
 Minibatch[ 601- 700]: loss = 0.173091 * 100, metric = 5.37% * 100;
 Minibatch[ 701- 800]: loss = 0.163506 * 100, metric = 5.26% * 100;
 Minibatch[ 801- 900]: loss = 0.158415 * 100, metric = 5.15% * 100;
 Minibatch[ 901-1000]: loss = 0.162469 * 100, metric = 5.22% * 100;
 Minibatch[1001-1100]: loss = 0.172265 * 100, metric = 5.55% * 100;
 Minibatch[1101-1200]: loss = 0.172292 * 100, metric = 5.55% * 100;
 Minibatch[1201-1300]: loss = 0.168855 * 100, metric = 5.42% * 100;
 Minibatch[1301-1400]: loss = 0.161908 * 100, metric = 5.07% * 100;
 Minibatch[1401-1500]: loss = 0.167532 * 100, metric = 5.41% * 100;
 Minibatch[1501-1600]: loss = 0.153203 * 100, metric = 4.88% * 100;
 Minibatch[1601-1700]: loss = 0.176732 * 100, metric = 5.61% * 100;
 Minibatch[1701-1800]: loss = 0.171555 * 100, metric = 5.51% * 100;
 Minibatch[1801-1900]: loss = 0.162324 * 100, metric = 5.15% * 100;
 Minibatch[1901-2000]: loss = 0.161243 * 100, metric = 5.21% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.165287 * 2000, metric = 5.28% * 2000 914.589s (  2.2 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.67% * 2000;
 Minibatch[   1- 100]: loss = 0.164394 * 100, metric = 5.15% * 100;
 Minibatch[ 101- 200]: loss = 0.168720 * 100, metric = 5.23% * 100;
 Minibatch[ 201- 300]: loss = 0.164548 * 100, metric = 5.32% * 100;
 Minibatch[ 301- 400]: loss = 0.161353 * 100, metric = 5.17% * 100;
 Minibatch[ 401- 500]: loss = 0.162713 * 100, metric = 5.17% * 100;
 Minibatch[ 501- 600]: loss = 0.166662 * 100, metric = 5.32% * 100;
 Minibatch[ 601- 700]: loss = 0.154565 * 100, metric = 4.81% * 100;
 Minibatch[ 701- 800]: loss = 0.162274 * 100, metric = 5.18% * 100;
 Minibatch[ 801- 900]: loss = 0.173786 * 100, metric = 5.45% * 100;
 Minibatch[ 901-1000]: loss = 0.164367 * 100, metric = 5.27% * 100;
 Minibatch[1001-1100]: loss = 0.156796 * 100, metric = 5.10% * 100;
 Minibatch[1101-1200]: loss = 0.168622 * 100, metric = 5.47% * 100;
 Minibatch[1201-1300]: loss = 0.162141 * 100, metric = 5.14% * 100;
 Minibatch[1301-1400]: loss = 0.170999 * 100, metric = 5.58% * 100;
 Minibatch[1401-1500]: loss = 0.160972 * 100, metric = 5.07% * 100;
 Minibatch[1501-1600]: loss = 0.160240 * 100, metric = 5.01% * 100;
 Minibatch[1601-1700]: loss = 0.153558 * 100, metric = 4.87% * 100;
 Minibatch[1701-1800]: loss = 0.158816 * 100, metric = 5.01% * 100;
 Minibatch[1801-1900]: loss = 0.161613 * 100, metric = 5.13% * 100;
 Minibatch[1901-2000]: loss = 0.162306 * 100, metric = 5.12% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.162972 * 2000, metric = 5.18% * 2000 868.712s (  2.3 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 14.98% * 2000;
 Minibatch[   1- 100]: loss = 0.163260 * 100, metric = 5.16% * 100;
 Minibatch[ 101- 200]: loss = 0.155259 * 100, metric = 4.91% * 100;
 Minibatch[ 201- 300]: loss = 0.162558 * 100, metric = 4.98% * 100;
 Minibatch[ 301- 400]: loss = 0.165029 * 100, metric = 5.23% * 100;
 Minibatch[ 401- 500]: loss = 0.164171 * 100, metric = 5.46% * 100;
 Minibatch[ 501- 600]: loss = 0.171889 * 100, metric = 5.37% * 100;
 Minibatch[ 601- 700]: loss = 0.156938 * 100, metric = 5.08% * 100;
 Minibatch[ 701- 800]: loss = 0.155308 * 100, metric = 5.01% * 100;
 Minibatch[ 801- 900]: loss = 0.162534 * 100, metric = 5.20% * 100;
 Minibatch[ 901-1000]: loss = 0.168330 * 100, metric = 5.34% * 100;
 Minibatch[1001-1100]: loss = 0.157273 * 100, metric = 5.02% * 100;
 Minibatch[1101-1200]: loss = 0.155888 * 100, metric = 4.99% * 100;
 Minibatch[1201-1300]: loss = 0.159853 * 100, metric = 5.02% * 100;
 Minibatch[1301-1400]: loss = 0.156278 * 100, metric = 4.93% * 100;
 Minibatch[1401-1500]: loss = 0.167895 * 100, metric = 5.39% * 100;
 Minibatch[1501-1600]: loss = 0.157811 * 100, metric = 5.00% * 100;
 Minibatch[1601-1700]: loss = 0.162343 * 100, metric = 5.18% * 100;
 Minibatch[1701-1800]: loss = 0.155589 * 100, metric = 5.04% * 100;
 Minibatch[1801-1900]: loss = 0.162234 * 100, metric = 5.20% * 100;
 Minibatch[1901-2000]: loss = 0.163022 * 100, metric = 5.14% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.161173 * 2000, metric = 5.13% * 2000 907.054s (  2.2 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 14.35% * 2000;
0.4237161088399589
 Minibatch[   1- 100]: loss = 0.156083 * 100, metric = 4.89% * 100;
 Minibatch[ 101- 200]: loss = 0.158680 * 100, metric = 5.01% * 100;
 Minibatch[ 201- 300]: loss = 0.161284 * 100, metric = 5.17% * 100;
 Minibatch[ 301- 400]: loss = 0.171600 * 100, metric = 5.50% * 100;
 Minibatch[ 401- 500]: loss = 0.156672 * 100, metric = 5.03% * 100;
 Minibatch[ 501- 600]: loss = 0.162655 * 100, metric = 5.33% * 100;
 Minibatch[ 601- 700]: loss = 0.157205 * 100, metric = 5.16% * 100;
 Minibatch[ 701- 800]: loss = 0.171332 * 100, metric = 5.41% * 100;
 Minibatch[ 801- 900]: loss = 0.156315 * 100, metric = 5.05% * 100;
 Minibatch[ 901-1000]: loss = 0.164238 * 100, metric = 5.31% * 100;
 Minibatch[1001-1100]: loss = 0.159313 * 100, metric = 5.06% * 100;
 Minibatch[1101-1200]: loss = 0.157166 * 100, metric = 5.03% * 100;
 Minibatch[1201-1300]: loss = 0.155779 * 100, metric = 5.10% * 100;
 Minibatch[1301-1400]: loss = 0.152952 * 100, metric = 4.93% * 100;
 Minibatch[1401-1500]: loss = 0.165967 * 100, metric = 5.19% * 100;
 Minibatch[1501-1600]: loss = 0.153038 * 100, metric = 4.83% * 100;
 Minibatch[1601-1700]: loss = 0.163209 * 100, metric = 5.20% * 100;
 Minibatch[1701-1800]: loss = 0.153641 * 100, metric = 4.89% * 100;
 Minibatch[1801-1900]: loss = 0.166446 * 100, metric = 5.30% * 100;
 Minibatch[1901-2000]: loss = 0.154704 * 100, metric = 4.96% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.159914 * 2000, metric = 5.12% * 2000 917.689s (  2.2 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 16.47% * 2000;
 Minibatch[   1- 100]: loss = 0.161262 * 100, metric = 5.06% * 100;
 Minibatch[ 101- 200]: loss = 0.144474 * 100, metric = 4.59% * 100;
 Minibatch[ 201- 300]: loss = 0.154576 * 100, metric = 4.91% * 100;
 Minibatch[ 301- 400]: loss = 0.157732 * 100, metric = 5.06% * 100;
 Minibatch[ 401- 500]: loss = 0.156878 * 100, metric = 5.01% * 100;
 Minibatch[ 501- 600]: loss = 0.143179 * 100, metric = 4.59% * 100;
 Minibatch[ 601- 700]: loss = 0.155212 * 100, metric = 5.03% * 100;
 Minibatch[ 701- 800]: loss = 0.144573 * 100, metric = 4.52% * 100;
 Minibatch[ 801- 900]: loss = 0.165473 * 100, metric = 5.10% * 100;
 Minibatch[ 901-1000]: loss = 0.145237 * 100, metric = 4.64% * 100;
 Minibatch[1001-1100]: loss = 0.160177 * 100, metric = 5.09% * 100;
 Minibatch[1101-1200]: loss = 0.162025 * 100, metric = 5.24% * 100;
 Minibatch[1201-1300]: loss = 0.157565 * 100, metric = 4.93% * 100;
 Minibatch[1301-1400]: loss = 0.155834 * 100, metric = 4.96% * 100;
 Minibatch[1401-1500]: loss = 0.155189 * 100, metric = 5.02% * 100;
 Minibatch[1501-1600]: loss = 0.159419 * 100, metric = 5.16% * 100;
 Minibatch[1601-1700]: loss = 0.152820 * 100, metric = 4.83% * 100;
 Minibatch[1701-1800]: loss = 0.159300 * 100, metric = 5.04% * 100;
 Minibatch[1801-1900]: loss = 0.158630 * 100, metric = 5.12% * 100;
 Minibatch[1901-2000]: loss = 0.167373 * 100, metric = 5.35% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.155846 * 2000, metric = 4.96% * 2000 920.688s (  2.2 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 16.64% * 2000;
 Minibatch[   1- 100]: loss = 0.151657 * 100, metric = 4.85% * 100;
 Minibatch[ 101- 200]: loss = 0.165457 * 100, metric = 5.34% * 100;
 Minibatch[ 201- 300]: loss = 0.155761 * 100, metric = 4.95% * 100;
 Minibatch[ 301- 400]: loss = 0.155182 * 100, metric = 5.06% * 100;
 Minibatch[ 401- 500]: loss = 0.152166 * 100, metric = 4.81% * 100;
 Minibatch[ 501- 600]: loss = 0.152248 * 100, metric = 4.76% * 100;
 Minibatch[ 601- 700]: loss = 0.163846 * 100, metric = 5.27% * 100;
 Minibatch[ 701- 800]: loss = 0.160707 * 100, metric = 5.12% * 100;
 Minibatch[ 801- 900]: loss = 0.157921 * 100, metric = 5.00% * 100;
 Minibatch[ 901-1000]: loss = 0.150498 * 100, metric = 4.94% * 100;
 Minibatch[1001-1100]: loss = 0.147293 * 100, metric = 4.78% * 100;
 Minibatch[1101-1200]: loss = 0.156169 * 100, metric = 5.11% * 100;
 Minibatch[1201-1300]: loss = 0.156824 * 100, metric = 5.03% * 100;
 Minibatch[1301-1400]: loss = 0.158443 * 100, metric = 4.99% * 100;
 Minibatch[1401-1500]: loss = 0.163598 * 100, metric = 5.24% * 100;
 Minibatch[1501-1600]: loss = 0.151365 * 100, metric = 4.88% * 100;
 Minibatch[1601-1700]: loss = 0.154700 * 100, metric = 5.03% * 100;
 Minibatch[1701-1800]: loss = 0.159402 * 100, metric = 5.21% * 100;
 Minibatch[1801-1900]: loss = 0.161021 * 100, metric = 5.26% * 100;
 Minibatch[1901-2000]: loss = 0.157043 * 100, metric = 5.15% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.156565 * 2000, metric = 5.04% * 2000 918.300s (  2.2 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 15.75% * 2000;
 Minibatch[   1- 100]: loss = 0.153296 * 100, metric = 4.99% * 100;
 Minibatch[ 101- 200]: loss = 0.157612 * 100, metric = 5.03% * 100;
 Minibatch[ 201- 300]: loss = 0.162104 * 100, metric = 5.15% * 100;
 Minibatch[ 301- 400]: loss = 0.165200 * 100, metric = 5.15% * 100;
 Minibatch[ 401- 500]: loss = 0.159228 * 100, metric = 5.16% * 100;
 Minibatch[ 501- 600]: loss = 0.157651 * 100, metric = 5.05% * 100;
 Minibatch[ 601- 700]: loss = 0.150056 * 100, metric = 4.80% * 100;
 Minibatch[ 701- 800]: loss = 0.152655 * 100, metric = 4.81% * 100;
 Minibatch[ 801- 900]: loss = 0.157301 * 100, metric = 5.00% * 100;
 Minibatch[ 901-1000]: loss = 0.146340 * 100, metric = 4.66% * 100;
 Minibatch[1001-1100]: loss = 0.146246 * 100, metric = 4.73% * 100;
 Minibatch[1101-1200]: loss = 0.157352 * 100, metric = 5.06% * 100;
 Minibatch[1201-1300]: loss = 0.158177 * 100, metric = 4.98% * 100;
 Minibatch[1301-1400]: loss = 0.153628 * 100, metric = 4.91% * 100;
 Minibatch[1401-1500]: loss = 0.156192 * 100, metric = 5.12% * 100;
 Minibatch[1501-1600]: loss = 0.159350 * 100, metric = 4.97% * 100;
 Minibatch[1601-1700]: loss = 0.149843 * 100, metric = 4.84% * 100;
 Minibatch[1701-1800]: loss = 0.156619 * 100, metric = 4.99% * 100;
 Minibatch[1801-1900]: loss = 0.146320 * 100, metric = 4.66% * 100;
 Minibatch[1901-2000]: loss = 0.159758 * 100, metric = 5.23% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.155246 * 2000, metric = 4.97% * 2000 902.083s (  2.2 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 15.66% * 2000;
 Minibatch[   1- 100]: loss = 0.164029 * 100, metric = 5.22% * 100;
 Minibatch[ 101- 200]: loss = 0.151335 * 100, metric = 4.92% * 100;
 Minibatch[ 201- 300]: loss = 0.151106 * 100, metric = 4.84% * 100;
 Minibatch[ 301- 400]: loss = 0.154574 * 100, metric = 4.89% * 100;
 Minibatch[ 401- 500]: loss = 0.148018 * 100, metric = 4.71% * 100;
 Minibatch[ 501- 600]: loss = 0.152262 * 100, metric = 4.76% * 100;
 Minibatch[ 601- 700]: loss = 0.154191 * 100, metric = 4.95% * 100;
 Minibatch[ 701- 800]: loss = 0.150500 * 100, metric = 4.89% * 100;
 Minibatch[ 801- 900]: loss = 0.146732 * 100, metric = 4.63% * 100;
 Minibatch[ 901-1000]: loss = 0.139659 * 100, metric = 4.48% * 100;
 Minibatch[1001-1100]: loss = 0.151348 * 100, metric = 5.01% * 100;
 Minibatch[1101-1200]: loss = 0.143642 * 100, metric = 4.64% * 100;
 Minibatch[1201-1300]: loss = 0.156894 * 100, metric = 4.87% * 100;
 Minibatch[1301-1400]: loss = 0.142592 * 100, metric = 4.64% * 100;
 Minibatch[1401-1500]: loss = 0.163416 * 100, metric = 5.12% * 100;
 Minibatch[1501-1600]: loss = 0.156072 * 100, metric = 4.93% * 100;
 Minibatch[1601-1700]: loss = 0.147185 * 100, metric = 4.54% * 100;
 Minibatch[1701-1800]: loss = 0.148770 * 100, metric = 4.73% * 100;
 Minibatch[1801-1900]: loss = 0.144973 * 100, metric = 4.68% * 100;
 Minibatch[1901-2000]: loss = 0.158351 * 100, metric = 5.00% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.151282 * 2000, metric = 4.82% * 2000 819.839s (  2.4 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 14.43% * 2000;
 Minibatch[   1- 100]: loss = 0.141145 * 100, metric = 4.49% * 100;
 Minibatch[ 101- 200]: loss = 0.152655 * 100, metric = 4.91% * 100;
 Minibatch[ 201- 300]: loss = 0.144182 * 100, metric = 4.62% * 100;
 Minibatch[ 301- 400]: loss = 0.154320 * 100, metric = 4.92% * 100;
 Minibatch[ 401- 500]: loss = 0.148113 * 100, metric = 4.66% * 100;
 Minibatch[ 501- 600]: loss = 0.155638 * 100, metric = 4.98% * 100;
 Minibatch[ 601- 700]: loss = 0.154065 * 100, metric = 4.87% * 100;
 Minibatch[ 701- 800]: loss = 0.151189 * 100, metric = 4.93% * 100;
 Minibatch[ 801- 900]: loss = 0.144874 * 100, metric = 4.58% * 100;
 Minibatch[ 901-1000]: loss = 0.145226 * 100, metric = 4.66% * 100;
 Minibatch[1001-1100]: loss = 0.154058 * 100, metric = 5.01% * 100;
 Minibatch[1101-1200]: loss = 0.147222 * 100, metric = 4.84% * 100;
 Minibatch[1201-1300]: loss = 0.152164 * 100, metric = 5.00% * 100;
 Minibatch[1301-1400]: loss = 0.149337 * 100, metric = 4.82% * 100;
 Minibatch[1401-1500]: loss = 0.156854 * 100, metric = 5.06% * 100;
 Minibatch[1501-1600]: loss = 0.150418 * 100, metric = 4.79% * 100;
 Minibatch[1601-1700]: loss = 0.158343 * 100, metric = 5.21% * 100;
 Minibatch[1701-1800]: loss = 0.145576 * 100, metric = 4.67% * 100;
 Minibatch[1801-1900]: loss = 0.146065 * 100, metric = 4.71% * 100;
 Minibatch[1901-2000]: loss = 0.150025 * 100, metric = 4.90% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.150073 * 2000, metric = 4.83% * 2000 840.558s (  2.4 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 16.19% * 2000;
 Minibatch[   1- 100]: loss = 0.141220 * 100, metric = 4.51% * 100;
 Minibatch[ 101- 200]: loss = 0.148791 * 100, metric = 4.86% * 100;
 Minibatch[ 201- 300]: loss = 0.152010 * 100, metric = 4.98% * 100;
 Minibatch[ 301- 400]: loss = 0.141220 * 100, metric = 4.53% * 100;
 Minibatch[ 401- 500]: loss = 0.147953 * 100, metric = 4.68% * 100;
 Minibatch[ 501- 600]: loss = 0.134854 * 100, metric = 4.21% * 100;
 Minibatch[ 601- 700]: loss = 0.149913 * 100, metric = 4.85% * 100;
 Minibatch[ 701- 800]: loss = 0.138622 * 100, metric = 4.55% * 100;
 Minibatch[ 801- 900]: loss = 0.153718 * 100, metric = 4.89% * 100;
 Minibatch[ 901-1000]: loss = 0.145827 * 100, metric = 4.67% * 100;
 Minibatch[1001-1100]: loss = 0.154489 * 100, metric = 4.93% * 100;
 Minibatch[1101-1200]: loss = 0.143344 * 100, metric = 4.53% * 100;
 Minibatch[1201-1300]: loss = 0.153754 * 100, metric = 4.96% * 100;
 Minibatch[1301-1400]: loss = 0.151897 * 100, metric = 4.88% * 100;
 Minibatch[1401-1500]: loss = 0.142529 * 100, metric = 4.60% * 100;
 Minibatch[1501-1600]: loss = 0.149540 * 100, metric = 4.83% * 100;
 Minibatch[1601-1700]: loss = 0.147976 * 100, metric = 4.79% * 100;
 Minibatch[1701-1800]: loss = 0.142589 * 100, metric = 4.52% * 100;
 Minibatch[1801-1900]: loss = 0.158631 * 100, metric = 4.99% * 100;
 Minibatch[1901-2000]: loss = 0.142208 * 100, metric = 4.56% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.147054 * 2000, metric = 4.72% * 2000 822.329s (  2.4 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 16.04% * 2000;
 Minibatch[   1- 100]: loss = 0.140404 * 100, metric = 4.55% * 100;
 Minibatch[ 101- 200]: loss = 0.137436 * 100, metric = 4.48% * 100;
 Minibatch[ 201- 300]: loss = 0.156109 * 100, metric = 5.02% * 100;
 Minibatch[ 301- 400]: loss = 0.144988 * 100, metric = 4.59% * 100;
 Minibatch[ 401- 500]: loss = 0.141358 * 100, metric = 4.38% * 100;
 Minibatch[ 501- 600]: loss = 0.144343 * 100, metric = 4.62% * 100;
 Minibatch[ 601- 700]: loss = 0.148163 * 100, metric = 4.63% * 100;
 Minibatch[ 701- 800]: loss = 0.137566 * 100, metric = 4.42% * 100;
 Minibatch[ 801- 900]: loss = 0.142800 * 100, metric = 4.63% * 100;
 Minibatch[ 901-1000]: loss = 0.150755 * 100, metric = 4.87% * 100;
 Minibatch[1001-1100]: loss = 0.156928 * 100, metric = 5.13% * 100;
 Minibatch[1101-1200]: loss = 0.149887 * 100, metric = 4.79% * 100;
 Minibatch[1201-1300]: loss = 0.148374 * 100, metric = 4.79% * 100;
 Minibatch[1301-1400]: loss = 0.131759 * 100, metric = 4.16% * 100;
 Minibatch[1401-1500]: loss = 0.140723 * 100, metric = 4.39% * 100;
 Minibatch[1501-1600]: loss = 0.143460 * 100, metric = 4.57% * 100;
 Minibatch[1601-1700]: loss = 0.154120 * 100, metric = 4.85% * 100;
 Minibatch[1701-1800]: loss = 0.146195 * 100, metric = 4.66% * 100;
 Minibatch[1801-1900]: loss = 0.144472 * 100, metric = 4.67% * 100;
 Minibatch[1901-2000]: loss = 0.147526 * 100, metric = 4.59% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.145368 * 2000, metric = 4.64% * 2000 814.750s (  2.5 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 14.20% * 2000;
 Minibatch[   1- 100]: loss = 0.144242 * 100, metric = 4.55% * 100;
 Minibatch[ 101- 200]: loss = 0.150604 * 100, metric = 4.74% * 100;
 Minibatch[ 201- 300]: loss = 0.151356 * 100, metric = 5.00% * 100;
 Minibatch[ 301- 400]: loss = 0.144177 * 100, metric = 4.67% * 100;
 Minibatch[ 401- 500]: loss = 0.146173 * 100, metric = 4.77% * 100;
 Minibatch[ 501- 600]: loss = 0.138649 * 100, metric = 4.42% * 100;
 Minibatch[ 601- 700]: loss = 0.143981 * 100, metric = 4.66% * 100;
 Minibatch[ 701- 800]: loss = 0.153486 * 100, metric = 4.90% * 100;
 Minibatch[ 801- 900]: loss = 0.146544 * 100, metric = 4.80% * 100;
 Minibatch[ 901-1000]: loss = 0.140430 * 100, metric = 4.41% * 100;
 Minibatch[1001-1100]: loss = 0.138597 * 100, metric = 4.40% * 100;
 Minibatch[1101-1200]: loss = 0.155265 * 100, metric = 5.00% * 100;
 Minibatch[1201-1300]: loss = 0.148055 * 100, metric = 4.63% * 100;
 Minibatch[1301-1400]: loss = 0.140692 * 100, metric = 4.50% * 100;
 Minibatch[1401-1500]: loss = 0.147188 * 100, metric = 4.85% * 100;
 Minibatch[1501-1600]: loss = 0.138298 * 100, metric = 4.46% * 100;
 Minibatch[1601-1700]: loss = 0.145960 * 100, metric = 4.62% * 100;
 Minibatch[1701-1800]: loss = 0.139826 * 100, metric = 4.47% * 100;
 Minibatch[1801-1900]: loss = 0.148126 * 100, metric = 4.78% * 100;
 Minibatch[1901-2000]: loss = 0.145085 * 100, metric = 4.68% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.145337 * 2000, metric = 4.67% * 2000 832.527s (  2.4 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 15.20% * 2000;
 Minibatch[   1- 100]: loss = 0.145282 * 100, metric = 4.74% * 100;
 Minibatch[ 101- 200]: loss = 0.147418 * 100, metric = 4.72% * 100;
 Minibatch[ 201- 300]: loss = 0.137192 * 100, metric = 4.44% * 100;
 Minibatch[ 301- 400]: loss = 0.141448 * 100, metric = 4.56% * 100;
 Minibatch[ 401- 500]: loss = 0.142081 * 100, metric = 4.52% * 100;
 Minibatch[ 501- 600]: loss = 0.138871 * 100, metric = 4.28% * 100;
 Minibatch[ 601- 700]: loss = 0.142665 * 100, metric = 4.67% * 100;
 Minibatch[ 701- 800]: loss = 0.142069 * 100, metric = 4.52% * 100;
 Minibatch[ 801- 900]: loss = 0.147119 * 100, metric = 4.68% * 100;
 Minibatch[ 901-1000]: loss = 0.141506 * 100, metric = 4.53% * 100;
 Minibatch[1001-1100]: loss = 0.145069 * 100, metric = 4.63% * 100;
 Minibatch[1101-1200]: loss = 0.137224 * 100, metric = 4.33% * 100;
 Minibatch[1201-1300]: loss = 0.144251 * 100, metric = 4.73% * 100;
 Minibatch[1301-1400]: loss = 0.147190 * 100, metric = 4.69% * 100;
 Minibatch[1401-1500]: loss = 0.145506 * 100, metric = 4.72% * 100;
 Minibatch[1501-1600]: loss = 0.142320 * 100, metric = 4.65% * 100;
 Minibatch[1601-1700]: loss = 0.135974 * 100, metric = 4.42% * 100;
 Minibatch[1701-1800]: loss = 0.146985 * 100, metric = 4.74% * 100;
 Minibatch[1801-1900]: loss = 0.142596 * 100, metric = 4.60% * 100;
 Minibatch[1901-2000]: loss = 0.144896 * 100, metric = 4.62% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.142883 * 2000, metric = 4.59% * 2000 825.319s (  2.4 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 15.87% * 2000;
 Minibatch[   1- 100]: loss = 0.144157 * 100, metric = 4.69% * 100;
 Minibatch[ 101- 200]: loss = 0.146889 * 100, metric = 4.74% * 100;
 Minibatch[ 201- 300]: loss = 0.144556 * 100, metric = 4.54% * 100;
 Minibatch[ 301- 400]: loss = 0.137732 * 100, metric = 4.33% * 100;
 Minibatch[ 401- 500]: loss = 0.139620 * 100, metric = 4.55% * 100;
 Minibatch[ 501- 600]: loss = 0.148286 * 100, metric = 4.75% * 100;
 Minibatch[ 601- 700]: loss = 0.145782 * 100, metric = 4.72% * 100;
 Minibatch[ 701- 800]: loss = 0.143631 * 100, metric = 4.78% * 100;
 Minibatch[ 801- 900]: loss = 0.137311 * 100, metric = 4.45% * 100;
 Minibatch[ 901-1000]: loss = 0.141328 * 100, metric = 4.60% * 100;
 Minibatch[1001-1100]: loss = 0.148699 * 100, metric = 4.74% * 100;
 Minibatch[1101-1200]: loss = 0.142497 * 100, metric = 4.58% * 100;
 Minibatch[1201-1300]: loss = 0.143966 * 100, metric = 4.52% * 100;
 Minibatch[1301-1400]: loss = 0.150943 * 100, metric = 4.69% * 100;
 Minibatch[1401-1500]: loss = 0.144878 * 100, metric = 4.67% * 100;
 Minibatch[1501-1600]: loss = 0.145970 * 100, metric = 4.59% * 100;
 Minibatch[1601-1700]: loss = 0.140031 * 100, metric = 4.52% * 100;
 Minibatch[1701-1800]: loss = 0.146004 * 100, metric = 4.63% * 100;
 Minibatch[1801-1900]: loss = 0.140308 * 100, metric = 4.48% * 100;
 Minibatch[1901-2000]: loss = 0.139278 * 100, metric = 4.45% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.143593 * 2000, metric = 4.60% * 2000 833.131s (  2.4 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 15.69% * 2000;
 Minibatch[   1- 100]: loss = 0.138729 * 100, metric = 4.52% * 100;
 Minibatch[ 101- 200]: loss = 0.136156 * 100, metric = 4.37% * 100;
 Minibatch[ 201- 300]: loss = 0.143402 * 100, metric = 4.58% * 100;
 Minibatch[ 301- 400]: loss = 0.140786 * 100, metric = 4.42% * 100;
 Minibatch[ 401- 500]: loss = 0.137790 * 100, metric = 4.50% * 100;
 Minibatch[ 501- 600]: loss = 0.147463 * 100, metric = 4.58% * 100;
 Minibatch[ 601- 700]: loss = 0.146050 * 100, metric = 4.72% * 100;
 Minibatch[ 701- 800]: loss = 0.140706 * 100, metric = 4.48% * 100;
 Minibatch[ 801- 900]: loss = 0.141444 * 100, metric = 4.57% * 100;
 Minibatch[ 901-1000]: loss = 0.141020 * 100, metric = 4.59% * 100;
 Minibatch[1001-1100]: loss = 0.155059 * 100, metric = 5.02% * 100;
 Minibatch[1101-1200]: loss = 0.145516 * 100, metric = 4.72% * 100;
 Minibatch[1201-1300]: loss = 0.142995 * 100, metric = 4.56% * 100;
 Minibatch[1301-1400]: loss = 0.143903 * 100, metric = 4.71% * 100;
 Minibatch[1401-1500]: loss = 0.138630 * 100, metric = 4.43% * 100;
 Minibatch[1501-1600]: loss = 0.141331 * 100, metric = 4.66% * 100;
 Minibatch[1601-1700]: loss = 0.141989 * 100, metric = 4.48% * 100;
 Minibatch[1701-1800]: loss = 0.141520 * 100, metric = 4.59% * 100;
 Minibatch[1801-1900]: loss = 0.143577 * 100, metric = 4.62% * 100;
 Minibatch[1901-2000]: loss = 0.149949 * 100, metric = 4.78% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.142901 * 2000, metric = 4.60% * 2000 813.647s (  2.5 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 15.07% * 2000;
 Minibatch[   1- 100]: loss = 0.144785 * 100, metric = 4.64% * 100;
 Minibatch[ 101- 200]: loss = 0.141264 * 100, metric = 4.51% * 100;
 Minibatch[ 201- 300]: loss = 0.145791 * 100, metric = 4.67% * 100;
 Minibatch[ 301- 400]: loss = 0.148164 * 100, metric = 4.75% * 100;
 Minibatch[ 401- 500]: loss = 0.141878 * 100, metric = 4.65% * 100;
 Minibatch[ 501- 600]: loss = 0.136234 * 100, metric = 4.29% * 100;
 Minibatch[ 601- 700]: loss = 0.149172 * 100, metric = 4.66% * 100;
 Minibatch[ 701- 800]: loss = 0.145295 * 100, metric = 4.59% * 100;
 Minibatch[ 801- 900]: loss = 0.136409 * 100, metric = 4.47% * 100;
 Minibatch[ 901-1000]: loss = 0.140450 * 100, metric = 4.50% * 100;
 Minibatch[1001-1100]: loss = 0.134464 * 100, metric = 4.29% * 100;
 Minibatch[1101-1200]: loss = 0.144490 * 100, metric = 4.65% * 100;
 Minibatch[1201-1300]: loss = 0.142826 * 100, metric = 4.70% * 100;
 Minibatch[1301-1400]: loss = 0.135106 * 100, metric = 4.40% * 100;
 Minibatch[1401-1500]: loss = 0.138277 * 100, metric = 4.47% * 100;
 Minibatch[1501-1600]: loss = 0.140538 * 100, metric = 4.41% * 100;
 Minibatch[1601-1700]: loss = 0.144887 * 100, metric = 4.56% * 100;
 Minibatch[1701-1800]: loss = 0.139882 * 100, metric = 4.36% * 100;
 Minibatch[1801-1900]: loss = 0.137561 * 100, metric = 4.33% * 100;
 Minibatch[1901-2000]: loss = 0.130654 * 100, metric = 4.16% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.140906 * 2000, metric = 4.50% * 2000 826.372s (  2.4 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 16.03% * 2000;
 Minibatch[   1- 100]: loss = 0.135419 * 100, metric = 4.39% * 100;
 Minibatch[ 101- 200]: loss = 0.146685 * 100, metric = 4.79% * 100;
 Minibatch[ 201- 300]: loss = 0.139265 * 100, metric = 4.46% * 100;
 Minibatch[ 301- 400]: loss = 0.136350 * 100, metric = 4.37% * 100;
 Minibatch[ 401- 500]: loss = 0.132409 * 100, metric = 4.31% * 100;
 Minibatch[ 501- 600]: loss = 0.140258 * 100, metric = 4.50% * 100;
 Minibatch[ 601- 700]: loss = 0.139931 * 100, metric = 4.49% * 100;
 Minibatch[ 701- 800]: loss = 0.133549 * 100, metric = 4.39% * 100;
 Minibatch[ 801- 900]: loss = 0.140048 * 100, metric = 4.47% * 100;
 Minibatch[ 901-1000]: loss = 0.140600 * 100, metric = 4.54% * 100;
 Minibatch[1001-1100]: loss = 0.141393 * 100, metric = 4.52% * 100;
 Minibatch[1101-1200]: loss = 0.142729 * 100, metric = 4.56% * 100;
 Minibatch[1201-1300]: loss = 0.136395 * 100, metric = 4.36% * 100;
 Minibatch[1301-1400]: loss = 0.139140 * 100, metric = 4.55% * 100;
 Minibatch[1401-1500]: loss = 0.135613 * 100, metric = 4.38% * 100;
 Minibatch[1501-1600]: loss = 0.139867 * 100, metric = 4.54% * 100;
 Minibatch[1601-1700]: loss = 0.140093 * 100, metric = 4.46% * 100;
 Minibatch[1701-1800]: loss = 0.139047 * 100, metric = 4.53% * 100;
 Minibatch[1801-1900]: loss = 0.134902 * 100, metric = 4.42% * 100;
 Minibatch[1901-2000]: loss = 0.137496 * 100, metric = 4.43% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.138559 * 2000, metric = 4.47% * 2000 816.956s (  2.4 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 14.74% * 2000;
 Minibatch[   1- 100]: loss = 0.149632 * 100, metric = 4.77% * 100;
 Minibatch[ 101- 200]: loss = 0.128869 * 100, metric = 4.06% * 100;
 Minibatch[ 201- 300]: loss = 0.140944 * 100, metric = 4.55% * 100;
 Minibatch[ 301- 400]: loss = 0.139581 * 100, metric = 4.51% * 100;
 Minibatch[ 401- 500]: loss = 0.130675 * 100, metric = 4.22% * 100;
 Minibatch[ 501- 600]: loss = 0.133841 * 100, metric = 4.28% * 100;
 Minibatch[ 601- 700]: loss = 0.144724 * 100, metric = 4.61% * 100;
 Minibatch[ 701- 800]: loss = 0.138498 * 100, metric = 4.49% * 100;
 Minibatch[ 801- 900]: loss = 0.135744 * 100, metric = 4.33% * 100;
 Minibatch[ 901-1000]: loss = 0.134738 * 100, metric = 4.29% * 100;
 Minibatch[1001-1100]: loss = 0.137359 * 100, metric = 4.33% * 100;
 Minibatch[1101-1200]: loss = 0.132807 * 100, metric = 4.31% * 100;
 Minibatch[1201-1300]: loss = 0.145561 * 100, metric = 4.76% * 100;
 Minibatch[1301-1400]: loss = 0.141226 * 100, metric = 4.59% * 100;
 Minibatch[1401-1500]: loss = 0.132022 * 100, metric = 4.34% * 100;
 Minibatch[1501-1600]: loss = 0.144985 * 100, metric = 4.61% * 100;
 Minibatch[1601-1700]: loss = 0.136804 * 100, metric = 4.40% * 100;
 Minibatch[1701-1800]: loss = 0.135714 * 100, metric = 4.47% * 100;
 Minibatch[1801-1900]: loss = 0.139901 * 100, metric = 4.54% * 100;
 Minibatch[1901-2000]: loss = 0.135261 * 100, metric = 4.34% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.137944 * 2000, metric = 4.44% * 2000 819.468s (  2.4 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 15.63% * 2000;
 Minibatch[   1- 100]: loss = 0.135958 * 100, metric = 4.41% * 100;
 Minibatch[ 101- 200]: loss = 0.139868 * 100, metric = 4.57% * 100;
 Minibatch[ 201- 300]: loss = 0.142680 * 100, metric = 4.43% * 100;
 Minibatch[ 301- 400]: loss = 0.141015 * 100, metric = 4.49% * 100;
 Minibatch[ 401- 500]: loss = 0.134464 * 100, metric = 4.40% * 100;
 Minibatch[ 501- 600]: loss = 0.137004 * 100, metric = 4.46% * 100;
 Minibatch[ 601- 700]: loss = 0.141518 * 100, metric = 4.40% * 100;
 Minibatch[ 701- 800]: loss = 0.125087 * 100, metric = 4.11% * 100;
 Minibatch[ 801- 900]: loss = 0.132367 * 100, metric = 4.22% * 100;
 Minibatch[ 901-1000]: loss = 0.133974 * 100, metric = 4.39% * 100;
 Minibatch[1001-1100]: loss = 0.130632 * 100, metric = 4.04% * 100;
 Minibatch[1101-1200]: loss = 0.132805 * 100, metric = 4.25% * 100;
 Minibatch[1201-1300]: loss = 0.136186 * 100, metric = 4.40% * 100;
 Minibatch[1301-1400]: loss = 0.132493 * 100, metric = 4.33% * 100;
 Minibatch[1401-1500]: loss = 0.130085 * 100, metric = 4.20% * 100;
 Minibatch[1501-1600]: loss = 0.128059 * 100, metric = 4.20% * 100;
 Minibatch[1601-1700]: loss = 0.131772 * 100, metric = 4.23% * 100;
 Minibatch[1701-1800]: loss = 0.140525 * 100, metric = 4.68% * 100;
 Minibatch[1801-1900]: loss = 0.130973 * 100, metric = 4.17% * 100;
 Minibatch[1901-2000]: loss = 0.130417 * 100, metric = 4.22% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.134394 * 2000, metric = 4.33% * 2000 813.384s (  2.5 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 14.56% * 2000;
 Minibatch[   1- 100]: loss = 0.134753 * 100, metric = 4.27% * 100;
 Minibatch[ 101- 200]: loss = 0.135974 * 100, metric = 4.22% * 100;
 Minibatch[ 201- 300]: loss = 0.135428 * 100, metric = 4.47% * 100;
 Minibatch[ 301- 400]: loss = 0.136016 * 100, metric = 4.41% * 100;
 Minibatch[ 401- 500]: loss = 0.133412 * 100, metric = 4.34% * 100;
 Minibatch[ 501- 600]: loss = 0.128412 * 100, metric = 4.02% * 100;
 Minibatch[ 601- 700]: loss = 0.127048 * 100, metric = 4.08% * 100;
 Minibatch[ 701- 800]: loss = 0.126953 * 100, metric = 4.11% * 100;
 Minibatch[ 801- 900]: loss = 0.141964 * 100, metric = 4.51% * 100;
 Minibatch[ 901-1000]: loss = 0.127249 * 100, metric = 4.12% * 100;
 Minibatch[1001-1100]: loss = 0.131061 * 100, metric = 4.19% * 100;
 Minibatch[1101-1200]: loss = 0.140145 * 100, metric = 4.31% * 100;
 Minibatch[1201-1300]: loss = 0.136838 * 100, metric = 4.35% * 100;
 Minibatch[1301-1400]: loss = 0.130020 * 100, metric = 4.25% * 100;
 Minibatch[1401-1500]: loss = 0.136489 * 100, metric = 4.41% * 100;
 Minibatch[1501-1600]: loss = 0.131624 * 100, metric = 4.21% * 100;
 Minibatch[1601-1700]: loss = 0.133928 * 100, metric = 4.27% * 100;
 Minibatch[1701-1800]: loss = 0.136567 * 100, metric = 4.34% * 100;
 Minibatch[1801-1900]: loss = 0.138023 * 100, metric = 4.54% * 100;
 Minibatch[1901-2000]: loss = 0.131951 * 100, metric = 4.19% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.133693 * 2000, metric = 4.28% * 2000 822.872s (  2.4 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 17.49% * 2000;
 Minibatch[   1- 100]: loss = 0.129688 * 100, metric = 4.20% * 100;
 Minibatch[ 101- 200]: loss = 0.135504 * 100, metric = 4.46% * 100;
 Minibatch[ 201- 300]: loss = 0.131521 * 100, metric = 4.19% * 100;
 Minibatch[ 301- 400]: loss = 0.141815 * 100, metric = 4.56% * 100;
 Minibatch[ 401- 500]: loss = 0.135131 * 100, metric = 4.43% * 100;
 Minibatch[ 501- 600]: loss = 0.137069 * 100, metric = 4.51% * 100;
 Minibatch[ 601- 700]: loss = 0.118086 * 100, metric = 3.77% * 100;
 Minibatch[ 701- 800]: loss = 0.127879 * 100, metric = 4.06% * 100;
 Minibatch[ 801- 900]: loss = 0.131285 * 100, metric = 4.27% * 100;
 Minibatch[ 901-1000]: loss = 0.134193 * 100, metric = 4.20% * 100;
 Minibatch[1001-1100]: loss = 0.131218 * 100, metric = 4.22% * 100;
 Minibatch[1101-1200]: loss = 0.137404 * 100, metric = 4.44% * 100;
 Minibatch[1201-1300]: loss = 0.128837 * 100, metric = 4.12% * 100;
 Minibatch[1301-1400]: loss = 0.135496 * 100, metric = 4.41% * 100;
 Minibatch[1401-1500]: loss = 0.126452 * 100, metric = 4.11% * 100;
 Minibatch[1501-1600]: loss = 0.133507 * 100, metric = 4.33% * 100;
 Minibatch[1601-1700]: loss = 0.131669 * 100, metric = 4.21% * 100;
 Minibatch[1701-1800]: loss = 0.142859 * 100, metric = 4.50% * 100;
 Minibatch[1801-1900]: loss = 0.130515 * 100, metric = 4.08% * 100;
 Minibatch[1901-2000]: loss = 0.129849 * 100, metric = 4.16% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.132499 * 2000, metric = 4.26% * 2000 830.251s (  2.4 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 14.12% * 2000;
 Minibatch[   1- 100]: loss = 0.128313 * 100, metric = 4.08% * 100;
 Minibatch[ 101- 200]: loss = 0.129110 * 100, metric = 4.13% * 100;
 Minibatch[ 201- 300]: loss = 0.130677 * 100, metric = 4.10% * 100;
 Minibatch[ 301- 400]: loss = 0.126559 * 100, metric = 4.04% * 100;
 Minibatch[ 401- 500]: loss = 0.126722 * 100, metric = 4.04% * 100;
 Minibatch[ 501- 600]: loss = 0.128213 * 100, metric = 4.05% * 100;
 Minibatch[ 601- 700]: loss = 0.136087 * 100, metric = 4.37% * 100;
 Minibatch[ 701- 800]: loss = 0.138199 * 100, metric = 4.48% * 100;
 Minibatch[ 801- 900]: loss = 0.128914 * 100, metric = 4.13% * 100;
 Minibatch[ 901-1000]: loss = 0.128804 * 100, metric = 4.05% * 100;
 Minibatch[1001-1100]: loss = 0.142398 * 100, metric = 4.45% * 100;
 Minibatch[1101-1200]: loss = 0.129293 * 100, metric = 4.14% * 100;
 Minibatch[1201-1300]: loss = 0.125504 * 100, metric = 4.03% * 100;
 Minibatch[1301-1400]: loss = 0.127629 * 100, metric = 4.10% * 100;
 Minibatch[1401-1500]: loss = 0.135568 * 100, metric = 4.29% * 100;
 Minibatch[1501-1600]: loss = 0.130552 * 100, metric = 4.23% * 100;
 Minibatch[1601-1700]: loss = 0.132851 * 100, metric = 4.38% * 100;
 Minibatch[1701-1800]: loss = 0.134715 * 100, metric = 4.34% * 100;
 Minibatch[1801-1900]: loss = 0.132832 * 100, metric = 4.40% * 100;
 Minibatch[1901-2000]: loss = 0.139445 * 100, metric = 4.60% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.131619 * 2000, metric = 4.22% * 2000 829.950s (  2.4 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 13.16% * 2000;
 Minibatch[   1- 100]: loss = 0.133134 * 100, metric = 4.31% * 100;
 Minibatch[ 101- 200]: loss = 0.133639 * 100, metric = 4.41% * 100;
 Minibatch[ 201- 300]: loss = 0.140704 * 100, metric = 4.53% * 100;
 Minibatch[ 301- 400]: loss = 0.131637 * 100, metric = 4.30% * 100;
 Minibatch[ 401- 500]: loss = 0.140709 * 100, metric = 4.59% * 100;
 Minibatch[ 501- 600]: loss = 0.146475 * 100, metric = 4.58% * 100;
 Minibatch[ 601- 700]: loss = 0.139026 * 100, metric = 4.37% * 100;
 Minibatch[ 701- 800]: loss = 0.129759 * 100, metric = 4.10% * 100;
 Minibatch[ 801- 900]: loss = 0.131169 * 100, metric = 4.27% * 100;
 Minibatch[ 901-1000]: loss = 0.134414 * 100, metric = 4.43% * 100;
 Minibatch[1001-1100]: loss = 0.132244 * 100, metric = 4.36% * 100;
 Minibatch[1101-1200]: loss = 0.136182 * 100, metric = 4.36% * 100;
 Minibatch[1201-1300]: loss = 0.133309 * 100, metric = 4.27% * 100;
 Minibatch[1301-1400]: loss = 0.129916 * 100, metric = 4.15% * 100;
 Minibatch[1401-1500]: loss = 0.131731 * 100, metric = 4.36% * 100;
 Minibatch[1501-1600]: loss = 0.131880 * 100, metric = 4.31% * 100;
 Minibatch[1601-1700]: loss = 0.128021 * 100, metric = 4.21% * 100;
 Minibatch[1701-1800]: loss = 0.127105 * 100, metric = 4.01% * 100;
 Minibatch[1801-1900]: loss = 0.135123 * 100, metric = 4.39% * 100;
 Minibatch[1901-2000]: loss = 0.124811 * 100, metric = 4.09% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.133549 * 2000, metric = 4.32% * 2000 820.462s (  2.4 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 17.06% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
