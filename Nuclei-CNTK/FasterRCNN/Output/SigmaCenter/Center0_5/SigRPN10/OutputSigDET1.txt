Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.100521 * 100, metric = 25.74% * 100;
 Minibatch[ 101- 200]: loss = 0.851018 * 100, metric = 23.26% * 100;
 Minibatch[ 201- 300]: loss = 0.729260 * 100, metric = 20.95% * 100;
 Minibatch[ 301- 400]: loss = 0.673826 * 100, metric = 19.67% * 100;
 Minibatch[ 401- 500]: loss = 0.606177 * 100, metric = 17.84% * 100;
 Minibatch[ 501- 600]: loss = 0.593249 * 100, metric = 16.88% * 100;
 Minibatch[ 601- 700]: loss = 0.542241 * 100, metric = 15.35% * 100;
 Minibatch[ 701- 800]: loss = 0.518297 * 100, metric = 14.89% * 100;
 Minibatch[ 801- 900]: loss = 0.533149 * 100, metric = 15.63% * 100;
 Minibatch[ 901-1000]: loss = 0.534441 * 100, metric = 15.36% * 100;
 Minibatch[1001-1100]: loss = 0.515762 * 100, metric = 15.10% * 100;
 Minibatch[1101-1200]: loss = 0.503068 * 100, metric = 14.41% * 100;
 Minibatch[1201-1300]: loss = 0.492402 * 100, metric = 14.45% * 100;
 Minibatch[1301-1400]: loss = 0.472250 * 100, metric = 13.48% * 100;
 Minibatch[1401-1500]: loss = 0.483838 * 100, metric = 13.84% * 100;
 Minibatch[1501-1600]: loss = 0.474624 * 100, metric = 13.82% * 100;
 Minibatch[1601-1700]: loss = 0.458950 * 100, metric = 13.25% * 100;
 Minibatch[1701-1800]: loss = 0.469636 * 100, metric = 13.60% * 100;
 Minibatch[1801-1900]: loss = 0.468505 * 100, metric = 13.61% * 100;
 Minibatch[1901-2000]: loss = 0.437963 * 100, metric = 12.35% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.572959 * 2000, metric = 16.17% * 2000 1058.028s (  1.9 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 25.62% * 2000;
0.661734842300415
 Minibatch[   1- 100]: loss = 0.444826 * 100, metric = 12.87% * 100;
 Minibatch[ 101- 200]: loss = 0.466834 * 100, metric = 13.65% * 100;
 Minibatch[ 201- 300]: loss = 0.445638 * 100, metric = 12.53% * 100;
 Minibatch[ 301- 400]: loss = 0.447514 * 100, metric = 12.78% * 100;
 Minibatch[ 401- 500]: loss = 0.440329 * 100, metric = 12.72% * 100;
 Minibatch[ 501- 600]: loss = 0.448601 * 100, metric = 12.19% * 100;
 Minibatch[ 601- 700]: loss = 0.419026 * 100, metric = 12.04% * 100;
 Minibatch[ 701- 800]: loss = 0.437012 * 100, metric = 12.53% * 100;
 Minibatch[ 801- 900]: loss = 0.414289 * 100, metric = 11.85% * 100;
 Minibatch[ 901-1000]: loss = 0.410772 * 100, metric = 11.70% * 100;
 Minibatch[1001-1100]: loss = 0.413965 * 100, metric = 11.71% * 100;
 Minibatch[1101-1200]: loss = 0.415947 * 100, metric = 11.65% * 100;
 Minibatch[1201-1300]: loss = 0.411939 * 100, metric = 11.93% * 100;
 Minibatch[1301-1400]: loss = 0.422195 * 100, metric = 11.94% * 100;
 Minibatch[1401-1500]: loss = 0.404977 * 100, metric = 11.25% * 100;
 Minibatch[1501-1600]: loss = 0.395227 * 100, metric = 11.35% * 100;
 Minibatch[1601-1700]: loss = 0.407234 * 100, metric = 11.39% * 100;
 Minibatch[1701-1800]: loss = 0.417081 * 100, metric = 12.04% * 100;
 Minibatch[1801-1900]: loss = 0.415789 * 100, metric = 11.90% * 100;
 Minibatch[1901-2000]: loss = 0.387696 * 100, metric = 11.10% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.423344 * 2000, metric = 12.06% * 2000 938.719s (  2.1 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 21.12% * 2000;
0.5489831214398145
 Minibatch[   1- 100]: loss = 0.410326 * 100, metric = 11.83% * 100;
 Minibatch[ 101- 200]: loss = 0.406481 * 100, metric = 11.52% * 100;
 Minibatch[ 201- 300]: loss = 0.394664 * 100, metric = 11.23% * 100;
 Minibatch[ 301- 400]: loss = 0.408144 * 100, metric = 11.68% * 100;
 Minibatch[ 401- 500]: loss = 0.412438 * 100, metric = 11.92% * 100;
 Minibatch[ 501- 600]: loss = 0.401465 * 100, metric = 11.32% * 100;
 Minibatch[ 601- 700]: loss = 0.406213 * 100, metric = 11.64% * 100;
 Minibatch[ 701- 800]: loss = 0.384013 * 100, metric = 10.98% * 100;
 Minibatch[ 801- 900]: loss = 0.411773 * 100, metric = 11.93% * 100;
 Minibatch[ 901-1000]: loss = 0.385774 * 100, metric = 11.03% * 100;
 Minibatch[1001-1100]: loss = 0.397309 * 100, metric = 11.55% * 100;
 Minibatch[1101-1200]: loss = 0.382079 * 100, metric = 10.88% * 100;
 Minibatch[1201-1300]: loss = 0.386324 * 100, metric = 11.16% * 100;
 Minibatch[1301-1400]: loss = 0.392953 * 100, metric = 11.29% * 100;
 Minibatch[1401-1500]: loss = 0.395279 * 100, metric = 11.46% * 100;
 Minibatch[1501-1600]: loss = 0.380035 * 100, metric = 10.73% * 100;
 Minibatch[1601-1700]: loss = 0.376415 * 100, metric = 10.70% * 100;
 Minibatch[1701-1800]: loss = 0.390910 * 100, metric = 11.39% * 100;
 Minibatch[1801-1900]: loss = 0.377330 * 100, metric = 10.72% * 100;
 Minibatch[1901-2000]: loss = 0.371937 * 100, metric = 10.64% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.393593 * 2000, metric = 11.28% * 2000 892.017s (  2.2 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 20.67% * 2000;
0.5262386109158397
 Minibatch[   1- 100]: loss = 0.390593 * 100, metric = 11.04% * 100;
 Minibatch[ 101- 200]: loss = 0.363049 * 100, metric = 10.41% * 100;
 Minibatch[ 201- 300]: loss = 0.372086 * 100, metric = 10.67% * 100;
 Minibatch[ 301- 400]: loss = 0.348858 * 100, metric = 10.22% * 100;
 Minibatch[ 401- 500]: loss = 0.375226 * 100, metric = 10.74% * 100;
 Minibatch[ 501- 600]: loss = 0.353164 * 100, metric = 9.74% * 100;
 Minibatch[ 601- 700]: loss = 0.351200 * 100, metric = 9.79% * 100;
 Minibatch[ 701- 800]: loss = 0.359123 * 100, metric = 10.17% * 100;
 Minibatch[ 801- 900]: loss = 0.366248 * 100, metric = 10.53% * 100;
 Minibatch[ 901-1000]: loss = 0.370011 * 100, metric = 10.81% * 100;
 Minibatch[1001-1100]: loss = 0.371931 * 100, metric = 10.79% * 100;
 Minibatch[1101-1200]: loss = 0.360243 * 100, metric = 10.55% * 100;
 Minibatch[1201-1300]: loss = 0.359337 * 100, metric = 10.23% * 100;
 Minibatch[1301-1400]: loss = 0.364539 * 100, metric = 10.42% * 100;
 Minibatch[1401-1500]: loss = 0.368657 * 100, metric = 10.68% * 100;
 Minibatch[1501-1600]: loss = 0.338018 * 100, metric = 9.63% * 100;
 Minibatch[1601-1700]: loss = 0.360230 * 100, metric = 10.58% * 100;
 Minibatch[1701-1800]: loss = 0.368474 * 100, metric = 10.67% * 100;
 Minibatch[1801-1900]: loss = 0.354331 * 100, metric = 10.08% * 100;
 Minibatch[1901-2000]: loss = 0.345227 * 100, metric = 9.86% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.362027 * 2000, metric = 10.38% * 2000 898.502s (  2.2 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 21.01% * 2000;
 Minibatch[   1- 100]: loss = 0.367548 * 100, metric = 10.61% * 100;
 Minibatch[ 101- 200]: loss = 0.347170 * 100, metric = 10.10% * 100;
 Minibatch[ 201- 300]: loss = 0.344468 * 100, metric = 9.82% * 100;
 Minibatch[ 301- 400]: loss = 0.367325 * 100, metric = 10.80% * 100;
 Minibatch[ 401- 500]: loss = 0.335027 * 100, metric = 9.49% * 100;
 Minibatch[ 501- 600]: loss = 0.334165 * 100, metric = 9.50% * 100;
 Minibatch[ 601- 700]: loss = 0.342935 * 100, metric = 9.57% * 100;
 Minibatch[ 701- 800]: loss = 0.354251 * 100, metric = 10.15% * 100;
 Minibatch[ 801- 900]: loss = 0.333749 * 100, metric = 9.44% * 100;
 Minibatch[ 901-1000]: loss = 0.337985 * 100, metric = 9.58% * 100;
 Minibatch[1001-1100]: loss = 0.345166 * 100, metric = 9.78% * 100;
 Minibatch[1101-1200]: loss = 0.331110 * 100, metric = 9.23% * 100;
 Minibatch[1201-1300]: loss = 0.344677 * 100, metric = 9.60% * 100;
 Minibatch[1301-1400]: loss = 0.355845 * 100, metric = 10.30% * 100;
 Minibatch[1401-1500]: loss = 0.344984 * 100, metric = 9.96% * 100;
 Minibatch[1501-1600]: loss = 0.337664 * 100, metric = 9.63% * 100;
 Minibatch[1601-1700]: loss = 0.353272 * 100, metric = 10.15% * 100;
 Minibatch[1701-1800]: loss = 0.356750 * 100, metric = 10.31% * 100;
 Minibatch[1801-1900]: loss = 0.354877 * 100, metric = 10.14% * 100;
 Minibatch[1901-2000]: loss = 0.336223 * 100, metric = 9.44% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.346259 * 2000, metric = 9.88% * 2000 876.829s (  2.3 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 18.87% * 2000;
0.49301817499101164
 Minibatch[   1- 100]: loss = 0.331404 * 100, metric = 9.48% * 100;
 Minibatch[ 101- 200]: loss = 0.323602 * 100, metric = 9.18% * 100;
 Minibatch[ 201- 300]: loss = 0.340878 * 100, metric = 9.77% * 100;
 Minibatch[ 301- 400]: loss = 0.340622 * 100, metric = 9.69% * 100;
 Minibatch[ 401- 500]: loss = 0.330256 * 100, metric = 9.45% * 100;
 Minibatch[ 501- 600]: loss = 0.336590 * 100, metric = 9.68% * 100;
 Minibatch[ 601- 700]: loss = 0.329253 * 100, metric = 9.60% * 100;
 Minibatch[ 701- 800]: loss = 0.337743 * 100, metric = 9.70% * 100;
 Minibatch[ 801- 900]: loss = 0.340439 * 100, metric = 9.77% * 100;
 Minibatch[ 901-1000]: loss = 0.335880 * 100, metric = 9.81% * 100;
 Minibatch[1001-1100]: loss = 0.330775 * 100, metric = 9.11% * 100;
 Minibatch[1101-1200]: loss = 0.341522 * 100, metric = 9.57% * 100;
 Minibatch[1201-1300]: loss = 0.351076 * 100, metric = 10.07% * 100;
 Minibatch[1301-1400]: loss = 0.331758 * 100, metric = 9.60% * 100;
 Minibatch[1401-1500]: loss = 0.336104 * 100, metric = 9.64% * 100;
 Minibatch[1501-1600]: loss = 0.317891 * 100, metric = 9.05% * 100;
 Minibatch[1601-1700]: loss = 0.325208 * 100, metric = 9.13% * 100;
 Minibatch[1701-1800]: loss = 0.320520 * 100, metric = 9.16% * 100;
 Minibatch[1801-1900]: loss = 0.337506 * 100, metric = 9.54% * 100;
 Minibatch[1901-2000]: loss = 0.327792 * 100, metric = 9.43% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.333341 * 2000, metric = 9.52% * 2000 882.183s (  2.3 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.03% * 2000;
 Minibatch[   1- 100]: loss = 0.326866 * 100, metric = 9.41% * 100;
 Minibatch[ 101- 200]: loss = 0.332178 * 100, metric = 9.38% * 100;
 Minibatch[ 201- 300]: loss = 0.339295 * 100, metric = 9.71% * 100;
 Minibatch[ 301- 400]: loss = 0.321643 * 100, metric = 9.08% * 100;
 Minibatch[ 401- 500]: loss = 0.333251 * 100, metric = 9.48% * 100;
 Minibatch[ 501- 600]: loss = 0.309005 * 100, metric = 8.83% * 100;
 Minibatch[ 601- 700]: loss = 0.327914 * 100, metric = 9.13% * 100;
 Minibatch[ 701- 800]: loss = 0.332964 * 100, metric = 9.55% * 100;
 Minibatch[ 801- 900]: loss = 0.336628 * 100, metric = 9.74% * 100;
 Minibatch[ 901-1000]: loss = 0.324846 * 100, metric = 9.18% * 100;
 Minibatch[1001-1100]: loss = 0.344241 * 100, metric = 9.82% * 100;
 Minibatch[1101-1200]: loss = 0.319911 * 100, metric = 9.18% * 100;
 Minibatch[1201-1300]: loss = 0.334069 * 100, metric = 9.73% * 100;
 Minibatch[1301-1400]: loss = 0.316884 * 100, metric = 9.08% * 100;
 Minibatch[1401-1500]: loss = 0.314401 * 100, metric = 8.96% * 100;
 Minibatch[1501-1600]: loss = 0.318609 * 100, metric = 9.23% * 100;
 Minibatch[1601-1700]: loss = 0.321043 * 100, metric = 9.01% * 100;
 Minibatch[1701-1800]: loss = 0.313254 * 100, metric = 8.73% * 100;
 Minibatch[1801-1900]: loss = 0.319090 * 100, metric = 9.01% * 100;
 Minibatch[1901-2000]: loss = 0.316306 * 100, metric = 8.84% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.325120 * 2000, metric = 9.25% * 2000 879.114s (  2.3 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 16.15% * 2000;
0.43597757402807474
 Minibatch[   1- 100]: loss = 0.317896 * 100, metric = 9.13% * 100;
 Minibatch[ 101- 200]: loss = 0.317536 * 100, metric = 9.10% * 100;
 Minibatch[ 201- 300]: loss = 0.296859 * 100, metric = 8.49% * 100;
 Minibatch[ 301- 400]: loss = 0.307064 * 100, metric = 8.86% * 100;
 Minibatch[ 401- 500]: loss = 0.318002 * 100, metric = 9.29% * 100;
 Minibatch[ 501- 600]: loss = 0.325194 * 100, metric = 9.31% * 100;
 Minibatch[ 601- 700]: loss = 0.300437 * 100, metric = 8.48% * 100;
 Minibatch[ 701- 800]: loss = 0.310783 * 100, metric = 8.65% * 100;
 Minibatch[ 801- 900]: loss = 0.298724 * 100, metric = 8.29% * 100;
 Minibatch[ 901-1000]: loss = 0.288759 * 100, metric = 7.94% * 100;
 Minibatch[1001-1100]: loss = 0.294276 * 100, metric = 8.17% * 100;
 Minibatch[1101-1200]: loss = 0.295575 * 100, metric = 8.18% * 100;
 Minibatch[1201-1300]: loss = 0.309897 * 100, metric = 8.72% * 100;
 Minibatch[1301-1400]: loss = 0.311682 * 100, metric = 8.83% * 100;
 Minibatch[1401-1500]: loss = 0.297858 * 100, metric = 8.19% * 100;
 Minibatch[1501-1600]: loss = 0.305900 * 100, metric = 8.63% * 100;
 Minibatch[1601-1700]: loss = 0.300000 * 100, metric = 8.28% * 100;
 Minibatch[1701-1800]: loss = 0.299197 * 100, metric = 8.30% * 100;
 Minibatch[1801-1900]: loss = 0.302550 * 100, metric = 8.39% * 100;
 Minibatch[1901-2000]: loss = 0.306470 * 100, metric = 8.70% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.305233 * 2000, metric = 8.60% * 2000 873.135s (  2.3 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 16.39% * 2000;
 Minibatch[   1- 100]: loss = 0.286862 * 100, metric = 7.98% * 100;
 Minibatch[ 101- 200]: loss = 0.317134 * 100, metric = 8.88% * 100;
 Minibatch[ 201- 300]: loss = 0.294694 * 100, metric = 8.29% * 100;
 Minibatch[ 301- 400]: loss = 0.314641 * 100, metric = 8.97% * 100;
 Minibatch[ 401- 500]: loss = 0.298402 * 100, metric = 8.28% * 100;
 Minibatch[ 501- 600]: loss = 0.300948 * 100, metric = 8.36% * 100;
 Minibatch[ 601- 700]: loss = 0.304108 * 100, metric = 8.66% * 100;
 Minibatch[ 701- 800]: loss = 0.293831 * 100, metric = 8.44% * 100;
 Minibatch[ 801- 900]: loss = 0.291200 * 100, metric = 8.39% * 100;
 Minibatch[ 901-1000]: loss = 0.306931 * 100, metric = 8.77% * 100;
 Minibatch[1001-1100]: loss = 0.285193 * 100, metric = 8.19% * 100;
 Minibatch[1101-1200]: loss = 0.297146 * 100, metric = 8.57% * 100;
 Minibatch[1201-1300]: loss = 0.291481 * 100, metric = 8.32% * 100;
 Minibatch[1301-1400]: loss = 0.291228 * 100, metric = 8.09% * 100;
 Minibatch[1401-1500]: loss = 0.301992 * 100, metric = 8.48% * 100;
 Minibatch[1501-1600]: loss = 0.298714 * 100, metric = 8.45% * 100;
 Minibatch[1601-1700]: loss = 0.297814 * 100, metric = 8.37% * 100;
 Minibatch[1701-1800]: loss = 0.294026 * 100, metric = 8.28% * 100;
 Minibatch[1801-1900]: loss = 0.289236 * 100, metric = 8.21% * 100;
 Minibatch[1901-2000]: loss = 0.298992 * 100, metric = 8.51% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.297729 * 2000, metric = 8.43% * 2000 869.540s (  2.3 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 15.15% * 2000;
0.4293979105502367
 Minibatch[   1- 100]: loss = 0.308970 * 100, metric = 8.85% * 100;
 Minibatch[ 101- 200]: loss = 0.288557 * 100, metric = 8.21% * 100;
 Minibatch[ 201- 300]: loss = 0.292284 * 100, metric = 8.26% * 100;
 Minibatch[ 301- 400]: loss = 0.284678 * 100, metric = 8.04% * 100;
 Minibatch[ 401- 500]: loss = 0.295260 * 100, metric = 8.22% * 100;
 Minibatch[ 501- 600]: loss = 0.279491 * 100, metric = 7.86% * 100;
 Minibatch[ 601- 700]: loss = 0.275729 * 100, metric = 7.69% * 100;
 Minibatch[ 701- 800]: loss = 0.269243 * 100, metric = 7.50% * 100;
 Minibatch[ 801- 900]: loss = 0.283436 * 100, metric = 8.07% * 100;
 Minibatch[ 901-1000]: loss = 0.284736 * 100, metric = 7.94% * 100;
 Minibatch[1001-1100]: loss = 0.285464 * 100, metric = 7.98% * 100;
 Minibatch[1101-1200]: loss = 0.287379 * 100, metric = 8.03% * 100;
 Minibatch[1201-1300]: loss = 0.282827 * 100, metric = 7.89% * 100;
 Minibatch[1301-1400]: loss = 0.287476 * 100, metric = 7.98% * 100;
 Minibatch[1401-1500]: loss = 0.275396 * 100, metric = 7.77% * 100;
 Minibatch[1501-1600]: loss = 0.281702 * 100, metric = 8.03% * 100;
 Minibatch[1601-1700]: loss = 0.275635 * 100, metric = 7.60% * 100;
 Minibatch[1701-1800]: loss = 0.288555 * 100, metric = 7.93% * 100;
 Minibatch[1801-1900]: loss = 0.283868 * 100, metric = 8.01% * 100;
 Minibatch[1901-2000]: loss = 0.275284 * 100, metric = 7.39% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.284299 * 2000, metric = 7.96% * 2000 861.746s (  2.3 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 14.90% * 2000;
0.4223515290170908
 Minibatch[   1- 100]: loss = 0.264912 * 100, metric = 7.29% * 100;
 Minibatch[ 101- 200]: loss = 0.275336 * 100, metric = 7.64% * 100;
 Minibatch[ 201- 300]: loss = 0.283443 * 100, metric = 8.13% * 100;
 Minibatch[ 301- 400]: loss = 0.274985 * 100, metric = 7.56% * 100;
 Minibatch[ 401- 500]: loss = 0.269935 * 100, metric = 7.37% * 100;
 Minibatch[ 501- 600]: loss = 0.283262 * 100, metric = 7.92% * 100;
 Minibatch[ 601- 700]: loss = 0.266506 * 100, metric = 7.17% * 100;
 Minibatch[ 701- 800]: loss = 0.285284 * 100, metric = 8.23% * 100;
 Minibatch[ 801- 900]: loss = 0.280708 * 100, metric = 7.83% * 100;
 Minibatch[ 901-1000]: loss = 0.284774 * 100, metric = 7.89% * 100;
 Minibatch[1001-1100]: loss = 0.279344 * 100, metric = 7.71% * 100;
 Minibatch[1101-1200]: loss = 0.281058 * 100, metric = 7.77% * 100;
 Minibatch[1201-1300]: loss = 0.277384 * 100, metric = 7.67% * 100;
 Minibatch[1301-1400]: loss = 0.259869 * 100, metric = 7.26% * 100;
 Minibatch[1401-1500]: loss = 0.278180 * 100, metric = 7.82% * 100;
 Minibatch[1501-1600]: loss = 0.267233 * 100, metric = 7.43% * 100;
 Minibatch[1601-1700]: loss = 0.266322 * 100, metric = 7.33% * 100;
 Minibatch[1701-1800]: loss = 0.279800 * 100, metric = 7.78% * 100;
 Minibatch[1801-1900]: loss = 0.274343 * 100, metric = 7.72% * 100;
 Minibatch[1901-2000]: loss = 0.272287 * 100, metric = 7.73% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.275248 * 2000, metric = 7.66% * 2000 869.774s (  2.3 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 15.58% * 2000;
 Minibatch[   1- 100]: loss = 0.262064 * 100, metric = 7.57% * 100;
 Minibatch[ 101- 200]: loss = 0.262841 * 100, metric = 7.14% * 100;
 Minibatch[ 201- 300]: loss = 0.269094 * 100, metric = 7.54% * 100;
 Minibatch[ 301- 400]: loss = 0.291783 * 100, metric = 8.25% * 100;
 Minibatch[ 401- 500]: loss = 0.266530 * 100, metric = 7.30% * 100;
 Minibatch[ 501- 600]: loss = 0.262736 * 100, metric = 7.33% * 100;
 Minibatch[ 601- 700]: loss = 0.260090 * 100, metric = 7.28% * 100;
 Minibatch[ 701- 800]: loss = 0.268870 * 100, metric = 7.39% * 100;
 Minibatch[ 801- 900]: loss = 0.259362 * 100, metric = 7.04% * 100;
 Minibatch[ 901-1000]: loss = 0.267242 * 100, metric = 7.54% * 100;
 Minibatch[1001-1100]: loss = 0.268788 * 100, metric = 7.64% * 100;
 Minibatch[1101-1200]: loss = 0.269075 * 100, metric = 7.49% * 100;
 Minibatch[1201-1300]: loss = 0.274402 * 100, metric = 7.79% * 100;
 Minibatch[1301-1400]: loss = 0.263132 * 100, metric = 7.21% * 100;
 Minibatch[1401-1500]: loss = 0.271299 * 100, metric = 7.61% * 100;
 Minibatch[1501-1600]: loss = 0.252014 * 100, metric = 6.93% * 100;
 Minibatch[1601-1700]: loss = 0.269552 * 100, metric = 7.73% * 100;
 Minibatch[1701-1800]: loss = 0.256137 * 100, metric = 7.18% * 100;
 Minibatch[1801-1900]: loss = 0.264674 * 100, metric = 7.46% * 100;
 Minibatch[1901-2000]: loss = 0.275918 * 100, metric = 7.74% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.266780 * 2000, metric = 7.46% * 2000 861.584s (  2.3 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 15.97% * 2000;
 Minibatch[   1- 100]: loss = 0.268107 * 100, metric = 7.45% * 100;
 Minibatch[ 101- 200]: loss = 0.268485 * 100, metric = 7.47% * 100;
 Minibatch[ 201- 300]: loss = 0.263181 * 100, metric = 7.51% * 100;
 Minibatch[ 301- 400]: loss = 0.267964 * 100, metric = 7.37% * 100;
 Minibatch[ 401- 500]: loss = 0.274474 * 100, metric = 7.65% * 100;
 Minibatch[ 501- 600]: loss = 0.274265 * 100, metric = 7.76% * 100;
 Minibatch[ 601- 700]: loss = 0.263116 * 100, metric = 7.09% * 100;
 Minibatch[ 701- 800]: loss = 0.253508 * 100, metric = 7.06% * 100;
 Minibatch[ 801- 900]: loss = 0.259180 * 100, metric = 7.25% * 100;
 Minibatch[ 901-1000]: loss = 0.277279 * 100, metric = 7.74% * 100;
 Minibatch[1001-1100]: loss = 0.274983 * 100, metric = 7.71% * 100;
 Minibatch[1101-1200]: loss = 0.264260 * 100, metric = 7.48% * 100;
 Minibatch[1201-1300]: loss = 0.264744 * 100, metric = 7.50% * 100;
 Minibatch[1301-1400]: loss = 0.258611 * 100, metric = 7.18% * 100;
 Minibatch[1401-1500]: loss = 0.258077 * 100, metric = 7.24% * 100;
 Minibatch[1501-1600]: loss = 0.250370 * 100, metric = 6.85% * 100;
 Minibatch[1601-1700]: loss = 0.260205 * 100, metric = 7.42% * 100;
 Minibatch[1701-1800]: loss = 0.256776 * 100, metric = 7.11% * 100;
 Minibatch[1801-1900]: loss = 0.256155 * 100, metric = 7.34% * 100;
 Minibatch[1901-2000]: loss = 0.264237 * 100, metric = 7.20% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.263899 * 2000, metric = 7.37% * 2000 865.924s (  2.3 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 17.95% * 2000;
 Minibatch[   1- 100]: loss = 0.260816 * 100, metric = 7.20% * 100;
 Minibatch[ 101- 200]: loss = 0.248756 * 100, metric = 6.86% * 100;
 Minibatch[ 201- 300]: loss = 0.264165 * 100, metric = 7.49% * 100;
 Minibatch[ 301- 400]: loss = 0.261767 * 100, metric = 7.42% * 100;
 Minibatch[ 401- 500]: loss = 0.259580 * 100, metric = 7.32% * 100;
 Minibatch[ 501- 600]: loss = 0.255748 * 100, metric = 7.07% * 100;
 Minibatch[ 601- 700]: loss = 0.256768 * 100, metric = 7.16% * 100;
 Minibatch[ 701- 800]: loss = 0.272312 * 100, metric = 7.69% * 100;
 Minibatch[ 801- 900]: loss = 0.265559 * 100, metric = 7.54% * 100;
 Minibatch[ 901-1000]: loss = 0.266131 * 100, metric = 7.59% * 100;
 Minibatch[1001-1100]: loss = 0.259677 * 100, metric = 7.06% * 100;
 Minibatch[1101-1200]: loss = 0.252690 * 100, metric = 6.95% * 100;
 Minibatch[1201-1300]: loss = 0.239600 * 100, metric = 6.60% * 100;
 Minibatch[1301-1400]: loss = 0.257915 * 100, metric = 7.18% * 100;
 Minibatch[1401-1500]: loss = 0.263839 * 100, metric = 7.36% * 100;
 Minibatch[1501-1600]: loss = 0.249501 * 100, metric = 6.98% * 100;
 Minibatch[1601-1700]: loss = 0.252454 * 100, metric = 7.03% * 100;
 Minibatch[1701-1800]: loss = 0.254316 * 100, metric = 7.14% * 100;
 Minibatch[1801-1900]: loss = 0.254562 * 100, metric = 7.10% * 100;
 Minibatch[1901-2000]: loss = 0.263520 * 100, metric = 7.33% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.257984 * 2000, metric = 7.20% * 2000 862.331s (  2.3 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 16.64% * 2000;
 Minibatch[   1- 100]: loss = 0.253393 * 100, metric = 7.21% * 100;
 Minibatch[ 101- 200]: loss = 0.261541 * 100, metric = 7.37% * 100;
 Minibatch[ 201- 300]: loss = 0.260147 * 100, metric = 7.09% * 100;
 Minibatch[ 301- 400]: loss = 0.251359 * 100, metric = 7.13% * 100;
 Minibatch[ 401- 500]: loss = 0.256845 * 100, metric = 7.27% * 100;
 Minibatch[ 501- 600]: loss = 0.244792 * 100, metric = 6.83% * 100;
 Minibatch[ 601- 700]: loss = 0.239008 * 100, metric = 6.74% * 100;
 Minibatch[ 701- 800]: loss = 0.256497 * 100, metric = 7.17% * 100;
 Minibatch[ 801- 900]: loss = 0.267257 * 100, metric = 7.60% * 100;
 Minibatch[ 901-1000]: loss = 0.247128 * 100, metric = 6.94% * 100;
 Minibatch[1001-1100]: loss = 0.254716 * 100, metric = 7.12% * 100;
 Minibatch[1101-1200]: loss = 0.247391 * 100, metric = 6.83% * 100;
 Minibatch[1201-1300]: loss = 0.240063 * 100, metric = 6.66% * 100;
 Minibatch[1301-1400]: loss = 0.261162 * 100, metric = 7.37% * 100;
 Minibatch[1401-1500]: loss = 0.234568 * 100, metric = 6.58% * 100;
 Minibatch[1501-1600]: loss = 0.239996 * 100, metric = 6.75% * 100;
 Minibatch[1601-1700]: loss = 0.250379 * 100, metric = 7.15% * 100;
 Minibatch[1701-1800]: loss = 0.236907 * 100, metric = 6.53% * 100;
 Minibatch[1801-1900]: loss = 0.249366 * 100, metric = 7.04% * 100;
 Minibatch[1901-2000]: loss = 0.243419 * 100, metric = 6.91% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.249797 * 2000, metric = 7.02% * 2000 861.240s (  2.3 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 14.28% * 2000;
0.41245270224288105
 Minibatch[   1- 100]: loss = 0.257118 * 100, metric = 7.39% * 100;
 Minibatch[ 101- 200]: loss = 0.247800 * 100, metric = 6.82% * 100;
 Minibatch[ 201- 300]: loss = 0.248129 * 100, metric = 6.89% * 100;
 Minibatch[ 301- 400]: loss = 0.245648 * 100, metric = 6.72% * 100;
 Minibatch[ 401- 500]: loss = 0.235090 * 100, metric = 6.40% * 100;
 Minibatch[ 501- 600]: loss = 0.242924 * 100, metric = 6.75% * 100;
 Minibatch[ 601- 700]: loss = 0.238942 * 100, metric = 6.79% * 100;
 Minibatch[ 701- 800]: loss = 0.237828 * 100, metric = 6.70% * 100;
 Minibatch[ 801- 900]: loss = 0.235281 * 100, metric = 6.52% * 100;
 Minibatch[ 901-1000]: loss = 0.247022 * 100, metric = 7.09% * 100;
 Minibatch[1001-1100]: loss = 0.238401 * 100, metric = 6.54% * 100;
 Minibatch[1101-1200]: loss = 0.249119 * 100, metric = 7.24% * 100;
 Minibatch[1201-1300]: loss = 0.237241 * 100, metric = 6.67% * 100;
 Minibatch[1301-1400]: loss = 0.237116 * 100, metric = 6.60% * 100;
 Minibatch[1401-1500]: loss = 0.239386 * 100, metric = 6.76% * 100;
 Minibatch[1501-1600]: loss = 0.241795 * 100, metric = 6.77% * 100;
 Minibatch[1601-1700]: loss = 0.238582 * 100, metric = 6.55% * 100;
 Minibatch[1701-1800]: loss = 0.245776 * 100, metric = 6.58% * 100;
 Minibatch[1801-1900]: loss = 0.248832 * 100, metric = 6.84% * 100;
 Minibatch[1901-2000]: loss = 0.238255 * 100, metric = 6.81% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.242514 * 2000, metric = 6.77% * 2000 870.320s (  2.3 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.25% * 2000;
 Minibatch[   1- 100]: loss = 0.233661 * 100, metric = 6.54% * 100;
 Minibatch[ 101- 200]: loss = 0.249420 * 100, metric = 7.00% * 100;
 Minibatch[ 201- 300]: loss = 0.247925 * 100, metric = 6.88% * 100;
 Minibatch[ 301- 400]: loss = 0.241688 * 100, metric = 6.75% * 100;
 Minibatch[ 401- 500]: loss = 0.249048 * 100, metric = 6.92% * 100;
 Minibatch[ 501- 600]: loss = 0.246035 * 100, metric = 6.91% * 100;
 Minibatch[ 601- 700]: loss = 0.235331 * 100, metric = 6.51% * 100;
 Minibatch[ 701- 800]: loss = 0.240662 * 100, metric = 6.76% * 100;
 Minibatch[ 801- 900]: loss = 0.239742 * 100, metric = 6.70% * 100;
 Minibatch[ 901-1000]: loss = 0.234153 * 100, metric = 6.42% * 100;
 Minibatch[1001-1100]: loss = 0.232134 * 100, metric = 6.46% * 100;
 Minibatch[1101-1200]: loss = 0.247916 * 100, metric = 7.12% * 100;
 Minibatch[1201-1300]: loss = 0.242429 * 100, metric = 6.75% * 100;
 Minibatch[1301-1400]: loss = 0.229164 * 100, metric = 6.50% * 100;
 Minibatch[1401-1500]: loss = 0.239697 * 100, metric = 6.79% * 100;
 Minibatch[1501-1600]: loss = 0.235692 * 100, metric = 6.51% * 100;
 Minibatch[1601-1700]: loss = 0.238079 * 100, metric = 6.65% * 100;
 Minibatch[1701-1800]: loss = 0.234344 * 100, metric = 6.58% * 100;
 Minibatch[1801-1900]: loss = 0.245515 * 100, metric = 6.79% * 100;
 Minibatch[1901-2000]: loss = 0.247381 * 100, metric = 6.88% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.240501 * 2000, metric = 6.72% * 2000 857.172s (  2.3 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.14% * 2000;
 Minibatch[   1- 100]: loss = 0.224171 * 100, metric = 6.29% * 100;
 Minibatch[ 101- 200]: loss = 0.250170 * 100, metric = 7.19% * 100;
 Minibatch[ 201- 300]: loss = 0.232943 * 100, metric = 6.73% * 100;
 Minibatch[ 301- 400]: loss = 0.236650 * 100, metric = 6.71% * 100;
 Minibatch[ 401- 500]: loss = 0.230702 * 100, metric = 6.71% * 100;
 Minibatch[ 501- 600]: loss = 0.233364 * 100, metric = 6.50% * 100;
 Minibatch[ 601- 700]: loss = 0.239101 * 100, metric = 6.76% * 100;
 Minibatch[ 701- 800]: loss = 0.225739 * 100, metric = 6.25% * 100;
 Minibatch[ 801- 900]: loss = 0.238405 * 100, metric = 6.72% * 100;
 Minibatch[ 901-1000]: loss = 0.240928 * 100, metric = 6.72% * 100;
 Minibatch[1001-1100]: loss = 0.246294 * 100, metric = 6.96% * 100;
 Minibatch[1101-1200]: loss = 0.236446 * 100, metric = 6.61% * 100;
 Minibatch[1201-1300]: loss = 0.242952 * 100, metric = 6.90% * 100;
 Minibatch[1301-1400]: loss = 0.246428 * 100, metric = 6.91% * 100;
 Minibatch[1401-1500]: loss = 0.222616 * 100, metric = 6.27% * 100;
 Minibatch[1501-1600]: loss = 0.236890 * 100, metric = 6.52% * 100;
 Minibatch[1601-1700]: loss = 0.221287 * 100, metric = 6.05% * 100;
 Minibatch[1701-1800]: loss = 0.225011 * 100, metric = 6.31% * 100;
 Minibatch[1801-1900]: loss = 0.224604 * 100, metric = 6.38% * 100;
 Minibatch[1901-2000]: loss = 0.227158 * 100, metric = 6.38% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.234093 * 2000, metric = 6.59% * 2000 858.337s (  2.3 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 16.77% * 2000;
 Minibatch[   1- 100]: loss = 0.237530 * 100, metric = 6.76% * 100;
 Minibatch[ 101- 200]: loss = 0.243975 * 100, metric = 6.85% * 100;
 Minibatch[ 201- 300]: loss = 0.225792 * 100, metric = 6.19% * 100;
 Minibatch[ 301- 400]: loss = 0.233437 * 100, metric = 6.60% * 100;
 Minibatch[ 401- 500]: loss = 0.231614 * 100, metric = 6.35% * 100;
 Minibatch[ 501- 600]: loss = 0.224811 * 100, metric = 6.22% * 100;
 Minibatch[ 601- 700]: loss = 0.231794 * 100, metric = 6.45% * 100;
 Minibatch[ 701- 800]: loss = 0.229876 * 100, metric = 6.51% * 100;
 Minibatch[ 801- 900]: loss = 0.247844 * 100, metric = 6.98% * 100;
 Minibatch[ 901-1000]: loss = 0.221097 * 100, metric = 6.29% * 100;
 Minibatch[1001-1100]: loss = 0.238147 * 100, metric = 6.91% * 100;
 Minibatch[1101-1200]: loss = 0.237706 * 100, metric = 6.90% * 100;
 Minibatch[1201-1300]: loss = 0.231608 * 100, metric = 6.64% * 100;
 Minibatch[1301-1400]: loss = 0.226503 * 100, metric = 6.45% * 100;
 Minibatch[1401-1500]: loss = 0.233788 * 100, metric = 6.67% * 100;
 Minibatch[1501-1600]: loss = 0.236347 * 100, metric = 6.86% * 100;
 Minibatch[1601-1700]: loss = 0.227296 * 100, metric = 6.43% * 100;
 Minibatch[1701-1800]: loss = 0.221993 * 100, metric = 6.34% * 100;
 Minibatch[1801-1900]: loss = 0.219590 * 100, metric = 6.12% * 100;
 Minibatch[1901-2000]: loss = 0.218705 * 100, metric = 6.03% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.230973 * 2000, metric = 6.53% * 2000 863.805s (  2.3 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 15.76% * 2000;
 Minibatch[   1- 100]: loss = 0.221388 * 100, metric = 6.05% * 100;
 Minibatch[ 101- 200]: loss = 0.218553 * 100, metric = 6.08% * 100;
 Minibatch[ 201- 300]: loss = 0.218885 * 100, metric = 6.11% * 100;
 Minibatch[ 301- 400]: loss = 0.232943 * 100, metric = 6.41% * 100;
 Minibatch[ 401- 500]: loss = 0.224614 * 100, metric = 6.55% * 100;
 Minibatch[ 501- 600]: loss = 0.226898 * 100, metric = 6.42% * 100;
 Minibatch[ 601- 700]: loss = 0.230626 * 100, metric = 6.53% * 100;
 Minibatch[ 701- 800]: loss = 0.222108 * 100, metric = 6.22% * 100;
 Minibatch[ 801- 900]: loss = 0.233745 * 100, metric = 6.71% * 100;
 Minibatch[ 901-1000]: loss = 0.229014 * 100, metric = 6.37% * 100;
 Minibatch[1001-1100]: loss = 0.207768 * 100, metric = 5.85% * 100;
 Minibatch[1101-1200]: loss = 0.218486 * 100, metric = 6.05% * 100;
 Minibatch[1201-1300]: loss = 0.231599 * 100, metric = 6.38% * 100;
 Minibatch[1301-1400]: loss = 0.231786 * 100, metric = 6.56% * 100;
 Minibatch[1401-1500]: loss = 0.226674 * 100, metric = 6.55% * 100;
 Minibatch[1501-1600]: loss = 0.232860 * 100, metric = 6.52% * 100;
 Minibatch[1601-1700]: loss = 0.230342 * 100, metric = 6.52% * 100;
 Minibatch[1701-1800]: loss = 0.235318 * 100, metric = 6.76% * 100;
 Minibatch[1801-1900]: loss = 0.226552 * 100, metric = 6.45% * 100;
 Minibatch[1901-2000]: loss = 0.223119 * 100, metric = 6.29% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.226164 * 2000, metric = 6.37% * 2000 861.641s (  2.3 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 15.08% * 2000;
 Minibatch[   1- 100]: loss = 0.231842 * 100, metric = 6.65% * 100;
 Minibatch[ 101- 200]: loss = 0.227482 * 100, metric = 6.35% * 100;
 Minibatch[ 201- 300]: loss = 0.225563 * 100, metric = 6.35% * 100;
 Minibatch[ 301- 400]: loss = 0.227123 * 100, metric = 6.40% * 100;
 Minibatch[ 401- 500]: loss = 0.219922 * 100, metric = 6.21% * 100;
 Minibatch[ 501- 600]: loss = 0.217606 * 100, metric = 6.15% * 100;
 Minibatch[ 601- 700]: loss = 0.222180 * 100, metric = 6.33% * 100;
 Minibatch[ 701- 800]: loss = 0.209186 * 100, metric = 5.96% * 100;
 Minibatch[ 801- 900]: loss = 0.226167 * 100, metric = 6.30% * 100;
 Minibatch[ 901-1000]: loss = 0.226130 * 100, metric = 6.57% * 100;
 Minibatch[1001-1100]: loss = 0.219771 * 100, metric = 6.17% * 100;
 Minibatch[1101-1200]: loss = 0.217831 * 100, metric = 5.99% * 100;
 Minibatch[1201-1300]: loss = 0.219669 * 100, metric = 6.22% * 100;
 Minibatch[1301-1400]: loss = 0.211905 * 100, metric = 6.00% * 100;
 Minibatch[1401-1500]: loss = 0.223338 * 100, metric = 6.35% * 100;
 Minibatch[1501-1600]: loss = 0.228786 * 100, metric = 6.55% * 100;
 Minibatch[1601-1700]: loss = 0.215415 * 100, metric = 5.94% * 100;
 Minibatch[1701-1800]: loss = 0.221538 * 100, metric = 6.17% * 100;
 Minibatch[1801-1900]: loss = 0.235655 * 100, metric = 6.88% * 100;
 Minibatch[1901-2000]: loss = 0.213404 * 100, metric = 5.75% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.222026 * 2000, metric = 6.26% * 2000 857.268s (  2.3 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 13.94% * 2000;
 Minibatch[   1- 100]: loss = 0.226726 * 100, metric = 6.39% * 100;
 Minibatch[ 101- 200]: loss = 0.215868 * 100, metric = 5.97% * 100;
 Minibatch[ 201- 300]: loss = 0.229112 * 100, metric = 6.54% * 100;
 Minibatch[ 301- 400]: loss = 0.221660 * 100, metric = 6.39% * 100;
 Minibatch[ 401- 500]: loss = 0.220366 * 100, metric = 6.17% * 100;
 Minibatch[ 501- 600]: loss = 0.221743 * 100, metric = 6.09% * 100;
 Minibatch[ 601- 700]: loss = 0.210205 * 100, metric = 5.96% * 100;
 Minibatch[ 701- 800]: loss = 0.221988 * 100, metric = 6.30% * 100;
 Minibatch[ 801- 900]: loss = 0.219515 * 100, metric = 6.21% * 100;
 Minibatch[ 901-1000]: loss = 0.225061 * 100, metric = 6.37% * 100;
 Minibatch[1001-1100]: loss = 0.208651 * 100, metric = 5.57% * 100;
 Minibatch[1101-1200]: loss = 0.203481 * 100, metric = 5.58% * 100;
 Minibatch[1201-1300]: loss = 0.216696 * 100, metric = 6.04% * 100;
 Minibatch[1301-1400]: loss = 0.218119 * 100, metric = 6.11% * 100;
 Minibatch[1401-1500]: loss = 0.209097 * 100, metric = 5.95% * 100;
 Minibatch[1501-1600]: loss = 0.205545 * 100, metric = 5.61% * 100;
 Minibatch[1601-1700]: loss = 0.211951 * 100, metric = 6.02% * 100;
 Minibatch[1701-1800]: loss = 0.211313 * 100, metric = 5.90% * 100;
 Minibatch[1801-1900]: loss = 0.208581 * 100, metric = 5.89% * 100;
 Minibatch[1901-2000]: loss = 0.213706 * 100, metric = 6.08% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.215969 * 2000, metric = 6.06% * 2000 857.528s (  2.3 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 15.55% * 2000;
 Minibatch[   1- 100]: loss = 0.221674 * 100, metric = 6.25% * 100;
 Minibatch[ 101- 200]: loss = 0.223062 * 100, metric = 6.23% * 100;
 Minibatch[ 201- 300]: loss = 0.210768 * 100, metric = 6.04% * 100;
 Minibatch[ 301- 400]: loss = 0.218909 * 100, metric = 6.21% * 100;
 Minibatch[ 401- 500]: loss = 0.219985 * 100, metric = 6.21% * 100;
 Minibatch[ 501- 600]: loss = 0.212883 * 100, metric = 5.79% * 100;
 Minibatch[ 601- 700]: loss = 0.217414 * 100, metric = 6.25% * 100;
 Minibatch[ 701- 800]: loss = 0.203684 * 100, metric = 5.68% * 100;
 Minibatch[ 801- 900]: loss = 0.207634 * 100, metric = 6.07% * 100;
 Minibatch[ 901-1000]: loss = 0.214711 * 100, metric = 5.89% * 100;
 Minibatch[1001-1100]: loss = 0.207210 * 100, metric = 5.73% * 100;
 Minibatch[1101-1200]: loss = 0.213027 * 100, metric = 6.02% * 100;
 Minibatch[1201-1300]: loss = 0.212982 * 100, metric = 5.96% * 100;
 Minibatch[1301-1400]: loss = 0.223362 * 100, metric = 6.43% * 100;
 Minibatch[1401-1500]: loss = 0.209922 * 100, metric = 5.78% * 100;
 Minibatch[1501-1600]: loss = 0.208112 * 100, metric = 5.75% * 100;
 Minibatch[1601-1700]: loss = 0.211654 * 100, metric = 6.06% * 100;
 Minibatch[1701-1800]: loss = 0.215236 * 100, metric = 6.01% * 100;
 Minibatch[1801-1900]: loss = 0.217502 * 100, metric = 6.27% * 100;
 Minibatch[1901-2000]: loss = 0.213583 * 100, metric = 6.04% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.214166 * 2000, metric = 6.03% * 2000 861.802s (  2.3 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 15.14% * 2000;
 Minibatch[   1- 100]: loss = 0.198007 * 100, metric = 5.55% * 100;
 Minibatch[ 101- 200]: loss = 0.213445 * 100, metric = 6.03% * 100;
 Minibatch[ 201- 300]: loss = 0.211411 * 100, metric = 6.10% * 100;
 Minibatch[ 301- 400]: loss = 0.211235 * 100, metric = 5.87% * 100;
 Minibatch[ 401- 500]: loss = 0.213898 * 100, metric = 6.17% * 100;
 Minibatch[ 501- 600]: loss = 0.201563 * 100, metric = 5.70% * 100;
 Minibatch[ 601- 700]: loss = 0.215143 * 100, metric = 6.03% * 100;
 Minibatch[ 701- 800]: loss = 0.207407 * 100, metric = 5.91% * 100;
 Minibatch[ 801- 900]: loss = 0.216780 * 100, metric = 6.11% * 100;
 Minibatch[ 901-1000]: loss = 0.207885 * 100, metric = 5.76% * 100;
 Minibatch[1001-1100]: loss = 0.208264 * 100, metric = 5.81% * 100;
 Minibatch[1101-1200]: loss = 0.215697 * 100, metric = 5.89% * 100;
 Minibatch[1201-1300]: loss = 0.211053 * 100, metric = 5.96% * 100;
 Minibatch[1301-1400]: loss = 0.207014 * 100, metric = 5.71% * 100;
 Minibatch[1401-1500]: loss = 0.203051 * 100, metric = 5.66% * 100;
 Minibatch[1501-1600]: loss = 0.216362 * 100, metric = 6.09% * 100;
 Minibatch[1601-1700]: loss = 0.202568 * 100, metric = 5.67% * 100;
 Minibatch[1701-1800]: loss = 0.207355 * 100, metric = 5.82% * 100;
 Minibatch[1801-1900]: loss = 0.208488 * 100, metric = 5.88% * 100;
 Minibatch[1901-2000]: loss = 0.217051 * 100, metric = 6.22% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.209684 * 2000, metric = 5.90% * 2000 855.830s (  2.3 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.24% * 2000;
 Minibatch[   1- 100]: loss = 0.214815 * 100, metric = 6.23% * 100;
 Minibatch[ 101- 200]: loss = 0.214756 * 100, metric = 6.12% * 100;
 Minibatch[ 201- 300]: loss = 0.212326 * 100, metric = 6.07% * 100;
 Minibatch[ 301- 400]: loss = 0.208643 * 100, metric = 5.84% * 100;
 Minibatch[ 401- 500]: loss = 0.206082 * 100, metric = 5.74% * 100;
 Minibatch[ 501- 600]: loss = 0.203485 * 100, metric = 5.76% * 100;
 Minibatch[ 601- 700]: loss = 0.209383 * 100, metric = 5.78% * 100;
 Minibatch[ 701- 800]: loss = 0.197957 * 100, metric = 5.45% * 100;
 Minibatch[ 801- 900]: loss = 0.200214 * 100, metric = 5.75% * 100;
 Minibatch[ 901-1000]: loss = 0.206817 * 100, metric = 5.94% * 100;
 Minibatch[1001-1100]: loss = 0.204351 * 100, metric = 5.71% * 100;
 Minibatch[1101-1200]: loss = 0.218366 * 100, metric = 6.19% * 100;
 Minibatch[1201-1300]: loss = 0.218722 * 100, metric = 6.06% * 100;
 Minibatch[1301-1400]: loss = 0.203515 * 100, metric = 5.65% * 100;
 Minibatch[1401-1500]: loss = 0.203238 * 100, metric = 5.58% * 100;
 Minibatch[1501-1600]: loss = 0.212977 * 100, metric = 6.09% * 100;
 Minibatch[1601-1700]: loss = 0.202587 * 100, metric = 5.72% * 100;
 Minibatch[1701-1800]: loss = 0.208812 * 100, metric = 6.00% * 100;
 Minibatch[1801-1900]: loss = 0.198000 * 100, metric = 5.47% * 100;
 Minibatch[1901-2000]: loss = 0.196689 * 100, metric = 5.50% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.207087 * 2000, metric = 5.83% * 2000 853.237s (  2.3 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.10% * 2000;
 Minibatch[   1- 100]: loss = 0.207055 * 100, metric = 5.81% * 100;
 Minibatch[ 101- 200]: loss = 0.190415 * 100, metric = 5.35% * 100;
 Minibatch[ 201- 300]: loss = 0.204394 * 100, metric = 5.78% * 100;
 Minibatch[ 301- 400]: loss = 0.201232 * 100, metric = 5.78% * 100;
 Minibatch[ 401- 500]: loss = 0.206974 * 100, metric = 5.85% * 100;
 Minibatch[ 501- 600]: loss = 0.199179 * 100, metric = 5.52% * 100;
 Minibatch[ 601- 700]: loss = 0.211058 * 100, metric = 5.77% * 100;
 Minibatch[ 701- 800]: loss = 0.202647 * 100, metric = 5.87% * 100;
 Minibatch[ 801- 900]: loss = 0.190974 * 100, metric = 5.34% * 100;
 Minibatch[ 901-1000]: loss = 0.195813 * 100, metric = 5.57% * 100;
 Minibatch[1001-1100]: loss = 0.210174 * 100, metric = 6.05% * 100;
 Minibatch[1101-1200]: loss = 0.207047 * 100, metric = 5.76% * 100;
 Minibatch[1201-1300]: loss = 0.197304 * 100, metric = 5.53% * 100;
 Minibatch[1301-1400]: loss = 0.196312 * 100, metric = 5.49% * 100;
 Minibatch[1401-1500]: loss = 0.202196 * 100, metric = 5.74% * 100;
 Minibatch[1501-1600]: loss = 0.192632 * 100, metric = 5.29% * 100;
 Minibatch[1601-1700]: loss = 0.215342 * 100, metric = 6.03% * 100;
 Minibatch[1701-1800]: loss = 0.208824 * 100, metric = 5.85% * 100;
 Minibatch[1801-1900]: loss = 0.202260 * 100, metric = 5.69% * 100;
 Minibatch[1901-2000]: loss = 0.207979 * 100, metric = 6.08% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.202490 * 2000, metric = 5.71% * 2000 872.947s (  2.3 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.12% * 2000;
 Minibatch[   1- 100]: loss = 0.204236 * 100, metric = 5.66% * 100;
 Minibatch[ 101- 200]: loss = 0.213397 * 100, metric = 6.02% * 100;
 Minibatch[ 201- 300]: loss = 0.202041 * 100, metric = 5.80% * 100;
 Minibatch[ 301- 400]: loss = 0.201763 * 100, metric = 5.73% * 100;
 Minibatch[ 401- 500]: loss = 0.203883 * 100, metric = 5.77% * 100;
 Minibatch[ 501- 600]: loss = 0.197802 * 100, metric = 5.49% * 100;
 Minibatch[ 601- 700]: loss = 0.195525 * 100, metric = 5.54% * 100;
 Minibatch[ 701- 800]: loss = 0.200807 * 100, metric = 5.72% * 100;
 Minibatch[ 801- 900]: loss = 0.207244 * 100, metric = 5.81% * 100;
 Minibatch[ 901-1000]: loss = 0.214842 * 100, metric = 6.21% * 100;
 Minibatch[1001-1100]: loss = 0.193586 * 100, metric = 5.43% * 100;
 Minibatch[1101-1200]: loss = 0.208711 * 100, metric = 6.05% * 100;
 Minibatch[1201-1300]: loss = 0.202107 * 100, metric = 5.77% * 100;
 Minibatch[1301-1400]: loss = 0.203308 * 100, metric = 5.83% * 100;
 Minibatch[1401-1500]: loss = 0.199585 * 100, metric = 5.64% * 100;
 Minibatch[1501-1600]: loss = 0.202970 * 100, metric = 5.77% * 100;
 Minibatch[1601-1700]: loss = 0.193902 * 100, metric = 5.41% * 100;
 Minibatch[1701-1800]: loss = 0.200150 * 100, metric = 5.63% * 100;
 Minibatch[1801-1900]: loss = 0.205282 * 100, metric = 5.83% * 100;
 Minibatch[1901-2000]: loss = 0.203500 * 100, metric = 5.59% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.202732 * 2000, metric = 5.74% * 2000 857.558s (  2.3 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.65% * 2000;
 Minibatch[   1- 100]: loss = 0.207268 * 100, metric = 5.96% * 100;
 Minibatch[ 101- 200]: loss = 0.191080 * 100, metric = 5.26% * 100;
 Minibatch[ 201- 300]: loss = 0.206863 * 100, metric = 5.84% * 100;
 Minibatch[ 301- 400]: loss = 0.201329 * 100, metric = 5.69% * 100;
 Minibatch[ 401- 500]: loss = 0.203486 * 100, metric = 5.86% * 100;
 Minibatch[ 501- 600]: loss = 0.212114 * 100, metric = 6.25% * 100;
 Minibatch[ 601- 700]: loss = 0.196469 * 100, metric = 5.55% * 100;
 Minibatch[ 701- 800]: loss = 0.188762 * 100, metric = 5.29% * 100;
 Minibatch[ 801- 900]: loss = 0.197188 * 100, metric = 5.68% * 100;
 Minibatch[ 901-1000]: loss = 0.204167 * 100, metric = 5.79% * 100;
 Minibatch[1001-1100]: loss = 0.195901 * 100, metric = 5.60% * 100;
 Minibatch[1101-1200]: loss = 0.191100 * 100, metric = 5.41% * 100;
 Minibatch[1201-1300]: loss = 0.198698 * 100, metric = 5.62% * 100;
 Minibatch[1301-1400]: loss = 0.199651 * 100, metric = 5.81% * 100;
 Minibatch[1401-1500]: loss = 0.203517 * 100, metric = 5.83% * 100;
 Minibatch[1501-1600]: loss = 0.190596 * 100, metric = 5.38% * 100;
 Minibatch[1601-1700]: loss = 0.193076 * 100, metric = 5.51% * 100;
 Minibatch[1701-1800]: loss = 0.193161 * 100, metric = 5.44% * 100;
 Minibatch[1801-1900]: loss = 0.200420 * 100, metric = 5.75% * 100;
 Minibatch[1901-2000]: loss = 0.197527 * 100, metric = 5.59% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.198619 * 2000, metric = 5.66% * 2000 854.593s (  2.3 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 15.08% * 2000;
 Minibatch[   1- 100]: loss = 0.189355 * 100, metric = 5.21% * 100;
 Minibatch[ 101- 200]: loss = 0.195643 * 100, metric = 5.48% * 100;
 Minibatch[ 201- 300]: loss = 0.194979 * 100, metric = 5.56% * 100;
 Minibatch[ 301- 400]: loss = 0.203232 * 100, metric = 5.76% * 100;
 Minibatch[ 401- 500]: loss = 0.192293 * 100, metric = 5.50% * 100;
 Minibatch[ 501- 600]: loss = 0.198001 * 100, metric = 5.71% * 100;
 Minibatch[ 601- 700]: loss = 0.190441 * 100, metric = 5.36% * 100;
 Minibatch[ 701- 800]: loss = 0.200818 * 100, metric = 5.61% * 100;
 Minibatch[ 801- 900]: loss = 0.190753 * 100, metric = 5.40% * 100;
 Minibatch[ 901-1000]: loss = 0.195191 * 100, metric = 5.57% * 100;
 Minibatch[1001-1100]: loss = 0.194217 * 100, metric = 5.57% * 100;
 Minibatch[1101-1200]: loss = 0.187447 * 100, metric = 5.23% * 100;
 Minibatch[1201-1300]: loss = 0.188468 * 100, metric = 5.30% * 100;
 Minibatch[1301-1400]: loss = 0.190893 * 100, metric = 5.42% * 100;
 Minibatch[1401-1500]: loss = 0.201351 * 100, metric = 5.81% * 100;
 Minibatch[1501-1600]: loss = 0.189881 * 100, metric = 5.54% * 100;
 Minibatch[1601-1700]: loss = 0.201384 * 100, metric = 5.69% * 100;
 Minibatch[1701-1800]: loss = 0.189542 * 100, metric = 5.43% * 100;
 Minibatch[1801-1900]: loss = 0.201731 * 100, metric = 5.69% * 100;
 Minibatch[1901-2000]: loss = 0.195724 * 100, metric = 5.65% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.194567 * 2000, metric = 5.52% * 2000 854.762s (  2.3 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 14.82% * 2000;
 Minibatch[   1- 100]: loss = 0.204487 * 100, metric = 5.85% * 100;
 Minibatch[ 101- 200]: loss = 0.185500 * 100, metric = 5.27% * 100;
 Minibatch[ 201- 300]: loss = 0.193609 * 100, metric = 5.46% * 100;
 Minibatch[ 301- 400]: loss = 0.193684 * 100, metric = 5.48% * 100;
 Minibatch[ 401- 500]: loss = 0.193352 * 100, metric = 5.54% * 100;
 Minibatch[ 501- 600]: loss = 0.175544 * 100, metric = 4.98% * 100;
 Minibatch[ 601- 700]: loss = 0.197112 * 100, metric = 5.65% * 100;
 Minibatch[ 701- 800]: loss = 0.187635 * 100, metric = 5.37% * 100;
 Minibatch[ 801- 900]: loss = 0.201160 * 100, metric = 5.76% * 100;
 Minibatch[ 901-1000]: loss = 0.182693 * 100, metric = 5.23% * 100;
 Minibatch[1001-1100]: loss = 0.196285 * 100, metric = 5.45% * 100;
 Minibatch[1101-1200]: loss = 0.200625 * 100, metric = 5.73% * 100;
 Minibatch[1201-1300]: loss = 0.192876 * 100, metric = 5.44% * 100;
 Minibatch[1301-1400]: loss = 0.193891 * 100, metric = 5.46% * 100;
 Minibatch[1401-1500]: loss = 0.193965 * 100, metric = 5.43% * 100;
 Minibatch[1501-1600]: loss = 0.202646 * 100, metric = 5.95% * 100;
 Minibatch[1601-1700]: loss = 0.196511 * 100, metric = 5.63% * 100;
 Minibatch[1701-1800]: loss = 0.197091 * 100, metric = 5.58% * 100;
 Minibatch[1801-1900]: loss = 0.192084 * 100, metric = 5.49% * 100;
 Minibatch[1901-2000]: loss = 0.204673 * 100, metric = 5.94% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.194271 * 2000, metric = 5.53% * 2000 859.829s (  2.3 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.55% * 2000;
 Minibatch[   1- 100]: loss = 0.189513 * 100, metric = 5.40% * 100;
 Minibatch[ 101- 200]: loss = 0.205313 * 100, metric = 6.07% * 100;
 Minibatch[ 201- 300]: loss = 0.195196 * 100, metric = 5.51% * 100;
 Minibatch[ 301- 400]: loss = 0.192914 * 100, metric = 5.56% * 100;
 Minibatch[ 401- 500]: loss = 0.194244 * 100, metric = 5.49% * 100;
 Minibatch[ 501- 600]: loss = 0.188679 * 100, metric = 5.23% * 100;
 Minibatch[ 601- 700]: loss = 0.202886 * 100, metric = 5.88% * 100;
 Minibatch[ 701- 800]: loss = 0.200724 * 100, metric = 5.77% * 100;
 Minibatch[ 801- 900]: loss = 0.198334 * 100, metric = 5.52% * 100;
 Minibatch[ 901-1000]: loss = 0.188700 * 100, metric = 5.49% * 100;
 Minibatch[1001-1100]: loss = 0.187986 * 100, metric = 5.34% * 100;
 Minibatch[1101-1200]: loss = 0.194028 * 100, metric = 5.55% * 100;
 Minibatch[1201-1300]: loss = 0.190062 * 100, metric = 5.36% * 100;
 Minibatch[1301-1400]: loss = 0.203040 * 100, metric = 5.78% * 100;
 Minibatch[1401-1500]: loss = 0.199994 * 100, metric = 5.71% * 100;
 Minibatch[1501-1600]: loss = 0.195378 * 100, metric = 5.77% * 100;
 Minibatch[1601-1700]: loss = 0.196227 * 100, metric = 5.61% * 100;
 Minibatch[1701-1800]: loss = 0.193099 * 100, metric = 5.60% * 100;
 Minibatch[1801-1900]: loss = 0.201118 * 100, metric = 5.95% * 100;
 Minibatch[1901-2000]: loss = 0.194348 * 100, metric = 5.63% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.195589 * 2000, metric = 5.61% * 2000 858.818s (  2.3 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 13.91% * 2000;
 Minibatch[   1- 100]: loss = 0.190916 * 100, metric = 5.48% * 100;
 Minibatch[ 101- 200]: loss = 0.200830 * 100, metric = 6.04% * 100;
 Minibatch[ 201- 300]: loss = 0.204923 * 100, metric = 5.96% * 100;
 Minibatch[ 301- 400]: loss = 0.206451 * 100, metric = 5.88% * 100;
 Minibatch[ 401- 500]: loss = 0.196783 * 100, metric = 5.78% * 100;
 Minibatch[ 501- 600]: loss = 0.198894 * 100, metric = 5.71% * 100;
 Minibatch[ 601- 700]: loss = 0.191500 * 100, metric = 5.47% * 100;
 Minibatch[ 701- 800]: loss = 0.193044 * 100, metric = 5.67% * 100;
 Minibatch[ 801- 900]: loss = 0.199230 * 100, metric = 5.80% * 100;
 Minibatch[ 901-1000]: loss = 0.185572 * 100, metric = 5.34% * 100;
 Minibatch[1001-1100]: loss = 0.185776 * 100, metric = 5.32% * 100;
 Minibatch[1101-1200]: loss = 0.194109 * 100, metric = 5.57% * 100;
 Minibatch[1201-1300]: loss = 0.198373 * 100, metric = 5.80% * 100;
 Minibatch[1301-1400]: loss = 0.191211 * 100, metric = 5.33% * 100;
 Minibatch[1401-1500]: loss = 0.187894 * 100, metric = 5.49% * 100;
 Minibatch[1501-1600]: loss = 0.195659 * 100, metric = 5.55% * 100;
 Minibatch[1601-1700]: loss = 0.187579 * 100, metric = 5.36% * 100;
 Minibatch[1701-1800]: loss = 0.197947 * 100, metric = 5.73% * 100;
 Minibatch[1801-1900]: loss = 0.182569 * 100, metric = 5.21% * 100;
 Minibatch[1901-2000]: loss = 0.195653 * 100, metric = 5.74% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.194246 * 2000, metric = 5.61% * 2000 860.529s (  2.3 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 14.78% * 2000;
 Minibatch[   1- 100]: loss = 0.202212 * 100, metric = 5.76% * 100;
 Minibatch[ 101- 200]: loss = 0.193572 * 100, metric = 5.63% * 100;
 Minibatch[ 201- 300]: loss = 0.193069 * 100, metric = 5.71% * 100;
 Minibatch[ 301- 400]: loss = 0.195145 * 100, metric = 5.69% * 100;
 Minibatch[ 401- 500]: loss = 0.189866 * 100, metric = 5.29% * 100;
 Minibatch[ 501- 600]: loss = 0.190433 * 100, metric = 5.46% * 100;
 Minibatch[ 601- 700]: loss = 0.197155 * 100, metric = 5.69% * 100;
 Minibatch[ 701- 800]: loss = 0.193358 * 100, metric = 5.72% * 100;
 Minibatch[ 801- 900]: loss = 0.186197 * 100, metric = 5.18% * 100;
 Minibatch[ 901-1000]: loss = 0.187725 * 100, metric = 5.52% * 100;
 Minibatch[1001-1100]: loss = 0.190778 * 100, metric = 5.62% * 100;
 Minibatch[1101-1200]: loss = 0.183635 * 100, metric = 5.40% * 100;
 Minibatch[1201-1300]: loss = 0.195235 * 100, metric = 5.46% * 100;
 Minibatch[1301-1400]: loss = 0.182992 * 100, metric = 5.38% * 100;
 Minibatch[1401-1500]: loss = 0.198343 * 100, metric = 5.49% * 100;
 Minibatch[1501-1600]: loss = 0.195520 * 100, metric = 5.56% * 100;
 Minibatch[1601-1700]: loss = 0.192726 * 100, metric = 5.52% * 100;
 Minibatch[1701-1800]: loss = 0.186628 * 100, metric = 5.35% * 100;
 Minibatch[1801-1900]: loss = 0.191866 * 100, metric = 5.59% * 100;
 Minibatch[1901-2000]: loss = 0.197992 * 100, metric = 5.64% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.192222 * 2000, metric = 5.53% * 2000 850.361s (  2.4 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.80% * 2000;
 Minibatch[   1- 100]: loss = 0.183800 * 100, metric = 5.40% * 100;
 Minibatch[ 101- 200]: loss = 0.188920 * 100, metric = 5.40% * 100;
 Minibatch[ 201- 300]: loss = 0.180544 * 100, metric = 5.24% * 100;
 Minibatch[ 301- 400]: loss = 0.191174 * 100, metric = 5.54% * 100;
 Minibatch[ 401- 500]: loss = 0.181916 * 100, metric = 5.11% * 100;
 Minibatch[ 501- 600]: loss = 0.188342 * 100, metric = 5.42% * 100;
 Minibatch[ 601- 700]: loss = 0.191831 * 100, metric = 5.72% * 100;
 Minibatch[ 701- 800]: loss = 0.184932 * 100, metric = 5.28% * 100;
 Minibatch[ 801- 900]: loss = 0.176254 * 100, metric = 4.91% * 100;
 Minibatch[ 901-1000]: loss = 0.188465 * 100, metric = 5.54% * 100;
 Minibatch[1001-1100]: loss = 0.191914 * 100, metric = 5.50% * 100;
 Minibatch[1101-1200]: loss = 0.190850 * 100, metric = 5.65% * 100;
 Minibatch[1201-1300]: loss = 0.190607 * 100, metric = 5.47% * 100;
 Minibatch[1301-1400]: loss = 0.185092 * 100, metric = 5.37% * 100;
 Minibatch[1401-1500]: loss = 0.193207 * 100, metric = 5.71% * 100;
 Minibatch[1501-1600]: loss = 0.189516 * 100, metric = 5.45% * 100;
 Minibatch[1601-1700]: loss = 0.194538 * 100, metric = 5.67% * 100;
 Minibatch[1701-1800]: loss = 0.187513 * 100, metric = 5.45% * 100;
 Minibatch[1801-1900]: loss = 0.185985 * 100, metric = 5.41% * 100;
 Minibatch[1901-2000]: loss = 0.182515 * 100, metric = 5.08% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.187396 * 2000, metric = 5.42% * 2000 862.624s (  2.3 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.82% * 2000;
 Minibatch[   1- 100]: loss = 0.176390 * 100, metric = 5.09% * 100;
 Minibatch[ 101- 200]: loss = 0.183957 * 100, metric = 5.18% * 100;
 Minibatch[ 201- 300]: loss = 0.181806 * 100, metric = 5.23% * 100;
 Minibatch[ 301- 400]: loss = 0.177335 * 100, metric = 5.03% * 100;
 Minibatch[ 401- 500]: loss = 0.183353 * 100, metric = 5.21% * 100;
 Minibatch[ 501- 600]: loss = 0.171134 * 100, metric = 4.81% * 100;
 Minibatch[ 601- 700]: loss = 0.184755 * 100, metric = 5.36% * 100;
 Minibatch[ 701- 800]: loss = 0.177275 * 100, metric = 5.18% * 100;
 Minibatch[ 801- 900]: loss = 0.186159 * 100, metric = 5.24% * 100;
 Minibatch[ 901-1000]: loss = 0.181078 * 100, metric = 5.17% * 100;
 Minibatch[1001-1100]: loss = 0.191044 * 100, metric = 5.37% * 100;
 Minibatch[1101-1200]: loss = 0.182121 * 100, metric = 5.16% * 100;
 Minibatch[1201-1300]: loss = 0.188081 * 100, metric = 5.53% * 100;
 Minibatch[1301-1400]: loss = 0.188346 * 100, metric = 5.54% * 100;
 Minibatch[1401-1500]: loss = 0.178775 * 100, metric = 5.13% * 100;
 Minibatch[1501-1600]: loss = 0.189716 * 100, metric = 5.51% * 100;
 Minibatch[1601-1700]: loss = 0.185323 * 100, metric = 5.28% * 100;
 Minibatch[1701-1800]: loss = 0.183386 * 100, metric = 5.33% * 100;
 Minibatch[1801-1900]: loss = 0.189982 * 100, metric = 5.47% * 100;
 Minibatch[1901-2000]: loss = 0.179390 * 100, metric = 5.09% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.182970 * 2000, metric = 5.25% * 2000 855.816s (  2.3 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 14.78% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
