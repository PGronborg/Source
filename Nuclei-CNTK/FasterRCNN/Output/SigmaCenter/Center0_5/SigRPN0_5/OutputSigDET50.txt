Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.309770 * 100, metric = 23.66% * 100;
 Minibatch[ 101- 200]: loss = 1.153879 * 100, metric = 22.70% * 100;
 Minibatch[ 201- 300]: loss = 1.032973 * 100, metric = 20.93% * 100;
 Minibatch[ 301- 400]: loss = 1.074326 * 100, metric = 21.37% * 100;
 Minibatch[ 401- 500]: loss = 0.997030 * 100, metric = 19.89% * 100;
 Minibatch[ 501- 600]: loss = 0.981130 * 100, metric = 19.21% * 100;
 Minibatch[ 601- 700]: loss = 0.960303 * 100, metric = 18.38% * 100;
 Minibatch[ 701- 800]: loss = 0.913948 * 100, metric = 17.11% * 100;
 Minibatch[ 801- 900]: loss = 0.940759 * 100, metric = 17.68% * 100;
 Minibatch[ 901-1000]: loss = 0.951237 * 100, metric = 17.92% * 100;
 Minibatch[1001-1100]: loss = 0.930472 * 100, metric = 17.40% * 100;
 Minibatch[1101-1200]: loss = 0.910106 * 100, metric = 16.74% * 100;
 Minibatch[1201-1300]: loss = 0.916058 * 100, metric = 17.14% * 100;
 Minibatch[1301-1400]: loss = 0.877415 * 100, metric = 16.15% * 100;
 Minibatch[1401-1500]: loss = 0.906404 * 100, metric = 16.73% * 100;
 Minibatch[1501-1600]: loss = 0.870988 * 100, metric = 16.04% * 100;
 Minibatch[1601-1700]: loss = 0.869497 * 100, metric = 16.09% * 100;
 Minibatch[1701-1800]: loss = 0.877190 * 100, metric = 16.13% * 100;
 Minibatch[1801-1900]: loss = 0.880563 * 100, metric = 16.21% * 100;
 Minibatch[1901-2000]: loss = 0.867565 * 100, metric = 15.46% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.961081 * 2000, metric = 18.15% * 2000 1059.903s (  1.9 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 23.33% * 2000;
0.8583859838619828
 Minibatch[   1- 100]: loss = 0.847197 * 100, metric = 15.26% * 100;
 Minibatch[ 101- 200]: loss = 0.861541 * 100, metric = 16.16% * 100;
 Minibatch[ 201- 300]: loss = 0.846678 * 100, metric = 15.01% * 100;
 Minibatch[ 301- 400]: loss = 0.857491 * 100, metric = 15.46% * 100;
 Minibatch[ 401- 500]: loss = 0.843070 * 100, metric = 14.97% * 100;
 Minibatch[ 501- 600]: loss = 0.860841 * 100, metric = 15.05% * 100;
 Minibatch[ 601- 700]: loss = 0.822684 * 100, metric = 15.08% * 100;
 Minibatch[ 701- 800]: loss = 0.840012 * 100, metric = 15.24% * 100;
 Minibatch[ 801- 900]: loss = 0.827622 * 100, metric = 14.96% * 100;
 Minibatch[ 901-1000]: loss = 0.811463 * 100, metric = 14.36% * 100;
 Minibatch[1001-1100]: loss = 0.829799 * 100, metric = 14.94% * 100;
 Minibatch[1101-1200]: loss = 0.827885 * 100, metric = 14.83% * 100;
 Minibatch[1201-1300]: loss = 0.820635 * 100, metric = 14.86% * 100;
 Minibatch[1301-1400]: loss = 0.836707 * 100, metric = 14.82% * 100;
 Minibatch[1401-1500]: loss = 0.807698 * 100, metric = 14.15% * 100;
 Minibatch[1501-1600]: loss = 0.801251 * 100, metric = 13.96% * 100;
 Minibatch[1601-1700]: loss = 0.812260 * 100, metric = 14.31% * 100;
 Minibatch[1701-1800]: loss = 0.821667 * 100, metric = 14.85% * 100;
 Minibatch[1801-1900]: loss = 0.819258 * 100, metric = 14.37% * 100;
 Minibatch[1901-2000]: loss = 0.789652 * 100, metric = 14.10% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.829271 * 2000, metric = 14.84% * 2000 958.238s (  2.1 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 19.20% * 2000;
0.7758418205976486
 Minibatch[   1- 100]: loss = 0.804912 * 100, metric = 14.03% * 100;
 Minibatch[ 101- 200]: loss = 0.804453 * 100, metric = 14.23% * 100;
 Minibatch[ 201- 300]: loss = 0.798241 * 100, metric = 14.01% * 100;
 Minibatch[ 301- 400]: loss = 0.809038 * 100, metric = 14.56% * 100;
 Minibatch[ 401- 500]: loss = 0.822425 * 100, metric = 14.88% * 100;
 Minibatch[ 501- 600]: loss = 0.817366 * 100, metric = 14.45% * 100;
 Minibatch[ 601- 700]: loss = 0.822110 * 100, metric = 14.45% * 100;
 Minibatch[ 701- 800]: loss = 0.786754 * 100, metric = 13.39% * 100;
 Minibatch[ 801- 900]: loss = 0.808745 * 100, metric = 14.07% * 100;
 Minibatch[ 901-1000]: loss = 0.778399 * 100, metric = 14.26% * 100;
 Minibatch[1001-1100]: loss = 0.795795 * 100, metric = 13.95% * 100;
 Minibatch[1101-1200]: loss = 0.773220 * 100, metric = 13.31% * 100;
 Minibatch[1201-1300]: loss = 0.772791 * 100, metric = 13.39% * 100;
 Minibatch[1301-1400]: loss = 0.791984 * 100, metric = 13.79% * 100;
 Minibatch[1401-1500]: loss = 0.783040 * 100, metric = 13.63% * 100;
 Minibatch[1501-1600]: loss = 0.777456 * 100, metric = 13.23% * 100;
 Minibatch[1601-1700]: loss = 0.768853 * 100, metric = 13.06% * 100;
 Minibatch[1701-1800]: loss = 0.784729 * 100, metric = 13.50% * 100;
 Minibatch[1801-1900]: loss = 0.775868 * 100, metric = 13.32% * 100;
 Minibatch[1901-2000]: loss = 0.778591 * 100, metric = 13.39% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.792738 * 2000, metric = 13.85% * 2000 997.835s (  2.0 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 19.46% * 2000;
 Minibatch[   1- 100]: loss = 0.794530 * 100, metric = 13.37% * 100;
 Minibatch[ 101- 200]: loss = 0.770006 * 100, metric = 13.13% * 100;
 Minibatch[ 201- 300]: loss = 0.781594 * 100, metric = 13.64% * 100;
 Minibatch[ 301- 400]: loss = 0.741195 * 100, metric = 12.66% * 100;
 Minibatch[ 401- 500]: loss = 0.777918 * 100, metric = 13.29% * 100;
 Minibatch[ 501- 600]: loss = 0.760676 * 100, metric = 12.83% * 100;
 Minibatch[ 601- 700]: loss = 0.764651 * 100, metric = 13.16% * 100;
 Minibatch[ 701- 800]: loss = 0.777834 * 100, metric = 13.56% * 100;
 Minibatch[ 801- 900]: loss = 0.759733 * 100, metric = 12.93% * 100;
 Minibatch[ 901-1000]: loss = 0.772050 * 100, metric = 13.23% * 100;
 Minibatch[1001-1100]: loss = 0.785203 * 100, metric = 13.75% * 100;
 Minibatch[1101-1200]: loss = 0.759932 * 100, metric = 12.97% * 100;
 Minibatch[1201-1300]: loss = 0.748868 * 100, metric = 12.78% * 100;
 Minibatch[1301-1400]: loss = 0.774247 * 100, metric = 13.12% * 100;
 Minibatch[1401-1500]: loss = 0.778036 * 100, metric = 13.46% * 100;
 Minibatch[1501-1600]: loss = 0.733119 * 100, metric = 12.42% * 100;
 Minibatch[1601-1700]: loss = 0.766349 * 100, metric = 13.21% * 100;
 Minibatch[1701-1800]: loss = 0.771466 * 100, metric = 13.29% * 100;
 Minibatch[1801-1900]: loss = 0.752572 * 100, metric = 13.06% * 100;
 Minibatch[1901-2000]: loss = 0.752307 * 100, metric = 12.84% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.766114 * 2000, metric = 13.14% * 2000 992.350s (  2.0 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 20.31% * 2000;
 Minibatch[   1- 100]: loss = 0.777254 * 100, metric = 13.16% * 100;
 Minibatch[ 101- 200]: loss = 0.752637 * 100, metric = 12.84% * 100;
 Minibatch[ 201- 300]: loss = 0.741559 * 100, metric = 12.61% * 100;
 Minibatch[ 301- 400]: loss = 0.783478 * 100, metric = 13.68% * 100;
 Minibatch[ 401- 500]: loss = 0.732863 * 100, metric = 12.21% * 100;
 Minibatch[ 501- 600]: loss = 0.734305 * 100, metric = 12.22% * 100;
 Minibatch[ 601- 700]: loss = 0.751409 * 100, metric = 12.55% * 100;
 Minibatch[ 701- 800]: loss = 0.758669 * 100, metric = 12.94% * 100;
 Minibatch[ 801- 900]: loss = 0.739694 * 100, metric = 12.36% * 100;
 Minibatch[ 901-1000]: loss = 0.735806 * 100, metric = 12.57% * 100;
 Minibatch[1001-1100]: loss = 0.747183 * 100, metric = 12.74% * 100;
 Minibatch[1101-1200]: loss = 0.733107 * 100, metric = 12.24% * 100;
 Minibatch[1201-1300]: loss = 0.736595 * 100, metric = 12.40% * 100;
 Minibatch[1301-1400]: loss = 0.768472 * 100, metric = 13.00% * 100;
 Minibatch[1401-1500]: loss = 0.747047 * 100, metric = 12.83% * 100;
 Minibatch[1501-1600]: loss = 0.748655 * 100, metric = 12.79% * 100;
 Minibatch[1601-1700]: loss = 0.768801 * 100, metric = 13.37% * 100;
 Minibatch[1701-1800]: loss = 0.767993 * 100, metric = 13.13% * 100;
 Minibatch[1801-1900]: loss = 0.762074 * 100, metric = 13.09% * 100;
 Minibatch[1901-2000]: loss = 0.733427 * 100, metric = 12.48% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.751052 * 2000, metric = 12.76% * 2000 981.020s (  2.0 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.39% * 2000;
 Minibatch[   1- 100]: loss = 0.735661 * 100, metric = 12.25% * 100;
 Minibatch[ 101- 200]: loss = 0.731381 * 100, metric = 12.51% * 100;
 Minibatch[ 201- 300]: loss = 0.744155 * 100, metric = 12.58% * 100;
 Minibatch[ 301- 400]: loss = 0.741754 * 100, metric = 12.56% * 100;
 Minibatch[ 401- 500]: loss = 0.711156 * 100, metric = 12.04% * 100;
 Minibatch[ 501- 600]: loss = 0.730360 * 100, metric = 12.26% * 100;
 Minibatch[ 601- 700]: loss = 0.730426 * 100, metric = 12.30% * 100;
 Minibatch[ 701- 800]: loss = 0.739280 * 100, metric = 12.73% * 100;
 Minibatch[ 801- 900]: loss = 0.738288 * 100, metric = 12.62% * 100;
 Minibatch[ 901-1000]: loss = 0.718246 * 100, metric = 12.23% * 100;
 Minibatch[1001-1100]: loss = 0.731907 * 100, metric = 11.97% * 100;
 Minibatch[1101-1200]: loss = 0.737618 * 100, metric = 12.13% * 100;
 Minibatch[1201-1300]: loss = 0.754567 * 100, metric = 12.96% * 100;
 Minibatch[1301-1400]: loss = 0.723282 * 100, metric = 12.25% * 100;
 Minibatch[1401-1500]: loss = 0.730034 * 100, metric = 12.38% * 100;
 Minibatch[1501-1600]: loss = 0.713586 * 100, metric = 11.69% * 100;
 Minibatch[1601-1700]: loss = 0.716666 * 100, metric = 11.73% * 100;
 Minibatch[1701-1800]: loss = 0.716646 * 100, metric = 11.92% * 100;
 Minibatch[1801-1900]: loss = 0.741031 * 100, metric = 12.34% * 100;
 Minibatch[1901-2000]: loss = 0.724612 * 100, metric = 12.25% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.730533 * 2000, metric = 12.28% * 2000 1007.642s (  2.0 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 21.99% * 2000;
 Minibatch[   1- 100]: loss = 0.730346 * 100, metric = 12.25% * 100;
 Minibatch[ 101- 200]: loss = 0.739633 * 100, metric = 11.99% * 100;
 Minibatch[ 201- 300]: loss = 0.733945 * 100, metric = 12.52% * 100;
 Minibatch[ 301- 400]: loss = 0.714254 * 100, metric = 11.68% * 100;
 Minibatch[ 401- 500]: loss = 0.728708 * 100, metric = 12.08% * 100;
 Minibatch[ 501- 600]: loss = 0.705306 * 100, metric = 11.32% * 100;
 Minibatch[ 601- 700]: loss = 0.726351 * 100, metric = 11.98% * 100;
 Minibatch[ 701- 800]: loss = 0.736174 * 100, metric = 12.03% * 100;
 Minibatch[ 801- 900]: loss = 0.725842 * 100, metric = 12.20% * 100;
 Minibatch[ 901-1000]: loss = 0.726631 * 100, metric = 11.88% * 100;
 Minibatch[1001-1100]: loss = 0.733792 * 100, metric = 12.36% * 100;
 Minibatch[1101-1200]: loss = 0.710197 * 100, metric = 11.74% * 100;
 Minibatch[1201-1300]: loss = 0.731898 * 100, metric = 12.37% * 100;
 Minibatch[1301-1400]: loss = 0.716981 * 100, metric = 12.11% * 100;
 Minibatch[1401-1500]: loss = 0.707433 * 100, metric = 11.84% * 100;
 Minibatch[1501-1600]: loss = 0.725277 * 100, metric = 11.90% * 100;
 Minibatch[1601-1700]: loss = 0.729310 * 100, metric = 12.56% * 100;
 Minibatch[1701-1800]: loss = 0.715739 * 100, metric = 11.87% * 100;
 Minibatch[1801-1900]: loss = 0.720127 * 100, metric = 12.12% * 100;
 Minibatch[1901-2000]: loss = 0.722697 * 100, metric = 12.14% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.724032 * 2000, metric = 12.05% * 2000 975.084s (  2.1 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 19.54% * 2000;
0.772379900880158
 Minibatch[   1- 100]: loss = 0.726378 * 100, metric = 12.19% * 100;
 Minibatch[ 101- 200]: loss = 0.719074 * 100, metric = 12.21% * 100;
 Minibatch[ 201- 300]: loss = 0.700715 * 100, metric = 11.72% * 100;
 Minibatch[ 301- 400]: loss = 0.700464 * 100, metric = 11.78% * 100;
 Minibatch[ 401- 500]: loss = 0.729558 * 100, metric = 12.39% * 100;
 Minibatch[ 501- 600]: loss = 0.741295 * 100, metric = 12.71% * 100;
 Minibatch[ 601- 700]: loss = 0.701952 * 100, metric = 11.80% * 100;
 Minibatch[ 701- 800]: loss = 0.722297 * 100, metric = 11.91% * 100;
 Minibatch[ 801- 900]: loss = 0.695803 * 100, metric = 11.23% * 100;
 Minibatch[ 901-1000]: loss = 0.692917 * 100, metric = 11.37% * 100;
 Minibatch[1001-1100]: loss = 0.691895 * 100, metric = 11.26% * 100;
 Minibatch[1101-1200]: loss = 0.696888 * 100, metric = 11.53% * 100;
 Minibatch[1201-1300]: loss = 0.707936 * 100, metric = 12.04% * 100;
 Minibatch[1301-1400]: loss = 0.719319 * 100, metric = 12.45% * 100;
 Minibatch[1401-1500]: loss = 0.713533 * 100, metric = 12.02% * 100;
 Minibatch[1501-1600]: loss = 0.714954 * 100, metric = 12.20% * 100;
 Minibatch[1601-1700]: loss = 0.700872 * 100, metric = 11.67% * 100;
 Minibatch[1701-1800]: loss = 0.702948 * 100, metric = 11.33% * 100;
 Minibatch[1801-1900]: loss = 0.705850 * 100, metric = 11.56% * 100;
 Minibatch[1901-2000]: loss = 0.698955 * 100, metric = 11.42% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.709180 * 2000, metric = 11.84% * 2000 987.073s (  2.0 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 18.30% * 2000;
0.7417018634751439
 Minibatch[   1- 100]: loss = 0.671346 * 100, metric = 10.83% * 100;
 Minibatch[ 101- 200]: loss = 0.708608 * 100, metric = 11.85% * 100;
 Minibatch[ 201- 300]: loss = 0.693091 * 100, metric = 11.41% * 100;
 Minibatch[ 301- 400]: loss = 0.706824 * 100, metric = 11.73% * 100;
 Minibatch[ 401- 500]: loss = 0.698973 * 100, metric = 11.36% * 100;
 Minibatch[ 501- 600]: loss = 0.685381 * 100, metric = 11.21% * 100;
 Minibatch[ 601- 700]: loss = 0.683654 * 100, metric = 11.28% * 100;
 Minibatch[ 701- 800]: loss = 0.671170 * 100, metric = 10.93% * 100;
 Minibatch[ 801- 900]: loss = 0.679238 * 100, metric = 11.16% * 100;
 Minibatch[ 901-1000]: loss = 0.687458 * 100, metric = 11.42% * 100;
 Minibatch[1001-1100]: loss = 0.672482 * 100, metric = 10.71% * 100;
 Minibatch[1101-1200]: loss = 0.686409 * 100, metric = 11.30% * 100;
 Minibatch[1201-1300]: loss = 0.690245 * 100, metric = 11.45% * 100;
 Minibatch[1301-1400]: loss = 0.672441 * 100, metric = 10.77% * 100;
 Minibatch[1401-1500]: loss = 0.692640 * 100, metric = 11.63% * 100;
 Minibatch[1501-1600]: loss = 0.688195 * 100, metric = 11.30% * 100;
 Minibatch[1601-1700]: loss = 0.691844 * 100, metric = 11.25% * 100;
 Minibatch[1701-1800]: loss = 0.668971 * 100, metric = 10.59% * 100;
 Minibatch[1801-1900]: loss = 0.672836 * 100, metric = 11.03% * 100;
 Minibatch[1901-2000]: loss = 0.688461 * 100, metric = 11.30% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.685513 * 2000, metric = 11.23% * 2000 984.564s (  2.0 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 17.23% * 2000;
0.7275589893907308
 Minibatch[   1- 100]: loss = 0.693911 * 100, metric = 11.57% * 100;
 Minibatch[ 101- 200]: loss = 0.662113 * 100, metric = 10.64% * 100;
 Minibatch[ 201- 300]: loss = 0.676153 * 100, metric = 10.64% * 100;
 Minibatch[ 301- 400]: loss = 0.676279 * 100, metric = 11.06% * 100;
 Minibatch[ 401- 500]: loss = 0.682772 * 100, metric = 11.22% * 100;
 Minibatch[ 501- 600]: loss = 0.657264 * 100, metric = 10.71% * 100;
 Minibatch[ 601- 700]: loss = 0.656281 * 100, metric = 10.48% * 100;
 Minibatch[ 701- 800]: loss = 0.651934 * 100, metric = 10.03% * 100;
 Minibatch[ 801- 900]: loss = 0.679342 * 100, metric = 10.82% * 100;
 Minibatch[ 901-1000]: loss = 0.674640 * 100, metric = 10.88% * 100;
 Minibatch[1001-1100]: loss = 0.667249 * 100, metric = 10.95% * 100;
 Minibatch[1101-1200]: loss = 0.676926 * 100, metric = 10.95% * 100;
 Minibatch[1201-1300]: loss = 0.672573 * 100, metric = 10.93% * 100;
 Minibatch[1301-1400]: loss = 0.668756 * 100, metric = 11.08% * 100;
 Minibatch[1401-1500]: loss = 0.650586 * 100, metric = 10.23% * 100;
 Minibatch[1501-1600]: loss = 0.665776 * 100, metric = 10.88% * 100;
 Minibatch[1601-1700]: loss = 0.668519 * 100, metric = 10.69% * 100;
 Minibatch[1701-1800]: loss = 0.675236 * 100, metric = 10.90% * 100;
 Minibatch[1801-1900]: loss = 0.677970 * 100, metric = 11.26% * 100;
 Minibatch[1901-2000]: loss = 0.655685 * 100, metric = 10.70% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.669498 * 2000, metric = 10.83% * 2000 1023.087s (  2.0 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 18.67% * 2000;
 Minibatch[   1- 100]: loss = 0.648707 * 100, metric = 10.28% * 100;
 Minibatch[ 101- 200]: loss = 0.663839 * 100, metric = 10.63% * 100;
 Minibatch[ 201- 300]: loss = 0.667293 * 100, metric = 10.96% * 100;
 Minibatch[ 301- 400]: loss = 0.672336 * 100, metric = 10.93% * 100;
 Minibatch[ 401- 500]: loss = 0.655787 * 100, metric = 10.40% * 100;
 Minibatch[ 501- 600]: loss = 0.671300 * 100, metric = 10.87% * 100;
 Minibatch[ 601- 700]: loss = 0.655806 * 100, metric = 10.32% * 100;
 Minibatch[ 701- 800]: loss = 0.668197 * 100, metric = 10.88% * 100;
 Minibatch[ 801- 900]: loss = 0.658236 * 100, metric = 10.46% * 100;
 Minibatch[ 901-1000]: loss = 0.676172 * 100, metric = 10.92% * 100;
 Minibatch[1001-1100]: loss = 0.668058 * 100, metric = 10.82% * 100;
 Minibatch[1101-1200]: loss = 0.666785 * 100, metric = 10.95% * 100;
 Minibatch[1201-1300]: loss = 0.657221 * 100, metric = 10.71% * 100;
 Minibatch[1301-1400]: loss = 0.641384 * 100, metric = 10.56% * 100;
 Minibatch[1401-1500]: loss = 0.666697 * 100, metric = 11.00% * 100;
 Minibatch[1501-1600]: loss = 0.648260 * 100, metric = 10.72% * 100;
 Minibatch[1601-1700]: loss = 0.646555 * 100, metric = 10.46% * 100;
 Minibatch[1701-1800]: loss = 0.663457 * 100, metric = 10.81% * 100;
 Minibatch[1801-1900]: loss = 0.649088 * 100, metric = 10.40% * 100;
 Minibatch[1901-2000]: loss = 0.646923 * 100, metric = 10.94% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.659605 * 2000, metric = 10.70% * 2000 989.457s (  2.0 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 18.51% * 2000;
 Minibatch[   1- 100]: loss = 0.631402 * 100, metric = 10.35% * 100;
 Minibatch[ 101- 200]: loss = 0.646123 * 100, metric = 10.25% * 100;
 Minibatch[ 201- 300]: loss = 0.644457 * 100, metric = 10.54% * 100;
 Minibatch[ 301- 400]: loss = 0.674854 * 100, metric = 11.34% * 100;
 Minibatch[ 401- 500]: loss = 0.643309 * 100, metric = 10.30% * 100;
 Minibatch[ 501- 600]: loss = 0.624837 * 100, metric = 9.82% * 100;
 Minibatch[ 601- 700]: loss = 0.632208 * 100, metric = 9.87% * 100;
 Minibatch[ 701- 800]: loss = 0.643110 * 100, metric = 10.45% * 100;
 Minibatch[ 801- 900]: loss = 0.647933 * 100, metric = 10.51% * 100;
 Minibatch[ 901-1000]: loss = 0.641139 * 100, metric = 10.62% * 100;
 Minibatch[1001-1100]: loss = 0.657350 * 100, metric = 11.08% * 100;
 Minibatch[1101-1200]: loss = 0.656503 * 100, metric = 10.80% * 100;
 Minibatch[1201-1300]: loss = 0.653665 * 100, metric = 10.97% * 100;
 Minibatch[1301-1400]: loss = 0.637480 * 100, metric = 10.29% * 100;
 Minibatch[1401-1500]: loss = 0.654453 * 100, metric = 10.69% * 100;
 Minibatch[1501-1600]: loss = 0.621205 * 100, metric = 9.96% * 100;
 Minibatch[1601-1700]: loss = 0.646487 * 100, metric = 10.65% * 100;
 Minibatch[1701-1800]: loss = 0.627905 * 100, metric = 10.05% * 100;
 Minibatch[1801-1900]: loss = 0.634240 * 100, metric = 10.38% * 100;
 Minibatch[1901-2000]: loss = 0.645453 * 100, metric = 10.35% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.643206 * 2000, metric = 10.46% * 2000 1010.716s (  2.0 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 20.17% * 2000;
 Minibatch[   1- 100]: loss = 0.639421 * 100, metric = 10.41% * 100;
 Minibatch[ 101- 200]: loss = 0.651090 * 100, metric = 10.86% * 100;
 Minibatch[ 201- 300]: loss = 0.641942 * 100, metric = 10.42% * 100;
 Minibatch[ 301- 400]: loss = 0.654819 * 100, metric = 10.65% * 100;
 Minibatch[ 401- 500]: loss = 0.650577 * 100, metric = 11.01% * 100;
 Minibatch[ 501- 600]: loss = 0.661367 * 100, metric = 10.96% * 100;
 Minibatch[ 601- 700]: loss = 0.619642 * 100, metric = 9.87% * 100;
 Minibatch[ 701- 800]: loss = 0.638276 * 100, metric = 10.20% * 100;
 Minibatch[ 801- 900]: loss = 0.644836 * 100, metric = 10.20% * 100;
 Minibatch[ 901-1000]: loss = 0.656132 * 100, metric = 10.61% * 100;
 Minibatch[1001-1100]: loss = 0.652091 * 100, metric = 10.61% * 100;
 Minibatch[1101-1200]: loss = 0.634767 * 100, metric = 10.20% * 100;
 Minibatch[1201-1300]: loss = 0.644995 * 100, metric = 10.54% * 100;
 Minibatch[1301-1400]: loss = 0.631049 * 100, metric = 10.36% * 100;
 Minibatch[1401-1500]: loss = 0.637358 * 100, metric = 10.15% * 100;
 Minibatch[1501-1600]: loss = 0.626593 * 100, metric = 10.24% * 100;
 Minibatch[1601-1700]: loss = 0.612328 * 100, metric = 9.90% * 100;
 Minibatch[1701-1800]: loss = 0.631993 * 100, metric = 9.95% * 100;
 Minibatch[1801-1900]: loss = 0.619818 * 100, metric = 9.79% * 100;
 Minibatch[1901-2000]: loss = 0.632246 * 100, metric = 10.32% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.639067 * 2000, metric = 10.36% * 2000 1033.876s (  1.9 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 20.45% * 2000;
 Minibatch[   1- 100]: loss = 0.629927 * 100, metric = 9.97% * 100;
 Minibatch[ 101- 200]: loss = 0.619024 * 100, metric = 9.84% * 100;
 Minibatch[ 201- 300]: loss = 0.645544 * 100, metric = 10.67% * 100;
 Minibatch[ 301- 400]: loss = 0.637851 * 100, metric = 10.40% * 100;
 Minibatch[ 401- 500]: loss = 0.631653 * 100, metric = 10.30% * 100;
 Minibatch[ 501- 600]: loss = 0.638195 * 100, metric = 10.26% * 100;
 Minibatch[ 601- 700]: loss = 0.621507 * 100, metric = 9.73% * 100;
 Minibatch[ 701- 800]: loss = 0.638961 * 100, metric = 10.59% * 100;
 Minibatch[ 801- 900]: loss = 0.636986 * 100, metric = 10.50% * 100;
 Minibatch[ 901-1000]: loss = 0.639280 * 100, metric = 10.59% * 100;
 Minibatch[1001-1100]: loss = 0.627471 * 100, metric = 10.30% * 100;
 Minibatch[1101-1200]: loss = 0.624968 * 100, metric = 10.17% * 100;
 Minibatch[1201-1300]: loss = 0.612166 * 100, metric = 9.94% * 100;
 Minibatch[1301-1400]: loss = 0.639669 * 100, metric = 10.93% * 100;
 Minibatch[1401-1500]: loss = 0.638382 * 100, metric = 10.51% * 100;
 Minibatch[1501-1600]: loss = 0.606091 * 100, metric = 10.08% * 100;
 Minibatch[1601-1700]: loss = 0.634813 * 100, metric = 10.39% * 100;
 Minibatch[1701-1800]: loss = 0.626517 * 100, metric = 9.98% * 100;
 Minibatch[1801-1900]: loss = 0.641047 * 100, metric = 10.50% * 100;
 Minibatch[1901-2000]: loss = 0.635242 * 100, metric = 10.10% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.631265 * 2000, metric = 10.29% * 2000 994.745s (  2.0 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 20.11% * 2000;
 Minibatch[   1- 100]: loss = 0.617368 * 100, metric = 9.91% * 100;
 Minibatch[ 101- 200]: loss = 0.632726 * 100, metric = 10.32% * 100;
 Minibatch[ 201- 300]: loss = 0.633596 * 100, metric = 10.33% * 100;
 Minibatch[ 301- 400]: loss = 0.614652 * 100, metric = 10.00% * 100;
 Minibatch[ 401- 500]: loss = 0.620565 * 100, metric = 10.25% * 100;
 Minibatch[ 501- 600]: loss = 0.618249 * 100, metric = 9.84% * 100;
 Minibatch[ 601- 700]: loss = 0.600857 * 100, metric = 9.79% * 100;
 Minibatch[ 701- 800]: loss = 0.631315 * 100, metric = 10.33% * 100;
 Minibatch[ 801- 900]: loss = 0.635600 * 100, metric = 10.85% * 100;
 Minibatch[ 901-1000]: loss = 0.620804 * 100, metric = 10.23% * 100;
 Minibatch[1001-1100]: loss = 0.633035 * 100, metric = 10.37% * 100;
 Minibatch[1101-1200]: loss = 0.614332 * 100, metric = 9.96% * 100;
 Minibatch[1201-1300]: loss = 0.612189 * 100, metric = 9.67% * 100;
 Minibatch[1301-1400]: loss = 0.629635 * 100, metric = 10.37% * 100;
 Minibatch[1401-1500]: loss = 0.589808 * 100, metric = 9.49% * 100;
 Minibatch[1501-1600]: loss = 0.614748 * 100, metric = 9.88% * 100;
 Minibatch[1601-1700]: loss = 0.613520 * 100, metric = 9.73% * 100;
 Minibatch[1701-1800]: loss = 0.596810 * 100, metric = 9.37% * 100;
 Minibatch[1801-1900]: loss = 0.602345 * 100, metric = 9.83% * 100;
 Minibatch[1901-2000]: loss = 0.600659 * 100, metric = 9.81% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.616641 * 2000, metric = 10.02% * 2000 982.308s (  2.0 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 16.88% * 2000;
0.7017610711455345
 Minibatch[   1- 100]: loss = 0.626457 * 100, metric = 10.43% * 100;
 Minibatch[ 101- 200]: loss = 0.619123 * 100, metric = 10.01% * 100;
 Minibatch[ 201- 300]: loss = 0.617810 * 100, metric = 9.96% * 100;
 Minibatch[ 301- 400]: loss = 0.617395 * 100, metric = 10.06% * 100;
 Minibatch[ 401- 500]: loss = 0.587324 * 100, metric = 9.42% * 100;
 Minibatch[ 501- 600]: loss = 0.597240 * 100, metric = 9.49% * 100;
 Minibatch[ 601- 700]: loss = 0.605740 * 100, metric = 9.58% * 100;
 Minibatch[ 701- 800]: loss = 0.598676 * 100, metric = 9.66% * 100;
 Minibatch[ 801- 900]: loss = 0.588277 * 100, metric = 9.48% * 100;
 Minibatch[ 901-1000]: loss = 0.602620 * 100, metric = 9.72% * 100;
 Minibatch[1001-1100]: loss = 0.589362 * 100, metric = 9.39% * 100;
 Minibatch[1101-1200]: loss = 0.600270 * 100, metric = 9.71% * 100;
 Minibatch[1201-1300]: loss = 0.593173 * 100, metric = 9.44% * 100;
 Minibatch[1301-1400]: loss = 0.601663 * 100, metric = 9.88% * 100;
 Minibatch[1401-1500]: loss = 0.591479 * 100, metric = 9.74% * 100;
 Minibatch[1501-1600]: loss = 0.597159 * 100, metric = 9.51% * 100;
 Minibatch[1601-1700]: loss = 0.607791 * 100, metric = 10.02% * 100;
 Minibatch[1701-1800]: loss = 0.627052 * 100, metric = 10.35% * 100;
 Minibatch[1801-1900]: loss = 0.612604 * 100, metric = 10.39% * 100;
 Minibatch[1901-2000]: loss = 0.595793 * 100, metric = 9.75% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.603850 * 2000, metric = 9.80% * 2000 998.971s (  2.0 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 16.59% * 2000;
 Minibatch[   1- 100]: loss = 0.594137 * 100, metric = 9.43% * 100;
 Minibatch[ 101- 200]: loss = 0.608788 * 100, metric = 9.84% * 100;
 Minibatch[ 201- 300]: loss = 0.607379 * 100, metric = 9.97% * 100;
 Minibatch[ 301- 400]: loss = 0.605944 * 100, metric = 9.88% * 100;
 Minibatch[ 401- 500]: loss = 0.608912 * 100, metric = 9.79% * 100;
 Minibatch[ 501- 600]: loss = 0.598083 * 100, metric = 9.56% * 100;
 Minibatch[ 601- 700]: loss = 0.584930 * 100, metric = 9.10% * 100;
 Minibatch[ 701- 800]: loss = 0.595724 * 100, metric = 9.73% * 100;
 Minibatch[ 801- 900]: loss = 0.601740 * 100, metric = 9.81% * 100;
 Minibatch[ 901-1000]: loss = 0.597590 * 100, metric = 9.77% * 100;
 Minibatch[1001-1100]: loss = 0.581793 * 100, metric = 9.36% * 100;
 Minibatch[1101-1200]: loss = 0.612989 * 100, metric = 10.06% * 100;
 Minibatch[1201-1300]: loss = 0.607164 * 100, metric = 9.80% * 100;
 Minibatch[1301-1400]: loss = 0.589773 * 100, metric = 9.50% * 100;
 Minibatch[1401-1500]: loss = 0.595990 * 100, metric = 9.76% * 100;
 Minibatch[1501-1600]: loss = 0.595369 * 100, metric = 9.74% * 100;
 Minibatch[1601-1700]: loss = 0.611210 * 100, metric = 9.96% * 100;
 Minibatch[1701-1800]: loss = 0.588543 * 100, metric = 9.40% * 100;
 Minibatch[1801-1900]: loss = 0.617772 * 100, metric = 10.34% * 100;
 Minibatch[1901-2000]: loss = 0.617437 * 100, metric = 10.34% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.601063 * 2000, metric = 9.76% * 2000 983.138s (  2.0 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 16.88% * 2000;
 Minibatch[   1- 100]: loss = 0.586873 * 100, metric = 9.35% * 100;
 Minibatch[ 101- 200]: loss = 0.621038 * 100, metric = 10.28% * 100;
 Minibatch[ 201- 300]: loss = 0.590675 * 100, metric = 9.65% * 100;
 Minibatch[ 301- 400]: loss = 0.597823 * 100, metric = 9.66% * 100;
 Minibatch[ 401- 500]: loss = 0.579539 * 100, metric = 9.34% * 100;
 Minibatch[ 501- 600]: loss = 0.587432 * 100, metric = 9.71% * 100;
 Minibatch[ 601- 700]: loss = 0.598453 * 100, metric = 9.64% * 100;
 Minibatch[ 701- 800]: loss = 0.581246 * 100, metric = 9.45% * 100;
 Minibatch[ 801- 900]: loss = 0.601749 * 100, metric = 9.80% * 100;
 Minibatch[ 901-1000]: loss = 0.597562 * 100, metric = 9.68% * 100;
 Minibatch[1001-1100]: loss = 0.608431 * 100, metric = 10.14% * 100;
 Minibatch[1101-1200]: loss = 0.602291 * 100, metric = 9.89% * 100;
 Minibatch[1201-1300]: loss = 0.613145 * 100, metric = 10.35% * 100;
 Minibatch[1301-1400]: loss = 0.611628 * 100, metric = 10.21% * 100;
 Minibatch[1401-1500]: loss = 0.585779 * 100, metric = 9.32% * 100;
 Minibatch[1501-1600]: loss = 0.596253 * 100, metric = 9.66% * 100;
 Minibatch[1601-1700]: loss = 0.572669 * 100, metric = 9.06% * 100;
 Minibatch[1701-1800]: loss = 0.588928 * 100, metric = 9.47% * 100;
 Minibatch[1801-1900]: loss = 0.577356 * 100, metric = 9.50% * 100;
 Minibatch[1901-2000]: loss = 0.574718 * 100, metric = 9.13% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.593679 * 2000, metric = 9.66% * 2000 1001.799s (  2.0 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 18.11% * 2000;
 Minibatch[   1- 100]: loss = 0.599943 * 100, metric = 10.00% * 100;
 Minibatch[ 101- 200]: loss = 0.600592 * 100, metric = 9.77% * 100;
 Minibatch[ 201- 300]: loss = 0.573090 * 100, metric = 8.90% * 100;
 Minibatch[ 301- 400]: loss = 0.596327 * 100, metric = 9.73% * 100;
 Minibatch[ 401- 500]: loss = 0.594095 * 100, metric = 9.52% * 100;
 Minibatch[ 501- 600]: loss = 0.582552 * 100, metric = 9.21% * 100;
 Minibatch[ 601- 700]: loss = 0.595047 * 100, metric = 9.77% * 100;
 Minibatch[ 701- 800]: loss = 0.571757 * 100, metric = 9.35% * 100;
 Minibatch[ 801- 900]: loss = 0.610560 * 100, metric = 10.28% * 100;
 Minibatch[ 901-1000]: loss = 0.580603 * 100, metric = 9.29% * 100;
 Minibatch[1001-1100]: loss = 0.597839 * 100, metric = 9.68% * 100;
 Minibatch[1101-1200]: loss = 0.583313 * 100, metric = 9.67% * 100;
 Minibatch[1201-1300]: loss = 0.586926 * 100, metric = 9.41% * 100;
 Minibatch[1301-1400]: loss = 0.579629 * 100, metric = 9.38% * 100;
 Minibatch[1401-1500]: loss = 0.596351 * 100, metric = 9.93% * 100;
 Minibatch[1501-1600]: loss = 0.594746 * 100, metric = 9.87% * 100;
 Minibatch[1601-1700]: loss = 0.566441 * 100, metric = 9.30% * 100;
 Minibatch[1701-1800]: loss = 0.556948 * 100, metric = 8.80% * 100;
 Minibatch[1801-1900]: loss = 0.580706 * 100, metric = 9.39% * 100;
 Minibatch[1901-2000]: loss = 0.566696 * 100, metric = 8.97% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.585708 * 2000, metric = 9.51% * 2000 1001.439s (  2.0 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 17.45% * 2000;
 Minibatch[   1- 100]: loss = 0.567911 * 100, metric = 8.87% * 100;
 Minibatch[ 101- 200]: loss = 0.574084 * 100, metric = 9.17% * 100;
 Minibatch[ 201- 300]: loss = 0.579750 * 100, metric = 9.23% * 100;
 Minibatch[ 301- 400]: loss = 0.592955 * 100, metric = 9.29% * 100;
 Minibatch[ 401- 500]: loss = 0.578073 * 100, metric = 9.33% * 100;
 Minibatch[ 501- 600]: loss = 0.577628 * 100, metric = 9.36% * 100;
 Minibatch[ 601- 700]: loss = 0.583425 * 100, metric = 9.54% * 100;
 Minibatch[ 701- 800]: loss = 0.583080 * 100, metric = 9.37% * 100;
 Minibatch[ 801- 900]: loss = 0.583435 * 100, metric = 9.30% * 100;
 Minibatch[ 901-1000]: loss = 0.591239 * 100, metric = 9.44% * 100;
 Minibatch[1001-1100]: loss = 0.559058 * 100, metric = 8.69% * 100;
 Minibatch[1101-1200]: loss = 0.571407 * 100, metric = 8.99% * 100;
 Minibatch[1201-1300]: loss = 0.573896 * 100, metric = 9.02% * 100;
 Minibatch[1301-1400]: loss = 0.574717 * 100, metric = 9.44% * 100;
 Minibatch[1401-1500]: loss = 0.567338 * 100, metric = 9.41% * 100;
 Minibatch[1501-1600]: loss = 0.588173 * 100, metric = 9.56% * 100;
 Minibatch[1601-1700]: loss = 0.573414 * 100, metric = 9.30% * 100;
 Minibatch[1701-1800]: loss = 0.579464 * 100, metric = 9.50% * 100;
 Minibatch[1801-1900]: loss = 0.565875 * 100, metric = 9.20% * 100;
 Minibatch[1901-2000]: loss = 0.567954 * 100, metric = 9.34% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.576644 * 2000, metric = 9.27% * 2000 989.043s (  2.0 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 17.55% * 2000;
 Minibatch[   1- 100]: loss = 0.579401 * 100, metric = 9.22% * 100;
 Minibatch[ 101- 200]: loss = 0.573918 * 100, metric = 9.30% * 100;
 Minibatch[ 201- 300]: loss = 0.566802 * 100, metric = 9.06% * 100;
 Minibatch[ 301- 400]: loss = 0.582980 * 100, metric = 9.57% * 100;
 Minibatch[ 401- 500]: loss = 0.568438 * 100, metric = 9.41% * 100;
 Minibatch[ 501- 600]: loss = 0.566877 * 100, metric = 9.04% * 100;
 Minibatch[ 601- 700]: loss = 0.567446 * 100, metric = 9.24% * 100;
 Minibatch[ 701- 800]: loss = 0.541297 * 100, metric = 8.56% * 100;
 Minibatch[ 801- 900]: loss = 0.578063 * 100, metric = 9.29% * 100;
 Minibatch[ 901-1000]: loss = 0.552448 * 100, metric = 8.69% * 100;
 Minibatch[1001-1100]: loss = 0.558812 * 100, metric = 8.99% * 100;
 Minibatch[1101-1200]: loss = 0.548692 * 100, metric = 8.60% * 100;
 Minibatch[1201-1300]: loss = 0.562230 * 100, metric = 8.82% * 100;
 Minibatch[1301-1400]: loss = 0.547991 * 100, metric = 8.56% * 100;
 Minibatch[1401-1500]: loss = 0.567823 * 100, metric = 9.02% * 100;
 Minibatch[1501-1600]: loss = 0.570371 * 100, metric = 9.48% * 100;
 Minibatch[1601-1700]: loss = 0.550656 * 100, metric = 8.87% * 100;
 Minibatch[1701-1800]: loss = 0.548704 * 100, metric = 8.76% * 100;
 Minibatch[1801-1900]: loss = 0.577980 * 100, metric = 9.31% * 100;
 Minibatch[1901-2000]: loss = 0.539185 * 100, metric = 8.28% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.562506 * 2000, metric = 9.00% * 2000 962.143s (  2.1 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 16.23% * 2000;
0.683284511320293
 Minibatch[   1- 100]: loss = 0.571003 * 100, metric = 9.41% * 100;
 Minibatch[ 101- 200]: loss = 0.555624 * 100, metric = 8.90% * 100;
 Minibatch[ 201- 300]: loss = 0.566129 * 100, metric = 9.36% * 100;
 Minibatch[ 301- 400]: loss = 0.552998 * 100, metric = 9.04% * 100;
 Minibatch[ 401- 500]: loss = 0.555954 * 100, metric = 8.88% * 100;
 Minibatch[ 501- 600]: loss = 0.563526 * 100, metric = 8.87% * 100;
 Minibatch[ 601- 700]: loss = 0.552358 * 100, metric = 8.55% * 100;
 Minibatch[ 701- 800]: loss = 0.553282 * 100, metric = 8.83% * 100;
 Minibatch[ 801- 900]: loss = 0.563918 * 100, metric = 9.01% * 100;
 Minibatch[ 901-1000]: loss = 0.569016 * 100, metric = 9.15% * 100;
 Minibatch[1001-1100]: loss = 0.541391 * 100, metric = 8.49% * 100;
 Minibatch[1101-1200]: loss = 0.532492 * 100, metric = 8.39% * 100;
 Minibatch[1201-1300]: loss = 0.552465 * 100, metric = 8.91% * 100;
 Minibatch[1301-1400]: loss = 0.557925 * 100, metric = 8.99% * 100;
 Minibatch[1401-1500]: loss = 0.548358 * 100, metric = 8.58% * 100;
 Minibatch[1501-1600]: loss = 0.536746 * 100, metric = 8.33% * 100;
 Minibatch[1601-1700]: loss = 0.540667 * 100, metric = 8.54% * 100;
 Minibatch[1701-1800]: loss = 0.545972 * 100, metric = 8.55% * 100;
 Minibatch[1801-1900]: loss = 0.538192 * 100, metric = 8.45% * 100;
 Minibatch[1901-2000]: loss = 0.547980 * 100, metric = 8.58% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.552300 * 2000, metric = 8.79% * 2000 961.523s (  2.1 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 17.52% * 2000;
 Minibatch[   1- 100]: loss = 0.564435 * 100, metric = 9.04% * 100;
 Minibatch[ 101- 200]: loss = 0.562245 * 100, metric = 9.09% * 100;
 Minibatch[ 201- 300]: loss = 0.552024 * 100, metric = 8.55% * 100;
 Minibatch[ 301- 400]: loss = 0.559553 * 100, metric = 8.85% * 100;
 Minibatch[ 401- 500]: loss = 0.560502 * 100, metric = 9.12% * 100;
 Minibatch[ 501- 600]: loss = 0.550616 * 100, metric = 8.82% * 100;
 Minibatch[ 601- 700]: loss = 0.551316 * 100, metric = 8.72% * 100;
 Minibatch[ 701- 800]: loss = 0.535009 * 100, metric = 8.19% * 100;
 Minibatch[ 801- 900]: loss = 0.518003 * 100, metric = 8.19% * 100;
 Minibatch[ 901-1000]: loss = 0.554051 * 100, metric = 8.65% * 100;
 Minibatch[1001-1100]: loss = 0.540356 * 100, metric = 8.53% * 100;
 Minibatch[1101-1200]: loss = 0.544647 * 100, metric = 8.64% * 100;
 Minibatch[1201-1300]: loss = 0.564484 * 100, metric = 9.24% * 100;
 Minibatch[1301-1400]: loss = 0.556476 * 100, metric = 9.04% * 100;
 Minibatch[1401-1500]: loss = 0.546313 * 100, metric = 8.79% * 100;
 Minibatch[1501-1600]: loss = 0.548174 * 100, metric = 8.73% * 100;
 Minibatch[1601-1700]: loss = 0.546487 * 100, metric = 8.90% * 100;
 Minibatch[1701-1800]: loss = 0.553748 * 100, metric = 8.83% * 100;
 Minibatch[1801-1900]: loss = 0.549021 * 100, metric = 9.12% * 100;
 Minibatch[1901-2000]: loss = 0.549502 * 100, metric = 8.58% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.550348 * 2000, metric = 8.78% * 2000 964.972s (  2.1 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 17.91% * 2000;
 Minibatch[   1- 100]: loss = 0.523793 * 100, metric = 8.51% * 100;
 Minibatch[ 101- 200]: loss = 0.545988 * 100, metric = 9.08% * 100;
 Minibatch[ 201- 300]: loss = 0.535478 * 100, metric = 8.68% * 100;
 Minibatch[ 301- 400]: loss = 0.543203 * 100, metric = 8.58% * 100;
 Minibatch[ 401- 500]: loss = 0.551317 * 100, metric = 8.96% * 100;
 Minibatch[ 501- 600]: loss = 0.529969 * 100, metric = 8.47% * 100;
 Minibatch[ 601- 700]: loss = 0.550568 * 100, metric = 8.80% * 100;
 Minibatch[ 701- 800]: loss = 0.539907 * 100, metric = 8.66% * 100;
 Minibatch[ 801- 900]: loss = 0.553441 * 100, metric = 9.04% * 100;
 Minibatch[ 901-1000]: loss = 0.542469 * 100, metric = 8.67% * 100;
 Minibatch[1001-1100]: loss = 0.538200 * 100, metric = 8.21% * 100;
 Minibatch[1101-1200]: loss = 0.556820 * 100, metric = 8.86% * 100;
 Minibatch[1201-1300]: loss = 0.543152 * 100, metric = 8.64% * 100;
 Minibatch[1301-1400]: loss = 0.539811 * 100, metric = 8.45% * 100;
 Minibatch[1401-1500]: loss = 0.536361 * 100, metric = 8.41% * 100;
 Minibatch[1501-1600]: loss = 0.546710 * 100, metric = 8.78% * 100;
 Minibatch[1601-1700]: loss = 0.524400 * 100, metric = 8.50% * 100;
 Minibatch[1701-1800]: loss = 0.535246 * 100, metric = 8.48% * 100;
 Minibatch[1801-1900]: loss = 0.549476 * 100, metric = 8.92% * 100;
 Minibatch[1901-2000]: loss = 0.543595 * 100, metric = 8.80% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.541495 * 2000, metric = 8.68% * 2000 974.990s (  2.1 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 16.42% * 2000;
 Minibatch[   1- 100]: loss = 0.545897 * 100, metric = 8.74% * 100;
 Minibatch[ 101- 200]: loss = 0.540203 * 100, metric = 8.73% * 100;
 Minibatch[ 201- 300]: loss = 0.540832 * 100, metric = 8.73% * 100;
 Minibatch[ 301- 400]: loss = 0.539360 * 100, metric = 8.66% * 100;
 Minibatch[ 401- 500]: loss = 0.534994 * 100, metric = 8.62% * 100;
 Minibatch[ 501- 600]: loss = 0.543091 * 100, metric = 8.48% * 100;
 Minibatch[ 601- 700]: loss = 0.542108 * 100, metric = 8.70% * 100;
 Minibatch[ 701- 800]: loss = 0.524359 * 100, metric = 8.32% * 100;
 Minibatch[ 801- 900]: loss = 0.532279 * 100, metric = 8.41% * 100;
 Minibatch[ 901-1000]: loss = 0.537985 * 100, metric = 8.53% * 100;
 Minibatch[1001-1100]: loss = 0.542310 * 100, metric = 8.88% * 100;
 Minibatch[1101-1200]: loss = 0.545908 * 100, metric = 8.86% * 100;
 Minibatch[1201-1300]: loss = 0.562233 * 100, metric = 9.20% * 100;
 Minibatch[1301-1400]: loss = 0.535342 * 100, metric = 8.41% * 100;
 Minibatch[1401-1500]: loss = 0.534310 * 100, metric = 8.25% * 100;
 Minibatch[1501-1600]: loss = 0.544544 * 100, metric = 8.98% * 100;
 Minibatch[1601-1700]: loss = 0.532744 * 100, metric = 8.68% * 100;
 Minibatch[1701-1800]: loss = 0.539855 * 100, metric = 8.50% * 100;
 Minibatch[1801-1900]: loss = 0.520065 * 100, metric = 8.08% * 100;
 Minibatch[1901-2000]: loss = 0.508592 * 100, metric = 8.04% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.537351 * 2000, metric = 8.59% * 2000 962.907s (  2.1 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 16.50% * 2000;
 Minibatch[   1- 100]: loss = 0.534166 * 100, metric = 8.66% * 100;
 Minibatch[ 101- 200]: loss = 0.509583 * 100, metric = 7.83% * 100;
 Minibatch[ 201- 300]: loss = 0.532800 * 100, metric = 8.51% * 100;
 Minibatch[ 301- 400]: loss = 0.521954 * 100, metric = 7.99% * 100;
 Minibatch[ 401- 500]: loss = 0.527168 * 100, metric = 8.30% * 100;
 Minibatch[ 501- 600]: loss = 0.528363 * 100, metric = 8.13% * 100;
 Minibatch[ 601- 700]: loss = 0.537149 * 100, metric = 8.77% * 100;
 Minibatch[ 701- 800]: loss = 0.522741 * 100, metric = 8.50% * 100;
 Minibatch[ 801- 900]: loss = 0.510462 * 100, metric = 7.81% * 100;
 Minibatch[ 901-1000]: loss = 0.507507 * 100, metric = 7.82% * 100;
 Minibatch[1001-1100]: loss = 0.536530 * 100, metric = 8.84% * 100;
 Minibatch[1101-1200]: loss = 0.541786 * 100, metric = 8.71% * 100;
 Minibatch[1201-1300]: loss = 0.527558 * 100, metric = 8.33% * 100;
 Minibatch[1301-1400]: loss = 0.512228 * 100, metric = 7.89% * 100;
 Minibatch[1401-1500]: loss = 0.524302 * 100, metric = 8.50% * 100;
 Minibatch[1501-1600]: loss = 0.518612 * 100, metric = 7.85% * 100;
 Minibatch[1601-1700]: loss = 0.545660 * 100, metric = 8.73% * 100;
 Minibatch[1701-1800]: loss = 0.542426 * 100, metric = 8.86% * 100;
 Minibatch[1801-1900]: loss = 0.522838 * 100, metric = 8.28% * 100;
 Minibatch[1901-2000]: loss = 0.532320 * 100, metric = 8.34% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.526808 * 2000, metric = 8.33% * 2000 952.958s (  2.1 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 16.93% * 2000;
 Minibatch[   1- 100]: loss = 0.520433 * 100, metric = 8.10% * 100;
 Minibatch[ 101- 200]: loss = 0.546246 * 100, metric = 8.71% * 100;
 Minibatch[ 201- 300]: loss = 0.530098 * 100, metric = 8.45% * 100;
 Minibatch[ 301- 400]: loss = 0.514039 * 100, metric = 8.09% * 100;
 Minibatch[ 401- 500]: loss = 0.529242 * 100, metric = 8.46% * 100;
 Minibatch[ 501- 600]: loss = 0.521336 * 100, metric = 8.19% * 100;
 Minibatch[ 601- 700]: loss = 0.519105 * 100, metric = 8.21% * 100;
 Minibatch[ 701- 800]: loss = 0.524229 * 100, metric = 8.07% * 100;
 Minibatch[ 801- 900]: loss = 0.534780 * 100, metric = 8.46% * 100;
 Minibatch[ 901-1000]: loss = 0.527664 * 100, metric = 8.64% * 100;
 Minibatch[1001-1100]: loss = 0.513428 * 100, metric = 7.72% * 100;
 Minibatch[1101-1200]: loss = 0.535120 * 100, metric = 8.32% * 100;
 Minibatch[1201-1300]: loss = 0.512834 * 100, metric = 7.91% * 100;
 Minibatch[1301-1400]: loss = 0.536826 * 100, metric = 8.56% * 100;
 Minibatch[1401-1500]: loss = 0.514704 * 100, metric = 7.99% * 100;
 Minibatch[1501-1600]: loss = 0.527560 * 100, metric = 8.38% * 100;
 Minibatch[1601-1700]: loss = 0.500075 * 100, metric = 7.71% * 100;
 Minibatch[1701-1800]: loss = 0.514352 * 100, metric = 7.86% * 100;
 Minibatch[1801-1900]: loss = 0.511499 * 100, metric = 7.97% * 100;
 Minibatch[1901-2000]: loss = 0.521094 * 100, metric = 8.19% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.522733 * 2000, metric = 8.20% * 2000 965.740s (  2.1 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 15.84% * 2000;
0.6758317962735891
 Minibatch[   1- 100]: loss = 0.525909 * 100, metric = 8.58% * 100;
 Minibatch[ 101- 200]: loss = 0.498906 * 100, metric = 7.63% * 100;
 Minibatch[ 201- 300]: loss = 0.512209 * 100, metric = 8.07% * 100;
 Minibatch[ 301- 400]: loss = 0.510859 * 100, metric = 7.89% * 100;
 Minibatch[ 401- 500]: loss = 0.512594 * 100, metric = 7.94% * 100;
 Minibatch[ 501- 600]: loss = 0.533385 * 100, metric = 8.69% * 100;
 Minibatch[ 601- 700]: loss = 0.507469 * 100, metric = 7.71% * 100;
 Minibatch[ 701- 800]: loss = 0.497926 * 100, metric = 7.72% * 100;
 Minibatch[ 801- 900]: loss = 0.516572 * 100, metric = 8.17% * 100;
 Minibatch[ 901-1000]: loss = 0.515830 * 100, metric = 8.18% * 100;
 Minibatch[1001-1100]: loss = 0.507954 * 100, metric = 7.91% * 100;
 Minibatch[1101-1200]: loss = 0.511979 * 100, metric = 7.89% * 100;
 Minibatch[1201-1300]: loss = 0.519952 * 100, metric = 8.27% * 100;
 Minibatch[1301-1400]: loss = 0.504637 * 100, metric = 7.95% * 100;
 Minibatch[1401-1500]: loss = 0.522887 * 100, metric = 8.19% * 100;
 Minibatch[1501-1600]: loss = 0.501434 * 100, metric = 7.66% * 100;
 Minibatch[1601-1700]: loss = 0.518110 * 100, metric = 8.08% * 100;
 Minibatch[1701-1800]: loss = 0.507427 * 100, metric = 7.96% * 100;
 Minibatch[1801-1900]: loss = 0.510458 * 100, metric = 8.30% * 100;
 Minibatch[1901-2000]: loss = 0.513303 * 100, metric = 8.07% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.512490 * 2000, metric = 8.04% * 2000 981.093s (  2.0 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 14.94% * 2000;
 Minibatch[   1- 100]: loss = 0.500273 * 100, metric = 7.76% * 100;
 Minibatch[ 101- 200]: loss = 0.506392 * 100, metric = 7.79% * 100;
 Minibatch[ 201- 300]: loss = 0.511616 * 100, metric = 8.10% * 100;
 Minibatch[ 301- 400]: loss = 0.534273 * 100, metric = 8.60% * 100;
 Minibatch[ 401- 500]: loss = 0.495657 * 100, metric = 7.39% * 100;
 Minibatch[ 501- 600]: loss = 0.513028 * 100, metric = 8.02% * 100;
 Minibatch[ 601- 700]: loss = 0.502119 * 100, metric = 7.83% * 100;
 Minibatch[ 701- 800]: loss = 0.511953 * 100, metric = 8.14% * 100;
 Minibatch[ 801- 900]: loss = 0.505817 * 100, metric = 8.05% * 100;
 Minibatch[ 901-1000]: loss = 0.520321 * 100, metric = 8.31% * 100;
 Minibatch[1001-1100]: loss = 0.506780 * 100, metric = 7.97% * 100;
 Minibatch[1101-1200]: loss = 0.488944 * 100, metric = 7.46% * 100;
 Minibatch[1201-1300]: loss = 0.507736 * 100, metric = 7.76% * 100;
 Minibatch[1301-1400]: loss = 0.491718 * 100, metric = 7.71% * 100;
 Minibatch[1401-1500]: loss = 0.509245 * 100, metric = 7.88% * 100;
 Minibatch[1501-1600]: loss = 0.491501 * 100, metric = 7.45% * 100;
 Minibatch[1601-1700]: loss = 0.518400 * 100, metric = 8.25% * 100;
 Minibatch[1701-1800]: loss = 0.492441 * 100, metric = 7.42% * 100;
 Minibatch[1801-1900]: loss = 0.520661 * 100, metric = 8.18% * 100;
 Minibatch[1901-2000]: loss = 0.506120 * 100, metric = 7.77% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.506750 * 2000, metric = 7.89% * 2000 954.537s (  2.1 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 17.22% * 2000;
 Minibatch[   1- 100]: loss = 0.522156 * 100, metric = 8.04% * 100;
 Minibatch[ 101- 200]: loss = 0.476040 * 100, metric = 7.26% * 100;
 Minibatch[ 201- 300]: loss = 0.495989 * 100, metric = 7.79% * 100;
 Minibatch[ 301- 400]: loss = 0.508361 * 100, metric = 8.04% * 100;
 Minibatch[ 401- 500]: loss = 0.503714 * 100, metric = 7.80% * 100;
 Minibatch[ 501- 600]: loss = 0.483562 * 100, metric = 7.31% * 100;
 Minibatch[ 601- 700]: loss = 0.506032 * 100, metric = 8.01% * 100;
 Minibatch[ 701- 800]: loss = 0.500237 * 100, metric = 7.78% * 100;
 Minibatch[ 801- 900]: loss = 0.507964 * 100, metric = 7.98% * 100;
 Minibatch[ 901-1000]: loss = 0.478655 * 100, metric = 7.28% * 100;
 Minibatch[1001-1100]: loss = 0.497143 * 100, metric = 7.63% * 100;
 Minibatch[1101-1200]: loss = 0.513915 * 100, metric = 7.98% * 100;
 Minibatch[1201-1300]: loss = 0.500983 * 100, metric = 7.87% * 100;
 Minibatch[1301-1400]: loss = 0.506725 * 100, metric = 7.92% * 100;
 Minibatch[1401-1500]: loss = 0.493220 * 100, metric = 7.58% * 100;
 Minibatch[1501-1600]: loss = 0.514387 * 100, metric = 8.10% * 100;
 Minibatch[1601-1700]: loss = 0.505859 * 100, metric = 7.95% * 100;
 Minibatch[1701-1800]: loss = 0.505236 * 100, metric = 7.87% * 100;
 Minibatch[1801-1900]: loss = 0.504915 * 100, metric = 7.88% * 100;
 Minibatch[1901-2000]: loss = 0.512834 * 100, metric = 8.03% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.501896 * 2000, metric = 7.81% * 2000 958.437s (  2.1 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 16.30% * 2000;
 Minibatch[   1- 100]: loss = 0.503649 * 100, metric = 7.57% * 100;
 Minibatch[ 101- 200]: loss = 0.521964 * 100, metric = 8.44% * 100;
 Minibatch[ 201- 300]: loss = 0.502285 * 100, metric = 7.89% * 100;
 Minibatch[ 301- 400]: loss = 0.502171 * 100, metric = 7.72% * 100;
 Minibatch[ 401- 500]: loss = 0.500144 * 100, metric = 7.79% * 100;
 Minibatch[ 501- 600]: loss = 0.495227 * 100, metric = 7.79% * 100;
 Minibatch[ 601- 700]: loss = 0.514719 * 100, metric = 8.19% * 100;
 Minibatch[ 701- 800]: loss = 0.513632 * 100, metric = 8.15% * 100;
 Minibatch[ 801- 900]: loss = 0.504449 * 100, metric = 7.71% * 100;
 Minibatch[ 901-1000]: loss = 0.489901 * 100, metric = 7.71% * 100;
 Minibatch[1001-1100]: loss = 0.494947 * 100, metric = 7.65% * 100;
 Minibatch[1101-1200]: loss = 0.507534 * 100, metric = 8.19% * 100;
 Minibatch[1201-1300]: loss = 0.498136 * 100, metric = 7.82% * 100;
 Minibatch[1301-1400]: loss = 0.502125 * 100, metric = 8.05% * 100;
 Minibatch[1401-1500]: loss = 0.507324 * 100, metric = 7.98% * 100;
 Minibatch[1501-1600]: loss = 0.481949 * 100, metric = 7.41% * 100;
 Minibatch[1601-1700]: loss = 0.503215 * 100, metric = 7.98% * 100;
 Minibatch[1701-1800]: loss = 0.495440 * 100, metric = 7.74% * 100;
 Minibatch[1801-1900]: loss = 0.506924 * 100, metric = 7.98% * 100;
 Minibatch[1901-2000]: loss = 0.499875 * 100, metric = 7.97% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.502280 * 2000, metric = 7.89% * 2000 957.468s (  2.1 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 16.23% * 2000;
 Minibatch[   1- 100]: loss = 0.495272 * 100, metric = 7.71% * 100;
 Minibatch[ 101- 200]: loss = 0.504180 * 100, metric = 7.89% * 100;
 Minibatch[ 201- 300]: loss = 0.510856 * 100, metric = 8.04% * 100;
 Minibatch[ 301- 400]: loss = 0.513623 * 100, metric = 7.89% * 100;
 Minibatch[ 401- 500]: loss = 0.509415 * 100, metric = 8.15% * 100;
 Minibatch[ 501- 600]: loss = 0.499678 * 100, metric = 7.90% * 100;
 Minibatch[ 601- 700]: loss = 0.482015 * 100, metric = 7.37% * 100;
 Minibatch[ 701- 800]: loss = 0.496809 * 100, metric = 7.68% * 100;
 Minibatch[ 801- 900]: loss = 0.486503 * 100, metric = 7.55% * 100;
 Minibatch[ 901-1000]: loss = 0.480191 * 100, metric = 7.44% * 100;
 Minibatch[1001-1100]: loss = 0.484265 * 100, metric = 7.59% * 100;
 Minibatch[1101-1200]: loss = 0.499088 * 100, metric = 7.80% * 100;
 Minibatch[1201-1300]: loss = 0.509143 * 100, metric = 8.38% * 100;
 Minibatch[1301-1400]: loss = 0.494294 * 100, metric = 7.78% * 100;
 Minibatch[1401-1500]: loss = 0.494677 * 100, metric = 7.87% * 100;
 Minibatch[1501-1600]: loss = 0.506459 * 100, metric = 7.87% * 100;
 Minibatch[1601-1700]: loss = 0.489997 * 100, metric = 7.58% * 100;
 Minibatch[1701-1800]: loss = 0.511841 * 100, metric = 8.13% * 100;
 Minibatch[1801-1900]: loss = 0.485218 * 100, metric = 7.35% * 100;
 Minibatch[1901-2000]: loss = 0.510750 * 100, metric = 8.15% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.498214 * 2000, metric = 7.81% * 2000 933.534s (  2.1 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 15.70% * 2000;
 Minibatch[   1- 100]: loss = 0.511486 * 100, metric = 8.23% * 100;
 Minibatch[ 101- 200]: loss = 0.488999 * 100, metric = 7.51% * 100;
 Minibatch[ 201- 300]: loss = 0.487114 * 100, metric = 7.60% * 100;
 Minibatch[ 301- 400]: loss = 0.498759 * 100, metric = 7.98% * 100;
 Minibatch[ 401- 500]: loss = 0.486899 * 100, metric = 7.56% * 100;
 Minibatch[ 501- 600]: loss = 0.501384 * 100, metric = 7.82% * 100;
 Minibatch[ 601- 700]: loss = 0.503662 * 100, metric = 8.07% * 100;
 Minibatch[ 701- 800]: loss = 0.495459 * 100, metric = 7.71% * 100;
 Minibatch[ 801- 900]: loss = 0.496086 * 100, metric = 7.44% * 100;
 Minibatch[ 901-1000]: loss = 0.475388 * 100, metric = 7.24% * 100;
 Minibatch[1001-1100]: loss = 0.487187 * 100, metric = 7.57% * 100;
 Minibatch[1101-1200]: loss = 0.469069 * 100, metric = 7.20% * 100;
 Minibatch[1201-1300]: loss = 0.500952 * 100, metric = 7.57% * 100;
 Minibatch[1301-1400]: loss = 0.481611 * 100, metric = 7.24% * 100;
 Minibatch[1401-1500]: loss = 0.507075 * 100, metric = 7.93% * 100;
 Minibatch[1501-1600]: loss = 0.499464 * 100, metric = 7.87% * 100;
 Minibatch[1601-1700]: loss = 0.491729 * 100, metric = 7.62% * 100;
 Minibatch[1701-1800]: loss = 0.494239 * 100, metric = 7.51% * 100;
 Minibatch[1801-1900]: loss = 0.488370 * 100, metric = 7.48% * 100;
 Minibatch[1901-2000]: loss = 0.505916 * 100, metric = 7.97% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.493542 * 2000, metric = 7.66% * 2000 946.468s (  2.1 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 15.91% * 2000;
 Minibatch[   1- 100]: loss = 0.485664 * 100, metric = 7.44% * 100;
 Minibatch[ 101- 200]: loss = 0.492413 * 100, metric = 7.47% * 100;
 Minibatch[ 201- 300]: loss = 0.481166 * 100, metric = 7.27% * 100;
 Minibatch[ 301- 400]: loss = 0.490582 * 100, metric = 7.42% * 100;
 Minibatch[ 401- 500]: loss = 0.474135 * 100, metric = 7.21% * 100;
 Minibatch[ 501- 600]: loss = 0.487665 * 100, metric = 7.69% * 100;
 Minibatch[ 601- 700]: loss = 0.494007 * 100, metric = 7.58% * 100;
 Minibatch[ 701- 800]: loss = 0.479585 * 100, metric = 7.34% * 100;
 Minibatch[ 801- 900]: loss = 0.466847 * 100, metric = 6.84% * 100;
 Minibatch[ 901-1000]: loss = 0.481166 * 100, metric = 7.58% * 100;
 Minibatch[1001-1100]: loss = 0.488470 * 100, metric = 7.64% * 100;
 Minibatch[1101-1200]: loss = 0.481605 * 100, metric = 7.60% * 100;
 Minibatch[1201-1300]: loss = 0.486959 * 100, metric = 7.63% * 100;
 Minibatch[1301-1400]: loss = 0.475157 * 100, metric = 7.54% * 100;
 Minibatch[1401-1500]: loss = 0.491719 * 100, metric = 7.84% * 100;
 Minibatch[1501-1600]: loss = 0.496005 * 100, metric = 7.83% * 100;
 Minibatch[1601-1700]: loss = 0.497126 * 100, metric = 7.86% * 100;
 Minibatch[1701-1800]: loss = 0.487250 * 100, metric = 7.74% * 100;
 Minibatch[1801-1900]: loss = 0.480484 * 100, metric = 7.57% * 100;
 Minibatch[1901-2000]: loss = 0.483577 * 100, metric = 7.43% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.485079 * 2000, metric = 7.53% * 2000 970.077s (  2.1 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 15.99% * 2000;
 Minibatch[   1- 100]: loss = 0.460789 * 100, metric = 6.96% * 100;
 Minibatch[ 101- 200]: loss = 0.485466 * 100, metric = 7.49% * 100;
 Minibatch[ 201- 300]: loss = 0.481624 * 100, metric = 7.44% * 100;
 Minibatch[ 301- 400]: loss = 0.468227 * 100, metric = 7.19% * 100;
 Minibatch[ 401- 500]: loss = 0.474384 * 100, metric = 7.25% * 100;
 Minibatch[ 501- 600]: loss = 0.455300 * 100, metric = 6.79% * 100;
 Minibatch[ 601- 700]: loss = 0.491956 * 100, metric = 7.51% * 100;
 Minibatch[ 701- 800]: loss = 0.451622 * 100, metric = 6.72% * 100;
 Minibatch[ 801- 900]: loss = 0.481929 * 100, metric = 7.44% * 100;
 Minibatch[ 901-1000]: loss = 0.465135 * 100, metric = 7.17% * 100;
 Minibatch[1001-1100]: loss = 0.485814 * 100, metric = 7.60% * 100;
 Minibatch[1101-1200]: loss = 0.472319 * 100, metric = 7.20% * 100;
 Minibatch[1201-1300]: loss = 0.476656 * 100, metric = 7.53% * 100;
 Minibatch[1301-1400]: loss = 0.477671 * 100, metric = 7.48% * 100;
 Minibatch[1401-1500]: loss = 0.469094 * 100, metric = 7.03% * 100;
 Minibatch[1501-1600]: loss = 0.474962 * 100, metric = 7.40% * 100;
 Minibatch[1601-1700]: loss = 0.475967 * 100, metric = 7.23% * 100;
 Minibatch[1701-1800]: loss = 0.469352 * 100, metric = 7.12% * 100;
 Minibatch[1801-1900]: loss = 0.482477 * 100, metric = 7.55% * 100;
 Minibatch[1901-2000]: loss = 0.467693 * 100, metric = 6.97% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.473422 * 2000, metric = 7.25% * 2000 935.733s (  2.1 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 14.85% * 2000;
0.6743057071194053
 Minibatch[   1- 100]: loss = 0.465336 * 100, metric = 6.95% * 100;
 Minibatch[ 101- 200]: loss = 0.453943 * 100, metric = 6.83% * 100;
 Minibatch[ 201- 300]: loss = 0.478335 * 100, metric = 7.59% * 100;
 Minibatch[ 301- 400]: loss = 0.469722 * 100, metric = 7.13% * 100;
 Minibatch[ 401- 500]: loss = 0.463522 * 100, metric = 7.04% * 100;
 Minibatch[ 501- 600]: loss = 0.476690 * 100, metric = 7.27% * 100;
 Minibatch[ 601- 700]: loss = 0.481069 * 100, metric = 7.26% * 100;
 Minibatch[ 701- 800]: loss = 0.453386 * 100, metric = 6.99% * 100;
 Minibatch[ 801- 900]: loss = 0.451098 * 100, metric = 6.95% * 100;
 Minibatch[ 901-1000]: loss = 0.483322 * 100, metric = 7.55% * 100;
 Minibatch[1001-1100]: loss = 0.490147 * 100, metric = 7.70% * 100;
 Minibatch[1101-1200]: loss = 0.474446 * 100, metric = 7.47% * 100;
 Minibatch[1201-1300]: loss = 0.472499 * 100, metric = 7.12% * 100;
 Minibatch[1301-1400]: loss = 0.441870 * 100, metric = 6.53% * 100;
 Minibatch[1401-1500]: loss = 0.461810 * 100, metric = 6.94% * 100;
 Minibatch[1501-1600]: loss = 0.466959 * 100, metric = 7.20% * 100;
 Minibatch[1601-1700]: loss = 0.485928 * 100, metric = 7.74% * 100;
 Minibatch[1701-1800]: loss = 0.472740 * 100, metric = 7.38% * 100;
 Minibatch[1801-1900]: loss = 0.472115 * 100, metric = 7.26% * 100;
 Minibatch[1901-2000]: loss = 0.461312 * 100, metric = 6.87% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.468812 * 2000, metric = 7.19% * 2000 936.234s (  2.1 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 15.57% * 2000;
 Minibatch[   1- 100]: loss = 0.468488 * 100, metric = 7.10% * 100;
 Minibatch[ 101- 200]: loss = 0.476174 * 100, metric = 7.37% * 100;
 Minibatch[ 201- 300]: loss = 0.468758 * 100, metric = 7.39% * 100;
 Minibatch[ 301- 400]: loss = 0.467986 * 100, metric = 7.08% * 100;
 Minibatch[ 401- 500]: loss = 0.469039 * 100, metric = 7.36% * 100;
 Minibatch[ 501- 600]: loss = 0.452443 * 100, metric = 6.84% * 100;
 Minibatch[ 601- 700]: loss = 0.468683 * 100, metric = 7.22% * 100;
 Minibatch[ 701- 800]: loss = 0.485705 * 100, metric = 7.46% * 100;
 Minibatch[ 801- 900]: loss = 0.472401 * 100, metric = 7.16% * 100;
 Minibatch[ 901-1000]: loss = 0.449972 * 100, metric = 6.58% * 100;
 Minibatch[1001-1100]: loss = 0.466059 * 100, metric = 7.25% * 100;
 Minibatch[1101-1200]: loss = 0.477985 * 100, metric = 7.36% * 100;
 Minibatch[1201-1300]: loss = 0.478369 * 100, metric = 7.42% * 100;
 Minibatch[1301-1400]: loss = 0.466121 * 100, metric = 7.00% * 100;
 Minibatch[1401-1500]: loss = 0.466188 * 100, metric = 7.16% * 100;
 Minibatch[1501-1600]: loss = 0.449824 * 100, metric = 6.89% * 100;
 Minibatch[1601-1700]: loss = 0.466838 * 100, metric = 7.34% * 100;
 Minibatch[1701-1800]: loss = 0.463008 * 100, metric = 6.90% * 100;
 Minibatch[1801-1900]: loss = 0.473981 * 100, metric = 7.24% * 100;
 Minibatch[1901-2000]: loss = 0.465375 * 100, metric = 7.15% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.467670 * 2000, metric = 7.16% * 2000 962.541s (  2.1 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 15.20% * 2000;
 Minibatch[   1- 100]: loss = 0.479794 * 100, metric = 7.57% * 100;
 Minibatch[ 101- 200]: loss = 0.474661 * 100, metric = 7.20% * 100;
 Minibatch[ 201- 300]: loss = 0.450296 * 100, metric = 6.47% * 100;
 Minibatch[ 301- 400]: loss = 0.450243 * 100, metric = 6.89% * 100;
 Minibatch[ 401- 500]: loss = 0.459809 * 100, metric = 7.05% * 100;
 Minibatch[ 501- 600]: loss = 0.460234 * 100, metric = 7.12% * 100;
 Minibatch[ 601- 700]: loss = 0.461187 * 100, metric = 7.17% * 100;
 Minibatch[ 701- 800]: loss = 0.459689 * 100, metric = 7.10% * 100;
 Minibatch[ 801- 900]: loss = 0.463260 * 100, metric = 7.09% * 100;
 Minibatch[ 901-1000]: loss = 0.458187 * 100, metric = 6.90% * 100;
 Minibatch[1001-1100]: loss = 0.469742 * 100, metric = 7.18% * 100;
 Minibatch[1101-1200]: loss = 0.445719 * 100, metric = 6.66% * 100;
 Minibatch[1201-1300]: loss = 0.458026 * 100, metric = 7.12% * 100;
 Minibatch[1301-1400]: loss = 0.470165 * 100, metric = 7.02% * 100;
 Minibatch[1401-1500]: loss = 0.464232 * 100, metric = 7.05% * 100;
 Minibatch[1501-1600]: loss = 0.468724 * 100, metric = 7.17% * 100;
 Minibatch[1601-1700]: loss = 0.449019 * 100, metric = 6.87% * 100;
 Minibatch[1701-1800]: loss = 0.453734 * 100, metric = 7.10% * 100;
 Minibatch[1801-1900]: loss = 0.460577 * 100, metric = 6.92% * 100;
 Minibatch[1901-2000]: loss = 0.461823 * 100, metric = 6.98% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.460956 * 2000, metric = 7.03% * 2000 946.679s (  2.1 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 14.85% * 2000;
 Minibatch[   1- 100]: loss = 0.447477 * 100, metric = 6.78% * 100;
 Minibatch[ 101- 200]: loss = 0.458396 * 100, metric = 6.84% * 100;
 Minibatch[ 201- 300]: loss = 0.461988 * 100, metric = 6.93% * 100;
 Minibatch[ 301- 400]: loss = 0.452587 * 100, metric = 6.99% * 100;
 Minibatch[ 401- 500]: loss = 0.448128 * 100, metric = 6.85% * 100;
 Minibatch[ 501- 600]: loss = 0.465952 * 100, metric = 7.06% * 100;
 Minibatch[ 601- 700]: loss = 0.463627 * 100, metric = 7.23% * 100;
 Minibatch[ 701- 800]: loss = 0.463251 * 100, metric = 7.04% * 100;
 Minibatch[ 801- 900]: loss = 0.443802 * 100, metric = 6.59% * 100;
 Minibatch[ 901-1000]: loss = 0.443661 * 100, metric = 6.53% * 100;
 Minibatch[1001-1100]: loss = 0.467703 * 100, metric = 7.28% * 100;
 Minibatch[1101-1200]: loss = 0.463636 * 100, metric = 7.12% * 100;
 Minibatch[1201-1300]: loss = 0.455424 * 100, metric = 6.74% * 100;
 Minibatch[1301-1400]: loss = 0.472697 * 100, metric = 7.39% * 100;
 Minibatch[1401-1500]: loss = 0.469391 * 100, metric = 7.16% * 100;
 Minibatch[1501-1600]: loss = 0.460348 * 100, metric = 6.77% * 100;
 Minibatch[1601-1700]: loss = 0.459080 * 100, metric = 7.01% * 100;
 Minibatch[1701-1800]: loss = 0.466721 * 100, metric = 7.14% * 100;
 Minibatch[1801-1900]: loss = 0.461631 * 100, metric = 6.99% * 100;
 Minibatch[1901-2000]: loss = 0.453313 * 100, metric = 6.72% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.458941 * 2000, metric = 6.96% * 2000 936.496s (  2.1 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 15.33% * 2000;
 Minibatch[   1- 100]: loss = 0.455109 * 100, metric = 6.91% * 100;
 Minibatch[ 101- 200]: loss = 0.440258 * 100, metric = 6.76% * 100;
 Minibatch[ 201- 300]: loss = 0.462746 * 100, metric = 6.98% * 100;
 Minibatch[ 301- 400]: loss = 0.460212 * 100, metric = 7.00% * 100;
 Minibatch[ 401- 500]: loss = 0.449881 * 100, metric = 6.73% * 100;
 Minibatch[ 501- 600]: loss = 0.445458 * 100, metric = 6.85% * 100;
 Minibatch[ 601- 700]: loss = 0.462690 * 100, metric = 7.06% * 100;
 Minibatch[ 701- 800]: loss = 0.449278 * 100, metric = 6.82% * 100;
 Minibatch[ 801- 900]: loss = 0.454326 * 100, metric = 7.00% * 100;
 Minibatch[ 901-1000]: loss = 0.455650 * 100, metric = 6.98% * 100;
 Minibatch[1001-1100]: loss = 0.468329 * 100, metric = 7.31% * 100;
 Minibatch[1101-1200]: loss = 0.461645 * 100, metric = 7.03% * 100;
 Minibatch[1201-1300]: loss = 0.442974 * 100, metric = 6.44% * 100;
 Minibatch[1301-1400]: loss = 0.448995 * 100, metric = 6.87% * 100;
 Minibatch[1401-1500]: loss = 0.449661 * 100, metric = 6.71% * 100;
 Minibatch[1501-1600]: loss = 0.459254 * 100, metric = 6.76% * 100;
 Minibatch[1601-1700]: loss = 0.457942 * 100, metric = 6.92% * 100;
 Minibatch[1701-1800]: loss = 0.440855 * 100, metric = 6.54% * 100;
 Minibatch[1801-1900]: loss = 0.443939 * 100, metric = 6.71% * 100;
 Minibatch[1901-2000]: loss = 0.461661 * 100, metric = 7.07% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.453543 * 2000, metric = 6.87% * 2000 949.887s (  2.1 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 15.39% * 2000;
 Minibatch[   1- 100]: loss = 0.452948 * 100, metric = 6.98% * 100;
 Minibatch[ 101- 200]: loss = 0.444791 * 100, metric = 6.70% * 100;
 Minibatch[ 201- 300]: loss = 0.448542 * 100, metric = 6.63% * 100;
 Minibatch[ 301- 400]: loss = 0.455163 * 100, metric = 6.93% * 100;
 Minibatch[ 401- 500]: loss = 0.454688 * 100, metric = 6.86% * 100;
 Minibatch[ 501- 600]: loss = 0.439546 * 100, metric = 6.31% * 100;
 Minibatch[ 601- 700]: loss = 0.452837 * 100, metric = 6.89% * 100;
 Minibatch[ 701- 800]: loss = 0.451081 * 100, metric = 6.85% * 100;
 Minibatch[ 801- 900]: loss = 0.438063 * 100, metric = 6.59% * 100;
 Minibatch[ 901-1000]: loss = 0.454366 * 100, metric = 7.00% * 100;
 Minibatch[1001-1100]: loss = 0.455688 * 100, metric = 6.84% * 100;
 Minibatch[1101-1200]: loss = 0.464612 * 100, metric = 6.93% * 100;
 Minibatch[1201-1300]: loss = 0.460583 * 100, metric = 7.08% * 100;
 Minibatch[1301-1400]: loss = 0.437645 * 100, metric = 6.50% * 100;
 Minibatch[1401-1500]: loss = 0.440237 * 100, metric = 6.59% * 100;
 Minibatch[1501-1600]: loss = 0.444964 * 100, metric = 6.60% * 100;
 Minibatch[1601-1700]: loss = 0.444965 * 100, metric = 6.59% * 100;
 Minibatch[1701-1800]: loss = 0.446045 * 100, metric = 6.63% * 100;
 Minibatch[1801-1900]: loss = 0.443649 * 100, metric = 6.77% * 100;
 Minibatch[1901-2000]: loss = 0.446497 * 100, metric = 6.64% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.448845 * 2000, metric = 6.74% * 2000 921.614s (  2.2 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 15.16% * 2000;
 Minibatch[   1- 100]: loss = 0.441491 * 100, metric = 6.56% * 100;
 Minibatch[ 101- 200]: loss = 0.445498 * 100, metric = 6.90% * 100;
 Minibatch[ 201- 300]: loss = 0.443025 * 100, metric = 6.54% * 100;
 Minibatch[ 301- 400]: loss = 0.433471 * 100, metric = 6.42% * 100;
 Minibatch[ 401- 500]: loss = 0.442195 * 100, metric = 6.49% * 100;
 Minibatch[ 501- 600]: loss = 0.446237 * 100, metric = 6.56% * 100;
 Minibatch[ 601- 700]: loss = 0.437826 * 100, metric = 6.66% * 100;
 Minibatch[ 701- 800]: loss = 0.429842 * 100, metric = 6.41% * 100;
 Minibatch[ 801- 900]: loss = 0.433312 * 100, metric = 6.54% * 100;
 Minibatch[ 901-1000]: loss = 0.458673 * 100, metric = 6.84% * 100;
 Minibatch[1001-1100]: loss = 0.439157 * 100, metric = 6.60% * 100;
 Minibatch[1101-1200]: loss = 0.434427 * 100, metric = 6.66% * 100;
 Minibatch[1201-1300]: loss = 0.434147 * 100, metric = 6.41% * 100;
 Minibatch[1301-1400]: loss = 0.445230 * 100, metric = 6.57% * 100;
 Minibatch[1401-1500]: loss = 0.432359 * 100, metric = 6.28% * 100;
 Minibatch[1501-1600]: loss = 0.440502 * 100, metric = 6.44% * 100;
 Minibatch[1601-1700]: loss = 0.452778 * 100, metric = 6.84% * 100;
 Minibatch[1701-1800]: loss = 0.445441 * 100, metric = 6.65% * 100;
 Minibatch[1801-1900]: loss = 0.442747 * 100, metric = 6.58% * 100;
 Minibatch[1901-2000]: loss = 0.437455 * 100, metric = 6.60% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.440791 * 2000, metric = 6.58% * 2000 937.586s (  2.1 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 14.00% * 2000;
0.6593937908709049
 Minibatch[   1- 100]: loss = 0.461385 * 100, metric = 7.37% * 100;
 Minibatch[ 101- 200]: loss = 0.432512 * 100, metric = 6.41% * 100;
 Minibatch[ 201- 300]: loss = 0.448187 * 100, metric = 7.06% * 100;
 Minibatch[ 301- 400]: loss = 0.448988 * 100, metric = 6.74% * 100;
 Minibatch[ 401- 500]: loss = 0.443038 * 100, metric = 6.52% * 100;
 Minibatch[ 501- 600]: loss = 0.432919 * 100, metric = 6.51% * 100;
 Minibatch[ 601- 700]: loss = 0.446052 * 100, metric = 6.83% * 100;
 Minibatch[ 701- 800]: loss = 0.430659 * 100, metric = 6.63% * 100;
 Minibatch[ 801- 900]: loss = 0.436460 * 100, metric = 6.57% * 100;
 Minibatch[ 901-1000]: loss = 0.444915 * 100, metric = 6.61% * 100;
 Minibatch[1001-1100]: loss = 0.439495 * 100, metric = 6.57% * 100;
 Minibatch[1101-1200]: loss = 0.445032 * 100, metric = 6.52% * 100;
 Minibatch[1201-1300]: loss = 0.449059 * 100, metric = 7.15% * 100;
 Minibatch[1301-1400]: loss = 0.449363 * 100, metric = 6.84% * 100;
 Minibatch[1401-1500]: loss = 0.428267 * 100, metric = 6.38% * 100;
 Minibatch[1501-1600]: loss = 0.453882 * 100, metric = 6.86% * 100;
 Minibatch[1601-1700]: loss = 0.442831 * 100, metric = 6.63% * 100;
 Minibatch[1701-1800]: loss = 0.434539 * 100, metric = 6.56% * 100;
 Minibatch[1801-1900]: loss = 0.447514 * 100, metric = 6.73% * 100;
 Minibatch[1901-2000]: loss = 0.434487 * 100, metric = 6.43% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.442479 * 2000, metric = 6.70% * 2000 922.409s (  2.2 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 14.78% * 2000;
 Minibatch[   1- 100]: loss = 0.441986 * 100, metric = 6.56% * 100;
 Minibatch[ 101- 200]: loss = 0.434246 * 100, metric = 6.49% * 100;
 Minibatch[ 201- 300]: loss = 0.432021 * 100, metric = 6.55% * 100;
 Minibatch[ 301- 400]: loss = 0.450231 * 100, metric = 6.78% * 100;
 Minibatch[ 401- 500]: loss = 0.440122 * 100, metric = 6.33% * 100;
 Minibatch[ 501- 600]: loss = 0.433723 * 100, metric = 6.63% * 100;
 Minibatch[ 601- 700]: loss = 0.446993 * 100, metric = 6.86% * 100;
 Minibatch[ 701- 800]: loss = 0.414589 * 100, metric = 6.06% * 100;
 Minibatch[ 801- 900]: loss = 0.429701 * 100, metric = 6.21% * 100;
 Minibatch[ 901-1000]: loss = 0.430649 * 100, metric = 6.42% * 100;
 Minibatch[1001-1100]: loss = 0.430195 * 100, metric = 6.20% * 100;
 Minibatch[1101-1200]: loss = 0.419303 * 100, metric = 6.00% * 100;
 Minibatch[1201-1300]: loss = 0.429055 * 100, metric = 6.26% * 100;
 Minibatch[1301-1400]: loss = 0.427120 * 100, metric = 6.39% * 100;
 Minibatch[1401-1500]: loss = 0.422156 * 100, metric = 6.12% * 100;
 Minibatch[1501-1600]: loss = 0.413950 * 100, metric = 6.10% * 100;
 Minibatch[1601-1700]: loss = 0.428537 * 100, metric = 6.36% * 100;
 Minibatch[1701-1800]: loss = 0.448989 * 100, metric = 7.01% * 100;
 Minibatch[1801-1900]: loss = 0.431098 * 100, metric = 6.17% * 100;
 Minibatch[1901-2000]: loss = 0.417200 * 100, metric = 6.31% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.431093 * 2000, metric = 6.39% * 2000 928.469s (  2.2 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 14.71% * 2000;
 Minibatch[   1- 100]: loss = 0.440345 * 100, metric = 6.27% * 100;
 Minibatch[ 101- 200]: loss = 0.428709 * 100, metric = 6.22% * 100;
 Minibatch[ 201- 300]: loss = 0.424337 * 100, metric = 6.10% * 100;
 Minibatch[ 301- 400]: loss = 0.441245 * 100, metric = 6.73% * 100;
 Minibatch[ 401- 500]: loss = 0.429789 * 100, metric = 6.26% * 100;
 Minibatch[ 501- 600]: loss = 0.415302 * 100, metric = 5.79% * 100;
 Minibatch[ 601- 700]: loss = 0.419911 * 100, metric = 6.18% * 100;
 Minibatch[ 701- 800]: loss = 0.417453 * 100, metric = 6.28% * 100;
 Minibatch[ 801- 900]: loss = 0.452948 * 100, metric = 6.84% * 100;
 Minibatch[ 901-1000]: loss = 0.424562 * 100, metric = 6.24% * 100;
 Minibatch[1001-1100]: loss = 0.424690 * 100, metric = 6.31% * 100;
 Minibatch[1101-1200]: loss = 0.443509 * 100, metric = 6.79% * 100;
 Minibatch[1201-1300]: loss = 0.431584 * 100, metric = 6.46% * 100;
 Minibatch[1301-1400]: loss = 0.426772 * 100, metric = 6.16% * 100;
 Minibatch[1401-1500]: loss = 0.437556 * 100, metric = 6.55% * 100;
 Minibatch[1501-1600]: loss = 0.439953 * 100, metric = 6.62% * 100;
 Minibatch[1601-1700]: loss = 0.423062 * 100, metric = 6.45% * 100;
 Minibatch[1701-1800]: loss = 0.434572 * 100, metric = 6.69% * 100;
 Minibatch[1801-1900]: loss = 0.436310 * 100, metric = 6.63% * 100;
 Minibatch[1901-2000]: loss = 0.438771 * 100, metric = 6.55% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.431569 * 2000, metric = 6.41% * 2000 914.068s (  2.2 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 15.12% * 2000;
 Minibatch[   1- 100]: loss = 0.422852 * 100, metric = 6.40% * 100;
 Minibatch[ 101- 200]: loss = 0.444705 * 100, metric = 6.74% * 100;
 Minibatch[ 201- 300]: loss = 0.426270 * 100, metric = 6.35% * 100;
 Minibatch[ 301- 400]: loss = 0.442536 * 100, metric = 6.68% * 100;
 Minibatch[ 401- 500]: loss = 0.428242 * 100, metric = 6.33% * 100;
 Minibatch[ 501- 600]: loss = 0.421103 * 100, metric = 6.40% * 100;
 Minibatch[ 601- 700]: loss = 0.403004 * 100, metric = 5.67% * 100;
 Minibatch[ 701- 800]: loss = 0.415478 * 100, metric = 6.02% * 100;
 Minibatch[ 801- 900]: loss = 0.423244 * 100, metric = 6.27% * 100;
 Minibatch[ 901-1000]: loss = 0.431636 * 100, metric = 6.40% * 100;
 Minibatch[1001-1100]: loss = 0.418120 * 100, metric = 6.17% * 100;
 Minibatch[1101-1200]: loss = 0.433146 * 100, metric = 6.57% * 100;
 Minibatch[1201-1300]: loss = 0.431156 * 100, metric = 6.33% * 100;
 Minibatch[1301-1400]: loss = 0.427821 * 100, metric = 6.46% * 100;
 Minibatch[1401-1500]: loss = 0.421525 * 100, metric = 6.21% * 100;
 Minibatch[1501-1600]: loss = 0.424660 * 100, metric = 6.25% * 100;
 Minibatch[1601-1700]: loss = 0.411561 * 100, metric = 6.04% * 100;
 Minibatch[1701-1800]: loss = 0.438392 * 100, metric = 6.70% * 100;
 Minibatch[1801-1900]: loss = 0.414102 * 100, metric = 5.74% * 100;
 Minibatch[1901-2000]: loss = 0.421353 * 100, metric = 6.12% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.425045 * 2000, metric = 6.29% * 2000 917.148s (  2.2 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 14.36% * 2000;
 Minibatch[   1- 100]: loss = 0.422834 * 100, metric = 6.28% * 100;
 Minibatch[ 101- 200]: loss = 0.418037 * 100, metric = 6.05% * 100;
 Minibatch[ 201- 300]: loss = 0.430471 * 100, metric = 6.42% * 100;
 Minibatch[ 301- 400]: loss = 0.415900 * 100, metric = 6.08% * 100;
 Minibatch[ 401- 500]: loss = 0.414490 * 100, metric = 6.30% * 100;
 Minibatch[ 501- 600]: loss = 0.422748 * 100, metric = 6.41% * 100;
 Minibatch[ 601- 700]: loss = 0.433289 * 100, metric = 6.56% * 100;
 Minibatch[ 701- 800]: loss = 0.436840 * 100, metric = 6.65% * 100;
 Minibatch[ 801- 900]: loss = 0.422849 * 100, metric = 6.06% * 100;
 Minibatch[ 901-1000]: loss = 0.424402 * 100, metric = 6.21% * 100;
 Minibatch[1001-1100]: loss = 0.442566 * 100, metric = 6.82% * 100;
 Minibatch[1101-1200]: loss = 0.430399 * 100, metric = 6.40% * 100;
 Minibatch[1201-1300]: loss = 0.408168 * 100, metric = 5.93% * 100;
 Minibatch[1301-1400]: loss = 0.416406 * 100, metric = 6.28% * 100;
 Minibatch[1401-1500]: loss = 0.429473 * 100, metric = 6.45% * 100;
 Minibatch[1501-1600]: loss = 0.426561 * 100, metric = 6.23% * 100;
 Minibatch[1601-1700]: loss = 0.417036 * 100, metric = 6.13% * 100;
 Minibatch[1701-1800]: loss = 0.429670 * 100, metric = 6.39% * 100;
 Minibatch[1801-1900]: loss = 0.433054 * 100, metric = 6.47% * 100;
 Minibatch[1901-2000]: loss = 0.436688 * 100, metric = 6.51% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.425594 * 2000, metric = 6.33% * 2000 913.059s (  2.2 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 14.21% * 2000;
 Minibatch[   1- 100]: loss = 0.429260 * 100, metric = 6.51% * 100;
 Minibatch[ 101- 200]: loss = 0.428781 * 100, metric = 6.37% * 100;
 Minibatch[ 201- 300]: loss = 0.419094 * 100, metric = 6.45% * 100;
 Minibatch[ 301- 400]: loss = 0.417573 * 100, metric = 6.21% * 100;
 Minibatch[ 401- 500]: loss = 0.429600 * 100, metric = 6.41% * 100;
 Minibatch[ 501- 600]: loss = 0.439045 * 100, metric = 6.79% * 100;
 Minibatch[ 601- 700]: loss = 0.440977 * 100, metric = 6.58% * 100;
 Minibatch[ 701- 800]: loss = 0.422600 * 100, metric = 6.03% * 100;
 Minibatch[ 801- 900]: loss = 0.409436 * 100, metric = 5.93% * 100;
 Minibatch[ 901-1000]: loss = 0.427686 * 100, metric = 6.41% * 100;
 Minibatch[1001-1100]: loss = 0.421801 * 100, metric = 6.42% * 100;
 Minibatch[1101-1200]: loss = 0.421067 * 100, metric = 5.94% * 100;
 Minibatch[1201-1300]: loss = 0.414351 * 100, metric = 6.14% * 100;
 Minibatch[1301-1400]: loss = 0.413618 * 100, metric = 6.08% * 100;
 Minibatch[1401-1500]: loss = 0.418240 * 100, metric = 6.24% * 100;
 Minibatch[1501-1600]: loss = 0.419908 * 100, metric = 6.50% * 100;
 Minibatch[1601-1700]: loss = 0.408420 * 100, metric = 6.00% * 100;
 Minibatch[1701-1800]: loss = 0.413571 * 100, metric = 5.85% * 100;
 Minibatch[1801-1900]: loss = 0.422183 * 100, metric = 6.24% * 100;
 Minibatch[1901-2000]: loss = 0.409814 * 100, metric = 5.78% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.421351 * 2000, metric = 6.24% * 2000 909.920s (  2.2 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 14.60% * 2000;
 Minibatch[   1- 100]: loss = 0.433645 * 100, metric = 6.48% * 100;
 Minibatch[ 101- 200]: loss = 0.413431 * 100, metric = 5.97% * 100;
 Minibatch[ 201- 300]: loss = 0.421655 * 100, metric = 6.31% * 100;
 Minibatch[ 301- 400]: loss = 0.416423 * 100, metric = 6.22% * 100;
 Minibatch[ 401- 500]: loss = 0.425816 * 100, metric = 6.34% * 100;
 Minibatch[ 501- 600]: loss = 0.413154 * 100, metric = 6.18% * 100;
 Minibatch[ 601- 700]: loss = 0.416173 * 100, metric = 6.12% * 100;
 Minibatch[ 701- 800]: loss = 0.418483 * 100, metric = 6.06% * 100;
 Minibatch[ 801- 900]: loss = 0.410638 * 100, metric = 5.93% * 100;
 Minibatch[ 901-1000]: loss = 0.428728 * 100, metric = 6.54% * 100;
 Minibatch[1001-1100]: loss = 0.425156 * 100, metric = 6.35% * 100;
 Minibatch[1101-1200]: loss = 0.422209 * 100, metric = 6.17% * 100;
 Minibatch[1201-1300]: loss = 0.397490 * 100, metric = 5.71% * 100;
 Minibatch[1301-1400]: loss = 0.426624 * 100, metric = 6.47% * 100;
 Minibatch[1401-1500]: loss = 0.410029 * 100, metric = 6.13% * 100;
 Minibatch[1501-1600]: loss = 0.394271 * 100, metric = 5.41% * 100;
 Minibatch[1601-1700]: loss = 0.432261 * 100, metric = 6.74% * 100;
 Minibatch[1701-1800]: loss = 0.421544 * 100, metric = 6.20% * 100;
 Minibatch[1801-1900]: loss = 0.419256 * 100, metric = 6.38% * 100;
 Minibatch[1901-2000]: loss = 0.410181 * 100, metric = 6.00% * 100;
Finished Epoch[49 of 200]: [Training] loss = 0.417858 * 2000, metric = 6.18% * 2000 873.626s (  2.3 samples/s);
Finished Evaluation [49]: Minibatch[1-2000]: metric = 13.78% * 2000;
 Minibatch[   1- 100]: loss = 0.426283 * 100, metric = 6.47% * 100;
 Minibatch[ 101- 200]: loss = 0.407587 * 100, metric = 5.91% * 100;
 Minibatch[ 201- 300]: loss = 0.399313 * 100, metric = 5.75% * 100;
 Minibatch[ 301- 400]: loss = 0.413287 * 100, metric = 6.02% * 100;
 Minibatch[ 401- 500]: loss = 0.420944 * 100, metric = 6.45% * 100;
 Minibatch[ 501- 600]: loss = 0.430868 * 100, metric = 6.57% * 100;
 Minibatch[ 601- 700]: loss = 0.404607 * 100, metric = 6.07% * 100;
 Minibatch[ 701- 800]: loss = 0.404985 * 100, metric = 5.96% * 100;
 Minibatch[ 801- 900]: loss = 0.417872 * 100, metric = 6.09% * 100;
 Minibatch[ 901-1000]: loss = 0.407634 * 100, metric = 5.66% * 100;
 Minibatch[1001-1100]: loss = 0.404463 * 100, metric = 5.92% * 100;
 Minibatch[1101-1200]: loss = 0.405724 * 100, metric = 5.96% * 100;
 Minibatch[1201-1300]: loss = 0.410854 * 100, metric = 6.15% * 100;
 Minibatch[1301-1400]: loss = 0.395469 * 100, metric = 5.80% * 100;
 Minibatch[1401-1500]: loss = 0.414904 * 100, metric = 6.28% * 100;
 Minibatch[1501-1600]: loss = 0.401446 * 100, metric = 5.54% * 100;
 Minibatch[1601-1700]: loss = 0.404074 * 100, metric = 5.95% * 100;
 Minibatch[1701-1800]: loss = 0.415524 * 100, metric = 6.17% * 100;
 Minibatch[1801-1900]: loss = 0.415217 * 100, metric = 5.97% * 100;
 Minibatch[1901-2000]: loss = 0.417794 * 100, metric = 6.40% * 100;
Finished Epoch[50 of 200]: [Training] loss = 0.410942 * 2000, metric = 6.05% * 2000 869.270s (  2.3 samples/s);
Finished Evaluation [50]: Minibatch[1-2000]: metric = 14.58% * 2000;
 Minibatch[   1- 100]: loss = 0.405716 * 100, metric = 5.88% * 100;
 Minibatch[ 101- 200]: loss = 0.420211 * 100, metric = 6.27% * 100;
 Minibatch[ 201- 300]: loss = 0.421737 * 100, metric = 6.21% * 100;
 Minibatch[ 301- 400]: loss = 0.405980 * 100, metric = 6.06% * 100;
 Minibatch[ 401- 500]: loss = 0.414037 * 100, metric = 6.10% * 100;
 Minibatch[ 501- 600]: loss = 0.416533 * 100, metric = 6.32% * 100;
 Minibatch[ 601- 700]: loss = 0.393132 * 100, metric = 5.92% * 100;
 Minibatch[ 701- 800]: loss = 0.406588 * 100, metric = 5.88% * 100;
 Minibatch[ 801- 900]: loss = 0.408736 * 100, metric = 5.90% * 100;
 Minibatch[ 901-1000]: loss = 0.407887 * 100, metric = 6.02% * 100;
 Minibatch[1001-1100]: loss = 0.414940 * 100, metric = 6.14% * 100;
 Minibatch[1101-1200]: loss = 0.417233 * 100, metric = 6.13% * 100;
 Minibatch[1201-1300]: loss = 0.424564 * 100, metric = 6.15% * 100;
 Minibatch[1301-1400]: loss = 0.417153 * 100, metric = 6.09% * 100;
 Minibatch[1401-1500]: loss = 0.402971 * 100, metric = 5.91% * 100;
 Minibatch[1501-1600]: loss = 0.416283 * 100, metric = 6.14% * 100;
 Minibatch[1601-1700]: loss = 0.406243 * 100, metric = 5.98% * 100;
 Minibatch[1701-1800]: loss = 0.412847 * 100, metric = 6.29% * 100;
 Minibatch[1801-1900]: loss = 0.390974 * 100, metric = 5.59% * 100;
 Minibatch[1901-2000]: loss = 0.404095 * 100, metric = 5.89% * 100;
Finished Epoch[51 of 200]: [Training] loss = 0.410393 * 2000, metric = 6.04% * 2000 866.923s (  2.3 samples/s);
Finished Evaluation [51]: Minibatch[1-2000]: metric = 14.19% * 2000;
 Minibatch[   1- 100]: loss = 0.395170 * 100, metric = 5.86% * 100;
 Minibatch[ 101- 200]: loss = 0.415051 * 100, metric = 5.95% * 100;
 Minibatch[ 201- 300]: loss = 0.421858 * 100, metric = 6.29% * 100;
 Minibatch[ 301- 400]: loss = 0.406156 * 100, metric = 5.82% * 100;
 Minibatch[ 401- 500]: loss = 0.424228 * 100, metric = 6.32% * 100;
 Minibatch[ 501- 600]: loss = 0.411185 * 100, metric = 6.01% * 100;
 Minibatch[ 601- 700]: loss = 0.402370 * 100, metric = 5.94% * 100;
 Minibatch[ 701- 800]: loss = 0.420225 * 100, metric = 6.31% * 100;
 Minibatch[ 801- 900]: loss = 0.417355 * 100, metric = 6.22% * 100;
 Minibatch[ 901-1000]: loss = 0.428993 * 100, metric = 6.42% * 100;
 Minibatch[1001-1100]: loss = 0.404455 * 100, metric = 6.11% * 100;
 Minibatch[1101-1200]: loss = 0.397491 * 100, metric = 5.60% * 100;
 Minibatch[1201-1300]: loss = 0.397620 * 100, metric = 5.78% * 100;
 Minibatch[1301-1400]: loss = 0.400474 * 100, metric = 5.78% * 100;
 Minibatch[1401-1500]: loss = 0.395289 * 100, metric = 5.76% * 100;
 Minibatch[1501-1600]: loss = 0.394304 * 100, metric = 5.82% * 100;
 Minibatch[1601-1700]: loss = 0.415347 * 100, metric = 6.08% * 100;
 Minibatch[1701-1800]: loss = 0.399453 * 100, metric = 5.97% * 100;
 Minibatch[1801-1900]: loss = 0.397698 * 100, metric = 5.58% * 100;
 Minibatch[1901-2000]: loss = 0.411401 * 100, metric = 6.30% * 100;
Finished Epoch[52 of 200]: [Training] loss = 0.407806 * 2000, metric = 6.00% * 2000 859.058s (  2.3 samples/s);
Finished Evaluation [52]: Minibatch[1-2000]: metric = 15.66% * 2000;
 Minibatch[   1- 100]: loss = 0.409410 * 100, metric = 5.98% * 100;
 Minibatch[ 101- 200]: loss = 0.387416 * 100, metric = 5.50% * 100;
 Minibatch[ 201- 300]: loss = 0.406367 * 100, metric = 5.95% * 100;
 Minibatch[ 301- 400]: loss = 0.408937 * 100, metric = 6.12% * 100;
 Minibatch[ 401- 500]: loss = 0.402121 * 100, metric = 5.89% * 100;
 Minibatch[ 501- 600]: loss = 0.410096 * 100, metric = 6.04% * 100;
 Minibatch[ 601- 700]: loss = 0.400598 * 100, metric = 6.03% * 100;
 Minibatch[ 701- 800]: loss = 0.417225 * 100, metric = 6.04% * 100;
 Minibatch[ 801- 900]: loss = 0.415426 * 100, metric = 6.28% * 100;
 Minibatch[ 901-1000]: loss = 0.397611 * 100, metric = 5.88% * 100;
 Minibatch[1001-1100]: loss = 0.410449 * 100, metric = 6.00% * 100;
 Minibatch[1101-1200]: loss = 0.396634 * 100, metric = 5.78% * 100;
 Minibatch[1201-1300]: loss = 0.394811 * 100, metric = 5.61% * 100;
 Minibatch[1301-1400]: loss = 0.401752 * 100, metric = 5.63% * 100;
 Minibatch[1401-1500]: loss = 0.402579 * 100, metric = 5.83% * 100;
 Minibatch[1501-1600]: loss = 0.412582 * 100, metric = 6.07% * 100;
 Minibatch[1601-1700]: loss = 0.399585 * 100, metric = 5.86% * 100;
 Minibatch[1701-1800]: loss = 0.411764 * 100, metric = 6.10% * 100;
 Minibatch[1801-1900]: loss = 0.419249 * 100, metric = 6.27% * 100;
 Minibatch[1901-2000]: loss = 0.385596 * 100, metric = 5.46% * 100;
Finished Epoch[53 of 200]: [Training] loss = 0.404510 * 2000, metric = 5.92% * 2000 872.511s (  2.3 samples/s);
Finished Evaluation [53]: Minibatch[1-2000]: metric = 13.99% * 2000;
 Minibatch[   1- 100]: loss = 0.401046 * 100, metric = 5.79% * 100;
 Minibatch[ 101- 200]: loss = 0.398216 * 100, metric = 5.91% * 100;
 Minibatch[ 201- 300]: loss = 0.396635 * 100, metric = 5.92% * 100;
 Minibatch[ 301- 400]: loss = 0.390805 * 100, metric = 5.48% * 100;
 Minibatch[ 401- 500]: loss = 0.399645 * 100, metric = 5.95% * 100;
 Minibatch[ 501- 600]: loss = 0.390485 * 100, metric = 5.59% * 100;
 Minibatch[ 601- 700]: loss = 0.413114 * 100, metric = 6.10% * 100;
 Minibatch[ 701- 800]: loss = 0.405406 * 100, metric = 6.06% * 100;
 Minibatch[ 801- 900]: loss = 0.385119 * 100, metric = 5.40% * 100;
 Minibatch[ 901-1000]: loss = 0.396995 * 100, metric = 5.60% * 100;
 Minibatch[1001-1100]: loss = 0.385552 * 100, metric = 5.35% * 100;
 Minibatch[1101-1200]: loss = 0.386401 * 100, metric = 5.57% * 100;
 Minibatch[1201-1300]: loss = 0.390110 * 100, metric = 5.66% * 100;
 Minibatch[1301-1400]: loss = 0.389476 * 100, metric = 5.93% * 100;
 Minibatch[1401-1500]: loss = 0.409295 * 100, metric = 6.02% * 100;
 Minibatch[1501-1600]: loss = 0.398604 * 100, metric = 5.71% * 100;
 Minibatch[1601-1700]: loss = 0.395461 * 100, metric = 5.84% * 100;
 Minibatch[1701-1800]: loss = 0.397244 * 100, metric = 5.83% * 100;
 Minibatch[1801-1900]: loss = 0.406262 * 100, metric = 6.14% * 100;
 Minibatch[1901-2000]: loss = 0.397553 * 100, metric = 5.84% * 100;
Finished Epoch[54 of 200]: [Training] loss = 0.396671 * 2000, metric = 5.78% * 2000 850.666s (  2.4 samples/s);
Finished Evaluation [54]: Minibatch[1-2000]: metric = 13.26% * 2000;
0.659326900459826
 Minibatch[   1- 100]: loss = 0.403023 * 100, metric = 5.78% * 100;
 Minibatch[ 101- 200]: loss = 0.402025 * 100, metric = 5.79% * 100;
 Minibatch[ 201- 300]: loss = 0.402140 * 100, metric = 5.69% * 100;
 Minibatch[ 301- 400]: loss = 0.389257 * 100, metric = 5.53% * 100;
 Minibatch[ 401- 500]: loss = 0.399294 * 100, metric = 5.66% * 100;
 Minibatch[ 501- 600]: loss = 0.401688 * 100, metric = 5.84% * 100;
 Minibatch[ 601- 700]: loss = 0.403309 * 100, metric = 6.00% * 100;
 Minibatch[ 701- 800]: loss = 0.415642 * 100, metric = 6.12% * 100;
 Minibatch[ 801- 900]: loss = 0.395003 * 100, metric = 5.81% * 100;
 Minibatch[ 901-1000]: loss = 0.395496 * 100, metric = 5.67% * 100;
 Minibatch[1001-1100]: loss = 0.396230 * 100, metric = 5.58% * 100;
 Minibatch[1101-1200]: loss = 0.400596 * 100, metric = 5.80% * 100;
 Minibatch[1201-1300]: loss = 0.399249 * 100, metric = 5.62% * 100;
 Minibatch[1301-1400]: loss = 0.381553 * 100, metric = 5.27% * 100;
 Minibatch[1401-1500]: loss = 0.387906 * 100, metric = 5.55% * 100;
 Minibatch[1501-1600]: loss = 0.392719 * 100, metric = 5.57% * 100;
 Minibatch[1601-1700]: loss = 0.392578 * 100, metric = 5.79% * 100;
 Minibatch[1701-1800]: loss = 0.402292 * 100, metric = 5.78% * 100;
 Minibatch[1801-1900]: loss = 0.379265 * 100, metric = 5.34% * 100;
 Minibatch[1901-2000]: loss = 0.389351 * 100, metric = 5.53% * 100;
Finished Epoch[55 of 200]: [Training] loss = 0.396431 * 2000, metric = 5.69% * 2000 860.698s (  2.3 samples/s);
Finished Evaluation [55]: Minibatch[1-2000]: metric = 13.99% * 2000;
 Minibatch[   1- 100]: loss = 0.394368 * 100, metric = 5.80% * 100;
 Minibatch[ 101- 200]: loss = 0.382519 * 100, metric = 5.28% * 100;
 Minibatch[ 201- 300]: loss = 0.403301 * 100, metric = 5.99% * 100;
 Minibatch[ 301- 400]: loss = 0.393436 * 100, metric = 5.68% * 100;
 Minibatch[ 401- 500]: loss = 0.404489 * 100, metric = 5.98% * 100;
 Minibatch[ 501- 600]: loss = 0.402691 * 100, metric = 5.77% * 100;
 Minibatch[ 601- 700]: loss = 0.388497 * 100, metric = 5.70% * 100;
 Minibatch[ 701- 800]: loss = 0.391666 * 100, metric = 5.64% * 100;
 Minibatch[ 801- 900]: loss = 0.392784 * 100, metric = 5.67% * 100;
 Minibatch[ 901-1000]: loss = 0.399932 * 100, metric = 6.01% * 100;
 Minibatch[1001-1100]: loss = 0.403348 * 100, metric = 5.89% * 100;
 Minibatch[1101-1200]: loss = 0.393773 * 100, metric = 5.81% * 100;
 Minibatch[1201-1300]: loss = 0.394065 * 100, metric = 5.73% * 100;
 Minibatch[1301-1400]: loss = 0.393143 * 100, metric = 5.59% * 100;
 Minibatch[1401-1500]: loss = 0.395906 * 100, metric = 5.69% * 100;
 Minibatch[1501-1600]: loss = 0.389520 * 100, metric = 5.61% * 100;
 Minibatch[1601-1700]: loss = 0.380883 * 100, metric = 5.28% * 100;
 Minibatch[1701-1800]: loss = 0.387601 * 100, metric = 5.66% * 100;
 Minibatch[1801-1900]: loss = 0.382032 * 100, metric = 5.51% * 100;
 Minibatch[1901-2000]: loss = 0.403208 * 100, metric = 5.95% * 100;
Finished Epoch[56 of 200]: [Training] loss = 0.393858 * 2000, metric = 5.71% * 2000 864.005s (  2.3 samples/s);
Finished Evaluation [56]: Minibatch[1-2000]: metric = 13.53% * 2000;
0.65586484888196
 Minibatch[   1- 100]: loss = 0.391156 * 100, metric = 5.48% * 100;
 Minibatch[ 101- 200]: loss = 0.389395 * 100, metric = 5.71% * 100;
 Minibatch[ 201- 300]: loss = 0.388178 * 100, metric = 5.38% * 100;
 Minibatch[ 301- 400]: loss = 0.386573 * 100, metric = 5.47% * 100;
 Minibatch[ 401- 500]: loss = 0.380827 * 100, metric = 5.47% * 100;
 Minibatch[ 501- 600]: loss = 0.377739 * 100, metric = 5.44% * 100;
 Minibatch[ 601- 700]: loss = 0.396904 * 100, metric = 5.62% * 100;
 Minibatch[ 701- 800]: loss = 0.379864 * 100, metric = 5.40% * 100;
 Minibatch[ 801- 900]: loss = 0.393262 * 100, metric = 5.72% * 100;
 Minibatch[ 901-1000]: loss = 0.391735 * 100, metric = 5.42% * 100;
 Minibatch[1001-1100]: loss = 0.397158 * 100, metric = 5.60% * 100;
 Minibatch[1101-1200]: loss = 0.383806 * 100, metric = 5.42% * 100;
 Minibatch[1201-1300]: loss = 0.392172 * 100, metric = 5.86% * 100;
 Minibatch[1301-1400]: loss = 0.376695 * 100, metric = 5.44% * 100;
 Minibatch[1401-1500]: loss = 0.400764 * 100, metric = 5.80% * 100;
 Minibatch[1501-1600]: loss = 0.380364 * 100, metric = 5.50% * 100;
 Minibatch[1601-1700]: loss = 0.380894 * 100, metric = 5.40% * 100;
 Minibatch[1701-1800]: loss = 0.383330 * 100, metric = 5.56% * 100;
 Minibatch[1801-1900]: loss = 0.392420 * 100, metric = 5.54% * 100;
 Minibatch[1901-2000]: loss = 0.392442 * 100, metric = 5.68% * 100;
Finished Epoch[57 of 200]: [Training] loss = 0.387784 * 2000, metric = 5.55% * 2000 847.141s (  2.4 samples/s);
Finished Evaluation [57]: Minibatch[1-2000]: metric = 14.81% * 2000;
 Minibatch[   1- 100]: loss = 0.390500 * 100, metric = 5.34% * 100;
 Minibatch[ 101- 200]: loss = 0.391227 * 100, metric = 5.70% * 100;
 Minibatch[ 201- 300]: loss = 0.380945 * 100, metric = 5.47% * 100;
 Minibatch[ 301- 400]: loss = 0.393519 * 100, metric = 5.46% * 100;
 Minibatch[ 401- 500]: loss = 0.403963 * 100, metric = 6.00% * 100;
 Minibatch[ 501- 600]: loss = 0.381720 * 100, metric = 5.36% * 100;
 Minibatch[ 601- 700]: loss = 0.393460 * 100, metric = 5.70% * 100;
 Minibatch[ 701- 800]: loss = 0.397777 * 100, metric = 5.73% * 100;
 Minibatch[ 801- 900]: loss = 0.395202 * 100, metric = 5.75% * 100;
 Minibatch[ 901-1000]: loss = 0.379910 * 100, metric = 5.57% * 100;
 Minibatch[1001-1100]: loss = 0.395995 * 100, metric = 5.79% * 100;
 Minibatch[1101-1200]: loss = 0.397661 * 100, metric = 5.76% * 100;
 Minibatch[1201-1300]: loss = 0.390464 * 100, metric = 5.78% * 100;
 Minibatch[1301-1400]: loss = 0.393433 * 100, metric = 5.93% * 100;
 Minibatch[1401-1500]: loss = 0.379763 * 100, metric = 5.32% * 100;
 Minibatch[1501-1600]: loss = 0.392477 * 100, metric = 5.61% * 100;
 Minibatch[1601-1700]: loss = 0.395129 * 100, metric = 5.68% * 100;
 Minibatch[1701-1800]: loss = 0.386960 * 100, metric = 5.52% * 100;
 Minibatch[1801-1900]: loss = 0.390399 * 100, metric = 5.59% * 100;
 Minibatch[1901-2000]: loss = 0.376198 * 100, metric = 5.17% * 100;
Finished Epoch[58 of 200]: [Training] loss = 0.390335 * 2000, metric = 5.61% * 2000 862.714s (  2.3 samples/s);
Finished Evaluation [58]: Minibatch[1-2000]: metric = 13.33% * 2000;
0.6468024529665709
 Minibatch[   1- 100]: loss = 0.396957 * 100, metric = 5.93% * 100;
 Minibatch[ 101- 200]: loss = 0.404102 * 100, metric = 6.18% * 100;
 Minibatch[ 201- 300]: loss = 0.380625 * 100, metric = 5.58% * 100;
 Minibatch[ 301- 400]: loss = 0.376768 * 100, metric = 5.25% * 100;
 Minibatch[ 401- 500]: loss = 0.383461 * 100, metric = 5.63% * 100;
 Minibatch[ 501- 600]: loss = 0.374956 * 100, metric = 5.17% * 100;
 Minibatch[ 601- 700]: loss = 0.385271 * 100, metric = 5.67% * 100;
 Minibatch[ 701- 800]: loss = 0.382698 * 100, metric = 5.34% * 100;
 Minibatch[ 801- 900]: loss = 0.382986 * 100, metric = 5.55% * 100;
 Minibatch[ 901-1000]: loss = 0.382690 * 100, metric = 5.39% * 100;
 Minibatch[1001-1100]: loss = 0.376672 * 100, metric = 5.31% * 100;
 Minibatch[1101-1200]: loss = 0.388333 * 100, metric = 5.44% * 100;
 Minibatch[1201-1300]: loss = 0.388179 * 100, metric = 5.63% * 100;
 Minibatch[1301-1400]: loss = 0.376833 * 100, metric = 5.28% * 100;
 Minibatch[1401-1500]: loss = 0.382424 * 100, metric = 5.60% * 100;
 Minibatch[1501-1600]: loss = 0.381470 * 100, metric = 5.54% * 100;
 Minibatch[1601-1700]: loss = 0.379753 * 100, metric = 5.39% * 100;
 Minibatch[1701-1800]: loss = 0.389138 * 100, metric = 5.57% * 100;
 Minibatch[1801-1900]: loss = 0.388620 * 100, metric = 5.69% * 100;
 Minibatch[1901-2000]: loss = 0.390842 * 100, metric = 5.61% * 100;
Finished Epoch[59 of 200]: [Training] loss = 0.384639 * 2000, metric = 5.54% * 2000 853.743s (  2.3 samples/s);
Finished Evaluation [59]: Minibatch[1-2000]: metric = 15.20% * 2000;
 Minibatch[   1- 100]: loss = 0.382191 * 100, metric = 5.44% * 100;
 Minibatch[ 101- 200]: loss = 0.365325 * 100, metric = 5.16% * 100;
 Minibatch[ 201- 300]: loss = 0.367819 * 100, metric = 5.18% * 100;
 Minibatch[ 301- 400]: loss = 0.388956 * 100, metric = 5.50% * 100;
 Minibatch[ 401- 500]: loss = 0.390800 * 100, metric = 5.76% * 100;
 Minibatch[ 501- 600]: loss = 0.390269 * 100, metric = 5.80% * 100;
 Minibatch[ 601- 700]: loss = 0.366634 * 100, metric = 5.11% * 100;
 Minibatch[ 701- 800]: loss = 0.385085 * 100, metric = 5.38% * 100;
 Minibatch[ 801- 900]: loss = 0.380819 * 100, metric = 5.56% * 100;
 Minibatch[ 901-1000]: loss = 0.392128 * 100, metric = 5.88% * 100;
 Minibatch[1001-1100]: loss = 0.401770 * 100, metric = 6.11% * 100;
 Minibatch[1101-1200]: loss = 0.384232 * 100, metric = 5.32% * 100;
 Minibatch[1201-1300]: loss = 0.386693 * 100, metric = 5.54% * 100;
 Minibatch[1301-1400]: loss = 0.377784 * 100, metric = 5.57% * 100;
 Minibatch[1401-1500]: loss = 0.367238 * 100, metric = 5.10% * 100;
 Minibatch[1501-1600]: loss = 0.385734 * 100, metric = 5.48% * 100;
 Minibatch[1601-1700]: loss = 0.377591 * 100, metric = 5.47% * 100;
 Minibatch[1701-1800]: loss = 0.388449 * 100, metric = 5.52% * 100;
 Minibatch[1801-1900]: loss = 0.386931 * 100, metric = 5.52% * 100;
 Minibatch[1901-2000]: loss = 0.375944 * 100, metric = 5.40% * 100;
Finished Epoch[60 of 200]: [Training] loss = 0.382120 * 2000, metric = 5.49% * 2000 861.422s (  2.3 samples/s);
Finished Evaluation [60]: Minibatch[1-2000]: metric = 13.80% * 2000;
 Minibatch[   1- 100]: loss = 0.401877 * 100, metric = 5.67% * 100;
 Minibatch[ 101- 200]: loss = 0.371364 * 100, metric = 5.09% * 100;
 Minibatch[ 201- 300]: loss = 0.376486 * 100, metric = 5.44% * 100;
 Minibatch[ 301- 400]: loss = 0.386103 * 100, metric = 5.50% * 100;
 Minibatch[ 401- 500]: loss = 0.376090 * 100, metric = 5.38% * 100;
 Minibatch[ 501- 600]: loss = 0.345015 * 100, metric = 4.68% * 100;
 Minibatch[ 601- 700]: loss = 0.384749 * 100, metric = 5.17% * 100;
 Minibatch[ 701- 800]: loss = 0.386495 * 100, metric = 5.50% * 100;
 Minibatch[ 801- 900]: loss = 0.368224 * 100, metric = 5.13% * 100;
 Minibatch[ 901-1000]: loss = 0.377617 * 100, metric = 5.38% * 100;
 Minibatch[1001-1100]: loss = 0.378294 * 100, metric = 5.34% * 100;
 Minibatch[1101-1200]: loss = 0.391042 * 100, metric = 5.56% * 100;
 Minibatch[1201-1300]: loss = 0.379864 * 100, metric = 5.38% * 100;
 Minibatch[1301-1400]: loss = 0.360549 * 100, metric = 4.67% * 100;
 Minibatch[1401-1500]: loss = 0.385020 * 100, metric = 5.59% * 100;
 Minibatch[1501-1600]: loss = 0.391884 * 100, metric = 5.65% * 100;
 Minibatch[1601-1700]: loss = 0.388323 * 100, metric = 5.65% * 100;
 Minibatch[1701-1800]: loss = 0.376119 * 100, metric = 5.29% * 100;
 Minibatch[1801-1900]: loss = 0.385960 * 100, metric = 5.38% * 100;
 Minibatch[1901-2000]: loss = 0.375379 * 100, metric = 5.34% * 100;
Finished Epoch[61 of 200]: [Training] loss = 0.379323 * 2000, metric = 5.34% * 2000 843.877s (  2.4 samples/s);
Finished Evaluation [61]: Minibatch[1-2000]: metric = 14.20% * 2000;
 Minibatch[   1- 100]: loss = 0.370217 * 100, metric = 5.33% * 100;
 Minibatch[ 101- 200]: loss = 0.374041 * 100, metric = 5.33% * 100;
 Minibatch[ 201- 300]: loss = 0.374174 * 100, metric = 5.32% * 100;
 Minibatch[ 301- 400]: loss = 0.375013 * 100, metric = 5.40% * 100;
 Minibatch[ 401- 500]: loss = 0.380514 * 100, metric = 5.37% * 100;
 Minibatch[ 501- 600]: loss = 0.377729 * 100, metric = 5.38% * 100;
 Minibatch[ 601- 700]: loss = 0.386602 * 100, metric = 5.61% * 100;
 Minibatch[ 701- 800]: loss = 0.369507 * 100, metric = 5.26% * 100;
 Minibatch[ 801- 900]: loss = 0.377148 * 100, metric = 5.33% * 100;
 Minibatch[ 901-1000]: loss = 0.378730 * 100, metric = 5.36% * 100;
 Minibatch[1001-1100]: loss = 0.356152 * 100, metric = 4.85% * 100;
 Minibatch[1101-1200]: loss = 0.380300 * 100, metric = 5.44% * 100;
 Minibatch[1201-1300]: loss = 0.374956 * 100, metric = 5.21% * 100;
 Minibatch[1301-1400]: loss = 0.387704 * 100, metric = 5.43% * 100;
 Minibatch[1401-1500]: loss = 0.365110 * 100, metric = 5.15% * 100;
 Minibatch[1501-1600]: loss = 0.362145 * 100, metric = 4.86% * 100;
 Minibatch[1601-1700]: loss = 0.380339 * 100, metric = 5.46% * 100;
 Minibatch[1701-1800]: loss = 0.376542 * 100, metric = 5.37% * 100;
 Minibatch[1801-1900]: loss = 0.388463 * 100, metric = 5.53% * 100;
 Minibatch[1901-2000]: loss = 0.377967 * 100, metric = 5.49% * 100;
Finished Epoch[62 of 200]: [Training] loss = 0.375668 * 2000, metric = 5.32% * 2000 870.730s (  2.3 samples/s);
Finished Evaluation [62]: Minibatch[1-2000]: metric = 13.54% * 2000;
 Minibatch[   1- 100]: loss = 0.373939 * 100, metric = 5.31% * 100;
 Minibatch[ 101- 200]: loss = 0.362711 * 100, metric = 4.94% * 100;
 Minibatch[ 201- 300]: loss = 0.382190 * 100, metric = 5.38% * 100;
 Minibatch[ 301- 400]: loss = 0.360924 * 100, metric = 5.06% * 100;
 Minibatch[ 401- 500]: loss = 0.363762 * 100, metric = 5.11% * 100;
 Minibatch[ 501- 600]: loss = 0.358704 * 100, metric = 4.87% * 100;
 Minibatch[ 601- 700]: loss = 0.378463 * 100, metric = 5.48% * 100;
 Minibatch[ 701- 800]: loss = 0.383265 * 100, metric = 5.52% * 100;
 Minibatch[ 801- 900]: loss = 0.375288 * 100, metric = 5.24% * 100;
 Minibatch[ 901-1000]: loss = 0.363986 * 100, metric = 4.90% * 100;
 Minibatch[1001-1100]: loss = 0.379399 * 100, metric = 5.37% * 100;
 Minibatch[1101-1200]: loss = 0.366820 * 100, metric = 5.16% * 100;
 Minibatch[1201-1300]: loss = 0.384109 * 100, metric = 5.38% * 100;
 Minibatch[1301-1400]: loss = 0.379258 * 100, metric = 5.28% * 100;
 Minibatch[1401-1500]: loss = 0.351705 * 100, metric = 4.96% * 100;
 Minibatch[1501-1600]: loss = 0.369855 * 100, metric = 5.07% * 100;
 Minibatch[1601-1700]: loss = 0.368531 * 100, metric = 5.22% * 100;
 Minibatch[1701-1800]: loss = 0.358320 * 100, metric = 5.03% * 100;
 Minibatch[1801-1900]: loss = 0.367527 * 100, metric = 4.96% * 100;
 Minibatch[1901-2000]: loss = 0.368118 * 100, metric = 5.21% * 100;
Finished Epoch[63 of 200]: [Training] loss = 0.369844 * 2000, metric = 5.17% * 2000 840.731s (  2.4 samples/s);
Finished Evaluation [63]: Minibatch[1-2000]: metric = 14.04% * 2000;
 Minibatch[   1- 100]: loss = 0.364125 * 100, metric = 5.17% * 100;
 Minibatch[ 101- 200]: loss = 0.374740 * 100, metric = 5.16% * 100;
 Minibatch[ 201- 300]: loss = 0.375793 * 100, metric = 5.40% * 100;
 Minibatch[ 301- 400]: loss = 0.374279 * 100, metric = 5.31% * 100;
 Minibatch[ 401- 500]: loss = 0.370424 * 100, metric = 5.39% * 100;
 Minibatch[ 501- 600]: loss = 0.368981 * 100, metric = 4.96% * 100;
 Minibatch[ 601- 700]: loss = 0.358343 * 100, metric = 4.74% * 100;
 Minibatch[ 701- 800]: loss = 0.373845 * 100, metric = 5.08% * 100;
 Minibatch[ 801- 900]: loss = 0.373994 * 100, metric = 5.09% * 100;
 Minibatch[ 901-1000]: loss = 0.365671 * 100, metric = 4.90% * 100;
 Minibatch[1001-1100]: loss = 0.365364 * 100, metric = 5.04% * 100;
 Minibatch[1101-1200]: loss = 0.364030 * 100, metric = 5.11% * 100;
 Minibatch[1201-1300]: loss = 0.359312 * 100, metric = 4.88% * 100;
 Minibatch[1301-1400]: loss = 0.376659 * 100, metric = 5.40% * 100;
 Minibatch[1401-1500]: loss = 0.372654 * 100, metric = 5.24% * 100;
 Minibatch[1501-1600]: loss = 0.371738 * 100, metric = 5.30% * 100;
 Minibatch[1601-1700]: loss = 0.353676 * 100, metric = 4.80% * 100;
 Minibatch[1701-1800]: loss = 0.367567 * 100, metric = 5.12% * 100;
 Minibatch[1801-1900]: loss = 0.380021 * 100, metric = 5.49% * 100;
 Minibatch[1901-2000]: loss = 0.366257 * 100, metric = 5.16% * 100;
Finished Epoch[64 of 200]: [Training] loss = 0.368874 * 2000, metric = 5.14% * 2000 843.795s (  2.4 samples/s);
Finished Evaluation [64]: Minibatch[1-2000]: metric = 14.58% * 2000;
 Minibatch[   1- 100]: loss = 0.364995 * 100, metric = 5.12% * 100;
 Minibatch[ 101- 200]: loss = 0.359255 * 100, metric = 4.99% * 100;
 Minibatch[ 201- 300]: loss = 0.375959 * 100, metric = 5.34% * 100;
 Minibatch[ 301- 400]: loss = 0.375049 * 100, metric = 5.32% * 100;
 Minibatch[ 401- 500]: loss = 0.369263 * 100, metric = 5.11% * 100;
 Minibatch[ 501- 600]: loss = 0.371329 * 100, metric = 5.33% * 100;
 Minibatch[ 601- 700]: loss = 0.370212 * 100, metric = 5.24% * 100;
 Minibatch[ 701- 800]: loss = 0.386349 * 100, metric = 5.64% * 100;
 Minibatch[ 801- 900]: loss = 0.370780 * 100, metric = 5.24% * 100;
 Minibatch[ 901-1000]: loss = 0.370333 * 100, metric = 5.29% * 100;
 Minibatch[1001-1100]: loss = 0.375835 * 100, metric = 5.57% * 100;
 Minibatch[1101-1200]: loss = 0.372726 * 100, metric = 5.34% * 100;
 Minibatch[1201-1300]: loss = 0.379980 * 100, metric = 5.33% * 100;
 Minibatch[1301-1400]: loss = 0.364068 * 100, metric = 5.23% * 100;
 Minibatch[1401-1500]: loss = 0.365601 * 100, metric = 5.15% * 100;
 Minibatch[1501-1600]: loss = 0.364509 * 100, metric = 5.27% * 100;
 Minibatch[1601-1700]: loss = 0.378759 * 100, metric = 5.28% * 100;
 Minibatch[1701-1800]: loss = 0.379256 * 100, metric = 5.27% * 100;
 Minibatch[1801-1900]: loss = 0.378506 * 100, metric = 5.32% * 100;
 Minibatch[1901-2000]: loss = 0.372886 * 100, metric = 5.27% * 100;
Finished Epoch[65 of 200]: [Training] loss = 0.372282 * 2000, metric = 5.28% * 2000 858.017s (  2.3 samples/s);
Finished Evaluation [65]: Minibatch[1-2000]: metric = 13.02% * 2000;
 Minibatch[   1- 100]: loss = 0.364637 * 100, metric = 4.95% * 100;
 Minibatch[ 101- 200]: loss = 0.377316 * 100, metric = 5.32% * 100;
 Minibatch[ 201- 300]: loss = 0.373657 * 100, metric = 5.14% * 100;
 Minibatch[ 301- 400]: loss = 0.363828 * 100, metric = 5.30% * 100;
 Minibatch[ 401- 500]: loss = 0.370969 * 100, metric = 5.27% * 100;
 Minibatch[ 501- 600]: loss = 0.360495 * 100, metric = 4.89% * 100;
 Minibatch[ 601- 700]: loss = 0.355879 * 100, metric = 4.99% * 100;
 Minibatch[ 701- 800]: loss = 0.368859 * 100, metric = 5.15% * 100;
 Minibatch[ 801- 900]: loss = 0.345569 * 100, metric = 4.64% * 100;
 Minibatch[ 901-1000]: loss = 0.359408 * 100, metric = 5.01% * 100;
 Minibatch[1001-1100]: loss = 0.369297 * 100, metric = 5.06% * 100;
 Minibatch[1101-1200]: loss = 0.357851 * 100, metric = 5.20% * 100;
 Minibatch[1201-1300]: loss = 0.369414 * 100, metric = 5.18% * 100;
 Minibatch[1301-1400]: loss = 0.359647 * 100, metric = 4.94% * 100;
 Minibatch[1401-1500]: loss = 0.357882 * 100, metric = 4.87% * 100;
 Minibatch[1501-1600]: loss = 0.367237 * 100, metric = 5.21% * 100;
 Minibatch[1601-1700]: loss = 0.363387 * 100, metric = 4.91% * 100;
 Minibatch[1701-1800]: loss = 0.369285 * 100, metric = 5.20% * 100;
 Minibatch[1801-1900]: loss = 0.365702 * 100, metric = 5.12% * 100;
 Minibatch[1901-2000]: loss = 0.360928 * 100, metric = 5.13% * 100;
Finished Epoch[66 of 200]: [Training] loss = 0.364062 * 2000, metric = 5.07% * 2000 835.661s (  2.4 samples/s);
Finished Evaluation [66]: Minibatch[1-2000]: metric = 13.55% * 2000;
 Minibatch[   1- 100]: loss = 0.366166 * 100, metric = 5.21% * 100;
 Minibatch[ 101- 200]: loss = 0.367912 * 100, metric = 5.22% * 100;
 Minibatch[ 201- 300]: loss = 0.362873 * 100, metric = 5.11% * 100;
 Minibatch[ 301- 400]: loss = 0.378415 * 100, metric = 5.45% * 100;
 Minibatch[ 401- 500]: loss = 0.362622 * 100, metric = 5.12% * 100;
 Minibatch[ 501- 600]: loss = 0.365542 * 100, metric = 5.30% * 100;
 Minibatch[ 601- 700]: loss = 0.359738 * 100, metric = 4.86% * 100;
 Minibatch[ 701- 800]: loss = 0.369558 * 100, metric = 5.33% * 100;
 Minibatch[ 801- 900]: loss = 0.364737 * 100, metric = 5.08% * 100;
 Minibatch[ 901-1000]: loss = 0.372414 * 100, metric = 5.17% * 100;
 Minibatch[1001-1100]: loss = 0.363073 * 100, metric = 5.07% * 100;
 Minibatch[1101-1200]: loss = 0.367436 * 100, metric = 5.06% * 100;
 Minibatch[1201-1300]: loss = 0.371359 * 100, metric = 5.21% * 100;
 Minibatch[1301-1400]: loss = 0.369050 * 100, metric = 5.18% * 100;
 Minibatch[1401-1500]: loss = 0.350959 * 100, metric = 4.77% * 100;
 Minibatch[1501-1600]: loss = 0.361128 * 100, metric = 5.01% * 100;
 Minibatch[1601-1700]: loss = 0.351628 * 100, metric = 4.73% * 100;
 Minibatch[1701-1800]: loss = 0.383536 * 100, metric = 5.63% * 100;
 Minibatch[1801-1900]: loss = 0.362409 * 100, metric = 5.13% * 100;
 Minibatch[1901-2000]: loss = 0.375030 * 100, metric = 5.45% * 100;
Finished Epoch[67 of 200]: [Training] loss = 0.366279 * 2000, metric = 5.16% * 2000 842.213s (  2.4 samples/s);
Finished Evaluation [67]: Minibatch[1-2000]: metric = 13.33% * 2000;
 Minibatch[   1- 100]: loss = 0.357220 * 100, metric = 4.84% * 100;
 Minibatch[ 101- 200]: loss = 0.372330 * 100, metric = 5.30% * 100;
 Minibatch[ 201- 300]: loss = 0.372083 * 100, metric = 5.25% * 100;
 Minibatch[ 301- 400]: loss = 0.362517 * 100, metric = 5.00% * 100;
 Minibatch[ 401- 500]: loss = 0.375836 * 100, metric = 5.14% * 100;
 Minibatch[ 501- 600]: loss = 0.365511 * 100, metric = 5.26% * 100;
 Minibatch[ 601- 700]: loss = 0.357233 * 100, metric = 5.06% * 100;
 Minibatch[ 701- 800]: loss = 0.366462 * 100, metric = 5.25% * 100;
 Minibatch[ 801- 900]: loss = 0.351780 * 100, metric = 4.67% * 100;
 Minibatch[ 901-1000]: loss = 0.362901 * 100, metric = 5.19% * 100;
 Minibatch[1001-1100]: loss = 0.372931 * 100, metric = 5.06% * 100;
 Minibatch[1101-1200]: loss = 0.367223 * 100, metric = 5.15% * 100;
 Minibatch[1201-1300]: loss = 0.354242 * 100, metric = 4.99% * 100;
 Minibatch[1301-1400]: loss = 0.340865 * 100, metric = 4.68% * 100;
 Minibatch[1401-1500]: loss = 0.354145 * 100, metric = 5.00% * 100;
 Minibatch[1501-1600]: loss = 0.354924 * 100, metric = 5.00% * 100;
 Minibatch[1601-1700]: loss = 0.355113 * 100, metric = 4.99% * 100;
 Minibatch[1701-1800]: loss = 0.365837 * 100, metric = 5.09% * 100;
 Minibatch[1801-1900]: loss = 0.371875 * 100, metric = 5.42% * 100;
 Minibatch[1901-2000]: loss = 0.348942 * 100, metric = 4.85% * 100;
Finished Epoch[68 of 200]: [Training] loss = 0.361498 * 2000, metric = 5.06% * 2000 849.037s (  2.4 samples/s);
Finished Evaluation [68]: Minibatch[1-2000]: metric = 13.36% * 2000;
 Minibatch[   1- 100]: loss = 0.353624 * 100, metric = 5.10% * 100;
 Minibatch[ 101- 200]: loss = 0.362838 * 100, metric = 5.00% * 100;
 Minibatch[ 201- 300]: loss = 0.350159 * 100, metric = 4.80% * 100;
 Minibatch[ 301- 400]: loss = 0.367331 * 100, metric = 5.27% * 100;
 Minibatch[ 401- 500]: loss = 0.369216 * 100, metric = 5.23% * 100;
 Minibatch[ 501- 600]: loss = 0.372280 * 100, metric = 5.36% * 100;
 Minibatch[ 601- 700]: loss = 0.360812 * 100, metric = 4.92% * 100;
 Minibatch[ 701- 800]: loss = 0.362249 * 100, metric = 5.09% * 100;
 Minibatch[ 801- 900]: loss = 0.350813 * 100, metric = 4.93% * 100;
 Minibatch[ 901-1000]: loss = 0.365274 * 100, metric = 5.14% * 100;
 Minibatch[1001-1100]: loss = 0.366255 * 100, metric = 5.16% * 100;
 Minibatch[1101-1200]: loss = 0.357286 * 100, metric = 4.67% * 100;
 Minibatch[1201-1300]: loss = 0.375253 * 100, metric = 5.35% * 100;
 Minibatch[1301-1400]: loss = 0.362427 * 100, metric = 5.03% * 100;
 Minibatch[1401-1500]: loss = 0.363122 * 100, metric = 5.13% * 100;
 Minibatch[1501-1600]: loss = 0.357286 * 100, metric = 4.98% * 100;
 Minibatch[1601-1700]: loss = 0.359930 * 100, metric = 4.99% * 100;
 Minibatch[1701-1800]: loss = 0.366945 * 100, metric = 5.29% * 100;
 Minibatch[1801-1900]: loss = 0.362608 * 100, metric = 5.09% * 100;
 Minibatch[1901-2000]: loss = 0.355530 * 100, metric = 5.01% * 100;
Finished Epoch[69 of 200]: [Training] loss = 0.362062 * 2000, metric = 5.08% * 2000 845.118s (  2.4 samples/s);
Finished Evaluation [69]: Minibatch[1-2000]: metric = 13.21% * 2000;
 Minibatch[   1- 100]: loss = 0.354543 * 100, metric = 4.75% * 100;
 Minibatch[ 101- 200]: loss = 0.341353 * 100, metric = 4.84% * 100;
 Minibatch[ 201- 300]: loss = 0.356186 * 100, metric = 4.89% * 100;
 Minibatch[ 301- 400]: loss = 0.354008 * 100, metric = 4.94% * 100;
 Minibatch[ 401- 500]: loss = 0.352816 * 100, metric = 4.91% * 100;
 Minibatch[ 501- 600]: loss = 0.365477 * 100, metric = 5.16% * 100;
 Minibatch[ 601- 700]: loss = 0.354345 * 100, metric = 4.75% * 100;
 Minibatch[ 701- 800]: loss = 0.358733 * 100, metric = 5.17% * 100;
 Minibatch[ 801- 900]: loss = 0.351245 * 100, metric = 4.82% * 100;
 Minibatch[ 901-1000]: loss = 0.362500 * 100, metric = 5.18% * 100;
 Minibatch[1001-1100]: loss = 0.345945 * 100, metric = 4.71% * 100;
 Minibatch[1101-1200]: loss = 0.347641 * 100, metric = 4.86% * 100;
 Minibatch[1201-1300]: loss = 0.359631 * 100, metric = 5.02% * 100;
 Minibatch[1301-1400]: loss = 0.363809 * 100, metric = 5.07% * 100;
 Minibatch[1401-1500]: loss = 0.352477 * 100, metric = 4.78% * 100;
 Minibatch[1501-1600]: loss = 0.361647 * 100, metric = 5.01% * 100;
 Minibatch[1601-1700]: loss = 0.360591 * 100, metric = 5.07% * 100;
 Minibatch[1701-1800]: loss = 0.366423 * 100, metric = 5.24% * 100;
 Minibatch[1801-1900]: loss = 0.348608 * 100, metric = 4.62% * 100;
 Minibatch[1901-2000]: loss = 0.359686 * 100, metric = 5.15% * 100;
Finished Epoch[70 of 200]: [Training] loss = 0.355883 * 2000, metric = 4.95% * 2000 842.492s (  2.4 samples/s);
Finished Evaluation [70]: Minibatch[1-2000]: metric = 13.28% * 2000;
 Minibatch[   1- 100]: loss = 0.368708 * 100, metric = 5.46% * 100;
 Minibatch[ 101- 200]: loss = 0.349275 * 100, metric = 4.67% * 100;
 Minibatch[ 201- 300]: loss = 0.362607 * 100, metric = 5.15% * 100;
 Minibatch[ 301- 400]: loss = 0.354675 * 100, metric = 4.71% * 100;
 Minibatch[ 401- 500]: loss = 0.357878 * 100, metric = 5.12% * 100;
 Minibatch[ 501- 600]: loss = 0.364839 * 100, metric = 5.14% * 100;
 Minibatch[ 601- 700]: loss = 0.347773 * 100, metric = 4.62% * 100;
 Minibatch[ 701- 800]: loss = 0.352762 * 100, metric = 5.07% * 100;
 Minibatch[ 801- 900]: loss = 0.356588 * 100, metric = 5.02% * 100;
 Minibatch[ 901-1000]: loss = 0.356769 * 100, metric = 4.84% * 100;
 Minibatch[1001-1100]: loss = 0.361939 * 100, metric = 5.07% * 100;
 Minibatch[1101-1200]: loss = 0.343184 * 100, metric = 4.83% * 100;
 Minibatch[1201-1300]: loss = 0.344283 * 100, metric = 4.61% * 100;
 Minibatch[1301-1400]: loss = 0.348782 * 100, metric = 4.77% * 100;
 Minibatch[1401-1500]: loss = 0.362715 * 100, metric = 4.88% * 100;
 Minibatch[1501-1600]: loss = 0.376141 * 100, metric = 5.27% * 100;
 Minibatch[1601-1700]: loss = 0.353710 * 100, metric = 4.81% * 100;
 Minibatch[1701-1800]: loss = 0.357897 * 100, metric = 4.81% * 100;
 Minibatch[1801-1900]: loss = 0.351852 * 100, metric = 4.80% * 100;
 Minibatch[1901-2000]: loss = 0.358399 * 100, metric = 4.95% * 100;
Finished Epoch[71 of 200]: [Training] loss = 0.356539 * 2000, metric = 4.93% * 2000 846.259s (  2.4 samples/s);
Finished Evaluation [71]: Minibatch[1-2000]: metric = 12.55% * 2000;
 Minibatch[   1- 100]: loss = 0.364523 * 100, metric = 4.91% * 100;
 Minibatch[ 101- 200]: loss = 0.355330 * 100, metric = 4.99% * 100;
 Minibatch[ 201- 300]: loss = 0.345295 * 100, metric = 4.78% * 100;
 Minibatch[ 301- 400]: loss = 0.347133 * 100, metric = 4.71% * 100;
 Minibatch[ 401- 500]: loss = 0.353645 * 100, metric = 5.06% * 100;
 Minibatch[ 501- 600]: loss = 0.343129 * 100, metric = 4.73% * 100;
 Minibatch[ 601- 700]: loss = 0.342145 * 100, metric = 4.70% * 100;
 Minibatch[ 701- 800]: loss = 0.352076 * 100, metric = 4.94% * 100;
 Minibatch[ 801- 900]: loss = 0.335026 * 100, metric = 4.50% * 100;
 Minibatch[ 901-1000]: loss = 0.340276 * 100, metric = 4.84% * 100;
 Minibatch[1001-1100]: loss = 0.351741 * 100, metric = 4.90% * 100;
 Minibatch[1101-1200]: loss = 0.332878 * 100, metric = 4.52% * 100;
 Minibatch[1201-1300]: loss = 0.338531 * 100, metric = 4.61% * 100;
 Minibatch[1301-1400]: loss = 0.356256 * 100, metric = 4.91% * 100;
 Minibatch[1401-1500]: loss = 0.354416 * 100, metric = 4.85% * 100;
 Minibatch[1501-1600]: loss = 0.360339 * 100, metric = 5.02% * 100;
 Minibatch[1601-1700]: loss = 0.355565 * 100, metric = 4.89% * 100;
 Minibatch[1701-1800]: loss = 0.349875 * 100, metric = 4.70% * 100;
 Minibatch[1801-1900]: loss = 0.346393 * 100, metric = 4.63% * 100;
 Minibatch[1901-2000]: loss = 0.356670 * 100, metric = 4.96% * 100;
Finished Epoch[72 of 200]: [Training] loss = 0.349062 * 2000, metric = 4.81% * 2000 842.472s (  2.4 samples/s);
Finished Evaluation [72]: Minibatch[1-2000]: metric = 13.48% * 2000;
 Minibatch[   1- 100]: loss = 0.341770 * 100, metric = 4.61% * 100;
 Minibatch[ 101- 200]: loss = 0.346002 * 100, metric = 4.86% * 100;
 Minibatch[ 201- 300]: loss = 0.341703 * 100, metric = 4.70% * 100;
 Minibatch[ 301- 400]: loss = 0.350133 * 100, metric = 4.80% * 100;
 Minibatch[ 401- 500]: loss = 0.345422 * 100, metric = 4.77% * 100;
 Minibatch[ 501- 600]: loss = 0.344877 * 100, metric = 4.77% * 100;
 Minibatch[ 601- 700]: loss = 0.342957 * 100, metric = 4.67% * 100;
 Minibatch[ 701- 800]: loss = 0.339480 * 100, metric = 4.75% * 100;
 Minibatch[ 801- 900]: loss = 0.348278 * 100, metric = 4.65% * 100;
 Minibatch[ 901-1000]: loss = 0.357148 * 100, metric = 4.84% * 100;
 Minibatch[1001-1100]: loss = 0.349987 * 100, metric = 4.85% * 100;
 Minibatch[1101-1200]: loss = 0.335773 * 100, metric = 4.73% * 100;
 Minibatch[1201-1300]: loss = 0.351925 * 100, metric = 4.89% * 100;
 Minibatch[1301-1400]: loss = 0.348176 * 100, metric = 4.85% * 100;
 Minibatch[1401-1500]: loss = 0.341073 * 100, metric = 4.70% * 100;
 Minibatch[1501-1600]: loss = 0.352623 * 100, metric = 4.89% * 100;
 Minibatch[1601-1700]: loss = 0.351811 * 100, metric = 4.84% * 100;
 Minibatch[1701-1800]: loss = 0.337192 * 100, metric = 4.78% * 100;
 Minibatch[1801-1900]: loss = 0.342195 * 100, metric = 4.83% * 100;
 Minibatch[1901-2000]: loss = 0.359169 * 100, metric = 4.96% * 100;
Finished Epoch[73 of 200]: [Training] loss = 0.346385 * 2000, metric = 4.79% * 2000 840.447s (  2.4 samples/s);
Finished Evaluation [73]: Minibatch[1-2000]: metric = 12.92% * 2000;
 Minibatch[   1- 100]: loss = 0.333698 * 100, metric = 4.73% * 100;
 Minibatch[ 101- 200]: loss = 0.347492 * 100, metric = 4.70% * 100;
 Minibatch[ 201- 300]: loss = 0.345872 * 100, metric = 4.61% * 100;
 Minibatch[ 301- 400]: loss = 0.341209 * 100, metric = 4.67% * 100;
 Minibatch[ 401- 500]: loss = 0.350925 * 100, metric = 4.78% * 100;
 Minibatch[ 501- 600]: loss = 0.355967 * 100, metric = 4.92% * 100;
 Minibatch[ 601- 700]: loss = 0.344230 * 100, metric = 4.46% * 100;
 Minibatch[ 701- 800]: loss = 0.345352 * 100, metric = 4.77% * 100;
 Minibatch[ 801- 900]: loss = 0.358224 * 100, metric = 4.85% * 100;
 Minibatch[ 901-1000]: loss = 0.359534 * 100, metric = 4.96% * 100;
 Minibatch[1001-1100]: loss = 0.348134 * 100, metric = 4.72% * 100;
 Minibatch[1101-1200]: loss = 0.366289 * 100, metric = 5.18% * 100;
 Minibatch[1201-1300]: loss = 0.334655 * 100, metric = 4.52% * 100;
 Minibatch[1301-1400]: loss = 0.344886 * 100, metric = 4.70% * 100;
 Minibatch[1401-1500]: loss = 0.335523 * 100, metric = 4.42% * 100;
 Minibatch[1501-1600]: loss = 0.351783 * 100, metric = 4.72% * 100;
 Minibatch[1601-1700]: loss = 0.331040 * 100, metric = 4.50% * 100;
 Minibatch[1701-1800]: loss = 0.345735 * 100, metric = 4.54% * 100;
 Minibatch[1801-1900]: loss = 0.336263 * 100, metric = 4.67% * 100;
 Minibatch[1901-2000]: loss = 0.348857 * 100, metric = 4.86% * 100;
Finished Epoch[74 of 200]: [Training] loss = 0.346284 * 2000, metric = 4.71% * 2000 828.870s (  2.4 samples/s);
Finished Evaluation [74]: Minibatch[1-2000]: metric = 12.91% * 2000;
 Minibatch[   1- 100]: loss = 0.335217 * 100, metric = 4.58% * 100;
 Minibatch[ 101- 200]: loss = 0.346438 * 100, metric = 4.94% * 100;
 Minibatch[ 201- 300]: loss = 0.337306 * 100, metric = 4.50% * 100;
 Minibatch[ 301- 400]: loss = 0.336609 * 100, metric = 4.44% * 100;
 Minibatch[ 401- 500]: loss = 0.341344 * 100, metric = 4.56% * 100;
 Minibatch[ 501- 600]: loss = 0.344439 * 100, metric = 4.71% * 100;
 Minibatch[ 601- 700]: loss = 0.356529 * 100, metric = 4.79% * 100;
 Minibatch[ 701- 800]: loss = 0.343970 * 100, metric = 4.78% * 100;
 Minibatch[ 801- 900]: loss = 0.339539 * 100, metric = 4.56% * 100;
 Minibatch[ 901-1000]: loss = 0.343331 * 100, metric = 4.79% * 100;
 Minibatch[1001-1100]: loss = 0.335172 * 100, metric = 4.50% * 100;
 Minibatch[1101-1200]: loss = 0.337344 * 100, metric = 4.65% * 100;
 Minibatch[1201-1300]: loss = 0.340439 * 100, metric = 4.64% * 100;
 Minibatch[1301-1400]: loss = 0.321551 * 100, metric = 4.25% * 100;
 Minibatch[1401-1500]: loss = 0.328709 * 100, metric = 4.19% * 100;
 Minibatch[1501-1600]: loss = 0.342804 * 100, metric = 4.67% * 100;
 Minibatch[1601-1700]: loss = 0.341013 * 100, metric = 4.70% * 100;
 Minibatch[1701-1800]: loss = 0.328975 * 100, metric = 4.50% * 100;
 Minibatch[1801-1900]: loss = 0.333060 * 100, metric = 4.43% * 100;
 Minibatch[1901-2000]: loss = 0.343270 * 100, metric = 4.66% * 100;
Finished Epoch[75 of 200]: [Training] loss = 0.338853 * 2000, metric = 4.59% * 2000 842.638s (  2.4 samples/s);
Finished Evaluation [75]: Minibatch[1-2000]: metric = 13.20% * 2000;
 Minibatch[   1- 100]: loss = 0.336957 * 100, metric = 4.24% * 100;
 Minibatch[ 101- 200]: loss = 0.344335 * 100, metric = 4.50% * 100;
 Minibatch[ 201- 300]: loss = 0.357262 * 100, metric = 4.94% * 100;
 Minibatch[ 301- 400]: loss = 0.345841 * 100, metric = 4.61% * 100;
 Minibatch[ 401- 500]: loss = 0.340589 * 100, metric = 4.60% * 100;
 Minibatch[ 501- 600]: loss = 0.320631 * 100, metric = 4.32% * 100;
 Minibatch[ 601- 700]: loss = 0.333157 * 100, metric = 4.50% * 100;
 Minibatch[ 701- 800]: loss = 0.329797 * 100, metric = 4.36% * 100;
 Minibatch[ 801- 900]: loss = 0.347323 * 100, metric = 4.69% * 100;
 Minibatch[ 901-1000]: loss = 0.336961 * 100, metric = 4.40% * 100;
 Minibatch[1001-1100]: loss = 0.336185 * 100, metric = 4.44% * 100;
 Minibatch[1101-1200]: loss = 0.332905 * 100, metric = 4.50% * 100;
 Minibatch[1201-1300]: loss = 0.329985 * 100, metric = 4.32% * 100;
 Minibatch[1301-1400]: loss = 0.344379 * 100, metric = 4.70% * 100;
 Minibatch[1401-1500]: loss = 0.342016 * 100, metric = 4.54% * 100;
 Minibatch[1501-1600]: loss = 0.335572 * 100, metric = 4.50% * 100;
 Minibatch[1601-1700]: loss = 0.334562 * 100, metric = 4.58% * 100;
 Minibatch[1701-1800]: loss = 0.320068 * 100, metric = 4.23% * 100;
 Minibatch[1801-1900]: loss = 0.334051 * 100, metric = 4.51% * 100;
 Minibatch[1901-2000]: loss = 0.330193 * 100, metric = 4.27% * 100;
Finished Epoch[76 of 200]: [Training] loss = 0.336638 * 2000, metric = 4.49% * 2000 846.292s (  2.4 samples/s);
Finished Evaluation [76]: Minibatch[1-2000]: metric = 13.00% * 2000;
 Minibatch[   1- 100]: loss = 0.343150 * 100, metric = 4.75% * 100;
 Minibatch[ 101- 200]: loss = 0.340309 * 100, metric = 4.54% * 100;
 Minibatch[ 201- 300]: loss = 0.330398 * 100, metric = 4.34% * 100;
 Minibatch[ 301- 400]: loss = 0.352134 * 100, metric = 4.77% * 100;
 Minibatch[ 401- 500]: loss = 0.339841 * 100, metric = 4.52% * 100;
 Minibatch[ 501- 600]: loss = 0.320124 * 100, metric = 4.32% * 100;
 Minibatch[ 601- 700]: loss = 0.339126 * 100, metric = 4.56% * 100;
 Minibatch[ 701- 800]: loss = 0.337217 * 100, metric = 4.54% * 100;
 Minibatch[ 801- 900]: loss = 0.332307 * 100, metric = 4.43% * 100;
 Minibatch[ 901-1000]: loss = 0.331456 * 100, metric = 4.36% * 100;
 Minibatch[1001-1100]: loss = 0.327584 * 100, metric = 4.36% * 100;
 Minibatch[1101-1200]: loss = 0.338487 * 100, metric = 4.49% * 100;
 Minibatch[1201-1300]: loss = 0.352809 * 100, metric = 4.94% * 100;
 Minibatch[1301-1400]: loss = 0.321810 * 100, metric = 4.24% * 100;
 Minibatch[1401-1500]: loss = 0.342503 * 100, metric = 4.60% * 100;
 Minibatch[1501-1600]: loss = 0.339556 * 100, metric = 4.65% * 100;
 Minibatch[1601-1700]: loss = 0.327596 * 100, metric = 4.36% * 100;
 Minibatch[1701-1800]: loss = 0.325364 * 100, metric = 4.30% * 100;
 Minibatch[1801-1900]: loss = 0.341989 * 100, metric = 4.66% * 100;
 Minibatch[1901-2000]: loss = 0.335759 * 100, metric = 4.59% * 100;
Finished Epoch[77 of 200]: [Training] loss = 0.335976 * 2000, metric = 4.52% * 2000 842.021s (  2.4 samples/s);
Finished Evaluation [77]: Minibatch[1-2000]: metric = 12.86% * 2000;
 Minibatch[   1- 100]: loss = 0.337047 * 100, metric = 4.49% * 100;
 Minibatch[ 101- 200]: loss = 0.335270 * 100, metric = 4.52% * 100;
 Minibatch[ 201- 300]: loss = 0.321085 * 100, metric = 4.21% * 100;
 Minibatch[ 301- 400]: loss = 0.335015 * 100, metric = 4.35% * 100;
 Minibatch[ 401- 500]: loss = 0.347863 * 100, metric = 4.66% * 100;
 Minibatch[ 501- 600]: loss = 0.337450 * 100, metric = 4.57% * 100;
 Minibatch[ 601- 700]: loss = 0.330171 * 100, metric = 4.54% * 100;
 Minibatch[ 701- 800]: loss = 0.332762 * 100, metric = 4.35% * 100;
 Minibatch[ 801- 900]: loss = 0.323299 * 100, metric = 4.21% * 100;
 Minibatch[ 901-1000]: loss = 0.343192 * 100, metric = 4.68% * 100;
 Minibatch[1001-1100]: loss = 0.340041 * 100, metric = 4.73% * 100;
 Minibatch[1101-1200]: loss = 0.330937 * 100, metric = 4.24% * 100;
 Minibatch[1201-1300]: loss = 0.343226 * 100, metric = 4.80% * 100;
 Minibatch[1301-1400]: loss = 0.328741 * 100, metric = 4.34% * 100;
 Minibatch[1401-1500]: loss = 0.338167 * 100, metric = 4.44% * 100;
 Minibatch[1501-1600]: loss = 0.327435 * 100, metric = 4.26% * 100;
 Minibatch[1601-1700]: loss = 0.335739 * 100, metric = 4.54% * 100;
 Minibatch[1701-1800]: loss = 0.330838 * 100, metric = 4.33% * 100;
 Minibatch[1801-1900]: loss = 0.344861 * 100, metric = 4.79% * 100;
 Minibatch[1901-2000]: loss = 0.342153 * 100, metric = 4.65% * 100;
Finished Epoch[78 of 200]: [Training] loss = 0.335265 * 2000, metric = 4.48% * 2000 853.730s (  2.3 samples/s);
Finished Evaluation [78]: Minibatch[1-2000]: metric = 13.21% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
