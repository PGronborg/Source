Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.068162 * 100, metric = 24.37% * 100;
 Minibatch[ 101- 200]: loss = 0.892070 * 100, metric = 23.13% * 100;
 Minibatch[ 201- 300]: loss = 0.782006 * 100, metric = 22.62% * 100;
 Minibatch[ 301- 400]: loss = 0.758431 * 100, metric = 21.74% * 100;
 Minibatch[ 401- 500]: loss = 0.688117 * 100, metric = 20.46% * 100;
 Minibatch[ 501- 600]: loss = 0.679477 * 100, metric = 19.36% * 100;
 Minibatch[ 601- 700]: loss = 0.664198 * 100, metric = 19.25% * 100;
 Minibatch[ 701- 800]: loss = 0.626064 * 100, metric = 18.28% * 100;
 Minibatch[ 801- 900]: loss = 0.629230 * 100, metric = 18.47% * 100;
 Minibatch[ 901-1000]: loss = 0.644781 * 100, metric = 18.83% * 100;
 Minibatch[1001-1100]: loss = 0.614675 * 100, metric = 17.97% * 100;
 Minibatch[1101-1200]: loss = 0.598161 * 100, metric = 17.67% * 100;
 Minibatch[1201-1300]: loss = 0.612153 * 100, metric = 18.24% * 100;
 Minibatch[1301-1400]: loss = 0.568146 * 100, metric = 16.84% * 100;
 Minibatch[1401-1500]: loss = 0.581469 * 100, metric = 17.04% * 100;
 Minibatch[1501-1600]: loss = 0.557848 * 100, metric = 16.88% * 100;
 Minibatch[1601-1700]: loss = 0.561366 * 100, metric = 16.84% * 100;
 Minibatch[1701-1800]: loss = 0.561619 * 100, metric = 16.51% * 100;
 Minibatch[1801-1900]: loss = 0.560441 * 100, metric = 16.78% * 100;
 Minibatch[1901-2000]: loss = 0.545404 * 100, metric = 16.27% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.659691 * 2000, metric = 18.88% * 2000 1193.984s (  1.7 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 23.57% * 2000;
0.60891643563658
 Minibatch[   1- 100]: loss = 0.538326 * 100, metric = 16.35% * 100;
 Minibatch[ 101- 200]: loss = 0.548441 * 100, metric = 16.86% * 100;
 Minibatch[ 201- 300]: loss = 0.538782 * 100, metric = 15.76% * 100;
 Minibatch[ 301- 400]: loss = 0.537318 * 100, metric = 15.69% * 100;
 Minibatch[ 401- 500]: loss = 0.530966 * 100, metric = 15.99% * 100;
 Minibatch[ 501- 600]: loss = 0.532914 * 100, metric = 15.49% * 100;
 Minibatch[ 601- 700]: loss = 0.501133 * 100, metric = 14.94% * 100;
 Minibatch[ 701- 800]: loss = 0.520356 * 100, metric = 15.65% * 100;
 Minibatch[ 801- 900]: loss = 0.505652 * 100, metric = 15.59% * 100;
 Minibatch[ 901-1000]: loss = 0.488636 * 100, metric = 14.75% * 100;
 Minibatch[1001-1100]: loss = 0.499871 * 100, metric = 15.24% * 100;
 Minibatch[1101-1200]: loss = 0.507292 * 100, metric = 15.43% * 100;
 Minibatch[1201-1300]: loss = 0.489606 * 100, metric = 15.15% * 100;
 Minibatch[1301-1400]: loss = 0.506508 * 100, metric = 15.00% * 100;
 Minibatch[1401-1500]: loss = 0.485749 * 100, metric = 14.62% * 100;
 Minibatch[1501-1600]: loss = 0.481544 * 100, metric = 14.74% * 100;
 Minibatch[1601-1700]: loss = 0.483999 * 100, metric = 14.52% * 100;
 Minibatch[1701-1800]: loss = 0.502200 * 100, metric = 15.12% * 100;
 Minibatch[1801-1900]: loss = 0.491440 * 100, metric = 14.68% * 100;
 Minibatch[1901-2000]: loss = 0.473067 * 100, metric = 14.52% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.508190 * 2000, metric = 15.31% * 2000 1107.681s (  1.8 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 20.09% * 2000;
0.5376466537192464
 Minibatch[   1- 100]: loss = 0.485357 * 100, metric = 14.83% * 100;
 Minibatch[ 101- 200]: loss = 0.495676 * 100, metric = 15.10% * 100;
 Minibatch[ 201- 300]: loss = 0.471050 * 100, metric = 14.22% * 100;
 Minibatch[ 301- 400]: loss = 0.488224 * 100, metric = 14.93% * 100;
 Minibatch[ 401- 500]: loss = 0.491771 * 100, metric = 15.18% * 100;
 Minibatch[ 501- 600]: loss = 0.480319 * 100, metric = 14.67% * 100;
 Minibatch[ 601- 700]: loss = 0.490222 * 100, metric = 14.70% * 100;
 Minibatch[ 701- 800]: loss = 0.454702 * 100, metric = 13.58% * 100;
 Minibatch[ 801- 900]: loss = 0.489092 * 100, metric = 14.88% * 100;
 Minibatch[ 901-1000]: loss = 0.458832 * 100, metric = 14.37% * 100;
 Minibatch[1001-1100]: loss = 0.473433 * 100, metric = 14.64% * 100;
 Minibatch[1101-1200]: loss = 0.456346 * 100, metric = 14.18% * 100;
 Minibatch[1201-1300]: loss = 0.466146 * 100, metric = 14.19% * 100;
 Minibatch[1301-1400]: loss = 0.477343 * 100, metric = 14.97% * 100;
 Minibatch[1401-1500]: loss = 0.472917 * 100, metric = 14.88% * 100;
 Minibatch[1501-1600]: loss = 0.459164 * 100, metric = 14.02% * 100;
 Minibatch[1601-1700]: loss = 0.451158 * 100, metric = 13.45% * 100;
 Minibatch[1701-1800]: loss = 0.466326 * 100, metric = 14.37% * 100;
 Minibatch[1801-1900]: loss = 0.451638 * 100, metric = 13.96% * 100;
 Minibatch[1901-2000]: loss = 0.453703 * 100, metric = 14.03% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.471671 * 2000, metric = 14.46% * 2000 1108.328s (  1.8 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 20.63% * 2000;
0.5274600648656488
 Minibatch[   1- 100]: loss = 0.464853 * 100, metric = 13.97% * 100;
 Minibatch[ 101- 200]: loss = 0.442762 * 100, metric = 13.53% * 100;
 Minibatch[ 201- 300]: loss = 0.457321 * 100, metric = 14.06% * 100;
 Minibatch[ 301- 400]: loss = 0.427253 * 100, metric = 13.20% * 100;
 Minibatch[ 401- 500]: loss = 0.464141 * 100, metric = 14.10% * 100;
 Minibatch[ 501- 600]: loss = 0.441938 * 100, metric = 13.44% * 100;
 Minibatch[ 601- 700]: loss = 0.450329 * 100, metric = 13.93% * 100;
 Minibatch[ 701- 800]: loss = 0.452043 * 100, metric = 14.04% * 100;
 Minibatch[ 801- 900]: loss = 0.455987 * 100, metric = 13.97% * 100;
 Minibatch[ 901-1000]: loss = 0.455573 * 100, metric = 14.27% * 100;
 Minibatch[1001-1100]: loss = 0.456849 * 100, metric = 14.41% * 100;
 Minibatch[1101-1200]: loss = 0.442027 * 100, metric = 13.98% * 100;
 Minibatch[1201-1300]: loss = 0.438221 * 100, metric = 13.57% * 100;
 Minibatch[1301-1400]: loss = 0.456797 * 100, metric = 13.83% * 100;
 Minibatch[1401-1500]: loss = 0.460259 * 100, metric = 14.23% * 100;
 Minibatch[1501-1600]: loss = 0.433209 * 100, metric = 13.26% * 100;
 Minibatch[1601-1700]: loss = 0.446151 * 100, metric = 14.02% * 100;
 Minibatch[1701-1800]: loss = 0.445792 * 100, metric = 13.89% * 100;
 Minibatch[1801-1900]: loss = 0.431897 * 100, metric = 13.38% * 100;
 Minibatch[1901-2000]: loss = 0.423907 * 100, metric = 13.00% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.447366 * 2000, metric = 13.80% * 2000 1109.454s (  1.8 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 21.27% * 2000;
 Minibatch[   1- 100]: loss = 0.451302 * 100, metric = 14.04% * 100;
 Minibatch[ 101- 200]: loss = 0.431843 * 100, metric = 13.10% * 100;
 Minibatch[ 201- 300]: loss = 0.423960 * 100, metric = 12.89% * 100;
 Minibatch[ 301- 400]: loss = 0.463781 * 100, metric = 14.51% * 100;
 Minibatch[ 401- 500]: loss = 0.420634 * 100, metric = 12.78% * 100;
 Minibatch[ 501- 600]: loss = 0.425264 * 100, metric = 12.85% * 100;
 Minibatch[ 601- 700]: loss = 0.425081 * 100, metric = 12.84% * 100;
 Minibatch[ 701- 800]: loss = 0.435793 * 100, metric = 13.32% * 100;
 Minibatch[ 801- 900]: loss = 0.420919 * 100, metric = 12.77% * 100;
 Minibatch[ 901-1000]: loss = 0.425560 * 100, metric = 13.34% * 100;
 Minibatch[1001-1100]: loss = 0.429738 * 100, metric = 13.24% * 100;
 Minibatch[1101-1200]: loss = 0.418208 * 100, metric = 12.98% * 100;
 Minibatch[1201-1300]: loss = 0.433196 * 100, metric = 13.40% * 100;
 Minibatch[1301-1400]: loss = 0.446846 * 100, metric = 14.05% * 100;
 Minibatch[1401-1500]: loss = 0.427196 * 100, metric = 13.23% * 100;
 Minibatch[1501-1600]: loss = 0.419892 * 100, metric = 12.79% * 100;
 Minibatch[1601-1700]: loss = 0.433066 * 100, metric = 13.49% * 100;
 Minibatch[1701-1800]: loss = 0.429772 * 100, metric = 13.38% * 100;
 Minibatch[1801-1900]: loss = 0.433260 * 100, metric = 13.20% * 100;
 Minibatch[1901-2000]: loss = 0.418365 * 100, metric = 12.86% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.430684 * 2000, metric = 13.25% * 2000 1114.388s (  1.8 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 21.48% * 2000;
 Minibatch[   1- 100]: loss = 0.412248 * 100, metric = 12.76% * 100;
 Minibatch[ 101- 200]: loss = 0.408750 * 100, metric = 12.68% * 100;
 Minibatch[ 201- 300]: loss = 0.419812 * 100, metric = 12.87% * 100;
 Minibatch[ 301- 400]: loss = 0.422337 * 100, metric = 12.87% * 100;
 Minibatch[ 401- 500]: loss = 0.406456 * 100, metric = 12.35% * 100;
 Minibatch[ 501- 600]: loss = 0.413573 * 100, metric = 12.84% * 100;
 Minibatch[ 601- 700]: loss = 0.414501 * 100, metric = 13.01% * 100;
 Minibatch[ 701- 800]: loss = 0.418960 * 100, metric = 13.02% * 100;
 Minibatch[ 801- 900]: loss = 0.415032 * 100, metric = 12.77% * 100;
 Minibatch[ 901-1000]: loss = 0.407672 * 100, metric = 12.78% * 100;
 Minibatch[1001-1100]: loss = 0.408575 * 100, metric = 12.35% * 100;
 Minibatch[1101-1200]: loss = 0.424262 * 100, metric = 12.86% * 100;
 Minibatch[1201-1300]: loss = 0.429746 * 100, metric = 13.31% * 100;
 Minibatch[1301-1400]: loss = 0.414474 * 100, metric = 12.88% * 100;
 Minibatch[1401-1500]: loss = 0.416083 * 100, metric = 13.21% * 100;
 Minibatch[1501-1600]: loss = 0.401571 * 100, metric = 12.41% * 100;
 Minibatch[1601-1700]: loss = 0.403884 * 100, metric = 12.44% * 100;
 Minibatch[1701-1800]: loss = 0.396710 * 100, metric = 12.26% * 100;
 Minibatch[1801-1900]: loss = 0.415472 * 100, metric = 12.88% * 100;
 Minibatch[1901-2000]: loss = 0.403005 * 100, metric = 12.41% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.412656 * 2000, metric = 12.75% * 2000 1118.835s (  1.8 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 23.01% * 2000;
 Minibatch[   1- 100]: loss = 0.399566 * 100, metric = 12.37% * 100;
 Minibatch[ 101- 200]: loss = 0.405935 * 100, metric = 12.36% * 100;
 Minibatch[ 201- 300]: loss = 0.416845 * 100, metric = 13.07% * 100;
 Minibatch[ 301- 400]: loss = 0.395742 * 100, metric = 12.24% * 100;
 Minibatch[ 401- 500]: loss = 0.408618 * 100, metric = 12.58% * 100;
 Minibatch[ 501- 600]: loss = 0.389743 * 100, metric = 11.98% * 100;
 Minibatch[ 601- 700]: loss = 0.401449 * 100, metric = 12.33% * 100;
 Minibatch[ 701- 800]: loss = 0.404990 * 100, metric = 12.44% * 100;
 Minibatch[ 801- 900]: loss = 0.408802 * 100, metric = 12.81% * 100;
 Minibatch[ 901-1000]: loss = 0.401042 * 100, metric = 12.58% * 100;
 Minibatch[1001-1100]: loss = 0.417520 * 100, metric = 13.07% * 100;
 Minibatch[1101-1200]: loss = 0.395366 * 100, metric = 12.12% * 100;
 Minibatch[1201-1300]: loss = 0.405406 * 100, metric = 12.75% * 100;
 Minibatch[1301-1400]: loss = 0.395861 * 100, metric = 12.11% * 100;
 Minibatch[1401-1500]: loss = 0.393959 * 100, metric = 12.12% * 100;
 Minibatch[1501-1600]: loss = 0.401622 * 100, metric = 12.05% * 100;
 Minibatch[1601-1700]: loss = 0.417145 * 100, metric = 13.10% * 100;
 Minibatch[1701-1800]: loss = 0.403647 * 100, metric = 12.56% * 100;
 Minibatch[1801-1900]: loss = 0.404053 * 100, metric = 12.51% * 100;
 Minibatch[1901-2000]: loss = 0.409836 * 100, metric = 12.71% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.403857 * 2000, metric = 12.49% * 2000 1114.262s (  1.8 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 19.25% * 2000;
0.48903587948530913
 Minibatch[   1- 100]: loss = 0.412270 * 100, metric = 12.75% * 100;
 Minibatch[ 101- 200]: loss = 0.402744 * 100, metric = 12.66% * 100;
 Minibatch[ 201- 300]: loss = 0.387344 * 100, metric = 12.13% * 100;
 Minibatch[ 301- 400]: loss = 0.398041 * 100, metric = 12.50% * 100;
 Minibatch[ 401- 500]: loss = 0.404809 * 100, metric = 12.70% * 100;
 Minibatch[ 501- 600]: loss = 0.413882 * 100, metric = 12.91% * 100;
 Minibatch[ 601- 700]: loss = 0.390335 * 100, metric = 12.23% * 100;
 Minibatch[ 701- 800]: loss = 0.405127 * 100, metric = 12.57% * 100;
 Minibatch[ 801- 900]: loss = 0.384509 * 100, metric = 11.83% * 100;
 Minibatch[ 901-1000]: loss = 0.374030 * 100, metric = 11.46% * 100;
 Minibatch[1001-1100]: loss = 0.379216 * 100, metric = 11.79% * 100;
 Minibatch[1101-1200]: loss = 0.382740 * 100, metric = 11.84% * 100;
 Minibatch[1201-1300]: loss = 0.399933 * 100, metric = 12.35% * 100;
 Minibatch[1301-1400]: loss = 0.399269 * 100, metric = 12.60% * 100;
 Minibatch[1401-1500]: loss = 0.387507 * 100, metric = 11.91% * 100;
 Minibatch[1501-1600]: loss = 0.388337 * 100, metric = 12.10% * 100;
 Minibatch[1601-1700]: loss = 0.383140 * 100, metric = 11.91% * 100;
 Minibatch[1701-1800]: loss = 0.385706 * 100, metric = 11.86% * 100;
 Minibatch[1801-1900]: loss = 0.383578 * 100, metric = 12.09% * 100;
 Minibatch[1901-2000]: loss = 0.383730 * 100, metric = 12.14% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.392312 * 2000, metric = 12.22% * 2000 1114.340s (  1.8 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 18.81% * 2000;
0.4767750872001052
 Minibatch[   1- 100]: loss = 0.366085 * 100, metric = 11.20% * 100;
 Minibatch[ 101- 200]: loss = 0.402970 * 100, metric = 12.42% * 100;
 Minibatch[ 201- 300]: loss = 0.384995 * 100, metric = 11.97% * 100;
 Minibatch[ 301- 400]: loss = 0.398855 * 100, metric = 12.19% * 100;
 Minibatch[ 401- 500]: loss = 0.386788 * 100, metric = 11.86% * 100;
 Minibatch[ 501- 600]: loss = 0.378432 * 100, metric = 11.88% * 100;
 Minibatch[ 601- 700]: loss = 0.379657 * 100, metric = 11.63% * 100;
 Minibatch[ 701- 800]: loss = 0.369695 * 100, metric = 11.64% * 100;
 Minibatch[ 801- 900]: loss = 0.370077 * 100, metric = 11.46% * 100;
 Minibatch[ 901-1000]: loss = 0.386938 * 100, metric = 12.01% * 100;
 Minibatch[1001-1100]: loss = 0.362853 * 100, metric = 11.12% * 100;
 Minibatch[1101-1200]: loss = 0.374814 * 100, metric = 11.81% * 100;
 Minibatch[1201-1300]: loss = 0.376165 * 100, metric = 11.78% * 100;
 Minibatch[1301-1400]: loss = 0.361539 * 100, metric = 10.93% * 100;
 Minibatch[1401-1500]: loss = 0.379276 * 100, metric = 11.91% * 100;
 Minibatch[1501-1600]: loss = 0.381278 * 100, metric = 11.71% * 100;
 Minibatch[1601-1700]: loss = 0.374603 * 100, metric = 11.43% * 100;
 Minibatch[1701-1800]: loss = 0.366779 * 100, metric = 11.24% * 100;
 Minibatch[1801-1900]: loss = 0.366906 * 100, metric = 11.17% * 100;
 Minibatch[1901-2000]: loss = 0.370104 * 100, metric = 11.58% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.376940 * 2000, metric = 11.65% * 2000 1125.967s (  1.8 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 17.60% * 2000;
0.4659922818318009
 Minibatch[   1- 100]: loss = 0.391800 * 100, metric = 12.28% * 100;
 Minibatch[ 101- 200]: loss = 0.357968 * 100, metric = 11.12% * 100;
 Minibatch[ 201- 300]: loss = 0.371385 * 100, metric = 11.62% * 100;
 Minibatch[ 301- 400]: loss = 0.362712 * 100, metric = 11.24% * 100;
 Minibatch[ 401- 500]: loss = 0.370932 * 100, metric = 11.57% * 100;
 Minibatch[ 501- 600]: loss = 0.352815 * 100, metric = 10.76% * 100;
 Minibatch[ 601- 700]: loss = 0.352214 * 100, metric = 11.06% * 100;
 Minibatch[ 701- 800]: loss = 0.341996 * 100, metric = 10.56% * 100;
 Minibatch[ 801- 900]: loss = 0.354723 * 100, metric = 11.27% * 100;
 Minibatch[ 901-1000]: loss = 0.364830 * 100, metric = 11.27% * 100;
 Minibatch[1001-1100]: loss = 0.364780 * 100, metric = 11.34% * 100;
 Minibatch[1101-1200]: loss = 0.367265 * 100, metric = 11.15% * 100;
 Minibatch[1201-1300]: loss = 0.367656 * 100, metric = 11.48% * 100;
 Minibatch[1301-1400]: loss = 0.365151 * 100, metric = 11.41% * 100;
 Minibatch[1401-1500]: loss = 0.352850 * 100, metric = 10.79% * 100;
 Minibatch[1501-1600]: loss = 0.364346 * 100, metric = 11.42% * 100;
 Minibatch[1601-1700]: loss = 0.362529 * 100, metric = 11.13% * 100;
 Minibatch[1701-1800]: loss = 0.366455 * 100, metric = 11.22% * 100;
 Minibatch[1801-1900]: loss = 0.369017 * 100, metric = 11.66% * 100;
 Minibatch[1901-2000]: loss = 0.358403 * 100, metric = 11.27% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.362991 * 2000, metric = 11.28% * 2000 1113.859s (  1.8 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 18.13% * 2000;
 Minibatch[   1- 100]: loss = 0.345064 * 100, metric = 10.61% * 100;
 Minibatch[ 101- 200]: loss = 0.358356 * 100, metric = 11.16% * 100;
 Minibatch[ 201- 300]: loss = 0.361674 * 100, metric = 11.32% * 100;
 Minibatch[ 301- 400]: loss = 0.353002 * 100, metric = 11.03% * 100;
 Minibatch[ 401- 500]: loss = 0.350838 * 100, metric = 11.04% * 100;
 Minibatch[ 501- 600]: loss = 0.357812 * 100, metric = 11.25% * 100;
 Minibatch[ 601- 700]: loss = 0.349668 * 100, metric = 10.82% * 100;
 Minibatch[ 701- 800]: loss = 0.360725 * 100, metric = 11.36% * 100;
 Minibatch[ 801- 900]: loss = 0.355925 * 100, metric = 10.84% * 100;
 Minibatch[ 901-1000]: loss = 0.363278 * 100, metric = 11.18% * 100;
 Minibatch[1001-1100]: loss = 0.358664 * 100, metric = 11.02% * 100;
 Minibatch[1101-1200]: loss = 0.361284 * 100, metric = 11.25% * 100;
 Minibatch[1201-1300]: loss = 0.349578 * 100, metric = 10.77% * 100;
 Minibatch[1301-1400]: loss = 0.340252 * 100, metric = 10.63% * 100;
 Minibatch[1401-1500]: loss = 0.358087 * 100, metric = 11.31% * 100;
 Minibatch[1501-1600]: loss = 0.346591 * 100, metric = 10.71% * 100;
 Minibatch[1601-1700]: loss = 0.343769 * 100, metric = 10.62% * 100;
 Minibatch[1701-1800]: loss = 0.359807 * 100, metric = 11.37% * 100;
 Minibatch[1801-1900]: loss = 0.353600 * 100, metric = 11.06% * 100;
 Minibatch[1901-2000]: loss = 0.352363 * 100, metric = 11.28% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.354017 * 2000, metric = 11.03% * 2000 1105.629s (  1.8 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 19.30% * 2000;
 Minibatch[   1- 100]: loss = 0.336751 * 100, metric = 10.34% * 100;
 Minibatch[ 101- 200]: loss = 0.336881 * 100, metric = 10.45% * 100;
 Minibatch[ 201- 300]: loss = 0.345309 * 100, metric = 11.00% * 100;
 Minibatch[ 301- 400]: loss = 0.371510 * 100, metric = 11.88% * 100;
 Minibatch[ 401- 500]: loss = 0.347382 * 100, metric = 10.79% * 100;
 Minibatch[ 501- 600]: loss = 0.329099 * 100, metric = 10.15% * 100;
 Minibatch[ 601- 700]: loss = 0.340607 * 100, metric = 10.58% * 100;
 Minibatch[ 701- 800]: loss = 0.346638 * 100, metric = 10.76% * 100;
 Minibatch[ 801- 900]: loss = 0.338153 * 100, metric = 10.50% * 100;
 Minibatch[ 901-1000]: loss = 0.349012 * 100, metric = 10.99% * 100;
 Minibatch[1001-1100]: loss = 0.348013 * 100, metric = 10.94% * 100;
 Minibatch[1101-1200]: loss = 0.349924 * 100, metric = 10.92% * 100;
 Minibatch[1201-1300]: loss = 0.352287 * 100, metric = 11.00% * 100;
 Minibatch[1301-1400]: loss = 0.339223 * 100, metric = 10.66% * 100;
 Minibatch[1401-1500]: loss = 0.350721 * 100, metric = 11.13% * 100;
 Minibatch[1501-1600]: loss = 0.322150 * 100, metric = 10.00% * 100;
 Minibatch[1601-1700]: loss = 0.347974 * 100, metric = 10.90% * 100;
 Minibatch[1701-1800]: loss = 0.328719 * 100, metric = 10.01% * 100;
 Minibatch[1801-1900]: loss = 0.337655 * 100, metric = 10.55% * 100;
 Minibatch[1901-2000]: loss = 0.348015 * 100, metric = 10.75% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.343301 * 2000, metric = 10.72% * 2000 1101.407s (  1.8 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 19.11% * 2000;
 Minibatch[   1- 100]: loss = 0.340245 * 100, metric = 10.59% * 100;
 Minibatch[ 101- 200]: loss = 0.341277 * 100, metric = 10.81% * 100;
 Minibatch[ 201- 300]: loss = 0.338949 * 100, metric = 10.61% * 100;
 Minibatch[ 301- 400]: loss = 0.342539 * 100, metric = 10.75% * 100;
 Minibatch[ 401- 500]: loss = 0.354213 * 100, metric = 11.33% * 100;
 Minibatch[ 501- 600]: loss = 0.356579 * 100, metric = 11.10% * 100;
 Minibatch[ 601- 700]: loss = 0.331527 * 100, metric = 10.02% * 100;
 Minibatch[ 701- 800]: loss = 0.330836 * 100, metric = 10.45% * 100;
 Minibatch[ 801- 900]: loss = 0.334328 * 100, metric = 10.34% * 100;
 Minibatch[ 901-1000]: loss = 0.343940 * 100, metric = 10.87% * 100;
 Minibatch[1001-1100]: loss = 0.348524 * 100, metric = 10.84% * 100;
 Minibatch[1101-1200]: loss = 0.335739 * 100, metric = 10.45% * 100;
 Minibatch[1201-1300]: loss = 0.337431 * 100, metric = 10.86% * 100;
 Minibatch[1301-1400]: loss = 0.338784 * 100, metric = 10.62% * 100;
 Minibatch[1401-1500]: loss = 0.333964 * 100, metric = 10.51% * 100;
 Minibatch[1501-1600]: loss = 0.328567 * 100, metric = 10.09% * 100;
 Minibatch[1601-1700]: loss = 0.322456 * 100, metric = 10.15% * 100;
 Minibatch[1701-1800]: loss = 0.339855 * 100, metric = 10.46% * 100;
 Minibatch[1801-1900]: loss = 0.326450 * 100, metric = 10.30% * 100;
 Minibatch[1901-2000]: loss = 0.342186 * 100, metric = 10.86% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.338419 * 2000, metric = 10.60% * 2000 1097.819s (  1.8 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 20.25% * 2000;
 Minibatch[   1- 100]: loss = 0.329313 * 100, metric = 10.24% * 100;
 Minibatch[ 101- 200]: loss = 0.319613 * 100, metric = 9.98% * 100;
 Minibatch[ 201- 300]: loss = 0.336578 * 100, metric = 10.66% * 100;
 Minibatch[ 301- 400]: loss = 0.334435 * 100, metric = 10.58% * 100;
 Minibatch[ 401- 500]: loss = 0.334570 * 100, metric = 10.54% * 100;
 Minibatch[ 501- 600]: loss = 0.333999 * 100, metric = 10.30% * 100;
 Minibatch[ 601- 700]: loss = 0.338796 * 100, metric = 10.62% * 100;
 Minibatch[ 701- 800]: loss = 0.346031 * 100, metric = 10.97% * 100;
 Minibatch[ 801- 900]: loss = 0.351133 * 100, metric = 11.07% * 100;
 Minibatch[ 901-1000]: loss = 0.340956 * 100, metric = 11.00% * 100;
 Minibatch[1001-1100]: loss = 0.338973 * 100, metric = 10.84% * 100;
 Minibatch[1101-1200]: loss = 0.328189 * 100, metric = 10.41% * 100;
 Minibatch[1201-1300]: loss = 0.317913 * 100, metric = 9.83% * 100;
 Minibatch[1301-1400]: loss = 0.335975 * 100, metric = 10.91% * 100;
 Minibatch[1401-1500]: loss = 0.338088 * 100, metric = 10.82% * 100;
 Minibatch[1501-1600]: loss = 0.326773 * 100, metric = 10.37% * 100;
 Minibatch[1601-1700]: loss = 0.324924 * 100, metric = 10.22% * 100;
 Minibatch[1701-1800]: loss = 0.315900 * 100, metric = 9.94% * 100;
 Minibatch[1801-1900]: loss = 0.323425 * 100, metric = 10.12% * 100;
 Minibatch[1901-2000]: loss = 0.334437 * 100, metric = 10.72% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.332501 * 2000, metric = 10.51% * 2000 1100.080s (  1.8 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 20.35% * 2000;
 Minibatch[   1- 100]: loss = 0.319588 * 100, metric = 10.19% * 100;
 Minibatch[ 101- 200]: loss = 0.332423 * 100, metric = 10.50% * 100;
 Minibatch[ 201- 300]: loss = 0.329381 * 100, metric = 10.41% * 100;
 Minibatch[ 301- 400]: loss = 0.313460 * 100, metric = 10.01% * 100;
 Minibatch[ 401- 500]: loss = 0.318470 * 100, metric = 9.95% * 100;
 Minibatch[ 501- 600]: loss = 0.305978 * 100, metric = 9.53% * 100;
 Minibatch[ 601- 700]: loss = 0.315096 * 100, metric = 9.77% * 100;
 Minibatch[ 701- 800]: loss = 0.325448 * 100, metric = 10.28% * 100;
 Minibatch[ 801- 900]: loss = 0.338217 * 100, metric = 10.90% * 100;
 Minibatch[ 901-1000]: loss = 0.320687 * 100, metric = 10.21% * 100;
 Minibatch[1001-1100]: loss = 0.321425 * 100, metric = 10.09% * 100;
 Minibatch[1101-1200]: loss = 0.325090 * 100, metric = 10.13% * 100;
 Minibatch[1201-1300]: loss = 0.307007 * 100, metric = 9.40% * 100;
 Minibatch[1301-1400]: loss = 0.334041 * 100, metric = 10.46% * 100;
 Minibatch[1401-1500]: loss = 0.296763 * 100, metric = 9.30% * 100;
 Minibatch[1501-1600]: loss = 0.311737 * 100, metric = 9.86% * 100;
 Minibatch[1601-1700]: loss = 0.316747 * 100, metric = 10.08% * 100;
 Minibatch[1701-1800]: loss = 0.306677 * 100, metric = 9.37% * 100;
 Minibatch[1801-1900]: loss = 0.310812 * 100, metric = 9.73% * 100;
 Minibatch[1901-2000]: loss = 0.313025 * 100, metric = 9.86% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.318104 * 2000, metric = 10.00% * 2000 1096.422s (  1.8 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 17.53% * 2000;
0.4617728027179837
 Minibatch[   1- 100]: loss = 0.335192 * 100, metric = 10.72% * 100;
 Minibatch[ 101- 200]: loss = 0.315142 * 100, metric = 9.99% * 100;
 Minibatch[ 201- 300]: loss = 0.318579 * 100, metric = 10.18% * 100;
 Minibatch[ 301- 400]: loss = 0.314561 * 100, metric = 9.99% * 100;
 Minibatch[ 401- 500]: loss = 0.302344 * 100, metric = 9.43% * 100;
 Minibatch[ 501- 600]: loss = 0.316239 * 100, metric = 9.93% * 100;
 Minibatch[ 601- 700]: loss = 0.309546 * 100, metric = 9.77% * 100;
 Minibatch[ 701- 800]: loss = 0.305669 * 100, metric = 9.52% * 100;
 Minibatch[ 801- 900]: loss = 0.300026 * 100, metric = 9.58% * 100;
 Minibatch[ 901-1000]: loss = 0.306714 * 100, metric = 9.72% * 100;
 Minibatch[1001-1100]: loss = 0.294258 * 100, metric = 9.24% * 100;
 Minibatch[1101-1200]: loss = 0.302153 * 100, metric = 9.58% * 100;
 Minibatch[1201-1300]: loss = 0.295373 * 100, metric = 9.47% * 100;
 Minibatch[1301-1400]: loss = 0.306194 * 100, metric = 9.78% * 100;
 Minibatch[1401-1500]: loss = 0.302875 * 100, metric = 9.77% * 100;
 Minibatch[1501-1600]: loss = 0.302267 * 100, metric = 9.66% * 100;
 Minibatch[1601-1700]: loss = 0.310746 * 100, metric = 9.94% * 100;
 Minibatch[1701-1800]: loss = 0.311049 * 100, metric = 9.87% * 100;
 Minibatch[1801-1900]: loss = 0.317194 * 100, metric = 10.04% * 100;
 Minibatch[1901-2000]: loss = 0.298281 * 100, metric = 9.85% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.308220 * 2000, metric = 9.80% * 2000 1092.852s (  1.8 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 16.98% * 2000;
0.45638471802324054
 Minibatch[   1- 100]: loss = 0.294914 * 100, metric = 9.42% * 100;
 Minibatch[ 101- 200]: loss = 0.314528 * 100, metric = 9.81% * 100;
 Minibatch[ 201- 300]: loss = 0.306704 * 100, metric = 9.79% * 100;
 Minibatch[ 301- 400]: loss = 0.300566 * 100, metric = 9.40% * 100;
 Minibatch[ 401- 500]: loss = 0.307209 * 100, metric = 9.54% * 100;
 Minibatch[ 501- 600]: loss = 0.298726 * 100, metric = 9.47% * 100;
 Minibatch[ 601- 700]: loss = 0.283464 * 100, metric = 8.97% * 100;
 Minibatch[ 701- 800]: loss = 0.299455 * 100, metric = 9.30% * 100;
 Minibatch[ 801- 900]: loss = 0.307948 * 100, metric = 9.48% * 100;
 Minibatch[ 901-1000]: loss = 0.295779 * 100, metric = 9.42% * 100;
 Minibatch[1001-1100]: loss = 0.287800 * 100, metric = 8.96% * 100;
 Minibatch[1101-1200]: loss = 0.313891 * 100, metric = 9.81% * 100;
 Minibatch[1201-1300]: loss = 0.298719 * 100, metric = 9.43% * 100;
 Minibatch[1301-1400]: loss = 0.294345 * 100, metric = 9.37% * 100;
 Minibatch[1401-1500]: loss = 0.301295 * 100, metric = 9.60% * 100;
 Minibatch[1501-1600]: loss = 0.300469 * 100, metric = 9.52% * 100;
 Minibatch[1601-1700]: loss = 0.302140 * 100, metric = 9.22% * 100;
 Minibatch[1701-1800]: loss = 0.293340 * 100, metric = 9.23% * 100;
 Minibatch[1801-1900]: loss = 0.316412 * 100, metric = 10.30% * 100;
 Minibatch[1901-2000]: loss = 0.313598 * 100, metric = 9.88% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.301565 * 2000, metric = 9.50% * 2000 1091.130s (  1.8 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 17.40% * 2000;
 Minibatch[   1- 100]: loss = 0.292007 * 100, metric = 9.16% * 100;
 Minibatch[ 101- 200]: loss = 0.305898 * 100, metric = 9.60% * 100;
 Minibatch[ 201- 300]: loss = 0.292937 * 100, metric = 9.36% * 100;
 Minibatch[ 301- 400]: loss = 0.298089 * 100, metric = 9.53% * 100;
 Minibatch[ 401- 500]: loss = 0.283252 * 100, metric = 8.94% * 100;
 Minibatch[ 501- 600]: loss = 0.291043 * 100, metric = 9.00% * 100;
 Minibatch[ 601- 700]: loss = 0.295991 * 100, metric = 9.24% * 100;
 Minibatch[ 701- 800]: loss = 0.286718 * 100, metric = 9.25% * 100;
 Minibatch[ 801- 900]: loss = 0.297417 * 100, metric = 9.29% * 100;
 Minibatch[ 901-1000]: loss = 0.294197 * 100, metric = 9.30% * 100;
 Minibatch[1001-1100]: loss = 0.309460 * 100, metric = 10.11% * 100;
 Minibatch[1101-1200]: loss = 0.298145 * 100, metric = 9.28% * 100;
 Minibatch[1201-1300]: loss = 0.307712 * 100, metric = 9.76% * 100;
 Minibatch[1301-1400]: loss = 0.308122 * 100, metric = 9.62% * 100;
 Minibatch[1401-1500]: loss = 0.281860 * 100, metric = 8.73% * 100;
 Minibatch[1501-1600]: loss = 0.296361 * 100, metric = 9.09% * 100;
 Minibatch[1601-1700]: loss = 0.276238 * 100, metric = 8.42% * 100;
 Minibatch[1701-1800]: loss = 0.282126 * 100, metric = 8.94% * 100;
 Minibatch[1801-1900]: loss = 0.277496 * 100, metric = 8.72% * 100;
 Minibatch[1901-2000]: loss = 0.280278 * 100, metric = 8.57% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.292767 * 2000, metric = 9.20% * 2000 1081.814s (  1.8 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 18.38% * 2000;
 Minibatch[   1- 100]: loss = 0.300378 * 100, metric = 9.62% * 100;
 Minibatch[ 101- 200]: loss = 0.299067 * 100, metric = 9.46% * 100;
 Minibatch[ 201- 300]: loss = 0.278014 * 100, metric = 8.83% * 100;
 Minibatch[ 301- 400]: loss = 0.294522 * 100, metric = 9.14% * 100;
 Minibatch[ 401- 500]: loss = 0.291267 * 100, metric = 9.08% * 100;
 Minibatch[ 501- 600]: loss = 0.283435 * 100, metric = 8.76% * 100;
 Minibatch[ 601- 700]: loss = 0.291234 * 100, metric = 9.10% * 100;
 Minibatch[ 701- 800]: loss = 0.280578 * 100, metric = 8.59% * 100;
 Minibatch[ 801- 900]: loss = 0.303846 * 100, metric = 9.62% * 100;
 Minibatch[ 901-1000]: loss = 0.279609 * 100, metric = 8.62% * 100;
 Minibatch[1001-1100]: loss = 0.294749 * 100, metric = 9.20% * 100;
 Minibatch[1101-1200]: loss = 0.291840 * 100, metric = 9.46% * 100;
 Minibatch[1201-1300]: loss = 0.287230 * 100, metric = 9.15% * 100;
 Minibatch[1301-1400]: loss = 0.281409 * 100, metric = 8.73% * 100;
 Minibatch[1401-1500]: loss = 0.291241 * 100, metric = 9.27% * 100;
 Minibatch[1501-1600]: loss = 0.290918 * 100, metric = 9.22% * 100;
 Minibatch[1601-1700]: loss = 0.277387 * 100, metric = 8.83% * 100;
 Minibatch[1701-1800]: loss = 0.269037 * 100, metric = 8.45% * 100;
 Minibatch[1801-1900]: loss = 0.270897 * 100, metric = 8.31% * 100;
 Minibatch[1901-2000]: loss = 0.265819 * 100, metric = 8.32% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.286124 * 2000, metric = 8.99% * 2000 1082.016s (  1.8 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 17.19% * 2000;
 Minibatch[   1- 100]: loss = 0.272859 * 100, metric = 8.31% * 100;
 Minibatch[ 101- 200]: loss = 0.278156 * 100, metric = 8.73% * 100;
 Minibatch[ 201- 300]: loss = 0.269851 * 100, metric = 8.27% * 100;
 Minibatch[ 301- 400]: loss = 0.290219 * 100, metric = 8.85% * 100;
 Minibatch[ 401- 500]: loss = 0.273225 * 100, metric = 8.59% * 100;
 Minibatch[ 501- 600]: loss = 0.279028 * 100, metric = 8.97% * 100;
 Minibatch[ 601- 700]: loss = 0.287886 * 100, metric = 9.21% * 100;
 Minibatch[ 701- 800]: loss = 0.279568 * 100, metric = 8.81% * 100;
 Minibatch[ 801- 900]: loss = 0.284982 * 100, metric = 9.08% * 100;
 Minibatch[ 901-1000]: loss = 0.286166 * 100, metric = 8.98% * 100;
 Minibatch[1001-1100]: loss = 0.260827 * 100, metric = 8.14% * 100;
 Minibatch[1101-1200]: loss = 0.274500 * 100, metric = 8.62% * 100;
 Minibatch[1201-1300]: loss = 0.280979 * 100, metric = 8.74% * 100;
 Minibatch[1301-1400]: loss = 0.285955 * 100, metric = 9.14% * 100;
 Minibatch[1401-1500]: loss = 0.272400 * 100, metric = 8.61% * 100;
 Minibatch[1501-1600]: loss = 0.284602 * 100, metric = 8.81% * 100;
 Minibatch[1601-1700]: loss = 0.275530 * 100, metric = 8.57% * 100;
 Minibatch[1701-1800]: loss = 0.284337 * 100, metric = 9.12% * 100;
 Minibatch[1801-1900]: loss = 0.276420 * 100, metric = 8.74% * 100;
 Minibatch[1901-2000]: loss = 0.276946 * 100, metric = 8.84% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.278722 * 2000, metric = 8.76% * 2000 1071.577s (  1.9 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 17.83% * 2000;
 Minibatch[   1- 100]: loss = 0.273316 * 100, metric = 8.61% * 100;
 Minibatch[ 101- 200]: loss = 0.276116 * 100, metric = 8.81% * 100;
 Minibatch[ 201- 300]: loss = 0.271512 * 100, metric = 8.44% * 100;
 Minibatch[ 301- 400]: loss = 0.281164 * 100, metric = 9.10% * 100;
 Minibatch[ 401- 500]: loss = 0.271206 * 100, metric = 8.63% * 100;
 Minibatch[ 501- 600]: loss = 0.267508 * 100, metric = 8.60% * 100;
 Minibatch[ 601- 700]: loss = 0.270034 * 100, metric = 8.58% * 100;
 Minibatch[ 701- 800]: loss = 0.253527 * 100, metric = 8.07% * 100;
 Minibatch[ 801- 900]: loss = 0.268453 * 100, metric = 8.41% * 100;
 Minibatch[ 901-1000]: loss = 0.263830 * 100, metric = 8.26% * 100;
 Minibatch[1001-1100]: loss = 0.266533 * 100, metric = 8.33% * 100;
 Minibatch[1101-1200]: loss = 0.267619 * 100, metric = 8.30% * 100;
 Minibatch[1201-1300]: loss = 0.271662 * 100, metric = 8.59% * 100;
 Minibatch[1301-1400]: loss = 0.264664 * 100, metric = 8.34% * 100;
 Minibatch[1401-1500]: loss = 0.271617 * 100, metric = 8.60% * 100;
 Minibatch[1501-1600]: loss = 0.280855 * 100, metric = 9.02% * 100;
 Minibatch[1601-1700]: loss = 0.265664 * 100, metric = 8.53% * 100;
 Minibatch[1701-1800]: loss = 0.257462 * 100, metric = 8.14% * 100;
 Minibatch[1801-1900]: loss = 0.282013 * 100, metric = 9.00% * 100;
 Minibatch[1901-2000]: loss = 0.264004 * 100, metric = 8.22% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.269438 * 2000, metric = 8.53% * 2000 1068.083s (  1.9 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 16.68% * 2000;
0.45627238803729414
 Minibatch[   1- 100]: loss = 0.275743 * 100, metric = 8.75% * 100;
 Minibatch[ 101- 200]: loss = 0.274511 * 100, metric = 8.63% * 100;
 Minibatch[ 201- 300]: loss = 0.274754 * 100, metric = 8.77% * 100;
 Minibatch[ 301- 400]: loss = 0.266971 * 100, metric = 8.62% * 100;
 Minibatch[ 401- 500]: loss = 0.263918 * 100, metric = 8.21% * 100;
 Minibatch[ 501- 600]: loss = 0.271251 * 100, metric = 8.52% * 100;
 Minibatch[ 601- 700]: loss = 0.257691 * 100, metric = 8.07% * 100;
 Minibatch[ 701- 800]: loss = 0.262701 * 100, metric = 8.57% * 100;
 Minibatch[ 801- 900]: loss = 0.273304 * 100, metric = 8.78% * 100;
 Minibatch[ 901-1000]: loss = 0.270517 * 100, metric = 8.43% * 100;
 Minibatch[1001-1100]: loss = 0.252348 * 100, metric = 7.80% * 100;
 Minibatch[1101-1200]: loss = 0.246597 * 100, metric = 7.66% * 100;
 Minibatch[1201-1300]: loss = 0.260963 * 100, metric = 8.22% * 100;
 Minibatch[1301-1400]: loss = 0.262441 * 100, metric = 8.24% * 100;
 Minibatch[1401-1500]: loss = 0.259126 * 100, metric = 8.08% * 100;
 Minibatch[1501-1600]: loss = 0.254885 * 100, metric = 8.05% * 100;
 Minibatch[1601-1700]: loss = 0.259746 * 100, metric = 8.26% * 100;
 Minibatch[1701-1800]: loss = 0.256924 * 100, metric = 7.93% * 100;
 Minibatch[1801-1900]: loss = 0.257062 * 100, metric = 8.28% * 100;
 Minibatch[1901-2000]: loss = 0.254592 * 100, metric = 8.01% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.262802 * 2000, metric = 8.29% * 2000 1066.997s (  1.9 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 17.24% * 2000;
 Minibatch[   1- 100]: loss = 0.265423 * 100, metric = 8.36% * 100;
 Minibatch[ 101- 200]: loss = 0.267635 * 100, metric = 8.53% * 100;
 Minibatch[ 201- 300]: loss = 0.261071 * 100, metric = 8.28% * 100;
 Minibatch[ 301- 400]: loss = 0.267862 * 100, metric = 8.45% * 100;
 Minibatch[ 401- 500]: loss = 0.269769 * 100, metric = 8.66% * 100;
 Minibatch[ 501- 600]: loss = 0.259493 * 100, metric = 8.09% * 100;
 Minibatch[ 601- 700]: loss = 0.259567 * 100, metric = 8.25% * 100;
 Minibatch[ 701- 800]: loss = 0.246983 * 100, metric = 7.74% * 100;
 Minibatch[ 801- 900]: loss = 0.256943 * 100, metric = 8.18% * 100;
 Minibatch[ 901-1000]: loss = 0.265686 * 100, metric = 8.53% * 100;
 Minibatch[1001-1100]: loss = 0.254087 * 100, metric = 7.85% * 100;
 Minibatch[1101-1200]: loss = 0.260067 * 100, metric = 8.27% * 100;
 Minibatch[1201-1300]: loss = 0.259915 * 100, metric = 8.36% * 100;
 Minibatch[1301-1400]: loss = 0.267371 * 100, metric = 8.68% * 100;
 Minibatch[1401-1500]: loss = 0.249144 * 100, metric = 7.93% * 100;
 Minibatch[1501-1600]: loss = 0.253464 * 100, metric = 7.96% * 100;
 Minibatch[1601-1700]: loss = 0.252927 * 100, metric = 8.04% * 100;
 Minibatch[1701-1800]: loss = 0.257580 * 100, metric = 8.09% * 100;
 Minibatch[1801-1900]: loss = 0.257542 * 100, metric = 8.38% * 100;
 Minibatch[1901-2000]: loss = 0.255250 * 100, metric = 8.07% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.259389 * 2000, metric = 8.24% * 2000 1059.770s (  1.9 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 17.11% * 2000;
 Minibatch[   1- 100]: loss = 0.250069 * 100, metric = 8.00% * 100;
 Minibatch[ 101- 200]: loss = 0.255548 * 100, metric = 8.27% * 100;
 Minibatch[ 201- 300]: loss = 0.251377 * 100, metric = 8.13% * 100;
 Minibatch[ 301- 400]: loss = 0.255055 * 100, metric = 8.14% * 100;
 Minibatch[ 401- 500]: loss = 0.250660 * 100, metric = 8.08% * 100;
 Minibatch[ 501- 600]: loss = 0.253019 * 100, metric = 7.98% * 100;
 Minibatch[ 601- 700]: loss = 0.263532 * 100, metric = 8.21% * 100;
 Minibatch[ 701- 800]: loss = 0.251133 * 100, metric = 7.98% * 100;
 Minibatch[ 801- 900]: loss = 0.256548 * 100, metric = 8.16% * 100;
 Minibatch[ 901-1000]: loss = 0.251255 * 100, metric = 8.10% * 100;
 Minibatch[1001-1100]: loss = 0.252558 * 100, metric = 7.98% * 100;
 Minibatch[1101-1200]: loss = 0.264356 * 100, metric = 8.30% * 100;
 Minibatch[1201-1300]: loss = 0.254265 * 100, metric = 8.04% * 100;
 Minibatch[1301-1400]: loss = 0.254866 * 100, metric = 8.14% * 100;
 Minibatch[1401-1500]: loss = 0.244579 * 100, metric = 7.59% * 100;
 Minibatch[1501-1600]: loss = 0.260092 * 100, metric = 8.39% * 100;
 Minibatch[1601-1700]: loss = 0.244890 * 100, metric = 7.70% * 100;
 Minibatch[1701-1800]: loss = 0.245635 * 100, metric = 7.77% * 100;
 Minibatch[1801-1900]: loss = 0.254186 * 100, metric = 8.06% * 100;
 Minibatch[1901-2000]: loss = 0.256269 * 100, metric = 8.22% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.253495 * 2000, metric = 8.06% * 2000 1065.436s (  1.9 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 16.48% * 2000;
 Minibatch[   1- 100]: loss = 0.255985 * 100, metric = 8.11% * 100;
 Minibatch[ 101- 200]: loss = 0.248470 * 100, metric = 7.91% * 100;
 Minibatch[ 201- 300]: loss = 0.255278 * 100, metric = 8.23% * 100;
 Minibatch[ 301- 400]: loss = 0.250803 * 100, metric = 7.96% * 100;
 Minibatch[ 401- 500]: loss = 0.251111 * 100, metric = 7.95% * 100;
 Minibatch[ 501- 600]: loss = 0.255321 * 100, metric = 8.19% * 100;
 Minibatch[ 601- 700]: loss = 0.258528 * 100, metric = 8.22% * 100;
 Minibatch[ 701- 800]: loss = 0.243781 * 100, metric = 7.72% * 100;
 Minibatch[ 801- 900]: loss = 0.243337 * 100, metric = 7.74% * 100;
 Minibatch[ 901-1000]: loss = 0.256049 * 100, metric = 8.12% * 100;
 Minibatch[1001-1100]: loss = 0.253120 * 100, metric = 8.12% * 100;
 Minibatch[1101-1200]: loss = 0.259016 * 100, metric = 8.22% * 100;
 Minibatch[1201-1300]: loss = 0.267829 * 100, metric = 8.47% * 100;
 Minibatch[1301-1400]: loss = 0.246089 * 100, metric = 7.63% * 100;
 Minibatch[1401-1500]: loss = 0.243136 * 100, metric = 7.52% * 100;
 Minibatch[1501-1600]: loss = 0.264603 * 100, metric = 8.54% * 100;
 Minibatch[1601-1700]: loss = 0.247458 * 100, metric = 7.87% * 100;
 Minibatch[1701-1800]: loss = 0.249525 * 100, metric = 8.00% * 100;
 Minibatch[1801-1900]: loss = 0.238599 * 100, metric = 7.50% * 100;
 Minibatch[1901-2000]: loss = 0.232531 * 100, metric = 7.28% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.251028 * 2000, metric = 7.96% * 2000 1050.117s (  1.9 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 16.74% * 2000;
 Minibatch[   1- 100]: loss = 0.248043 * 100, metric = 7.80% * 100;
 Minibatch[ 101- 200]: loss = 0.233541 * 100, metric = 7.40% * 100;
 Minibatch[ 201- 300]: loss = 0.248748 * 100, metric = 7.92% * 100;
 Minibatch[ 301- 400]: loss = 0.238311 * 100, metric = 7.39% * 100;
 Minibatch[ 401- 500]: loss = 0.248891 * 100, metric = 7.81% * 100;
 Minibatch[ 501- 600]: loss = 0.241031 * 100, metric = 7.49% * 100;
 Minibatch[ 601- 700]: loss = 0.247883 * 100, metric = 7.73% * 100;
 Minibatch[ 701- 800]: loss = 0.238957 * 100, metric = 7.71% * 100;
 Minibatch[ 801- 900]: loss = 0.236579 * 100, metric = 7.45% * 100;
 Minibatch[ 901-1000]: loss = 0.235471 * 100, metric = 7.18% * 100;
 Minibatch[1001-1100]: loss = 0.253884 * 100, metric = 8.29% * 100;
 Minibatch[1101-1200]: loss = 0.253305 * 100, metric = 8.00% * 100;
 Minibatch[1201-1300]: loss = 0.240844 * 100, metric = 7.58% * 100;
 Minibatch[1301-1400]: loss = 0.229074 * 100, metric = 6.99% * 100;
 Minibatch[1401-1500]: loss = 0.241329 * 100, metric = 7.77% * 100;
 Minibatch[1501-1600]: loss = 0.236374 * 100, metric = 7.39% * 100;
 Minibatch[1601-1700]: loss = 0.253802 * 100, metric = 8.12% * 100;
 Minibatch[1701-1800]: loss = 0.249786 * 100, metric = 7.98% * 100;
 Minibatch[1801-1900]: loss = 0.240707 * 100, metric = 7.60% * 100;
 Minibatch[1901-2000]: loss = 0.241956 * 100, metric = 7.61% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.242926 * 2000, metric = 7.66% * 2000 1039.823s (  1.9 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 17.32% * 2000;
 Minibatch[   1- 100]: loss = 0.237824 * 100, metric = 7.48% * 100;
 Minibatch[ 101- 200]: loss = 0.246874 * 100, metric = 7.87% * 100;
 Minibatch[ 201- 300]: loss = 0.241047 * 100, metric = 7.66% * 100;
 Minibatch[ 301- 400]: loss = 0.235692 * 100, metric = 7.39% * 100;
 Minibatch[ 401- 500]: loss = 0.234511 * 100, metric = 7.34% * 100;
 Minibatch[ 501- 600]: loss = 0.237730 * 100, metric = 7.38% * 100;
 Minibatch[ 601- 700]: loss = 0.232384 * 100, metric = 7.37% * 100;
 Minibatch[ 701- 800]: loss = 0.241616 * 100, metric = 7.70% * 100;
 Minibatch[ 801- 900]: loss = 0.247179 * 100, metric = 7.71% * 100;
 Minibatch[ 901-1000]: loss = 0.239168 * 100, metric = 7.69% * 100;
 Minibatch[1001-1100]: loss = 0.230628 * 100, metric = 7.43% * 100;
 Minibatch[1101-1200]: loss = 0.243105 * 100, metric = 7.63% * 100;
 Minibatch[1201-1300]: loss = 0.232928 * 100, metric = 7.35% * 100;
 Minibatch[1301-1400]: loss = 0.247830 * 100, metric = 7.98% * 100;
 Minibatch[1401-1500]: loss = 0.235262 * 100, metric = 7.59% * 100;
 Minibatch[1501-1600]: loss = 0.239809 * 100, metric = 7.63% * 100;
 Minibatch[1601-1700]: loss = 0.226193 * 100, metric = 6.97% * 100;
 Minibatch[1701-1800]: loss = 0.235237 * 100, metric = 7.20% * 100;
 Minibatch[1801-1900]: loss = 0.232721 * 100, metric = 7.21% * 100;
 Minibatch[1901-2000]: loss = 0.239771 * 100, metric = 7.44% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.237875 * 2000, metric = 7.50% * 2000 1053.443s (  1.9 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 15.75% * 2000;
 Minibatch[   1- 100]: loss = 0.242958 * 100, metric = 7.79% * 100;
 Minibatch[ 101- 200]: loss = 0.233322 * 100, metric = 7.25% * 100;
 Minibatch[ 201- 300]: loss = 0.238302 * 100, metric = 7.53% * 100;
 Minibatch[ 301- 400]: loss = 0.236987 * 100, metric = 7.26% * 100;
 Minibatch[ 401- 500]: loss = 0.239963 * 100, metric = 7.69% * 100;
 Minibatch[ 501- 600]: loss = 0.246637 * 100, metric = 7.98% * 100;
 Minibatch[ 601- 700]: loss = 0.228742 * 100, metric = 7.25% * 100;
 Minibatch[ 701- 800]: loss = 0.220595 * 100, metric = 7.11% * 100;
 Minibatch[ 801- 900]: loss = 0.241181 * 100, metric = 7.61% * 100;
 Minibatch[ 901-1000]: loss = 0.242570 * 100, metric = 7.70% * 100;
 Minibatch[1001-1100]: loss = 0.239331 * 100, metric = 7.67% * 100;
 Minibatch[1101-1200]: loss = 0.223910 * 100, metric = 6.98% * 100;
 Minibatch[1201-1300]: loss = 0.235444 * 100, metric = 7.53% * 100;
 Minibatch[1301-1400]: loss = 0.224785 * 100, metric = 7.10% * 100;
 Minibatch[1401-1500]: loss = 0.233726 * 100, metric = 7.27% * 100;
 Minibatch[1501-1600]: loss = 0.223194 * 100, metric = 6.92% * 100;
 Minibatch[1601-1700]: loss = 0.229609 * 100, metric = 7.13% * 100;
 Minibatch[1701-1800]: loss = 0.225705 * 100, metric = 7.01% * 100;
 Minibatch[1801-1900]: loss = 0.228508 * 100, metric = 7.17% * 100;
 Minibatch[1901-2000]: loss = 0.229086 * 100, metric = 7.26% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.233228 * 2000, metric = 7.36% * 2000 1050.849s (  1.9 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 15.82% * 2000;
 Minibatch[   1- 100]: loss = 0.223042 * 100, metric = 6.95% * 100;
 Minibatch[ 101- 200]: loss = 0.229507 * 100, metric = 7.16% * 100;
 Minibatch[ 201- 300]: loss = 0.237122 * 100, metric = 7.69% * 100;
 Minibatch[ 301- 400]: loss = 0.236379 * 100, metric = 7.55% * 100;
 Minibatch[ 401- 500]: loss = 0.214469 * 100, metric = 6.70% * 100;
 Minibatch[ 501- 600]: loss = 0.226329 * 100, metric = 7.24% * 100;
 Minibatch[ 601- 700]: loss = 0.228868 * 100, metric = 7.28% * 100;
 Minibatch[ 701- 800]: loss = 0.233622 * 100, metric = 7.49% * 100;
 Minibatch[ 801- 900]: loss = 0.225858 * 100, metric = 7.19% * 100;
 Minibatch[ 901-1000]: loss = 0.231543 * 100, metric = 7.46% * 100;
 Minibatch[1001-1100]: loss = 0.228481 * 100, metric = 7.30% * 100;
 Minibatch[1101-1200]: loss = 0.223282 * 100, metric = 7.01% * 100;
 Minibatch[1201-1300]: loss = 0.231446 * 100, metric = 7.32% * 100;
 Minibatch[1301-1400]: loss = 0.219720 * 100, metric = 6.80% * 100;
 Minibatch[1401-1500]: loss = 0.235007 * 100, metric = 7.46% * 100;
 Minibatch[1501-1600]: loss = 0.218642 * 100, metric = 6.89% * 100;
 Minibatch[1601-1700]: loss = 0.231508 * 100, metric = 7.37% * 100;
 Minibatch[1701-1800]: loss = 0.215580 * 100, metric = 6.88% * 100;
 Minibatch[1801-1900]: loss = 0.235951 * 100, metric = 7.58% * 100;
 Minibatch[1901-2000]: loss = 0.227068 * 100, metric = 7.33% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.227671 * 2000, metric = 7.23% * 2000 1046.274s (  1.9 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 16.66% * 2000;
 Minibatch[   1- 100]: loss = 0.240503 * 100, metric = 7.67% * 100;
 Minibatch[ 101- 200]: loss = 0.214530 * 100, metric = 6.72% * 100;
 Minibatch[ 201- 300]: loss = 0.222431 * 100, metric = 7.03% * 100;
 Minibatch[ 301- 400]: loss = 0.227503 * 100, metric = 7.26% * 100;
 Minibatch[ 401- 500]: loss = 0.223958 * 100, metric = 7.14% * 100;
 Minibatch[ 501- 600]: loss = 0.207581 * 100, metric = 6.48% * 100;
 Minibatch[ 601- 700]: loss = 0.225908 * 100, metric = 7.28% * 100;
 Minibatch[ 701- 800]: loss = 0.213267 * 100, metric = 6.63% * 100;
 Minibatch[ 801- 900]: loss = 0.232379 * 100, metric = 7.24% * 100;
 Minibatch[ 901-1000]: loss = 0.207398 * 100, metric = 6.40% * 100;
 Minibatch[1001-1100]: loss = 0.224678 * 100, metric = 6.89% * 100;
 Minibatch[1101-1200]: loss = 0.232169 * 100, metric = 7.42% * 100;
 Minibatch[1201-1300]: loss = 0.216326 * 100, metric = 6.73% * 100;
 Minibatch[1301-1400]: loss = 0.222338 * 100, metric = 7.08% * 100;
 Minibatch[1401-1500]: loss = 0.218430 * 100, metric = 6.87% * 100;
 Minibatch[1501-1600]: loss = 0.228241 * 100, metric = 7.38% * 100;
 Minibatch[1601-1700]: loss = 0.226295 * 100, metric = 7.07% * 100;
 Minibatch[1701-1800]: loss = 0.228076 * 100, metric = 7.26% * 100;
 Minibatch[1801-1900]: loss = 0.223962 * 100, metric = 7.21% * 100;
 Minibatch[1901-2000]: loss = 0.233759 * 100, metric = 7.36% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.223487 * 2000, metric = 7.06% * 2000 1030.717s (  1.9 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 16.45% * 2000;
 Minibatch[   1- 100]: loss = 0.215639 * 100, metric = 6.56% * 100;
 Minibatch[ 101- 200]: loss = 0.232626 * 100, metric = 7.57% * 100;
 Minibatch[ 201- 300]: loss = 0.222411 * 100, metric = 6.92% * 100;
 Minibatch[ 301- 400]: loss = 0.222453 * 100, metric = 7.26% * 100;
 Minibatch[ 401- 500]: loss = 0.224229 * 100, metric = 7.08% * 100;
 Minibatch[ 501- 600]: loss = 0.220498 * 100, metric = 7.00% * 100;
 Minibatch[ 601- 700]: loss = 0.230742 * 100, metric = 7.47% * 100;
 Minibatch[ 701- 800]: loss = 0.223612 * 100, metric = 7.12% * 100;
 Minibatch[ 801- 900]: loss = 0.221821 * 100, metric = 7.00% * 100;
 Minibatch[ 901-1000]: loss = 0.215191 * 100, metric = 6.72% * 100;
 Minibatch[1001-1100]: loss = 0.212795 * 100, metric = 6.66% * 100;
 Minibatch[1101-1200]: loss = 0.224558 * 100, metric = 7.30% * 100;
 Minibatch[1201-1300]: loss = 0.220688 * 100, metric = 7.07% * 100;
 Minibatch[1301-1400]: loss = 0.222956 * 100, metric = 7.06% * 100;
 Minibatch[1401-1500]: loss = 0.226703 * 100, metric = 7.10% * 100;
 Minibatch[1501-1600]: loss = 0.211526 * 100, metric = 6.60% * 100;
 Minibatch[1601-1700]: loss = 0.219161 * 100, metric = 6.91% * 100;
 Minibatch[1701-1800]: loss = 0.222019 * 100, metric = 7.22% * 100;
 Minibatch[1801-1900]: loss = 0.222802 * 100, metric = 7.04% * 100;
 Minibatch[1901-2000]: loss = 0.222586 * 100, metric = 7.15% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.221751 * 2000, metric = 7.04% * 2000 936.039s (  2.1 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 15.79% * 2000;
 Minibatch[   1- 100]: loss = 0.220947 * 100, metric = 6.94% * 100;
 Minibatch[ 101- 200]: loss = 0.219095 * 100, metric = 6.86% * 100;
 Minibatch[ 201- 300]: loss = 0.235339 * 100, metric = 7.54% * 100;
 Minibatch[ 301- 400]: loss = 0.232112 * 100, metric = 7.22% * 100;
 Minibatch[ 401- 500]: loss = 0.221931 * 100, metric = 7.11% * 100;
 Minibatch[ 501- 600]: loss = 0.217048 * 100, metric = 6.80% * 100;
 Minibatch[ 601- 700]: loss = 0.214880 * 100, metric = 6.68% * 100;
 Minibatch[ 701- 800]: loss = 0.212867 * 100, metric = 6.72% * 100;
 Minibatch[ 801- 900]: loss = 0.222063 * 100, metric = 6.93% * 100;
 Minibatch[ 901-1000]: loss = 0.211402 * 100, metric = 6.70% * 100;
 Minibatch[1001-1100]: loss = 0.205640 * 100, metric = 6.49% * 100;
 Minibatch[1101-1200]: loss = 0.220272 * 100, metric = 6.87% * 100;
 Minibatch[1201-1300]: loss = 0.224892 * 100, metric = 7.20% * 100;
 Minibatch[1301-1400]: loss = 0.224131 * 100, metric = 7.13% * 100;
 Minibatch[1401-1500]: loss = 0.218008 * 100, metric = 6.90% * 100;
 Minibatch[1501-1600]: loss = 0.227125 * 100, metric = 7.12% * 100;
 Minibatch[1601-1700]: loss = 0.211269 * 100, metric = 6.65% * 100;
 Minibatch[1701-1800]: loss = 0.225374 * 100, metric = 7.14% * 100;
 Minibatch[1801-1900]: loss = 0.208355 * 100, metric = 6.61% * 100;
 Minibatch[1901-2000]: loss = 0.221947 * 100, metric = 7.13% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.219735 * 2000, metric = 6.94% * 2000 893.657s (  2.2 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 15.50% * 2000;
 Minibatch[   1- 100]: loss = 0.232137 * 100, metric = 7.31% * 100;
 Minibatch[ 101- 200]: loss = 0.218794 * 100, metric = 6.97% * 100;
 Minibatch[ 201- 300]: loss = 0.214421 * 100, metric = 6.88% * 100;
 Minibatch[ 301- 400]: loss = 0.219621 * 100, metric = 7.17% * 100;
 Minibatch[ 401- 500]: loss = 0.211831 * 100, metric = 6.63% * 100;
 Minibatch[ 501- 600]: loss = 0.213103 * 100, metric = 6.69% * 100;
 Minibatch[ 601- 700]: loss = 0.221510 * 100, metric = 7.04% * 100;
 Minibatch[ 701- 800]: loss = 0.213496 * 100, metric = 6.69% * 100;
 Minibatch[ 801- 900]: loss = 0.210336 * 100, metric = 6.57% * 100;
 Minibatch[ 901-1000]: loss = 0.209722 * 100, metric = 6.65% * 100;
 Minibatch[1001-1100]: loss = 0.209566 * 100, metric = 6.65% * 100;
 Minibatch[1101-1200]: loss = 0.204440 * 100, metric = 6.50% * 100;
 Minibatch[1201-1300]: loss = 0.228171 * 100, metric = 7.03% * 100;
 Minibatch[1301-1400]: loss = 0.204578 * 100, metric = 6.42% * 100;
 Minibatch[1401-1500]: loss = 0.226859 * 100, metric = 6.96% * 100;
 Minibatch[1501-1600]: loss = 0.221891 * 100, metric = 7.05% * 100;
 Minibatch[1601-1700]: loss = 0.211974 * 100, metric = 6.55% * 100;
 Minibatch[1701-1800]: loss = 0.204415 * 100, metric = 6.31% * 100;
 Minibatch[1801-1900]: loss = 0.207673 * 100, metric = 6.47% * 100;
 Minibatch[1901-2000]: loss = 0.226378 * 100, metric = 7.26% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.215546 * 2000, metric = 6.79% * 2000 888.933s (  2.2 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 15.48% * 2000;
0.4515294298194349
 Minibatch[   1- 100]: loss = 0.211026 * 100, metric = 6.75% * 100;
 Minibatch[ 101- 200]: loss = 0.215568 * 100, metric = 6.78% * 100;
 Minibatch[ 201- 300]: loss = 0.208562 * 100, metric = 6.59% * 100;
 Minibatch[ 301- 400]: loss = 0.218574 * 100, metric = 6.78% * 100;
 Minibatch[ 401- 500]: loss = 0.212596 * 100, metric = 6.69% * 100;
 Minibatch[ 501- 600]: loss = 0.220605 * 100, metric = 6.87% * 100;
 Minibatch[ 601- 700]: loss = 0.215264 * 100, metric = 6.80% * 100;
 Minibatch[ 701- 800]: loss = 0.210255 * 100, metric = 6.68% * 100;
 Minibatch[ 801- 900]: loss = 0.204601 * 100, metric = 6.15% * 100;
 Minibatch[ 901-1000]: loss = 0.212772 * 100, metric = 6.82% * 100;
 Minibatch[1001-1100]: loss = 0.213288 * 100, metric = 6.68% * 100;
 Minibatch[1101-1200]: loss = 0.210226 * 100, metric = 6.73% * 100;
 Minibatch[1201-1300]: loss = 0.211994 * 100, metric = 6.67% * 100;
 Minibatch[1301-1400]: loss = 0.212544 * 100, metric = 6.66% * 100;
 Minibatch[1401-1500]: loss = 0.217051 * 100, metric = 6.97% * 100;
 Minibatch[1501-1600]: loss = 0.216649 * 100, metric = 6.92% * 100;
 Minibatch[1601-1700]: loss = 0.221326 * 100, metric = 7.23% * 100;
 Minibatch[1701-1800]: loss = 0.204339 * 100, metric = 6.45% * 100;
 Minibatch[1801-1900]: loss = 0.207787 * 100, metric = 6.59% * 100;
 Minibatch[1901-2000]: loss = 0.203317 * 100, metric = 6.50% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.212417 * 2000, metric = 6.72% * 2000 886.563s (  2.3 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 15.90% * 2000;
 Minibatch[   1- 100]: loss = 0.195319 * 100, metric = 5.96% * 100;
 Minibatch[ 101- 200]: loss = 0.211366 * 100, metric = 6.77% * 100;
 Minibatch[ 201- 300]: loss = 0.207988 * 100, metric = 6.66% * 100;
 Minibatch[ 301- 400]: loss = 0.197466 * 100, metric = 6.06% * 100;
 Minibatch[ 401- 500]: loss = 0.206230 * 100, metric = 6.50% * 100;
 Minibatch[ 501- 600]: loss = 0.194736 * 100, metric = 5.96% * 100;
 Minibatch[ 601- 700]: loss = 0.207355 * 100, metric = 6.63% * 100;
 Minibatch[ 701- 800]: loss = 0.196906 * 100, metric = 6.18% * 100;
 Minibatch[ 801- 900]: loss = 0.209829 * 100, metric = 6.71% * 100;
 Minibatch[ 901-1000]: loss = 0.199546 * 100, metric = 6.35% * 100;
 Minibatch[1001-1100]: loss = 0.214965 * 100, metric = 6.67% * 100;
 Minibatch[1101-1200]: loss = 0.199937 * 100, metric = 6.24% * 100;
 Minibatch[1201-1300]: loss = 0.203260 * 100, metric = 6.45% * 100;
 Minibatch[1301-1400]: loss = 0.217425 * 100, metric = 6.94% * 100;
 Minibatch[1401-1500]: loss = 0.201992 * 100, metric = 6.31% * 100;
 Minibatch[1501-1600]: loss = 0.206427 * 100, metric = 6.58% * 100;
 Minibatch[1601-1700]: loss = 0.207710 * 100, metric = 6.56% * 100;
 Minibatch[1701-1800]: loss = 0.199498 * 100, metric = 6.22% * 100;
 Minibatch[1801-1900]: loss = 0.209254 * 100, metric = 6.59% * 100;
 Minibatch[1901-2000]: loss = 0.195292 * 100, metric = 6.26% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.204125 * 2000, metric = 6.43% * 2000 877.776s (  2.3 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 15.71% * 2000;
 Minibatch[   1- 100]: loss = 0.191272 * 100, metric = 5.90% * 100;
 Minibatch[ 101- 200]: loss = 0.188937 * 100, metric = 5.98% * 100;
 Minibatch[ 201- 300]: loss = 0.214292 * 100, metric = 6.81% * 100;
 Minibatch[ 301- 400]: loss = 0.201331 * 100, metric = 6.42% * 100;
 Minibatch[ 401- 500]: loss = 0.196351 * 100, metric = 6.21% * 100;
 Minibatch[ 501- 600]: loss = 0.201990 * 100, metric = 6.41% * 100;
 Minibatch[ 601- 700]: loss = 0.205378 * 100, metric = 6.36% * 100;
 Minibatch[ 701- 800]: loss = 0.194141 * 100, metric = 6.04% * 100;
 Minibatch[ 801- 900]: loss = 0.196967 * 100, metric = 6.16% * 100;
 Minibatch[ 901-1000]: loss = 0.207264 * 100, metric = 6.67% * 100;
 Minibatch[1001-1100]: loss = 0.210984 * 100, metric = 6.62% * 100;
 Minibatch[1101-1200]: loss = 0.203929 * 100, metric = 6.38% * 100;
 Minibatch[1201-1300]: loss = 0.204459 * 100, metric = 6.38% * 100;
 Minibatch[1301-1400]: loss = 0.187389 * 100, metric = 5.97% * 100;
 Minibatch[1401-1500]: loss = 0.196714 * 100, metric = 6.04% * 100;
 Minibatch[1501-1600]: loss = 0.198845 * 100, metric = 6.25% * 100;
 Minibatch[1601-1700]: loss = 0.212983 * 100, metric = 6.83% * 100;
 Minibatch[1701-1800]: loss = 0.201944 * 100, metric = 6.37% * 100;
 Minibatch[1801-1900]: loss = 0.196873 * 100, metric = 6.22% * 100;
 Minibatch[1901-2000]: loss = 0.200836 * 100, metric = 6.35% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.200644 * 2000, metric = 6.32% * 2000 882.033s (  2.3 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 14.91% * 2000;
0.4475962165296078
 Minibatch[   1- 100]: loss = 0.198897 * 100, metric = 6.21% * 100;
 Minibatch[ 101- 200]: loss = 0.208797 * 100, metric = 6.50% * 100;
 Minibatch[ 201- 300]: loss = 0.202899 * 100, metric = 6.34% * 100;
 Minibatch[ 301- 400]: loss = 0.204437 * 100, metric = 6.57% * 100;
 Minibatch[ 401- 500]: loss = 0.203766 * 100, metric = 6.52% * 100;
 Minibatch[ 501- 600]: loss = 0.190414 * 100, metric = 6.15% * 100;
 Minibatch[ 601- 700]: loss = 0.198584 * 100, metric = 6.44% * 100;
 Minibatch[ 701- 800]: loss = 0.209728 * 100, metric = 6.63% * 100;
 Minibatch[ 801- 900]: loss = 0.201638 * 100, metric = 6.47% * 100;
 Minibatch[ 901-1000]: loss = 0.189521 * 100, metric = 5.98% * 100;
 Minibatch[1001-1100]: loss = 0.196723 * 100, metric = 6.28% * 100;
 Minibatch[1101-1200]: loss = 0.208356 * 100, metric = 6.57% * 100;
 Minibatch[1201-1300]: loss = 0.206074 * 100, metric = 6.47% * 100;
 Minibatch[1301-1400]: loss = 0.196504 * 100, metric = 6.24% * 100;
 Minibatch[1401-1500]: loss = 0.206013 * 100, metric = 6.58% * 100;
 Minibatch[1501-1600]: loss = 0.194760 * 100, metric = 6.15% * 100;
 Minibatch[1601-1700]: loss = 0.199950 * 100, metric = 6.43% * 100;
 Minibatch[1701-1800]: loss = 0.195359 * 100, metric = 6.17% * 100;
 Minibatch[1801-1900]: loss = 0.198502 * 100, metric = 6.21% * 100;
 Minibatch[1901-2000]: loss = 0.193727 * 100, metric = 6.06% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.200232 * 2000, metric = 6.35% * 2000 877.307s (  2.3 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 15.01% * 2000;
 Minibatch[   1- 100]: loss = 0.198907 * 100, metric = 6.37% * 100;
 Minibatch[ 101- 200]: loss = 0.194335 * 100, metric = 6.22% * 100;
 Minibatch[ 201- 300]: loss = 0.185985 * 100, metric = 5.63% * 100;
 Minibatch[ 301- 400]: loss = 0.189234 * 100, metric = 6.12% * 100;
 Minibatch[ 401- 500]: loss = 0.194420 * 100, metric = 6.16% * 100;
 Minibatch[ 501- 600]: loss = 0.188419 * 100, metric = 5.85% * 100;
 Minibatch[ 601- 700]: loss = 0.198642 * 100, metric = 6.29% * 100;
 Minibatch[ 701- 800]: loss = 0.196317 * 100, metric = 6.24% * 100;
 Minibatch[ 801- 900]: loss = 0.200610 * 100, metric = 6.40% * 100;
 Minibatch[ 901-1000]: loss = 0.193156 * 100, metric = 6.09% * 100;
 Minibatch[1001-1100]: loss = 0.197095 * 100, metric = 6.30% * 100;
 Minibatch[1101-1200]: loss = 0.190627 * 100, metric = 6.08% * 100;
 Minibatch[1201-1300]: loss = 0.194622 * 100, metric = 6.27% * 100;
 Minibatch[1301-1400]: loss = 0.202087 * 100, metric = 6.37% * 100;
 Minibatch[1401-1500]: loss = 0.196851 * 100, metric = 6.31% * 100;
 Minibatch[1501-1600]: loss = 0.193872 * 100, metric = 6.13% * 100;
 Minibatch[1601-1700]: loss = 0.195175 * 100, metric = 6.16% * 100;
 Minibatch[1701-1800]: loss = 0.197468 * 100, metric = 6.31% * 100;
 Minibatch[1801-1900]: loss = 0.194221 * 100, metric = 6.30% * 100;
 Minibatch[1901-2000]: loss = 0.192166 * 100, metric = 6.13% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.194710 * 2000, metric = 6.19% * 2000 858.942s (  2.3 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 14.80% * 2000;
 Minibatch[   1- 100]: loss = 0.194079 * 100, metric = 6.20% * 100;
 Minibatch[ 101- 200]: loss = 0.199485 * 100, metric = 6.31% * 100;
 Minibatch[ 201- 300]: loss = 0.193503 * 100, metric = 6.00% * 100;
 Minibatch[ 301- 400]: loss = 0.186173 * 100, metric = 5.75% * 100;
 Minibatch[ 401- 500]: loss = 0.192555 * 100, metric = 6.21% * 100;
 Minibatch[ 501- 600]: loss = 0.199223 * 100, metric = 6.29% * 100;
 Minibatch[ 601- 700]: loss = 0.199652 * 100, metric = 6.36% * 100;
 Minibatch[ 701- 800]: loss = 0.197378 * 100, metric = 6.31% * 100;
 Minibatch[ 801- 900]: loss = 0.186344 * 100, metric = 5.95% * 100;
 Minibatch[ 901-1000]: loss = 0.187381 * 100, metric = 5.84% * 100;
 Minibatch[1001-1100]: loss = 0.204725 * 100, metric = 6.48% * 100;
 Minibatch[1101-1200]: loss = 0.195034 * 100, metric = 6.16% * 100;
 Minibatch[1201-1300]: loss = 0.193855 * 100, metric = 6.15% * 100;
 Minibatch[1301-1400]: loss = 0.203264 * 100, metric = 6.26% * 100;
 Minibatch[1401-1500]: loss = 0.198857 * 100, metric = 6.35% * 100;
 Minibatch[1501-1600]: loss = 0.196424 * 100, metric = 6.04% * 100;
 Minibatch[1601-1700]: loss = 0.187806 * 100, metric = 5.92% * 100;
 Minibatch[1701-1800]: loss = 0.196888 * 100, metric = 6.23% * 100;
 Minibatch[1801-1900]: loss = 0.186986 * 100, metric = 5.96% * 100;
 Minibatch[1901-2000]: loss = 0.187608 * 100, metric = 5.82% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.194361 * 2000, metric = 6.13% * 2000 866.758s (  2.3 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 14.66% * 2000;
 Minibatch[   1- 100]: loss = 0.189491 * 100, metric = 5.97% * 100;
 Minibatch[ 101- 200]: loss = 0.185889 * 100, metric = 5.90% * 100;
 Minibatch[ 201- 300]: loss = 0.195286 * 100, metric = 6.17% * 100;
 Minibatch[ 301- 400]: loss = 0.196681 * 100, metric = 6.38% * 100;
 Minibatch[ 401- 500]: loss = 0.188040 * 100, metric = 5.93% * 100;
 Minibatch[ 501- 600]: loss = 0.192293 * 100, metric = 6.06% * 100;
 Minibatch[ 601- 700]: loss = 0.193367 * 100, metric = 6.14% * 100;
 Minibatch[ 701- 800]: loss = 0.183792 * 100, metric = 5.70% * 100;
 Minibatch[ 801- 900]: loss = 0.186360 * 100, metric = 5.86% * 100;
 Minibatch[ 901-1000]: loss = 0.183639 * 100, metric = 5.76% * 100;
 Minibatch[1001-1100]: loss = 0.200239 * 100, metric = 6.34% * 100;
 Minibatch[1101-1200]: loss = 0.186526 * 100, metric = 5.91% * 100;
 Minibatch[1201-1300]: loss = 0.188391 * 100, metric = 5.88% * 100;
 Minibatch[1301-1400]: loss = 0.193133 * 100, metric = 6.02% * 100;
 Minibatch[1401-1500]: loss = 0.182696 * 100, metric = 5.74% * 100;
 Minibatch[1501-1600]: loss = 0.193409 * 100, metric = 6.14% * 100;
 Minibatch[1601-1700]: loss = 0.188578 * 100, metric = 5.87% * 100;
 Minibatch[1701-1800]: loss = 0.183378 * 100, metric = 5.77% * 100;
 Minibatch[1801-1900]: loss = 0.183464 * 100, metric = 5.75% * 100;
 Minibatch[1901-2000]: loss = 0.193824 * 100, metric = 6.09% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.189424 * 2000, metric = 5.97% * 2000 855.042s (  2.3 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 14.52% * 2000;
 Minibatch[   1- 100]: loss = 0.184925 * 100, metric = 5.89% * 100;
 Minibatch[ 101- 200]: loss = 0.184314 * 100, metric = 5.66% * 100;
 Minibatch[ 201- 300]: loss = 0.195306 * 100, metric = 6.11% * 100;
 Minibatch[ 301- 400]: loss = 0.195375 * 100, metric = 6.13% * 100;
 Minibatch[ 401- 500]: loss = 0.188992 * 100, metric = 5.90% * 100;
 Minibatch[ 501- 600]: loss = 0.186006 * 100, metric = 5.84% * 100;
 Minibatch[ 601- 700]: loss = 0.195263 * 100, metric = 6.12% * 100;
 Minibatch[ 701- 800]: loss = 0.188792 * 100, metric = 5.96% * 100;
 Minibatch[ 801- 900]: loss = 0.183238 * 100, metric = 5.87% * 100;
 Minibatch[ 901-1000]: loss = 0.192277 * 100, metric = 6.19% * 100;
 Minibatch[1001-1100]: loss = 0.182147 * 100, metric = 5.72% * 100;
 Minibatch[1101-1200]: loss = 0.194089 * 100, metric = 6.06% * 100;
 Minibatch[1201-1300]: loss = 0.195200 * 100, metric = 6.16% * 100;
 Minibatch[1301-1400]: loss = 0.173566 * 100, metric = 5.30% * 100;
 Minibatch[1401-1500]: loss = 0.182964 * 100, metric = 5.69% * 100;
 Minibatch[1501-1600]: loss = 0.185110 * 100, metric = 6.05% * 100;
 Minibatch[1601-1700]: loss = 0.190510 * 100, metric = 5.94% * 100;
 Minibatch[1701-1800]: loss = 0.189030 * 100, metric = 6.08% * 100;
 Minibatch[1801-1900]: loss = 0.186759 * 100, metric = 5.94% * 100;
 Minibatch[1901-2000]: loss = 0.182713 * 100, metric = 5.71% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.187829 * 2000, metric = 5.92% * 2000 856.435s (  2.3 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 15.63% * 2000;
 Minibatch[   1- 100]: loss = 0.180595 * 100, metric = 5.79% * 100;
 Minibatch[ 101- 200]: loss = 0.186170 * 100, metric = 5.93% * 100;
 Minibatch[ 201- 300]: loss = 0.178230 * 100, metric = 5.67% * 100;
 Minibatch[ 301- 400]: loss = 0.181414 * 100, metric = 5.65% * 100;
 Minibatch[ 401- 500]: loss = 0.182387 * 100, metric = 5.78% * 100;
 Minibatch[ 501- 600]: loss = 0.184970 * 100, metric = 5.81% * 100;
 Minibatch[ 601- 700]: loss = 0.181031 * 100, metric = 5.76% * 100;
 Minibatch[ 701- 800]: loss = 0.179399 * 100, metric = 5.64% * 100;
 Minibatch[ 801- 900]: loss = 0.182947 * 100, metric = 5.78% * 100;
 Minibatch[ 901-1000]: loss = 0.191715 * 100, metric = 6.19% * 100;
 Minibatch[1001-1100]: loss = 0.187013 * 100, metric = 5.86% * 100;
 Minibatch[1101-1200]: loss = 0.187266 * 100, metric = 5.77% * 100;
 Minibatch[1201-1300]: loss = 0.179735 * 100, metric = 5.67% * 100;
 Minibatch[1301-1400]: loss = 0.184617 * 100, metric = 5.88% * 100;
 Minibatch[1401-1500]: loss = 0.179619 * 100, metric = 5.57% * 100;
 Minibatch[1501-1600]: loss = 0.183996 * 100, metric = 5.82% * 100;
 Minibatch[1601-1700]: loss = 0.183258 * 100, metric = 5.73% * 100;
 Minibatch[1701-1800]: loss = 0.179321 * 100, metric = 5.67% * 100;
 Minibatch[1801-1900]: loss = 0.182485 * 100, metric = 5.77% * 100;
 Minibatch[1901-2000]: loss = 0.182150 * 100, metric = 5.77% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.182916 * 2000, metric = 5.78% * 2000 854.375s (  2.3 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 14.23% * 2000;
 Minibatch[   1- 100]: loss = 0.199370 * 100, metric = 6.41% * 100;
 Minibatch[ 101- 200]: loss = 0.167583 * 100, metric = 5.32% * 100;
 Minibatch[ 201- 300]: loss = 0.188720 * 100, metric = 5.85% * 100;
 Minibatch[ 301- 400]: loss = 0.183996 * 100, metric = 5.85% * 100;
 Minibatch[ 401- 500]: loss = 0.179637 * 100, metric = 5.66% * 100;
 Minibatch[ 501- 600]: loss = 0.181673 * 100, metric = 5.70% * 100;
 Minibatch[ 601- 700]: loss = 0.192499 * 100, metric = 6.00% * 100;
 Minibatch[ 701- 800]: loss = 0.187993 * 100, metric = 6.04% * 100;
 Minibatch[ 801- 900]: loss = 0.180271 * 100, metric = 5.70% * 100;
 Minibatch[ 901-1000]: loss = 0.182526 * 100, metric = 5.82% * 100;
 Minibatch[1001-1100]: loss = 0.182592 * 100, metric = 5.83% * 100;
 Minibatch[1101-1200]: loss = 0.173817 * 100, metric = 5.50% * 100;
 Minibatch[1201-1300]: loss = 0.189426 * 100, metric = 6.20% * 100;
 Minibatch[1301-1400]: loss = 0.187904 * 100, metric = 6.05% * 100;
 Minibatch[1401-1500]: loss = 0.168463 * 100, metric = 5.30% * 100;
 Minibatch[1501-1600]: loss = 0.189434 * 100, metric = 5.89% * 100;
 Minibatch[1601-1700]: loss = 0.183664 * 100, metric = 5.84% * 100;
 Minibatch[1701-1800]: loss = 0.179453 * 100, metric = 5.74% * 100;
 Minibatch[1801-1900]: loss = 0.183811 * 100, metric = 5.85% * 100;
 Minibatch[1901-2000]: loss = 0.174735 * 100, metric = 5.67% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.182878 * 2000, metric = 5.81% * 2000 858.627s (  2.3 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 14.54% * 2000;
 Minibatch[   1- 100]: loss = 0.180875 * 100, metric = 5.85% * 100;
 Minibatch[ 101- 200]: loss = 0.182255 * 100, metric = 5.67% * 100;
 Minibatch[ 201- 300]: loss = 0.181950 * 100, metric = 5.72% * 100;
 Minibatch[ 301- 400]: loss = 0.184364 * 100, metric = 5.98% * 100;
 Minibatch[ 401- 500]: loss = 0.180529 * 100, metric = 5.73% * 100;
 Minibatch[ 501- 600]: loss = 0.180149 * 100, metric = 5.72% * 100;
 Minibatch[ 601- 700]: loss = 0.187166 * 100, metric = 5.96% * 100;
 Minibatch[ 701- 800]: loss = 0.163942 * 100, metric = 5.22% * 100;
 Minibatch[ 801- 900]: loss = 0.171094 * 100, metric = 5.28% * 100;
 Minibatch[ 901-1000]: loss = 0.171227 * 100, metric = 5.35% * 100;
 Minibatch[1001-1100]: loss = 0.175022 * 100, metric = 5.21% * 100;
 Minibatch[1101-1200]: loss = 0.165777 * 100, metric = 5.13% * 100;
 Minibatch[1201-1300]: loss = 0.173872 * 100, metric = 5.54% * 100;
 Minibatch[1301-1400]: loss = 0.170621 * 100, metric = 5.24% * 100;
 Minibatch[1401-1500]: loss = 0.170862 * 100, metric = 5.41% * 100;
 Minibatch[1501-1600]: loss = 0.167538 * 100, metric = 5.38% * 100;
 Minibatch[1601-1700]: loss = 0.172472 * 100, metric = 5.44% * 100;
 Minibatch[1701-1800]: loss = 0.181907 * 100, metric = 5.79% * 100;
 Minibatch[1801-1900]: loss = 0.175264 * 100, metric = 5.53% * 100;
 Minibatch[1901-2000]: loss = 0.169849 * 100, metric = 5.37% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.175337 * 2000, metric = 5.53% * 2000 850.207s (  2.4 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 14.61% * 2000;
 Minibatch[   1- 100]: loss = 0.177767 * 100, metric = 5.57% * 100;
 Minibatch[ 101- 200]: loss = 0.176051 * 100, metric = 5.34% * 100;
 Minibatch[ 201- 300]: loss = 0.175346 * 100, metric = 5.57% * 100;
 Minibatch[ 301- 400]: loss = 0.181049 * 100, metric = 5.79% * 100;
 Minibatch[ 401- 500]: loss = 0.175995 * 100, metric = 5.50% * 100;
 Minibatch[ 501- 600]: loss = 0.163581 * 100, metric = 5.12% * 100;
 Minibatch[ 601- 700]: loss = 0.166075 * 100, metric = 5.20% * 100;
 Minibatch[ 701- 800]: loss = 0.170248 * 100, metric = 5.43% * 100;
 Minibatch[ 801- 900]: loss = 0.185976 * 100, metric = 5.98% * 100;
 Minibatch[ 901-1000]: loss = 0.168249 * 100, metric = 5.45% * 100;
 Minibatch[1001-1100]: loss = 0.170619 * 100, metric = 5.24% * 100;
 Minibatch[1101-1200]: loss = 0.179647 * 100, metric = 5.48% * 100;
 Minibatch[1201-1300]: loss = 0.178508 * 100, metric = 5.70% * 100;
 Minibatch[1301-1400]: loss = 0.164846 * 100, metric = 5.20% * 100;
 Minibatch[1401-1500]: loss = 0.177305 * 100, metric = 5.75% * 100;
 Minibatch[1501-1600]: loss = 0.168885 * 100, metric = 5.41% * 100;
 Minibatch[1601-1700]: loss = 0.171451 * 100, metric = 5.56% * 100;
 Minibatch[1701-1800]: loss = 0.177628 * 100, metric = 5.60% * 100;
 Minibatch[1801-1900]: loss = 0.177716 * 100, metric = 5.79% * 100;
 Minibatch[1901-2000]: loss = 0.166447 * 100, metric = 5.19% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.173669 * 2000, metric = 5.49% * 2000 855.957s (  2.3 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 15.39% * 2000;
 Minibatch[   1- 100]: loss = 0.168415 * 100, metric = 5.42% * 100;
 Minibatch[ 101- 200]: loss = 0.177989 * 100, metric = 5.66% * 100;
 Minibatch[ 201- 300]: loss = 0.170061 * 100, metric = 5.37% * 100;
 Minibatch[ 301- 400]: loss = 0.184225 * 100, metric = 5.70% * 100;
 Minibatch[ 401- 500]: loss = 0.171746 * 100, metric = 5.29% * 100;
 Minibatch[ 501- 600]: loss = 0.173620 * 100, metric = 5.60% * 100;
 Minibatch[ 601- 700]: loss = 0.162210 * 100, metric = 5.14% * 100;
 Minibatch[ 701- 800]: loss = 0.163481 * 100, metric = 5.07% * 100;
 Minibatch[ 801- 900]: loss = 0.164698 * 100, metric = 5.22% * 100;
 Minibatch[ 901-1000]: loss = 0.171606 * 100, metric = 5.38% * 100;
 Minibatch[1001-1100]: loss = 0.168523 * 100, metric = 5.27% * 100;
 Minibatch[1101-1200]: loss = 0.174160 * 100, metric = 5.55% * 100;
 Minibatch[1201-1300]: loss = 0.164366 * 100, metric = 5.19% * 100;
 Minibatch[1301-1400]: loss = 0.170685 * 100, metric = 5.36% * 100;
 Minibatch[1401-1500]: loss = 0.160288 * 100, metric = 5.15% * 100;
 Minibatch[1501-1600]: loss = 0.170328 * 100, metric = 5.28% * 100;
 Minibatch[1601-1700]: loss = 0.165124 * 100, metric = 5.12% * 100;
 Minibatch[1701-1800]: loss = 0.181537 * 100, metric = 5.79% * 100;
 Minibatch[1801-1900]: loss = 0.162836 * 100, metric = 5.02% * 100;
 Minibatch[1901-2000]: loss = 0.168482 * 100, metric = 5.33% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.169719 * 2000, metric = 5.34% * 2000 858.554s (  2.3 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 14.25% * 2000;
 Minibatch[   1- 100]: loss = 0.167675 * 100, metric = 5.29% * 100;
 Minibatch[ 101- 200]: loss = 0.168668 * 100, metric = 5.38% * 100;
 Minibatch[ 201- 300]: loss = 0.169780 * 100, metric = 5.34% * 100;
 Minibatch[ 301- 400]: loss = 0.161635 * 100, metric = 5.05% * 100;
 Minibatch[ 401- 500]: loss = 0.166858 * 100, metric = 5.25% * 100;
 Minibatch[ 501- 600]: loss = 0.166397 * 100, metric = 5.21% * 100;
 Minibatch[ 601- 700]: loss = 0.171660 * 100, metric = 5.44% * 100;
 Minibatch[ 701- 800]: loss = 0.175541 * 100, metric = 5.58% * 100;
 Minibatch[ 801- 900]: loss = 0.163548 * 100, metric = 5.14% * 100;
 Minibatch[ 901-1000]: loss = 0.168195 * 100, metric = 5.28% * 100;
 Minibatch[1001-1100]: loss = 0.180392 * 100, metric = 5.68% * 100;
 Minibatch[1101-1200]: loss = 0.168723 * 100, metric = 5.29% * 100;
 Minibatch[1201-1300]: loss = 0.156933 * 100, metric = 4.84% * 100;
 Minibatch[1301-1400]: loss = 0.170883 * 100, metric = 5.37% * 100;
 Minibatch[1401-1500]: loss = 0.168544 * 100, metric = 5.25% * 100;
 Minibatch[1501-1600]: loss = 0.171086 * 100, metric = 5.40% * 100;
 Minibatch[1601-1700]: loss = 0.165706 * 100, metric = 5.19% * 100;
 Minibatch[1701-1800]: loss = 0.174197 * 100, metric = 5.54% * 100;
 Minibatch[1801-1900]: loss = 0.169250 * 100, metric = 5.27% * 100;
 Minibatch[1901-2000]: loss = 0.172669 * 100, metric = 5.49% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.168917 * 2000, metric = 5.31% * 2000 857.116s (  2.3 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 13.59% * 2000;
 Minibatch[   1- 100]: loss = 0.169243 * 100, metric = 5.33% * 100;
 Minibatch[ 101- 200]: loss = 0.170523 * 100, metric = 5.52% * 100;
 Minibatch[ 201- 300]: loss = 0.175522 * 100, metric = 5.56% * 100;
 Minibatch[ 301- 400]: loss = 0.169717 * 100, metric = 5.29% * 100;
 Minibatch[ 401- 500]: loss = 0.171464 * 100, metric = 5.42% * 100;
 Minibatch[ 501- 600]: loss = 0.182353 * 100, metric = 5.59% * 100;
 Minibatch[ 601- 700]: loss = 0.181901 * 100, metric = 5.59% * 100;
 Minibatch[ 701- 800]: loss = 0.167357 * 100, metric = 5.09% * 100;
 Minibatch[ 801- 900]: loss = 0.159043 * 100, metric = 4.94% * 100;
 Minibatch[ 901-1000]: loss = 0.170305 * 100, metric = 5.50% * 100;
 Minibatch[1001-1100]: loss = 0.170646 * 100, metric = 5.40% * 100;
 Minibatch[1101-1200]: loss = 0.167339 * 100, metric = 5.36% * 100;
 Minibatch[1201-1300]: loss = 0.166348 * 100, metric = 5.22% * 100;
 Minibatch[1301-1400]: loss = 0.166085 * 100, metric = 5.22% * 100;
 Minibatch[1401-1500]: loss = 0.162546 * 100, metric = 5.22% * 100;
 Minibatch[1501-1600]: loss = 0.169090 * 100, metric = 5.38% * 100;
 Minibatch[1601-1700]: loss = 0.163661 * 100, metric = 5.20% * 100;
 Minibatch[1701-1800]: loss = 0.165020 * 100, metric = 5.08% * 100;
 Minibatch[1801-1900]: loss = 0.167007 * 100, metric = 5.34% * 100;
 Minibatch[1901-2000]: loss = 0.158412 * 100, metric = 5.05% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.168679 * 2000, metric = 5.31% * 2000 851.342s (  2.3 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 13.73% * 2000;
0.4440059112086892
 Minibatch[   1- 100]: loss = 0.173333 * 100, metric = 5.55% * 100;
 Minibatch[ 101- 200]: loss = 0.165152 * 100, metric = 5.15% * 100;
 Minibatch[ 201- 300]: loss = 0.174745 * 100, metric = 5.55% * 100;
 Minibatch[ 301- 400]: loss = 0.168496 * 100, metric = 5.26% * 100;
 Minibatch[ 401- 500]: loss = 0.174693 * 100, metric = 5.67% * 100;
 Minibatch[ 501- 600]: loss = 0.168431 * 100, metric = 5.39% * 100;
 Minibatch[ 601- 700]: loss = 0.164645 * 100, metric = 5.16% * 100;
 Minibatch[ 701- 800]: loss = 0.164610 * 100, metric = 5.15% * 100;
 Minibatch[ 801- 900]: loss = 0.157336 * 100, metric = 5.00% * 100;
 Minibatch[ 901-1000]: loss = 0.176528 * 100, metric = 5.62% * 100;
 Minibatch[1001-1100]: loss = 0.170879 * 100, metric = 5.40% * 100;
 Minibatch[1101-1200]: loss = 0.170506 * 100, metric = 5.48% * 100;
 Minibatch[1201-1300]: loss = 0.157482 * 100, metric = 5.00% * 100;
 Minibatch[1301-1400]: loss = 0.170765 * 100, metric = 5.47% * 100;
 Minibatch[1401-1500]: loss = 0.165090 * 100, metric = 5.31% * 100;
 Minibatch[1501-1600]: loss = 0.152207 * 100, metric = 4.82% * 100;
 Minibatch[1601-1700]: loss = 0.175881 * 100, metric = 5.75% * 100;
 Minibatch[1701-1800]: loss = 0.172419 * 100, metric = 5.54% * 100;
 Minibatch[1801-1900]: loss = 0.166052 * 100, metric = 5.40% * 100;
 Minibatch[1901-2000]: loss = 0.162909 * 100, metric = 5.14% * 100;
Finished Epoch[49 of 200]: [Training] loss = 0.167608 * 2000, metric = 5.34% * 2000 854.451s (  2.3 samples/s);
Finished Evaluation [49]: Minibatch[1-2000]: metric = 13.21% * 2000;
 Minibatch[   1- 100]: loss = 0.170440 * 100, metric = 5.50% * 100;
 Minibatch[ 101- 200]: loss = 0.158160 * 100, metric = 4.98% * 100;
 Minibatch[ 201- 300]: loss = 0.161000 * 100, metric = 4.98% * 100;
 Minibatch[ 301- 400]: loss = 0.161218 * 100, metric = 5.25% * 100;
 Minibatch[ 401- 500]: loss = 0.163765 * 100, metric = 5.25% * 100;
 Minibatch[ 501- 600]: loss = 0.171473 * 100, metric = 5.38% * 100;
 Minibatch[ 601- 700]: loss = 0.161384 * 100, metric = 5.11% * 100;
 Minibatch[ 701- 800]: loss = 0.156477 * 100, metric = 4.86% * 100;
 Minibatch[ 801- 900]: loss = 0.162558 * 100, metric = 5.12% * 100;
 Minibatch[ 901-1000]: loss = 0.163478 * 100, metric = 5.09% * 100;
 Minibatch[1001-1100]: loss = 0.157360 * 100, metric = 5.02% * 100;
 Minibatch[1101-1200]: loss = 0.163509 * 100, metric = 5.18% * 100;
 Minibatch[1201-1300]: loss = 0.163028 * 100, metric = 5.37% * 100;
 Minibatch[1301-1400]: loss = 0.159778 * 100, metric = 5.04% * 100;
 Minibatch[1401-1500]: loss = 0.163711 * 100, metric = 5.23% * 100;
 Minibatch[1501-1600]: loss = 0.154452 * 100, metric = 4.93% * 100;
 Minibatch[1601-1700]: loss = 0.158537 * 100, metric = 4.93% * 100;
 Minibatch[1701-1800]: loss = 0.165623 * 100, metric = 5.42% * 100;
 Minibatch[1801-1900]: loss = 0.166861 * 100, metric = 5.32% * 100;
 Minibatch[1901-2000]: loss = 0.165438 * 100, metric = 5.34% * 100;
Finished Epoch[50 of 200]: [Training] loss = 0.162413 * 2000, metric = 5.16% * 2000 869.089s (  2.3 samples/s);
Finished Evaluation [50]: Minibatch[1-2000]: metric = 14.64% * 2000;
 Minibatch[   1- 100]: loss = 0.157293 * 100, metric = 5.00% * 100;
 Minibatch[ 101- 200]: loss = 0.165173 * 100, metric = 5.27% * 100;
 Minibatch[ 201- 300]: loss = 0.162518 * 100, metric = 5.07% * 100;
 Minibatch[ 301- 400]: loss = 0.154671 * 100, metric = 4.79% * 100;
 Minibatch[ 401- 500]: loss = 0.157161 * 100, metric = 4.94% * 100;
 Minibatch[ 501- 600]: loss = 0.167917 * 100, metric = 5.30% * 100;
 Minibatch[ 601- 700]: loss = 0.159873 * 100, metric = 5.06% * 100;
 Minibatch[ 701- 800]: loss = 0.157351 * 100, metric = 4.82% * 100;
 Minibatch[ 801- 900]: loss = 0.165663 * 100, metric = 5.21% * 100;
 Minibatch[ 901-1000]: loss = 0.161679 * 100, metric = 5.15% * 100;
 Minibatch[1001-1100]: loss = 0.163073 * 100, metric = 5.28% * 100;
 Minibatch[1101-1200]: loss = 0.161771 * 100, metric = 5.10% * 100;
 Minibatch[1201-1300]: loss = 0.173338 * 100, metric = 5.37% * 100;
 Minibatch[1301-1400]: loss = 0.163812 * 100, metric = 5.18% * 100;
 Minibatch[1401-1500]: loss = 0.156154 * 100, metric = 4.86% * 100;
 Minibatch[1501-1600]: loss = 0.167459 * 100, metric = 5.18% * 100;
 Minibatch[1601-1700]: loss = 0.155343 * 100, metric = 4.98% * 100;
 Minibatch[1701-1800]: loss = 0.165174 * 100, metric = 5.13% * 100;
 Minibatch[1801-1900]: loss = 0.148917 * 100, metric = 4.59% * 100;
 Minibatch[1901-2000]: loss = 0.160738 * 100, metric = 4.99% * 100;
Finished Epoch[51 of 200]: [Training] loss = 0.161254 * 2000, metric = 5.06% * 2000 846.151s (  2.4 samples/s);
Finished Evaluation [51]: Minibatch[1-2000]: metric = 13.50% * 2000;
0.4434477495327592
 Minibatch[   1- 100]: loss = 0.150409 * 100, metric = 4.83% * 100;
 Minibatch[ 101- 200]: loss = 0.155410 * 100, metric = 4.88% * 100;
 Minibatch[ 201- 300]: loss = 0.162786 * 100, metric = 5.10% * 100;
 Minibatch[ 301- 400]: loss = 0.152957 * 100, metric = 4.86% * 100;
 Minibatch[ 401- 500]: loss = 0.162845 * 100, metric = 5.06% * 100;
 Minibatch[ 501- 600]: loss = 0.157749 * 100, metric = 5.02% * 100;
 Minibatch[ 601- 700]: loss = 0.163239 * 100, metric = 4.95% * 100;
 Minibatch[ 701- 800]: loss = 0.166099 * 100, metric = 5.22% * 100;
 Minibatch[ 801- 900]: loss = 0.158545 * 100, metric = 5.06% * 100;
 Minibatch[ 901-1000]: loss = 0.167424 * 100, metric = 5.30% * 100;
 Minibatch[1001-1100]: loss = 0.167633 * 100, metric = 5.30% * 100;
 Minibatch[1101-1200]: loss = 0.147849 * 100, metric = 4.54% * 100;
 Minibatch[1201-1300]: loss = 0.156346 * 100, metric = 4.93% * 100;
 Minibatch[1301-1400]: loss = 0.159479 * 100, metric = 4.75% * 100;
 Minibatch[1401-1500]: loss = 0.148734 * 100, metric = 4.55% * 100;
 Minibatch[1501-1600]: loss = 0.151983 * 100, metric = 4.77% * 100;
 Minibatch[1601-1700]: loss = 0.157255 * 100, metric = 5.02% * 100;
 Minibatch[1701-1800]: loss = 0.154856 * 100, metric = 4.89% * 100;
 Minibatch[1801-1900]: loss = 0.153658 * 100, metric = 4.96% * 100;
 Minibatch[1901-2000]: loss = 0.159802 * 100, metric = 5.01% * 100;
Finished Epoch[52 of 200]: [Training] loss = 0.157753 * 2000, metric = 4.95% * 2000 839.904s (  2.4 samples/s);
Finished Evaluation [52]: Minibatch[1-2000]: metric = 14.45% * 2000;
 Minibatch[   1- 100]: loss = 0.154700 * 100, metric = 4.85% * 100;
 Minibatch[ 101- 200]: loss = 0.148823 * 100, metric = 4.65% * 100;
 Minibatch[ 201- 300]: loss = 0.157794 * 100, metric = 5.02% * 100;
 Minibatch[ 301- 400]: loss = 0.160388 * 100, metric = 5.11% * 100;
 Minibatch[ 401- 500]: loss = 0.162296 * 100, metric = 5.17% * 100;
 Minibatch[ 501- 600]: loss = 0.155159 * 100, metric = 4.87% * 100;
 Minibatch[ 601- 700]: loss = 0.150315 * 100, metric = 4.75% * 100;
 Minibatch[ 701- 800]: loss = 0.156717 * 100, metric = 4.92% * 100;
 Minibatch[ 801- 900]: loss = 0.153575 * 100, metric = 4.85% * 100;
 Minibatch[ 901-1000]: loss = 0.155764 * 100, metric = 4.99% * 100;
 Minibatch[1001-1100]: loss = 0.154449 * 100, metric = 4.86% * 100;
 Minibatch[1101-1200]: loss = 0.153414 * 100, metric = 4.79% * 100;
 Minibatch[1201-1300]: loss = 0.148714 * 100, metric = 4.78% * 100;
 Minibatch[1301-1400]: loss = 0.149543 * 100, metric = 4.58% * 100;
 Minibatch[1401-1500]: loss = 0.152831 * 100, metric = 4.82% * 100;
 Minibatch[1501-1600]: loss = 0.160680 * 100, metric = 5.24% * 100;
 Minibatch[1601-1700]: loss = 0.150041 * 100, metric = 4.68% * 100;
 Minibatch[1701-1800]: loss = 0.159982 * 100, metric = 5.14% * 100;
 Minibatch[1801-1900]: loss = 0.161516 * 100, metric = 5.09% * 100;
 Minibatch[1901-2000]: loss = 0.148150 * 100, metric = 4.59% * 100;
Finished Epoch[53 of 200]: [Training] loss = 0.154743 * 2000, metric = 4.89% * 2000 861.212s (  2.3 samples/s);
Finished Evaluation [53]: Minibatch[1-2000]: metric = 13.85% * 2000;
 Minibatch[   1- 100]: loss = 0.155466 * 100, metric = 4.91% * 100;
 Minibatch[ 101- 200]: loss = 0.153605 * 100, metric = 4.90% * 100;
 Minibatch[ 201- 300]: loss = 0.149551 * 100, metric = 4.64% * 100;
 Minibatch[ 301- 400]: loss = 0.145825 * 100, metric = 4.58% * 100;
 Minibatch[ 401- 500]: loss = 0.151962 * 100, metric = 4.85% * 100;
 Minibatch[ 501- 600]: loss = 0.148685 * 100, metric = 4.71% * 100;
 Minibatch[ 601- 700]: loss = 0.159157 * 100, metric = 5.04% * 100;
 Minibatch[ 701- 800]: loss = 0.156198 * 100, metric = 4.93% * 100;
 Minibatch[ 801- 900]: loss = 0.146790 * 100, metric = 4.53% * 100;
 Minibatch[ 901-1000]: loss = 0.154611 * 100, metric = 4.84% * 100;
 Minibatch[1001-1100]: loss = 0.145239 * 100, metric = 4.53% * 100;
 Minibatch[1101-1200]: loss = 0.151424 * 100, metric = 4.92% * 100;
 Minibatch[1201-1300]: loss = 0.151088 * 100, metric = 4.72% * 100;
 Minibatch[1301-1400]: loss = 0.151290 * 100, metric = 4.89% * 100;
 Minibatch[1401-1500]: loss = 0.157692 * 100, metric = 5.02% * 100;
 Minibatch[1501-1600]: loss = 0.158255 * 100, metric = 4.97% * 100;
 Minibatch[1601-1700]: loss = 0.154302 * 100, metric = 4.80% * 100;
 Minibatch[1701-1800]: loss = 0.157650 * 100, metric = 5.03% * 100;
 Minibatch[1801-1900]: loss = 0.160566 * 100, metric = 4.92% * 100;
 Minibatch[1901-2000]: loss = 0.162088 * 100, metric = 4.96% * 100;
Finished Epoch[54 of 200]: [Training] loss = 0.153572 * 2000, metric = 4.83% * 2000 848.619s (  2.4 samples/s);
Finished Evaluation [54]: Minibatch[1-2000]: metric = 13.46% * 2000;
 Minibatch[   1- 100]: loss = 0.161563 * 100, metric = 5.01% * 100;
 Minibatch[ 101- 200]: loss = 0.156819 * 100, metric = 4.88% * 100;
 Minibatch[ 201- 300]: loss = 0.155380 * 100, metric = 4.89% * 100;
 Minibatch[ 301- 400]: loss = 0.150960 * 100, metric = 4.72% * 100;
 Minibatch[ 401- 500]: loss = 0.152458 * 100, metric = 4.94% * 100;
 Minibatch[ 501- 600]: loss = 0.158580 * 100, metric = 4.98% * 100;
 Minibatch[ 601- 700]: loss = 0.157051 * 100, metric = 5.14% * 100;
 Minibatch[ 701- 800]: loss = 0.164641 * 100, metric = 5.33% * 100;
 Minibatch[ 801- 900]: loss = 0.154562 * 100, metric = 4.82% * 100;
 Minibatch[ 901-1000]: loss = 0.152010 * 100, metric = 4.75% * 100;
 Minibatch[1001-1100]: loss = 0.156540 * 100, metric = 4.95% * 100;
 Minibatch[1101-1200]: loss = 0.155111 * 100, metric = 4.94% * 100;
 Minibatch[1201-1300]: loss = 0.152562 * 100, metric = 4.83% * 100;
 Minibatch[1301-1400]: loss = 0.147369 * 100, metric = 4.66% * 100;
 Minibatch[1401-1500]: loss = 0.150248 * 100, metric = 4.68% * 100;
 Minibatch[1501-1600]: loss = 0.152892 * 100, metric = 4.86% * 100;
 Minibatch[1601-1700]: loss = 0.153075 * 100, metric = 4.93% * 100;
 Minibatch[1701-1800]: loss = 0.155629 * 100, metric = 4.91% * 100;
 Minibatch[1801-1900]: loss = 0.148314 * 100, metric = 4.68% * 100;
 Minibatch[1901-2000]: loss = 0.155721 * 100, metric = 4.92% * 100;
Finished Epoch[55 of 200]: [Training] loss = 0.154574 * 2000, metric = 4.89% * 2000 852.343s (  2.3 samples/s);
Finished Evaluation [55]: Minibatch[1-2000]: metric = 13.54% * 2000;
 Minibatch[   1- 100]: loss = 0.166290 * 100, metric = 5.28% * 100;
 Minibatch[ 101- 200]: loss = 0.150510 * 100, metric = 4.84% * 100;
 Minibatch[ 201- 300]: loss = 0.157614 * 100, metric = 5.06% * 100;
 Minibatch[ 301- 400]: loss = 0.156815 * 100, metric = 5.06% * 100;
 Minibatch[ 401- 500]: loss = 0.158837 * 100, metric = 5.10% * 100;
 Minibatch[ 501- 600]: loss = 0.163536 * 100, metric = 5.17% * 100;
 Minibatch[ 601- 700]: loss = 0.159335 * 100, metric = 5.12% * 100;
 Minibatch[ 701- 800]: loss = 0.149212 * 100, metric = 4.77% * 100;
 Minibatch[ 801- 900]: loss = 0.152342 * 100, metric = 4.78% * 100;
 Minibatch[ 901-1000]: loss = 0.155934 * 100, metric = 5.00% * 100;
 Minibatch[1001-1100]: loss = 0.161430 * 100, metric = 5.11% * 100;
 Minibatch[1101-1200]: loss = 0.157476 * 100, metric = 4.86% * 100;
 Minibatch[1201-1300]: loss = 0.156387 * 100, metric = 4.83% * 100;
 Minibatch[1301-1400]: loss = 0.144995 * 100, metric = 4.61% * 100;
 Minibatch[1401-1500]: loss = 0.157319 * 100, metric = 4.84% * 100;
 Minibatch[1501-1600]: loss = 0.150811 * 100, metric = 4.57% * 100;
 Minibatch[1601-1700]: loss = 0.153674 * 100, metric = 4.68% * 100;
 Minibatch[1701-1800]: loss = 0.148845 * 100, metric = 4.72% * 100;
 Minibatch[1801-1900]: loss = 0.143456 * 100, metric = 4.40% * 100;
 Minibatch[1901-2000]: loss = 0.164402 * 100, metric = 5.14% * 100;
Finished Epoch[56 of 200]: [Training] loss = 0.155461 * 2000, metric = 4.90% * 2000 854.186s (  2.3 samples/s);
Finished Evaluation [56]: Minibatch[1-2000]: metric = 12.95% * 2000;
0.43497191793471573
 Minibatch[   1- 100]: loss = 0.152156 * 100, metric = 4.75% * 100;
 Minibatch[ 101- 200]: loss = 0.150209 * 100, metric = 4.88% * 100;
 Minibatch[ 201- 300]: loss = 0.149944 * 100, metric = 4.73% * 100;
 Minibatch[ 301- 400]: loss = 0.155005 * 100, metric = 4.79% * 100;
 Minibatch[ 401- 500]: loss = 0.153517 * 100, metric = 4.81% * 100;
 Minibatch[ 501- 600]: loss = 0.144989 * 100, metric = 4.62% * 100;
 Minibatch[ 601- 700]: loss = 0.152038 * 100, metric = 4.80% * 100;
 Minibatch[ 701- 800]: loss = 0.143567 * 100, metric = 4.50% * 100;
 Minibatch[ 801- 900]: loss = 0.155156 * 100, metric = 4.89% * 100;
 Minibatch[ 901-1000]: loss = 0.148790 * 100, metric = 4.80% * 100;
 Minibatch[1001-1100]: loss = 0.151387 * 100, metric = 4.76% * 100;
 Minibatch[1101-1200]: loss = 0.155469 * 100, metric = 4.81% * 100;
 Minibatch[1201-1300]: loss = 0.153651 * 100, metric = 4.81% * 100;
 Minibatch[1301-1400]: loss = 0.147924 * 100, metric = 4.58% * 100;
 Minibatch[1401-1500]: loss = 0.154184 * 100, metric = 4.84% * 100;
 Minibatch[1501-1600]: loss = 0.148223 * 100, metric = 4.70% * 100;
 Minibatch[1601-1700]: loss = 0.148358 * 100, metric = 4.56% * 100;
 Minibatch[1701-1800]: loss = 0.152028 * 100, metric = 4.84% * 100;
 Minibatch[1801-1900]: loss = 0.153750 * 100, metric = 4.73% * 100;
 Minibatch[1901-2000]: loss = 0.153127 * 100, metric = 4.88% * 100;
Finished Epoch[57 of 200]: [Training] loss = 0.151174 * 2000, metric = 4.75% * 2000 855.892s (  2.3 samples/s);
Finished Evaluation [57]: Minibatch[1-2000]: metric = 13.53% * 2000;
 Minibatch[   1- 100]: loss = 0.146240 * 100, metric = 4.50% * 100;
 Minibatch[ 101- 200]: loss = 0.149538 * 100, metric = 4.78% * 100;
 Minibatch[ 201- 300]: loss = 0.149403 * 100, metric = 4.77% * 100;
 Minibatch[ 301- 400]: loss = 0.152910 * 100, metric = 4.72% * 100;
 Minibatch[ 401- 500]: loss = 0.159849 * 100, metric = 5.07% * 100;
 Minibatch[ 501- 600]: loss = 0.152006 * 100, metric = 4.83% * 100;
 Minibatch[ 601- 700]: loss = 0.150272 * 100, metric = 4.71% * 100;
 Minibatch[ 701- 800]: loss = 0.156706 * 100, metric = 4.93% * 100;
 Minibatch[ 801- 900]: loss = 0.151117 * 100, metric = 4.98% * 100;
 Minibatch[ 901-1000]: loss = 0.150454 * 100, metric = 4.84% * 100;
 Minibatch[1001-1100]: loss = 0.152310 * 100, metric = 4.91% * 100;
 Minibatch[1101-1200]: loss = 0.159186 * 100, metric = 5.15% * 100;
 Minibatch[1201-1300]: loss = 0.150174 * 100, metric = 4.84% * 100;
 Minibatch[1301-1400]: loss = 0.152098 * 100, metric = 4.92% * 100;
 Minibatch[1401-1500]: loss = 0.145107 * 100, metric = 4.58% * 100;
 Minibatch[1501-1600]: loss = 0.152849 * 100, metric = 4.85% * 100;
 Minibatch[1601-1700]: loss = 0.158390 * 100, metric = 4.91% * 100;
 Minibatch[1701-1800]: loss = 0.151837 * 100, metric = 4.74% * 100;
 Minibatch[1801-1900]: loss = 0.155788 * 100, metric = 4.95% * 100;
 Minibatch[1901-2000]: loss = 0.142893 * 100, metric = 4.44% * 100;
Finished Epoch[58 of 200]: [Training] loss = 0.151956 * 2000, metric = 4.82% * 2000 847.979s (  2.4 samples/s);
Finished Evaluation [58]: Minibatch[1-2000]: metric = 13.40% * 2000;
 Minibatch[   1- 100]: loss = 0.159079 * 100, metric = 5.10% * 100;
 Minibatch[ 101- 200]: loss = 0.160601 * 100, metric = 5.10% * 100;
 Minibatch[ 201- 300]: loss = 0.150248 * 100, metric = 4.61% * 100;
 Minibatch[ 301- 400]: loss = 0.148189 * 100, metric = 4.54% * 100;
 Minibatch[ 401- 500]: loss = 0.152203 * 100, metric = 4.80% * 100;
 Minibatch[ 501- 600]: loss = 0.143145 * 100, metric = 4.58% * 100;
 Minibatch[ 601- 700]: loss = 0.148045 * 100, metric = 4.60% * 100;
 Minibatch[ 701- 800]: loss = 0.148544 * 100, metric = 4.66% * 100;
 Minibatch[ 801- 900]: loss = 0.148508 * 100, metric = 4.75% * 100;
 Minibatch[ 901-1000]: loss = 0.150115 * 100, metric = 4.77% * 100;
 Minibatch[1001-1100]: loss = 0.144831 * 100, metric = 4.54% * 100;
 Minibatch[1101-1200]: loss = 0.149806 * 100, metric = 4.90% * 100;
 Minibatch[1201-1300]: loss = 0.149740 * 100, metric = 4.65% * 100;
 Minibatch[1301-1400]: loss = 0.146929 * 100, metric = 4.60% * 100;
 Minibatch[1401-1500]: loss = 0.146919 * 100, metric = 4.64% * 100;
 Minibatch[1501-1600]: loss = 0.144316 * 100, metric = 4.57% * 100;
 Minibatch[1601-1700]: loss = 0.150295 * 100, metric = 4.86% * 100;
 Minibatch[1701-1800]: loss = 0.148037 * 100, metric = 4.68% * 100;
 Minibatch[1801-1900]: loss = 0.148936 * 100, metric = 4.63% * 100;
 Minibatch[1901-2000]: loss = 0.151105 * 100, metric = 4.74% * 100;
Finished Epoch[59 of 200]: [Training] loss = 0.149479 * 2000, metric = 4.72% * 2000 850.931s (  2.4 samples/s);
Finished Evaluation [59]: Minibatch[1-2000]: metric = 14.30% * 2000;
 Minibatch[   1- 100]: loss = 0.148429 * 100, metric = 4.69% * 100;
 Minibatch[ 101- 200]: loss = 0.139859 * 100, metric = 4.43% * 100;
 Minibatch[ 201- 300]: loss = 0.143314 * 100, metric = 4.29% * 100;
 Minibatch[ 301- 400]: loss = 0.149545 * 100, metric = 4.70% * 100;
 Minibatch[ 401- 500]: loss = 0.152189 * 100, metric = 4.87% * 100;
 Minibatch[ 501- 600]: loss = 0.153482 * 100, metric = 4.90% * 100;
 Minibatch[ 601- 700]: loss = 0.139139 * 100, metric = 4.41% * 100;
 Minibatch[ 701- 800]: loss = 0.148281 * 100, metric = 4.67% * 100;
 Minibatch[ 801- 900]: loss = 0.148179 * 100, metric = 4.67% * 100;
 Minibatch[ 901-1000]: loss = 0.153948 * 100, metric = 4.97% * 100;
 Minibatch[1001-1100]: loss = 0.155228 * 100, metric = 4.99% * 100;
 Minibatch[1101-1200]: loss = 0.146655 * 100, metric = 4.59% * 100;
 Minibatch[1201-1300]: loss = 0.150894 * 100, metric = 4.85% * 100;
 Minibatch[1301-1400]: loss = 0.146524 * 100, metric = 4.59% * 100;
 Minibatch[1401-1500]: loss = 0.141273 * 100, metric = 4.39% * 100;
 Minibatch[1501-1600]: loss = 0.149610 * 100, metric = 4.71% * 100;
 Minibatch[1601-1700]: loss = 0.144668 * 100, metric = 4.59% * 100;
 Minibatch[1701-1800]: loss = 0.147464 * 100, metric = 4.65% * 100;
 Minibatch[1801-1900]: loss = 0.150429 * 100, metric = 4.75% * 100;
 Minibatch[1901-2000]: loss = 0.148474 * 100, metric = 4.69% * 100;
Finished Epoch[60 of 200]: [Training] loss = 0.147879 * 2000, metric = 4.67% * 2000 850.157s (  2.4 samples/s);
Finished Evaluation [60]: Minibatch[1-2000]: metric = 14.33% * 2000;
 Minibatch[   1- 100]: loss = 0.158879 * 100, metric = 4.95% * 100;
 Minibatch[ 101- 200]: loss = 0.137846 * 100, metric = 4.40% * 100;
 Minibatch[ 201- 300]: loss = 0.151068 * 100, metric = 4.79% * 100;
 Minibatch[ 301- 400]: loss = 0.155515 * 100, metric = 5.05% * 100;
 Minibatch[ 401- 500]: loss = 0.147805 * 100, metric = 4.69% * 100;
 Minibatch[ 501- 600]: loss = 0.133834 * 100, metric = 4.15% * 100;
 Minibatch[ 601- 700]: loss = 0.142342 * 100, metric = 4.48% * 100;
 Minibatch[ 701- 800]: loss = 0.147360 * 100, metric = 4.63% * 100;
 Minibatch[ 801- 900]: loss = 0.141047 * 100, metric = 4.35% * 100;
 Minibatch[ 901-1000]: loss = 0.140243 * 100, metric = 4.37% * 100;
 Minibatch[1001-1100]: loss = 0.146281 * 100, metric = 4.58% * 100;
 Minibatch[1101-1200]: loss = 0.154694 * 100, metric = 4.94% * 100;
 Minibatch[1201-1300]: loss = 0.143166 * 100, metric = 4.58% * 100;
 Minibatch[1301-1400]: loss = 0.132442 * 100, metric = 4.04% * 100;
 Minibatch[1401-1500]: loss = 0.145682 * 100, metric = 4.73% * 100;
 Minibatch[1501-1600]: loss = 0.154930 * 100, metric = 4.96% * 100;
 Minibatch[1601-1700]: loss = 0.158478 * 100, metric = 4.87% * 100;
 Minibatch[1701-1800]: loss = 0.146262 * 100, metric = 4.59% * 100;
 Minibatch[1801-1900]: loss = 0.148759 * 100, metric = 4.70% * 100;
 Minibatch[1901-2000]: loss = 0.144660 * 100, metric = 4.48% * 100;
Finished Epoch[61 of 200]: [Training] loss = 0.146565 * 2000, metric = 4.62% * 2000 844.991s (  2.4 samples/s);
Finished Evaluation [61]: Minibatch[1-2000]: metric = 13.03% * 2000;
 Minibatch[   1- 100]: loss = 0.140288 * 100, metric = 4.37% * 100;
 Minibatch[ 101- 200]: loss = 0.138442 * 100, metric = 4.38% * 100;
 Minibatch[ 201- 300]: loss = 0.143121 * 100, metric = 4.50% * 100;
 Minibatch[ 301- 400]: loss = 0.145640 * 100, metric = 4.70% * 100;
 Minibatch[ 401- 500]: loss = 0.143444 * 100, metric = 4.53% * 100;
 Minibatch[ 501- 600]: loss = 0.150018 * 100, metric = 4.54% * 100;
 Minibatch[ 601- 700]: loss = 0.147164 * 100, metric = 4.65% * 100;
 Minibatch[ 701- 800]: loss = 0.142075 * 100, metric = 4.65% * 100;
 Minibatch[ 801- 900]: loss = 0.145040 * 100, metric = 4.54% * 100;
 Minibatch[ 901-1000]: loss = 0.151302 * 100, metric = 4.81% * 100;
 Minibatch[1001-1100]: loss = 0.130333 * 100, metric = 4.07% * 100;
 Minibatch[1101-1200]: loss = 0.150029 * 100, metric = 4.73% * 100;
 Minibatch[1201-1300]: loss = 0.143886 * 100, metric = 4.57% * 100;
 Minibatch[1301-1400]: loss = 0.152786 * 100, metric = 4.76% * 100;
 Minibatch[1401-1500]: loss = 0.139829 * 100, metric = 4.39% * 100;
 Minibatch[1501-1600]: loss = 0.141008 * 100, metric = 4.41% * 100;
 Minibatch[1601-1700]: loss = 0.141037 * 100, metric = 4.54% * 100;
 Minibatch[1701-1800]: loss = 0.145243 * 100, metric = 4.57% * 100;
 Minibatch[1801-1900]: loss = 0.145393 * 100, metric = 4.68% * 100;
 Minibatch[1901-2000]: loss = 0.149207 * 100, metric = 4.77% * 100;
Finished Epoch[62 of 200]: [Training] loss = 0.144264 * 2000, metric = 4.56% * 2000 845.552s (  2.4 samples/s);
Finished Evaluation [62]: Minibatch[1-2000]: metric = 13.92% * 2000;
 Minibatch[   1- 100]: loss = 0.147917 * 100, metric = 4.76% * 100;
 Minibatch[ 101- 200]: loss = 0.138164 * 100, metric = 4.35% * 100;
 Minibatch[ 201- 300]: loss = 0.146924 * 100, metric = 4.60% * 100;
 Minibatch[ 301- 400]: loss = 0.138522 * 100, metric = 4.45% * 100;
 Minibatch[ 401- 500]: loss = 0.137743 * 100, metric = 4.39% * 100;
 Minibatch[ 501- 600]: loss = 0.136707 * 100, metric = 4.28% * 100;
 Minibatch[ 601- 700]: loss = 0.147366 * 100, metric = 4.72% * 100;
 Minibatch[ 701- 800]: loss = 0.143923 * 100, metric = 4.58% * 100;
 Minibatch[ 801- 900]: loss = 0.138558 * 100, metric = 4.36% * 100;
 Minibatch[ 901-1000]: loss = 0.130971 * 100, metric = 4.04% * 100;
 Minibatch[1001-1100]: loss = 0.146885 * 100, metric = 4.65% * 100;
 Minibatch[1101-1200]: loss = 0.138465 * 100, metric = 4.43% * 100;
 Minibatch[1201-1300]: loss = 0.141530 * 100, metric = 4.44% * 100;
 Minibatch[1301-1400]: loss = 0.141710 * 100, metric = 4.43% * 100;
 Minibatch[1401-1500]: loss = 0.136982 * 100, metric = 4.41% * 100;
 Minibatch[1501-1600]: loss = 0.142875 * 100, metric = 4.53% * 100;
 Minibatch[1601-1700]: loss = 0.140355 * 100, metric = 4.46% * 100;
 Minibatch[1701-1800]: loss = 0.138939 * 100, metric = 4.43% * 100;
 Minibatch[1801-1900]: loss = 0.144237 * 100, metric = 4.33% * 100;
 Minibatch[1901-2000]: loss = 0.146517 * 100, metric = 4.73% * 100;
Finished Epoch[63 of 200]: [Training] loss = 0.141264 * 2000, metric = 4.47% * 2000 835.257s (  2.4 samples/s);
Finished Evaluation [63]: Minibatch[1-2000]: metric = 12.64% * 2000;
 Minibatch[   1- 100]: loss = 0.141665 * 100, metric = 4.43% * 100;
 Minibatch[ 101- 200]: loss = 0.143466 * 100, metric = 4.58% * 100;
 Minibatch[ 201- 300]: loss = 0.145459 * 100, metric = 4.61% * 100;
 Minibatch[ 301- 400]: loss = 0.145453 * 100, metric = 4.55% * 100;
 Minibatch[ 401- 500]: loss = 0.138208 * 100, metric = 4.46% * 100;
 Minibatch[ 501- 600]: loss = 0.136632 * 100, metric = 4.19% * 100;
 Minibatch[ 601- 700]: loss = 0.136873 * 100, metric = 4.25% * 100;
 Minibatch[ 701- 800]: loss = 0.153262 * 100, metric = 4.79% * 100;
 Minibatch[ 801- 900]: loss = 0.143473 * 100, metric = 4.51% * 100;
 Minibatch[ 901-1000]: loss = 0.140117 * 100, metric = 4.47% * 100;
 Minibatch[1001-1100]: loss = 0.141006 * 100, metric = 4.63% * 100;
 Minibatch[1101-1200]: loss = 0.143737 * 100, metric = 4.55% * 100;
 Minibatch[1201-1300]: loss = 0.138183 * 100, metric = 4.37% * 100;
 Minibatch[1301-1400]: loss = 0.145617 * 100, metric = 4.68% * 100;
 Minibatch[1401-1500]: loss = 0.144397 * 100, metric = 4.63% * 100;
 Minibatch[1501-1600]: loss = 0.148313 * 100, metric = 4.77% * 100;
 Minibatch[1601-1700]: loss = 0.130863 * 100, metric = 4.12% * 100;
 Minibatch[1701-1800]: loss = 0.140512 * 100, metric = 4.49% * 100;
 Minibatch[1801-1900]: loss = 0.145855 * 100, metric = 4.62% * 100;
 Minibatch[1901-2000]: loss = 0.144297 * 100, metric = 4.42% * 100;
Finished Epoch[64 of 200]: [Training] loss = 0.142370 * 2000, metric = 4.51% * 2000 836.611s (  2.4 samples/s);
Finished Evaluation [64]: Minibatch[1-2000]: metric = 14.36% * 2000;
 Minibatch[   1- 100]: loss = 0.141449 * 100, metric = 4.54% * 100;
 Minibatch[ 101- 200]: loss = 0.139221 * 100, metric = 4.39% * 100;
 Minibatch[ 201- 300]: loss = 0.146108 * 100, metric = 4.66% * 100;
 Minibatch[ 301- 400]: loss = 0.145028 * 100, metric = 4.63% * 100;
 Minibatch[ 401- 500]: loss = 0.140648 * 100, metric = 4.37% * 100;
 Minibatch[ 501- 600]: loss = 0.139629 * 100, metric = 4.41% * 100;
 Minibatch[ 601- 700]: loss = 0.149407 * 100, metric = 4.67% * 100;
 Minibatch[ 701- 800]: loss = 0.147982 * 100, metric = 4.80% * 100;
 Minibatch[ 801- 900]: loss = 0.140118 * 100, metric = 4.61% * 100;
 Minibatch[ 901-1000]: loss = 0.144560 * 100, metric = 4.53% * 100;
 Minibatch[1001-1100]: loss = 0.143094 * 100, metric = 4.51% * 100;
 Minibatch[1101-1200]: loss = 0.144790 * 100, metric = 4.56% * 100;
 Minibatch[1201-1300]: loss = 0.152966 * 100, metric = 4.75% * 100;
 Minibatch[1301-1400]: loss = 0.139253 * 100, metric = 4.46% * 100;
 Minibatch[1401-1500]: loss = 0.141618 * 100, metric = 4.41% * 100;
 Minibatch[1501-1600]: loss = 0.140798 * 100, metric = 4.46% * 100;
 Minibatch[1601-1700]: loss = 0.145667 * 100, metric = 4.57% * 100;
 Minibatch[1701-1800]: loss = 0.143607 * 100, metric = 4.60% * 100;
 Minibatch[1801-1900]: loss = 0.141341 * 100, metric = 4.44% * 100;
 Minibatch[1901-2000]: loss = 0.136590 * 100, metric = 4.36% * 100;
Finished Epoch[65 of 200]: [Training] loss = 0.143194 * 2000, metric = 4.54% * 2000 843.760s (  2.4 samples/s);
Finished Evaluation [65]: Minibatch[1-2000]: metric = 13.56% * 2000;
 Minibatch[   1- 100]: loss = 0.137601 * 100, metric = 4.32% * 100;
 Minibatch[ 101- 200]: loss = 0.143879 * 100, metric = 4.50% * 100;
 Minibatch[ 201- 300]: loss = 0.139336 * 100, metric = 4.37% * 100;
 Minibatch[ 301- 400]: loss = 0.138381 * 100, metric = 4.41% * 100;
 Minibatch[ 401- 500]: loss = 0.142627 * 100, metric = 4.58% * 100;
 Minibatch[ 501- 600]: loss = 0.134734 * 100, metric = 4.28% * 100;
 Minibatch[ 601- 700]: loss = 0.132659 * 100, metric = 4.16% * 100;
 Minibatch[ 701- 800]: loss = 0.139006 * 100, metric = 4.32% * 100;
 Minibatch[ 801- 900]: loss = 0.127348 * 100, metric = 4.05% * 100;
 Minibatch[ 901-1000]: loss = 0.135415 * 100, metric = 4.22% * 100;
 Minibatch[1001-1100]: loss = 0.142460 * 100, metric = 4.55% * 100;
 Minibatch[1101-1200]: loss = 0.141823 * 100, metric = 4.52% * 100;
 Minibatch[1201-1300]: loss = 0.143398 * 100, metric = 4.53% * 100;
 Minibatch[1301-1400]: loss = 0.134112 * 100, metric = 4.15% * 100;
 Minibatch[1401-1500]: loss = 0.135706 * 100, metric = 4.23% * 100;
 Minibatch[1501-1600]: loss = 0.141108 * 100, metric = 4.44% * 100;
 Minibatch[1601-1700]: loss = 0.137547 * 100, metric = 4.42% * 100;
 Minibatch[1701-1800]: loss = 0.146726 * 100, metric = 4.71% * 100;
 Minibatch[1801-1900]: loss = 0.138065 * 100, metric = 4.42% * 100;
 Minibatch[1901-2000]: loss = 0.139354 * 100, metric = 4.39% * 100;
Finished Epoch[66 of 200]: [Training] loss = 0.138564 * 2000, metric = 4.38% * 2000 838.852s (  2.4 samples/s);
Finished Evaluation [66]: Minibatch[1-2000]: metric = 13.86% * 2000;
 Minibatch[   1- 100]: loss = 0.149547 * 100, metric = 4.64% * 100;
 Minibatch[ 101- 200]: loss = 0.138390 * 100, metric = 4.44% * 100;
 Minibatch[ 201- 300]: loss = 0.139819 * 100, metric = 4.37% * 100;
 Minibatch[ 301- 400]: loss = 0.144176 * 100, metric = 4.61% * 100;
 Minibatch[ 401- 500]: loss = 0.142953 * 100, metric = 4.54% * 100;
 Minibatch[ 501- 600]: loss = 0.139023 * 100, metric = 4.40% * 100;
 Minibatch[ 601- 700]: loss = 0.135711 * 100, metric = 4.38% * 100;
 Minibatch[ 701- 800]: loss = 0.138211 * 100, metric = 4.38% * 100;
 Minibatch[ 801- 900]: loss = 0.134888 * 100, metric = 4.25% * 100;
 Minibatch[ 901-1000]: loss = 0.142551 * 100, metric = 4.52% * 100;
 Minibatch[1001-1100]: loss = 0.135948 * 100, metric = 4.25% * 100;
 Minibatch[1101-1200]: loss = 0.142406 * 100, metric = 4.42% * 100;
 Minibatch[1201-1300]: loss = 0.138014 * 100, metric = 4.37% * 100;
 Minibatch[1301-1400]: loss = 0.141320 * 100, metric = 4.49% * 100;
 Minibatch[1401-1500]: loss = 0.133007 * 100, metric = 4.12% * 100;
 Minibatch[1501-1600]: loss = 0.134414 * 100, metric = 4.29% * 100;
 Minibatch[1601-1700]: loss = 0.132974 * 100, metric = 4.17% * 100;
 Minibatch[1701-1800]: loss = 0.145967 * 100, metric = 4.71% * 100;
 Minibatch[1801-1900]: loss = 0.135596 * 100, metric = 4.33% * 100;
 Minibatch[1901-2000]: loss = 0.147449 * 100, metric = 4.62% * 100;
Finished Epoch[67 of 200]: [Training] loss = 0.139618 * 2000, metric = 4.41% * 2000 846.626s (  2.4 samples/s);
Finished Evaluation [67]: Minibatch[1-2000]: metric = 13.31% * 2000;
 Minibatch[   1- 100]: loss = 0.131238 * 100, metric = 4.29% * 100;
 Minibatch[ 101- 200]: loss = 0.140863 * 100, metric = 4.63% * 100;
 Minibatch[ 201- 300]: loss = 0.144832 * 100, metric = 4.64% * 100;
 Minibatch[ 301- 400]: loss = 0.134271 * 100, metric = 4.25% * 100;
 Minibatch[ 401- 500]: loss = 0.144472 * 100, metric = 4.46% * 100;
 Minibatch[ 501- 600]: loss = 0.141320 * 100, metric = 4.48% * 100;
 Minibatch[ 601- 700]: loss = 0.141082 * 100, metric = 4.33% * 100;
 Minibatch[ 701- 800]: loss = 0.140816 * 100, metric = 4.50% * 100;
 Minibatch[ 801- 900]: loss = 0.139431 * 100, metric = 4.28% * 100;
 Minibatch[ 901-1000]: loss = 0.134594 * 100, metric = 4.28% * 100;
 Minibatch[1001-1100]: loss = 0.141897 * 100, metric = 4.37% * 100;
 Minibatch[1101-1200]: loss = 0.143928 * 100, metric = 4.52% * 100;
 Minibatch[1201-1300]: loss = 0.139301 * 100, metric = 4.35% * 100;
 Minibatch[1301-1400]: loss = 0.128973 * 100, metric = 4.08% * 100;
 Minibatch[1401-1500]: loss = 0.130007 * 100, metric = 4.11% * 100;
 Minibatch[1501-1600]: loss = 0.138413 * 100, metric = 4.37% * 100;
 Minibatch[1601-1700]: loss = 0.135435 * 100, metric = 4.33% * 100;
 Minibatch[1701-1800]: loss = 0.138723 * 100, metric = 4.37% * 100;
 Minibatch[1801-1900]: loss = 0.140104 * 100, metric = 4.55% * 100;
 Minibatch[1901-2000]: loss = 0.128274 * 100, metric = 4.02% * 100;
Finished Epoch[68 of 200]: [Training] loss = 0.137899 * 2000, metric = 4.36% * 2000 853.447s (  2.3 samples/s);
Finished Evaluation [68]: Minibatch[1-2000]: metric = 12.46% * 2000;
 Minibatch[   1- 100]: loss = 0.132203 * 100, metric = 4.22% * 100;
 Minibatch[ 101- 200]: loss = 0.138980 * 100, metric = 4.42% * 100;
 Minibatch[ 201- 300]: loss = 0.128701 * 100, metric = 4.06% * 100;
 Minibatch[ 301- 400]: loss = 0.138981 * 100, metric = 4.29% * 100;
 Minibatch[ 401- 500]: loss = 0.138675 * 100, metric = 4.46% * 100;
 Minibatch[ 501- 600]: loss = 0.144269 * 100, metric = 4.67% * 100;
 Minibatch[ 601- 700]: loss = 0.129953 * 100, metric = 4.07% * 100;
 Minibatch[ 701- 800]: loss = 0.138072 * 100, metric = 4.37% * 100;
 Minibatch[ 801- 900]: loss = 0.134114 * 100, metric = 4.30% * 100;
 Minibatch[ 901-1000]: loss = 0.139245 * 100, metric = 4.41% * 100;
 Minibatch[1001-1100]: loss = 0.136433 * 100, metric = 4.32% * 100;
 Minibatch[1101-1200]: loss = 0.135583 * 100, metric = 4.12% * 100;
 Minibatch[1201-1300]: loss = 0.141463 * 100, metric = 4.45% * 100;
 Minibatch[1301-1400]: loss = 0.139390 * 100, metric = 4.40% * 100;
 Minibatch[1401-1500]: loss = 0.134266 * 100, metric = 4.13% * 100;
 Minibatch[1501-1600]: loss = 0.137565 * 100, metric = 4.28% * 100;
 Minibatch[1601-1700]: loss = 0.137549 * 100, metric = 4.40% * 100;
 Minibatch[1701-1800]: loss = 0.141406 * 100, metric = 4.63% * 100;
 Minibatch[1801-1900]: loss = 0.141353 * 100, metric = 4.36% * 100;
 Minibatch[1901-2000]: loss = 0.137468 * 100, metric = 4.35% * 100;
Finished Epoch[69 of 200]: [Training] loss = 0.137284 * 2000, metric = 4.34% * 2000 838.394s (  2.4 samples/s);
Finished Evaluation [69]: Minibatch[1-2000]: metric = 12.88% * 2000;
 Minibatch[   1- 100]: loss = 0.132520 * 100, metric = 4.20% * 100;
 Minibatch[ 101- 200]: loss = 0.127421 * 100, metric = 4.10% * 100;
 Minibatch[ 201- 300]: loss = 0.134203 * 100, metric = 4.08% * 100;
 Minibatch[ 301- 400]: loss = 0.132679 * 100, metric = 4.18% * 100;
 Minibatch[ 401- 500]: loss = 0.129126 * 100, metric = 4.11% * 100;
 Minibatch[ 501- 600]: loss = 0.142362 * 100, metric = 4.49% * 100;
 Minibatch[ 601- 700]: loss = 0.130096 * 100, metric = 4.04% * 100;
 Minibatch[ 701- 800]: loss = 0.137283 * 100, metric = 4.34% * 100;
 Minibatch[ 801- 900]: loss = 0.133227 * 100, metric = 4.14% * 100;
 Minibatch[ 901-1000]: loss = 0.135112 * 100, metric = 4.17% * 100;
 Minibatch[1001-1100]: loss = 0.128244 * 100, metric = 4.03% * 100;
 Minibatch[1101-1200]: loss = 0.130788 * 100, metric = 4.19% * 100;
 Minibatch[1201-1300]: loss = 0.137446 * 100, metric = 4.19% * 100;
 Minibatch[1301-1400]: loss = 0.140554 * 100, metric = 4.55% * 100;
 Minibatch[1401-1500]: loss = 0.126850 * 100, metric = 3.95% * 100;
 Minibatch[1501-1600]: loss = 0.136603 * 100, metric = 4.37% * 100;
 Minibatch[1601-1700]: loss = 0.139914 * 100, metric = 4.48% * 100;
 Minibatch[1701-1800]: loss = 0.145781 * 100, metric = 4.42% * 100;
 Minibatch[1801-1900]: loss = 0.136342 * 100, metric = 4.27% * 100;
 Minibatch[1901-2000]: loss = 0.135930 * 100, metric = 4.29% * 100;
Finished Epoch[70 of 200]: [Training] loss = 0.134624 * 2000, metric = 4.23% * 2000 842.426s (  2.4 samples/s);
Finished Evaluation [70]: Minibatch[1-2000]: metric = 12.86% * 2000;
 Minibatch[   1- 100]: loss = 0.144685 * 100, metric = 4.69% * 100;
 Minibatch[ 101- 200]: loss = 0.130811 * 100, metric = 4.17% * 100;
 Minibatch[ 201- 300]: loss = 0.137365 * 100, metric = 4.38% * 100;
 Minibatch[ 301- 400]: loss = 0.132167 * 100, metric = 4.15% * 100;
 Minibatch[ 401- 500]: loss = 0.133367 * 100, metric = 4.25% * 100;
 Minibatch[ 501- 600]: loss = 0.142315 * 100, metric = 4.35% * 100;
 Minibatch[ 601- 700]: loss = 0.127356 * 100, metric = 4.02% * 100;
 Minibatch[ 701- 800]: loss = 0.135018 * 100, metric = 4.43% * 100;
 Minibatch[ 801- 900]: loss = 0.133979 * 100, metric = 4.30% * 100;
 Minibatch[ 901-1000]: loss = 0.134894 * 100, metric = 4.22% * 100;
 Minibatch[1001-1100]: loss = 0.136615 * 100, metric = 4.42% * 100;
 Minibatch[1101-1200]: loss = 0.128556 * 100, metric = 3.96% * 100;
 Minibatch[1201-1300]: loss = 0.133099 * 100, metric = 4.19% * 100;
 Minibatch[1301-1400]: loss = 0.130457 * 100, metric = 4.07% * 100;
 Minibatch[1401-1500]: loss = 0.132254 * 100, metric = 4.06% * 100;
 Minibatch[1501-1600]: loss = 0.141431 * 100, metric = 4.45% * 100;
 Minibatch[1601-1700]: loss = 0.135999 * 100, metric = 4.17% * 100;
 Minibatch[1701-1800]: loss = 0.136026 * 100, metric = 4.27% * 100;
 Minibatch[1801-1900]: loss = 0.133059 * 100, metric = 4.15% * 100;
 Minibatch[1901-2000]: loss = 0.134253 * 100, metric = 4.21% * 100;
Finished Epoch[71 of 200]: [Training] loss = 0.134685 * 2000, metric = 4.24% * 2000 831.869s (  2.4 samples/s);
Finished Evaluation [71]: Minibatch[1-2000]: metric = 12.41% * 2000;
0.43433941804617643
 Minibatch[   1- 100]: loss = 0.135018 * 100, metric = 4.21% * 100;
 Minibatch[ 101- 200]: loss = 0.138483 * 100, metric = 4.37% * 100;
 Minibatch[ 201- 300]: loss = 0.131050 * 100, metric = 4.10% * 100;
 Minibatch[ 301- 400]: loss = 0.133275 * 100, metric = 4.06% * 100;
 Minibatch[ 401- 500]: loss = 0.134320 * 100, metric = 4.30% * 100;
 Minibatch[ 501- 600]: loss = 0.133228 * 100, metric = 4.20% * 100;
 Minibatch[ 601- 700]: loss = 0.133612 * 100, metric = 4.21% * 100;
 Minibatch[ 701- 800]: loss = 0.134451 * 100, metric = 4.20% * 100;
 Minibatch[ 801- 900]: loss = 0.125179 * 100, metric = 4.07% * 100;
 Minibatch[ 901-1000]: loss = 0.133987 * 100, metric = 4.19% * 100;
 Minibatch[1001-1100]: loss = 0.132893 * 100, metric = 4.17% * 100;
 Minibatch[1101-1200]: loss = 0.126546 * 100, metric = 4.04% * 100;
 Minibatch[1201-1300]: loss = 0.126770 * 100, metric = 3.99% * 100;
 Minibatch[1301-1400]: loss = 0.137341 * 100, metric = 4.19% * 100;
 Minibatch[1401-1500]: loss = 0.137645 * 100, metric = 4.26% * 100;
 Minibatch[1501-1600]: loss = 0.134821 * 100, metric = 4.12% * 100;
 Minibatch[1601-1700]: loss = 0.131825 * 100, metric = 4.22% * 100;
 Minibatch[1701-1800]: loss = 0.130474 * 100, metric = 3.99% * 100;
 Minibatch[1801-1900]: loss = 0.127688 * 100, metric = 3.96% * 100;
 Minibatch[1901-2000]: loss = 0.134335 * 100, metric = 4.33% * 100;
Finished Epoch[72 of 200]: [Training] loss = 0.132647 * 2000, metric = 4.16% * 2000 836.967s (  2.4 samples/s);
Finished Evaluation [72]: Minibatch[1-2000]: metric = 12.95% * 2000;
 Minibatch[   1- 100]: loss = 0.129565 * 100, metric = 4.06% * 100;
 Minibatch[ 101- 200]: loss = 0.129986 * 100, metric = 4.15% * 100;
 Minibatch[ 201- 300]: loss = 0.133061 * 100, metric = 4.15% * 100;
 Minibatch[ 301- 400]: loss = 0.133739 * 100, metric = 4.12% * 100;
 Minibatch[ 401- 500]: loss = 0.136256 * 100, metric = 4.24% * 100;
 Minibatch[ 501- 600]: loss = 0.128646 * 100, metric = 4.17% * 100;
 Minibatch[ 601- 700]: loss = 0.124086 * 100, metric = 3.83% * 100;
 Minibatch[ 701- 800]: loss = 0.127305 * 100, metric = 3.96% * 100;
 Minibatch[ 801- 900]: loss = 0.127533 * 100, metric = 3.93% * 100;
 Minibatch[ 901-1000]: loss = 0.132343 * 100, metric = 4.20% * 100;
 Minibatch[1001-1100]: loss = 0.124663 * 100, metric = 3.86% * 100;
 Minibatch[1101-1200]: loss = 0.126677 * 100, metric = 3.88% * 100;
 Minibatch[1201-1300]: loss = 0.136454 * 100, metric = 4.23% * 100;
 Minibatch[1301-1400]: loss = 0.131933 * 100, metric = 4.19% * 100;
 Minibatch[1401-1500]: loss = 0.127448 * 100, metric = 3.96% * 100;
 Minibatch[1501-1600]: loss = 0.129546 * 100, metric = 4.06% * 100;
 Minibatch[1601-1700]: loss = 0.131815 * 100, metric = 4.16% * 100;
 Minibatch[1701-1800]: loss = 0.125511 * 100, metric = 4.00% * 100;
 Minibatch[1801-1900]: loss = 0.127399 * 100, metric = 3.97% * 100;
 Minibatch[1901-2000]: loss = 0.133494 * 100, metric = 4.20% * 100;
Finished Epoch[73 of 200]: [Training] loss = 0.129873 * 2000, metric = 4.06% * 2000 833.696s (  2.4 samples/s);
Finished Evaluation [73]: Minibatch[1-2000]: metric = 12.91% * 2000;
 Minibatch[   1- 100]: loss = 0.132155 * 100, metric = 4.03% * 100;
 Minibatch[ 101- 200]: loss = 0.130181 * 100, metric = 4.14% * 100;
 Minibatch[ 201- 300]: loss = 0.127998 * 100, metric = 3.99% * 100;
 Minibatch[ 301- 400]: loss = 0.128059 * 100, metric = 3.97% * 100;
 Minibatch[ 401- 500]: loss = 0.129547 * 100, metric = 4.04% * 100;
 Minibatch[ 501- 600]: loss = 0.133446 * 100, metric = 4.12% * 100;
 Minibatch[ 601- 700]: loss = 0.132347 * 100, metric = 4.15% * 100;
 Minibatch[ 701- 800]: loss = 0.135337 * 100, metric = 4.18% * 100;
 Minibatch[ 801- 900]: loss = 0.136719 * 100, metric = 4.27% * 100;
 Minibatch[ 901-1000]: loss = 0.135251 * 100, metric = 4.26% * 100;
 Minibatch[1001-1100]: loss = 0.129376 * 100, metric = 4.14% * 100;
 Minibatch[1101-1200]: loss = 0.141204 * 100, metric = 4.51% * 100;
 Minibatch[1201-1300]: loss = 0.126602 * 100, metric = 3.97% * 100;
 Minibatch[1301-1400]: loss = 0.131900 * 100, metric = 4.25% * 100;
 Minibatch[1401-1500]: loss = 0.124568 * 100, metric = 3.87% * 100;
 Minibatch[1501-1600]: loss = 0.131921 * 100, metric = 4.11% * 100;
 Minibatch[1601-1700]: loss = 0.123418 * 100, metric = 3.91% * 100;
 Minibatch[1701-1800]: loss = 0.130260 * 100, metric = 3.96% * 100;
 Minibatch[1801-1900]: loss = 0.125149 * 100, metric = 3.91% * 100;
 Minibatch[1901-2000]: loss = 0.134866 * 100, metric = 4.28% * 100;
Finished Epoch[74 of 200]: [Training] loss = 0.131015 * 2000, metric = 4.10% * 2000 842.392s (  2.4 samples/s);
Finished Evaluation [74]: Minibatch[1-2000]: metric = 12.35% * 2000;
0.4223478391431272
 Minibatch[   1- 100]: loss = 0.125842 * 100, metric = 3.95% * 100;
 Minibatch[ 101- 200]: loss = 0.137056 * 100, metric = 4.18% * 100;
 Minibatch[ 201- 300]: loss = 0.129488 * 100, metric = 4.04% * 100;
 Minibatch[ 301- 400]: loss = 0.123200 * 100, metric = 3.91% * 100;
 Minibatch[ 401- 500]: loss = 0.130060 * 100, metric = 3.98% * 100;
 Minibatch[ 501- 600]: loss = 0.129394 * 100, metric = 4.03% * 100;
 Minibatch[ 601- 700]: loss = 0.133855 * 100, metric = 4.18% * 100;
 Minibatch[ 701- 800]: loss = 0.134740 * 100, metric = 4.12% * 100;
 Minibatch[ 801- 900]: loss = 0.127205 * 100, metric = 3.89% * 100;
 Minibatch[ 901-1000]: loss = 0.121348 * 100, metric = 3.69% * 100;
 Minibatch[1001-1100]: loss = 0.129046 * 100, metric = 3.98% * 100;
 Minibatch[1101-1200]: loss = 0.124138 * 100, metric = 3.86% * 100;
 Minibatch[1201-1300]: loss = 0.127891 * 100, metric = 4.12% * 100;
 Minibatch[1301-1400]: loss = 0.120264 * 100, metric = 3.71% * 100;
 Minibatch[1401-1500]: loss = 0.119466 * 100, metric = 3.73% * 100;
 Minibatch[1501-1600]: loss = 0.130958 * 100, metric = 4.05% * 100;
 Minibatch[1601-1700]: loss = 0.127558 * 100, metric = 4.04% * 100;
 Minibatch[1701-1800]: loss = 0.124889 * 100, metric = 3.97% * 100;
 Minibatch[1801-1900]: loss = 0.126337 * 100, metric = 3.92% * 100;
 Minibatch[1901-2000]: loss = 0.124203 * 100, metric = 3.85% * 100;
Finished Epoch[75 of 200]: [Training] loss = 0.127347 * 2000, metric = 3.96% * 2000 843.421s (  2.4 samples/s);
Finished Evaluation [75]: Minibatch[1-2000]: metric = 13.04% * 2000;
 Minibatch[   1- 100]: loss = 0.119546 * 100, metric = 3.70% * 100;
 Minibatch[ 101- 200]: loss = 0.126532 * 100, metric = 3.88% * 100;
 Minibatch[ 201- 300]: loss = 0.141349 * 100, metric = 4.34% * 100;
 Minibatch[ 301- 400]: loss = 0.128759 * 100, metric = 4.08% * 100;
 Minibatch[ 401- 500]: loss = 0.128228 * 100, metric = 3.94% * 100;
 Minibatch[ 501- 600]: loss = 0.117312 * 100, metric = 3.67% * 100;
 Minibatch[ 601- 700]: loss = 0.121848 * 100, metric = 3.77% * 100;
 Minibatch[ 701- 800]: loss = 0.127060 * 100, metric = 3.96% * 100;
 Minibatch[ 801- 900]: loss = 0.130118 * 100, metric = 4.17% * 100;
 Minibatch[ 901-1000]: loss = 0.130030 * 100, metric = 4.04% * 100;
 Minibatch[1001-1100]: loss = 0.132330 * 100, metric = 4.13% * 100;
 Minibatch[1101-1200]: loss = 0.129950 * 100, metric = 4.15% * 100;
 Minibatch[1201-1300]: loss = 0.122261 * 100, metric = 3.80% * 100;
 Minibatch[1301-1400]: loss = 0.132906 * 100, metric = 4.20% * 100;
 Minibatch[1401-1500]: loss = 0.128490 * 100, metric = 3.94% * 100;
 Minibatch[1501-1600]: loss = 0.126604 * 100, metric = 3.90% * 100;
 Minibatch[1601-1700]: loss = 0.125373 * 100, metric = 4.01% * 100;
 Minibatch[1701-1800]: loss = 0.123635 * 100, metric = 3.75% * 100;
 Minibatch[1801-1900]: loss = 0.128412 * 100, metric = 3.93% * 100;
 Minibatch[1901-2000]: loss = 0.124035 * 100, metric = 3.89% * 100;
Finished Epoch[76 of 200]: [Training] loss = 0.127239 * 2000, metric = 3.96% * 2000 843.371s (  2.4 samples/s);
Finished Evaluation [76]: Minibatch[1-2000]: metric = 12.67% * 2000;
 Minibatch[   1- 100]: loss = 0.134268 * 100, metric = 4.28% * 100;
 Minibatch[ 101- 200]: loss = 0.130547 * 100, metric = 4.03% * 100;
 Minibatch[ 201- 300]: loss = 0.120250 * 100, metric = 3.60% * 100;
 Minibatch[ 301- 400]: loss = 0.133079 * 100, metric = 4.06% * 100;
 Minibatch[ 401- 500]: loss = 0.130081 * 100, metric = 3.98% * 100;
 Minibatch[ 501- 600]: loss = 0.124529 * 100, metric = 3.86% * 100;
 Minibatch[ 601- 700]: loss = 0.129812 * 100, metric = 4.03% * 100;
 Minibatch[ 701- 800]: loss = 0.124722 * 100, metric = 3.87% * 100;
 Minibatch[ 801- 900]: loss = 0.126442 * 100, metric = 4.08% * 100;
 Minibatch[ 901-1000]: loss = 0.120977 * 100, metric = 3.86% * 100;
 Minibatch[1001-1100]: loss = 0.131550 * 100, metric = 4.08% * 100;
 Minibatch[1101-1200]: loss = 0.133117 * 100, metric = 4.11% * 100;
 Minibatch[1201-1300]: loss = 0.135732 * 100, metric = 4.28% * 100;
 Minibatch[1301-1400]: loss = 0.125487 * 100, metric = 3.91% * 100;
 Minibatch[1401-1500]: loss = 0.129768 * 100, metric = 4.06% * 100;
 Minibatch[1501-1600]: loss = 0.126000 * 100, metric = 4.02% * 100;
 Minibatch[1601-1700]: loss = 0.127333 * 100, metric = 3.87% * 100;
 Minibatch[1701-1800]: loss = 0.121497 * 100, metric = 3.80% * 100;
 Minibatch[1801-1900]: loss = 0.130077 * 100, metric = 4.13% * 100;
 Minibatch[1901-2000]: loss = 0.122455 * 100, metric = 3.94% * 100;
Finished Epoch[77 of 200]: [Training] loss = 0.127886 * 2000, metric = 3.99% * 2000 845.109s (  2.4 samples/s);
Finished Evaluation [77]: Minibatch[1-2000]: metric = 12.30% * 2000;
 Minibatch[   1- 100]: loss = 0.122901 * 100, metric = 3.83% * 100;
 Minibatch[ 101- 200]: loss = 0.123279 * 100, metric = 3.88% * 100;
 Minibatch[ 201- 300]: loss = 0.115382 * 100, metric = 3.53% * 100;
 Minibatch[ 301- 400]: loss = 0.127573 * 100, metric = 3.87% * 100;
 Minibatch[ 401- 500]: loss = 0.131817 * 100, metric = 4.19% * 100;
 Minibatch[ 501- 600]: loss = 0.132625 * 100, metric = 4.16% * 100;
 Minibatch[ 601- 700]: loss = 0.128743 * 100, metric = 4.06% * 100;
 Minibatch[ 701- 800]: loss = 0.122773 * 100, metric = 3.72% * 100;
 Minibatch[ 801- 900]: loss = 0.114505 * 100, metric = 3.61% * 100;
 Minibatch[ 901-1000]: loss = 0.127291 * 100, metric = 3.96% * 100;
 Minibatch[1001-1100]: loss = 0.126214 * 100, metric = 3.99% * 100;
 Minibatch[1101-1200]: loss = 0.122351 * 100, metric = 3.89% * 100;
 Minibatch[1201-1300]: loss = 0.134495 * 100, metric = 4.21% * 100;
 Minibatch[1301-1400]: loss = 0.122604 * 100, metric = 3.83% * 100;
 Minibatch[1401-1500]: loss = 0.126722 * 100, metric = 3.98% * 100;
 Minibatch[1501-1600]: loss = 0.130575 * 100, metric = 4.01% * 100;
 Minibatch[1601-1700]: loss = 0.128607 * 100, metric = 4.00% * 100;
 Minibatch[1701-1800]: loss = 0.129648 * 100, metric = 3.93% * 100;
 Minibatch[1801-1900]: loss = 0.133050 * 100, metric = 4.21% * 100;
 Minibatch[1901-2000]: loss = 0.133785 * 100, metric = 4.20% * 100;
Finished Epoch[78 of 200]: [Training] loss = 0.126747 * 2000, metric = 3.95% * 2000 840.880s (  2.4 samples/s);
Finished Evaluation [78]: Minibatch[1-2000]: metric = 12.85% * 2000;
 Minibatch[   1- 100]: loss = 0.130416 * 100, metric = 4.04% * 100;
 Minibatch[ 101- 200]: loss = 0.123089 * 100, metric = 3.86% * 100;
 Minibatch[ 201- 300]: loss = 0.128229 * 100, metric = 3.97% * 100;
 Minibatch[ 301- 400]: loss = 0.124493 * 100, metric = 3.97% * 100;
 Minibatch[ 401- 500]: loss = 0.131676 * 100, metric = 4.08% * 100;
 Minibatch[ 501- 600]: loss = 0.128272 * 100, metric = 4.17% * 100;
 Minibatch[ 601- 700]: loss = 0.127352 * 100, metric = 4.21% * 100;
 Minibatch[ 701- 800]: loss = 0.122983 * 100, metric = 3.84% * 100;
 Minibatch[ 801- 900]: loss = 0.127750 * 100, metric = 3.85% * 100;
 Minibatch[ 901-1000]: loss = 0.130381 * 100, metric = 4.16% * 100;
 Minibatch[1001-1100]: loss = 0.132514 * 100, metric = 4.10% * 100;
 Minibatch[1101-1200]: loss = 0.118311 * 100, metric = 3.72% * 100;
 Minibatch[1201-1300]: loss = 0.135188 * 100, metric = 4.25% * 100;
 Minibatch[1301-1400]: loss = 0.125389 * 100, metric = 3.74% * 100;
 Minibatch[1401-1500]: loss = 0.125523 * 100, metric = 3.98% * 100;
 Minibatch[1501-1600]: loss = 0.130630 * 100, metric = 4.22% * 100;
 Minibatch[1601-1700]: loss = 0.125047 * 100, metric = 3.76% * 100;
 Minibatch[1701-1800]: loss = 0.124982 * 100, metric = 3.92% * 100;
 Minibatch[1801-1900]: loss = 0.128769 * 100, metric = 3.87% * 100;
 Minibatch[1901-2000]: loss = 0.132976 * 100, metric = 4.16% * 100;
Finished Epoch[79 of 200]: [Training] loss = 0.127699 * 2000, metric = 3.99% * 2000 841.120s (  2.4 samples/s);
Finished Evaluation [79]: Minibatch[1-2000]: metric = 12.18% * 2000;
 Minibatch[   1- 100]: loss = 0.122915 * 100, metric = 3.81% * 100;
 Minibatch[ 101- 200]: loss = 0.123934 * 100, metric = 3.74% * 100;
 Minibatch[ 201- 300]: loss = 0.119462 * 100, metric = 3.78% * 100;
 Minibatch[ 301- 400]: loss = 0.121384 * 100, metric = 3.85% * 100;
 Minibatch[ 401- 500]: loss = 0.132462 * 100, metric = 4.13% * 100;
 Minibatch[ 501- 600]: loss = 0.127740 * 100, metric = 4.17% * 100;
 Minibatch[ 601- 700]: loss = 0.128043 * 100, metric = 4.01% * 100;
 Minibatch[ 701- 800]: loss = 0.123320 * 100, metric = 3.77% * 100;
 Minibatch[ 801- 900]: loss = 0.126066 * 100, metric = 3.99% * 100;
 Minibatch[ 901-1000]: loss = 0.119986 * 100, metric = 3.74% * 100;
 Minibatch[1001-1100]: loss = 0.126709 * 100, metric = 4.00% * 100;
 Minibatch[1101-1200]: loss = 0.121394 * 100, metric = 3.70% * 100;
 Minibatch[1201-1300]: loss = 0.117769 * 100, metric = 3.73% * 100;
 Minibatch[1301-1400]: loss = 0.118709 * 100, metric = 3.73% * 100;
 Minibatch[1401-1500]: loss = 0.120009 * 100, metric = 3.74% * 100;
 Minibatch[1501-1600]: loss = 0.118990 * 100, metric = 3.66% * 100;
 Minibatch[1601-1700]: loss = 0.132165 * 100, metric = 4.20% * 100;
 Minibatch[1701-1800]: loss = 0.123301 * 100, metric = 3.80% * 100;
 Minibatch[1801-1900]: loss = 0.124172 * 100, metric = 3.85% * 100;
 Minibatch[1901-2000]: loss = 0.122616 * 100, metric = 3.82% * 100;
Finished Epoch[80 of 200]: [Training] loss = 0.123557 * 2000, metric = 3.86% * 2000 826.674s (  2.4 samples/s);
Finished Evaluation [80]: Minibatch[1-2000]: metric = 12.44% * 2000;
 Minibatch[   1- 100]: loss = 0.120909 * 100, metric = 3.74% * 100;
 Minibatch[ 101- 200]: loss = 0.125906 * 100, metric = 3.90% * 100;
 Minibatch[ 201- 300]: loss = 0.123021 * 100, metric = 3.77% * 100;
 Minibatch[ 301- 400]: loss = 0.125309 * 100, metric = 3.86% * 100;
 Minibatch[ 401- 500]: loss = 0.125047 * 100, metric = 3.90% * 100;
 Minibatch[ 501- 600]: loss = 0.120868 * 100, metric = 3.71% * 100;
 Minibatch[ 601- 700]: loss = 0.131513 * 100, metric = 4.24% * 100;
 Minibatch[ 701- 800]: loss = 0.123948 * 100, metric = 3.65% * 100;
 Minibatch[ 801- 900]: loss = 0.127626 * 100, metric = 3.95% * 100;
 Minibatch[ 901-1000]: loss = 0.119797 * 100, metric = 3.73% * 100;
 Minibatch[1001-1100]: loss = 0.128072 * 100, metric = 4.04% * 100;
 Minibatch[1101-1200]: loss = 0.128482 * 100, metric = 4.01% * 100;
 Minibatch[1201-1300]: loss = 0.126466 * 100, metric = 3.95% * 100;
 Minibatch[1301-1400]: loss = 0.129588 * 100, metric = 4.12% * 100;
 Minibatch[1401-1500]: loss = 0.125155 * 100, metric = 3.87% * 100;
 Minibatch[1501-1600]: loss = 0.127345 * 100, metric = 3.99% * 100;
 Minibatch[1601-1700]: loss = 0.124059 * 100, metric = 3.92% * 100;
 Minibatch[1701-1800]: loss = 0.128609 * 100, metric = 4.03% * 100;
 Minibatch[1801-1900]: loss = 0.123813 * 100, metric = 3.79% * 100;
 Minibatch[1901-2000]: loss = 0.127403 * 100, metric = 3.99% * 100;
Finished Epoch[81 of 200]: [Training] loss = 0.125647 * 2000, metric = 3.91% * 2000 821.455s (  2.4 samples/s);
Finished Evaluation [81]: Minibatch[1-2000]: metric = 12.47% * 2000;
 Minibatch[   1- 100]: loss = 0.124964 * 100, metric = 3.96% * 100;
 Minibatch[ 101- 200]: loss = 0.126869 * 100, metric = 3.94% * 100;
 Minibatch[ 201- 300]: loss = 0.125552 * 100, metric = 3.95% * 100;
 Minibatch[ 301- 400]: loss = 0.125865 * 100, metric = 3.96% * 100;
 Minibatch[ 401- 500]: loss = 0.121486 * 100, metric = 3.83% * 100;
 Minibatch[ 501- 600]: loss = 0.125708 * 100, metric = 3.94% * 100;
 Minibatch[ 601- 700]: loss = 0.116049 * 100, metric = 3.56% * 100;
 Minibatch[ 701- 800]: loss = 0.118739 * 100, metric = 3.72% * 100;
 Minibatch[ 801- 900]: loss = 0.128651 * 100, metric = 4.03% * 100;
 Minibatch[ 901-1000]: loss = 0.120285 * 100, metric = 3.71% * 100;
 Minibatch[1001-1100]: loss = 0.125633 * 100, metric = 3.96% * 100;
 Minibatch[1101-1200]: loss = 0.130899 * 100, metric = 4.00% * 100;
 Minibatch[1201-1300]: loss = 0.127301 * 100, metric = 3.89% * 100;
 Minibatch[1301-1400]: loss = 0.128890 * 100, metric = 4.02% * 100;
 Minibatch[1401-1500]: loss = 0.123122 * 100, metric = 3.77% * 100;
 Minibatch[1501-1600]: loss = 0.122235 * 100, metric = 3.71% * 100;
 Minibatch[1601-1700]: loss = 0.121959 * 100, metric = 3.84% * 100;
 Minibatch[1701-1800]: loss = 0.124415 * 100, metric = 3.83% * 100;
 Minibatch[1801-1900]: loss = 0.121872 * 100, metric = 3.72% * 100;
 Minibatch[1901-2000]: loss = 0.121015 * 100, metric = 3.78% * 100;
Finished Epoch[82 of 200]: [Training] loss = 0.124076 * 2000, metric = 3.86% * 2000 816.045s (  2.5 samples/s);
Finished Evaluation [82]: Minibatch[1-2000]: metric = 12.52% * 2000;
 Minibatch[   1- 100]: loss = 0.118058 * 100, metric = 3.64% * 100;
 Minibatch[ 101- 200]: loss = 0.129075 * 100, metric = 4.03% * 100;
 Minibatch[ 201- 300]: loss = 0.114720 * 100, metric = 3.61% * 100;
 Minibatch[ 301- 400]: loss = 0.124439 * 100, metric = 3.94% * 100;
 Minibatch[ 401- 500]: loss = 0.112036 * 100, metric = 3.43% * 100;
 Minibatch[ 501- 600]: loss = 0.119287 * 100, metric = 3.77% * 100;
 Minibatch[ 601- 700]: loss = 0.125562 * 100, metric = 3.79% * 100;
 Minibatch[ 701- 800]: loss = 0.113632 * 100, metric = 3.51% * 100;
 Minibatch[ 801- 900]: loss = 0.126631 * 100, metric = 3.96% * 100;
 Minibatch[ 901-1000]: loss = 0.124250 * 100, metric = 3.76% * 100;
 Minibatch[1001-1100]: loss = 0.119746 * 100, metric = 3.63% * 100;
 Minibatch[1101-1200]: loss = 0.118907 * 100, metric = 3.68% * 100;
 Minibatch[1201-1300]: loss = 0.121911 * 100, metric = 3.72% * 100;
 Minibatch[1301-1400]: loss = 0.108338 * 100, metric = 3.45% * 100;
 Minibatch[1401-1500]: loss = 0.115886 * 100, metric = 3.50% * 100;
 Minibatch[1501-1600]: loss = 0.123511 * 100, metric = 3.88% * 100;
 Minibatch[1601-1700]: loss = 0.116781 * 100, metric = 3.57% * 100;
 Minibatch[1701-1800]: loss = 0.115925 * 100, metric = 3.59% * 100;
 Minibatch[1801-1900]: loss = 0.125038 * 100, metric = 3.83% * 100;
 Minibatch[1901-2000]: loss = 0.119236 * 100, metric = 3.72% * 100;
Finished Epoch[83 of 200]: [Training] loss = 0.119648 * 2000, metric = 3.70% * 2000 826.398s (  2.4 samples/s);
Finished Evaluation [83]: Minibatch[1-2000]: metric = 12.85% * 2000;
 Minibatch[   1- 100]: loss = 0.118821 * 100, metric = 3.74% * 100;
 Minibatch[ 101- 200]: loss = 0.122845 * 100, metric = 3.86% * 100;
 Minibatch[ 201- 300]: loss = 0.119247 * 100, metric = 3.70% * 100;
 Minibatch[ 301- 400]: loss = 0.123176 * 100, metric = 3.81% * 100;
 Minibatch[ 401- 500]: loss = 0.114988 * 100, metric = 3.43% * 100;
 Minibatch[ 501- 600]: loss = 0.127178 * 100, metric = 3.83% * 100;
 Minibatch[ 601- 700]: loss = 0.126925 * 100, metric = 3.95% * 100;
 Minibatch[ 701- 800]: loss = 0.120207 * 100, metric = 3.64% * 100;
 Minibatch[ 801- 900]: loss = 0.122059 * 100, metric = 3.80% * 100;
 Minibatch[ 901-1000]: loss = 0.123221 * 100, metric = 3.93% * 100;
 Minibatch[1001-1100]: loss = 0.122766 * 100, metric = 3.83% * 100;
 Minibatch[1101-1200]: loss = 0.117786 * 100, metric = 3.68% * 100;
 Minibatch[1201-1300]: loss = 0.121711 * 100, metric = 3.76% * 100;
 Minibatch[1301-1400]: loss = 0.120224 * 100, metric = 3.76% * 100;
 Minibatch[1401-1500]: loss = 0.119937 * 100, metric = 3.81% * 100;
 Minibatch[1501-1600]: loss = 0.115546 * 100, metric = 3.54% * 100;
 Minibatch[1601-1700]: loss = 0.118319 * 100, metric = 3.67% * 100;
 Minibatch[1701-1800]: loss = 0.120947 * 100, metric = 3.74% * 100;
 Minibatch[1801-1900]: loss = 0.118921 * 100, metric = 3.67% * 100;
 Minibatch[1901-2000]: loss = 0.126572 * 100, metric = 4.00% * 100;
Finished Epoch[84 of 200]: [Training] loss = 0.121070 * 2000, metric = 3.76% * 2000 842.056s (  2.4 samples/s);
Finished Evaluation [84]: Minibatch[1-2000]: metric = 13.52% * 2000;
 Minibatch[   1- 100]: loss = 0.121667 * 100, metric = 3.74% * 100;
 Minibatch[ 101- 200]: loss = 0.120539 * 100, metric = 3.60% * 100;
 Minibatch[ 201- 300]: loss = 0.123585 * 100, metric = 3.85% * 100;
 Minibatch[ 301- 400]: loss = 0.122464 * 100, metric = 3.88% * 100;
 Minibatch[ 401- 500]: loss = 0.123620 * 100, metric = 3.72% * 100;
 Minibatch[ 501- 600]: loss = 0.124244 * 100, metric = 3.85% * 100;
 Minibatch[ 601- 700]: loss = 0.119746 * 100, metric = 3.65% * 100;
 Minibatch[ 701- 800]: loss = 0.122286 * 100, metric = 3.79% * 100;
 Minibatch[ 801- 900]: loss = 0.118798 * 100, metric = 3.71% * 100;
 Minibatch[ 901-1000]: loss = 0.124030 * 100, metric = 3.80% * 100;
 Minibatch[1001-1100]: loss = 0.124140 * 100, metric = 3.84% * 100;
 Minibatch[1101-1200]: loss = 0.118012 * 100, metric = 3.70% * 100;
 Minibatch[1201-1300]: loss = 0.115668 * 100, metric = 3.50% * 100;
 Minibatch[1301-1400]: loss = 0.124814 * 100, metric = 3.88% * 100;
 Minibatch[1401-1500]: loss = 0.118613 * 100, metric = 3.66% * 100;
 Minibatch[1501-1600]: loss = 0.127336 * 100, metric = 3.82% * 100;
 Minibatch[1601-1700]: loss = 0.125159 * 100, metric = 3.79% * 100;
 Minibatch[1701-1800]: loss = 0.116165 * 100, metric = 3.58% * 100;
 Minibatch[1801-1900]: loss = 0.121170 * 100, metric = 3.70% * 100;
 Minibatch[1901-2000]: loss = 0.119907 * 100, metric = 3.69% * 100;
Finished Epoch[85 of 200]: [Training] loss = 0.121598 * 2000, metric = 3.74% * 2000 830.729s (  2.4 samples/s);
Finished Evaluation [85]: Minibatch[1-2000]: metric = 12.53% * 2000;
 Minibatch[   1- 100]: loss = 0.123601 * 100, metric = 3.86% * 100;
 Minibatch[ 101- 200]: loss = 0.110320 * 100, metric = 3.36% * 100;
 Minibatch[ 201- 300]: loss = 0.120888 * 100, metric = 3.63% * 100;
 Minibatch[ 301- 400]: loss = 0.116885 * 100, metric = 3.67% * 100;
 Minibatch[ 401- 500]: loss = 0.123391 * 100, metric = 3.81% * 100;
 Minibatch[ 501- 600]: loss = 0.117297 * 100, metric = 3.62% * 100;
 Minibatch[ 601- 700]: loss = 0.127841 * 100, metric = 3.80% * 100;
 Minibatch[ 701- 800]: loss = 0.121327 * 100, metric = 3.90% * 100;
 Minibatch[ 801- 900]: loss = 0.111179 * 100, metric = 3.45% * 100;
 Minibatch[ 901-1000]: loss = 0.121850 * 100, metric = 3.79% * 100;
 Minibatch[1001-1100]: loss = 0.114643 * 100, metric = 3.53% * 100;
 Minibatch[1101-1200]: loss = 0.122158 * 100, metric = 3.72% * 100;
 Minibatch[1201-1300]: loss = 0.120592 * 100, metric = 3.75% * 100;
 Minibatch[1301-1400]: loss = 0.119270 * 100, metric = 3.66% * 100;
 Minibatch[1401-1500]: loss = 0.116776 * 100, metric = 3.71% * 100;
 Minibatch[1501-1600]: loss = 0.121004 * 100, metric = 3.59% * 100;
 Minibatch[1601-1700]: loss = 0.128856 * 100, metric = 3.88% * 100;
 Minibatch[1701-1800]: loss = 0.126339 * 100, metric = 3.97% * 100;
 Minibatch[1801-1900]: loss = 0.129946 * 100, metric = 3.92% * 100;
 Minibatch[1901-2000]: loss = 0.123971 * 100, metric = 3.91% * 100;
Finished Epoch[86 of 200]: [Training] loss = 0.120907 * 2000, metric = 3.73% * 2000 822.989s (  2.4 samples/s);
Finished Evaluation [86]: Minibatch[1-2000]: metric = 11.61% * 2000;
 Minibatch[   1- 100]: loss = 0.116672 * 100, metric = 3.67% * 100;
 Minibatch[ 101- 200]: loss = 0.124035 * 100, metric = 3.76% * 100;
 Minibatch[ 201- 300]: loss = 0.114783 * 100, metric = 3.56% * 100;
 Minibatch[ 301- 400]: loss = 0.123500 * 100, metric = 3.80% * 100;
 Minibatch[ 401- 500]: loss = 0.117871 * 100, metric = 3.63% * 100;
 Minibatch[ 501- 600]: loss = 0.121214 * 100, metric = 3.88% * 100;
 Minibatch[ 601- 700]: loss = 0.122652 * 100, metric = 3.76% * 100;
 Minibatch[ 701- 800]: loss = 0.117911 * 100, metric = 3.66% * 100;
 Minibatch[ 801- 900]: loss = 0.115776 * 100, metric = 3.70% * 100;
 Minibatch[ 901-1000]: loss = 0.121713 * 100, metric = 3.82% * 100;
 Minibatch[1001-1100]: loss = 0.127704 * 100, metric = 3.92% * 100;
 Minibatch[1101-1200]: loss = 0.109852 * 100, metric = 3.41% * 100;
 Minibatch[1201-1300]: loss = 0.119042 * 100, metric = 3.77% * 100;
 Minibatch[1301-1400]: loss = 0.120445 * 100, metric = 3.84% * 100;
 Minibatch[1401-1500]: loss = 0.117438 * 100, metric = 3.71% * 100;
 Minibatch[1501-1600]: loss = 0.120378 * 100, metric = 3.65% * 100;
 Minibatch[1601-1700]: loss = 0.128144 * 100, metric = 3.93% * 100;
 Minibatch[1701-1800]: loss = 0.119027 * 100, metric = 3.61% * 100;
 Minibatch[1801-1900]: loss = 0.121913 * 100, metric = 3.88% * 100;
 Minibatch[1901-2000]: loss = 0.121858 * 100, metric = 3.71% * 100;
Finished Epoch[87 of 200]: [Training] loss = 0.120096 * 2000, metric = 3.73% * 2000 825.620s (  2.4 samples/s);
Finished Evaluation [87]: Minibatch[1-2000]: metric = 12.54% * 2000;
 Minibatch[   1- 100]: loss = 0.118379 * 100, metric = 3.76% * 100;
 Minibatch[ 101- 200]: loss = 0.117502 * 100, metric = 3.69% * 100;
 Minibatch[ 201- 300]: loss = 0.120020 * 100, metric = 3.64% * 100;
 Minibatch[ 301- 400]: loss = 0.123496 * 100, metric = 4.00% * 100;
 Minibatch[ 401- 500]: loss = 0.122179 * 100, metric = 3.77% * 100;
 Minibatch[ 501- 600]: loss = 0.113690 * 100, metric = 3.45% * 100;
 Minibatch[ 601- 700]: loss = 0.114611 * 100, metric = 3.56% * 100;
 Minibatch[ 701- 800]: loss = 0.117817 * 100, metric = 3.64% * 100;
 Minibatch[ 801- 900]: loss = 0.131292 * 100, metric = 4.11% * 100;
 Minibatch[ 901-1000]: loss = 0.119892 * 100, metric = 3.69% * 100;
 Minibatch[1001-1100]: loss = 0.121525 * 100, metric = 3.64% * 100;
 Minibatch[1101-1200]: loss = 0.122312 * 100, metric = 3.80% * 100;
 Minibatch[1201-1300]: loss = 0.119270 * 100, metric = 3.63% * 100;
 Minibatch[1301-1400]: loss = 0.119959 * 100, metric = 3.71% * 100;
 Minibatch[1401-1500]: loss = 0.122337 * 100, metric = 3.92% * 100;
 Minibatch[1501-1600]: loss = 0.109560 * 100, metric = 3.39% * 100;
 Minibatch[1601-1700]: loss = 0.116666 * 100, metric = 3.54% * 100;
 Minibatch[1701-1800]: loss = 0.117448 * 100, metric = 3.59% * 100;
 Minibatch[1801-1900]: loss = 0.126966 * 100, metric = 3.93% * 100;
 Minibatch[1901-2000]: loss = 0.109662 * 100, metric = 3.31% * 100;
Finished Epoch[88 of 200]: [Training] loss = 0.119229 * 2000, metric = 3.69% * 2000 817.130s (  2.4 samples/s);
Finished Evaluation [88]: Minibatch[1-2000]: metric = 12.79% * 2000;
 Minibatch[   1- 100]: loss = 0.122114 * 100, metric = 3.77% * 100;
 Minibatch[ 101- 200]: loss = 0.122086 * 100, metric = 3.84% * 100;
 Minibatch[ 201- 300]: loss = 0.110618 * 100, metric = 3.43% * 100;
 Minibatch[ 301- 400]: loss = 0.116459 * 100, metric = 3.62% * 100;
 Minibatch[ 401- 500]: loss = 0.115404 * 100, metric = 3.53% * 100;
 Minibatch[ 501- 600]: loss = 0.124238 * 100, metric = 3.78% * 100;
 Minibatch[ 601- 700]: loss = 0.121790 * 100, metric = 3.87% * 100;
 Minibatch[ 701- 800]: loss = 0.120573 * 100, metric = 3.61% * 100;
 Minibatch[ 801- 900]: loss = 0.116796 * 100, metric = 3.66% * 100;
 Minibatch[ 901-1000]: loss = 0.124221 * 100, metric = 3.76% * 100;
 Minibatch[1001-1100]: loss = 0.125747 * 100, metric = 4.02% * 100;
 Minibatch[1101-1200]: loss = 0.120283 * 100, metric = 3.76% * 100;
 Minibatch[1201-1300]: loss = 0.121349 * 100, metric = 3.87% * 100;
 Minibatch[1301-1400]: loss = 0.122086 * 100, metric = 3.65% * 100;
 Minibatch[1401-1500]: loss = 0.129689 * 100, metric = 4.06% * 100;
 Minibatch[1501-1600]: loss = 0.120345 * 100, metric = 3.70% * 100;
 Minibatch[1601-1700]: loss = 0.123202 * 100, metric = 3.79% * 100;
 Minibatch[1701-1800]: loss = 0.122448 * 100, metric = 3.74% * 100;
 Minibatch[1801-1900]: loss = 0.121056 * 100, metric = 3.84% * 100;
 Minibatch[1901-2000]: loss = 0.118496 * 100, metric = 3.65% * 100;
Finished Epoch[89 of 200]: [Training] loss = 0.120950 * 2000, metric = 3.75% * 2000 825.445s (  2.4 samples/s);
Finished Evaluation [89]: Minibatch[1-2000]: metric = 11.78% * 2000;
0.4188547461908311
 Minibatch[   1- 100]: loss = 0.116138 * 100, metric = 3.67% * 100;
 Minibatch[ 101- 200]: loss = 0.114289 * 100, metric = 3.53% * 100;
 Minibatch[ 201- 300]: loss = 0.125648 * 100, metric = 3.88% * 100;
 Minibatch[ 301- 400]: loss = 0.115425 * 100, metric = 3.54% * 100;
 Minibatch[ 401- 500]: loss = 0.119296 * 100, metric = 3.73% * 100;
 Minibatch[ 501- 600]: loss = 0.127057 * 100, metric = 3.90% * 100;
 Minibatch[ 601- 700]: loss = 0.121217 * 100, metric = 3.72% * 100;
 Minibatch[ 701- 800]: loss = 0.117429 * 100, metric = 3.61% * 100;
 Minibatch[ 801- 900]: loss = 0.122176 * 100, metric = 3.74% * 100;
 Minibatch[ 901-1000]: loss = 0.123208 * 100, metric = 3.63% * 100;
 Minibatch[1001-1100]: loss = 0.115346 * 100, metric = 3.54% * 100;
 Minibatch[1101-1200]: loss = 0.111712 * 100, metric = 3.38% * 100;
 Minibatch[1201-1300]: loss = 0.109115 * 100, metric = 3.36% * 100;
 Minibatch[1301-1400]: loss = 0.117948 * 100, metric = 3.63% * 100;
 Minibatch[1401-1500]: loss = 0.117535 * 100, metric = 3.72% * 100;
 Minibatch[1501-1600]: loss = 0.108271 * 100, metric = 3.21% * 100;
 Minibatch[1601-1700]: loss = 0.111218 * 100, metric = 3.46% * 100;
 Minibatch[1701-1800]: loss = 0.115533 * 100, metric = 3.58% * 100;
 Minibatch[1801-1900]: loss = 0.114763 * 100, metric = 3.47% * 100;
 Minibatch[1901-2000]: loss = 0.112009 * 100, metric = 3.43% * 100;
Finished Epoch[90 of 200]: [Training] loss = 0.116766 * 2000, metric = 3.59% * 2000 838.393s (  2.4 samples/s);
Finished Evaluation [90]: Minibatch[1-2000]: metric = 12.37% * 2000;
 Minibatch[   1- 100]: loss = 0.115993 * 100, metric = 3.49% * 100;
 Minibatch[ 101- 200]: loss = 0.121600 * 100, metric = 3.77% * 100;
 Minibatch[ 201- 300]: loss = 0.115151 * 100, metric = 3.58% * 100;
 Minibatch[ 301- 400]: loss = 0.111254 * 100, metric = 3.32% * 100;
 Minibatch[ 401- 500]: loss = 0.117631 * 100, metric = 3.62% * 100;
 Minibatch[ 501- 600]: loss = 0.115401 * 100, metric = 3.59% * 100;
 Minibatch[ 601- 700]: loss = 0.117331 * 100, metric = 3.61% * 100;
 Minibatch[ 701- 800]: loss = 0.127543 * 100, metric = 3.91% * 100;
 Minibatch[ 801- 900]: loss = 0.109034 * 100, metric = 3.38% * 100;
 Minibatch[ 901-1000]: loss = 0.114597 * 100, metric = 3.48% * 100;
 Minibatch[1001-1100]: loss = 0.114881 * 100, metric = 3.53% * 100;
 Minibatch[1101-1200]: loss = 0.123352 * 100, metric = 3.78% * 100;
 Minibatch[1201-1300]: loss = 0.112323 * 100, metric = 3.47% * 100;
 Minibatch[1301-1400]: loss = 0.118000 * 100, metric = 3.74% * 100;
 Minibatch[1401-1500]: loss = 0.108345 * 100, metric = 3.36% * 100;
 Minibatch[1501-1600]: loss = 0.112808 * 100, metric = 3.48% * 100;
 Minibatch[1601-1700]: loss = 0.113153 * 100, metric = 3.45% * 100;
 Minibatch[1701-1800]: loss = 0.122367 * 100, metric = 3.68% * 100;
 Minibatch[1801-1900]: loss = 0.115349 * 100, metric = 3.61% * 100;
 Minibatch[1901-2000]: loss = 0.114021 * 100, metric = 3.59% * 100;
Finished Epoch[91 of 200]: [Training] loss = 0.116007 * 2000, metric = 3.57% * 2000 825.477s (  2.4 samples/s);
Finished Evaluation [91]: Minibatch[1-2000]: metric = 12.34% * 2000;
 Minibatch[   1- 100]: loss = 0.123800 * 100, metric = 3.75% * 100;
 Minibatch[ 101- 200]: loss = 0.115933 * 100, metric = 3.57% * 100;
 Minibatch[ 201- 300]: loss = 0.119389 * 100, metric = 3.61% * 100;
 Minibatch[ 301- 400]: loss = 0.116124 * 100, metric = 3.48% * 100;
 Minibatch[ 401- 500]: loss = 0.120078 * 100, metric = 3.68% * 100;
 Minibatch[ 501- 600]: loss = 0.123159 * 100, metric = 3.78% * 100;
 Minibatch[ 601- 700]: loss = 0.115030 * 100, metric = 3.63% * 100;
 Minibatch[ 701- 800]: loss = 0.118003 * 100, metric = 3.65% * 100;
 Minibatch[ 801- 900]: loss = 0.115037 * 100, metric = 3.62% * 100;
 Minibatch[ 901-1000]: loss = 0.112381 * 100, metric = 3.46% * 100;
 Minibatch[1001-1100]: loss = 0.110703 * 100, metric = 3.42% * 100;
 Minibatch[1101-1200]: loss = 0.115880 * 100, metric = 3.57% * 100;
 Minibatch[1201-1300]: loss = 0.122360 * 100, metric = 3.66% * 100;
 Minibatch[1301-1400]: loss = 0.121447 * 100, metric = 3.77% * 100;
 Minibatch[1401-1500]: loss = 0.109832 * 100, metric = 3.34% * 100;
 Minibatch[1501-1600]: loss = 0.120880 * 100, metric = 3.65% * 100;
 Minibatch[1601-1700]: loss = 0.114825 * 100, metric = 3.47% * 100;
 Minibatch[1701-1800]: loss = 0.112654 * 100, metric = 3.51% * 100;
 Minibatch[1801-1900]: loss = 0.109804 * 100, metric = 3.37% * 100;
 Minibatch[1901-2000]: loss = 0.121083 * 100, metric = 3.75% * 100;
Finished Epoch[92 of 200]: [Training] loss = 0.116920 * 2000, metric = 3.59% * 2000 836.647s (  2.4 samples/s);
Finished Evaluation [92]: Minibatch[1-2000]: metric = 12.04% * 2000;
 Minibatch[   1- 100]: loss = 0.117182 * 100, metric = 3.64% * 100;
 Minibatch[ 101- 200]: loss = 0.115691 * 100, metric = 3.51% * 100;
 Minibatch[ 201- 300]: loss = 0.116153 * 100, metric = 3.59% * 100;
 Minibatch[ 301- 400]: loss = 0.112594 * 100, metric = 3.48% * 100;
 Minibatch[ 401- 500]: loss = 0.112364 * 100, metric = 3.44% * 100;
 Minibatch[ 501- 600]: loss = 0.114700 * 100, metric = 3.58% * 100;
 Minibatch[ 601- 700]: loss = 0.111421 * 100, metric = 3.41% * 100;
 Minibatch[ 701- 800]: loss = 0.114059 * 100, metric = 3.60% * 100;
 Minibatch[ 801- 900]: loss = 0.111031 * 100, metric = 3.50% * 100;
 Minibatch[ 901-1000]: loss = 0.108182 * 100, metric = 3.33% * 100;
 Minibatch[1001-1100]: loss = 0.112259 * 100, metric = 3.49% * 100;
 Minibatch[1101-1200]: loss = 0.114755 * 100, metric = 3.41% * 100;
 Minibatch[1201-1300]: loss = 0.114984 * 100, metric = 3.51% * 100;
 Minibatch[1301-1400]: loss = 0.114382 * 100, metric = 3.52% * 100;
 Minibatch[1401-1500]: loss = 0.115015 * 100, metric = 3.45% * 100;
 Minibatch[1501-1600]: loss = 0.112387 * 100, metric = 3.46% * 100;
 Minibatch[1601-1700]: loss = 0.120186 * 100, metric = 3.67% * 100;
 Minibatch[1701-1800]: loss = 0.115627 * 100, metric = 3.48% * 100;
 Minibatch[1801-1900]: loss = 0.108774 * 100, metric = 3.35% * 100;
 Minibatch[1901-2000]: loss = 0.113924 * 100, metric = 3.40% * 100;
Finished Epoch[93 of 200]: [Training] loss = 0.113784 * 2000, metric = 3.49% * 2000 827.639s (  2.4 samples/s);
Finished Evaluation [93]: Minibatch[1-2000]: metric = 12.21% * 2000;
 Minibatch[   1- 100]: loss = 0.114565 * 100, metric = 3.47% * 100;
 Minibatch[ 101- 200]: loss = 0.116142 * 100, metric = 3.54% * 100;
 Minibatch[ 201- 300]: loss = 0.112844 * 100, metric = 3.52% * 100;
 Minibatch[ 301- 400]: loss = 0.109774 * 100, metric = 3.38% * 100;
 Minibatch[ 401- 500]: loss = 0.112380 * 100, metric = 3.37% * 100;
 Minibatch[ 501- 600]: loss = 0.107830 * 100, metric = 3.28% * 100;
 Minibatch[ 601- 700]: loss = 0.108512 * 100, metric = 3.29% * 100;
 Minibatch[ 701- 800]: loss = 0.115710 * 100, metric = 3.57% * 100;
 Minibatch[ 801- 900]: loss = 0.110467 * 100, metric = 3.45% * 100;
 Minibatch[ 901-1000]: loss = 0.113283 * 100, metric = 3.51% * 100;
 Minibatch[1001-1100]: loss = 0.113301 * 100, metric = 3.59% * 100;
 Minibatch[1101-1200]: loss = 0.116108 * 100, metric = 3.66% * 100;
 Minibatch[1201-1300]: loss = 0.113477 * 100, metric = 3.50% * 100;
 Minibatch[1301-1400]: loss = 0.111746 * 100, metric = 3.37% * 100;
 Minibatch[1401-1500]: loss = 0.115868 * 100, metric = 3.60% * 100;
 Minibatch[1501-1600]: loss = 0.117812 * 100, metric = 3.71% * 100;
 Minibatch[1601-1700]: loss = 0.112345 * 100, metric = 3.43% * 100;
 Minibatch[1701-1800]: loss = 0.115907 * 100, metric = 3.59% * 100;
 Minibatch[1801-1900]: loss = 0.116756 * 100, metric = 3.68% * 100;
 Minibatch[1901-2000]: loss = 0.110897 * 100, metric = 3.46% * 100;
Finished Epoch[94 of 200]: [Training] loss = 0.113286 * 2000, metric = 3.50% * 2000 822.575s (  2.4 samples/s);
Finished Evaluation [94]: Minibatch[1-2000]: metric = 12.66% * 2000;
 Minibatch[   1- 100]: loss = 0.112933 * 100, metric = 3.48% * 100;
 Minibatch[ 101- 200]: loss = 0.109953 * 100, metric = 3.31% * 100;
 Minibatch[ 201- 300]: loss = 0.110501 * 100, metric = 3.37% * 100;
 Minibatch[ 301- 400]: loss = 0.116425 * 100, metric = 3.61% * 100;
 Minibatch[ 401- 500]: loss = 0.111520 * 100, metric = 3.34% * 100;
 Minibatch[ 501- 600]: loss = 0.111468 * 100, metric = 3.43% * 100;
 Minibatch[ 601- 700]: loss = 0.110586 * 100, metric = 3.35% * 100;
 Minibatch[ 701- 800]: loss = 0.114694 * 100, metric = 3.54% * 100;
 Minibatch[ 801- 900]: loss = 0.114256 * 100, metric = 3.39% * 100;
 Minibatch[ 901-1000]: loss = 0.112583 * 100, metric = 3.49% * 100;
 Minibatch[1001-1100]: loss = 0.109734 * 100, metric = 3.30% * 100;
 Minibatch[1101-1200]: loss = 0.114408 * 100, metric = 3.51% * 100;
 Minibatch[1201-1300]: loss = 0.118083 * 100, metric = 3.61% * 100;
 Minibatch[1301-1400]: loss = 0.111520 * 100, metric = 3.44% * 100;
 Minibatch[1401-1500]: loss = 0.113841 * 100, metric = 3.46% * 100;
 Minibatch[1501-1600]: loss = 0.112808 * 100, metric = 3.38% * 100;
 Minibatch[1601-1700]: loss = 0.111518 * 100, metric = 3.34% * 100;
 Minibatch[1701-1800]: loss = 0.109645 * 100, metric = 3.35% * 100;
 Minibatch[1801-1900]: loss = 0.109711 * 100, metric = 3.38% * 100;
 Minibatch[1901-2000]: loss = 0.116485 * 100, metric = 3.53% * 100;
Finished Epoch[95 of 200]: [Training] loss = 0.112634 * 2000, metric = 3.43% * 2000 840.425s (  2.4 samples/s);
Finished Evaluation [95]: Minibatch[1-2000]: metric = 12.22% * 2000;
 Minibatch[   1- 100]: loss = 0.114471 * 100, metric = 3.53% * 100;
 Minibatch[ 101- 200]: loss = 0.120127 * 100, metric = 3.59% * 100;
 Minibatch[ 201- 300]: loss = 0.113699 * 100, metric = 3.54% * 100;
 Minibatch[ 301- 400]: loss = 0.107309 * 100, metric = 3.39% * 100;
 Minibatch[ 401- 500]: loss = 0.119485 * 100, metric = 3.68% * 100;
 Minibatch[ 501- 600]: loss = 0.106173 * 100, metric = 3.36% * 100;
 Minibatch[ 601- 700]: loss = 0.111891 * 100, metric = 3.29% * 100;
 Minibatch[ 701- 800]: loss = 0.116103 * 100, metric = 3.66% * 100;
 Minibatch[ 801- 900]: loss = 0.111887 * 100, metric = 3.53% * 100;
 Minibatch[ 901-1000]: loss = 0.112135 * 100, metric = 3.50% * 100;
 Minibatch[1001-1100]: loss = 0.117864 * 100, metric = 3.68% * 100;
 Minibatch[1101-1200]: loss = 0.105089 * 100, metric = 3.26% * 100;
 Minibatch[1201-1300]: loss = 0.116867 * 100, metric = 3.59% * 100;
 Minibatch[1301-1400]: loss = 0.114703 * 100, metric = 3.47% * 100;
 Minibatch[1401-1500]: loss = 0.110820 * 100, metric = 3.41% * 100;
 Minibatch[1501-1600]: loss = 0.111129 * 100, metric = 3.34% * 100;
 Minibatch[1601-1700]: loss = 0.109972 * 100, metric = 3.32% * 100;
 Minibatch[1701-1800]: loss = 0.112220 * 100, metric = 3.47% * 100;
 Minibatch[1801-1900]: loss = 0.115806 * 100, metric = 3.60% * 100;
 Minibatch[1901-2000]: loss = 0.124906 * 100, metric = 3.92% * 100;
Finished Epoch[96 of 200]: [Training] loss = 0.113633 * 2000, metric = 3.51% * 2000 820.705s (  2.4 samples/s);
Finished Evaluation [96]: Minibatch[1-2000]: metric = 12.23% * 2000;
 Minibatch[   1- 100]: loss = 0.121492 * 100, metric = 3.93% * 100;
 Minibatch[ 101- 200]: loss = 0.117434 * 100, metric = 3.56% * 100;
 Minibatch[ 201- 300]: loss = 0.108245 * 100, metric = 3.35% * 100;
 Minibatch[ 301- 400]: loss = 0.117975 * 100, metric = 3.65% * 100;
 Minibatch[ 401- 500]: loss = 0.117812 * 100, metric = 3.48% * 100;
 Minibatch[ 501- 600]: loss = 0.112861 * 100, metric = 3.47% * 100;
 Minibatch[ 601- 700]: loss = 0.124897 * 100, metric = 3.68% * 100;
 Minibatch[ 701- 800]: loss = 0.121026 * 100, metric = 3.79% * 100;
 Minibatch[ 801- 900]: loss = 0.116348 * 100, metric = 3.63% * 100;
 Minibatch[ 901-1000]: loss = 0.111327 * 100, metric = 3.36% * 100;
 Minibatch[1001-1100]: loss = 0.109333 * 100, metric = 3.37% * 100;
 Minibatch[1101-1200]: loss = 0.109411 * 100, metric = 3.29% * 100;
 Minibatch[1201-1300]: loss = 0.123074 * 100, metric = 3.66% * 100;
 Minibatch[1301-1400]: loss = 0.109908 * 100, metric = 3.31% * 100;
 Minibatch[1401-1500]: loss = 0.111196 * 100, metric = 3.39% * 100;
 Minibatch[1501-1600]: loss = 0.108599 * 100, metric = 3.34% * 100;
 Minibatch[1601-1700]: loss = 0.112863 * 100, metric = 3.43% * 100;
 Minibatch[1701-1800]: loss = 0.110805 * 100, metric = 3.35% * 100;
 Minibatch[1801-1900]: loss = 0.107981 * 100, metric = 3.36% * 100;
 Minibatch[1901-2000]: loss = 0.117561 * 100, metric = 3.54% * 100;
Finished Epoch[97 of 200]: [Training] loss = 0.114507 * 2000, metric = 3.50% * 2000 829.318s (  2.4 samples/s);
Finished Evaluation [97]: Minibatch[1-2000]: metric = 11.33% * 2000;
 Minibatch[   1- 100]: loss = 0.109891 * 100, metric = 3.32% * 100;
 Minibatch[ 101- 200]: loss = 0.106292 * 100, metric = 3.31% * 100;
 Minibatch[ 201- 300]: loss = 0.114487 * 100, metric = 3.66% * 100;
 Minibatch[ 301- 400]: loss = 0.117836 * 100, metric = 3.62% * 100;
 Minibatch[ 401- 500]: loss = 0.113372 * 100, metric = 3.42% * 100;
 Minibatch[ 501- 600]: loss = 0.111500 * 100, metric = 3.45% * 100;
 Minibatch[ 601- 700]: loss = 0.116351 * 100, metric = 3.53% * 100;
 Minibatch[ 701- 800]: loss = 0.111756 * 100, metric = 3.52% * 100;
 Minibatch[ 801- 900]: loss = 0.113073 * 100, metric = 3.44% * 100;
 Minibatch[ 901-1000]: loss = 0.113996 * 100, metric = 3.45% * 100;
 Minibatch[1001-1100]: loss = 0.109077 * 100, metric = 3.33% * 100;
 Minibatch[1101-1200]: loss = 0.108888 * 100, metric = 3.29% * 100;
 Minibatch[1201-1300]: loss = 0.109478 * 100, metric = 3.37% * 100;
 Minibatch[1301-1400]: loss = 0.109037 * 100, metric = 3.41% * 100;
 Minibatch[1401-1500]: loss = 0.118365 * 100, metric = 3.56% * 100;
 Minibatch[1501-1600]: loss = 0.113977 * 100, metric = 3.46% * 100;
 Minibatch[1601-1700]: loss = 0.112345 * 100, metric = 3.46% * 100;
 Minibatch[1701-1800]: loss = 0.109970 * 100, metric = 3.39% * 100;
 Minibatch[1801-1900]: loss = 0.115657 * 100, metric = 3.48% * 100;
 Minibatch[1901-2000]: loss = 0.113515 * 100, metric = 3.41% * 100;
Finished Epoch[98 of 200]: [Training] loss = 0.112443 * 2000, metric = 3.44% * 2000 809.223s (  2.5 samples/s);
Finished Evaluation [98]: Minibatch[1-2000]: metric = 11.91% * 2000;
 Minibatch[   1- 100]: loss = 0.122414 * 100, metric = 3.71% * 100;
 Minibatch[ 101- 200]: loss = 0.113599 * 100, metric = 3.57% * 100;
 Minibatch[ 201- 300]: loss = 0.101645 * 100, metric = 3.00% * 100;
 Minibatch[ 301- 400]: loss = 0.112856 * 100, metric = 3.40% * 100;
 Minibatch[ 401- 500]: loss = 0.112008 * 100, metric = 3.42% * 100;
 Minibatch[ 501- 600]: loss = 0.116806 * 100, metric = 3.62% * 100;
 Minibatch[ 601- 700]: loss = 0.118957 * 100, metric = 3.55% * 100;
 Minibatch[ 701- 800]: loss = 0.116471 * 100, metric = 3.45% * 100;
 Minibatch[ 801- 900]: loss = 0.109593 * 100, metric = 3.29% * 100;
 Minibatch[ 901-1000]: loss = 0.120684 * 100, metric = 3.69% * 100;
 Minibatch[1001-1100]: loss = 0.107228 * 100, metric = 3.31% * 100;
 Minibatch[1101-1200]: loss = 0.114882 * 100, metric = 3.54% * 100;
 Minibatch[1201-1300]: loss = 0.113159 * 100, metric = 3.47% * 100;
 Minibatch[1301-1400]: loss = 0.115374 * 100, metric = 3.61% * 100;
 Minibatch[1401-1500]: loss = 0.104460 * 100, metric = 3.15% * 100;
 Minibatch[1501-1600]: loss = 0.113600 * 100, metric = 3.35% * 100;
 Minibatch[1601-1700]: loss = 0.115503 * 100, metric = 3.51% * 100;
 Minibatch[1701-1800]: loss = 0.117550 * 100, metric = 3.52% * 100;
 Minibatch[1801-1900]: loss = 0.105563 * 100, metric = 3.23% * 100;
 Minibatch[1901-2000]: loss = 0.112204 * 100, metric = 3.52% * 100;
Finished Epoch[99 of 200]: [Training] loss = 0.113228 * 2000, metric = 3.44% * 2000 827.495s (  2.4 samples/s);
Finished Evaluation [99]: Minibatch[1-2000]: metric = 12.28% * 2000;
 Minibatch[   1- 100]: loss = 0.112846 * 100, metric = 3.39% * 100;
 Minibatch[ 101- 200]: loss = 0.114435 * 100, metric = 3.48% * 100;
 Minibatch[ 201- 300]: loss = 0.111680 * 100, metric = 3.52% * 100;
 Minibatch[ 301- 400]: loss = 0.108147 * 100, metric = 3.30% * 100;
 Minibatch[ 401- 500]: loss = 0.124333 * 100, metric = 3.73% * 100;
 Minibatch[ 501- 600]: loss = 0.113177 * 100, metric = 3.43% * 100;
 Minibatch[ 601- 700]: loss = 0.116065 * 100, metric = 3.47% * 100;
 Minibatch[ 701- 800]: loss = 0.109022 * 100, metric = 3.37% * 100;
 Minibatch[ 801- 900]: loss = 0.109689 * 100, metric = 3.38% * 100;
 Minibatch[ 901-1000]: loss = 0.101464 * 100, metric = 3.03% * 100;
 Minibatch[1001-1100]: loss = 0.109453 * 100, metric = 3.39% * 100;
 Minibatch[1101-1200]: loss = 0.110089 * 100, metric = 3.19% * 100;
 Minibatch[1201-1300]: loss = 0.105414 * 100, metric = 3.19% * 100;
 Minibatch[1301-1400]: loss = 0.109245 * 100, metric = 3.45% * 100;
 Minibatch[1401-1500]: loss = 0.113731 * 100, metric = 3.31% * 100;
 Minibatch[1501-1600]: loss = 0.107431 * 100, metric = 3.34% * 100;
 Minibatch[1601-1700]: loss = 0.109213 * 100, metric = 3.42% * 100;
 Minibatch[1701-1800]: loss = 0.103240 * 100, metric = 3.09% * 100;
 Minibatch[1801-1900]: loss = 0.114214 * 100, metric = 3.45% * 100;
 Minibatch[1901-2000]: loss = 0.114725 * 100, metric = 3.49% * 100;
Finished Epoch[100 of 200]: [Training] loss = 0.110881 * 2000, metric = 3.37% * 2000 822.549s (  2.4 samples/s);
Finished Evaluation [100]: Minibatch[1-2000]: metric = 11.80% * 2000;
 Minibatch[   1- 100]: loss = 0.110946 * 100, metric = 3.38% * 100;
 Minibatch[ 101- 200]: loss = 0.107275 * 100, metric = 3.23% * 100;
 Minibatch[ 201- 300]: loss = 0.100525 * 100, metric = 3.04% * 100;
 Minibatch[ 301- 400]: loss = 0.112444 * 100, metric = 3.44% * 100;
 Minibatch[ 401- 500]: loss = 0.110130 * 100, metric = 3.40% * 100;
 Minibatch[ 501- 600]: loss = 0.111552 * 100, metric = 3.61% * 100;
 Minibatch[ 601- 700]: loss = 0.101109 * 100, metric = 3.04% * 100;
 Minibatch[ 701- 800]: loss = 0.106832 * 100, metric = 3.18% * 100;
 Minibatch[ 801- 900]: loss = 0.102142 * 100, metric = 3.06% * 100;
 Minibatch[ 901-1000]: loss = 0.107870 * 100, metric = 3.21% * 100;
 Minibatch[1001-1100]: loss = 0.110293 * 100, metric = 3.42% * 100;
 Minibatch[1101-1200]: loss = 0.105528 * 100, metric = 3.19% * 100;
 Minibatch[1201-1300]: loss = 0.108622 * 100, metric = 3.34% * 100;
 Minibatch[1301-1400]: loss = 0.108585 * 100, metric = 3.32% * 100;
 Minibatch[1401-1500]: loss = 0.106047 * 100, metric = 3.16% * 100;
 Minibatch[1501-1600]: loss = 0.107174 * 100, metric = 3.25% * 100;
 Minibatch[1601-1700]: loss = 0.112741 * 100, metric = 3.42% * 100;
 Minibatch[1701-1800]: loss = 0.111532 * 100, metric = 3.30% * 100;
 Minibatch[1801-1900]: loss = 0.117578 * 100, metric = 3.59% * 100;
 Minibatch[1901-2000]: loss = 0.103293 * 100, metric = 3.19% * 100;
Finished Epoch[101 of 200]: [Training] loss = 0.108111 * 2000, metric = 3.29% * 2000 824.137s (  2.4 samples/s);
Finished Evaluation [101]: Minibatch[1-2000]: metric = 11.85% * 2000;
 Minibatch[   1- 100]: loss = 0.107713 * 100, metric = 3.30% * 100;
 Minibatch[ 101- 200]: loss = 0.110825 * 100, metric = 3.45% * 100;
 Minibatch[ 201- 300]: loss = 0.111389 * 100, metric = 3.41% * 100;
 Minibatch[ 301- 400]: loss = 0.112464 * 100, metric = 3.55% * 100;
 Minibatch[ 401- 500]: loss = 0.105910 * 100, metric = 3.25% * 100;
 Minibatch[ 501- 600]: loss = 0.095811 * 100, metric = 2.83% * 100;
 Minibatch[ 601- 700]: loss = 0.105315 * 100, metric = 3.27% * 100;
 Minibatch[ 701- 800]: loss = 0.109030 * 100, metric = 3.34% * 100;
 Minibatch[ 801- 900]: loss = 0.102226 * 100, metric = 3.11% * 100;
 Minibatch[ 901-1000]: loss = 0.111510 * 100, metric = 3.29% * 100;
 Minibatch[1001-1100]: loss = 0.107493 * 100, metric = 3.28% * 100;
 Minibatch[1101-1200]: loss = 0.101859 * 100, metric = 3.15% * 100;
 Minibatch[1201-1300]: loss = 0.098745 * 100, metric = 2.95% * 100;
 Minibatch[1301-1400]: loss = 0.100482 * 100, metric = 3.06% * 100;
 Minibatch[1401-1500]: loss = 0.108100 * 100, metric = 3.31% * 100;
 Minibatch[1501-1600]: loss = 0.110147 * 100, metric = 3.19% * 100;
 Minibatch[1601-1700]: loss = 0.110760 * 100, metric = 3.36% * 100;
 Minibatch[1701-1800]: loss = 0.103943 * 100, metric = 3.13% * 100;
 Minibatch[1801-1900]: loss = 0.106213 * 100, metric = 3.21% * 100;
 Minibatch[1901-2000]: loss = 0.111221 * 100, metric = 3.40% * 100;
Finished Epoch[102 of 200]: [Training] loss = 0.106558 * 2000, metric = 3.24% * 2000 828.357s (  2.4 samples/s);
Finished Evaluation [102]: Minibatch[1-2000]: metric = 11.27% * 2000;
 Minibatch[   1- 100]: loss = 0.110526 * 100, metric = 3.47% * 100;
 Minibatch[ 101- 200]: loss = 0.109574 * 100, metric = 3.42% * 100;
 Minibatch[ 201- 300]: loss = 0.105748 * 100, metric = 3.21% * 100;
 Minibatch[ 301- 400]: loss = 0.105042 * 100, metric = 3.09% * 100;
 Minibatch[ 401- 500]: loss = 0.107463 * 100, metric = 3.23% * 100;
 Minibatch[ 501- 600]: loss = 0.101398 * 100, metric = 3.06% * 100;
 Minibatch[ 601- 700]: loss = 0.111761 * 100, metric = 3.40% * 100;
 Minibatch[ 701- 800]: loss = 0.111485 * 100, metric = 3.37% * 100;
 Minibatch[ 801- 900]: loss = 0.105740 * 100, metric = 3.33% * 100;
 Minibatch[ 901-1000]: loss = 0.105231 * 100, metric = 3.23% * 100;
 Minibatch[1001-1100]: loss = 0.114539 * 100, metric = 3.59% * 100;
 Minibatch[1101-1200]: loss = 0.106629 * 100, metric = 3.26% * 100;
 Minibatch[1201-1300]: loss = 0.113290 * 100, metric = 3.42% * 100;
 Minibatch[1301-1400]: loss = 0.103924 * 100, metric = 3.14% * 100;
 Minibatch[1401-1500]: loss = 0.103321 * 100, metric = 3.13% * 100;
 Minibatch[1501-1600]: loss = 0.108441 * 100, metric = 3.25% * 100;
 Minibatch[1601-1700]: loss = 0.103524 * 100, metric = 3.10% * 100;
 Minibatch[1701-1800]: loss = 0.101739 * 100, metric = 3.11% * 100;
 Minibatch[1801-1900]: loss = 0.105843 * 100, metric = 3.29% * 100;
 Minibatch[1901-2000]: loss = 0.107722 * 100, metric = 3.24% * 100;
Finished Epoch[103 of 200]: [Training] loss = 0.107147 * 2000, metric = 3.27% * 2000 822.141s (  2.4 samples/s);
Finished Evaluation [103]: Minibatch[1-2000]: metric = 12.48% * 2000;
 Minibatch[   1- 100]: loss = 0.111930 * 100, metric = 3.49% * 100;
 Minibatch[ 101- 200]: loss = 0.109152 * 100, metric = 3.26% * 100;
 Minibatch[ 201- 300]: loss = 0.113333 * 100, metric = 3.46% * 100;
 Minibatch[ 301- 400]: loss = 0.099606 * 100, metric = 3.04% * 100;
 Minibatch[ 401- 500]: loss = 0.113660 * 100, metric = 3.44% * 100;
 Minibatch[ 501- 600]: loss = 0.109389 * 100, metric = 3.29% * 100;
 Minibatch[ 601- 700]: loss = 0.111263 * 100, metric = 3.32% * 100;
 Minibatch[ 701- 800]: loss = 0.107563 * 100, metric = 3.28% * 100;
 Minibatch[ 801- 900]: loss = 0.105835 * 100, metric = 3.19% * 100;
 Minibatch[ 901-1000]: loss = 0.104689 * 100, metric = 3.15% * 100;
 Minibatch[1001-1100]: loss = 0.113223 * 100, metric = 3.42% * 100;
 Minibatch[1101-1200]: loss = 0.110226 * 100, metric = 3.36% * 100;
 Minibatch[1201-1300]: loss = 0.105483 * 100, metric = 3.12% * 100;
 Minibatch[1301-1400]: loss = 0.110791 * 100, metric = 3.36% * 100;
 Minibatch[1401-1500]: loss = 0.104910 * 100, metric = 3.28% * 100;
 Minibatch[1501-1600]: loss = 0.114500 * 100, metric = 3.41% * 100;
 Minibatch[1601-1700]: loss = 0.101891 * 100, metric = 3.12% * 100;
 Minibatch[1701-1800]: loss = 0.107767 * 100, metric = 3.30% * 100;
 Minibatch[1801-1900]: loss = 0.102661 * 100, metric = 3.04% * 100;
 Minibatch[1901-2000]: loss = 0.100677 * 100, metric = 3.05% * 100;
Finished Epoch[104 of 200]: [Training] loss = 0.107927 * 2000, metric = 3.27% * 2000 833.935s (  2.4 samples/s);
Finished Evaluation [104]: Minibatch[1-2000]: metric = 12.74% * 2000;
 Minibatch[   1- 100]: loss = 0.114243 * 100, metric = 3.54% * 100;
 Minibatch[ 101- 200]: loss = 0.112555 * 100, metric = 3.43% * 100;
 Minibatch[ 201- 300]: loss = 0.110556 * 100, metric = 3.33% * 100;
 Minibatch[ 301- 400]: loss = 0.107915 * 100, metric = 3.27% * 100;
 Minibatch[ 401- 500]: loss = 0.109023 * 100, metric = 3.26% * 100;
 Minibatch[ 501- 600]: loss = 0.106553 * 100, metric = 3.31% * 100;
 Minibatch[ 601- 700]: loss = 0.105089 * 100, metric = 3.20% * 100;
 Minibatch[ 701- 800]: loss = 0.113425 * 100, metric = 3.48% * 100;
 Minibatch[ 801- 900]: loss = 0.106980 * 100, metric = 3.17% * 100;
 Minibatch[ 901-1000]: loss = 0.114866 * 100, metric = 3.55% * 100;
 Minibatch[1001-1100]: loss = 0.104198 * 100, metric = 3.23% * 100;
 Minibatch[1101-1200]: loss = 0.114972 * 100, metric = 3.58% * 100;
 Minibatch[1201-1300]: loss = 0.102056 * 100, metric = 3.12% * 100;
 Minibatch[1301-1400]: loss = 0.115686 * 100, metric = 3.54% * 100;
 Minibatch[1401-1500]: loss = 0.113989 * 100, metric = 3.37% * 100;
 Minibatch[1501-1600]: loss = 0.111464 * 100, metric = 3.33% * 100;
 Minibatch[1601-1700]: loss = 0.109837 * 100, metric = 3.25% * 100;
 Minibatch[1701-1800]: loss = 0.099187 * 100, metric = 3.04% * 100;
 Minibatch[1801-1900]: loss = 0.116770 * 100, metric = 3.56% * 100;
 Minibatch[1901-2000]: loss = 0.106679 * 100, metric = 3.21% * 100;
Finished Epoch[105 of 200]: [Training] loss = 0.109802 * 2000, metric = 3.34% * 2000 819.035s (  2.4 samples/s);
Finished Evaluation [105]: Minibatch[1-2000]: metric = 12.12% * 2000;
 Minibatch[   1- 100]: loss = 0.100902 * 100, metric = 2.99% * 100;
 Minibatch[ 101- 200]: loss = 0.107422 * 100, metric = 3.30% * 100;
 Minibatch[ 201- 300]: loss = 0.108462 * 100, metric = 3.29% * 100;
 Minibatch[ 301- 400]: loss = 0.112272 * 100, metric = 3.27% * 100;
 Minibatch[ 401- 500]: loss = 0.109545 * 100, metric = 3.23% * 100;
 Minibatch[ 501- 600]: loss = 0.108639 * 100, metric = 3.36% * 100;
 Minibatch[ 601- 700]: loss = 0.103485 * 100, metric = 3.08% * 100;
 Minibatch[ 701- 800]: loss = 0.105810 * 100, metric = 3.17% * 100;
 Minibatch[ 801- 900]: loss = 0.112888 * 100, metric = 3.36% * 100;
 Minibatch[ 901-1000]: loss = 0.104167 * 100, metric = 3.21% * 100;
 Minibatch[1001-1100]: loss = 0.109593 * 100, metric = 3.28% * 100;
 Minibatch[1101-1200]: loss = 0.107422 * 100, metric = 3.18% * 100;
 Minibatch[1201-1300]: loss = 0.110659 * 100, metric = 3.40% * 100;
 Minibatch[1301-1400]: loss = 0.105832 * 100, metric = 3.18% * 100;
 Minibatch[1401-1500]: loss = 0.111058 * 100, metric = 3.45% * 100;
 Minibatch[1501-1600]: loss = 0.105965 * 100, metric = 3.30% * 100;
 Minibatch[1601-1700]: loss = 0.110490 * 100, metric = 3.28% * 100;
 Minibatch[1701-1800]: loss = 0.109346 * 100, metric = 3.41% * 100;
 Minibatch[1801-1900]: loss = 0.107761 * 100, metric = 3.40% * 100;
 Minibatch[1901-2000]: loss = 0.112305 * 100, metric = 3.40% * 100;
Finished Epoch[106 of 200]: [Training] loss = 0.108201 * 2000, metric = 3.28% * 2000 827.802s (  2.4 samples/s);
Finished Evaluation [106]: Minibatch[1-2000]: metric = 11.79% * 2000;
 Minibatch[   1- 100]: loss = 0.103520 * 100, metric = 3.21% * 100;
 Minibatch[ 101- 200]: loss = 0.106448 * 100, metric = 3.18% * 100;
 Minibatch[ 201- 300]: loss = 0.108307 * 100, metric = 3.18% * 100;
 Minibatch[ 301- 400]: loss = 0.109269 * 100, metric = 3.38% * 100;
 Minibatch[ 401- 500]: loss = 0.107741 * 100, metric = 3.28% * 100;
 Minibatch[ 501- 600]: loss = 0.112708 * 100, metric = 3.34% * 100;
 Minibatch[ 601- 700]: loss = 0.106950 * 100, metric = 3.29% * 100;
 Minibatch[ 701- 800]: loss = 0.104061 * 100, metric = 3.07% * 100;
 Minibatch[ 801- 900]: loss = 0.106644 * 100, metric = 3.25% * 100;
 Minibatch[ 901-1000]: loss = 0.100210 * 100, metric = 3.03% * 100;
 Minibatch[1001-1100]: loss = 0.105601 * 100, metric = 3.22% * 100;
 Minibatch[1101-1200]: loss = 0.110101 * 100, metric = 3.18% * 100;
 Minibatch[1201-1300]: loss = 0.104007 * 100, metric = 3.17% * 100;
 Minibatch[1301-1400]: loss = 0.107040 * 100, metric = 3.32% * 100;
 Minibatch[1401-1500]: loss = 0.102410 * 100, metric = 3.06% * 100;
 Minibatch[1501-1600]: loss = 0.109267 * 100, metric = 3.35% * 100;
 Minibatch[1601-1700]: loss = 0.116766 * 100, metric = 3.70% * 100;
 Minibatch[1701-1800]: loss = 0.106677 * 100, metric = 3.35% * 100;
 Minibatch[1801-1900]: loss = 0.107021 * 100, metric = 3.33% * 100;
 Minibatch[1901-2000]: loss = 0.103688 * 100, metric = 3.18% * 100;
Finished Epoch[107 of 200]: [Training] loss = 0.106922 * 2000, metric = 3.25% * 2000 828.493s (  2.4 samples/s);
Finished Evaluation [107]: Minibatch[1-2000]: metric = 12.18% * 2000;
 Minibatch[   1- 100]: loss = 0.104741 * 100, metric = 3.12% * 100;
 Minibatch[ 101- 200]: loss = 0.109065 * 100, metric = 3.41% * 100;
 Minibatch[ 201- 300]: loss = 0.110403 * 100, metric = 3.26% * 100;
 Minibatch[ 301- 400]: loss = 0.105135 * 100, metric = 3.14% * 100;
 Minibatch[ 401- 500]: loss = 0.101160 * 100, metric = 3.04% * 100;
 Minibatch[ 501- 600]: loss = 0.104825 * 100, metric = 3.22% * 100;
 Minibatch[ 601- 700]: loss = 0.107888 * 100, metric = 3.29% * 100;
 Minibatch[ 701- 800]: loss = 0.108417 * 100, metric = 3.22% * 100;
 Minibatch[ 801- 900]: loss = 0.112413 * 100, metric = 3.60% * 100;
 Minibatch[ 901-1000]: loss = 0.102299 * 100, metric = 3.13% * 100;
 Minibatch[1001-1100]: loss = 0.106181 * 100, metric = 3.21% * 100;
 Minibatch[1101-1200]: loss = 0.103580 * 100, metric = 3.21% * 100;
 Minibatch[1201-1300]: loss = 0.104118 * 100, metric = 3.20% * 100;
 Minibatch[1301-1400]: loss = 0.108078 * 100, metric = 3.38% * 100;
 Minibatch[1401-1500]: loss = 0.105667 * 100, metric = 3.23% * 100;
 Minibatch[1501-1600]: loss = 0.103010 * 100, metric = 3.14% * 100;
 Minibatch[1601-1700]: loss = 0.106662 * 100, metric = 3.11% * 100;
 Minibatch[1701-1800]: loss = 0.101061 * 100, metric = 3.11% * 100;
 Minibatch[1801-1900]: loss = 0.107420 * 100, metric = 3.16% * 100;
 Minibatch[1901-2000]: loss = 0.113664 * 100, metric = 3.48% * 100;
Finished Epoch[108 of 200]: [Training] loss = 0.106289 * 2000, metric = 3.23% * 2000 816.083s (  2.5 samples/s);
Finished Evaluation [108]: Minibatch[1-2000]: metric = 11.27% * 2000;
 Minibatch[   1- 100]: loss = 0.111886 * 100, metric = 3.49% * 100;
 Minibatch[ 101- 200]: loss = 0.110557 * 100, metric = 3.32% * 100;
 Minibatch[ 201- 300]: loss = 0.110235 * 100, metric = 3.36% * 100;
 Minibatch[ 301- 400]: loss = 0.112653 * 100, metric = 3.35% * 100;
 Minibatch[ 401- 500]: loss = 0.103329 * 100, metric = 3.11% * 100;
 Minibatch[ 501- 600]: loss = 0.103936 * 100, metric = 3.06% * 100;
 Minibatch[ 601- 700]: loss = 0.103536 * 100, metric = 3.19% * 100;
 Minibatch[ 701- 800]: loss = 0.105506 * 100, metric = 3.31% * 100;
 Minibatch[ 801- 900]: loss = 0.101983 * 100, metric = 3.01% * 100;
 Minibatch[ 901-1000]: loss = 0.108165 * 100, metric = 3.36% * 100;
 Minibatch[1001-1100]: loss = 0.109734 * 100, metric = 3.29% * 100;
 Minibatch[1101-1200]: loss = 0.103312 * 100, metric = 3.11% * 100;
 Minibatch[1201-1300]: loss = 0.097914 * 100, metric = 2.80% * 100;
 Minibatch[1301-1400]: loss = 0.102137 * 100, metric = 3.09% * 100;
 Minibatch[1401-1500]: loss = 0.109969 * 100, metric = 3.29% * 100;
 Minibatch[1501-1600]: loss = 0.105806 * 100, metric = 3.29% * 100;
 Minibatch[1601-1700]: loss = 0.107214 * 100, metric = 3.34% * 100;
 Minibatch[1701-1800]: loss = 0.099243 * 100, metric = 3.03% * 100;
 Minibatch[1801-1900]: loss = 0.108914 * 100, metric = 3.34% * 100;
 Minibatch[1901-2000]: loss = 0.104742 * 100, metric = 3.15% * 100;
Finished Epoch[109 of 200]: [Training] loss = 0.106039 * 2000, metric = 3.21% * 2000 835.250s (  2.4 samples/s);
Finished Evaluation [109]: Minibatch[1-2000]: metric = 11.15% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
