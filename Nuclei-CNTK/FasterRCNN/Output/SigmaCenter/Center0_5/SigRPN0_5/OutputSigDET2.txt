Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.181095 * 100, metric = 23.67% * 100;
 Minibatch[ 101- 200]: loss = 1.043629 * 100, metric = 22.69% * 100;
 Minibatch[ 201- 300]: loss = 0.928802 * 100, metric = 21.04% * 100;
 Minibatch[ 301- 400]: loss = 0.934444 * 100, metric = 20.26% * 100;
 Minibatch[ 401- 500]: loss = 0.866933 * 100, metric = 19.05% * 100;
 Minibatch[ 501- 600]: loss = 0.870629 * 100, metric = 18.78% * 100;
 Minibatch[ 601- 700]: loss = 0.821581 * 100, metric = 16.83% * 100;
 Minibatch[ 701- 800]: loss = 0.785877 * 100, metric = 16.29% * 100;
 Minibatch[ 801- 900]: loss = 0.816035 * 100, metric = 16.81% * 100;
 Minibatch[ 901-1000]: loss = 0.832465 * 100, metric = 17.26% * 100;
 Minibatch[1001-1100]: loss = 0.809407 * 100, metric = 16.96% * 100;
 Minibatch[1101-1200]: loss = 0.791764 * 100, metric = 16.28% * 100;
 Minibatch[1201-1300]: loss = 0.784656 * 100, metric = 16.27% * 100;
 Minibatch[1301-1400]: loss = 0.769404 * 100, metric = 16.10% * 100;
 Minibatch[1401-1500]: loss = 0.774867 * 100, metric = 16.18% * 100;
 Minibatch[1501-1600]: loss = 0.744419 * 100, metric = 15.65% * 100;
 Minibatch[1601-1700]: loss = 0.734543 * 100, metric = 15.36% * 100;
 Minibatch[1701-1800]: loss = 0.748936 * 100, metric = 15.71% * 100;
 Minibatch[1801-1900]: loss = 0.743802 * 100, metric = 15.38% * 100;
 Minibatch[1901-2000]: loss = 0.730222 * 100, metric = 14.88% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.835675 * 2000, metric = 17.57% * 2000 1047.601s (  1.9 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 22.31% * 2000;
0.7373047337383032
 Minibatch[   1- 100]: loss = 0.716942 * 100, metric = 14.71% * 100;
 Minibatch[ 101- 200]: loss = 0.734863 * 100, metric = 15.54% * 100;
 Minibatch[ 201- 300]: loss = 0.730931 * 100, metric = 14.59% * 100;
 Minibatch[ 301- 400]: loss = 0.727987 * 100, metric = 14.76% * 100;
 Minibatch[ 401- 500]: loss = 0.718364 * 100, metric = 14.87% * 100;
 Minibatch[ 501- 600]: loss = 0.736754 * 100, metric = 14.58% * 100;
 Minibatch[ 601- 700]: loss = 0.702809 * 100, metric = 14.28% * 100;
 Minibatch[ 701- 800]: loss = 0.713537 * 100, metric = 14.65% * 100;
 Minibatch[ 801- 900]: loss = 0.706406 * 100, metric = 14.72% * 100;
 Minibatch[ 901-1000]: loss = 0.695600 * 100, metric = 14.05% * 100;
 Minibatch[1001-1100]: loss = 0.707075 * 100, metric = 14.37% * 100;
 Minibatch[1101-1200]: loss = 0.712508 * 100, metric = 14.54% * 100;
 Minibatch[1201-1300]: loss = 0.701723 * 100, metric = 14.48% * 100;
 Minibatch[1301-1400]: loss = 0.718446 * 100, metric = 14.52% * 100;
 Minibatch[1401-1500]: loss = 0.689011 * 100, metric = 13.68% * 100;
 Minibatch[1501-1600]: loss = 0.689408 * 100, metric = 13.98% * 100;
 Minibatch[1601-1700]: loss = 0.695187 * 100, metric = 14.13% * 100;
 Minibatch[1701-1800]: loss = 0.694457 * 100, metric = 14.23% * 100;
 Minibatch[1801-1900]: loss = 0.694034 * 100, metric = 14.04% * 100;
 Minibatch[1901-2000]: loss = 0.674636 * 100, metric = 13.91% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.708034 * 2000, metric = 14.43% * 2000 978.779s (  2.0 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 19.95% * 2000;
0.6844943420141936
 Minibatch[   1- 100]: loss = 0.699029 * 100, metric = 14.53% * 100;
 Minibatch[ 101- 200]: loss = 0.703971 * 100, metric = 14.36% * 100;
 Minibatch[ 201- 300]: loss = 0.689302 * 100, metric = 13.93% * 100;
 Minibatch[ 301- 400]: loss = 0.715685 * 100, metric = 14.62% * 100;
 Minibatch[ 401- 500]: loss = 0.706066 * 100, metric = 14.51% * 100;
 Minibatch[ 501- 600]: loss = 0.698735 * 100, metric = 13.90% * 100;
 Minibatch[ 601- 700]: loss = 0.706286 * 100, metric = 14.06% * 100;
 Minibatch[ 701- 800]: loss = 0.676668 * 100, metric = 13.46% * 100;
 Minibatch[ 801- 900]: loss = 0.701647 * 100, metric = 14.32% * 100;
 Minibatch[ 901-1000]: loss = 0.669033 * 100, metric = 13.75% * 100;
 Minibatch[1001-1100]: loss = 0.694614 * 100, metric = 14.37% * 100;
 Minibatch[1101-1200]: loss = 0.669771 * 100, metric = 13.62% * 100;
 Minibatch[1201-1300]: loss = 0.666641 * 100, metric = 13.40% * 100;
 Minibatch[1301-1400]: loss = 0.685550 * 100, metric = 13.88% * 100;
 Minibatch[1401-1500]: loss = 0.678005 * 100, metric = 13.54% * 100;
 Minibatch[1501-1600]: loss = 0.671893 * 100, metric = 13.45% * 100;
 Minibatch[1601-1700]: loss = 0.660665 * 100, metric = 13.15% * 100;
 Minibatch[1701-1800]: loss = 0.682994 * 100, metric = 13.92% * 100;
 Minibatch[1801-1900]: loss = 0.667021 * 100, metric = 13.25% * 100;
 Minibatch[1901-2000]: loss = 0.667350 * 100, metric = 13.45% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.685546 * 2000, metric = 13.88% * 2000 973.983s (  2.1 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 17.76% * 2000;
0.6685040229707956
 Minibatch[   1- 100]: loss = 0.684163 * 100, metric = 13.31% * 100;
 Minibatch[ 101- 200]: loss = 0.664067 * 100, metric = 13.24% * 100;
 Minibatch[ 201- 300]: loss = 0.678395 * 100, metric = 13.69% * 100;
 Minibatch[ 301- 400]: loss = 0.642881 * 100, metric = 12.79% * 100;
 Minibatch[ 401- 500]: loss = 0.675193 * 100, metric = 13.36% * 100;
 Minibatch[ 501- 600]: loss = 0.655612 * 100, metric = 12.98% * 100;
 Minibatch[ 601- 700]: loss = 0.667793 * 100, metric = 13.54% * 100;
 Minibatch[ 701- 800]: loss = 0.668575 * 100, metric = 13.40% * 100;
 Minibatch[ 801- 900]: loss = 0.663002 * 100, metric = 13.39% * 100;
 Minibatch[ 901-1000]: loss = 0.666756 * 100, metric = 13.80% * 100;
 Minibatch[1001-1100]: loss = 0.679732 * 100, metric = 13.89% * 100;
 Minibatch[1101-1200]: loss = 0.654467 * 100, metric = 13.22% * 100;
 Minibatch[1201-1300]: loss = 0.650731 * 100, metric = 12.98% * 100;
 Minibatch[1301-1400]: loss = 0.676051 * 100, metric = 13.77% * 100;
 Minibatch[1401-1500]: loss = 0.682183 * 100, metric = 13.69% * 100;
 Minibatch[1501-1600]: loss = 0.642462 * 100, metric = 12.77% * 100;
 Minibatch[1601-1700]: loss = 0.670443 * 100, metric = 13.62% * 100;
 Minibatch[1701-1800]: loss = 0.672811 * 100, metric = 13.73% * 100;
 Minibatch[1801-1900]: loss = 0.652378 * 100, metric = 13.01% * 100;
 Minibatch[1901-2000]: loss = 0.646057 * 100, metric = 12.99% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.664688 * 2000, metric = 13.36% * 2000 1006.942s (  2.0 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 20.85% * 2000;
 Minibatch[   1- 100]: loss = 0.677987 * 100, metric = 13.73% * 100;
 Minibatch[ 101- 200]: loss = 0.652835 * 100, metric = 13.10% * 100;
 Minibatch[ 201- 300]: loss = 0.639969 * 100, metric = 12.92% * 100;
 Minibatch[ 301- 400]: loss = 0.680650 * 100, metric = 13.66% * 100;
 Minibatch[ 401- 500]: loss = 0.632733 * 100, metric = 12.27% * 100;
 Minibatch[ 501- 600]: loss = 0.630412 * 100, metric = 12.31% * 100;
 Minibatch[ 601- 700]: loss = 0.637811 * 100, metric = 12.45% * 100;
 Minibatch[ 701- 800]: loss = 0.646811 * 100, metric = 12.83% * 100;
 Minibatch[ 801- 900]: loss = 0.634326 * 100, metric = 12.28% * 100;
 Minibatch[ 901-1000]: loss = 0.635891 * 100, metric = 12.73% * 100;
 Minibatch[1001-1100]: loss = 0.639488 * 100, metric = 12.63% * 100;
 Minibatch[1101-1200]: loss = 0.627449 * 100, metric = 12.38% * 100;
 Minibatch[1201-1300]: loss = 0.639485 * 100, metric = 12.52% * 100;
 Minibatch[1301-1400]: loss = 0.660833 * 100, metric = 12.95% * 100;
 Minibatch[1401-1500]: loss = 0.637631 * 100, metric = 12.75% * 100;
 Minibatch[1501-1600]: loss = 0.645044 * 100, metric = 12.83% * 100;
 Minibatch[1601-1700]: loss = 0.662933 * 100, metric = 13.44% * 100;
 Minibatch[1701-1800]: loss = 0.662706 * 100, metric = 13.30% * 100;
 Minibatch[1801-1900]: loss = 0.659785 * 100, metric = 13.14% * 100;
 Minibatch[1901-2000]: loss = 0.636088 * 100, metric = 12.59% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.647043 * 2000, metric = 12.84% * 2000 1008.994s (  2.0 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 18.97% * 2000;
 Minibatch[   1- 100]: loss = 0.635036 * 100, metric = 12.61% * 100;
 Minibatch[ 101- 200]: loss = 0.630412 * 100, metric = 12.61% * 100;
 Minibatch[ 201- 300]: loss = 0.635334 * 100, metric = 12.58% * 100;
 Minibatch[ 301- 400]: loss = 0.637240 * 100, metric = 12.31% * 100;
 Minibatch[ 401- 500]: loss = 0.613709 * 100, metric = 12.37% * 100;
 Minibatch[ 501- 600]: loss = 0.625698 * 100, metric = 12.31% * 100;
 Minibatch[ 601- 700]: loss = 0.625427 * 100, metric = 12.51% * 100;
 Minibatch[ 701- 800]: loss = 0.638301 * 100, metric = 12.58% * 100;
 Minibatch[ 801- 900]: loss = 0.635760 * 100, metric = 12.54% * 100;
 Minibatch[ 901-1000]: loss = 0.615495 * 100, metric = 12.24% * 100;
 Minibatch[1001-1100]: loss = 0.626804 * 100, metric = 12.10% * 100;
 Minibatch[1101-1200]: loss = 0.632849 * 100, metric = 12.53% * 100;
 Minibatch[1201-1300]: loss = 0.643414 * 100, metric = 12.79% * 100;
 Minibatch[1301-1400]: loss = 0.623018 * 100, metric = 12.68% * 100;
 Minibatch[1401-1500]: loss = 0.631902 * 100, metric = 12.78% * 100;
 Minibatch[1501-1600]: loss = 0.618208 * 100, metric = 11.80% * 100;
 Minibatch[1601-1700]: loss = 0.615835 * 100, metric = 12.08% * 100;
 Minibatch[1701-1800]: loss = 0.604098 * 100, metric = 11.80% * 100;
 Minibatch[1801-1900]: loss = 0.634159 * 100, metric = 12.76% * 100;
 Minibatch[1901-2000]: loss = 0.612789 * 100, metric = 12.17% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.626774 * 2000, metric = 12.41% * 2000 1007.816s (  2.0 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 21.65% * 2000;
 Minibatch[   1- 100]: loss = 0.618643 * 100, metric = 12.09% * 100;
 Minibatch[ 101- 200]: loss = 0.632248 * 100, metric = 12.38% * 100;
 Minibatch[ 201- 300]: loss = 0.616258 * 100, metric = 12.09% * 100;
 Minibatch[ 301- 400]: loss = 0.608317 * 100, metric = 11.80% * 100;
 Minibatch[ 401- 500]: loss = 0.623163 * 100, metric = 12.11% * 100;
 Minibatch[ 501- 600]: loss = 0.599754 * 100, metric = 11.74% * 100;
 Minibatch[ 601- 700]: loss = 0.619070 * 100, metric = 12.10% * 100;
 Minibatch[ 701- 800]: loss = 0.619135 * 100, metric = 12.00% * 100;
 Minibatch[ 801- 900]: loss = 0.616342 * 100, metric = 12.15% * 100;
 Minibatch[ 901-1000]: loss = 0.611931 * 100, metric = 12.04% * 100;
 Minibatch[1001-1100]: loss = 0.627843 * 100, metric = 12.58% * 100;
 Minibatch[1101-1200]: loss = 0.605077 * 100, metric = 11.91% * 100;
 Minibatch[1201-1300]: loss = 0.625082 * 100, metric = 12.44% * 100;
 Minibatch[1301-1400]: loss = 0.608132 * 100, metric = 11.80% * 100;
 Minibatch[1401-1500]: loss = 0.598553 * 100, metric = 11.60% * 100;
 Minibatch[1501-1600]: loss = 0.613754 * 100, metric = 11.92% * 100;
 Minibatch[1601-1700]: loss = 0.616072 * 100, metric = 12.26% * 100;
 Minibatch[1701-1800]: loss = 0.601350 * 100, metric = 11.84% * 100;
 Minibatch[1801-1900]: loss = 0.611521 * 100, metric = 12.11% * 100;
 Minibatch[1901-2000]: loss = 0.611906 * 100, metric = 12.26% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.614208 * 2000, metric = 12.06% * 2000 996.812s (  2.0 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.74% * 2000;
 Minibatch[   1- 100]: loss = 0.614790 * 100, metric = 12.19% * 100;
 Minibatch[ 101- 200]: loss = 0.608838 * 100, metric = 12.09% * 100;
 Minibatch[ 201- 300]: loss = 0.593699 * 100, metric = 11.69% * 100;
 Minibatch[ 301- 400]: loss = 0.600144 * 100, metric = 12.08% * 100;
 Minibatch[ 401- 500]: loss = 0.612871 * 100, metric = 12.16% * 100;
 Minibatch[ 501- 600]: loss = 0.631808 * 100, metric = 12.66% * 100;
 Minibatch[ 601- 700]: loss = 0.586425 * 100, metric = 11.53% * 100;
 Minibatch[ 701- 800]: loss = 0.618403 * 100, metric = 12.05% * 100;
 Minibatch[ 801- 900]: loss = 0.577551 * 100, metric = 10.89% * 100;
 Minibatch[ 901-1000]: loss = 0.569611 * 100, metric = 10.85% * 100;
 Minibatch[1001-1100]: loss = 0.570521 * 100, metric = 11.10% * 100;
 Minibatch[1101-1200]: loss = 0.579040 * 100, metric = 11.25% * 100;
 Minibatch[1201-1300]: loss = 0.594423 * 100, metric = 11.85% * 100;
 Minibatch[1301-1400]: loss = 0.603972 * 100, metric = 12.01% * 100;
 Minibatch[1401-1500]: loss = 0.588276 * 100, metric = 11.34% * 100;
 Minibatch[1501-1600]: loss = 0.589655 * 100, metric = 11.24% * 100;
 Minibatch[1601-1700]: loss = 0.578536 * 100, metric = 11.12% * 100;
 Minibatch[1701-1800]: loss = 0.583314 * 100, metric = 11.08% * 100;
 Minibatch[1801-1900]: loss = 0.592303 * 100, metric = 11.46% * 100;
 Minibatch[1901-2000]: loss = 0.590129 * 100, metric = 11.52% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.594216 * 2000, metric = 11.61% * 2000 1021.343s (  2.0 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 18.41% * 2000;
0.6475429768934846
 Minibatch[   1- 100]: loss = 0.569222 * 100, metric = 10.88% * 100;
 Minibatch[ 101- 200]: loss = 0.601207 * 100, metric = 11.82% * 100;
 Minibatch[ 201- 300]: loss = 0.591083 * 100, metric = 11.26% * 100;
 Minibatch[ 301- 400]: loss = 0.608694 * 100, metric = 11.98% * 100;
 Minibatch[ 401- 500]: loss = 0.587331 * 100, metric = 11.48% * 100;
 Minibatch[ 501- 600]: loss = 0.577928 * 100, metric = 11.19% * 100;
 Minibatch[ 601- 700]: loss = 0.581449 * 100, metric = 11.41% * 100;
 Minibatch[ 701- 800]: loss = 0.566867 * 100, metric = 10.72% * 100;
 Minibatch[ 801- 900]: loss = 0.575263 * 100, metric = 11.08% * 100;
 Minibatch[ 901-1000]: loss = 0.584861 * 100, metric = 11.64% * 100;
 Minibatch[1001-1100]: loss = 0.560300 * 100, metric = 10.54% * 100;
 Minibatch[1101-1200]: loss = 0.578048 * 100, metric = 11.24% * 100;
 Minibatch[1201-1300]: loss = 0.576618 * 100, metric = 11.22% * 100;
 Minibatch[1301-1400]: loss = 0.568696 * 100, metric = 10.67% * 100;
 Minibatch[1401-1500]: loss = 0.584370 * 100, metric = 11.51% * 100;
 Minibatch[1501-1600]: loss = 0.582651 * 100, metric = 11.02% * 100;
 Minibatch[1601-1700]: loss = 0.582749 * 100, metric = 11.30% * 100;
 Minibatch[1701-1800]: loss = 0.560522 * 100, metric = 10.39% * 100;
 Minibatch[1801-1900]: loss = 0.567494 * 100, metric = 10.75% * 100;
 Minibatch[1901-2000]: loss = 0.571635 * 100, metric = 10.98% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.578849 * 2000, metric = 11.15% * 2000 1008.344s (  2.0 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 17.54% * 2000;
0.6322847360298037
 Minibatch[   1- 100]: loss = 0.595086 * 100, metric = 12.11% * 100;
 Minibatch[ 101- 200]: loss = 0.565212 * 100, metric = 11.10% * 100;
 Minibatch[ 201- 300]: loss = 0.571491 * 100, metric = 10.91% * 100;
 Minibatch[ 301- 400]: loss = 0.565374 * 100, metric = 10.81% * 100;
 Minibatch[ 401- 500]: loss = 0.577716 * 100, metric = 11.49% * 100;
 Minibatch[ 501- 600]: loss = 0.553839 * 100, metric = 10.61% * 100;
 Minibatch[ 601- 700]: loss = 0.556486 * 100, metric = 10.69% * 100;
 Minibatch[ 701- 800]: loss = 0.545474 * 100, metric = 10.10% * 100;
 Minibatch[ 801- 900]: loss = 0.564550 * 100, metric = 10.80% * 100;
 Minibatch[ 901-1000]: loss = 0.569115 * 100, metric = 10.96% * 100;
 Minibatch[1001-1100]: loss = 0.571193 * 100, metric = 11.08% * 100;
 Minibatch[1101-1200]: loss = 0.569603 * 100, metric = 10.79% * 100;
 Minibatch[1201-1300]: loss = 0.565846 * 100, metric = 10.83% * 100;
 Minibatch[1301-1400]: loss = 0.561273 * 100, metric = 10.96% * 100;
 Minibatch[1401-1500]: loss = 0.552660 * 100, metric = 10.47% * 100;
 Minibatch[1501-1600]: loss = 0.568815 * 100, metric = 11.12% * 100;
 Minibatch[1601-1700]: loss = 0.553531 * 100, metric = 10.42% * 100;
 Minibatch[1701-1800]: loss = 0.567070 * 100, metric = 10.93% * 100;
 Minibatch[1801-1900]: loss = 0.576592 * 100, metric = 11.12% * 100;
 Minibatch[1901-2000]: loss = 0.547469 * 100, metric = 10.54% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.564920 * 2000, metric = 10.89% * 2000 984.985s (  2.0 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 17.42% * 2000;
 Minibatch[   1- 100]: loss = 0.543715 * 100, metric = 10.36% * 100;
 Minibatch[ 101- 200]: loss = 0.560676 * 100, metric = 10.73% * 100;
 Minibatch[ 201- 300]: loss = 0.569059 * 100, metric = 11.31% * 100;
 Minibatch[ 301- 400]: loss = 0.562335 * 100, metric = 10.90% * 100;
 Minibatch[ 401- 500]: loss = 0.556483 * 100, metric = 10.79% * 100;
 Minibatch[ 501- 600]: loss = 0.562263 * 100, metric = 11.03% * 100;
 Minibatch[ 601- 700]: loss = 0.548536 * 100, metric = 10.61% * 100;
 Minibatch[ 701- 800]: loss = 0.566465 * 100, metric = 10.98% * 100;
 Minibatch[ 801- 900]: loss = 0.554537 * 100, metric = 10.66% * 100;
 Minibatch[ 901-1000]: loss = 0.556925 * 100, metric = 10.60% * 100;
 Minibatch[1001-1100]: loss = 0.552887 * 100, metric = 10.70% * 100;
 Minibatch[1101-1200]: loss = 0.559826 * 100, metric = 11.01% * 100;
 Minibatch[1201-1300]: loss = 0.549965 * 100, metric = 10.57% * 100;
 Minibatch[1301-1400]: loss = 0.534540 * 100, metric = 10.25% * 100;
 Minibatch[1401-1500]: loss = 0.559453 * 100, metric = 10.97% * 100;
 Minibatch[1501-1600]: loss = 0.539078 * 100, metric = 10.12% * 100;
 Minibatch[1601-1700]: loss = 0.536528 * 100, metric = 10.19% * 100;
 Minibatch[1701-1800]: loss = 0.564528 * 100, metric = 11.12% * 100;
 Minibatch[1801-1900]: loss = 0.548805 * 100, metric = 10.73% * 100;
 Minibatch[1901-2000]: loss = 0.546661 * 100, metric = 10.92% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.553663 * 2000, metric = 10.73% * 2000 986.787s (  2.0 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 18.15% * 2000;
 Minibatch[   1- 100]: loss = 0.534906 * 100, metric = 10.44% * 100;
 Minibatch[ 101- 200]: loss = 0.543956 * 100, metric = 10.06% * 100;
 Minibatch[ 201- 300]: loss = 0.545290 * 100, metric = 10.84% * 100;
 Minibatch[ 301- 400]: loss = 0.578584 * 100, metric = 11.49% * 100;
 Minibatch[ 401- 500]: loss = 0.542472 * 100, metric = 10.28% * 100;
 Minibatch[ 501- 600]: loss = 0.531861 * 100, metric = 9.98% * 100;
 Minibatch[ 601- 700]: loss = 0.533991 * 100, metric = 10.07% * 100;
 Minibatch[ 701- 800]: loss = 0.537288 * 100, metric = 10.36% * 100;
 Minibatch[ 801- 900]: loss = 0.543388 * 100, metric = 10.41% * 100;
 Minibatch[ 901-1000]: loss = 0.549389 * 100, metric = 10.77% * 100;
 Minibatch[1001-1100]: loss = 0.546232 * 100, metric = 10.58% * 100;
 Minibatch[1101-1200]: loss = 0.552755 * 100, metric = 10.65% * 100;
 Minibatch[1201-1300]: loss = 0.555162 * 100, metric = 11.01% * 100;
 Minibatch[1301-1400]: loss = 0.546374 * 100, metric = 10.37% * 100;
 Minibatch[1401-1500]: loss = 0.555643 * 100, metric = 10.99% * 100;
 Minibatch[1501-1600]: loss = 0.526268 * 100, metric = 10.03% * 100;
 Minibatch[1601-1700]: loss = 0.543229 * 100, metric = 10.56% * 100;
 Minibatch[1701-1800]: loss = 0.526052 * 100, metric = 9.91% * 100;
 Minibatch[1801-1900]: loss = 0.533760 * 100, metric = 10.12% * 100;
 Minibatch[1901-2000]: loss = 0.546963 * 100, metric = 10.72% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.543678 * 2000, metric = 10.48% * 2000 997.137s (  2.0 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 18.73% * 2000;
 Minibatch[   1- 100]: loss = 0.546610 * 100, metric = 10.66% * 100;
 Minibatch[ 101- 200]: loss = 0.539641 * 100, metric = 10.47% * 100;
 Minibatch[ 201- 300]: loss = 0.531027 * 100, metric = 10.21% * 100;
 Minibatch[ 301- 400]: loss = 0.544609 * 100, metric = 10.54% * 100;
 Minibatch[ 401- 500]: loss = 0.534076 * 100, metric = 10.67% * 100;
 Minibatch[ 501- 600]: loss = 0.545594 * 100, metric = 10.86% * 100;
 Minibatch[ 601- 700]: loss = 0.521220 * 100, metric = 9.85% * 100;
 Minibatch[ 701- 800]: loss = 0.520509 * 100, metric = 9.87% * 100;
 Minibatch[ 801- 900]: loss = 0.524656 * 100, metric = 9.99% * 100;
 Minibatch[ 901-1000]: loss = 0.541513 * 100, metric = 10.47% * 100;
 Minibatch[1001-1100]: loss = 0.536856 * 100, metric = 10.34% * 100;
 Minibatch[1101-1200]: loss = 0.526947 * 100, metric = 10.15% * 100;
 Minibatch[1201-1300]: loss = 0.530686 * 100, metric = 10.30% * 100;
 Minibatch[1301-1400]: loss = 0.520880 * 100, metric = 9.81% * 100;
 Minibatch[1401-1500]: loss = 0.523075 * 100, metric = 9.98% * 100;
 Minibatch[1501-1600]: loss = 0.512637 * 100, metric = 9.76% * 100;
 Minibatch[1601-1700]: loss = 0.503241 * 100, metric = 9.49% * 100;
 Minibatch[1701-1800]: loss = 0.526953 * 100, metric = 9.98% * 100;
 Minibatch[1801-1900]: loss = 0.515106 * 100, metric = 9.79% * 100;
 Minibatch[1901-2000]: loss = 0.530048 * 100, metric = 10.45% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.528794 * 2000, metric = 10.18% * 2000 994.891s (  2.0 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 20.07% * 2000;
 Minibatch[   1- 100]: loss = 0.515605 * 100, metric = 9.74% * 100;
 Minibatch[ 101- 200]: loss = 0.505438 * 100, metric = 9.65% * 100;
 Minibatch[ 201- 300]: loss = 0.529292 * 100, metric = 10.21% * 100;
 Minibatch[ 301- 400]: loss = 0.525041 * 100, metric = 10.19% * 100;
 Minibatch[ 401- 500]: loss = 0.518600 * 100, metric = 10.18% * 100;
 Minibatch[ 501- 600]: loss = 0.523285 * 100, metric = 10.11% * 100;
 Minibatch[ 601- 700]: loss = 0.512790 * 100, metric = 9.81% * 100;
 Minibatch[ 701- 800]: loss = 0.532967 * 100, metric = 10.42% * 100;
 Minibatch[ 801- 900]: loss = 0.535599 * 100, metric = 10.41% * 100;
 Minibatch[ 901-1000]: loss = 0.532444 * 100, metric = 10.36% * 100;
 Minibatch[1001-1100]: loss = 0.523369 * 100, metric = 10.16% * 100;
 Minibatch[1101-1200]: loss = 0.519437 * 100, metric = 9.81% * 100;
 Minibatch[1201-1300]: loss = 0.498856 * 100, metric = 9.29% * 100;
 Minibatch[1301-1400]: loss = 0.526244 * 100, metric = 10.61% * 100;
 Minibatch[1401-1500]: loss = 0.516915 * 100, metric = 10.02% * 100;
 Minibatch[1501-1600]: loss = 0.503622 * 100, metric = 9.81% * 100;
 Minibatch[1601-1700]: loss = 0.520211 * 100, metric = 10.02% * 100;
 Minibatch[1701-1800]: loss = 0.508405 * 100, metric = 9.58% * 100;
 Minibatch[1801-1900]: loss = 0.510233 * 100, metric = 9.73% * 100;
 Minibatch[1901-2000]: loss = 0.523871 * 100, metric = 10.08% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.519111 * 2000, metric = 10.01% * 2000 1003.778s (  2.0 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 19.32% * 2000;
 Minibatch[   1- 100]: loss = 0.505106 * 100, metric = 9.70% * 100;
 Minibatch[ 101- 200]: loss = 0.515068 * 100, metric = 10.01% * 100;
 Minibatch[ 201- 300]: loss = 0.510478 * 100, metric = 9.81% * 100;
 Minibatch[ 301- 400]: loss = 0.501826 * 100, metric = 9.53% * 100;
 Minibatch[ 401- 500]: loss = 0.505127 * 100, metric = 9.70% * 100;
 Minibatch[ 501- 600]: loss = 0.500264 * 100, metric = 9.53% * 100;
 Minibatch[ 601- 700]: loss = 0.489038 * 100, metric = 9.39% * 100;
 Minibatch[ 701- 800]: loss = 0.513640 * 100, metric = 9.97% * 100;
 Minibatch[ 801- 900]: loss = 0.525056 * 100, metric = 10.54% * 100;
 Minibatch[ 901-1000]: loss = 0.511546 * 100, metric = 9.84% * 100;
 Minibatch[1001-1100]: loss = 0.518452 * 100, metric = 10.04% * 100;
 Minibatch[1101-1200]: loss = 0.505502 * 100, metric = 9.65% * 100;
 Minibatch[1201-1300]: loss = 0.502540 * 100, metric = 9.59% * 100;
 Minibatch[1301-1400]: loss = 0.522986 * 100, metric = 10.39% * 100;
 Minibatch[1401-1500]: loss = 0.484750 * 100, metric = 9.28% * 100;
 Minibatch[1501-1600]: loss = 0.499927 * 100, metric = 9.64% * 100;
 Minibatch[1601-1700]: loss = 0.503060 * 100, metric = 9.49% * 100;
 Minibatch[1701-1800]: loss = 0.492378 * 100, metric = 9.32% * 100;
 Minibatch[1801-1900]: loss = 0.499428 * 100, metric = 9.69% * 100;
 Minibatch[1901-2000]: loss = 0.497907 * 100, metric = 9.57% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.505204 * 2000, metric = 9.74% * 2000 981.508s (  2.0 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 16.58% * 2000;
0.6057484727054835
 Minibatch[   1- 100]: loss = 0.513149 * 100, metric = 10.19% * 100;
 Minibatch[ 101- 200]: loss = 0.498689 * 100, metric = 9.47% * 100;
 Minibatch[ 201- 300]: loss = 0.503668 * 100, metric = 9.69% * 100;
 Minibatch[ 301- 400]: loss = 0.512712 * 100, metric = 9.94% * 100;
 Minibatch[ 401- 500]: loss = 0.482103 * 100, metric = 9.17% * 100;
 Minibatch[ 501- 600]: loss = 0.497377 * 100, metric = 9.48% * 100;
 Minibatch[ 601- 700]: loss = 0.493778 * 100, metric = 9.44% * 100;
 Minibatch[ 701- 800]: loss = 0.495202 * 100, metric = 9.58% * 100;
 Minibatch[ 801- 900]: loss = 0.483712 * 100, metric = 9.20% * 100;
 Minibatch[ 901-1000]: loss = 0.499595 * 100, metric = 9.72% * 100;
 Minibatch[1001-1100]: loss = 0.484738 * 100, metric = 9.55% * 100;
 Minibatch[1101-1200]: loss = 0.493395 * 100, metric = 9.36% * 100;
 Minibatch[1201-1300]: loss = 0.487806 * 100, metric = 9.28% * 100;
 Minibatch[1301-1400]: loss = 0.490136 * 100, metric = 9.52% * 100;
 Minibatch[1401-1500]: loss = 0.485930 * 100, metric = 9.29% * 100;
 Minibatch[1501-1600]: loss = 0.490853 * 100, metric = 9.49% * 100;
 Minibatch[1601-1700]: loss = 0.487408 * 100, metric = 9.40% * 100;
 Minibatch[1701-1800]: loss = 0.504226 * 100, metric = 9.69% * 100;
 Minibatch[1801-1900]: loss = 0.499828 * 100, metric = 9.88% * 100;
 Minibatch[1901-2000]: loss = 0.483677 * 100, metric = 9.52% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.494399 * 2000, metric = 9.54% * 2000 1010.931s (  2.0 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 17.19% * 2000;
 Minibatch[   1- 100]: loss = 0.477337 * 100, metric = 9.13% * 100;
 Minibatch[ 101- 200]: loss = 0.493848 * 100, metric = 9.45% * 100;
 Minibatch[ 201- 300]: loss = 0.493241 * 100, metric = 9.59% * 100;
 Minibatch[ 301- 400]: loss = 0.487826 * 100, metric = 9.29% * 100;
 Minibatch[ 401- 500]: loss = 0.492173 * 100, metric = 9.37% * 100;
 Minibatch[ 501- 600]: loss = 0.481341 * 100, metric = 8.94% * 100;
 Minibatch[ 601- 700]: loss = 0.462421 * 100, metric = 8.55% * 100;
 Minibatch[ 701- 800]: loss = 0.480458 * 100, metric = 9.01% * 100;
 Minibatch[ 801- 900]: loss = 0.484865 * 100, metric = 9.36% * 100;
 Minibatch[ 901-1000]: loss = 0.478552 * 100, metric = 9.01% * 100;
 Minibatch[1001-1100]: loss = 0.463162 * 100, metric = 8.82% * 100;
 Minibatch[1101-1200]: loss = 0.486664 * 100, metric = 9.26% * 100;
 Minibatch[1201-1300]: loss = 0.484530 * 100, metric = 9.37% * 100;
 Minibatch[1301-1400]: loss = 0.475322 * 100, metric = 8.77% * 100;
 Minibatch[1401-1500]: loss = 0.479995 * 100, metric = 9.45% * 100;
 Minibatch[1501-1600]: loss = 0.481557 * 100, metric = 9.29% * 100;
 Minibatch[1601-1700]: loss = 0.480727 * 100, metric = 9.03% * 100;
 Minibatch[1701-1800]: loss = 0.466426 * 100, metric = 8.85% * 100;
 Minibatch[1801-1900]: loss = 0.489440 * 100, metric = 9.49% * 100;
 Minibatch[1901-2000]: loss = 0.495249 * 100, metric = 9.56% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.481757 * 2000, metric = 9.18% * 2000 1001.656s (  2.0 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 16.61% * 2000;
0.6037989217787981
 Minibatch[   1- 100]: loss = 0.460425 * 100, metric = 8.65% * 100;
 Minibatch[ 101- 200]: loss = 0.488710 * 100, metric = 9.32% * 100;
 Minibatch[ 201- 300]: loss = 0.464866 * 100, metric = 8.84% * 100;
 Minibatch[ 301- 400]: loss = 0.481540 * 100, metric = 9.04% * 100;
 Minibatch[ 401- 500]: loss = 0.460261 * 100, metric = 8.64% * 100;
 Minibatch[ 501- 600]: loss = 0.468883 * 100, metric = 8.84% * 100;
 Minibatch[ 601- 700]: loss = 0.475108 * 100, metric = 9.05% * 100;
 Minibatch[ 701- 800]: loss = 0.463118 * 100, metric = 8.95% * 100;
 Minibatch[ 801- 900]: loss = 0.480224 * 100, metric = 9.34% * 100;
 Minibatch[ 901-1000]: loss = 0.481160 * 100, metric = 9.13% * 100;
 Minibatch[1001-1100]: loss = 0.482443 * 100, metric = 9.32% * 100;
 Minibatch[1101-1200]: loss = 0.481658 * 100, metric = 9.31% * 100;
 Minibatch[1201-1300]: loss = 0.486448 * 100, metric = 9.37% * 100;
 Minibatch[1301-1400]: loss = 0.487048 * 100, metric = 9.33% * 100;
 Minibatch[1401-1500]: loss = 0.461096 * 100, metric = 8.63% * 100;
 Minibatch[1501-1600]: loss = 0.476929 * 100, metric = 8.86% * 100;
 Minibatch[1601-1700]: loss = 0.453349 * 100, metric = 8.45% * 100;
 Minibatch[1701-1800]: loss = 0.468756 * 100, metric = 8.87% * 100;
 Minibatch[1801-1900]: loss = 0.447657 * 100, metric = 8.64% * 100;
 Minibatch[1901-2000]: loss = 0.453008 * 100, metric = 8.67% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.471134 * 2000, metric = 8.96% * 2000 964.680s (  2.1 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 17.64% * 2000;
 Minibatch[   1- 100]: loss = 0.474719 * 100, metric = 9.08% * 100;
 Minibatch[ 101- 200]: loss = 0.483263 * 100, metric = 9.39% * 100;
 Minibatch[ 201- 300]: loss = 0.461366 * 100, metric = 8.87% * 100;
 Minibatch[ 301- 400]: loss = 0.472054 * 100, metric = 9.16% * 100;
 Minibatch[ 401- 500]: loss = 0.468408 * 100, metric = 8.76% * 100;
 Minibatch[ 501- 600]: loss = 0.456628 * 100, metric = 8.53% * 100;
 Minibatch[ 601- 700]: loss = 0.470633 * 100, metric = 9.09% * 100;
 Minibatch[ 701- 800]: loss = 0.453781 * 100, metric = 8.65% * 100;
 Minibatch[ 801- 900]: loss = 0.491841 * 100, metric = 9.41% * 100;
 Minibatch[ 901-1000]: loss = 0.456733 * 100, metric = 8.75% * 100;
 Minibatch[1001-1100]: loss = 0.480818 * 100, metric = 9.12% * 100;
 Minibatch[1101-1200]: loss = 0.474279 * 100, metric = 9.06% * 100;
 Minibatch[1201-1300]: loss = 0.472235 * 100, metric = 9.12% * 100;
 Minibatch[1301-1400]: loss = 0.464574 * 100, metric = 8.84% * 100;
 Minibatch[1401-1500]: loss = 0.475668 * 100, metric = 9.25% * 100;
 Minibatch[1501-1600]: loss = 0.476770 * 100, metric = 9.28% * 100;
 Minibatch[1601-1700]: loss = 0.456572 * 100, metric = 8.81% * 100;
 Minibatch[1701-1800]: loss = 0.447163 * 100, metric = 8.36% * 100;
 Minibatch[1801-1900]: loss = 0.453223 * 100, metric = 8.51% * 100;
 Minibatch[1901-2000]: loss = 0.446562 * 100, metric = 8.32% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.466864 * 2000, metric = 8.92% * 2000 987.695s (  2.0 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 17.56% * 2000;
 Minibatch[   1- 100]: loss = 0.454459 * 100, metric = 8.58% * 100;
 Minibatch[ 101- 200]: loss = 0.455630 * 100, metric = 8.57% * 100;
 Minibatch[ 201- 300]: loss = 0.452507 * 100, metric = 8.48% * 100;
 Minibatch[ 301- 400]: loss = 0.473056 * 100, metric = 8.94% * 100;
 Minibatch[ 401- 500]: loss = 0.455306 * 100, metric = 8.72% * 100;
 Minibatch[ 501- 600]: loss = 0.459494 * 100, metric = 8.95% * 100;
 Minibatch[ 601- 700]: loss = 0.468468 * 100, metric = 8.92% * 100;
 Minibatch[ 701- 800]: loss = 0.462811 * 100, metric = 9.07% * 100;
 Minibatch[ 801- 900]: loss = 0.463972 * 100, metric = 9.05% * 100;
 Minibatch[ 901-1000]: loss = 0.477312 * 100, metric = 9.26% * 100;
 Minibatch[1001-1100]: loss = 0.439874 * 100, metric = 8.40% * 100;
 Minibatch[1101-1200]: loss = 0.456900 * 100, metric = 8.61% * 100;
 Minibatch[1201-1300]: loss = 0.467490 * 100, metric = 9.08% * 100;
 Minibatch[1301-1400]: loss = 0.461274 * 100, metric = 8.83% * 100;
 Minibatch[1401-1500]: loss = 0.451688 * 100, metric = 8.61% * 100;
 Minibatch[1501-1600]: loss = 0.469097 * 100, metric = 8.98% * 100;
 Minibatch[1601-1700]: loss = 0.458666 * 100, metric = 8.93% * 100;
 Minibatch[1701-1800]: loss = 0.468912 * 100, metric = 9.29% * 100;
 Minibatch[1801-1900]: loss = 0.452407 * 100, metric = 8.75% * 100;
 Minibatch[1901-2000]: loss = 0.449376 * 100, metric = 8.57% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.459935 * 2000, metric = 8.83% * 2000 973.818s (  2.1 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 17.08% * 2000;
 Minibatch[   1- 100]: loss = 0.461482 * 100, metric = 8.78% * 100;
 Minibatch[ 101- 200]: loss = 0.457577 * 100, metric = 8.81% * 100;
 Minibatch[ 201- 300]: loss = 0.455358 * 100, metric = 8.76% * 100;
 Minibatch[ 301- 400]: loss = 0.466614 * 100, metric = 9.21% * 100;
 Minibatch[ 401- 500]: loss = 0.447132 * 100, metric = 8.61% * 100;
 Minibatch[ 501- 600]: loss = 0.442629 * 100, metric = 8.31% * 100;
 Minibatch[ 601- 700]: loss = 0.448957 * 100, metric = 8.57% * 100;
 Minibatch[ 701- 800]: loss = 0.421535 * 100, metric = 7.99% * 100;
 Minibatch[ 801- 900]: loss = 0.460279 * 100, metric = 8.87% * 100;
 Minibatch[ 901-1000]: loss = 0.433108 * 100, metric = 8.23% * 100;
 Minibatch[1001-1100]: loss = 0.437742 * 100, metric = 8.33% * 100;
 Minibatch[1101-1200]: loss = 0.437721 * 100, metric = 8.35% * 100;
 Minibatch[1201-1300]: loss = 0.447227 * 100, metric = 8.18% * 100;
 Minibatch[1301-1400]: loss = 0.427688 * 100, metric = 7.85% * 100;
 Minibatch[1401-1500]: loss = 0.446390 * 100, metric = 8.57% * 100;
 Minibatch[1501-1600]: loss = 0.447216 * 100, metric = 8.84% * 100;
 Minibatch[1601-1700]: loss = 0.436066 * 100, metric = 8.39% * 100;
 Minibatch[1701-1800]: loss = 0.439855 * 100, metric = 8.25% * 100;
 Minibatch[1801-1900]: loss = 0.462159 * 100, metric = 9.05% * 100;
 Minibatch[1901-2000]: loss = 0.423414 * 100, metric = 7.82% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.445007 * 2000, metric = 8.49% * 2000 977.877s (  2.0 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 15.61% * 2000;
0.5795148869976401
 Minibatch[   1- 100]: loss = 0.455916 * 100, metric = 8.88% * 100;
 Minibatch[ 101- 200]: loss = 0.449110 * 100, metric = 8.48% * 100;
 Minibatch[ 201- 300]: loss = 0.452908 * 100, metric = 8.69% * 100;
 Minibatch[ 301- 400]: loss = 0.440376 * 100, metric = 8.33% * 100;
 Minibatch[ 401- 500]: loss = 0.444239 * 100, metric = 8.60% * 100;
 Minibatch[ 501- 600]: loss = 0.455377 * 100, metric = 8.68% * 100;
 Minibatch[ 601- 700]: loss = 0.441616 * 100, metric = 8.38% * 100;
 Minibatch[ 701- 800]: loss = 0.441522 * 100, metric = 8.46% * 100;
 Minibatch[ 801- 900]: loss = 0.447706 * 100, metric = 8.49% * 100;
 Minibatch[ 901-1000]: loss = 0.456763 * 100, metric = 8.85% * 100;
 Minibatch[1001-1100]: loss = 0.427989 * 100, metric = 7.97% * 100;
 Minibatch[1101-1200]: loss = 0.422803 * 100, metric = 7.82% * 100;
 Minibatch[1201-1300]: loss = 0.438873 * 100, metric = 8.34% * 100;
 Minibatch[1301-1400]: loss = 0.438248 * 100, metric = 8.38% * 100;
 Minibatch[1401-1500]: loss = 0.435122 * 100, metric = 8.32% * 100;
 Minibatch[1501-1600]: loss = 0.427556 * 100, metric = 7.91% * 100;
 Minibatch[1601-1700]: loss = 0.437891 * 100, metric = 8.18% * 100;
 Minibatch[1701-1800]: loss = 0.433190 * 100, metric = 8.00% * 100;
 Minibatch[1801-1900]: loss = 0.432099 * 100, metric = 8.01% * 100;
 Minibatch[1901-2000]: loss = 0.424918 * 100, metric = 7.78% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.440211 * 2000, metric = 8.33% * 2000 971.007s (  2.1 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 16.21% * 2000;
 Minibatch[   1- 100]: loss = 0.449245 * 100, metric = 8.48% * 100;
 Minibatch[ 101- 200]: loss = 0.446381 * 100, metric = 8.64% * 100;
 Minibatch[ 201- 300]: loss = 0.436902 * 100, metric = 7.99% * 100;
 Minibatch[ 301- 400]: loss = 0.447992 * 100, metric = 8.45% * 100;
 Minibatch[ 401- 500]: loss = 0.441041 * 100, metric = 8.50% * 100;
 Minibatch[ 501- 600]: loss = 0.440098 * 100, metric = 8.29% * 100;
 Minibatch[ 601- 700]: loss = 0.436344 * 100, metric = 8.25% * 100;
 Minibatch[ 701- 800]: loss = 0.418954 * 100, metric = 7.57% * 100;
 Minibatch[ 801- 900]: loss = 0.422339 * 100, metric = 7.88% * 100;
 Minibatch[ 901-1000]: loss = 0.443700 * 100, metric = 8.29% * 100;
 Minibatch[1001-1100]: loss = 0.428322 * 100, metric = 7.95% * 100;
 Minibatch[1101-1200]: loss = 0.441169 * 100, metric = 8.25% * 100;
 Minibatch[1201-1300]: loss = 0.432266 * 100, metric = 8.00% * 100;
 Minibatch[1301-1400]: loss = 0.434035 * 100, metric = 8.15% * 100;
 Minibatch[1401-1500]: loss = 0.421038 * 100, metric = 7.95% * 100;
 Minibatch[1501-1600]: loss = 0.426780 * 100, metric = 7.95% * 100;
 Minibatch[1601-1700]: loss = 0.428600 * 100, metric = 8.10% * 100;
 Minibatch[1701-1800]: loss = 0.431344 * 100, metric = 8.08% * 100;
 Minibatch[1801-1900]: loss = 0.433942 * 100, metric = 8.43% * 100;
 Minibatch[1901-2000]: loss = 0.438951 * 100, metric = 8.31% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.434972 * 2000, metric = 8.18% * 2000 974.409s (  2.1 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 16.78% * 2000;
 Minibatch[   1- 100]: loss = 0.409776 * 100, metric = 7.72% * 100;
 Minibatch[ 101- 200]: loss = 0.433192 * 100, metric = 8.31% * 100;
 Minibatch[ 201- 300]: loss = 0.426632 * 100, metric = 8.21% * 100;
 Minibatch[ 301- 400]: loss = 0.422987 * 100, metric = 7.81% * 100;
 Minibatch[ 401- 500]: loss = 0.432547 * 100, metric = 8.29% * 100;
 Minibatch[ 501- 600]: loss = 0.415151 * 100, metric = 7.90% * 100;
 Minibatch[ 601- 700]: loss = 0.432370 * 100, metric = 7.90% * 100;
 Minibatch[ 701- 800]: loss = 0.420846 * 100, metric = 7.83% * 100;
 Minibatch[ 801- 900]: loss = 0.442907 * 100, metric = 8.63% * 100;
 Minibatch[ 901-1000]: loss = 0.426848 * 100, metric = 8.13% * 100;
 Minibatch[1001-1100]: loss = 0.430919 * 100, metric = 8.30% * 100;
 Minibatch[1101-1200]: loss = 0.441110 * 100, metric = 8.59% * 100;
 Minibatch[1201-1300]: loss = 0.431091 * 100, metric = 8.16% * 100;
 Minibatch[1301-1400]: loss = 0.420359 * 100, metric = 7.94% * 100;
 Minibatch[1401-1500]: loss = 0.423922 * 100, metric = 7.92% * 100;
 Minibatch[1501-1600]: loss = 0.435701 * 100, metric = 8.30% * 100;
 Minibatch[1601-1700]: loss = 0.415039 * 100, metric = 7.95% * 100;
 Minibatch[1701-1800]: loss = 0.412255 * 100, metric = 7.58% * 100;
 Minibatch[1801-1900]: loss = 0.426649 * 100, metric = 8.18% * 100;
 Minibatch[1901-2000]: loss = 0.434830 * 100, metric = 8.40% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.426757 * 2000, metric = 8.10% * 2000 963.380s (  2.1 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 16.50% * 2000;
 Minibatch[   1- 100]: loss = 0.430859 * 100, metric = 8.07% * 100;
 Minibatch[ 101- 200]: loss = 0.423685 * 100, metric = 8.14% * 100;
 Minibatch[ 201- 300]: loss = 0.427767 * 100, metric = 8.45% * 100;
 Minibatch[ 301- 400]: loss = 0.429187 * 100, metric = 8.12% * 100;
 Minibatch[ 401- 500]: loss = 0.425216 * 100, metric = 7.99% * 100;
 Minibatch[ 501- 600]: loss = 0.422406 * 100, metric = 7.86% * 100;
 Minibatch[ 601- 700]: loss = 0.433872 * 100, metric = 8.36% * 100;
 Minibatch[ 701- 800]: loss = 0.414465 * 100, metric = 7.65% * 100;
 Minibatch[ 801- 900]: loss = 0.412226 * 100, metric = 7.67% * 100;
 Minibatch[ 901-1000]: loss = 0.424606 * 100, metric = 8.13% * 100;
 Minibatch[1001-1100]: loss = 0.424185 * 100, metric = 7.97% * 100;
 Minibatch[1101-1200]: loss = 0.428554 * 100, metric = 8.12% * 100;
 Minibatch[1201-1300]: loss = 0.440088 * 100, metric = 8.45% * 100;
 Minibatch[1301-1400]: loss = 0.417891 * 100, metric = 7.77% * 100;
 Minibatch[1401-1500]: loss = 0.411989 * 100, metric = 7.47% * 100;
 Minibatch[1501-1600]: loss = 0.433753 * 100, metric = 8.32% * 100;
 Minibatch[1601-1700]: loss = 0.415646 * 100, metric = 7.81% * 100;
 Minibatch[1701-1800]: loss = 0.414230 * 100, metric = 7.92% * 100;
 Minibatch[1801-1900]: loss = 0.404642 * 100, metric = 7.53% * 100;
 Minibatch[1901-2000]: loss = 0.395637 * 100, metric = 7.30% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.421545 * 2000, metric = 7.95% * 2000 968.630s (  2.1 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 16.95% * 2000;
 Minibatch[   1- 100]: loss = 0.411026 * 100, metric = 7.73% * 100;
 Minibatch[ 101- 200]: loss = 0.393497 * 100, metric = 7.20% * 100;
 Minibatch[ 201- 300]: loss = 0.416033 * 100, metric = 7.92% * 100;
 Minibatch[ 301- 400]: loss = 0.403194 * 100, metric = 7.37% * 100;
 Minibatch[ 401- 500]: loss = 0.410358 * 100, metric = 7.81% * 100;
 Minibatch[ 501- 600]: loss = 0.411153 * 100, metric = 7.74% * 100;
 Minibatch[ 601- 700]: loss = 0.419378 * 100, metric = 7.94% * 100;
 Minibatch[ 701- 800]: loss = 0.407542 * 100, metric = 7.54% * 100;
 Minibatch[ 801- 900]: loss = 0.395201 * 100, metric = 7.18% * 100;
 Minibatch[ 901-1000]: loss = 0.399520 * 100, metric = 7.31% * 100;
 Minibatch[1001-1100]: loss = 0.417984 * 100, metric = 8.06% * 100;
 Minibatch[1101-1200]: loss = 0.419145 * 100, metric = 7.79% * 100;
 Minibatch[1201-1300]: loss = 0.401005 * 100, metric = 7.48% * 100;
 Minibatch[1301-1400]: loss = 0.398224 * 100, metric = 7.30% * 100;
 Minibatch[1401-1500]: loss = 0.411370 * 100, metric = 7.66% * 100;
 Minibatch[1501-1600]: loss = 0.396191 * 100, metric = 7.13% * 100;
 Minibatch[1601-1700]: loss = 0.420320 * 100, metric = 8.00% * 100;
 Minibatch[1701-1800]: loss = 0.420073 * 100, metric = 8.01% * 100;
 Minibatch[1801-1900]: loss = 0.410176 * 100, metric = 7.73% * 100;
 Minibatch[1901-2000]: loss = 0.414611 * 100, metric = 7.77% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.408800 * 2000, metric = 7.63% * 2000 987.136s (  2.0 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 17.14% * 2000;
 Minibatch[   1- 100]: loss = 0.407644 * 100, metric = 7.46% * 100;
 Minibatch[ 101- 200]: loss = 0.421258 * 100, metric = 7.89% * 100;
 Minibatch[ 201- 300]: loss = 0.410506 * 100, metric = 7.69% * 100;
 Minibatch[ 301- 400]: loss = 0.392961 * 100, metric = 7.33% * 100;
 Minibatch[ 401- 500]: loss = 0.398586 * 100, metric = 7.41% * 100;
 Minibatch[ 501- 600]: loss = 0.399843 * 100, metric = 7.67% * 100;
 Minibatch[ 601- 700]: loss = 0.398589 * 100, metric = 7.29% * 100;
 Minibatch[ 701- 800]: loss = 0.397532 * 100, metric = 7.39% * 100;
 Minibatch[ 801- 900]: loss = 0.409329 * 100, metric = 7.67% * 100;
 Minibatch[ 901-1000]: loss = 0.405954 * 100, metric = 7.68% * 100;
 Minibatch[1001-1100]: loss = 0.393803 * 100, metric = 7.18% * 100;
 Minibatch[1101-1200]: loss = 0.409332 * 100, metric = 7.53% * 100;
 Minibatch[1201-1300]: loss = 0.396273 * 100, metric = 7.25% * 100;
 Minibatch[1301-1400]: loss = 0.417553 * 100, metric = 8.05% * 100;
 Minibatch[1401-1500]: loss = 0.397379 * 100, metric = 7.49% * 100;
 Minibatch[1501-1600]: loss = 0.399801 * 100, metric = 7.30% * 100;
 Minibatch[1601-1700]: loss = 0.381499 * 100, metric = 6.87% * 100;
 Minibatch[1701-1800]: loss = 0.401874 * 100, metric = 7.18% * 100;
 Minibatch[1801-1900]: loss = 0.395679 * 100, metric = 7.35% * 100;
 Minibatch[1901-2000]: loss = 0.404664 * 100, metric = 7.58% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.402003 * 2000, metric = 7.46% * 2000 978.301s (  2.0 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 16.11% * 2000;
 Minibatch[   1- 100]: loss = 0.411713 * 100, metric = 7.83% * 100;
 Minibatch[ 101- 200]: loss = 0.390792 * 100, metric = 7.00% * 100;
 Minibatch[ 201- 300]: loss = 0.402685 * 100, metric = 7.46% * 100;
 Minibatch[ 301- 400]: loss = 0.402269 * 100, metric = 7.58% * 100;
 Minibatch[ 401- 500]: loss = 0.404786 * 100, metric = 7.63% * 100;
 Minibatch[ 501- 600]: loss = 0.422670 * 100, metric = 8.19% * 100;
 Minibatch[ 601- 700]: loss = 0.392560 * 100, metric = 7.25% * 100;
 Minibatch[ 701- 800]: loss = 0.381700 * 100, metric = 7.06% * 100;
 Minibatch[ 801- 900]: loss = 0.395558 * 100, metric = 7.35% * 100;
 Minibatch[ 901-1000]: loss = 0.408919 * 100, metric = 7.72% * 100;
 Minibatch[1001-1100]: loss = 0.391262 * 100, metric = 7.24% * 100;
 Minibatch[1101-1200]: loss = 0.397308 * 100, metric = 7.24% * 100;
 Minibatch[1201-1300]: loss = 0.410445 * 100, metric = 7.87% * 100;
 Minibatch[1301-1400]: loss = 0.388611 * 100, metric = 7.31% * 100;
 Minibatch[1401-1500]: loss = 0.404971 * 100, metric = 7.60% * 100;
 Minibatch[1501-1600]: loss = 0.387884 * 100, metric = 7.17% * 100;
 Minibatch[1601-1700]: loss = 0.389810 * 100, metric = 7.11% * 100;
 Minibatch[1701-1800]: loss = 0.388515 * 100, metric = 7.07% * 100;
 Minibatch[1801-1900]: loss = 0.393607 * 100, metric = 7.37% * 100;
 Minibatch[1901-2000]: loss = 0.401528 * 100, metric = 7.58% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.398380 * 2000, metric = 7.43% * 2000 956.356s (  2.1 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 15.37% * 2000;
 Minibatch[   1- 100]: loss = 0.381879 * 100, metric = 7.05% * 100;
 Minibatch[ 101- 200]: loss = 0.391808 * 100, metric = 7.39% * 100;
 Minibatch[ 201- 300]: loss = 0.394711 * 100, metric = 7.56% * 100;
 Minibatch[ 301- 400]: loss = 0.413673 * 100, metric = 7.77% * 100;
 Minibatch[ 401- 500]: loss = 0.386047 * 100, metric = 7.14% * 100;
 Minibatch[ 501- 600]: loss = 0.395018 * 100, metric = 7.36% * 100;
 Minibatch[ 601- 700]: loss = 0.390963 * 100, metric = 7.26% * 100;
 Minibatch[ 701- 800]: loss = 0.396324 * 100, metric = 7.58% * 100;
 Minibatch[ 801- 900]: loss = 0.392816 * 100, metric = 7.52% * 100;
 Minibatch[ 901-1000]: loss = 0.400584 * 100, metric = 7.73% * 100;
 Minibatch[1001-1100]: loss = 0.393192 * 100, metric = 7.59% * 100;
 Minibatch[1101-1200]: loss = 0.374064 * 100, metric = 6.93% * 100;
 Minibatch[1201-1300]: loss = 0.387773 * 100, metric = 7.27% * 100;
 Minibatch[1301-1400]: loss = 0.385403 * 100, metric = 7.28% * 100;
 Minibatch[1401-1500]: loss = 0.403398 * 100, metric = 7.54% * 100;
 Minibatch[1501-1600]: loss = 0.378849 * 100, metric = 6.96% * 100;
 Minibatch[1601-1700]: loss = 0.400350 * 100, metric = 7.57% * 100;
 Minibatch[1701-1800]: loss = 0.373378 * 100, metric = 6.85% * 100;
 Minibatch[1801-1900]: loss = 0.399454 * 100, metric = 7.48% * 100;
 Minibatch[1901-2000]: loss = 0.392361 * 100, metric = 7.38% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.391602 * 2000, metric = 7.36% * 2000 943.877s (  2.1 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 16.87% * 2000;
 Minibatch[   1- 100]: loss = 0.398662 * 100, metric = 7.34% * 100;
 Minibatch[ 101- 200]: loss = 0.367544 * 100, metric = 6.66% * 100;
 Minibatch[ 201- 300]: loss = 0.381517 * 100, metric = 7.13% * 100;
 Minibatch[ 301- 400]: loss = 0.394575 * 100, metric = 7.44% * 100;
 Minibatch[ 401- 500]: loss = 0.389716 * 100, metric = 7.32% * 100;
 Minibatch[ 501- 600]: loss = 0.372626 * 100, metric = 6.74% * 100;
 Minibatch[ 601- 700]: loss = 0.387995 * 100, metric = 7.23% * 100;
 Minibatch[ 701- 800]: loss = 0.381926 * 100, metric = 7.00% * 100;
 Minibatch[ 801- 900]: loss = 0.396586 * 100, metric = 7.22% * 100;
 Minibatch[ 901-1000]: loss = 0.371456 * 100, metric = 6.75% * 100;
 Minibatch[1001-1100]: loss = 0.383069 * 100, metric = 6.94% * 100;
 Minibatch[1101-1200]: loss = 0.401433 * 100, metric = 7.29% * 100;
 Minibatch[1201-1300]: loss = 0.388806 * 100, metric = 7.18% * 100;
 Minibatch[1301-1400]: loss = 0.384051 * 100, metric = 7.17% * 100;
 Minibatch[1401-1500]: loss = 0.380133 * 100, metric = 7.03% * 100;
 Minibatch[1501-1600]: loss = 0.403143 * 100, metric = 7.55% * 100;
 Minibatch[1601-1700]: loss = 0.390959 * 100, metric = 7.27% * 100;
 Minibatch[1701-1800]: loss = 0.395948 * 100, metric = 7.45% * 100;
 Minibatch[1801-1900]: loss = 0.388364 * 100, metric = 7.34% * 100;
 Minibatch[1901-2000]: loss = 0.406556 * 100, metric = 7.93% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.388253 * 2000, metric = 7.20% * 2000 970.332s (  2.1 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 16.55% * 2000;
 Minibatch[   1- 100]: loss = 0.387380 * 100, metric = 7.06% * 100;
 Minibatch[ 101- 200]: loss = 0.400151 * 100, metric = 7.85% * 100;
 Minibatch[ 201- 300]: loss = 0.387396 * 100, metric = 7.36% * 100;
 Minibatch[ 301- 400]: loss = 0.387713 * 100, metric = 7.13% * 100;
 Minibatch[ 401- 500]: loss = 0.387300 * 100, metric = 7.22% * 100;
 Minibatch[ 501- 600]: loss = 0.385905 * 100, metric = 6.95% * 100;
 Minibatch[ 601- 700]: loss = 0.399938 * 100, metric = 7.63% * 100;
 Minibatch[ 701- 800]: loss = 0.391569 * 100, metric = 7.28% * 100;
 Minibatch[ 801- 900]: loss = 0.384618 * 100, metric = 7.20% * 100;
 Minibatch[ 901-1000]: loss = 0.375430 * 100, metric = 7.19% * 100;
 Minibatch[1001-1100]: loss = 0.379503 * 100, metric = 7.02% * 100;
 Minibatch[1101-1200]: loss = 0.390154 * 100, metric = 7.49% * 100;
 Minibatch[1201-1300]: loss = 0.379185 * 100, metric = 7.06% * 100;
 Minibatch[1301-1400]: loss = 0.380776 * 100, metric = 7.14% * 100;
 Minibatch[1401-1500]: loss = 0.387252 * 100, metric = 7.17% * 100;
 Minibatch[1501-1600]: loss = 0.371150 * 100, metric = 6.87% * 100;
 Minibatch[1601-1700]: loss = 0.385399 * 100, metric = 7.25% * 100;
 Minibatch[1701-1800]: loss = 0.375303 * 100, metric = 7.00% * 100;
 Minibatch[1801-1900]: loss = 0.386127 * 100, metric = 7.21% * 100;
 Minibatch[1901-2000]: loss = 0.379987 * 100, metric = 7.17% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.385112 * 2000, metric = 7.21% * 2000 963.534s (  2.1 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 15.77% * 2000;
 Minibatch[   1- 100]: loss = 0.381812 * 100, metric = 7.06% * 100;
 Minibatch[ 101- 200]: loss = 0.379986 * 100, metric = 6.86% * 100;
 Minibatch[ 201- 300]: loss = 0.395069 * 100, metric = 7.47% * 100;
 Minibatch[ 301- 400]: loss = 0.395073 * 100, metric = 7.35% * 100;
 Minibatch[ 401- 500]: loss = 0.380556 * 100, metric = 7.14% * 100;
 Minibatch[ 501- 600]: loss = 0.383948 * 100, metric = 7.21% * 100;
 Minibatch[ 601- 700]: loss = 0.372632 * 100, metric = 6.77% * 100;
 Minibatch[ 701- 800]: loss = 0.371510 * 100, metric = 6.73% * 100;
 Minibatch[ 801- 900]: loss = 0.376524 * 100, metric = 6.92% * 100;
 Minibatch[ 901-1000]: loss = 0.365613 * 100, metric = 6.56% * 100;
 Minibatch[1001-1100]: loss = 0.370003 * 100, metric = 6.52% * 100;
 Minibatch[1101-1200]: loss = 0.382010 * 100, metric = 7.17% * 100;
 Minibatch[1201-1300]: loss = 0.395275 * 100, metric = 7.77% * 100;
 Minibatch[1301-1400]: loss = 0.378345 * 100, metric = 7.15% * 100;
 Minibatch[1401-1500]: loss = 0.378570 * 100, metric = 7.26% * 100;
 Minibatch[1501-1600]: loss = 0.384370 * 100, metric = 6.99% * 100;
 Minibatch[1601-1700]: loss = 0.368229 * 100, metric = 6.80% * 100;
 Minibatch[1701-1800]: loss = 0.388818 * 100, metric = 7.23% * 100;
 Minibatch[1801-1900]: loss = 0.368643 * 100, metric = 6.70% * 100;
 Minibatch[1901-2000]: loss = 0.379323 * 100, metric = 7.31% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.379815 * 2000, metric = 7.05% * 2000 962.749s (  2.1 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 14.81% * 2000;
0.5714819377027452
 Minibatch[   1- 100]: loss = 0.388323 * 100, metric = 7.35% * 100;
 Minibatch[ 101- 200]: loss = 0.372365 * 100, metric = 7.14% * 100;
 Minibatch[ 201- 300]: loss = 0.372294 * 100, metric = 6.95% * 100;
 Minibatch[ 301- 400]: loss = 0.381743 * 100, metric = 7.20% * 100;
 Minibatch[ 401- 500]: loss = 0.368617 * 100, metric = 6.85% * 100;
 Minibatch[ 501- 600]: loss = 0.377340 * 100, metric = 7.00% * 100;
 Minibatch[ 601- 700]: loss = 0.389104 * 100, metric = 7.41% * 100;
 Minibatch[ 701- 800]: loss = 0.374375 * 100, metric = 6.88% * 100;
 Minibatch[ 801- 900]: loss = 0.376580 * 100, metric = 6.81% * 100;
 Minibatch[ 901-1000]: loss = 0.367911 * 100, metric = 6.64% * 100;
 Minibatch[1001-1100]: loss = 0.365585 * 100, metric = 6.80% * 100;
 Minibatch[1101-1200]: loss = 0.354800 * 100, metric = 6.61% * 100;
 Minibatch[1201-1300]: loss = 0.377810 * 100, metric = 6.95% * 100;
 Minibatch[1301-1400]: loss = 0.363312 * 100, metric = 6.57% * 100;
 Minibatch[1401-1500]: loss = 0.387039 * 100, metric = 7.07% * 100;
 Minibatch[1501-1600]: loss = 0.383558 * 100, metric = 6.96% * 100;
 Minibatch[1601-1700]: loss = 0.370995 * 100, metric = 6.66% * 100;
 Minibatch[1701-1800]: loss = 0.371660 * 100, metric = 6.67% * 100;
 Minibatch[1801-1900]: loss = 0.364910 * 100, metric = 6.46% * 100;
 Minibatch[1901-2000]: loss = 0.387150 * 100, metric = 7.21% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.374774 * 2000, metric = 6.91% * 2000 966.553s (  2.1 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 15.73% * 2000;
 Minibatch[   1- 100]: loss = 0.364297 * 100, metric = 6.46% * 100;
 Minibatch[ 101- 200]: loss = 0.375397 * 100, metric = 7.09% * 100;
 Minibatch[ 201- 300]: loss = 0.363667 * 100, metric = 6.69% * 100;
 Minibatch[ 301- 400]: loss = 0.372455 * 100, metric = 6.83% * 100;
 Minibatch[ 401- 500]: loss = 0.357490 * 100, metric = 6.34% * 100;
 Minibatch[ 501- 600]: loss = 0.370619 * 100, metric = 6.90% * 100;
 Minibatch[ 601- 700]: loss = 0.373825 * 100, metric = 6.87% * 100;
 Minibatch[ 701- 800]: loss = 0.366018 * 100, metric = 6.76% * 100;
 Minibatch[ 801- 900]: loss = 0.353866 * 100, metric = 6.20% * 100;
 Minibatch[ 901-1000]: loss = 0.365858 * 100, metric = 6.85% * 100;
 Minibatch[1001-1100]: loss = 0.373116 * 100, metric = 7.00% * 100;
 Minibatch[1101-1200]: loss = 0.363366 * 100, metric = 6.68% * 100;
 Minibatch[1201-1300]: loss = 0.365431 * 100, metric = 6.76% * 100;
 Minibatch[1301-1400]: loss = 0.366240 * 100, metric = 6.64% * 100;
 Minibatch[1401-1500]: loss = 0.378118 * 100, metric = 7.05% * 100;
 Minibatch[1501-1600]: loss = 0.378862 * 100, metric = 6.99% * 100;
 Minibatch[1601-1700]: loss = 0.377529 * 100, metric = 7.06% * 100;
 Minibatch[1701-1800]: loss = 0.368702 * 100, metric = 7.04% * 100;
 Minibatch[1801-1900]: loss = 0.368785 * 100, metric = 6.73% * 100;
 Minibatch[1901-2000]: loss = 0.364730 * 100, metric = 6.53% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.368419 * 2000, metric = 6.77% * 2000 981.180s (  2.0 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 16.03% * 2000;
 Minibatch[   1- 100]: loss = 0.349263 * 100, metric = 6.28% * 100;
 Minibatch[ 101- 200]: loss = 0.365594 * 100, metric = 6.79% * 100;
 Minibatch[ 201- 300]: loss = 0.368724 * 100, metric = 6.64% * 100;
 Minibatch[ 301- 400]: loss = 0.363947 * 100, metric = 6.55% * 100;
 Minibatch[ 401- 500]: loss = 0.362196 * 100, metric = 6.56% * 100;
 Minibatch[ 501- 600]: loss = 0.349110 * 100, metric = 6.16% * 100;
 Minibatch[ 601- 700]: loss = 0.379353 * 100, metric = 7.01% * 100;
 Minibatch[ 701- 800]: loss = 0.346560 * 100, metric = 6.38% * 100;
 Minibatch[ 801- 900]: loss = 0.366236 * 100, metric = 6.82% * 100;
 Minibatch[ 901-1000]: loss = 0.351340 * 100, metric = 6.32% * 100;
 Minibatch[1001-1100]: loss = 0.378083 * 100, metric = 6.89% * 100;
 Minibatch[1101-1200]: loss = 0.351818 * 100, metric = 6.36% * 100;
 Minibatch[1201-1300]: loss = 0.361013 * 100, metric = 6.70% * 100;
 Minibatch[1301-1400]: loss = 0.367076 * 100, metric = 6.92% * 100;
 Minibatch[1401-1500]: loss = 0.360169 * 100, metric = 6.46% * 100;
 Minibatch[1501-1600]: loss = 0.363889 * 100, metric = 6.88% * 100;
 Minibatch[1601-1700]: loss = 0.361230 * 100, metric = 6.60% * 100;
 Minibatch[1701-1800]: loss = 0.345319 * 100, metric = 6.21% * 100;
 Minibatch[1801-1900]: loss = 0.369124 * 100, metric = 6.93% * 100;
 Minibatch[1901-2000]: loss = 0.355583 * 100, metric = 6.61% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.360781 * 2000, metric = 6.60% * 2000 947.865s (  2.1 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 14.96% * 2000;
 Minibatch[   1- 100]: loss = 0.360411 * 100, metric = 6.64% * 100;
 Minibatch[ 101- 200]: loss = 0.343449 * 100, metric = 6.12% * 100;
 Minibatch[ 201- 300]: loss = 0.370688 * 100, metric = 6.93% * 100;
 Minibatch[ 301- 400]: loss = 0.349971 * 100, metric = 6.39% * 100;
 Minibatch[ 401- 500]: loss = 0.350662 * 100, metric = 6.38% * 100;
 Minibatch[ 501- 600]: loss = 0.357602 * 100, metric = 6.40% * 100;
 Minibatch[ 601- 700]: loss = 0.363597 * 100, metric = 6.64% * 100;
 Minibatch[ 701- 800]: loss = 0.340873 * 100, metric = 6.12% * 100;
 Minibatch[ 801- 900]: loss = 0.343988 * 100, metric = 6.34% * 100;
 Minibatch[ 901-1000]: loss = 0.356874 * 100, metric = 6.52% * 100;
 Minibatch[1001-1100]: loss = 0.362274 * 100, metric = 6.70% * 100;
 Minibatch[1101-1200]: loss = 0.347314 * 100, metric = 6.26% * 100;
 Minibatch[1201-1300]: loss = 0.356263 * 100, metric = 6.60% * 100;
 Minibatch[1301-1400]: loss = 0.331670 * 100, metric = 5.71% * 100;
 Minibatch[1401-1500]: loss = 0.343666 * 100, metric = 6.11% * 100;
 Minibatch[1501-1600]: loss = 0.353075 * 100, metric = 6.46% * 100;
 Minibatch[1601-1700]: loss = 0.367593 * 100, metric = 6.96% * 100;
 Minibatch[1701-1800]: loss = 0.350671 * 100, metric = 6.36% * 100;
 Minibatch[1801-1900]: loss = 0.350190 * 100, metric = 6.32% * 100;
 Minibatch[1901-2000]: loss = 0.342679 * 100, metric = 6.03% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.352175 * 2000, metric = 6.40% * 2000 957.957s (  2.1 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 14.52% * 2000;
 Minibatch[   1- 100]: loss = 0.344942 * 100, metric = 6.19% * 100;
 Minibatch[ 101- 200]: loss = 0.349865 * 100, metric = 6.42% * 100;
 Minibatch[ 201- 300]: loss = 0.348687 * 100, metric = 6.35% * 100;
 Minibatch[ 301- 400]: loss = 0.350017 * 100, metric = 6.28% * 100;
 Minibatch[ 401- 500]: loss = 0.351742 * 100, metric = 6.68% * 100;
 Minibatch[ 501- 600]: loss = 0.336797 * 100, metric = 6.04% * 100;
 Minibatch[ 601- 700]: loss = 0.352797 * 100, metric = 6.52% * 100;
 Minibatch[ 701- 800]: loss = 0.357702 * 100, metric = 6.56% * 100;
 Minibatch[ 801- 900]: loss = 0.355441 * 100, metric = 6.39% * 100;
 Minibatch[ 901-1000]: loss = 0.333881 * 100, metric = 5.91% * 100;
 Minibatch[1001-1100]: loss = 0.344531 * 100, metric = 6.23% * 100;
 Minibatch[1101-1200]: loss = 0.359063 * 100, metric = 6.61% * 100;
 Minibatch[1201-1300]: loss = 0.359068 * 100, metric = 6.62% * 100;
 Minibatch[1301-1400]: loss = 0.347567 * 100, metric = 6.10% * 100;
 Minibatch[1401-1500]: loss = 0.359340 * 100, metric = 6.69% * 100;
 Minibatch[1501-1600]: loss = 0.348835 * 100, metric = 6.27% * 100;
 Minibatch[1601-1700]: loss = 0.352115 * 100, metric = 6.56% * 100;
 Minibatch[1701-1800]: loss = 0.350153 * 100, metric = 6.26% * 100;
 Minibatch[1801-1900]: loss = 0.355448 * 100, metric = 6.46% * 100;
 Minibatch[1901-2000]: loss = 0.350729 * 100, metric = 6.32% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.350436 * 2000, metric = 6.37% * 2000 937.285s (  2.1 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 14.38% * 2000;
0.571110166363418
 Minibatch[   1- 100]: loss = 0.359616 * 100, metric = 6.62% * 100;
 Minibatch[ 101- 200]: loss = 0.348387 * 100, metric = 6.38% * 100;
 Minibatch[ 201- 300]: loss = 0.331932 * 100, metric = 5.89% * 100;
 Minibatch[ 301- 400]: loss = 0.348949 * 100, metric = 6.46% * 100;
 Minibatch[ 401- 500]: loss = 0.348282 * 100, metric = 6.15% * 100;
 Minibatch[ 501- 600]: loss = 0.344825 * 100, metric = 6.34% * 100;
 Minibatch[ 601- 700]: loss = 0.349937 * 100, metric = 6.48% * 100;
 Minibatch[ 701- 800]: loss = 0.343746 * 100, metric = 6.29% * 100;
 Minibatch[ 801- 900]: loss = 0.356785 * 100, metric = 6.37% * 100;
 Minibatch[ 901-1000]: loss = 0.349012 * 100, metric = 6.21% * 100;
 Minibatch[1001-1100]: loss = 0.351469 * 100, metric = 6.50% * 100;
 Minibatch[1101-1200]: loss = 0.333504 * 100, metric = 6.04% * 100;
 Minibatch[1201-1300]: loss = 0.345219 * 100, metric = 6.40% * 100;
 Minibatch[1301-1400]: loss = 0.354637 * 100, metric = 6.31% * 100;
 Minibatch[1401-1500]: loss = 0.346968 * 100, metric = 6.34% * 100;
 Minibatch[1501-1600]: loss = 0.352037 * 100, metric = 6.45% * 100;
 Minibatch[1601-1700]: loss = 0.329685 * 100, metric = 5.90% * 100;
 Minibatch[1701-1800]: loss = 0.339379 * 100, metric = 6.03% * 100;
 Minibatch[1801-1900]: loss = 0.340858 * 100, metric = 6.02% * 100;
 Minibatch[1901-2000]: loss = 0.346865 * 100, metric = 6.21% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.346105 * 2000, metric = 6.27% * 2000 972.037s (  2.1 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 14.61% * 2000;
 Minibatch[   1- 100]: loss = 0.335535 * 100, metric = 6.19% * 100;
 Minibatch[ 101- 200]: loss = 0.340690 * 100, metric = 6.20% * 100;
 Minibatch[ 201- 300]: loss = 0.341559 * 100, metric = 6.08% * 100;
 Minibatch[ 301- 400]: loss = 0.330312 * 100, metric = 5.76% * 100;
 Minibatch[ 401- 500]: loss = 0.335696 * 100, metric = 6.15% * 100;
 Minibatch[ 501- 600]: loss = 0.348283 * 100, metric = 6.22% * 100;
 Minibatch[ 601- 700]: loss = 0.336424 * 100, metric = 6.19% * 100;
 Minibatch[ 701- 800]: loss = 0.338839 * 100, metric = 6.12% * 100;
 Minibatch[ 801- 900]: loss = 0.324666 * 100, metric = 5.82% * 100;
 Minibatch[ 901-1000]: loss = 0.339662 * 100, metric = 6.16% * 100;
 Minibatch[1001-1100]: loss = 0.344116 * 100, metric = 6.38% * 100;
 Minibatch[1101-1200]: loss = 0.334805 * 100, metric = 6.18% * 100;
 Minibatch[1201-1300]: loss = 0.342747 * 100, metric = 6.12% * 100;
 Minibatch[1301-1400]: loss = 0.346065 * 100, metric = 6.33% * 100;
 Minibatch[1401-1500]: loss = 0.344884 * 100, metric = 6.40% * 100;
 Minibatch[1501-1600]: loss = 0.343917 * 100, metric = 6.12% * 100;
 Minibatch[1601-1700]: loss = 0.335886 * 100, metric = 6.07% * 100;
 Minibatch[1701-1800]: loss = 0.347217 * 100, metric = 6.40% * 100;
 Minibatch[1801-1900]: loss = 0.339803 * 100, metric = 6.22% * 100;
 Minibatch[1901-2000]: loss = 0.336381 * 100, metric = 5.92% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.339374 * 2000, metric = 6.15% * 2000 939.963s (  2.1 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 15.00% * 2000;
 Minibatch[   1- 100]: loss = 0.332584 * 100, metric = 6.17% * 100;
 Minibatch[ 101- 200]: loss = 0.328804 * 100, metric = 6.10% * 100;
 Minibatch[ 201- 300]: loss = 0.346007 * 100, metric = 6.20% * 100;
 Minibatch[ 301- 400]: loss = 0.339615 * 100, metric = 6.09% * 100;
 Minibatch[ 401- 500]: loss = 0.339606 * 100, metric = 6.29% * 100;
 Minibatch[ 501- 600]: loss = 0.333149 * 100, metric = 6.25% * 100;
 Minibatch[ 601- 700]: loss = 0.343868 * 100, metric = 6.09% * 100;
 Minibatch[ 701- 800]: loss = 0.330263 * 100, metric = 5.69% * 100;
 Minibatch[ 801- 900]: loss = 0.334810 * 100, metric = 5.97% * 100;
 Minibatch[ 901-1000]: loss = 0.330103 * 100, metric = 6.01% * 100;
 Minibatch[1001-1100]: loss = 0.337028 * 100, metric = 6.18% * 100;
 Minibatch[1101-1200]: loss = 0.336158 * 100, metric = 6.07% * 100;
 Minibatch[1201-1300]: loss = 0.334281 * 100, metric = 6.00% * 100;
 Minibatch[1301-1400]: loss = 0.340486 * 100, metric = 6.14% * 100;
 Minibatch[1401-1500]: loss = 0.332763 * 100, metric = 5.89% * 100;
 Minibatch[1501-1600]: loss = 0.344228 * 100, metric = 6.31% * 100;
 Minibatch[1601-1700]: loss = 0.343166 * 100, metric = 6.30% * 100;
 Minibatch[1701-1800]: loss = 0.325441 * 100, metric = 5.87% * 100;
 Minibatch[1801-1900]: loss = 0.333810 * 100, metric = 6.02% * 100;
 Minibatch[1901-2000]: loss = 0.345718 * 100, metric = 6.39% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.336594 * 2000, metric = 6.10% * 2000 924.858s (  2.2 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 15.30% * 2000;
 Minibatch[   1- 100]: loss = 0.335664 * 100, metric = 6.20% * 100;
 Minibatch[ 101- 200]: loss = 0.331974 * 100, metric = 5.95% * 100;
 Minibatch[ 201- 300]: loss = 0.339091 * 100, metric = 6.07% * 100;
 Minibatch[ 301- 400]: loss = 0.344507 * 100, metric = 6.32% * 100;
 Minibatch[ 401- 500]: loss = 0.337079 * 100, metric = 6.08% * 100;
 Minibatch[ 501- 600]: loss = 0.328976 * 100, metric = 5.79% * 100;
 Minibatch[ 601- 700]: loss = 0.341882 * 100, metric = 6.07% * 100;
 Minibatch[ 701- 800]: loss = 0.329727 * 100, metric = 5.95% * 100;
 Minibatch[ 801- 900]: loss = 0.331016 * 100, metric = 6.04% * 100;
 Minibatch[ 901-1000]: loss = 0.336992 * 100, metric = 6.15% * 100;
 Minibatch[1001-1100]: loss = 0.331255 * 100, metric = 5.85% * 100;
 Minibatch[1101-1200]: loss = 0.341879 * 100, metric = 6.16% * 100;
 Minibatch[1201-1300]: loss = 0.339534 * 100, metric = 6.06% * 100;
 Minibatch[1301-1400]: loss = 0.320031 * 100, metric = 5.71% * 100;
 Minibatch[1401-1500]: loss = 0.330961 * 100, metric = 6.07% * 100;
 Minibatch[1501-1600]: loss = 0.334207 * 100, metric = 5.97% * 100;
 Minibatch[1601-1700]: loss = 0.333743 * 100, metric = 6.19% * 100;
 Minibatch[1701-1800]: loss = 0.335260 * 100, metric = 6.09% * 100;
 Minibatch[1801-1900]: loss = 0.329822 * 100, metric = 6.16% * 100;
 Minibatch[1901-2000]: loss = 0.329862 * 100, metric = 5.87% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.334173 * 2000, metric = 6.04% * 2000 943.719s (  2.1 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 16.78% * 2000;
 Minibatch[   1- 100]: loss = 0.328569 * 100, metric = 5.91% * 100;
 Minibatch[ 101- 200]: loss = 0.331771 * 100, metric = 6.15% * 100;
 Minibatch[ 201- 300]: loss = 0.335365 * 100, metric = 6.19% * 100;
 Minibatch[ 301- 400]: loss = 0.324165 * 100, metric = 5.71% * 100;
 Minibatch[ 401- 500]: loss = 0.331669 * 100, metric = 5.95% * 100;
 Minibatch[ 501- 600]: loss = 0.337288 * 100, metric = 5.98% * 100;
 Minibatch[ 601- 700]: loss = 0.336410 * 100, metric = 6.14% * 100;
 Minibatch[ 701- 800]: loss = 0.322756 * 100, metric = 5.91% * 100;
 Minibatch[ 801- 900]: loss = 0.323866 * 100, metric = 5.76% * 100;
 Minibatch[ 901-1000]: loss = 0.341643 * 100, metric = 6.35% * 100;
 Minibatch[1001-1100]: loss = 0.333956 * 100, metric = 6.02% * 100;
 Minibatch[1101-1200]: loss = 0.328345 * 100, metric = 5.93% * 100;
 Minibatch[1201-1300]: loss = 0.324727 * 100, metric = 6.00% * 100;
 Minibatch[1301-1400]: loss = 0.331537 * 100, metric = 5.93% * 100;
 Minibatch[1401-1500]: loss = 0.323434 * 100, metric = 5.65% * 100;
 Minibatch[1501-1600]: loss = 0.322061 * 100, metric = 5.82% * 100;
 Minibatch[1601-1700]: loss = 0.329387 * 100, metric = 5.87% * 100;
 Minibatch[1701-1800]: loss = 0.327004 * 100, metric = 5.92% * 100;
 Minibatch[1801-1900]: loss = 0.327749 * 100, metric = 5.90% * 100;
 Minibatch[1901-2000]: loss = 0.321067 * 100, metric = 5.67% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.329138 * 2000, metric = 5.94% * 2000 925.501s (  2.2 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 14.05% * 2000;
 Minibatch[   1- 100]: loss = 0.341079 * 100, metric = 6.37% * 100;
 Minibatch[ 101- 200]: loss = 0.314955 * 100, metric = 5.61% * 100;
 Minibatch[ 201- 300]: loss = 0.335290 * 100, metric = 6.02% * 100;
 Minibatch[ 301- 400]: loss = 0.328749 * 100, metric = 6.00% * 100;
 Minibatch[ 401- 500]: loss = 0.325112 * 100, metric = 5.77% * 100;
 Minibatch[ 501- 600]: loss = 0.319308 * 100, metric = 5.79% * 100;
 Minibatch[ 601- 700]: loss = 0.330316 * 100, metric = 6.04% * 100;
 Minibatch[ 701- 800]: loss = 0.320894 * 100, metric = 6.00% * 100;
 Minibatch[ 801- 900]: loss = 0.323997 * 100, metric = 5.90% * 100;
 Minibatch[ 901-1000]: loss = 0.326846 * 100, metric = 5.71% * 100;
 Minibatch[1001-1100]: loss = 0.327426 * 100, metric = 6.03% * 100;
 Minibatch[1101-1200]: loss = 0.321893 * 100, metric = 5.90% * 100;
 Minibatch[1201-1300]: loss = 0.336842 * 100, metric = 6.26% * 100;
 Minibatch[1301-1400]: loss = 0.330303 * 100, metric = 6.15% * 100;
 Minibatch[1401-1500]: loss = 0.311163 * 100, metric = 5.48% * 100;
 Minibatch[1501-1600]: loss = 0.336715 * 100, metric = 5.93% * 100;
 Minibatch[1601-1700]: loss = 0.325273 * 100, metric = 6.00% * 100;
 Minibatch[1701-1800]: loss = 0.324110 * 100, metric = 6.01% * 100;
 Minibatch[1801-1900]: loss = 0.333652 * 100, metric = 6.18% * 100;
 Minibatch[1901-2000]: loss = 0.321674 * 100, metric = 5.63% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.326780 * 2000, metric = 5.94% * 2000 945.064s (  2.1 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 14.54% * 2000;
 Minibatch[   1- 100]: loss = 0.310295 * 100, metric = 5.48% * 100;
 Minibatch[ 101- 200]: loss = 0.323899 * 100, metric = 5.80% * 100;
 Minibatch[ 201- 300]: loss = 0.321727 * 100, metric = 5.78% * 100;
 Minibatch[ 301- 400]: loss = 0.326621 * 100, metric = 5.73% * 100;
 Minibatch[ 401- 500]: loss = 0.325376 * 100, metric = 5.86% * 100;
 Minibatch[ 501- 600]: loss = 0.312259 * 100, metric = 5.59% * 100;
 Minibatch[ 601- 700]: loss = 0.335096 * 100, metric = 6.25% * 100;
 Minibatch[ 701- 800]: loss = 0.300133 * 100, metric = 5.17% * 100;
 Minibatch[ 801- 900]: loss = 0.313582 * 100, metric = 5.48% * 100;
 Minibatch[ 901-1000]: loss = 0.312625 * 100, metric = 5.44% * 100;
 Minibatch[1001-1100]: loss = 0.311010 * 100, metric = 5.43% * 100;
 Minibatch[1101-1200]: loss = 0.306359 * 100, metric = 5.34% * 100;
 Minibatch[1201-1300]: loss = 0.312488 * 100, metric = 5.51% * 100;
 Minibatch[1301-1400]: loss = 0.315648 * 100, metric = 5.73% * 100;
 Minibatch[1401-1500]: loss = 0.310628 * 100, metric = 5.60% * 100;
 Minibatch[1501-1600]: loss = 0.304483 * 100, metric = 5.38% * 100;
 Minibatch[1601-1700]: loss = 0.321735 * 100, metric = 5.71% * 100;
 Minibatch[1701-1800]: loss = 0.327951 * 100, metric = 6.00% * 100;
 Minibatch[1801-1900]: loss = 0.314594 * 100, metric = 5.42% * 100;
 Minibatch[1901-2000]: loss = 0.304344 * 100, metric = 5.33% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.315543 * 2000, metric = 5.60% * 2000 933.706s (  2.1 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 15.24% * 2000;
 Minibatch[   1- 100]: loss = 0.323442 * 100, metric = 5.76% * 100;
 Minibatch[ 101- 200]: loss = 0.319555 * 100, metric = 5.67% * 100;
 Minibatch[ 201- 300]: loss = 0.308072 * 100, metric = 5.42% * 100;
 Minibatch[ 301- 400]: loss = 0.322323 * 100, metric = 5.76% * 100;
 Minibatch[ 401- 500]: loss = 0.318388 * 100, metric = 5.76% * 100;
 Minibatch[ 501- 600]: loss = 0.306410 * 100, metric = 5.33% * 100;
 Minibatch[ 601- 700]: loss = 0.307918 * 100, metric = 5.42% * 100;
 Minibatch[ 701- 800]: loss = 0.306793 * 100, metric = 5.66% * 100;
 Minibatch[ 801- 900]: loss = 0.333499 * 100, metric = 6.16% * 100;
 Minibatch[ 901-1000]: loss = 0.309440 * 100, metric = 5.47% * 100;
 Minibatch[1001-1100]: loss = 0.299336 * 100, metric = 5.14% * 100;
 Minibatch[1101-1200]: loss = 0.328433 * 100, metric = 5.88% * 100;
 Minibatch[1201-1300]: loss = 0.323193 * 100, metric = 5.81% * 100;
 Minibatch[1301-1400]: loss = 0.313655 * 100, metric = 5.66% * 100;
 Minibatch[1401-1500]: loss = 0.322919 * 100, metric = 5.85% * 100;
 Minibatch[1501-1600]: loss = 0.315807 * 100, metric = 5.61% * 100;
 Minibatch[1601-1700]: loss = 0.311944 * 100, metric = 5.61% * 100;
 Minibatch[1701-1800]: loss = 0.313975 * 100, metric = 5.64% * 100;
 Minibatch[1801-1900]: loss = 0.321885 * 100, metric = 6.00% * 100;
 Minibatch[1901-2000]: loss = 0.314169 * 100, metric = 5.45% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.316058 * 2000, metric = 5.65% * 2000 930.018s (  2.2 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 14.44% * 2000;
 Minibatch[   1- 100]: loss = 0.307874 * 100, metric = 5.54% * 100;
 Minibatch[ 101- 200]: loss = 0.326628 * 100, metric = 6.01% * 100;
 Minibatch[ 201- 300]: loss = 0.311639 * 100, metric = 5.40% * 100;
 Minibatch[ 301- 400]: loss = 0.321056 * 100, metric = 5.88% * 100;
 Minibatch[ 401- 500]: loss = 0.306693 * 100, metric = 5.31% * 100;
 Minibatch[ 501- 600]: loss = 0.314419 * 100, metric = 5.70% * 100;
 Minibatch[ 601- 700]: loss = 0.305044 * 100, metric = 5.38% * 100;
 Minibatch[ 701- 800]: loss = 0.302744 * 100, metric = 5.28% * 100;
 Minibatch[ 801- 900]: loss = 0.305002 * 100, metric = 5.43% * 100;
 Minibatch[ 901-1000]: loss = 0.311189 * 100, metric = 5.62% * 100;
 Minibatch[1001-1100]: loss = 0.308548 * 100, metric = 5.47% * 100;
 Minibatch[1101-1200]: loss = 0.311505 * 100, metric = 5.67% * 100;
 Minibatch[1201-1300]: loss = 0.312739 * 100, metric = 5.47% * 100;
 Minibatch[1301-1400]: loss = 0.306724 * 100, metric = 5.45% * 100;
 Minibatch[1401-1500]: loss = 0.305249 * 100, metric = 5.51% * 100;
 Minibatch[1501-1600]: loss = 0.319249 * 100, metric = 5.79% * 100;
 Minibatch[1601-1700]: loss = 0.296609 * 100, metric = 5.12% * 100;
 Minibatch[1701-1800]: loss = 0.322187 * 100, metric = 5.87% * 100;
 Minibatch[1801-1900]: loss = 0.300248 * 100, metric = 5.29% * 100;
 Minibatch[1901-2000]: loss = 0.305901 * 100, metric = 5.38% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.310062 * 2000, metric = 5.53% * 2000 933.708s (  2.1 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 14.48% * 2000;
 Minibatch[   1- 100]: loss = 0.308163 * 100, metric = 5.34% * 100;
 Minibatch[ 101- 200]: loss = 0.302012 * 100, metric = 5.44% * 100;
 Minibatch[ 201- 300]: loss = 0.310632 * 100, metric = 5.71% * 100;
 Minibatch[ 301- 400]: loss = 0.303910 * 100, metric = 5.21% * 100;
 Minibatch[ 401- 500]: loss = 0.296775 * 100, metric = 5.35% * 100;
 Minibatch[ 501- 600]: loss = 0.299835 * 100, metric = 5.42% * 100;
 Minibatch[ 601- 700]: loss = 0.313146 * 100, metric = 5.55% * 100;
 Minibatch[ 701- 800]: loss = 0.317721 * 100, metric = 5.84% * 100;
 Minibatch[ 801- 900]: loss = 0.303736 * 100, metric = 5.27% * 100;
 Minibatch[ 901-1000]: loss = 0.311472 * 100, metric = 5.45% * 100;
 Minibatch[1001-1100]: loss = 0.324108 * 100, metric = 6.08% * 100;
 Minibatch[1101-1200]: loss = 0.306548 * 100, metric = 5.39% * 100;
 Minibatch[1201-1300]: loss = 0.291048 * 100, metric = 5.08% * 100;
 Minibatch[1301-1400]: loss = 0.308044 * 100, metric = 5.49% * 100;
 Minibatch[1401-1500]: loss = 0.316836 * 100, metric = 5.55% * 100;
 Minibatch[1501-1600]: loss = 0.311284 * 100, metric = 5.41% * 100;
 Minibatch[1601-1700]: loss = 0.305922 * 100, metric = 5.32% * 100;
 Minibatch[1701-1800]: loss = 0.321652 * 100, metric = 5.73% * 100;
 Minibatch[1801-1900]: loss = 0.317190 * 100, metric = 5.74% * 100;
 Minibatch[1901-2000]: loss = 0.316008 * 100, metric = 5.64% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.309302 * 2000, metric = 5.50% * 2000 932.704s (  2.1 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 14.23% * 2000;
 Minibatch[   1- 100]: loss = 0.312690 * 100, metric = 5.65% * 100;
 Minibatch[ 101- 200]: loss = 0.309603 * 100, metric = 5.33% * 100;
 Minibatch[ 201- 300]: loss = 0.307686 * 100, metric = 5.63% * 100;
 Minibatch[ 301- 400]: loss = 0.300735 * 100, metric = 5.25% * 100;
 Minibatch[ 401- 500]: loss = 0.315405 * 100, metric = 5.64% * 100;
 Minibatch[ 501- 600]: loss = 0.326616 * 100, metric = 5.89% * 100;
 Minibatch[ 601- 700]: loss = 0.324995 * 100, metric = 5.66% * 100;
 Minibatch[ 701- 800]: loss = 0.309908 * 100, metric = 5.36% * 100;
 Minibatch[ 801- 900]: loss = 0.297607 * 100, metric = 5.05% * 100;
 Minibatch[ 901-1000]: loss = 0.311122 * 100, metric = 5.85% * 100;
 Minibatch[1001-1100]: loss = 0.308030 * 100, metric = 5.67% * 100;
 Minibatch[1101-1200]: loss = 0.308158 * 100, metric = 5.54% * 100;
 Minibatch[1201-1300]: loss = 0.298386 * 100, metric = 5.42% * 100;
 Minibatch[1301-1400]: loss = 0.303063 * 100, metric = 5.55% * 100;
 Minibatch[1401-1500]: loss = 0.311081 * 100, metric = 5.62% * 100;
 Minibatch[1501-1600]: loss = 0.301213 * 100, metric = 5.49% * 100;
 Minibatch[1601-1700]: loss = 0.298142 * 100, metric = 5.37% * 100;
 Minibatch[1701-1800]: loss = 0.304039 * 100, metric = 5.17% * 100;
 Minibatch[1801-1900]: loss = 0.305064 * 100, metric = 5.48% * 100;
 Minibatch[1901-2000]: loss = 0.291497 * 100, metric = 5.05% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.307252 * 2000, metric = 5.48% * 2000 933.510s (  2.1 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 14.74% * 2000;
 Minibatch[   1- 100]: loss = 0.315289 * 100, metric = 5.62% * 100;
 Minibatch[ 101- 200]: loss = 0.300043 * 100, metric = 5.36% * 100;
 Minibatch[ 201- 300]: loss = 0.314175 * 100, metric = 5.55% * 100;
 Minibatch[ 301- 400]: loss = 0.307691 * 100, metric = 5.50% * 100;
 Minibatch[ 401- 500]: loss = 0.316189 * 100, metric = 5.78% * 100;
 Minibatch[ 501- 600]: loss = 0.307409 * 100, metric = 5.46% * 100;
 Minibatch[ 601- 700]: loss = 0.299463 * 100, metric = 5.34% * 100;
 Minibatch[ 701- 800]: loss = 0.301150 * 100, metric = 5.32% * 100;
 Minibatch[ 801- 900]: loss = 0.299052 * 100, metric = 5.25% * 100;
 Minibatch[ 901-1000]: loss = 0.311400 * 100, metric = 5.69% * 100;
 Minibatch[1001-1100]: loss = 0.310160 * 100, metric = 5.62% * 100;
 Minibatch[1101-1200]: loss = 0.310822 * 100, metric = 5.77% * 100;
 Minibatch[1201-1300]: loss = 0.285525 * 100, metric = 4.96% * 100;
 Minibatch[1301-1400]: loss = 0.309944 * 100, metric = 5.51% * 100;
 Minibatch[1401-1500]: loss = 0.300622 * 100, metric = 5.41% * 100;
 Minibatch[1501-1600]: loss = 0.282049 * 100, metric = 4.85% * 100;
 Minibatch[1601-1700]: loss = 0.312447 * 100, metric = 5.85% * 100;
 Minibatch[1701-1800]: loss = 0.304952 * 100, metric = 5.56% * 100;
 Minibatch[1801-1900]: loss = 0.297575 * 100, metric = 5.23% * 100;
 Minibatch[1901-2000]: loss = 0.292233 * 100, metric = 5.13% * 100;
Finished Epoch[49 of 200]: [Training] loss = 0.303909 * 2000, metric = 5.44% * 2000 932.656s (  2.1 samples/s);
Finished Evaluation [49]: Minibatch[1-2000]: metric = 13.55% * 2000;
0.5698097478859127
 Minibatch[   1- 100]: loss = 0.306451 * 100, metric = 5.45% * 100;
 Minibatch[ 101- 200]: loss = 0.288282 * 100, metric = 5.01% * 100;
 Minibatch[ 201- 300]: loss = 0.292308 * 100, metric = 5.02% * 100;
 Minibatch[ 301- 400]: loss = 0.292621 * 100, metric = 5.06% * 100;
 Minibatch[ 401- 500]: loss = 0.310111 * 100, metric = 5.43% * 100;
 Minibatch[ 501- 600]: loss = 0.307352 * 100, metric = 5.62% * 100;
 Minibatch[ 601- 700]: loss = 0.294084 * 100, metric = 5.35% * 100;
 Minibatch[ 701- 800]: loss = 0.289845 * 100, metric = 5.16% * 100;
 Minibatch[ 801- 900]: loss = 0.302158 * 100, metric = 5.31% * 100;
 Minibatch[ 901-1000]: loss = 0.296237 * 100, metric = 5.07% * 100;
 Minibatch[1001-1100]: loss = 0.288880 * 100, metric = 5.30% * 100;
 Minibatch[1101-1200]: loss = 0.300957 * 100, metric = 5.30% * 100;
 Minibatch[1201-1300]: loss = 0.301974 * 100, metric = 5.52% * 100;
 Minibatch[1301-1400]: loss = 0.285583 * 100, metric = 5.25% * 100;
 Minibatch[1401-1500]: loss = 0.301638 * 100, metric = 5.58% * 100;
 Minibatch[1501-1600]: loss = 0.285846 * 100, metric = 4.98% * 100;
 Minibatch[1601-1700]: loss = 0.287532 * 100, metric = 5.13% * 100;
 Minibatch[1701-1800]: loss = 0.305912 * 100, metric = 5.60% * 100;
 Minibatch[1801-1900]: loss = 0.304954 * 100, metric = 5.40% * 100;
 Minibatch[1901-2000]: loss = 0.295189 * 100, metric = 5.28% * 100;
Finished Epoch[50 of 200]: [Training] loss = 0.296896 * 2000, metric = 5.29% * 2000 910.084s (  2.2 samples/s);
Finished Evaluation [50]: Minibatch[1-2000]: metric = 14.11% * 2000;
 Minibatch[   1- 100]: loss = 0.290195 * 100, metric = 5.14% * 100;
 Minibatch[ 101- 200]: loss = 0.300595 * 100, metric = 5.49% * 100;
 Minibatch[ 201- 300]: loss = 0.299378 * 100, metric = 5.26% * 100;
 Minibatch[ 301- 400]: loss = 0.295714 * 100, metric = 5.40% * 100;
 Minibatch[ 401- 500]: loss = 0.297007 * 100, metric = 5.35% * 100;
 Minibatch[ 501- 600]: loss = 0.301717 * 100, metric = 5.55% * 100;
 Minibatch[ 601- 700]: loss = 0.287034 * 100, metric = 5.08% * 100;
 Minibatch[ 701- 800]: loss = 0.295208 * 100, metric = 5.24% * 100;
 Minibatch[ 801- 900]: loss = 0.299692 * 100, metric = 5.31% * 100;
 Minibatch[ 901-1000]: loss = 0.299092 * 100, metric = 5.40% * 100;
 Minibatch[1001-1100]: loss = 0.297668 * 100, metric = 5.35% * 100;
 Minibatch[1101-1200]: loss = 0.301213 * 100, metric = 5.42% * 100;
 Minibatch[1201-1300]: loss = 0.313339 * 100, metric = 5.54% * 100;
 Minibatch[1301-1400]: loss = 0.301085 * 100, metric = 5.23% * 100;
 Minibatch[1401-1500]: loss = 0.292314 * 100, metric = 5.29% * 100;
 Minibatch[1501-1600]: loss = 0.307659 * 100, metric = 5.49% * 100;
 Minibatch[1601-1700]: loss = 0.288800 * 100, metric = 5.03% * 100;
 Minibatch[1701-1800]: loss = 0.298302 * 100, metric = 5.42% * 100;
 Minibatch[1801-1900]: loss = 0.281265 * 100, metric = 5.03% * 100;
 Minibatch[1901-2000]: loss = 0.291628 * 100, metric = 5.26% * 100;
Finished Epoch[51 of 200]: [Training] loss = 0.296945 * 2000, metric = 5.31% * 2000 895.777s (  2.2 samples/s);
Finished Evaluation [51]: Minibatch[1-2000]: metric = 13.74% * 2000;
0.5697926821000874
 Minibatch[   1- 100]: loss = 0.282008 * 100, metric = 5.09% * 100;
 Minibatch[ 101- 200]: loss = 0.293074 * 100, metric = 5.15% * 100;
 Minibatch[ 201- 300]: loss = 0.304560 * 100, metric = 5.58% * 100;
 Minibatch[ 301- 400]: loss = 0.290969 * 100, metric = 5.21% * 100;
 Minibatch[ 401- 500]: loss = 0.304942 * 100, metric = 5.41% * 100;
 Minibatch[ 501- 600]: loss = 0.294150 * 100, metric = 5.29% * 100;
 Minibatch[ 601- 700]: loss = 0.292568 * 100, metric = 5.14% * 100;
 Minibatch[ 701- 800]: loss = 0.302912 * 100, metric = 5.55% * 100;
 Minibatch[ 801- 900]: loss = 0.299098 * 100, metric = 5.51% * 100;
 Minibatch[ 901-1000]: loss = 0.311645 * 100, metric = 5.80% * 100;
 Minibatch[1001-1100]: loss = 0.298618 * 100, metric = 5.49% * 100;
 Minibatch[1101-1200]: loss = 0.281784 * 100, metric = 4.89% * 100;
 Minibatch[1201-1300]: loss = 0.284681 * 100, metric = 5.10% * 100;
 Minibatch[1301-1400]: loss = 0.294853 * 100, metric = 5.04% * 100;
 Minibatch[1401-1500]: loss = 0.277814 * 100, metric = 4.92% * 100;
 Minibatch[1501-1600]: loss = 0.283089 * 100, metric = 4.90% * 100;
 Minibatch[1601-1700]: loss = 0.299551 * 100, metric = 5.30% * 100;
 Minibatch[1701-1800]: loss = 0.286515 * 100, metric = 5.32% * 100;
 Minibatch[1801-1900]: loss = 0.283606 * 100, metric = 4.77% * 100;
 Minibatch[1901-2000]: loss = 0.291623 * 100, metric = 5.43% * 100;
Finished Epoch[52 of 200]: [Training] loss = 0.292903 * 2000, metric = 5.25% * 2000 908.341s (  2.2 samples/s);
Finished Evaluation [52]: Minibatch[1-2000]: metric = 14.35% * 2000;
 Minibatch[   1- 100]: loss = 0.296844 * 100, metric = 5.23% * 100;
 Minibatch[ 101- 200]: loss = 0.280578 * 100, metric = 4.81% * 100;
 Minibatch[ 201- 300]: loss = 0.293864 * 100, metric = 5.36% * 100;
 Minibatch[ 301- 400]: loss = 0.293190 * 100, metric = 5.33% * 100;
 Minibatch[ 401- 500]: loss = 0.298768 * 100, metric = 5.47% * 100;
 Minibatch[ 501- 600]: loss = 0.293390 * 100, metric = 5.23% * 100;
 Minibatch[ 601- 700]: loss = 0.291621 * 100, metric = 5.16% * 100;
 Minibatch[ 701- 800]: loss = 0.292006 * 100, metric = 5.21% * 100;
 Minibatch[ 801- 900]: loss = 0.294362 * 100, metric = 5.41% * 100;
 Minibatch[ 901-1000]: loss = 0.290969 * 100, metric = 5.17% * 100;
 Minibatch[1001-1100]: loss = 0.293173 * 100, metric = 5.17% * 100;
 Minibatch[1101-1200]: loss = 0.285399 * 100, metric = 5.14% * 100;
 Minibatch[1201-1300]: loss = 0.281714 * 100, metric = 5.06% * 100;
 Minibatch[1301-1400]: loss = 0.291438 * 100, metric = 5.18% * 100;
 Minibatch[1401-1500]: loss = 0.284005 * 100, metric = 4.93% * 100;
 Minibatch[1501-1600]: loss = 0.297289 * 100, metric = 5.56% * 100;
 Minibatch[1601-1700]: loss = 0.284571 * 100, metric = 4.97% * 100;
 Minibatch[1701-1800]: loss = 0.304500 * 100, metric = 5.44% * 100;
 Minibatch[1801-1900]: loss = 0.306118 * 100, metric = 5.53% * 100;
 Minibatch[1901-2000]: loss = 0.275967 * 100, metric = 4.75% * 100;
Finished Epoch[53 of 200]: [Training] loss = 0.291488 * 2000, metric = 5.20% * 2000 899.256s (  2.2 samples/s);
Finished Evaluation [53]: Minibatch[1-2000]: metric = 13.75% * 2000;
 Minibatch[   1- 100]: loss = 0.287371 * 100, metric = 5.15% * 100;
 Minibatch[ 101- 200]: loss = 0.288756 * 100, metric = 5.13% * 100;
 Minibatch[ 201- 300]: loss = 0.286157 * 100, metric = 5.19% * 100;
 Minibatch[ 301- 400]: loss = 0.282110 * 100, metric = 4.85% * 100;
 Minibatch[ 401- 500]: loss = 0.288505 * 100, metric = 5.17% * 100;
 Minibatch[ 501- 600]: loss = 0.279978 * 100, metric = 4.70% * 100;
 Minibatch[ 601- 700]: loss = 0.292727 * 100, metric = 5.20% * 100;
 Minibatch[ 701- 800]: loss = 0.286471 * 100, metric = 5.16% * 100;
 Minibatch[ 801- 900]: loss = 0.270710 * 100, metric = 4.73% * 100;
 Minibatch[ 901-1000]: loss = 0.283122 * 100, metric = 4.98% * 100;
 Minibatch[1001-1100]: loss = 0.275620 * 100, metric = 4.79% * 100;
 Minibatch[1101-1200]: loss = 0.277035 * 100, metric = 4.96% * 100;
 Minibatch[1201-1300]: loss = 0.281766 * 100, metric = 5.01% * 100;
 Minibatch[1301-1400]: loss = 0.280342 * 100, metric = 5.08% * 100;
 Minibatch[1401-1500]: loss = 0.289559 * 100, metric = 5.06% * 100;
 Minibatch[1501-1600]: loss = 0.289778 * 100, metric = 5.10% * 100;
 Minibatch[1601-1700]: loss = 0.282571 * 100, metric = 5.10% * 100;
 Minibatch[1701-1800]: loss = 0.282516 * 100, metric = 4.97% * 100;
 Minibatch[1801-1900]: loss = 0.291736 * 100, metric = 5.28% * 100;
 Minibatch[1901-2000]: loss = 0.288325 * 100, metric = 5.14% * 100;
Finished Epoch[54 of 200]: [Training] loss = 0.284258 * 2000, metric = 5.04% * 2000 890.654s (  2.2 samples/s);
Finished Evaluation [54]: Minibatch[1-2000]: metric = 13.40% * 2000;
 Minibatch[   1- 100]: loss = 0.287814 * 100, metric = 5.05% * 100;
 Minibatch[ 101- 200]: loss = 0.289283 * 100, metric = 5.24% * 100;
 Minibatch[ 201- 300]: loss = 0.287675 * 100, metric = 5.10% * 100;
 Minibatch[ 301- 400]: loss = 0.277509 * 100, metric = 4.74% * 100;
 Minibatch[ 401- 500]: loss = 0.281485 * 100, metric = 4.98% * 100;
 Minibatch[ 501- 600]: loss = 0.288629 * 100, metric = 4.93% * 100;
 Minibatch[ 601- 700]: loss = 0.291291 * 100, metric = 5.29% * 100;
 Minibatch[ 701- 800]: loss = 0.296636 * 100, metric = 5.33% * 100;
 Minibatch[ 801- 900]: loss = 0.288196 * 100, metric = 5.09% * 100;
 Minibatch[ 901-1000]: loss = 0.273375 * 100, metric = 4.79% * 100;
 Minibatch[1001-1100]: loss = 0.285970 * 100, metric = 5.06% * 100;
 Minibatch[1101-1200]: loss = 0.288937 * 100, metric = 5.03% * 100;
 Minibatch[1201-1300]: loss = 0.281088 * 100, metric = 4.98% * 100;
 Minibatch[1301-1400]: loss = 0.266503 * 100, metric = 4.61% * 100;
 Minibatch[1401-1500]: loss = 0.284439 * 100, metric = 5.04% * 100;
 Minibatch[1501-1600]: loss = 0.279177 * 100, metric = 4.85% * 100;
 Minibatch[1601-1700]: loss = 0.280199 * 100, metric = 5.02% * 100;
 Minibatch[1701-1800]: loss = 0.280697 * 100, metric = 4.98% * 100;
 Minibatch[1801-1900]: loss = 0.269843 * 100, metric = 4.69% * 100;
 Minibatch[1901-2000]: loss = 0.282104 * 100, metric = 4.84% * 100;
Finished Epoch[55 of 200]: [Training] loss = 0.283043 * 2000, metric = 4.98% * 2000 897.451s (  2.2 samples/s);
Finished Evaluation [55]: Minibatch[1-2000]: metric = 13.50% * 2000;
 Minibatch[   1- 100]: loss = 0.286922 * 100, metric = 5.32% * 100;
 Minibatch[ 101- 200]: loss = 0.272578 * 100, metric = 4.77% * 100;
 Minibatch[ 201- 300]: loss = 0.285787 * 100, metric = 4.95% * 100;
 Minibatch[ 301- 400]: loss = 0.281084 * 100, metric = 5.06% * 100;
 Minibatch[ 401- 500]: loss = 0.286944 * 100, metric = 5.22% * 100;
 Minibatch[ 501- 600]: loss = 0.294181 * 100, metric = 5.17% * 100;
 Minibatch[ 601- 700]: loss = 0.281002 * 100, metric = 5.04% * 100;
 Minibatch[ 701- 800]: loss = 0.273485 * 100, metric = 4.75% * 100;
 Minibatch[ 801- 900]: loss = 0.281361 * 100, metric = 5.03% * 100;
 Minibatch[ 901-1000]: loss = 0.281875 * 100, metric = 5.10% * 100;
 Minibatch[1001-1100]: loss = 0.284967 * 100, metric = 5.01% * 100;
 Minibatch[1101-1200]: loss = 0.286065 * 100, metric = 5.00% * 100;
 Minibatch[1201-1300]: loss = 0.280698 * 100, metric = 4.94% * 100;
 Minibatch[1301-1400]: loss = 0.274885 * 100, metric = 4.57% * 100;
 Minibatch[1401-1500]: loss = 0.289872 * 100, metric = 5.08% * 100;
 Minibatch[1501-1600]: loss = 0.278884 * 100, metric = 4.84% * 100;
 Minibatch[1601-1700]: loss = 0.275253 * 100, metric = 4.61% * 100;
 Minibatch[1701-1800]: loss = 0.278842 * 100, metric = 4.87% * 100;
 Minibatch[1801-1900]: loss = 0.273117 * 100, metric = 4.76% * 100;
 Minibatch[1901-2000]: loss = 0.286580 * 100, metric = 5.18% * 100;
Finished Epoch[56 of 200]: [Training] loss = 0.281719 * 2000, metric = 4.96% * 2000 918.176s (  2.2 samples/s);
Finished Evaluation [56]: Minibatch[1-2000]: metric = 12.69% * 2000;
0.5579839397966861
 Minibatch[   1- 100]: loss = 0.286748 * 100, metric = 4.89% * 100;
 Minibatch[ 101- 200]: loss = 0.270230 * 100, metric = 4.71% * 100;
 Minibatch[ 201- 300]: loss = 0.275561 * 100, metric = 4.81% * 100;
 Minibatch[ 301- 400]: loss = 0.274974 * 100, metric = 4.63% * 100;
 Minibatch[ 401- 500]: loss = 0.271513 * 100, metric = 4.70% * 100;
 Minibatch[ 501- 600]: loss = 0.266680 * 100, metric = 4.53% * 100;
 Minibatch[ 601- 700]: loss = 0.283895 * 100, metric = 4.90% * 100;
 Minibatch[ 701- 800]: loss = 0.268233 * 100, metric = 4.71% * 100;
 Minibatch[ 801- 900]: loss = 0.278211 * 100, metric = 4.89% * 100;
 Minibatch[ 901-1000]: loss = 0.276070 * 100, metric = 4.81% * 100;
 Minibatch[1001-1100]: loss = 0.287441 * 100, metric = 5.10% * 100;
 Minibatch[1101-1200]: loss = 0.278412 * 100, metric = 4.83% * 100;
 Minibatch[1201-1300]: loss = 0.280074 * 100, metric = 5.02% * 100;
 Minibatch[1301-1400]: loss = 0.274111 * 100, metric = 4.77% * 100;
 Minibatch[1401-1500]: loss = 0.288140 * 100, metric = 5.06% * 100;
 Minibatch[1501-1600]: loss = 0.270016 * 100, metric = 4.70% * 100;
 Minibatch[1601-1700]: loss = 0.278326 * 100, metric = 4.93% * 100;
 Minibatch[1701-1800]: loss = 0.276448 * 100, metric = 4.91% * 100;
 Minibatch[1801-1900]: loss = 0.283825 * 100, metric = 4.96% * 100;
 Minibatch[1901-2000]: loss = 0.285648 * 100, metric = 5.08% * 100;
Finished Epoch[57 of 200]: [Training] loss = 0.277728 * 2000, metric = 4.85% * 2000 904.663s (  2.2 samples/s);
Finished Evaluation [57]: Minibatch[1-2000]: metric = 13.36% * 2000;
 Minibatch[   1- 100]: loss = 0.273930 * 100, metric = 4.50% * 100;
 Minibatch[ 101- 200]: loss = 0.279748 * 100, metric = 4.99% * 100;
 Minibatch[ 201- 300]: loss = 0.271569 * 100, metric = 4.92% * 100;
 Minibatch[ 301- 400]: loss = 0.287602 * 100, metric = 5.03% * 100;
 Minibatch[ 401- 500]: loss = 0.296801 * 100, metric = 5.36% * 100;
 Minibatch[ 501- 600]: loss = 0.269690 * 100, metric = 4.72% * 100;
 Minibatch[ 601- 700]: loss = 0.279992 * 100, metric = 4.77% * 100;
 Minibatch[ 701- 800]: loss = 0.293261 * 100, metric = 5.24% * 100;
 Minibatch[ 801- 900]: loss = 0.278789 * 100, metric = 4.85% * 100;
 Minibatch[ 901-1000]: loss = 0.273015 * 100, metric = 4.83% * 100;
 Minibatch[1001-1100]: loss = 0.280681 * 100, metric = 4.99% * 100;
 Minibatch[1101-1200]: loss = 0.282560 * 100, metric = 5.04% * 100;
 Minibatch[1201-1300]: loss = 0.276517 * 100, metric = 4.86% * 100;
 Minibatch[1301-1400]: loss = 0.276645 * 100, metric = 4.85% * 100;
 Minibatch[1401-1500]: loss = 0.269894 * 100, metric = 4.72% * 100;
 Minibatch[1501-1600]: loss = 0.280610 * 100, metric = 4.92% * 100;
 Minibatch[1601-1700]: loss = 0.278376 * 100, metric = 4.87% * 100;
 Minibatch[1701-1800]: loss = 0.276170 * 100, metric = 4.83% * 100;
 Minibatch[1801-1900]: loss = 0.279406 * 100, metric = 4.81% * 100;
 Minibatch[1901-2000]: loss = 0.266276 * 100, metric = 4.47% * 100;
Finished Epoch[58 of 200]: [Training] loss = 0.278577 * 2000, metric = 4.88% * 2000 903.355s (  2.2 samples/s);
Finished Evaluation [58]: Minibatch[1-2000]: metric = 12.59% * 2000;
0.5528924955576658
 Minibatch[   1- 100]: loss = 0.289315 * 100, metric = 5.27% * 100;
 Minibatch[ 101- 200]: loss = 0.287752 * 100, metric = 5.45% * 100;
 Minibatch[ 201- 300]: loss = 0.274778 * 100, metric = 4.97% * 100;
 Minibatch[ 301- 400]: loss = 0.274632 * 100, metric = 4.66% * 100;
 Minibatch[ 401- 500]: loss = 0.274689 * 100, metric = 4.85% * 100;
 Minibatch[ 501- 600]: loss = 0.265235 * 100, metric = 4.67% * 100;
 Minibatch[ 601- 700]: loss = 0.268069 * 100, metric = 4.74% * 100;
 Minibatch[ 701- 800]: loss = 0.271716 * 100, metric = 4.58% * 100;
 Minibatch[ 801- 900]: loss = 0.267089 * 100, metric = 4.82% * 100;
 Minibatch[ 901-1000]: loss = 0.271957 * 100, metric = 4.82% * 100;
 Minibatch[1001-1100]: loss = 0.269132 * 100, metric = 4.74% * 100;
 Minibatch[1101-1200]: loss = 0.273855 * 100, metric = 4.90% * 100;
 Minibatch[1201-1300]: loss = 0.272928 * 100, metric = 4.84% * 100;
 Minibatch[1301-1400]: loss = 0.273346 * 100, metric = 4.76% * 100;
 Minibatch[1401-1500]: loss = 0.273264 * 100, metric = 4.74% * 100;
 Minibatch[1501-1600]: loss = 0.271349 * 100, metric = 4.79% * 100;
 Minibatch[1601-1700]: loss = 0.272890 * 100, metric = 4.88% * 100;
 Minibatch[1701-1800]: loss = 0.270930 * 100, metric = 4.73% * 100;
 Minibatch[1801-1900]: loss = 0.275598 * 100, metric = 4.95% * 100;
 Minibatch[1901-2000]: loss = 0.278987 * 100, metric = 4.83% * 100;
Finished Epoch[59 of 200]: [Training] loss = 0.273876 * 2000, metric = 4.85% * 2000 918.261s (  2.2 samples/s);
Finished Evaluation [59]: Minibatch[1-2000]: metric = 13.83% * 2000;
 Minibatch[   1- 100]: loss = 0.268103 * 100, metric = 4.78% * 100;
 Minibatch[ 101- 200]: loss = 0.262631 * 100, metric = 4.64% * 100;
 Minibatch[ 201- 300]: loss = 0.266007 * 100, metric = 4.54% * 100;
 Minibatch[ 301- 400]: loss = 0.272415 * 100, metric = 4.77% * 100;
 Minibatch[ 401- 500]: loss = 0.278202 * 100, metric = 5.08% * 100;
 Minibatch[ 501- 600]: loss = 0.280928 * 100, metric = 5.29% * 100;
 Minibatch[ 601- 700]: loss = 0.260289 * 100, metric = 4.55% * 100;
 Minibatch[ 701- 800]: loss = 0.271058 * 100, metric = 4.74% * 100;
 Minibatch[ 801- 900]: loss = 0.274547 * 100, metric = 5.09% * 100;
 Minibatch[ 901-1000]: loss = 0.273726 * 100, metric = 4.94% * 100;
 Minibatch[1001-1100]: loss = 0.282304 * 100, metric = 5.19% * 100;
 Minibatch[1101-1200]: loss = 0.268774 * 100, metric = 4.70% * 100;
 Minibatch[1201-1300]: loss = 0.269279 * 100, metric = 4.84% * 100;
 Minibatch[1301-1400]: loss = 0.267839 * 100, metric = 4.85% * 100;
 Minibatch[1401-1500]: loss = 0.258258 * 100, metric = 4.50% * 100;
 Minibatch[1501-1600]: loss = 0.272848 * 100, metric = 4.76% * 100;
 Minibatch[1601-1700]: loss = 0.270684 * 100, metric = 4.77% * 100;
 Minibatch[1701-1800]: loss = 0.272379 * 100, metric = 4.80% * 100;
 Minibatch[1801-1900]: loss = 0.278935 * 100, metric = 5.10% * 100;
 Minibatch[1901-2000]: loss = 0.264591 * 100, metric = 4.52% * 100;
Finished Epoch[60 of 200]: [Training] loss = 0.270690 * 2000, metric = 4.82% * 2000 926.725s (  2.2 samples/s);
Finished Evaluation [60]: Minibatch[1-2000]: metric = 13.76% * 2000;
 Minibatch[   1- 100]: loss = 0.281548 * 100, metric = 5.02% * 100;
 Minibatch[ 101- 200]: loss = 0.255449 * 100, metric = 4.35% * 100;
 Minibatch[ 201- 300]: loss = 0.270672 * 100, metric = 4.79% * 100;
 Minibatch[ 301- 400]: loss = 0.272287 * 100, metric = 4.89% * 100;
 Minibatch[ 401- 500]: loss = 0.267680 * 100, metric = 4.90% * 100;
 Minibatch[ 501- 600]: loss = 0.251630 * 100, metric = 4.29% * 100;
 Minibatch[ 601- 700]: loss = 0.268809 * 100, metric = 4.51% * 100;
 Minibatch[ 701- 800]: loss = 0.272813 * 100, metric = 4.85% * 100;
 Minibatch[ 801- 900]: loss = 0.263675 * 100, metric = 4.59% * 100;
 Minibatch[ 901-1000]: loss = 0.263046 * 100, metric = 4.77% * 100;
 Minibatch[1001-1100]: loss = 0.262227 * 100, metric = 4.69% * 100;
 Minibatch[1101-1200]: loss = 0.268014 * 100, metric = 4.81% * 100;
 Minibatch[1201-1300]: loss = 0.263059 * 100, metric = 4.74% * 100;
 Minibatch[1301-1400]: loss = 0.247061 * 100, metric = 4.00% * 100;
 Minibatch[1401-1500]: loss = 0.275110 * 100, metric = 5.03% * 100;
 Minibatch[1501-1600]: loss = 0.283244 * 100, metric = 5.13% * 100;
 Minibatch[1601-1700]: loss = 0.273642 * 100, metric = 4.93% * 100;
 Minibatch[1701-1800]: loss = 0.268463 * 100, metric = 4.60% * 100;
 Minibatch[1801-1900]: loss = 0.269580 * 100, metric = 4.82% * 100;
 Minibatch[1901-2000]: loss = 0.270090 * 100, metric = 4.82% * 100;
Finished Epoch[61 of 200]: [Training] loss = 0.267405 * 2000, metric = 4.73% * 2000 895.381s (  2.2 samples/s);
Finished Evaluation [61]: Minibatch[1-2000]: metric = 13.29% * 2000;
 Minibatch[   1- 100]: loss = 0.263847 * 100, metric = 4.66% * 100;
 Minibatch[ 101- 200]: loss = 0.259262 * 100, metric = 4.59% * 100;
 Minibatch[ 201- 300]: loss = 0.263010 * 100, metric = 4.61% * 100;
 Minibatch[ 301- 400]: loss = 0.267676 * 100, metric = 4.75% * 100;
 Minibatch[ 401- 500]: loss = 0.265613 * 100, metric = 4.64% * 100;
 Minibatch[ 501- 600]: loss = 0.268746 * 100, metric = 4.67% * 100;
 Minibatch[ 601- 700]: loss = 0.268884 * 100, metric = 4.84% * 100;
 Minibatch[ 701- 800]: loss = 0.262319 * 100, metric = 4.67% * 100;
 Minibatch[ 801- 900]: loss = 0.265318 * 100, metric = 4.77% * 100;
 Minibatch[ 901-1000]: loss = 0.270595 * 100, metric = 4.86% * 100;
 Minibatch[1001-1100]: loss = 0.254106 * 100, metric = 4.27% * 100;
 Minibatch[1101-1200]: loss = 0.274439 * 100, metric = 4.89% * 100;
 Minibatch[1201-1300]: loss = 0.260180 * 100, metric = 4.65% * 100;
 Minibatch[1301-1400]: loss = 0.281190 * 100, metric = 4.94% * 100;
 Minibatch[1401-1500]: loss = 0.252903 * 100, metric = 4.51% * 100;
 Minibatch[1501-1600]: loss = 0.256212 * 100, metric = 4.38% * 100;
 Minibatch[1601-1700]: loss = 0.265865 * 100, metric = 4.69% * 100;
 Minibatch[1701-1800]: loss = 0.276704 * 100, metric = 4.84% * 100;
 Minibatch[1801-1900]: loss = 0.274824 * 100, metric = 4.82% * 100;
 Minibatch[1901-2000]: loss = 0.271544 * 100, metric = 4.87% * 100;
Finished Epoch[62 of 200]: [Training] loss = 0.266162 * 2000, metric = 4.70% * 2000 910.694s (  2.2 samples/s);
Finished Evaluation [62]: Minibatch[1-2000]: metric = 13.26% * 2000;
 Minibatch[   1- 100]: loss = 0.264686 * 100, metric = 4.63% * 100;
 Minibatch[ 101- 200]: loss = 0.255443 * 100, metric = 4.40% * 100;
 Minibatch[ 201- 300]: loss = 0.273758 * 100, metric = 4.92% * 100;
 Minibatch[ 301- 400]: loss = 0.253540 * 100, metric = 4.42% * 100;
 Minibatch[ 401- 500]: loss = 0.257764 * 100, metric = 4.50% * 100;
 Minibatch[ 501- 600]: loss = 0.262188 * 100, metric = 4.34% * 100;
 Minibatch[ 601- 700]: loss = 0.267337 * 100, metric = 4.86% * 100;
 Minibatch[ 701- 800]: loss = 0.269365 * 100, metric = 4.81% * 100;
 Minibatch[ 801- 900]: loss = 0.265237 * 100, metric = 4.74% * 100;
 Minibatch[ 901-1000]: loss = 0.248439 * 100, metric = 4.35% * 100;
 Minibatch[1001-1100]: loss = 0.263771 * 100, metric = 4.56% * 100;
 Minibatch[1101-1200]: loss = 0.260395 * 100, metric = 4.56% * 100;
 Minibatch[1201-1300]: loss = 0.259039 * 100, metric = 4.41% * 100;
 Minibatch[1301-1400]: loss = 0.267616 * 100, metric = 4.61% * 100;
 Minibatch[1401-1500]: loss = 0.248862 * 100, metric = 4.32% * 100;
 Minibatch[1501-1600]: loss = 0.260527 * 100, metric = 4.62% * 100;
 Minibatch[1601-1700]: loss = 0.262689 * 100, metric = 4.60% * 100;
 Minibatch[1701-1800]: loss = 0.259063 * 100, metric = 4.69% * 100;
 Minibatch[1801-1900]: loss = 0.265583 * 100, metric = 4.48% * 100;
 Minibatch[1901-2000]: loss = 0.265504 * 100, metric = 4.78% * 100;
Finished Epoch[63 of 200]: [Training] loss = 0.261540 * 2000, metric = 4.58% * 2000 904.461s (  2.2 samples/s);
Finished Evaluation [63]: Minibatch[1-2000]: metric = 13.84% * 2000;
 Minibatch[   1- 100]: loss = 0.262453 * 100, metric = 4.47% * 100;
 Minibatch[ 101- 200]: loss = 0.263050 * 100, metric = 4.66% * 100;
 Minibatch[ 201- 300]: loss = 0.263537 * 100, metric = 4.66% * 100;
 Minibatch[ 301- 400]: loss = 0.267623 * 100, metric = 4.60% * 100;
 Minibatch[ 401- 500]: loss = 0.258320 * 100, metric = 4.53% * 100;
 Minibatch[ 501- 600]: loss = 0.258209 * 100, metric = 4.40% * 100;
 Minibatch[ 601- 700]: loss = 0.253927 * 100, metric = 4.39% * 100;
 Minibatch[ 701- 800]: loss = 0.266298 * 100, metric = 4.66% * 100;
 Minibatch[ 801- 900]: loss = 0.262298 * 100, metric = 4.49% * 100;
 Minibatch[ 901-1000]: loss = 0.253781 * 100, metric = 4.34% * 100;
 Minibatch[1001-1100]: loss = 0.260251 * 100, metric = 4.49% * 100;
 Minibatch[1101-1200]: loss = 0.259033 * 100, metric = 4.60% * 100;
 Minibatch[1201-1300]: loss = 0.255710 * 100, metric = 4.47% * 100;
 Minibatch[1301-1400]: loss = 0.266558 * 100, metric = 4.77% * 100;
 Minibatch[1401-1500]: loss = 0.263306 * 100, metric = 4.70% * 100;
 Minibatch[1501-1600]: loss = 0.267976 * 100, metric = 4.92% * 100;
 Minibatch[1601-1700]: loss = 0.249691 * 100, metric = 4.35% * 100;
 Minibatch[1701-1800]: loss = 0.254402 * 100, metric = 4.36% * 100;
 Minibatch[1801-1900]: loss = 0.265520 * 100, metric = 4.77% * 100;
 Minibatch[1901-2000]: loss = 0.256070 * 100, metric = 4.58% * 100;
Finished Epoch[64 of 200]: [Training] loss = 0.260401 * 2000, metric = 4.56% * 2000 906.680s (  2.2 samples/s);
Finished Evaluation [64]: Minibatch[1-2000]: metric = 14.10% * 2000;
 Minibatch[   1- 100]: loss = 0.249856 * 100, metric = 4.46% * 100;
 Minibatch[ 101- 200]: loss = 0.251210 * 100, metric = 4.40% * 100;
 Minibatch[ 201- 300]: loss = 0.256932 * 100, metric = 4.42% * 100;
 Minibatch[ 301- 400]: loss = 0.260259 * 100, metric = 4.57% * 100;
 Minibatch[ 401- 500]: loss = 0.263879 * 100, metric = 4.48% * 100;
 Minibatch[ 501- 600]: loss = 0.255866 * 100, metric = 4.46% * 100;
 Minibatch[ 601- 700]: loss = 0.256539 * 100, metric = 4.45% * 100;
 Minibatch[ 701- 800]: loss = 0.271123 * 100, metric = 5.05% * 100;
 Minibatch[ 801- 900]: loss = 0.255071 * 100, metric = 4.46% * 100;
 Minibatch[ 901-1000]: loss = 0.261022 * 100, metric = 4.69% * 100;
 Minibatch[1001-1100]: loss = 0.260897 * 100, metric = 4.75% * 100;
 Minibatch[1101-1200]: loss = 0.256978 * 100, metric = 4.33% * 100;
 Minibatch[1201-1300]: loss = 0.266641 * 100, metric = 4.60% * 100;
 Minibatch[1301-1400]: loss = 0.257197 * 100, metric = 4.62% * 100;
 Minibatch[1401-1500]: loss = 0.249608 * 100, metric = 4.25% * 100;
 Minibatch[1501-1600]: loss = 0.255172 * 100, metric = 4.60% * 100;
 Minibatch[1601-1700]: loss = 0.262984 * 100, metric = 4.39% * 100;
 Minibatch[1701-1800]: loss = 0.256890 * 100, metric = 4.54% * 100;
 Minibatch[1801-1900]: loss = 0.258045 * 100, metric = 4.57% * 100;
 Minibatch[1901-2000]: loss = 0.260089 * 100, metric = 4.51% * 100;
Finished Epoch[65 of 200]: [Training] loss = 0.258313 * 2000, metric = 4.53% * 2000 915.258s (  2.2 samples/s);
Finished Evaluation [65]: Minibatch[1-2000]: metric = 13.08% * 2000;
 Minibatch[   1- 100]: loss = 0.252273 * 100, metric = 4.35% * 100;
 Minibatch[ 101- 200]: loss = 0.260794 * 100, metric = 4.45% * 100;
 Minibatch[ 201- 300]: loss = 0.262390 * 100, metric = 4.59% * 100;
 Minibatch[ 301- 400]: loss = 0.250798 * 100, metric = 4.41% * 100;
 Minibatch[ 401- 500]: loss = 0.258542 * 100, metric = 4.50% * 100;
 Minibatch[ 501- 600]: loss = 0.246735 * 100, metric = 4.29% * 100;
 Minibatch[ 601- 700]: loss = 0.248619 * 100, metric = 4.25% * 100;
 Minibatch[ 701- 800]: loss = 0.254371 * 100, metric = 4.41% * 100;
 Minibatch[ 801- 900]: loss = 0.242090 * 100, metric = 4.11% * 100;
 Minibatch[ 901-1000]: loss = 0.256669 * 100, metric = 4.36% * 100;
 Minibatch[1001-1100]: loss = 0.260040 * 100, metric = 4.53% * 100;
 Minibatch[1101-1200]: loss = 0.254319 * 100, metric = 4.37% * 100;
 Minibatch[1201-1300]: loss = 0.256805 * 100, metric = 4.71% * 100;
 Minibatch[1301-1400]: loss = 0.250131 * 100, metric = 4.35% * 100;
 Minibatch[1401-1500]: loss = 0.248544 * 100, metric = 4.29% * 100;
 Minibatch[1501-1600]: loss = 0.260241 * 100, metric = 4.71% * 100;
 Minibatch[1601-1700]: loss = 0.250600 * 100, metric = 4.27% * 100;
 Minibatch[1701-1800]: loss = 0.260222 * 100, metric = 4.66% * 100;
 Minibatch[1801-1900]: loss = 0.256320 * 100, metric = 4.41% * 100;
 Minibatch[1901-2000]: loss = 0.256563 * 100, metric = 4.43% * 100;
Finished Epoch[66 of 200]: [Training] loss = 0.254353 * 2000, metric = 4.42% * 2000 928.696s (  2.2 samples/s);
Finished Evaluation [66]: Minibatch[1-2000]: metric = 13.75% * 2000;
 Minibatch[   1- 100]: loss = 0.259811 * 100, metric = 4.59% * 100;
 Minibatch[ 101- 200]: loss = 0.250620 * 100, metric = 4.49% * 100;
 Minibatch[ 201- 300]: loss = 0.255861 * 100, metric = 4.32% * 100;
 Minibatch[ 301- 400]: loss = 0.263950 * 100, metric = 4.79% * 100;
 Minibatch[ 401- 500]: loss = 0.261181 * 100, metric = 4.53% * 100;
 Minibatch[ 501- 600]: loss = 0.260421 * 100, metric = 4.46% * 100;
 Minibatch[ 601- 700]: loss = 0.248806 * 100, metric = 4.28% * 100;
 Minibatch[ 701- 800]: loss = 0.261247 * 100, metric = 4.62% * 100;
 Minibatch[ 801- 900]: loss = 0.257019 * 100, metric = 4.52% * 100;
 Minibatch[ 901-1000]: loss = 0.259701 * 100, metric = 4.50% * 100;
 Minibatch[1001-1100]: loss = 0.256280 * 100, metric = 4.41% * 100;
 Minibatch[1101-1200]: loss = 0.263885 * 100, metric = 4.65% * 100;
 Minibatch[1201-1300]: loss = 0.260136 * 100, metric = 4.61% * 100;
 Minibatch[1301-1400]: loss = 0.258987 * 100, metric = 4.46% * 100;
 Minibatch[1401-1500]: loss = 0.242788 * 100, metric = 4.09% * 100;
 Minibatch[1501-1600]: loss = 0.256387 * 100, metric = 4.55% * 100;
 Minibatch[1601-1700]: loss = 0.249162 * 100, metric = 4.38% * 100;
 Minibatch[1701-1800]: loss = 0.268689 * 100, metric = 4.78% * 100;
 Minibatch[1801-1900]: loss = 0.248820 * 100, metric = 4.36% * 100;
 Minibatch[1901-2000]: loss = 0.263096 * 100, metric = 4.71% * 100;
Finished Epoch[67 of 200]: [Training] loss = 0.257342 * 2000, metric = 4.50% * 2000 895.382s (  2.2 samples/s);
Finished Evaluation [67]: Minibatch[1-2000]: metric = 13.33% * 2000;
 Minibatch[   1- 100]: loss = 0.247208 * 100, metric = 4.21% * 100;
 Minibatch[ 101- 200]: loss = 0.259371 * 100, metric = 4.55% * 100;
 Minibatch[ 201- 300]: loss = 0.255839 * 100, metric = 4.51% * 100;
 Minibatch[ 301- 400]: loss = 0.248025 * 100, metric = 4.22% * 100;
 Minibatch[ 401- 500]: loss = 0.257827 * 100, metric = 4.45% * 100;
 Minibatch[ 501- 600]: loss = 0.251122 * 100, metric = 4.41% * 100;
 Minibatch[ 601- 700]: loss = 0.256338 * 100, metric = 4.45% * 100;
 Minibatch[ 701- 800]: loss = 0.253025 * 100, metric = 4.42% * 100;
 Minibatch[ 801- 900]: loss = 0.251111 * 100, metric = 4.39% * 100;
 Minibatch[ 901-1000]: loss = 0.252989 * 100, metric = 4.40% * 100;
 Minibatch[1001-1100]: loss = 0.266784 * 100, metric = 4.64% * 100;
 Minibatch[1101-1200]: loss = 0.256151 * 100, metric = 4.46% * 100;
 Minibatch[1201-1300]: loss = 0.249633 * 100, metric = 4.28% * 100;
 Minibatch[1301-1400]: loss = 0.239205 * 100, metric = 3.97% * 100;
 Minibatch[1401-1500]: loss = 0.243245 * 100, metric = 4.19% * 100;
 Minibatch[1501-1600]: loss = 0.250946 * 100, metric = 4.54% * 100;
 Minibatch[1601-1700]: loss = 0.248505 * 100, metric = 4.29% * 100;
 Minibatch[1701-1800]: loss = 0.257430 * 100, metric = 4.46% * 100;
 Minibatch[1801-1900]: loss = 0.258993 * 100, metric = 4.62% * 100;
 Minibatch[1901-2000]: loss = 0.247330 * 100, metric = 4.28% * 100;
Finished Epoch[68 of 200]: [Training] loss = 0.252554 * 2000, metric = 4.39% * 2000 864.668s (  2.3 samples/s);
Finished Evaluation [68]: Minibatch[1-2000]: metric = 12.73% * 2000;
 Minibatch[   1- 100]: loss = 0.244784 * 100, metric = 4.36% * 100;
 Minibatch[ 101- 200]: loss = 0.254303 * 100, metric = 4.50% * 100;
 Minibatch[ 201- 300]: loss = 0.243419 * 100, metric = 4.16% * 100;
 Minibatch[ 301- 400]: loss = 0.256925 * 100, metric = 4.48% * 100;
 Minibatch[ 401- 500]: loss = 0.256277 * 100, metric = 4.50% * 100;
 Minibatch[ 501- 600]: loss = 0.255794 * 100, metric = 4.54% * 100;
 Minibatch[ 601- 700]: loss = 0.249845 * 100, metric = 4.12% * 100;
 Minibatch[ 701- 800]: loss = 0.245002 * 100, metric = 4.22% * 100;
 Minibatch[ 801- 900]: loss = 0.239177 * 100, metric = 4.05% * 100;
 Minibatch[ 901-1000]: loss = 0.254468 * 100, metric = 4.36% * 100;
 Minibatch[1001-1100]: loss = 0.255354 * 100, metric = 4.44% * 100;
 Minibatch[1101-1200]: loss = 0.248535 * 100, metric = 4.00% * 100;
 Minibatch[1201-1300]: loss = 0.261122 * 100, metric = 4.53% * 100;
 Minibatch[1301-1400]: loss = 0.249927 * 100, metric = 4.28% * 100;
 Minibatch[1401-1500]: loss = 0.249343 * 100, metric = 4.35% * 100;
 Minibatch[1501-1600]: loss = 0.250508 * 100, metric = 4.29% * 100;
 Minibatch[1601-1700]: loss = 0.255041 * 100, metric = 4.55% * 100;
 Minibatch[1701-1800]: loss = 0.250133 * 100, metric = 4.37% * 100;
 Minibatch[1801-1900]: loss = 0.247131 * 100, metric = 4.15% * 100;
 Minibatch[1901-2000]: loss = 0.246546 * 100, metric = 4.26% * 100;
Finished Epoch[69 of 200]: [Training] loss = 0.250682 * 2000, metric = 4.33% * 2000 854.009s (  2.3 samples/s);
Finished Evaluation [69]: Minibatch[1-2000]: metric = 13.33% * 2000;
 Minibatch[   1- 100]: loss = 0.240453 * 100, metric = 4.18% * 100;
 Minibatch[ 101- 200]: loss = 0.236070 * 100, metric = 4.16% * 100;
 Minibatch[ 201- 300]: loss = 0.247264 * 100, metric = 4.13% * 100;
 Minibatch[ 301- 400]: loss = 0.244985 * 100, metric = 4.23% * 100;
 Minibatch[ 401- 500]: loss = 0.249485 * 100, metric = 4.24% * 100;
 Minibatch[ 501- 600]: loss = 0.259344 * 100, metric = 4.64% * 100;
 Minibatch[ 601- 700]: loss = 0.244376 * 100, metric = 4.13% * 100;
 Minibatch[ 701- 800]: loss = 0.246967 * 100, metric = 4.32% * 100;
 Minibatch[ 801- 900]: loss = 0.240263 * 100, metric = 4.09% * 100;
 Minibatch[ 901-1000]: loss = 0.249712 * 100, metric = 4.46% * 100;
 Minibatch[1001-1100]: loss = 0.237337 * 100, metric = 4.21% * 100;
 Minibatch[1101-1200]: loss = 0.242327 * 100, metric = 4.16% * 100;
 Minibatch[1201-1300]: loss = 0.249479 * 100, metric = 4.30% * 100;
 Minibatch[1301-1400]: loss = 0.254586 * 100, metric = 4.58% * 100;
 Minibatch[1401-1500]: loss = 0.240275 * 100, metric = 3.88% * 100;
 Minibatch[1501-1600]: loss = 0.249063 * 100, metric = 4.30% * 100;
 Minibatch[1601-1700]: loss = 0.249785 * 100, metric = 4.45% * 100;
 Minibatch[1701-1800]: loss = 0.261652 * 100, metric = 4.53% * 100;
 Minibatch[1801-1900]: loss = 0.243662 * 100, metric = 4.12% * 100;
 Minibatch[1901-2000]: loss = 0.251847 * 100, metric = 4.40% * 100;
Finished Epoch[70 of 200]: [Training] loss = 0.246947 * 2000, metric = 4.28% * 2000 860.603s (  2.3 samples/s);
Finished Evaluation [70]: Minibatch[1-2000]: metric = 13.00% * 2000;
 Minibatch[   1- 100]: loss = 0.258372 * 100, metric = 4.44% * 100;
 Minibatch[ 101- 200]: loss = 0.241609 * 100, metric = 4.09% * 100;
 Minibatch[ 201- 300]: loss = 0.252955 * 100, metric = 4.30% * 100;
 Minibatch[ 301- 400]: loss = 0.248846 * 100, metric = 4.16% * 100;
 Minibatch[ 401- 500]: loss = 0.254324 * 100, metric = 4.50% * 100;
 Minibatch[ 501- 600]: loss = 0.254438 * 100, metric = 4.44% * 100;
 Minibatch[ 601- 700]: loss = 0.237468 * 100, metric = 4.14% * 100;
 Minibatch[ 701- 800]: loss = 0.242781 * 100, metric = 4.26% * 100;
 Minibatch[ 801- 900]: loss = 0.249009 * 100, metric = 4.31% * 100;
 Minibatch[ 901-1000]: loss = 0.247561 * 100, metric = 4.23% * 100;
 Minibatch[1001-1100]: loss = 0.250605 * 100, metric = 4.47% * 100;
 Minibatch[1101-1200]: loss = 0.236463 * 100, metric = 3.99% * 100;
 Minibatch[1201-1300]: loss = 0.243510 * 100, metric = 4.17% * 100;
 Minibatch[1301-1400]: loss = 0.238096 * 100, metric = 4.21% * 100;
 Minibatch[1401-1500]: loss = 0.245891 * 100, metric = 4.29% * 100;
 Minibatch[1501-1600]: loss = 0.253818 * 100, metric = 4.46% * 100;
 Minibatch[1601-1700]: loss = 0.244764 * 100, metric = 4.25% * 100;
 Minibatch[1701-1800]: loss = 0.247762 * 100, metric = 4.25% * 100;
 Minibatch[1801-1900]: loss = 0.245956 * 100, metric = 4.26% * 100;
 Minibatch[1901-2000]: loss = 0.251494 * 100, metric = 4.38% * 100;
Finished Epoch[71 of 200]: [Training] loss = 0.247286 * 2000, metric = 4.28% * 2000 851.475s (  2.3 samples/s);
Finished Evaluation [71]: Minibatch[1-2000]: metric = 12.74% * 2000;
 Minibatch[   1- 100]: loss = 0.252294 * 100, metric = 4.32% * 100;
 Minibatch[ 101- 200]: loss = 0.245593 * 100, metric = 4.31% * 100;
 Minibatch[ 201- 300]: loss = 0.245345 * 100, metric = 4.28% * 100;
 Minibatch[ 301- 400]: loss = 0.240727 * 100, metric = 4.16% * 100;
 Minibatch[ 401- 500]: loss = 0.244174 * 100, metric = 4.27% * 100;
 Minibatch[ 501- 600]: loss = 0.241171 * 100, metric = 4.14% * 100;
 Minibatch[ 601- 700]: loss = 0.239843 * 100, metric = 4.17% * 100;
 Minibatch[ 701- 800]: loss = 0.245534 * 100, metric = 4.33% * 100;
 Minibatch[ 801- 900]: loss = 0.237161 * 100, metric = 4.01% * 100;
 Minibatch[ 901-1000]: loss = 0.239914 * 100, metric = 4.28% * 100;
 Minibatch[1001-1100]: loss = 0.245783 * 100, metric = 4.22% * 100;
 Minibatch[1101-1200]: loss = 0.234162 * 100, metric = 4.07% * 100;
 Minibatch[1201-1300]: loss = 0.236410 * 100, metric = 4.04% * 100;
 Minibatch[1301-1400]: loss = 0.247957 * 100, metric = 4.19% * 100;
 Minibatch[1401-1500]: loss = 0.242733 * 100, metric = 4.04% * 100;
 Minibatch[1501-1600]: loss = 0.246450 * 100, metric = 4.10% * 100;
 Minibatch[1601-1700]: loss = 0.250105 * 100, metric = 4.29% * 100;
 Minibatch[1701-1800]: loss = 0.241431 * 100, metric = 4.06% * 100;
 Minibatch[1801-1900]: loss = 0.242359 * 100, metric = 4.03% * 100;
 Minibatch[1901-2000]: loss = 0.243652 * 100, metric = 4.19% * 100;
Finished Epoch[72 of 200]: [Training] loss = 0.243140 * 2000, metric = 4.18% * 2000 849.360s (  2.4 samples/s);
Finished Evaluation [72]: Minibatch[1-2000]: metric = 13.05% * 2000;
 Minibatch[   1- 100]: loss = 0.235738 * 100, metric = 4.12% * 100;
 Minibatch[ 101- 200]: loss = 0.234296 * 100, metric = 4.10% * 100;
 Minibatch[ 201- 300]: loss = 0.236250 * 100, metric = 3.99% * 100;
 Minibatch[ 301- 400]: loss = 0.239646 * 100, metric = 4.14% * 100;
 Minibatch[ 401- 500]: loss = 0.240026 * 100, metric = 4.19% * 100;
 Minibatch[ 501- 600]: loss = 0.238763 * 100, metric = 4.22% * 100;
 Minibatch[ 601- 700]: loss = 0.237104 * 100, metric = 4.03% * 100;
 Minibatch[ 701- 800]: loss = 0.231017 * 100, metric = 3.92% * 100;
 Minibatch[ 801- 900]: loss = 0.241304 * 100, metric = 4.22% * 100;
 Minibatch[ 901-1000]: loss = 0.241736 * 100, metric = 4.25% * 100;
 Minibatch[1001-1100]: loss = 0.233298 * 100, metric = 4.01% * 100;
 Minibatch[1101-1200]: loss = 0.231955 * 100, metric = 4.09% * 100;
 Minibatch[1201-1300]: loss = 0.247454 * 100, metric = 4.39% * 100;
 Minibatch[1301-1400]: loss = 0.238128 * 100, metric = 4.12% * 100;
 Minibatch[1401-1500]: loss = 0.236008 * 100, metric = 4.15% * 100;
 Minibatch[1501-1600]: loss = 0.240027 * 100, metric = 4.11% * 100;
 Minibatch[1601-1700]: loss = 0.239915 * 100, metric = 4.18% * 100;
 Minibatch[1701-1800]: loss = 0.237474 * 100, metric = 4.16% * 100;
 Minibatch[1801-1900]: loss = 0.232686 * 100, metric = 4.02% * 100;
 Minibatch[1901-2000]: loss = 0.250163 * 100, metric = 4.40% * 100;
Finished Epoch[73 of 200]: [Training] loss = 0.238149 * 2000, metric = 4.14% * 2000 851.668s (  2.3 samples/s);
Finished Evaluation [73]: Minibatch[1-2000]: metric = 12.37% * 2000;
 Minibatch[   1- 100]: loss = 0.231134 * 100, metric = 3.99% * 100;
 Minibatch[ 101- 200]: loss = 0.244024 * 100, metric = 4.26% * 100;
 Minibatch[ 201- 300]: loss = 0.235309 * 100, metric = 4.12% * 100;
 Minibatch[ 301- 400]: loss = 0.234445 * 100, metric = 4.07% * 100;
 Minibatch[ 401- 500]: loss = 0.239396 * 100, metric = 4.14% * 100;
 Minibatch[ 501- 600]: loss = 0.242447 * 100, metric = 4.09% * 100;
 Minibatch[ 601- 700]: loss = 0.236975 * 100, metric = 3.97% * 100;
 Minibatch[ 701- 800]: loss = 0.236809 * 100, metric = 4.15% * 100;
 Minibatch[ 801- 900]: loss = 0.244089 * 100, metric = 4.24% * 100;
 Minibatch[ 901-1000]: loss = 0.248553 * 100, metric = 4.26% * 100;
 Minibatch[1001-1100]: loss = 0.246471 * 100, metric = 4.34% * 100;
 Minibatch[1101-1200]: loss = 0.259544 * 100, metric = 4.64% * 100;
 Minibatch[1201-1300]: loss = 0.233328 * 100, metric = 3.87% * 100;
 Minibatch[1301-1400]: loss = 0.234513 * 100, metric = 4.02% * 100;
 Minibatch[1401-1500]: loss = 0.238904 * 100, metric = 4.03% * 100;
 Minibatch[1501-1600]: loss = 0.248804 * 100, metric = 4.39% * 100;
 Minibatch[1601-1700]: loss = 0.232566 * 100, metric = 4.00% * 100;
 Minibatch[1701-1800]: loss = 0.241897 * 100, metric = 4.05% * 100;
 Minibatch[1801-1900]: loss = 0.230554 * 100, metric = 3.91% * 100;
 Minibatch[1901-2000]: loss = 0.247859 * 100, metric = 4.36% * 100;
Finished Epoch[74 of 200]: [Training] loss = 0.240381 * 2000, metric = 4.15% * 2000 847.285s (  2.4 samples/s);
Finished Evaluation [74]: Minibatch[1-2000]: metric = 13.27% * 2000;
 Minibatch[   1- 100]: loss = 0.244395 * 100, metric = 4.25% * 100;
 Minibatch[ 101- 200]: loss = 0.246378 * 100, metric = 4.30% * 100;
 Minibatch[ 201- 300]: loss = 0.238065 * 100, metric = 3.94% * 100;
 Minibatch[ 301- 400]: loss = 0.238509 * 100, metric = 4.06% * 100;
 Minibatch[ 401- 500]: loss = 0.242608 * 100, metric = 4.05% * 100;
 Minibatch[ 501- 600]: loss = 0.242656 * 100, metric = 4.20% * 100;
 Minibatch[ 601- 700]: loss = 0.251241 * 100, metric = 4.38% * 100;
 Minibatch[ 701- 800]: loss = 0.245533 * 100, metric = 4.32% * 100;
 Minibatch[ 801- 900]: loss = 0.238281 * 100, metric = 4.14% * 100;
 Minibatch[ 901-1000]: loss = 0.234027 * 100, metric = 3.79% * 100;
 Minibatch[1001-1100]: loss = 0.234215 * 100, metric = 3.86% * 100;
 Minibatch[1101-1200]: loss = 0.230547 * 100, metric = 4.00% * 100;
 Minibatch[1201-1300]: loss = 0.239153 * 100, metric = 4.14% * 100;
 Minibatch[1301-1400]: loss = 0.223835 * 100, metric = 3.85% * 100;
 Minibatch[1401-1500]: loss = 0.233445 * 100, metric = 3.94% * 100;
 Minibatch[1501-1600]: loss = 0.241610 * 100, metric = 4.31% * 100;
 Minibatch[1601-1700]: loss = 0.235583 * 100, metric = 4.19% * 100;
 Minibatch[1701-1800]: loss = 0.232268 * 100, metric = 3.98% * 100;
 Minibatch[1801-1900]: loss = 0.231019 * 100, metric = 3.99% * 100;
 Minibatch[1901-2000]: loss = 0.237548 * 100, metric = 4.01% * 100;
Finished Epoch[75 of 200]: [Training] loss = 0.238046 * 2000, metric = 4.09% * 2000 846.674s (  2.4 samples/s);
Finished Evaluation [75]: Minibatch[1-2000]: metric = 13.00% * 2000;
 Minibatch[   1- 100]: loss = 0.234204 * 100, metric = 3.87% * 100;
 Minibatch[ 101- 200]: loss = 0.242729 * 100, metric = 4.07% * 100;
 Minibatch[ 201- 300]: loss = 0.253291 * 100, metric = 4.25% * 100;
 Minibatch[ 301- 400]: loss = 0.240824 * 100, metric = 4.24% * 100;
 Minibatch[ 401- 500]: loss = 0.235212 * 100, metric = 3.97% * 100;
 Minibatch[ 501- 600]: loss = 0.223657 * 100, metric = 3.64% * 100;
 Minibatch[ 601- 700]: loss = 0.234270 * 100, metric = 4.10% * 100;
 Minibatch[ 701- 800]: loss = 0.229890 * 100, metric = 3.82% * 100;
 Minibatch[ 801- 900]: loss = 0.234738 * 100, metric = 4.18% * 100;
 Minibatch[ 901-1000]: loss = 0.235722 * 100, metric = 4.06% * 100;
 Minibatch[1001-1100]: loss = 0.237981 * 100, metric = 4.09% * 100;
 Minibatch[1101-1200]: loss = 0.234430 * 100, metric = 3.99% * 100;
 Minibatch[1201-1300]: loss = 0.231626 * 100, metric = 3.97% * 100;
 Minibatch[1301-1400]: loss = 0.242615 * 100, metric = 4.27% * 100;
 Minibatch[1401-1500]: loss = 0.241822 * 100, metric = 4.16% * 100;
 Minibatch[1501-1600]: loss = 0.231615 * 100, metric = 3.88% * 100;
 Minibatch[1601-1700]: loss = 0.231158 * 100, metric = 4.12% * 100;
 Minibatch[1701-1800]: loss = 0.224284 * 100, metric = 3.78% * 100;
 Minibatch[1801-1900]: loss = 0.241009 * 100, metric = 4.34% * 100;
 Minibatch[1901-2000]: loss = 0.230806 * 100, metric = 4.05% * 100;
Finished Epoch[76 of 200]: [Training] loss = 0.235594 * 2000, metric = 4.04% * 2000 852.297s (  2.3 samples/s);
Finished Evaluation [76]: Minibatch[1-2000]: metric = 12.40% * 2000;
 Minibatch[   1- 100]: loss = 0.242156 * 100, metric = 4.21% * 100;
 Minibatch[ 101- 200]: loss = 0.241131 * 100, metric = 4.21% * 100;
 Minibatch[ 201- 300]: loss = 0.227105 * 100, metric = 3.79% * 100;
 Minibatch[ 301- 400]: loss = 0.247005 * 100, metric = 4.23% * 100;
 Minibatch[ 401- 500]: loss = 0.234269 * 100, metric = 4.06% * 100;
 Minibatch[ 501- 600]: loss = 0.217562 * 100, metric = 3.69% * 100;
 Minibatch[ 601- 700]: loss = 0.239009 * 100, metric = 4.12% * 100;
 Minibatch[ 701- 800]: loss = 0.232618 * 100, metric = 3.90% * 100;
 Minibatch[ 801- 900]: loss = 0.229811 * 100, metric = 3.96% * 100;
 Minibatch[ 901-1000]: loss = 0.225995 * 100, metric = 3.77% * 100;
 Minibatch[1001-1100]: loss = 0.231354 * 100, metric = 3.99% * 100;
 Minibatch[1101-1200]: loss = 0.239023 * 100, metric = 4.08% * 100;
 Minibatch[1201-1300]: loss = 0.240112 * 100, metric = 4.16% * 100;
 Minibatch[1301-1400]: loss = 0.228852 * 100, metric = 4.03% * 100;
 Minibatch[1401-1500]: loss = 0.240068 * 100, metric = 4.16% * 100;
 Minibatch[1501-1600]: loss = 0.232295 * 100, metric = 4.12% * 100;
 Minibatch[1601-1700]: loss = 0.226448 * 100, metric = 3.91% * 100;
 Minibatch[1701-1800]: loss = 0.227175 * 100, metric = 3.87% * 100;
 Minibatch[1801-1900]: loss = 0.234801 * 100, metric = 4.00% * 100;
 Minibatch[1901-2000]: loss = 0.230555 * 100, metric = 4.01% * 100;
Finished Epoch[77 of 200]: [Training] loss = 0.233367 * 2000, metric = 4.01% * 2000 850.124s (  2.4 samples/s);
Finished Evaluation [77]: Minibatch[1-2000]: metric = 12.34% * 2000;
 Minibatch[   1- 100]: loss = 0.232867 * 100, metric = 3.89% * 100;
 Minibatch[ 101- 200]: loss = 0.229525 * 100, metric = 3.93% * 100;
 Minibatch[ 201- 300]: loss = 0.218678 * 100, metric = 3.72% * 100;
 Minibatch[ 301- 400]: loss = 0.231503 * 100, metric = 3.89% * 100;
 Minibatch[ 401- 500]: loss = 0.239440 * 100, metric = 4.13% * 100;
 Minibatch[ 501- 600]: loss = 0.241591 * 100, metric = 4.29% * 100;
 Minibatch[ 601- 700]: loss = 0.230455 * 100, metric = 4.10% * 100;
 Minibatch[ 701- 800]: loss = 0.225465 * 100, metric = 3.71% * 100;
 Minibatch[ 801- 900]: loss = 0.225458 * 100, metric = 3.73% * 100;
 Minibatch[ 901-1000]: loss = 0.243338 * 100, metric = 4.21% * 100;
 Minibatch[1001-1100]: loss = 0.241827 * 100, metric = 4.21% * 100;
 Minibatch[1101-1200]: loss = 0.231453 * 100, metric = 4.00% * 100;
 Minibatch[1201-1300]: loss = 0.240732 * 100, metric = 4.25% * 100;
 Minibatch[1301-1400]: loss = 0.226061 * 100, metric = 3.87% * 100;
 Minibatch[1401-1500]: loss = 0.233355 * 100, metric = 4.02% * 100;
 Minibatch[1501-1600]: loss = 0.230246 * 100, metric = 4.16% * 100;
 Minibatch[1601-1700]: loss = 0.227444 * 100, metric = 3.93% * 100;
 Minibatch[1701-1800]: loss = 0.230998 * 100, metric = 4.01% * 100;
 Minibatch[1801-1900]: loss = 0.238245 * 100, metric = 4.29% * 100;
 Minibatch[1901-2000]: loss = 0.238583 * 100, metric = 4.37% * 100;
Finished Epoch[78 of 200]: [Training] loss = 0.232863 * 2000, metric = 4.04% * 2000 850.288s (  2.4 samples/s);
Finished Evaluation [78]: Minibatch[1-2000]: metric = 12.94% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
