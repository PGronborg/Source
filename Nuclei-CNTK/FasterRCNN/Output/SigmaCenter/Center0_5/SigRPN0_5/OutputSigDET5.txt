Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.287554 * 100, metric = 23.87% * 100;
 Minibatch[ 101- 200]: loss = 1.122486 * 100, metric = 23.14% * 100;
 Minibatch[ 201- 300]: loss = 1.042080 * 100, metric = 22.17% * 100;
 Minibatch[ 301- 400]: loss = 1.031967 * 100, metric = 20.64% * 100;
 Minibatch[ 401- 500]: loss = 0.969863 * 100, metric = 18.97% * 100;
 Minibatch[ 501- 600]: loss = 0.950075 * 100, metric = 18.16% * 100;
 Minibatch[ 601- 700]: loss = 0.939646 * 100, metric = 18.22% * 100;
 Minibatch[ 701- 800]: loss = 0.891444 * 100, metric = 16.78% * 100;
 Minibatch[ 801- 900]: loss = 0.921821 * 100, metric = 17.59% * 100;
 Minibatch[ 901-1000]: loss = 0.925680 * 100, metric = 18.00% * 100;
 Minibatch[1001-1100]: loss = 0.915485 * 100, metric = 17.55% * 100;
 Minibatch[1101-1200]: loss = 0.898627 * 100, metric = 16.95% * 100;
 Minibatch[1201-1300]: loss = 0.892126 * 100, metric = 17.35% * 100;
 Minibatch[1301-1400]: loss = 0.861147 * 100, metric = 16.39% * 100;
 Minibatch[1401-1500]: loss = 0.876992 * 100, metric = 16.80% * 100;
 Minibatch[1501-1600]: loss = 0.854546 * 100, metric = 16.19% * 100;
 Minibatch[1601-1700]: loss = 0.838022 * 100, metric = 15.74% * 100;
 Minibatch[1701-1800]: loss = 0.855387 * 100, metric = 16.19% * 100;
 Minibatch[1801-1900]: loss = 0.850707 * 100, metric = 16.09% * 100;
 Minibatch[1901-2000]: loss = 0.828901 * 100, metric = 15.61% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.937728 * 2000, metric = 18.12% * 2000 1019.819s (  2.0 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 20.76% * 2000;
0.76248850158602
 Minibatch[   1- 100]: loss = 0.818305 * 100, metric = 15.48% * 100;
 Minibatch[ 101- 200]: loss = 0.824597 * 100, metric = 15.60% * 100;
 Minibatch[ 201- 300]: loss = 0.816497 * 100, metric = 15.06% * 100;
 Minibatch[ 301- 400]: loss = 0.829683 * 100, metric = 15.35% * 100;
 Minibatch[ 401- 500]: loss = 0.816040 * 100, metric = 14.92% * 100;
 Minibatch[ 501- 600]: loss = 0.830843 * 100, metric = 14.97% * 100;
 Minibatch[ 601- 700]: loss = 0.789066 * 100, metric = 14.56% * 100;
 Minibatch[ 701- 800]: loss = 0.804946 * 100, metric = 15.12% * 100;
 Minibatch[ 801- 900]: loss = 0.790386 * 100, metric = 14.49% * 100;
 Minibatch[ 901-1000]: loss = 0.763727 * 100, metric = 13.68% * 100;
 Minibatch[1001-1100]: loss = 0.797624 * 100, metric = 14.75% * 100;
 Minibatch[1101-1200]: loss = 0.782797 * 100, metric = 14.23% * 100;
 Minibatch[1201-1300]: loss = 0.778298 * 100, metric = 14.07% * 100;
 Minibatch[1301-1400]: loss = 0.789672 * 100, metric = 14.46% * 100;
 Minibatch[1401-1500]: loss = 0.771246 * 100, metric = 13.68% * 100;
 Minibatch[1501-1600]: loss = 0.768884 * 100, metric = 13.92% * 100;
 Minibatch[1601-1700]: loss = 0.759857 * 100, metric = 13.83% * 100;
 Minibatch[1701-1800]: loss = 0.780695 * 100, metric = 14.52% * 100;
 Minibatch[1801-1900]: loss = 0.783302 * 100, metric = 14.31% * 100;
 Minibatch[1901-2000]: loss = 0.749679 * 100, metric = 13.77% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.792307 * 2000, metric = 14.54% * 2000 950.732s (  2.1 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 19.87% * 2000;
0.7554059263989329
 Minibatch[   1- 100]: loss = 0.776634 * 100, metric = 14.18% * 100;
 Minibatch[ 101- 200]: loss = 0.779111 * 100, metric = 14.25% * 100;
 Minibatch[ 201- 300]: loss = 0.768886 * 100, metric = 13.99% * 100;
 Minibatch[ 301- 400]: loss = 0.793264 * 100, metric = 14.46% * 100;
 Minibatch[ 401- 500]: loss = 0.794671 * 100, metric = 14.78% * 100;
 Minibatch[ 501- 600]: loss = 0.784576 * 100, metric = 14.06% * 100;
 Minibatch[ 601- 700]: loss = 0.791459 * 100, metric = 14.31% * 100;
 Minibatch[ 701- 800]: loss = 0.758811 * 100, metric = 13.17% * 100;
 Minibatch[ 801- 900]: loss = 0.777527 * 100, metric = 14.13% * 100;
 Minibatch[ 901-1000]: loss = 0.746976 * 100, metric = 13.70% * 100;
 Minibatch[1001-1100]: loss = 0.771721 * 100, metric = 14.00% * 100;
 Minibatch[1101-1200]: loss = 0.755629 * 100, metric = 13.50% * 100;
 Minibatch[1201-1300]: loss = 0.744825 * 100, metric = 13.30% * 100;
 Minibatch[1301-1400]: loss = 0.776085 * 100, metric = 13.86% * 100;
 Minibatch[1401-1500]: loss = 0.777859 * 100, metric = 14.13% * 100;
 Minibatch[1501-1600]: loss = 0.746672 * 100, metric = 13.34% * 100;
 Minibatch[1601-1700]: loss = 0.748198 * 100, metric = 13.32% * 100;
 Minibatch[1701-1800]: loss = 0.764548 * 100, metric = 13.57% * 100;
 Minibatch[1801-1900]: loss = 0.752529 * 100, metric = 13.28% * 100;
 Minibatch[1901-2000]: loss = 0.757020 * 100, metric = 13.79% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.768350 * 2000, metric = 13.86% * 2000 990.500s (  2.0 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 18.39% * 2000;
0.7429225492179394
 Minibatch[   1- 100]: loss = 0.766636 * 100, metric = 13.02% * 100;
 Minibatch[ 101- 200]: loss = 0.739640 * 100, metric = 13.30% * 100;
 Minibatch[ 201- 300]: loss = 0.758706 * 100, metric = 13.81% * 100;
 Minibatch[ 301- 400]: loss = 0.723757 * 100, metric = 12.67% * 100;
 Minibatch[ 401- 500]: loss = 0.758548 * 100, metric = 13.51% * 100;
 Minibatch[ 501- 600]: loss = 0.735258 * 100, metric = 12.67% * 100;
 Minibatch[ 601- 700]: loss = 0.754962 * 100, metric = 13.74% * 100;
 Minibatch[ 701- 800]: loss = 0.763474 * 100, metric = 13.71% * 100;
 Minibatch[ 801- 900]: loss = 0.758248 * 100, metric = 13.63% * 100;
 Minibatch[ 901-1000]: loss = 0.761982 * 100, metric = 13.85% * 100;
 Minibatch[1001-1100]: loss = 0.760527 * 100, metric = 13.92% * 100;
 Minibatch[1101-1200]: loss = 0.736328 * 100, metric = 13.01% * 100;
 Minibatch[1201-1300]: loss = 0.735878 * 100, metric = 13.03% * 100;
 Minibatch[1301-1400]: loss = 0.770602 * 100, metric = 13.58% * 100;
 Minibatch[1401-1500]: loss = 0.778459 * 100, metric = 13.91% * 100;
 Minibatch[1501-1600]: loss = 0.735385 * 100, metric = 13.04% * 100;
 Minibatch[1601-1700]: loss = 0.762391 * 100, metric = 13.53% * 100;
 Minibatch[1701-1800]: loss = 0.765656 * 100, metric = 14.03% * 100;
 Minibatch[1801-1900]: loss = 0.743953 * 100, metric = 12.87% * 100;
 Minibatch[1901-2000]: loss = 0.743068 * 100, metric = 13.06% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.752673 * 2000, metric = 13.39% * 2000 965.056s (  2.1 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 19.87% * 2000;
 Minibatch[   1- 100]: loss = 0.771535 * 100, metric = 13.87% * 100;
 Minibatch[ 101- 200]: loss = 0.738561 * 100, metric = 13.19% * 100;
 Minibatch[ 201- 300]: loss = 0.725540 * 100, metric = 12.73% * 100;
 Minibatch[ 301- 400]: loss = 0.773074 * 100, metric = 13.81% * 100;
 Minibatch[ 401- 500]: loss = 0.725807 * 100, metric = 12.61% * 100;
 Minibatch[ 501- 600]: loss = 0.737251 * 100, metric = 12.78% * 100;
 Minibatch[ 601- 700]: loss = 0.741049 * 100, metric = 12.71% * 100;
 Minibatch[ 701- 800]: loss = 0.754045 * 100, metric = 13.21% * 100;
 Minibatch[ 801- 900]: loss = 0.731768 * 100, metric = 12.62% * 100;
 Minibatch[ 901-1000]: loss = 0.730416 * 100, metric = 12.98% * 100;
 Minibatch[1001-1100]: loss = 0.743921 * 100, metric = 12.97% * 100;
 Minibatch[1101-1200]: loss = 0.728353 * 100, metric = 12.81% * 100;
 Minibatch[1201-1300]: loss = 0.739401 * 100, metric = 13.23% * 100;
 Minibatch[1301-1400]: loss = 0.760096 * 100, metric = 13.45% * 100;
 Minibatch[1401-1500]: loss = 0.735294 * 100, metric = 13.19% * 100;
 Minibatch[1501-1600]: loss = 0.739194 * 100, metric = 13.06% * 100;
 Minibatch[1601-1700]: loss = 0.760862 * 100, metric = 13.79% * 100;
 Minibatch[1701-1800]: loss = 0.762260 * 100, metric = 13.53% * 100;
 Minibatch[1801-1900]: loss = 0.757909 * 100, metric = 13.46% * 100;
 Minibatch[1901-2000]: loss = 0.733024 * 100, metric = 12.83% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.744468 * 2000, metric = 13.14% * 2000 964.405s (  2.1 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.04% * 2000;
 Minibatch[   1- 100]: loss = 0.729370 * 100, metric = 12.91% * 100;
 Minibatch[ 101- 200]: loss = 0.726332 * 100, metric = 12.90% * 100;
 Minibatch[ 201- 300]: loss = 0.735791 * 100, metric = 12.91% * 100;
 Minibatch[ 301- 400]: loss = 0.737950 * 100, metric = 12.86% * 100;
 Minibatch[ 401- 500]: loss = 0.711896 * 100, metric = 12.54% * 100;
 Minibatch[ 501- 600]: loss = 0.731379 * 100, metric = 12.96% * 100;
 Minibatch[ 601- 700]: loss = 0.722371 * 100, metric = 12.82% * 100;
 Minibatch[ 701- 800]: loss = 0.740204 * 100, metric = 13.09% * 100;
 Minibatch[ 801- 900]: loss = 0.734263 * 100, metric = 12.88% * 100;
 Minibatch[ 901-1000]: loss = 0.714761 * 100, metric = 12.65% * 100;
 Minibatch[1001-1100]: loss = 0.727284 * 100, metric = 12.42% * 100;
 Minibatch[1101-1200]: loss = 0.742772 * 100, metric = 12.98% * 100;
 Minibatch[1201-1300]: loss = 0.754536 * 100, metric = 13.22% * 100;
 Minibatch[1301-1400]: loss = 0.725814 * 100, metric = 12.86% * 100;
 Minibatch[1401-1500]: loss = 0.727614 * 100, metric = 12.74% * 100;
 Minibatch[1501-1600]: loss = 0.720144 * 100, metric = 12.41% * 100;
 Minibatch[1601-1700]: loss = 0.715786 * 100, metric = 12.23% * 100;
 Minibatch[1701-1800]: loss = 0.706958 * 100, metric = 12.44% * 100;
 Minibatch[1801-1900]: loss = 0.729921 * 100, metric = 12.81% * 100;
 Minibatch[1901-2000]: loss = 0.712178 * 100, metric = 12.40% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.727366 * 2000, metric = 12.75% * 2000 1001.399s (  2.0 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.15% * 2000;
 Minibatch[   1- 100]: loss = 0.711981 * 100, metric = 12.42% * 100;
 Minibatch[ 101- 200]: loss = 0.730021 * 100, metric = 12.62% * 100;
 Minibatch[ 201- 300]: loss = 0.730996 * 100, metric = 12.83% * 100;
 Minibatch[ 301- 400]: loss = 0.706775 * 100, metric = 11.95% * 100;
 Minibatch[ 401- 500]: loss = 0.733882 * 100, metric = 12.75% * 100;
 Minibatch[ 501- 600]: loss = 0.701106 * 100, metric = 12.06% * 100;
 Minibatch[ 601- 700]: loss = 0.723772 * 100, metric = 12.16% * 100;
 Minibatch[ 701- 800]: loss = 0.730150 * 100, metric = 12.44% * 100;
 Minibatch[ 801- 900]: loss = 0.735124 * 100, metric = 12.75% * 100;
 Minibatch[ 901-1000]: loss = 0.718611 * 100, metric = 12.46% * 100;
 Minibatch[1001-1100]: loss = 0.721469 * 100, metric = 12.66% * 100;
 Minibatch[1101-1200]: loss = 0.706823 * 100, metric = 12.02% * 100;
 Minibatch[1201-1300]: loss = 0.729946 * 100, metric = 12.95% * 100;
 Minibatch[1301-1400]: loss = 0.714849 * 100, metric = 12.31% * 100;
 Minibatch[1401-1500]: loss = 0.701489 * 100, metric = 12.07% * 100;
 Minibatch[1501-1600]: loss = 0.716432 * 100, metric = 12.52% * 100;
 Minibatch[1601-1700]: loss = 0.715454 * 100, metric = 12.37% * 100;
 Minibatch[1701-1800]: loss = 0.708738 * 100, metric = 12.18% * 100;
 Minibatch[1801-1900]: loss = 0.709919 * 100, metric = 12.31% * 100;
 Minibatch[1901-2000]: loss = 0.720099 * 100, metric = 12.83% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.718382 * 2000, metric = 12.43% * 2000 986.816s (  2.0 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.47% * 2000;
0.7415122464075684
 Minibatch[   1- 100]: loss = 0.713093 * 100, metric = 12.37% * 100;
 Minibatch[ 101- 200]: loss = 0.702157 * 100, metric = 11.86% * 100;
 Minibatch[ 201- 300]: loss = 0.692178 * 100, metric = 11.80% * 100;
 Minibatch[ 301- 400]: loss = 0.696041 * 100, metric = 12.17% * 100;
 Minibatch[ 401- 500]: loss = 0.707133 * 100, metric = 12.43% * 100;
 Minibatch[ 501- 600]: loss = 0.720540 * 100, metric = 12.53% * 100;
 Minibatch[ 601- 700]: loss = 0.683753 * 100, metric = 11.69% * 100;
 Minibatch[ 701- 800]: loss = 0.705078 * 100, metric = 11.95% * 100;
 Minibatch[ 801- 900]: loss = 0.674987 * 100, metric = 10.94% * 100;
 Minibatch[ 901-1000]: loss = 0.673865 * 100, metric = 11.33% * 100;
 Minibatch[1001-1100]: loss = 0.681812 * 100, metric = 11.50% * 100;
 Minibatch[1101-1200]: loss = 0.686358 * 100, metric = 11.53% * 100;
 Minibatch[1201-1300]: loss = 0.699175 * 100, metric = 12.14% * 100;
 Minibatch[1301-1400]: loss = 0.714354 * 100, metric = 12.35% * 100;
 Minibatch[1401-1500]: loss = 0.697153 * 100, metric = 11.81% * 100;
 Minibatch[1501-1600]: loss = 0.703695 * 100, metric = 12.19% * 100;
 Minibatch[1601-1700]: loss = 0.692076 * 100, metric = 11.72% * 100;
 Minibatch[1701-1800]: loss = 0.687150 * 100, metric = 11.52% * 100;
 Minibatch[1801-1900]: loss = 0.704784 * 100, metric = 12.11% * 100;
 Minibatch[1901-2000]: loss = 0.697516 * 100, metric = 11.58% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.696645 * 2000, metric = 11.88% * 2000 1006.747s (  2.0 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 17.84% * 2000;
0.7133541376814246
 Minibatch[   1- 100]: loss = 0.670178 * 100, metric = 11.33% * 100;
 Minibatch[ 101- 200]: loss = 0.705665 * 100, metric = 12.34% * 100;
 Minibatch[ 201- 300]: loss = 0.705202 * 100, metric = 12.06% * 100;
 Minibatch[ 301- 400]: loss = 0.713950 * 100, metric = 12.35% * 100;
 Minibatch[ 401- 500]: loss = 0.691006 * 100, metric = 11.53% * 100;
 Minibatch[ 501- 600]: loss = 0.680874 * 100, metric = 11.54% * 100;
 Minibatch[ 601- 700]: loss = 0.688879 * 100, metric = 11.84% * 100;
 Minibatch[ 701- 800]: loss = 0.668647 * 100, metric = 11.21% * 100;
 Minibatch[ 801- 900]: loss = 0.667131 * 100, metric = 11.21% * 100;
 Minibatch[ 901-1000]: loss = 0.694750 * 100, metric = 12.07% * 100;
 Minibatch[1001-1100]: loss = 0.669258 * 100, metric = 11.26% * 100;
 Minibatch[1101-1200]: loss = 0.690412 * 100, metric = 11.97% * 100;
 Minibatch[1201-1300]: loss = 0.680231 * 100, metric = 11.46% * 100;
 Minibatch[1301-1400]: loss = 0.676952 * 100, metric = 11.22% * 100;
 Minibatch[1401-1500]: loss = 0.683631 * 100, metric = 11.66% * 100;
 Minibatch[1501-1600]: loss = 0.679149 * 100, metric = 11.25% * 100;
 Minibatch[1601-1700]: loss = 0.688678 * 100, metric = 11.74% * 100;
 Minibatch[1701-1800]: loss = 0.670710 * 100, metric = 11.01% * 100;
 Minibatch[1801-1900]: loss = 0.669309 * 100, metric = 11.22% * 100;
 Minibatch[1901-2000]: loss = 0.680411 * 100, metric = 11.61% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.683751 * 2000, metric = 11.59% * 2000 1003.011s (  2.0 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 16.88% * 2000;
0.7054328055158258
 Minibatch[   1- 100]: loss = 0.699469 * 100, metric = 12.43% * 100;
 Minibatch[ 101- 200]: loss = 0.660003 * 100, metric = 11.29% * 100;
 Minibatch[ 201- 300]: loss = 0.680737 * 100, metric = 11.57% * 100;
 Minibatch[ 301- 400]: loss = 0.669535 * 100, metric = 11.38% * 100;
 Minibatch[ 401- 500]: loss = 0.679215 * 100, metric = 11.76% * 100;
 Minibatch[ 501- 600]: loss = 0.660116 * 100, metric = 11.06% * 100;
 Minibatch[ 601- 700]: loss = 0.653960 * 100, metric = 10.73% * 100;
 Minibatch[ 701- 800]: loss = 0.655797 * 100, metric = 10.82% * 100;
 Minibatch[ 801- 900]: loss = 0.677142 * 100, metric = 11.43% * 100;
 Minibatch[ 901-1000]: loss = 0.679459 * 100, metric = 11.14% * 100;
 Minibatch[1001-1100]: loss = 0.668652 * 100, metric = 11.38% * 100;
 Minibatch[1101-1200]: loss = 0.677687 * 100, metric = 11.24% * 100;
 Minibatch[1201-1300]: loss = 0.668519 * 100, metric = 11.39% * 100;
 Minibatch[1301-1400]: loss = 0.669390 * 100, metric = 11.25% * 100;
 Minibatch[1401-1500]: loss = 0.649262 * 100, metric = 10.67% * 100;
 Minibatch[1501-1600]: loss = 0.667034 * 100, metric = 11.32% * 100;
 Minibatch[1601-1700]: loss = 0.665021 * 100, metric = 10.83% * 100;
 Minibatch[1701-1800]: loss = 0.671663 * 100, metric = 11.30% * 100;
 Minibatch[1801-1900]: loss = 0.679904 * 100, metric = 11.56% * 100;
 Minibatch[1901-2000]: loss = 0.647834 * 100, metric = 10.82% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.669020 * 2000, metric = 11.27% * 2000 1013.779s (  2.0 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 16.94% * 2000;
 Minibatch[   1- 100]: loss = 0.635358 * 100, metric = 10.42% * 100;
 Minibatch[ 101- 200]: loss = 0.660114 * 100, metric = 11.04% * 100;
 Minibatch[ 201- 300]: loss = 0.668869 * 100, metric = 11.51% * 100;
 Minibatch[ 301- 400]: loss = 0.667553 * 100, metric = 11.25% * 100;
 Minibatch[ 401- 500]: loss = 0.653252 * 100, metric = 11.01% * 100;
 Minibatch[ 501- 600]: loss = 0.661624 * 100, metric = 11.16% * 100;
 Minibatch[ 601- 700]: loss = 0.652669 * 100, metric = 10.94% * 100;
 Minibatch[ 701- 800]: loss = 0.662702 * 100, metric = 11.30% * 100;
 Minibatch[ 801- 900]: loss = 0.662481 * 100, metric = 11.11% * 100;
 Minibatch[ 901-1000]: loss = 0.665128 * 100, metric = 11.09% * 100;
 Minibatch[1001-1100]: loss = 0.652289 * 100, metric = 10.86% * 100;
 Minibatch[1101-1200]: loss = 0.660123 * 100, metric = 11.23% * 100;
 Minibatch[1201-1300]: loss = 0.642528 * 100, metric = 10.50% * 100;
 Minibatch[1301-1400]: loss = 0.639193 * 100, metric = 10.79% * 100;
 Minibatch[1401-1500]: loss = 0.660358 * 100, metric = 11.13% * 100;
 Minibatch[1501-1600]: loss = 0.643436 * 100, metric = 10.74% * 100;
 Minibatch[1601-1700]: loss = 0.657242 * 100, metric = 10.86% * 100;
 Minibatch[1701-1800]: loss = 0.673971 * 100, metric = 11.71% * 100;
 Minibatch[1801-1900]: loss = 0.655946 * 100, metric = 11.05% * 100;
 Minibatch[1901-2000]: loss = 0.653207 * 100, metric = 11.30% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.656402 * 2000, metric = 11.05% * 2000 1007.405s (  2.0 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 17.83% * 2000;
 Minibatch[   1- 100]: loss = 0.636567 * 100, metric = 10.56% * 100;
 Minibatch[ 101- 200]: loss = 0.655179 * 100, metric = 10.75% * 100;
 Minibatch[ 201- 300]: loss = 0.645069 * 100, metric = 10.93% * 100;
 Minibatch[ 301- 400]: loss = 0.683124 * 100, metric = 11.74% * 100;
 Minibatch[ 401- 500]: loss = 0.648767 * 100, metric = 10.84% * 100;
 Minibatch[ 501- 600]: loss = 0.631941 * 100, metric = 10.24% * 100;
 Minibatch[ 601- 700]: loss = 0.638815 * 100, metric = 10.57% * 100;
 Minibatch[ 701- 800]: loss = 0.649273 * 100, metric = 10.94% * 100;
 Minibatch[ 801- 900]: loss = 0.646628 * 100, metric = 10.73% * 100;
 Minibatch[ 901-1000]: loss = 0.654547 * 100, metric = 11.11% * 100;
 Minibatch[1001-1100]: loss = 0.652834 * 100, metric = 11.11% * 100;
 Minibatch[1101-1200]: loss = 0.652675 * 100, metric = 10.89% * 100;
 Minibatch[1201-1300]: loss = 0.655634 * 100, metric = 11.09% * 100;
 Minibatch[1301-1400]: loss = 0.643153 * 100, metric = 10.53% * 100;
 Minibatch[1401-1500]: loss = 0.660075 * 100, metric = 11.17% * 100;
 Minibatch[1501-1600]: loss = 0.621287 * 100, metric = 10.29% * 100;
 Minibatch[1601-1700]: loss = 0.648256 * 100, metric = 10.97% * 100;
 Minibatch[1701-1800]: loss = 0.636887 * 100, metric = 10.52% * 100;
 Minibatch[1801-1900]: loss = 0.646263 * 100, metric = 10.88% * 100;
 Minibatch[1901-2000]: loss = 0.662738 * 100, metric = 11.22% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.648486 * 2000, metric = 10.85% * 2000 1001.003s (  2.0 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 18.30% * 2000;
 Minibatch[   1- 100]: loss = 0.647298 * 100, metric = 10.75% * 100;
 Minibatch[ 101- 200]: loss = 0.651330 * 100, metric = 10.98% * 100;
 Minibatch[ 201- 300]: loss = 0.641599 * 100, metric = 10.93% * 100;
 Minibatch[ 301- 400]: loss = 0.645273 * 100, metric = 10.81% * 100;
 Minibatch[ 401- 500]: loss = 0.651892 * 100, metric = 11.30% * 100;
 Minibatch[ 501- 600]: loss = 0.654469 * 100, metric = 11.20% * 100;
 Minibatch[ 601- 700]: loss = 0.626880 * 100, metric = 10.36% * 100;
 Minibatch[ 701- 800]: loss = 0.627385 * 100, metric = 10.24% * 100;
 Minibatch[ 801- 900]: loss = 0.633351 * 100, metric = 10.68% * 100;
 Minibatch[ 901-1000]: loss = 0.653775 * 100, metric = 10.89% * 100;
 Minibatch[1001-1100]: loss = 0.652729 * 100, metric = 11.12% * 100;
 Minibatch[1101-1200]: loss = 0.641121 * 100, metric = 10.66% * 100;
 Minibatch[1201-1300]: loss = 0.644654 * 100, metric = 10.79% * 100;
 Minibatch[1301-1400]: loss = 0.633421 * 100, metric = 10.57% * 100;
 Minibatch[1401-1500]: loss = 0.633996 * 100, metric = 10.50% * 100;
 Minibatch[1501-1600]: loss = 0.632250 * 100, metric = 10.45% * 100;
 Minibatch[1601-1700]: loss = 0.615828 * 100, metric = 10.37% * 100;
 Minibatch[1701-1800]: loss = 0.628042 * 100, metric = 10.36% * 100;
 Minibatch[1801-1900]: loss = 0.617457 * 100, metric = 10.04% * 100;
 Minibatch[1901-2000]: loss = 0.637035 * 100, metric = 10.71% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.638489 * 2000, metric = 10.68% * 2000 1005.732s (  2.0 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 19.98% * 2000;
 Minibatch[   1- 100]: loss = 0.628649 * 100, metric = 10.52% * 100;
 Minibatch[ 101- 200]: loss = 0.617215 * 100, metric = 10.09% * 100;
 Minibatch[ 201- 300]: loss = 0.641622 * 100, metric = 10.85% * 100;
 Minibatch[ 301- 400]: loss = 0.629099 * 100, metric = 10.48% * 100;
 Minibatch[ 401- 500]: loss = 0.628410 * 100, metric = 10.49% * 100;
 Minibatch[ 501- 600]: loss = 0.634008 * 100, metric = 10.55% * 100;
 Minibatch[ 601- 700]: loss = 0.627632 * 100, metric = 10.59% * 100;
 Minibatch[ 701- 800]: loss = 0.643246 * 100, metric = 10.88% * 100;
 Minibatch[ 801- 900]: loss = 0.646070 * 100, metric = 11.28% * 100;
 Minibatch[ 901-1000]: loss = 0.645524 * 100, metric = 11.02% * 100;
 Minibatch[1001-1100]: loss = 0.628159 * 100, metric = 10.62% * 100;
 Minibatch[1101-1200]: loss = 0.626750 * 100, metric = 10.78% * 100;
 Minibatch[1201-1300]: loss = 0.607078 * 100, metric = 9.79% * 100;
 Minibatch[1301-1400]: loss = 0.626269 * 100, metric = 10.83% * 100;
 Minibatch[1401-1500]: loss = 0.626340 * 100, metric = 10.46% * 100;
 Minibatch[1501-1600]: loss = 0.598330 * 100, metric = 10.06% * 100;
 Minibatch[1601-1700]: loss = 0.617254 * 100, metric = 10.33% * 100;
 Minibatch[1701-1800]: loss = 0.612263 * 100, metric = 10.12% * 100;
 Minibatch[1801-1900]: loss = 0.616768 * 100, metric = 9.95% * 100;
 Minibatch[1901-2000]: loss = 0.619413 * 100, metric = 10.02% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.626005 * 2000, metric = 10.48% * 2000 1020.244s (  2.0 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 19.60% * 2000;
 Minibatch[   1- 100]: loss = 0.609359 * 100, metric = 10.04% * 100;
 Minibatch[ 101- 200]: loss = 0.624119 * 100, metric = 10.25% * 100;
 Minibatch[ 201- 300]: loss = 0.624392 * 100, metric = 10.67% * 100;
 Minibatch[ 301- 400]: loss = 0.602501 * 100, metric = 9.78% * 100;
 Minibatch[ 401- 500]: loss = 0.608049 * 100, metric = 10.10% * 100;
 Minibatch[ 501- 600]: loss = 0.603108 * 100, metric = 9.87% * 100;
 Minibatch[ 601- 700]: loss = 0.593814 * 100, metric = 9.87% * 100;
 Minibatch[ 701- 800]: loss = 0.619810 * 100, metric = 10.40% * 100;
 Minibatch[ 801- 900]: loss = 0.624102 * 100, metric = 10.71% * 100;
 Minibatch[ 901-1000]: loss = 0.612723 * 100, metric = 10.23% * 100;
 Minibatch[1001-1100]: loss = 0.607831 * 100, metric = 9.95% * 100;
 Minibatch[1101-1200]: loss = 0.602299 * 100, metric = 9.82% * 100;
 Minibatch[1201-1300]: loss = 0.596366 * 100, metric = 9.42% * 100;
 Minibatch[1301-1400]: loss = 0.619368 * 100, metric = 10.40% * 100;
 Minibatch[1401-1500]: loss = 0.582016 * 100, metric = 9.44% * 100;
 Minibatch[1501-1600]: loss = 0.596981 * 100, metric = 9.81% * 100;
 Minibatch[1601-1700]: loss = 0.609777 * 100, metric = 10.06% * 100;
 Minibatch[1701-1800]: loss = 0.585530 * 100, metric = 9.43% * 100;
 Minibatch[1801-1900]: loss = 0.600857 * 100, metric = 9.86% * 100;
 Minibatch[1901-2000]: loss = 0.595634 * 100, metric = 9.86% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.605932 * 2000, metric = 10.00% * 2000 1014.923s (  2.0 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 16.79% * 2000;
0.6928592400550843
 Minibatch[   1- 100]: loss = 0.613906 * 100, metric = 10.58% * 100;
 Minibatch[ 101- 200]: loss = 0.605461 * 100, metric = 9.83% * 100;
 Minibatch[ 201- 300]: loss = 0.602148 * 100, metric = 9.94% * 100;
 Minibatch[ 301- 400]: loss = 0.604149 * 100, metric = 9.93% * 100;
 Minibatch[ 401- 500]: loss = 0.578703 * 100, metric = 9.17% * 100;
 Minibatch[ 501- 600]: loss = 0.592195 * 100, metric = 9.84% * 100;
 Minibatch[ 601- 700]: loss = 0.598684 * 100, metric = 9.71% * 100;
 Minibatch[ 701- 800]: loss = 0.595093 * 100, metric = 9.74% * 100;
 Minibatch[ 801- 900]: loss = 0.578173 * 100, metric = 9.33% * 100;
 Minibatch[ 901-1000]: loss = 0.598069 * 100, metric = 9.96% * 100;
 Minibatch[1001-1100]: loss = 0.579844 * 100, metric = 9.54% * 100;
 Minibatch[1101-1200]: loss = 0.588023 * 100, metric = 9.76% * 100;
 Minibatch[1201-1300]: loss = 0.586871 * 100, metric = 9.33% * 100;
 Minibatch[1301-1400]: loss = 0.585352 * 100, metric = 9.42% * 100;
 Minibatch[1401-1500]: loss = 0.587457 * 100, metric = 9.75% * 100;
 Minibatch[1501-1600]: loss = 0.584550 * 100, metric = 9.46% * 100;
 Minibatch[1601-1700]: loss = 0.590877 * 100, metric = 9.74% * 100;
 Minibatch[1701-1800]: loss = 0.611658 * 100, metric = 10.15% * 100;
 Minibatch[1801-1900]: loss = 0.595101 * 100, metric = 9.92% * 100;
 Minibatch[1901-2000]: loss = 0.586783 * 100, metric = 9.75% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.593155 * 2000, metric = 9.74% * 2000 1013.406s (  2.0 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 17.81% * 2000;
 Minibatch[   1- 100]: loss = 0.575038 * 100, metric = 9.51% * 100;
 Minibatch[ 101- 200]: loss = 0.600358 * 100, metric = 9.92% * 100;
 Minibatch[ 201- 300]: loss = 0.595645 * 100, metric = 9.87% * 100;
 Minibatch[ 301- 400]: loss = 0.595157 * 100, metric = 9.80% * 100;
 Minibatch[ 401- 500]: loss = 0.592938 * 100, metric = 9.53% * 100;
 Minibatch[ 501- 600]: loss = 0.581592 * 100, metric = 9.47% * 100;
 Minibatch[ 601- 700]: loss = 0.562698 * 100, metric = 9.10% * 100;
 Minibatch[ 701- 800]: loss = 0.581490 * 100, metric = 9.50% * 100;
 Minibatch[ 801- 900]: loss = 0.588413 * 100, metric = 9.57% * 100;
 Minibatch[ 901-1000]: loss = 0.582700 * 100, metric = 9.64% * 100;
 Minibatch[1001-1100]: loss = 0.563298 * 100, metric = 9.13% * 100;
 Minibatch[1101-1200]: loss = 0.600741 * 100, metric = 9.85% * 100;
 Minibatch[1201-1300]: loss = 0.595475 * 100, metric = 9.83% * 100;
 Minibatch[1301-1400]: loss = 0.574528 * 100, metric = 9.26% * 100;
 Minibatch[1401-1500]: loss = 0.583265 * 100, metric = 9.77% * 100;
 Minibatch[1501-1600]: loss = 0.580375 * 100, metric = 9.60% * 100;
 Minibatch[1601-1700]: loss = 0.583355 * 100, metric = 9.29% * 100;
 Minibatch[1701-1800]: loss = 0.565869 * 100, metric = 9.01% * 100;
 Minibatch[1801-1900]: loss = 0.595397 * 100, metric = 9.96% * 100;
 Minibatch[1901-2000]: loss = 0.608923 * 100, metric = 10.08% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.585363 * 2000, metric = 9.58% * 2000 1028.978s (  1.9 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 16.75% * 2000;
 Minibatch[   1- 100]: loss = 0.562873 * 100, metric = 8.99% * 100;
 Minibatch[ 101- 200]: loss = 0.592660 * 100, metric = 9.48% * 100;
 Minibatch[ 201- 300]: loss = 0.570286 * 100, metric = 9.26% * 100;
 Minibatch[ 301- 400]: loss = 0.583244 * 100, metric = 9.42% * 100;
 Minibatch[ 401- 500]: loss = 0.557507 * 100, metric = 8.92% * 100;
 Minibatch[ 501- 600]: loss = 0.564091 * 100, metric = 8.99% * 100;
 Minibatch[ 601- 700]: loss = 0.575106 * 100, metric = 9.41% * 100;
 Minibatch[ 701- 800]: loss = 0.561154 * 100, metric = 9.21% * 100;
 Minibatch[ 801- 900]: loss = 0.584959 * 100, metric = 9.57% * 100;
 Minibatch[ 901-1000]: loss = 0.575402 * 100, metric = 9.16% * 100;
 Minibatch[1001-1100]: loss = 0.585023 * 100, metric = 9.59% * 100;
 Minibatch[1101-1200]: loss = 0.581725 * 100, metric = 9.61% * 100;
 Minibatch[1201-1300]: loss = 0.590444 * 100, metric = 9.95% * 100;
 Minibatch[1301-1400]: loss = 0.593430 * 100, metric = 9.85% * 100;
 Minibatch[1401-1500]: loss = 0.560721 * 100, metric = 8.87% * 100;
 Minibatch[1501-1600]: loss = 0.577744 * 100, metric = 9.13% * 100;
 Minibatch[1601-1700]: loss = 0.545479 * 100, metric = 8.47% * 100;
 Minibatch[1701-1800]: loss = 0.562344 * 100, metric = 8.96% * 100;
 Minibatch[1801-1900]: loss = 0.552533 * 100, metric = 9.06% * 100;
 Minibatch[1901-2000]: loss = 0.553134 * 100, metric = 8.77% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.571493 * 2000, metric = 9.23% * 2000 982.557s (  2.0 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 18.61% * 2000;
 Minibatch[   1- 100]: loss = 0.574234 * 100, metric = 9.30% * 100;
 Minibatch[ 101- 200]: loss = 0.579226 * 100, metric = 9.36% * 100;
 Minibatch[ 201- 300]: loss = 0.555482 * 100, metric = 8.84% * 100;
 Minibatch[ 301- 400]: loss = 0.573873 * 100, metric = 9.47% * 100;
 Minibatch[ 401- 500]: loss = 0.573992 * 100, metric = 9.00% * 100;
 Minibatch[ 501- 600]: loss = 0.553581 * 100, metric = 8.62% * 100;
 Minibatch[ 601- 700]: loss = 0.571010 * 100, metric = 9.21% * 100;
 Minibatch[ 701- 800]: loss = 0.545861 * 100, metric = 8.77% * 100;
 Minibatch[ 801- 900]: loss = 0.584039 * 100, metric = 9.48% * 100;
 Minibatch[ 901-1000]: loss = 0.553571 * 100, metric = 8.73% * 100;
 Minibatch[1001-1100]: loss = 0.579326 * 100, metric = 9.26% * 100;
 Minibatch[1101-1200]: loss = 0.568556 * 100, metric = 9.63% * 100;
 Minibatch[1201-1300]: loss = 0.564530 * 100, metric = 9.08% * 100;
 Minibatch[1301-1400]: loss = 0.555325 * 100, metric = 8.92% * 100;
 Minibatch[1401-1500]: loss = 0.570809 * 100, metric = 9.23% * 100;
 Minibatch[1501-1600]: loss = 0.578633 * 100, metric = 9.56% * 100;
 Minibatch[1601-1700]: loss = 0.549770 * 100, metric = 8.99% * 100;
 Minibatch[1701-1800]: loss = 0.538269 * 100, metric = 8.34% * 100;
 Minibatch[1801-1900]: loss = 0.546796 * 100, metric = 8.52% * 100;
 Minibatch[1901-2000]: loss = 0.544076 * 100, metric = 8.46% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.563048 * 2000, metric = 9.04% * 2000 1010.123s (  2.0 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 17.34% * 2000;
 Minibatch[   1- 100]: loss = 0.550756 * 100, metric = 8.55% * 100;
 Minibatch[ 101- 200]: loss = 0.548060 * 100, metric = 8.71% * 100;
 Minibatch[ 201- 300]: loss = 0.545839 * 100, metric = 8.53% * 100;
 Minibatch[ 301- 400]: loss = 0.562267 * 100, metric = 8.80% * 100;
 Minibatch[ 401- 500]: loss = 0.558752 * 100, metric = 8.94% * 100;
 Minibatch[ 501- 600]: loss = 0.550961 * 100, metric = 8.91% * 100;
 Minibatch[ 601- 700]: loss = 0.561497 * 100, metric = 9.00% * 100;
 Minibatch[ 701- 800]: loss = 0.559366 * 100, metric = 9.07% * 100;
 Minibatch[ 801- 900]: loss = 0.553144 * 100, metric = 8.72% * 100;
 Minibatch[ 901-1000]: loss = 0.557809 * 100, metric = 8.95% * 100;
 Minibatch[1001-1100]: loss = 0.527997 * 100, metric = 8.37% * 100;
 Minibatch[1101-1200]: loss = 0.546891 * 100, metric = 8.53% * 100;
 Minibatch[1201-1300]: loss = 0.552352 * 100, metric = 9.07% * 100;
 Minibatch[1301-1400]: loss = 0.549786 * 100, metric = 8.87% * 100;
 Minibatch[1401-1500]: loss = 0.534207 * 100, metric = 8.66% * 100;
 Minibatch[1501-1600]: loss = 0.554043 * 100, metric = 8.83% * 100;
 Minibatch[1601-1700]: loss = 0.540356 * 100, metric = 8.72% * 100;
 Minibatch[1701-1800]: loss = 0.553729 * 100, metric = 9.21% * 100;
 Minibatch[1801-1900]: loss = 0.542893 * 100, metric = 8.79% * 100;
 Minibatch[1901-2000]: loss = 0.548514 * 100, metric = 8.93% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.549961 * 2000, metric = 8.81% * 2000 997.815s (  2.0 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 18.18% * 2000;
 Minibatch[   1- 100]: loss = 0.550932 * 100, metric = 8.76% * 100;
 Minibatch[ 101- 200]: loss = 0.547813 * 100, metric = 8.85% * 100;
 Minibatch[ 201- 300]: loss = 0.542365 * 100, metric = 8.66% * 100;
 Minibatch[ 301- 400]: loss = 0.558493 * 100, metric = 9.23% * 100;
 Minibatch[ 401- 500]: loss = 0.537706 * 100, metric = 8.42% * 100;
 Minibatch[ 501- 600]: loss = 0.538427 * 100, metric = 8.59% * 100;
 Minibatch[ 601- 700]: loss = 0.541970 * 100, metric = 8.42% * 100;
 Minibatch[ 701- 800]: loss = 0.521381 * 100, metric = 8.24% * 100;
 Minibatch[ 801- 900]: loss = 0.544168 * 100, metric = 8.55% * 100;
 Minibatch[ 901-1000]: loss = 0.528802 * 100, metric = 8.43% * 100;
 Minibatch[1001-1100]: loss = 0.535167 * 100, metric = 8.18% * 100;
 Minibatch[1101-1200]: loss = 0.533102 * 100, metric = 8.47% * 100;
 Minibatch[1201-1300]: loss = 0.541245 * 100, metric = 8.70% * 100;
 Minibatch[1301-1400]: loss = 0.532423 * 100, metric = 8.34% * 100;
 Minibatch[1401-1500]: loss = 0.544514 * 100, metric = 8.59% * 100;
 Minibatch[1501-1600]: loss = 0.546321 * 100, metric = 9.08% * 100;
 Minibatch[1601-1700]: loss = 0.534165 * 100, metric = 8.67% * 100;
 Minibatch[1701-1800]: loss = 0.536526 * 100, metric = 8.31% * 100;
 Minibatch[1801-1900]: loss = 0.550289 * 100, metric = 8.98% * 100;
 Minibatch[1901-2000]: loss = 0.518784 * 100, metric = 8.18% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.539230 * 2000, metric = 8.58% * 2000 995.707s (  2.0 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 15.79% * 2000;
0.668218305297196
 Minibatch[   1- 100]: loss = 0.545008 * 100, metric = 8.73% * 100;
 Minibatch[ 101- 200]: loss = 0.536853 * 100, metric = 8.41% * 100;
 Minibatch[ 201- 300]: loss = 0.542115 * 100, metric = 8.79% * 100;
 Minibatch[ 301- 400]: loss = 0.531290 * 100, metric = 8.65% * 100;
 Minibatch[ 401- 500]: loss = 0.520882 * 100, metric = 8.17% * 100;
 Minibatch[ 501- 600]: loss = 0.534521 * 100, metric = 8.26% * 100;
 Minibatch[ 601- 700]: loss = 0.527122 * 100, metric = 8.22% * 100;
 Minibatch[ 701- 800]: loss = 0.528977 * 100, metric = 8.62% * 100;
 Minibatch[ 801- 900]: loss = 0.542046 * 100, metric = 8.67% * 100;
 Minibatch[ 901-1000]: loss = 0.546588 * 100, metric = 8.64% * 100;
 Minibatch[1001-1100]: loss = 0.514728 * 100, metric = 7.99% * 100;
 Minibatch[1101-1200]: loss = 0.512072 * 100, metric = 7.85% * 100;
 Minibatch[1201-1300]: loss = 0.532733 * 100, metric = 8.42% * 100;
 Minibatch[1301-1400]: loss = 0.540561 * 100, metric = 8.69% * 100;
 Minibatch[1401-1500]: loss = 0.527593 * 100, metric = 8.44% * 100;
 Minibatch[1501-1600]: loss = 0.528054 * 100, metric = 8.20% * 100;
 Minibatch[1601-1700]: loss = 0.527560 * 100, metric = 8.23% * 100;
 Minibatch[1701-1800]: loss = 0.526887 * 100, metric = 8.15% * 100;
 Minibatch[1801-1900]: loss = 0.521669 * 100, metric = 8.31% * 100;
 Minibatch[1901-2000]: loss = 0.531086 * 100, metric = 8.24% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.530917 * 2000, metric = 8.38% * 2000 984.252s (  2.0 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 16.88% * 2000;
 Minibatch[   1- 100]: loss = 0.534990 * 100, metric = 8.47% * 100;
 Minibatch[ 101- 200]: loss = 0.534897 * 100, metric = 8.78% * 100;
 Minibatch[ 201- 300]: loss = 0.534006 * 100, metric = 8.48% * 100;
 Minibatch[ 301- 400]: loss = 0.551102 * 100, metric = 8.86% * 100;
 Minibatch[ 401- 500]: loss = 0.537781 * 100, metric = 8.68% * 100;
 Minibatch[ 501- 600]: loss = 0.526971 * 100, metric = 8.39% * 100;
 Minibatch[ 601- 700]: loss = 0.537890 * 100, metric = 8.38% * 100;
 Minibatch[ 701- 800]: loss = 0.508568 * 100, metric = 7.88% * 100;
 Minibatch[ 801- 900]: loss = 0.514251 * 100, metric = 8.29% * 100;
 Minibatch[ 901-1000]: loss = 0.529521 * 100, metric = 8.50% * 100;
 Minibatch[1001-1100]: loss = 0.514056 * 100, metric = 7.94% * 100;
 Minibatch[1101-1200]: loss = 0.527218 * 100, metric = 8.23% * 100;
 Minibatch[1201-1300]: loss = 0.527717 * 100, metric = 8.32% * 100;
 Minibatch[1301-1400]: loss = 0.525281 * 100, metric = 8.24% * 100;
 Minibatch[1401-1500]: loss = 0.501675 * 100, metric = 7.95% * 100;
 Minibatch[1501-1600]: loss = 0.519666 * 100, metric = 8.02% * 100;
 Minibatch[1601-1700]: loss = 0.518839 * 100, metric = 8.33% * 100;
 Minibatch[1701-1800]: loss = 0.531161 * 100, metric = 8.36% * 100;
 Minibatch[1801-1900]: loss = 0.518389 * 100, metric = 8.37% * 100;
 Minibatch[1901-2000]: loss = 0.526337 * 100, metric = 8.21% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.526016 * 2000, metric = 8.33% * 2000 985.500s (  2.0 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 17.29% * 2000;
 Minibatch[   1- 100]: loss = 0.495838 * 100, metric = 7.83% * 100;
 Minibatch[ 101- 200]: loss = 0.526211 * 100, metric = 8.36% * 100;
 Minibatch[ 201- 300]: loss = 0.513927 * 100, metric = 8.16% * 100;
 Minibatch[ 301- 400]: loss = 0.524666 * 100, metric = 8.25% * 100;
 Minibatch[ 401- 500]: loss = 0.515519 * 100, metric = 8.02% * 100;
 Minibatch[ 501- 600]: loss = 0.505692 * 100, metric = 7.82% * 100;
 Minibatch[ 601- 700]: loss = 0.524152 * 100, metric = 8.21% * 100;
 Minibatch[ 701- 800]: loss = 0.505276 * 100, metric = 7.88% * 100;
 Minibatch[ 801- 900]: loss = 0.527899 * 100, metric = 8.30% * 100;
 Minibatch[ 901-1000]: loss = 0.511813 * 100, metric = 8.06% * 100;
 Minibatch[1001-1100]: loss = 0.522371 * 100, metric = 8.23% * 100;
 Minibatch[1101-1200]: loss = 0.525269 * 100, metric = 8.32% * 100;
 Minibatch[1201-1300]: loss = 0.523162 * 100, metric = 8.26% * 100;
 Minibatch[1301-1400]: loss = 0.513994 * 100, metric = 8.09% * 100;
 Minibatch[1401-1500]: loss = 0.510173 * 100, metric = 7.82% * 100;
 Minibatch[1501-1600]: loss = 0.526216 * 100, metric = 8.38% * 100;
 Minibatch[1601-1700]: loss = 0.499503 * 100, metric = 7.51% * 100;
 Minibatch[1701-1800]: loss = 0.496456 * 100, metric = 7.62% * 100;
 Minibatch[1801-1900]: loss = 0.520742 * 100, metric = 8.27% * 100;
 Minibatch[1901-2000]: loss = 0.523854 * 100, metric = 8.30% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.515637 * 2000, metric = 8.09% * 2000 986.399s (  2.0 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 16.88% * 2000;
 Minibatch[   1- 100]: loss = 0.514493 * 100, metric = 8.03% * 100;
 Minibatch[ 101- 200]: loss = 0.509282 * 100, metric = 8.17% * 100;
 Minibatch[ 201- 300]: loss = 0.511014 * 100, metric = 8.15% * 100;
 Minibatch[ 301- 400]: loss = 0.511667 * 100, metric = 8.01% * 100;
 Minibatch[ 401- 500]: loss = 0.504538 * 100, metric = 7.92% * 100;
 Minibatch[ 501- 600]: loss = 0.502579 * 100, metric = 7.80% * 100;
 Minibatch[ 601- 700]: loss = 0.514112 * 100, metric = 8.03% * 100;
 Minibatch[ 701- 800]: loss = 0.494684 * 100, metric = 7.60% * 100;
 Minibatch[ 801- 900]: loss = 0.500028 * 100, metric = 7.85% * 100;
 Minibatch[ 901-1000]: loss = 0.513201 * 100, metric = 8.10% * 100;
 Minibatch[1001-1100]: loss = 0.510570 * 100, metric = 8.12% * 100;
 Minibatch[1101-1200]: loss = 0.514515 * 100, metric = 8.05% * 100;
 Minibatch[1201-1300]: loss = 0.530336 * 100, metric = 8.54% * 100;
 Minibatch[1301-1400]: loss = 0.503671 * 100, metric = 7.71% * 100;
 Minibatch[1401-1500]: loss = 0.499726 * 100, metric = 7.67% * 100;
 Minibatch[1501-1600]: loss = 0.519670 * 100, metric = 8.37% * 100;
 Minibatch[1601-1700]: loss = 0.501043 * 100, metric = 7.67% * 100;
 Minibatch[1701-1800]: loss = 0.508788 * 100, metric = 8.06% * 100;
 Minibatch[1801-1900]: loss = 0.493466 * 100, metric = 7.54% * 100;
 Minibatch[1901-2000]: loss = 0.484973 * 100, metric = 7.30% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.507118 * 2000, metric = 7.94% * 2000 978.306s (  2.0 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 17.17% * 2000;
 Minibatch[   1- 100]: loss = 0.502818 * 100, metric = 7.94% * 100;
 Minibatch[ 101- 200]: loss = 0.489614 * 100, metric = 7.60% * 100;
 Minibatch[ 201- 300]: loss = 0.512431 * 100, metric = 8.30% * 100;
 Minibatch[ 301- 400]: loss = 0.493786 * 100, metric = 7.45% * 100;
 Minibatch[ 401- 500]: loss = 0.503344 * 100, metric = 8.05% * 100;
 Minibatch[ 501- 600]: loss = 0.493457 * 100, metric = 7.57% * 100;
 Minibatch[ 601- 700]: loss = 0.516163 * 100, metric = 8.15% * 100;
 Minibatch[ 701- 800]: loss = 0.497831 * 100, metric = 7.87% * 100;
 Minibatch[ 801- 900]: loss = 0.485667 * 100, metric = 7.29% * 100;
 Minibatch[ 901-1000]: loss = 0.485410 * 100, metric = 7.41% * 100;
 Minibatch[1001-1100]: loss = 0.511654 * 100, metric = 8.21% * 100;
 Minibatch[1101-1200]: loss = 0.515208 * 100, metric = 8.09% * 100;
 Minibatch[1201-1300]: loss = 0.499800 * 100, metric = 7.88% * 100;
 Minibatch[1301-1400]: loss = 0.478754 * 100, metric = 7.23% * 100;
 Minibatch[1401-1500]: loss = 0.498416 * 100, metric = 7.69% * 100;
 Minibatch[1501-1600]: loss = 0.493102 * 100, metric = 7.36% * 100;
 Minibatch[1601-1700]: loss = 0.513672 * 100, metric = 8.12% * 100;
 Minibatch[1701-1800]: loss = 0.505830 * 100, metric = 8.00% * 100;
 Minibatch[1801-1900]: loss = 0.493736 * 100, metric = 7.57% * 100;
 Minibatch[1901-2000]: loss = 0.502263 * 100, metric = 7.82% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.499648 * 2000, metric = 7.78% * 2000 978.734s (  2.0 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 17.74% * 2000;
 Minibatch[   1- 100]: loss = 0.488082 * 100, metric = 7.46% * 100;
 Minibatch[ 101- 200]: loss = 0.511750 * 100, metric = 8.03% * 100;
 Minibatch[ 201- 300]: loss = 0.488330 * 100, metric = 7.57% * 100;
 Minibatch[ 301- 400]: loss = 0.488426 * 100, metric = 7.62% * 100;
 Minibatch[ 401- 500]: loss = 0.491800 * 100, metric = 7.64% * 100;
 Minibatch[ 501- 600]: loss = 0.488508 * 100, metric = 7.59% * 100;
 Minibatch[ 601- 700]: loss = 0.489391 * 100, metric = 7.45% * 100;
 Minibatch[ 701- 800]: loss = 0.493892 * 100, metric = 7.70% * 100;
 Minibatch[ 801- 900]: loss = 0.504492 * 100, metric = 7.94% * 100;
 Minibatch[ 901-1000]: loss = 0.492676 * 100, metric = 7.77% * 100;
 Minibatch[1001-1100]: loss = 0.488424 * 100, metric = 7.39% * 100;
 Minibatch[1101-1200]: loss = 0.509491 * 100, metric = 8.00% * 100;
 Minibatch[1201-1300]: loss = 0.494558 * 100, metric = 7.59% * 100;
 Minibatch[1301-1400]: loss = 0.504933 * 100, metric = 8.01% * 100;
 Minibatch[1401-1500]: loss = 0.489984 * 100, metric = 7.58% * 100;
 Minibatch[1501-1600]: loss = 0.489548 * 100, metric = 7.68% * 100;
 Minibatch[1601-1700]: loss = 0.476157 * 100, metric = 7.14% * 100;
 Minibatch[1701-1800]: loss = 0.483959 * 100, metric = 7.28% * 100;
 Minibatch[1801-1900]: loss = 0.483111 * 100, metric = 7.44% * 100;
 Minibatch[1901-2000]: loss = 0.492452 * 100, metric = 7.55% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.492498 * 2000, metric = 7.62% * 2000 962.871s (  2.1 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 16.25% * 2000;
 Minibatch[   1- 100]: loss = 0.500787 * 100, metric = 7.81% * 100;
 Minibatch[ 101- 200]: loss = 0.472257 * 100, metric = 7.06% * 100;
 Minibatch[ 201- 300]: loss = 0.488423 * 100, metric = 7.65% * 100;
 Minibatch[ 301- 400]: loss = 0.491220 * 100, metric = 7.55% * 100;
 Minibatch[ 401- 500]: loss = 0.482431 * 100, metric = 7.48% * 100;
 Minibatch[ 501- 600]: loss = 0.504482 * 100, metric = 8.07% * 100;
 Minibatch[ 601- 700]: loss = 0.486991 * 100, metric = 7.35% * 100;
 Minibatch[ 701- 800]: loss = 0.473554 * 100, metric = 7.30% * 100;
 Minibatch[ 801- 900]: loss = 0.488887 * 100, metric = 7.51% * 100;
 Minibatch[ 901-1000]: loss = 0.491280 * 100, metric = 7.76% * 100;
 Minibatch[1001-1100]: loss = 0.498947 * 100, metric = 7.64% * 100;
 Minibatch[1101-1200]: loss = 0.487283 * 100, metric = 7.36% * 100;
 Minibatch[1201-1300]: loss = 0.489784 * 100, metric = 7.79% * 100;
 Minibatch[1301-1400]: loss = 0.481980 * 100, metric = 7.29% * 100;
 Minibatch[1401-1500]: loss = 0.492332 * 100, metric = 7.50% * 100;
 Minibatch[1501-1600]: loss = 0.472604 * 100, metric = 7.17% * 100;
 Minibatch[1601-1700]: loss = 0.477176 * 100, metric = 7.22% * 100;
 Minibatch[1701-1800]: loss = 0.487318 * 100, metric = 7.42% * 100;
 Minibatch[1801-1900]: loss = 0.483368 * 100, metric = 7.65% * 100;
 Minibatch[1901-2000]: loss = 0.484706 * 100, metric = 7.35% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.486790 * 2000, metric = 7.50% * 2000 948.604s (  2.1 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 15.08% * 2000;
0.6561516541689635
 Minibatch[   1- 100]: loss = 0.469270 * 100, metric = 6.99% * 100;
 Minibatch[ 101- 200]: loss = 0.480621 * 100, metric = 7.49% * 100;
 Minibatch[ 201- 300]: loss = 0.491514 * 100, metric = 7.76% * 100;
 Minibatch[ 301- 400]: loss = 0.509726 * 100, metric = 7.92% * 100;
 Minibatch[ 401- 500]: loss = 0.477953 * 100, metric = 7.19% * 100;
 Minibatch[ 501- 600]: loss = 0.495081 * 100, metric = 7.69% * 100;
 Minibatch[ 601- 700]: loss = 0.484123 * 100, metric = 7.50% * 100;
 Minibatch[ 701- 800]: loss = 0.488599 * 100, metric = 7.68% * 100;
 Minibatch[ 801- 900]: loss = 0.484946 * 100, metric = 7.41% * 100;
 Minibatch[ 901-1000]: loss = 0.490008 * 100, metric = 7.59% * 100;
 Minibatch[1001-1100]: loss = 0.482953 * 100, metric = 7.56% * 100;
 Minibatch[1101-1200]: loss = 0.472408 * 100, metric = 7.13% * 100;
 Minibatch[1201-1300]: loss = 0.483160 * 100, metric = 7.50% * 100;
 Minibatch[1301-1400]: loss = 0.470150 * 100, metric = 7.21% * 100;
 Minibatch[1401-1500]: loss = 0.492593 * 100, metric = 7.62% * 100;
 Minibatch[1501-1600]: loss = 0.455638 * 100, metric = 6.71% * 100;
 Minibatch[1601-1700]: loss = 0.487279 * 100, metric = 7.68% * 100;
 Minibatch[1701-1800]: loss = 0.453209 * 100, metric = 6.78% * 100;
 Minibatch[1801-1900]: loss = 0.487953 * 100, metric = 7.62% * 100;
 Minibatch[1901-2000]: loss = 0.468742 * 100, metric = 7.17% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.481296 * 2000, metric = 7.41% * 2000 981.043s (  2.0 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 17.85% * 2000;
 Minibatch[   1- 100]: loss = 0.488655 * 100, metric = 7.51% * 100;
 Minibatch[ 101- 200]: loss = 0.452573 * 100, metric = 6.68% * 100;
 Minibatch[ 201- 300]: loss = 0.462219 * 100, metric = 6.90% * 100;
 Minibatch[ 301- 400]: loss = 0.479048 * 100, metric = 7.35% * 100;
 Minibatch[ 401- 500]: loss = 0.470558 * 100, metric = 7.28% * 100;
 Minibatch[ 501- 600]: loss = 0.446426 * 100, metric = 6.51% * 100;
 Minibatch[ 601- 700]: loss = 0.472856 * 100, metric = 7.47% * 100;
 Minibatch[ 701- 800]: loss = 0.471938 * 100, metric = 7.17% * 100;
 Minibatch[ 801- 900]: loss = 0.477591 * 100, metric = 7.38% * 100;
 Minibatch[ 901-1000]: loss = 0.452951 * 100, metric = 6.78% * 100;
 Minibatch[1001-1100]: loss = 0.469763 * 100, metric = 7.12% * 100;
 Minibatch[1101-1200]: loss = 0.489209 * 100, metric = 7.45% * 100;
 Minibatch[1201-1300]: loss = 0.463563 * 100, metric = 6.92% * 100;
 Minibatch[1301-1400]: loss = 0.471094 * 100, metric = 7.29% * 100;
 Minibatch[1401-1500]: loss = 0.457109 * 100, metric = 6.82% * 100;
 Minibatch[1501-1600]: loss = 0.474534 * 100, metric = 7.21% * 100;
 Minibatch[1601-1700]: loss = 0.469889 * 100, metric = 7.24% * 100;
 Minibatch[1701-1800]: loss = 0.477413 * 100, metric = 7.28% * 100;
 Minibatch[1801-1900]: loss = 0.477310 * 100, metric = 7.35% * 100;
 Minibatch[1901-2000]: loss = 0.489240 * 100, metric = 7.62% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.470697 * 2000, metric = 7.17% * 2000 956.976s (  2.1 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 16.76% * 2000;
 Minibatch[   1- 100]: loss = 0.470574 * 100, metric = 6.94% * 100;
 Minibatch[ 101- 200]: loss = 0.485707 * 100, metric = 7.76% * 100;
 Minibatch[ 201- 300]: loss = 0.469812 * 100, metric = 7.43% * 100;
 Minibatch[ 301- 400]: loss = 0.472463 * 100, metric = 7.30% * 100;
 Minibatch[ 401- 500]: loss = 0.477398 * 100, metric = 7.29% * 100;
 Minibatch[ 501- 600]: loss = 0.460464 * 100, metric = 7.04% * 100;
 Minibatch[ 601- 700]: loss = 0.484423 * 100, metric = 7.68% * 100;
 Minibatch[ 701- 800]: loss = 0.481700 * 100, metric = 7.43% * 100;
 Minibatch[ 801- 900]: loss = 0.474490 * 100, metric = 7.08% * 100;
 Minibatch[ 901-1000]: loss = 0.469990 * 100, metric = 7.28% * 100;
 Minibatch[1001-1100]: loss = 0.471284 * 100, metric = 7.18% * 100;
 Minibatch[1101-1200]: loss = 0.471180 * 100, metric = 7.49% * 100;
 Minibatch[1201-1300]: loss = 0.468451 * 100, metric = 7.23% * 100;
 Minibatch[1301-1400]: loss = 0.467363 * 100, metric = 7.22% * 100;
 Minibatch[1401-1500]: loss = 0.490526 * 100, metric = 7.68% * 100;
 Minibatch[1501-1600]: loss = 0.452691 * 100, metric = 6.79% * 100;
 Minibatch[1601-1700]: loss = 0.467667 * 100, metric = 7.25% * 100;
 Minibatch[1701-1800]: loss = 0.462059 * 100, metric = 7.22% * 100;
 Minibatch[1801-1900]: loss = 0.477341 * 100, metric = 7.47% * 100;
 Minibatch[1901-2000]: loss = 0.475229 * 100, metric = 7.23% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.472541 * 2000, metric = 7.30% * 2000 989.898s (  2.0 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 15.56% * 2000;
 Minibatch[   1- 100]: loss = 0.473389 * 100, metric = 7.23% * 100;
 Minibatch[ 101- 200]: loss = 0.473306 * 100, metric = 7.19% * 100;
 Minibatch[ 201- 300]: loss = 0.481408 * 100, metric = 7.56% * 100;
 Minibatch[ 301- 400]: loss = 0.478858 * 100, metric = 7.34% * 100;
 Minibatch[ 401- 500]: loss = 0.475306 * 100, metric = 7.41% * 100;
 Minibatch[ 501- 600]: loss = 0.469318 * 100, metric = 7.52% * 100;
 Minibatch[ 601- 700]: loss = 0.457098 * 100, metric = 6.86% * 100;
 Minibatch[ 701- 800]: loss = 0.458610 * 100, metric = 7.02% * 100;
 Minibatch[ 801- 900]: loss = 0.467125 * 100, metric = 7.29% * 100;
 Minibatch[ 901-1000]: loss = 0.457800 * 100, metric = 6.95% * 100;
 Minibatch[1001-1100]: loss = 0.462207 * 100, metric = 6.83% * 100;
 Minibatch[1101-1200]: loss = 0.471544 * 100, metric = 7.26% * 100;
 Minibatch[1201-1300]: loss = 0.473498 * 100, metric = 7.56% * 100;
 Minibatch[1301-1400]: loss = 0.461782 * 100, metric = 7.27% * 100;
 Minibatch[1401-1500]: loss = 0.463458 * 100, metric = 7.38% * 100;
 Minibatch[1501-1600]: loss = 0.475792 * 100, metric = 7.16% * 100;
 Minibatch[1601-1700]: loss = 0.450770 * 100, metric = 6.92% * 100;
 Minibatch[1701-1800]: loss = 0.479614 * 100, metric = 7.26% * 100;
 Minibatch[1801-1900]: loss = 0.462699 * 100, metric = 7.03% * 100;
 Minibatch[1901-2000]: loss = 0.473259 * 100, metric = 7.51% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.468342 * 2000, metric = 7.23% * 2000 966.054s (  2.1 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 15.77% * 2000;
 Minibatch[   1- 100]: loss = 0.479118 * 100, metric = 7.42% * 100;
 Minibatch[ 101- 200]: loss = 0.463787 * 100, metric = 7.24% * 100;
 Minibatch[ 201- 300]: loss = 0.458925 * 100, metric = 7.10% * 100;
 Minibatch[ 301- 400]: loss = 0.464798 * 100, metric = 7.33% * 100;
 Minibatch[ 401- 500]: loss = 0.459781 * 100, metric = 7.08% * 100;
 Minibatch[ 501- 600]: loss = 0.470066 * 100, metric = 7.16% * 100;
 Minibatch[ 601- 700]: loss = 0.471261 * 100, metric = 7.27% * 100;
 Minibatch[ 701- 800]: loss = 0.471050 * 100, metric = 7.31% * 100;
 Minibatch[ 801- 900]: loss = 0.459447 * 100, metric = 6.94% * 100;
 Minibatch[ 901-1000]: loss = 0.450318 * 100, metric = 6.81% * 100;
 Minibatch[1001-1100]: loss = 0.453915 * 100, metric = 6.96% * 100;
 Minibatch[1101-1200]: loss = 0.444690 * 100, metric = 6.59% * 100;
 Minibatch[1201-1300]: loss = 0.472309 * 100, metric = 7.05% * 100;
 Minibatch[1301-1400]: loss = 0.448096 * 100, metric = 6.53% * 100;
 Minibatch[1401-1500]: loss = 0.476229 * 100, metric = 7.32% * 100;
 Minibatch[1501-1600]: loss = 0.467836 * 100, metric = 7.31% * 100;
 Minibatch[1601-1700]: loss = 0.463660 * 100, metric = 6.75% * 100;
 Minibatch[1701-1800]: loss = 0.453973 * 100, metric = 6.79% * 100;
 Minibatch[1801-1900]: loss = 0.449268 * 100, metric = 6.60% * 100;
 Minibatch[1901-2000]: loss = 0.483364 * 100, metric = 7.58% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.463094 * 2000, metric = 7.06% * 2000 970.410s (  2.1 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 15.74% * 2000;
 Minibatch[   1- 100]: loss = 0.451563 * 100, metric = 6.73% * 100;
 Minibatch[ 101- 200]: loss = 0.471573 * 100, metric = 7.23% * 100;
 Minibatch[ 201- 300]: loss = 0.441708 * 100, metric = 6.56% * 100;
 Minibatch[ 301- 400]: loss = 0.458001 * 100, metric = 7.15% * 100;
 Minibatch[ 401- 500]: loss = 0.455385 * 100, metric = 6.98% * 100;
 Minibatch[ 501- 600]: loss = 0.459100 * 100, metric = 7.12% * 100;
 Minibatch[ 601- 700]: loss = 0.471015 * 100, metric = 7.18% * 100;
 Minibatch[ 701- 800]: loss = 0.449080 * 100, metric = 6.78% * 100;
 Minibatch[ 801- 900]: loss = 0.445950 * 100, metric = 6.25% * 100;
 Minibatch[ 901-1000]: loss = 0.449807 * 100, metric = 7.06% * 100;
 Minibatch[1001-1100]: loss = 0.456667 * 100, metric = 7.01% * 100;
 Minibatch[1101-1200]: loss = 0.457078 * 100, metric = 7.10% * 100;
 Minibatch[1201-1300]: loss = 0.450735 * 100, metric = 6.84% * 100;
 Minibatch[1301-1400]: loss = 0.450944 * 100, metric = 6.89% * 100;
 Minibatch[1401-1500]: loss = 0.469614 * 100, metric = 7.29% * 100;
 Minibatch[1501-1600]: loss = 0.460106 * 100, metric = 6.90% * 100;
 Minibatch[1601-1700]: loss = 0.469971 * 100, metric = 7.32% * 100;
 Minibatch[1701-1800]: loss = 0.456992 * 100, metric = 7.12% * 100;
 Minibatch[1801-1900]: loss = 0.454517 * 100, metric = 6.98% * 100;
 Minibatch[1901-2000]: loss = 0.457396 * 100, metric = 6.93% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.456860 * 2000, metric = 6.97% * 2000 967.472s (  2.1 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 15.89% * 2000;
 Minibatch[   1- 100]: loss = 0.435021 * 100, metric = 6.44% * 100;
 Minibatch[ 101- 200]: loss = 0.459363 * 100, metric = 7.20% * 100;
 Minibatch[ 201- 300]: loss = 0.450016 * 100, metric = 6.84% * 100;
 Minibatch[ 301- 400]: loss = 0.440963 * 100, metric = 6.68% * 100;
 Minibatch[ 401- 500]: loss = 0.443935 * 100, metric = 6.79% * 100;
 Minibatch[ 501- 600]: loss = 0.424171 * 100, metric = 6.23% * 100;
 Minibatch[ 601- 700]: loss = 0.470620 * 100, metric = 7.16% * 100;
 Minibatch[ 701- 800]: loss = 0.436771 * 100, metric = 6.45% * 100;
 Minibatch[ 801- 900]: loss = 0.449984 * 100, metric = 6.87% * 100;
 Minibatch[ 901-1000]: loss = 0.438737 * 100, metric = 6.70% * 100;
 Minibatch[1001-1100]: loss = 0.465313 * 100, metric = 7.38% * 100;
 Minibatch[1101-1200]: loss = 0.443153 * 100, metric = 6.79% * 100;
 Minibatch[1201-1300]: loss = 0.452676 * 100, metric = 6.91% * 100;
 Minibatch[1301-1400]: loss = 0.456232 * 100, metric = 7.21% * 100;
 Minibatch[1401-1500]: loss = 0.440385 * 100, metric = 6.64% * 100;
 Minibatch[1501-1600]: loss = 0.452982 * 100, metric = 7.06% * 100;
 Minibatch[1601-1700]: loss = 0.456466 * 100, metric = 7.02% * 100;
 Minibatch[1701-1800]: loss = 0.445705 * 100, metric = 6.77% * 100;
 Minibatch[1801-1900]: loss = 0.455679 * 100, metric = 7.10% * 100;
 Minibatch[1901-2000]: loss = 0.443439 * 100, metric = 6.69% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.448081 * 2000, metric = 6.85% * 2000 933.823s (  2.1 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 15.62% * 2000;
 Minibatch[   1- 100]: loss = 0.441036 * 100, metric = 6.48% * 100;
 Minibatch[ 101- 200]: loss = 0.428765 * 100, metric = 6.42% * 100;
 Minibatch[ 201- 300]: loss = 0.462162 * 100, metric = 7.24% * 100;
 Minibatch[ 301- 400]: loss = 0.436677 * 100, metric = 6.56% * 100;
 Minibatch[ 401- 500]: loss = 0.437795 * 100, metric = 6.61% * 100;
 Minibatch[ 501- 600]: loss = 0.445611 * 100, metric = 6.79% * 100;
 Minibatch[ 601- 700]: loss = 0.450199 * 100, metric = 6.63% * 100;
 Minibatch[ 701- 800]: loss = 0.426089 * 100, metric = 6.22% * 100;
 Minibatch[ 801- 900]: loss = 0.423712 * 100, metric = 6.49% * 100;
 Minibatch[ 901-1000]: loss = 0.457703 * 100, metric = 6.93% * 100;
 Minibatch[1001-1100]: loss = 0.449998 * 100, metric = 6.96% * 100;
 Minibatch[1101-1200]: loss = 0.440617 * 100, metric = 6.62% * 100;
 Minibatch[1201-1300]: loss = 0.444695 * 100, metric = 6.64% * 100;
 Minibatch[1301-1400]: loss = 0.416966 * 100, metric = 6.16% * 100;
 Minibatch[1401-1500]: loss = 0.434033 * 100, metric = 6.29% * 100;
 Minibatch[1501-1600]: loss = 0.436876 * 100, metric = 6.51% * 100;
 Minibatch[1601-1700]: loss = 0.451928 * 100, metric = 6.98% * 100;
 Minibatch[1701-1800]: loss = 0.439468 * 100, metric = 6.65% * 100;
 Minibatch[1801-1900]: loss = 0.438406 * 100, metric = 6.55% * 100;
 Minibatch[1901-2000]: loss = 0.428106 * 100, metric = 6.28% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.439542 * 2000, metric = 6.60% * 2000 950.550s (  2.1 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 15.57% * 2000;
 Minibatch[   1- 100]: loss = 0.439652 * 100, metric = 6.45% * 100;
 Minibatch[ 101- 200]: loss = 0.447445 * 100, metric = 6.82% * 100;
 Minibatch[ 201- 300]: loss = 0.434445 * 100, metric = 6.53% * 100;
 Minibatch[ 301- 400]: loss = 0.445139 * 100, metric = 6.63% * 100;
 Minibatch[ 401- 500]: loss = 0.446557 * 100, metric = 6.76% * 100;
 Minibatch[ 501- 600]: loss = 0.430354 * 100, metric = 6.51% * 100;
 Minibatch[ 601- 700]: loss = 0.428643 * 100, metric = 6.32% * 100;
 Minibatch[ 701- 800]: loss = 0.443235 * 100, metric = 6.80% * 100;
 Minibatch[ 801- 900]: loss = 0.437066 * 100, metric = 6.49% * 100;
 Minibatch[ 901-1000]: loss = 0.418225 * 100, metric = 5.97% * 100;
 Minibatch[1001-1100]: loss = 0.422752 * 100, metric = 6.36% * 100;
 Minibatch[1101-1200]: loss = 0.454873 * 100, metric = 7.08% * 100;
 Minibatch[1201-1300]: loss = 0.449343 * 100, metric = 6.78% * 100;
 Minibatch[1301-1400]: loss = 0.430327 * 100, metric = 6.32% * 100;
 Minibatch[1401-1500]: loss = 0.433506 * 100, metric = 6.59% * 100;
 Minibatch[1501-1600]: loss = 0.420318 * 100, metric = 6.14% * 100;
 Minibatch[1601-1700]: loss = 0.431310 * 100, metric = 6.54% * 100;
 Minibatch[1701-1800]: loss = 0.428344 * 100, metric = 6.31% * 100;
 Minibatch[1801-1900]: loss = 0.435529 * 100, metric = 6.49% * 100;
 Minibatch[1901-2000]: loss = 0.431093 * 100, metric = 6.34% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.435408 * 2000, metric = 6.51% * 2000 933.421s (  2.1 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 14.43% * 2000;
0.649242259427905
 Minibatch[   1- 100]: loss = 0.438512 * 100, metric = 6.48% * 100;
 Minibatch[ 101- 200]: loss = 0.427277 * 100, metric = 6.45% * 100;
 Minibatch[ 201- 300]: loss = 0.418545 * 100, metric = 6.00% * 100;
 Minibatch[ 301- 400]: loss = 0.423404 * 100, metric = 6.34% * 100;
 Minibatch[ 401- 500]: loss = 0.432378 * 100, metric = 6.42% * 100;
 Minibatch[ 501- 600]: loss = 0.429669 * 100, metric = 6.26% * 100;
 Minibatch[ 601- 700]: loss = 0.434567 * 100, metric = 6.38% * 100;
 Minibatch[ 701- 800]: loss = 0.425852 * 100, metric = 6.08% * 100;
 Minibatch[ 801- 900]: loss = 0.449815 * 100, metric = 6.69% * 100;
 Minibatch[ 901-1000]: loss = 0.442424 * 100, metric = 6.56% * 100;
 Minibatch[1001-1100]: loss = 0.442988 * 100, metric = 6.93% * 100;
 Minibatch[1101-1200]: loss = 0.426190 * 100, metric = 6.45% * 100;
 Minibatch[1201-1300]: loss = 0.430978 * 100, metric = 6.36% * 100;
 Minibatch[1301-1400]: loss = 0.441434 * 100, metric = 6.53% * 100;
 Minibatch[1401-1500]: loss = 0.435800 * 100, metric = 6.50% * 100;
 Minibatch[1501-1600]: loss = 0.443574 * 100, metric = 6.77% * 100;
 Minibatch[1601-1700]: loss = 0.423095 * 100, metric = 6.14% * 100;
 Minibatch[1701-1800]: loss = 0.427753 * 100, metric = 6.61% * 100;
 Minibatch[1801-1900]: loss = 0.436473 * 100, metric = 6.46% * 100;
 Minibatch[1901-2000]: loss = 0.429744 * 100, metric = 6.34% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.433024 * 2000, metric = 6.44% * 2000 975.434s (  2.1 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 14.40% * 2000;
 Minibatch[   1- 100]: loss = 0.420227 * 100, metric = 6.28% * 100;
 Minibatch[ 101- 200]: loss = 0.431391 * 100, metric = 6.35% * 100;
 Minibatch[ 201- 300]: loss = 0.427640 * 100, metric = 6.03% * 100;
 Minibatch[ 301- 400]: loss = 0.423489 * 100, metric = 6.17% * 100;
 Minibatch[ 401- 500]: loss = 0.424428 * 100, metric = 6.33% * 100;
 Minibatch[ 501- 600]: loss = 0.438930 * 100, metric = 6.48% * 100;
 Minibatch[ 601- 700]: loss = 0.426509 * 100, metric = 6.37% * 100;
 Minibatch[ 701- 800]: loss = 0.436154 * 100, metric = 6.37% * 100;
 Minibatch[ 801- 900]: loss = 0.413351 * 100, metric = 6.04% * 100;
 Minibatch[ 901-1000]: loss = 0.418309 * 100, metric = 5.87% * 100;
 Minibatch[1001-1100]: loss = 0.429952 * 100, metric = 6.49% * 100;
 Minibatch[1101-1200]: loss = 0.425652 * 100, metric = 6.30% * 100;
 Minibatch[1201-1300]: loss = 0.422824 * 100, metric = 6.11% * 100;
 Minibatch[1301-1400]: loss = 0.439045 * 100, metric = 6.52% * 100;
 Minibatch[1401-1500]: loss = 0.441222 * 100, metric = 6.62% * 100;
 Minibatch[1501-1600]: loss = 0.430460 * 100, metric = 6.36% * 100;
 Minibatch[1601-1700]: loss = 0.427653 * 100, metric = 6.28% * 100;
 Minibatch[1701-1800]: loss = 0.430959 * 100, metric = 6.57% * 100;
 Minibatch[1801-1900]: loss = 0.435642 * 100, metric = 6.38% * 100;
 Minibatch[1901-2000]: loss = 0.430102 * 100, metric = 6.10% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.428697 * 2000, metric = 6.30% * 2000 955.225s (  2.1 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 15.03% * 2000;
 Minibatch[   1- 100]: loss = 0.428186 * 100, metric = 6.35% * 100;
 Minibatch[ 101- 200]: loss = 0.421486 * 100, metric = 6.31% * 100;
 Minibatch[ 201- 300]: loss = 0.438102 * 100, metric = 6.42% * 100;
 Minibatch[ 301- 400]: loss = 0.427286 * 100, metric = 6.33% * 100;
 Minibatch[ 401- 500]: loss = 0.423905 * 100, metric = 6.29% * 100;
 Minibatch[ 501- 600]: loss = 0.415229 * 100, metric = 6.40% * 100;
 Minibatch[ 601- 700]: loss = 0.436615 * 100, metric = 6.52% * 100;
 Minibatch[ 701- 800]: loss = 0.424451 * 100, metric = 6.29% * 100;
 Minibatch[ 801- 900]: loss = 0.425547 * 100, metric = 6.37% * 100;
 Minibatch[ 901-1000]: loss = 0.427047 * 100, metric = 6.27% * 100;
 Minibatch[1001-1100]: loss = 0.440902 * 100, metric = 6.84% * 100;
 Minibatch[1101-1200]: loss = 0.430830 * 100, metric = 6.48% * 100;
 Minibatch[1201-1300]: loss = 0.425270 * 100, metric = 6.24% * 100;
 Minibatch[1301-1400]: loss = 0.417896 * 100, metric = 6.05% * 100;
 Minibatch[1401-1500]: loss = 0.415104 * 100, metric = 6.17% * 100;
 Minibatch[1501-1600]: loss = 0.433183 * 100, metric = 6.52% * 100;
 Minibatch[1601-1700]: loss = 0.426935 * 100, metric = 6.22% * 100;
 Minibatch[1701-1800]: loss = 0.418000 * 100, metric = 6.07% * 100;
 Minibatch[1801-1900]: loss = 0.418000 * 100, metric = 6.14% * 100;
 Minibatch[1901-2000]: loss = 0.431861 * 100, metric = 6.49% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.426292 * 2000, metric = 6.34% * 2000 945.073s (  2.1 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 15.26% * 2000;
 Minibatch[   1- 100]: loss = 0.416843 * 100, metric = 6.29% * 100;
 Minibatch[ 101- 200]: loss = 0.419112 * 100, metric = 6.08% * 100;
 Minibatch[ 201- 300]: loss = 0.434510 * 100, metric = 6.55% * 100;
 Minibatch[ 301- 400]: loss = 0.427920 * 100, metric = 6.50% * 100;
 Minibatch[ 401- 500]: loss = 0.428335 * 100, metric = 6.45% * 100;
 Minibatch[ 501- 600]: loss = 0.420990 * 100, metric = 6.08% * 100;
 Minibatch[ 601- 700]: loss = 0.422426 * 100, metric = 6.32% * 100;
 Minibatch[ 701- 800]: loss = 0.415210 * 100, metric = 6.08% * 100;
 Minibatch[ 801- 900]: loss = 0.416571 * 100, metric = 6.19% * 100;
 Minibatch[ 901-1000]: loss = 0.419403 * 100, metric = 6.29% * 100;
 Minibatch[1001-1100]: loss = 0.417317 * 100, metric = 6.10% * 100;
 Minibatch[1101-1200]: loss = 0.427886 * 100, metric = 6.37% * 100;
 Minibatch[1201-1300]: loss = 0.418446 * 100, metric = 6.29% * 100;
 Minibatch[1301-1400]: loss = 0.403379 * 100, metric = 5.85% * 100;
 Minibatch[1401-1500]: loss = 0.411392 * 100, metric = 6.10% * 100;
 Minibatch[1501-1600]: loss = 0.420176 * 100, metric = 6.10% * 100;
 Minibatch[1601-1700]: loss = 0.422793 * 100, metric = 6.17% * 100;
 Minibatch[1701-1800]: loss = 0.426669 * 100, metric = 6.48% * 100;
 Minibatch[1801-1900]: loss = 0.418165 * 100, metric = 6.28% * 100;
 Minibatch[1901-2000]: loss = 0.412795 * 100, metric = 5.98% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.420017 * 2000, metric = 6.23% * 2000 962.922s (  2.1 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 15.61% * 2000;
 Minibatch[   1- 100]: loss = 0.407720 * 100, metric = 5.93% * 100;
 Minibatch[ 101- 200]: loss = 0.411258 * 100, metric = 6.18% * 100;
 Minibatch[ 201- 300]: loss = 0.417345 * 100, metric = 6.12% * 100;
 Minibatch[ 301- 400]: loss = 0.405010 * 100, metric = 5.73% * 100;
 Minibatch[ 401- 500]: loss = 0.413420 * 100, metric = 5.81% * 100;
 Minibatch[ 501- 600]: loss = 0.420208 * 100, metric = 6.05% * 100;
 Minibatch[ 601- 700]: loss = 0.419519 * 100, metric = 6.07% * 100;
 Minibatch[ 701- 800]: loss = 0.407128 * 100, metric = 5.88% * 100;
 Minibatch[ 801- 900]: loss = 0.413650 * 100, metric = 6.03% * 100;
 Minibatch[ 901-1000]: loss = 0.423655 * 100, metric = 6.23% * 100;
 Minibatch[1001-1100]: loss = 0.417932 * 100, metric = 6.19% * 100;
 Minibatch[1101-1200]: loss = 0.408606 * 100, metric = 6.06% * 100;
 Minibatch[1201-1300]: loss = 0.403599 * 100, metric = 5.93% * 100;
 Minibatch[1301-1400]: loss = 0.413724 * 100, metric = 6.08% * 100;
 Minibatch[1401-1500]: loss = 0.410444 * 100, metric = 5.84% * 100;
 Minibatch[1501-1600]: loss = 0.410923 * 100, metric = 5.91% * 100;
 Minibatch[1601-1700]: loss = 0.416437 * 100, metric = 6.21% * 100;
 Minibatch[1701-1800]: loss = 0.414010 * 100, metric = 6.02% * 100;
 Minibatch[1801-1900]: loss = 0.411458 * 100, metric = 5.97% * 100;
 Minibatch[1901-2000]: loss = 0.409036 * 100, metric = 5.81% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.412754 * 2000, metric = 6.00% * 2000 919.485s (  2.2 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 14.77% * 2000;
 Minibatch[   1- 100]: loss = 0.425647 * 100, metric = 6.27% * 100;
 Minibatch[ 101- 200]: loss = 0.404268 * 100, metric = 5.73% * 100;
 Minibatch[ 201- 300]: loss = 0.417344 * 100, metric = 5.99% * 100;
 Minibatch[ 301- 400]: loss = 0.412952 * 100, metric = 6.12% * 100;
 Minibatch[ 401- 500]: loss = 0.403501 * 100, metric = 5.88% * 100;
 Minibatch[ 501- 600]: loss = 0.399602 * 100, metric = 5.87% * 100;
 Minibatch[ 601- 700]: loss = 0.417104 * 100, metric = 6.29% * 100;
 Minibatch[ 701- 800]: loss = 0.402422 * 100, metric = 6.07% * 100;
 Minibatch[ 801- 900]: loss = 0.406502 * 100, metric = 5.91% * 100;
 Minibatch[ 901-1000]: loss = 0.414756 * 100, metric = 5.98% * 100;
 Minibatch[1001-1100]: loss = 0.410908 * 100, metric = 6.10% * 100;
 Minibatch[1101-1200]: loss = 0.409075 * 100, metric = 5.98% * 100;
 Minibatch[1201-1300]: loss = 0.418137 * 100, metric = 6.29% * 100;
 Minibatch[1301-1400]: loss = 0.418154 * 100, metric = 6.08% * 100;
 Minibatch[1401-1500]: loss = 0.396816 * 100, metric = 5.71% * 100;
 Minibatch[1501-1600]: loss = 0.421657 * 100, metric = 6.29% * 100;
 Minibatch[1601-1700]: loss = 0.407391 * 100, metric = 6.02% * 100;
 Minibatch[1701-1800]: loss = 0.406109 * 100, metric = 5.99% * 100;
 Minibatch[1801-1900]: loss = 0.408301 * 100, metric = 5.98% * 100;
 Minibatch[1901-2000]: loss = 0.405281 * 100, metric = 5.71% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.410296 * 2000, metric = 6.01% * 2000 938.256s (  2.1 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 14.78% * 2000;
 Minibatch[   1- 100]: loss = 0.403924 * 100, metric = 5.97% * 100;
 Minibatch[ 101- 200]: loss = 0.404302 * 100, metric = 5.84% * 100;
 Minibatch[ 201- 300]: loss = 0.411746 * 100, metric = 6.03% * 100;
 Minibatch[ 301- 400]: loss = 0.416723 * 100, metric = 6.19% * 100;
 Minibatch[ 401- 500]: loss = 0.405364 * 100, metric = 5.77% * 100;
 Minibatch[ 501- 600]: loss = 0.403378 * 100, metric = 5.87% * 100;
 Minibatch[ 601- 700]: loss = 0.415157 * 100, metric = 6.37% * 100;
 Minibatch[ 701- 800]: loss = 0.381211 * 100, metric = 5.17% * 100;
 Minibatch[ 801- 900]: loss = 0.395684 * 100, metric = 5.50% * 100;
 Minibatch[ 901-1000]: loss = 0.389701 * 100, metric = 5.50% * 100;
 Minibatch[1001-1100]: loss = 0.391765 * 100, metric = 5.46% * 100;
 Minibatch[1101-1200]: loss = 0.383749 * 100, metric = 5.29% * 100;
 Minibatch[1201-1300]: loss = 0.402134 * 100, metric = 5.83% * 100;
 Minibatch[1301-1400]: loss = 0.395509 * 100, metric = 5.60% * 100;
 Minibatch[1401-1500]: loss = 0.395790 * 100, metric = 5.67% * 100;
 Minibatch[1501-1600]: loss = 0.387181 * 100, metric = 5.48% * 100;
 Minibatch[1601-1700]: loss = 0.400757 * 100, metric = 5.73% * 100;
 Minibatch[1701-1800]: loss = 0.415688 * 100, metric = 6.16% * 100;
 Minibatch[1801-1900]: loss = 0.396628 * 100, metric = 5.54% * 100;
 Minibatch[1901-2000]: loss = 0.391396 * 100, metric = 5.75% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.399389 * 2000, metric = 5.74% * 2000 921.461s (  2.2 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 14.94% * 2000;
 Minibatch[   1- 100]: loss = 0.404622 * 100, metric = 5.71% * 100;
 Minibatch[ 101- 200]: loss = 0.398823 * 100, metric = 5.52% * 100;
 Minibatch[ 201- 300]: loss = 0.393328 * 100, metric = 5.63% * 100;
 Minibatch[ 301- 400]: loss = 0.413073 * 100, metric = 6.17% * 100;
 Minibatch[ 401- 500]: loss = 0.393214 * 100, metric = 5.60% * 100;
 Minibatch[ 501- 600]: loss = 0.389090 * 100, metric = 5.42% * 100;
 Minibatch[ 601- 700]: loss = 0.389149 * 100, metric = 5.47% * 100;
 Minibatch[ 701- 800]: loss = 0.384548 * 100, metric = 5.57% * 100;
 Minibatch[ 801- 900]: loss = 0.411345 * 100, metric = 6.18% * 100;
 Minibatch[ 901-1000]: loss = 0.394633 * 100, metric = 5.56% * 100;
 Minibatch[1001-1100]: loss = 0.394302 * 100, metric = 5.66% * 100;
 Minibatch[1101-1200]: loss = 0.408076 * 100, metric = 5.80% * 100;
 Minibatch[1201-1300]: loss = 0.399278 * 100, metric = 5.70% * 100;
 Minibatch[1301-1400]: loss = 0.394259 * 100, metric = 5.58% * 100;
 Minibatch[1401-1500]: loss = 0.405963 * 100, metric = 5.98% * 100;
 Minibatch[1501-1600]: loss = 0.391686 * 100, metric = 5.71% * 100;
 Minibatch[1601-1700]: loss = 0.383662 * 100, metric = 5.61% * 100;
 Minibatch[1701-1800]: loss = 0.397784 * 100, metric = 5.75% * 100;
 Minibatch[1801-1900]: loss = 0.394153 * 100, metric = 5.78% * 100;
 Minibatch[1901-2000]: loss = 0.404916 * 100, metric = 5.67% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.397295 * 2000, metric = 5.70% * 2000 937.010s (  2.1 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 15.59% * 2000;
 Minibatch[   1- 100]: loss = 0.385264 * 100, metric = 5.65% * 100;
 Minibatch[ 101- 200]: loss = 0.413185 * 100, metric = 6.07% * 100;
 Minibatch[ 201- 300]: loss = 0.387654 * 100, metric = 5.65% * 100;
 Minibatch[ 301- 400]: loss = 0.410552 * 100, metric = 6.11% * 100;
 Minibatch[ 401- 500]: loss = 0.392949 * 100, metric = 5.59% * 100;
 Minibatch[ 501- 600]: loss = 0.386673 * 100, metric = 5.55% * 100;
 Minibatch[ 601- 700]: loss = 0.377220 * 100, metric = 5.11% * 100;
 Minibatch[ 701- 800]: loss = 0.382686 * 100, metric = 5.34% * 100;
 Minibatch[ 801- 900]: loss = 0.394786 * 100, metric = 5.62% * 100;
 Minibatch[ 901-1000]: loss = 0.392048 * 100, metric = 5.50% * 100;
 Minibatch[1001-1100]: loss = 0.387686 * 100, metric = 5.55% * 100;
 Minibatch[1101-1200]: loss = 0.395662 * 100, metric = 5.78% * 100;
 Minibatch[1201-1300]: loss = 0.403051 * 100, metric = 5.73% * 100;
 Minibatch[1301-1400]: loss = 0.393886 * 100, metric = 5.68% * 100;
 Minibatch[1401-1500]: loss = 0.390295 * 100, metric = 5.72% * 100;
 Minibatch[1501-1600]: loss = 0.395134 * 100, metric = 5.52% * 100;
 Minibatch[1601-1700]: loss = 0.372423 * 100, metric = 5.31% * 100;
 Minibatch[1701-1800]: loss = 0.398881 * 100, metric = 5.79% * 100;
 Minibatch[1801-1900]: loss = 0.381674 * 100, metric = 5.29% * 100;
 Minibatch[1901-2000]: loss = 0.387219 * 100, metric = 5.47% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.391446 * 2000, metric = 5.60% * 2000 958.652s (  2.1 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 14.31% * 2000;
 Minibatch[   1- 100]: loss = 0.396387 * 100, metric = 5.58% * 100;
 Minibatch[ 101- 200]: loss = 0.384458 * 100, metric = 5.50% * 100;
 Minibatch[ 201- 300]: loss = 0.393817 * 100, metric = 5.55% * 100;
 Minibatch[ 301- 400]: loss = 0.378983 * 100, metric = 5.39% * 100;
 Minibatch[ 401- 500]: loss = 0.385100 * 100, metric = 5.56% * 100;
 Minibatch[ 501- 600]: loss = 0.380596 * 100, metric = 5.50% * 100;
 Minibatch[ 601- 700]: loss = 0.389183 * 100, metric = 5.65% * 100;
 Minibatch[ 701- 800]: loss = 0.396270 * 100, metric = 5.73% * 100;
 Minibatch[ 801- 900]: loss = 0.395557 * 100, metric = 5.45% * 100;
 Minibatch[ 901-1000]: loss = 0.392987 * 100, metric = 5.47% * 100;
 Minibatch[1001-1100]: loss = 0.405573 * 100, metric = 5.94% * 100;
 Minibatch[1101-1200]: loss = 0.395056 * 100, metric = 5.43% * 100;
 Minibatch[1201-1300]: loss = 0.370527 * 100, metric = 5.21% * 100;
 Minibatch[1301-1400]: loss = 0.390564 * 100, metric = 5.64% * 100;
 Minibatch[1401-1500]: loss = 0.389073 * 100, metric = 5.64% * 100;
 Minibatch[1501-1600]: loss = 0.400316 * 100, metric = 5.64% * 100;
 Minibatch[1601-1700]: loss = 0.377526 * 100, metric = 5.26% * 100;
 Minibatch[1701-1800]: loss = 0.399095 * 100, metric = 5.63% * 100;
 Minibatch[1801-1900]: loss = 0.389185 * 100, metric = 5.54% * 100;
 Minibatch[1901-2000]: loss = 0.396146 * 100, metric = 5.61% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.390320 * 2000, metric = 5.55% * 2000 915.544s (  2.2 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 14.20% * 2000;
 Minibatch[   1- 100]: loss = 0.391139 * 100, metric = 5.55% * 100;
 Minibatch[ 101- 200]: loss = 0.390650 * 100, metric = 5.48% * 100;
 Minibatch[ 201- 300]: loss = 0.386873 * 100, metric = 5.62% * 100;
 Minibatch[ 301- 400]: loss = 0.379861 * 100, metric = 5.38% * 100;
 Minibatch[ 401- 500]: loss = 0.400884 * 100, metric = 5.81% * 100;
 Minibatch[ 501- 600]: loss = 0.403434 * 100, metric = 5.73% * 100;
 Minibatch[ 601- 700]: loss = 0.404678 * 100, metric = 5.91% * 100;
 Minibatch[ 701- 800]: loss = 0.391034 * 100, metric = 5.37% * 100;
 Minibatch[ 801- 900]: loss = 0.379944 * 100, metric = 5.31% * 100;
 Minibatch[ 901-1000]: loss = 0.391004 * 100, metric = 5.69% * 100;
 Minibatch[1001-1100]: loss = 0.382858 * 100, metric = 5.41% * 100;
 Minibatch[1101-1200]: loss = 0.384376 * 100, metric = 5.38% * 100;
 Minibatch[1201-1300]: loss = 0.379736 * 100, metric = 5.48% * 100;
 Minibatch[1301-1400]: loss = 0.374127 * 100, metric = 5.33% * 100;
 Minibatch[1401-1500]: loss = 0.386533 * 100, metric = 5.62% * 100;
 Minibatch[1501-1600]: loss = 0.384014 * 100, metric = 5.56% * 100;
 Minibatch[1601-1700]: loss = 0.375330 * 100, metric = 5.33% * 100;
 Minibatch[1701-1800]: loss = 0.386343 * 100, metric = 5.31% * 100;
 Minibatch[1801-1900]: loss = 0.386265 * 100, metric = 5.49% * 100;
 Minibatch[1901-2000]: loss = 0.377175 * 100, metric = 5.32% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.386813 * 2000, metric = 5.50% * 2000 935.458s (  2.1 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 15.58% * 2000;
 Minibatch[   1- 100]: loss = 0.400251 * 100, metric = 5.84% * 100;
 Minibatch[ 101- 200]: loss = 0.382098 * 100, metric = 5.30% * 100;
 Minibatch[ 201- 300]: loss = 0.390503 * 100, metric = 5.57% * 100;
 Minibatch[ 301- 400]: loss = 0.386478 * 100, metric = 5.55% * 100;
 Minibatch[ 401- 500]: loss = 0.396458 * 100, metric = 5.80% * 100;
 Minibatch[ 501- 600]: loss = 0.386030 * 100, metric = 5.62% * 100;
 Minibatch[ 601- 700]: loss = 0.381378 * 100, metric = 5.50% * 100;
 Minibatch[ 701- 800]: loss = 0.384437 * 100, metric = 5.42% * 100;
 Minibatch[ 801- 900]: loss = 0.378562 * 100, metric = 5.29% * 100;
 Minibatch[ 901-1000]: loss = 0.391283 * 100, metric = 5.52% * 100;
 Minibatch[1001-1100]: loss = 0.389534 * 100, metric = 5.64% * 100;
 Minibatch[1101-1200]: loss = 0.397831 * 100, metric = 5.80% * 100;
 Minibatch[1201-1300]: loss = 0.371851 * 100, metric = 5.22% * 100;
 Minibatch[1301-1400]: loss = 0.390392 * 100, metric = 5.56% * 100;
 Minibatch[1401-1500]: loss = 0.377237 * 100, metric = 5.44% * 100;
 Minibatch[1501-1600]: loss = 0.362896 * 100, metric = 4.96% * 100;
 Minibatch[1601-1700]: loss = 0.401143 * 100, metric = 6.06% * 100;
 Minibatch[1701-1800]: loss = 0.380225 * 100, metric = 5.39% * 100;
 Minibatch[1801-1900]: loss = 0.385244 * 100, metric = 5.52% * 100;
 Minibatch[1901-2000]: loss = 0.378154 * 100, metric = 5.41% * 100;
Finished Epoch[49 of 200]: [Training] loss = 0.385599 * 2000, metric = 5.52% * 2000 947.498s (  2.1 samples/s);
Finished Evaluation [49]: Minibatch[1-2000]: metric = 14.00% * 2000;
 Minibatch[   1- 100]: loss = 0.385923 * 100, metric = 5.59% * 100;
 Minibatch[ 101- 200]: loss = 0.375862 * 100, metric = 5.38% * 100;
 Minibatch[ 201- 300]: loss = 0.375561 * 100, metric = 5.37% * 100;
 Minibatch[ 301- 400]: loss = 0.382307 * 100, metric = 5.27% * 100;
 Minibatch[ 401- 500]: loss = 0.388246 * 100, metric = 5.58% * 100;
 Minibatch[ 501- 600]: loss = 0.393893 * 100, metric = 5.88% * 100;
 Minibatch[ 601- 700]: loss = 0.366579 * 100, metric = 5.20% * 100;
 Minibatch[ 701- 800]: loss = 0.368166 * 100, metric = 5.18% * 100;
 Minibatch[ 801- 900]: loss = 0.382233 * 100, metric = 5.28% * 100;
 Minibatch[ 901-1000]: loss = 0.382385 * 100, metric = 5.28% * 100;
 Minibatch[1001-1100]: loss = 0.383686 * 100, metric = 5.67% * 100;
 Minibatch[1101-1200]: loss = 0.381272 * 100, metric = 5.55% * 100;
 Minibatch[1201-1300]: loss = 0.383661 * 100, metric = 5.76% * 100;
 Minibatch[1301-1400]: loss = 0.370423 * 100, metric = 5.38% * 100;
 Minibatch[1401-1500]: loss = 0.394362 * 100, metric = 5.79% * 100;
 Minibatch[1501-1600]: loss = 0.373506 * 100, metric = 5.30% * 100;
 Minibatch[1601-1700]: loss = 0.375607 * 100, metric = 5.27% * 100;
 Minibatch[1701-1800]: loss = 0.388564 * 100, metric = 5.58% * 100;
 Minibatch[1801-1900]: loss = 0.391237 * 100, metric = 5.49% * 100;
 Minibatch[1901-2000]: loss = 0.380758 * 100, metric = 5.46% * 100;
Finished Epoch[50 of 200]: [Training] loss = 0.381212 * 2000, metric = 5.46% * 2000 922.662s (  2.2 samples/s);
Finished Evaluation [50]: Minibatch[1-2000]: metric = 15.01% * 2000;
 Minibatch[   1- 100]: loss = 0.373533 * 100, metric = 5.22% * 100;
 Minibatch[ 101- 200]: loss = 0.386521 * 100, metric = 5.59% * 100;
 Minibatch[ 201- 300]: loss = 0.387216 * 100, metric = 5.36% * 100;
 Minibatch[ 301- 400]: loss = 0.377780 * 100, metric = 5.32% * 100;
 Minibatch[ 401- 500]: loss = 0.377884 * 100, metric = 5.26% * 100;
 Minibatch[ 501- 600]: loss = 0.383014 * 100, metric = 5.51% * 100;
 Minibatch[ 601- 700]: loss = 0.366882 * 100, metric = 5.23% * 100;
 Minibatch[ 701- 800]: loss = 0.385360 * 100, metric = 5.29% * 100;
 Minibatch[ 801- 900]: loss = 0.382866 * 100, metric = 5.44% * 100;
 Minibatch[ 901-1000]: loss = 0.374794 * 100, metric = 5.23% * 100;
 Minibatch[1001-1100]: loss = 0.378586 * 100, metric = 5.34% * 100;
 Minibatch[1101-1200]: loss = 0.383936 * 100, metric = 5.44% * 100;
 Minibatch[1201-1300]: loss = 0.394001 * 100, metric = 5.48% * 100;
 Minibatch[1301-1400]: loss = 0.376138 * 100, metric = 5.20% * 100;
 Minibatch[1401-1500]: loss = 0.375993 * 100, metric = 5.17% * 100;
 Minibatch[1501-1600]: loss = 0.392904 * 100, metric = 5.64% * 100;
 Minibatch[1601-1700]: loss = 0.360822 * 100, metric = 5.04% * 100;
 Minibatch[1701-1800]: loss = 0.380594 * 100, metric = 5.54% * 100;
 Minibatch[1801-1900]: loss = 0.361485 * 100, metric = 5.12% * 100;
 Minibatch[1901-2000]: loss = 0.372047 * 100, metric = 5.25% * 100;
Finished Epoch[51 of 200]: [Training] loss = 0.378618 * 2000, metric = 5.33% * 2000 938.132s (  2.1 samples/s);
Finished Evaluation [51]: Minibatch[1-2000]: metric = 13.82% * 2000;
0.644523274898529
 Minibatch[   1- 100]: loss = 0.362192 * 100, metric = 5.10% * 100;
 Minibatch[ 101- 200]: loss = 0.374134 * 100, metric = 5.21% * 100;
 Minibatch[ 201- 300]: loss = 0.384572 * 100, metric = 5.56% * 100;
 Minibatch[ 301- 400]: loss = 0.373665 * 100, metric = 5.32% * 100;
 Minibatch[ 401- 500]: loss = 0.387721 * 100, metric = 5.48% * 100;
 Minibatch[ 501- 600]: loss = 0.379943 * 100, metric = 5.48% * 100;
 Minibatch[ 601- 700]: loss = 0.366107 * 100, metric = 5.03% * 100;
 Minibatch[ 701- 800]: loss = 0.381980 * 100, metric = 5.43% * 100;
 Minibatch[ 801- 900]: loss = 0.388331 * 100, metric = 5.51% * 100;
 Minibatch[ 901-1000]: loss = 0.388516 * 100, metric = 5.57% * 100;
 Minibatch[1001-1100]: loss = 0.376956 * 100, metric = 5.42% * 100;
 Minibatch[1101-1200]: loss = 0.369823 * 100, metric = 4.94% * 100;
 Minibatch[1201-1300]: loss = 0.362808 * 100, metric = 5.04% * 100;
 Minibatch[1301-1400]: loss = 0.368158 * 100, metric = 5.03% * 100;
 Minibatch[1401-1500]: loss = 0.357350 * 100, metric = 4.87% * 100;
 Minibatch[1501-1600]: loss = 0.358989 * 100, metric = 4.93% * 100;
 Minibatch[1601-1700]: loss = 0.380455 * 100, metric = 5.37% * 100;
 Minibatch[1701-1800]: loss = 0.366669 * 100, metric = 5.21% * 100;
 Minibatch[1801-1900]: loss = 0.369949 * 100, metric = 5.10% * 100;
 Minibatch[1901-2000]: loss = 0.379274 * 100, metric = 5.46% * 100;
Finished Epoch[52 of 200]: [Training] loss = 0.373880 * 2000, metric = 5.25% * 2000 923.770s (  2.2 samples/s);
Finished Evaluation [52]: Minibatch[1-2000]: metric = 15.31% * 2000;
 Minibatch[   1- 100]: loss = 0.373104 * 100, metric = 5.26% * 100;
 Minibatch[ 101- 200]: loss = 0.358563 * 100, metric = 4.85% * 100;
 Minibatch[ 201- 300]: loss = 0.379500 * 100, metric = 5.28% * 100;
 Minibatch[ 301- 400]: loss = 0.374561 * 100, metric = 5.22% * 100;
 Minibatch[ 401- 500]: loss = 0.373190 * 100, metric = 5.39% * 100;
 Minibatch[ 501- 600]: loss = 0.366289 * 100, metric = 5.15% * 100;
 Minibatch[ 601- 700]: loss = 0.366099 * 100, metric = 4.98% * 100;
 Minibatch[ 701- 800]: loss = 0.371574 * 100, metric = 5.15% * 100;
 Minibatch[ 801- 900]: loss = 0.371329 * 100, metric = 5.23% * 100;
 Minibatch[ 901-1000]: loss = 0.378510 * 100, metric = 5.51% * 100;
 Minibatch[1001-1100]: loss = 0.377908 * 100, metric = 5.38% * 100;
 Minibatch[1101-1200]: loss = 0.363838 * 100, metric = 5.01% * 100;
 Minibatch[1201-1300]: loss = 0.371693 * 100, metric = 5.41% * 100;
 Minibatch[1301-1400]: loss = 0.374435 * 100, metric = 5.09% * 100;
 Minibatch[1401-1500]: loss = 0.368510 * 100, metric = 5.17% * 100;
 Minibatch[1501-1600]: loss = 0.376819 * 100, metric = 5.46% * 100;
 Minibatch[1601-1700]: loss = 0.371452 * 100, metric = 5.07% * 100;
 Minibatch[1701-1800]: loss = 0.387698 * 100, metric = 5.63% * 100;
 Minibatch[1801-1900]: loss = 0.386175 * 100, metric = 5.36% * 100;
 Minibatch[1901-2000]: loss = 0.357376 * 100, metric = 4.80% * 100;
Finished Epoch[53 of 200]: [Training] loss = 0.372431 * 2000, metric = 5.22% * 2000 940.791s (  2.1 samples/s);
Finished Evaluation [53]: Minibatch[1-2000]: metric = 14.43% * 2000;
 Minibatch[   1- 100]: loss = 0.370383 * 100, metric = 5.21% * 100;
 Minibatch[ 101- 200]: loss = 0.374540 * 100, metric = 5.35% * 100;
 Minibatch[ 201- 300]: loss = 0.365114 * 100, metric = 4.97% * 100;
 Minibatch[ 301- 400]: loss = 0.367117 * 100, metric = 4.98% * 100;
 Minibatch[ 401- 500]: loss = 0.374498 * 100, metric = 5.29% * 100;
 Minibatch[ 501- 600]: loss = 0.360235 * 100, metric = 4.81% * 100;
 Minibatch[ 601- 700]: loss = 0.378812 * 100, metric = 5.26% * 100;
 Minibatch[ 701- 800]: loss = 0.377761 * 100, metric = 5.26% * 100;
 Minibatch[ 801- 900]: loss = 0.346646 * 100, metric = 4.47% * 100;
 Minibatch[ 901-1000]: loss = 0.371070 * 100, metric = 5.07% * 100;
 Minibatch[1001-1100]: loss = 0.359732 * 100, metric = 4.88% * 100;
 Minibatch[1101-1200]: loss = 0.359005 * 100, metric = 4.98% * 100;
 Minibatch[1201-1300]: loss = 0.363816 * 100, metric = 5.05% * 100;
 Minibatch[1301-1400]: loss = 0.369089 * 100, metric = 5.26% * 100;
 Minibatch[1401-1500]: loss = 0.374849 * 100, metric = 5.36% * 100;
 Minibatch[1501-1600]: loss = 0.368810 * 100, metric = 5.18% * 100;
 Minibatch[1601-1700]: loss = 0.363323 * 100, metric = 5.19% * 100;
 Minibatch[1701-1800]: loss = 0.366977 * 100, metric = 5.20% * 100;
 Minibatch[1801-1900]: loss = 0.371264 * 100, metric = 5.38% * 100;
 Minibatch[1901-2000]: loss = 0.376813 * 100, metric = 5.40% * 100;
Finished Epoch[54 of 200]: [Training] loss = 0.367993 * 2000, metric = 5.13% * 2000 925.398s (  2.2 samples/s);
Finished Evaluation [54]: Minibatch[1-2000]: metric = 13.33% * 2000;
0.6422063818462193
 Minibatch[   1- 100]: loss = 0.375404 * 100, metric = 5.23% * 100;
 Minibatch[ 101- 200]: loss = 0.372834 * 100, metric = 5.31% * 100;
 Minibatch[ 201- 300]: loss = 0.369339 * 100, metric = 5.28% * 100;
 Minibatch[ 301- 400]: loss = 0.356359 * 100, metric = 4.91% * 100;
 Minibatch[ 401- 500]: loss = 0.367416 * 100, metric = 4.96% * 100;
 Minibatch[ 501- 600]: loss = 0.369866 * 100, metric = 5.10% * 100;
 Minibatch[ 601- 700]: loss = 0.370268 * 100, metric = 5.42% * 100;
 Minibatch[ 701- 800]: loss = 0.383629 * 100, metric = 5.46% * 100;
 Minibatch[ 801- 900]: loss = 0.369280 * 100, metric = 5.13% * 100;
 Minibatch[ 901-1000]: loss = 0.359205 * 100, metric = 4.93% * 100;
 Minibatch[1001-1100]: loss = 0.369249 * 100, metric = 5.16% * 100;
 Minibatch[1101-1200]: loss = 0.370394 * 100, metric = 5.16% * 100;
 Minibatch[1201-1300]: loss = 0.360236 * 100, metric = 4.97% * 100;
 Minibatch[1301-1400]: loss = 0.353123 * 100, metric = 4.84% * 100;
 Minibatch[1401-1500]: loss = 0.353549 * 100, metric = 4.92% * 100;
 Minibatch[1501-1600]: loss = 0.368052 * 100, metric = 5.06% * 100;
 Minibatch[1601-1700]: loss = 0.374359 * 100, metric = 5.41% * 100;
 Minibatch[1701-1800]: loss = 0.370656 * 100, metric = 5.23% * 100;
 Minibatch[1801-1900]: loss = 0.350654 * 100, metric = 4.76% * 100;
 Minibatch[1901-2000]: loss = 0.358807 * 100, metric = 5.03% * 100;
Finished Epoch[55 of 200]: [Training] loss = 0.366134 * 2000, metric = 5.11% * 2000 924.544s (  2.2 samples/s);
Finished Evaluation [55]: Minibatch[1-2000]: metric = 13.60% * 2000;
 Minibatch[   1- 100]: loss = 0.362193 * 100, metric = 5.25% * 100;
 Minibatch[ 101- 200]: loss = 0.363279 * 100, metric = 4.91% * 100;
 Minibatch[ 201- 300]: loss = 0.377145 * 100, metric = 5.42% * 100;
 Minibatch[ 301- 400]: loss = 0.372323 * 100, metric = 5.08% * 100;
 Minibatch[ 401- 500]: loss = 0.374046 * 100, metric = 5.38% * 100;
 Minibatch[ 501- 600]: loss = 0.384087 * 100, metric = 5.44% * 100;
 Minibatch[ 601- 700]: loss = 0.358870 * 100, metric = 4.81% * 100;
 Minibatch[ 701- 800]: loss = 0.370085 * 100, metric = 5.16% * 100;
 Minibatch[ 801- 900]: loss = 0.368981 * 100, metric = 5.24% * 100;
 Minibatch[ 901-1000]: loss = 0.368862 * 100, metric = 5.16% * 100;
 Minibatch[1001-1100]: loss = 0.370124 * 100, metric = 5.22% * 100;
 Minibatch[1101-1200]: loss = 0.366023 * 100, metric = 5.16% * 100;
 Minibatch[1201-1300]: loss = 0.365454 * 100, metric = 4.88% * 100;
 Minibatch[1301-1400]: loss = 0.352088 * 100, metric = 4.79% * 100;
 Minibatch[1401-1500]: loss = 0.375189 * 100, metric = 5.28% * 100;
 Minibatch[1501-1600]: loss = 0.356149 * 100, metric = 4.88% * 100;
 Minibatch[1601-1700]: loss = 0.365308 * 100, metric = 4.85% * 100;
 Minibatch[1701-1800]: loss = 0.366505 * 100, metric = 5.12% * 100;
 Minibatch[1801-1900]: loss = 0.361030 * 100, metric = 4.83% * 100;
 Minibatch[1901-2000]: loss = 0.381159 * 100, metric = 5.43% * 100;
Finished Epoch[56 of 200]: [Training] loss = 0.367945 * 2000, metric = 5.11% * 2000 942.720s (  2.1 samples/s);
Finished Evaluation [56]: Minibatch[1-2000]: metric = 13.46% * 2000;
 Minibatch[   1- 100]: loss = 0.372910 * 100, metric = 5.28% * 100;
 Minibatch[ 101- 200]: loss = 0.349902 * 100, metric = 4.85% * 100;
 Minibatch[ 201- 300]: loss = 0.353090 * 100, metric = 4.98% * 100;
 Minibatch[ 301- 400]: loss = 0.368497 * 100, metric = 5.08% * 100;
 Minibatch[ 401- 500]: loss = 0.366206 * 100, metric = 4.99% * 100;
 Minibatch[ 501- 600]: loss = 0.348958 * 100, metric = 4.86% * 100;
 Minibatch[ 601- 700]: loss = 0.369868 * 100, metric = 5.10% * 100;
 Minibatch[ 701- 800]: loss = 0.352372 * 100, metric = 4.75% * 100;
 Minibatch[ 801- 900]: loss = 0.359716 * 100, metric = 5.08% * 100;
 Minibatch[ 901-1000]: loss = 0.361933 * 100, metric = 4.92% * 100;
 Minibatch[1001-1100]: loss = 0.368390 * 100, metric = 5.12% * 100;
 Minibatch[1101-1200]: loss = 0.352927 * 100, metric = 4.82% * 100;
 Minibatch[1201-1300]: loss = 0.360929 * 100, metric = 5.13% * 100;
 Minibatch[1301-1400]: loss = 0.348515 * 100, metric = 4.68% * 100;
 Minibatch[1401-1500]: loss = 0.368127 * 100, metric = 5.26% * 100;
 Minibatch[1501-1600]: loss = 0.353354 * 100, metric = 4.80% * 100;
 Minibatch[1601-1700]: loss = 0.356894 * 100, metric = 4.76% * 100;
 Minibatch[1701-1800]: loss = 0.355598 * 100, metric = 4.97% * 100;
 Minibatch[1801-1900]: loss = 0.366568 * 100, metric = 5.17% * 100;
 Minibatch[1901-2000]: loss = 0.360241 * 100, metric = 5.00% * 100;
Finished Epoch[57 of 200]: [Training] loss = 0.359750 * 2000, metric = 4.98% * 2000 928.079s (  2.2 samples/s);
Finished Evaluation [57]: Minibatch[1-2000]: metric = 14.18% * 2000;
 Minibatch[   1- 100]: loss = 0.353471 * 100, metric = 4.65% * 100;
 Minibatch[ 101- 200]: loss = 0.362302 * 100, metric = 5.06% * 100;
 Minibatch[ 201- 300]: loss = 0.353329 * 100, metric = 4.93% * 100;
 Minibatch[ 301- 400]: loss = 0.368569 * 100, metric = 5.13% * 100;
 Minibatch[ 401- 500]: loss = 0.379680 * 100, metric = 5.57% * 100;
 Minibatch[ 501- 600]: loss = 0.354874 * 100, metric = 4.88% * 100;
 Minibatch[ 601- 700]: loss = 0.368415 * 100, metric = 5.21% * 100;
 Minibatch[ 701- 800]: loss = 0.371348 * 100, metric = 5.19% * 100;
 Minibatch[ 801- 900]: loss = 0.361575 * 100, metric = 4.98% * 100;
 Minibatch[ 901-1000]: loss = 0.350712 * 100, metric = 4.79% * 100;
 Minibatch[1001-1100]: loss = 0.358893 * 100, metric = 4.98% * 100;
 Minibatch[1101-1200]: loss = 0.357327 * 100, metric = 4.92% * 100;
 Minibatch[1201-1300]: loss = 0.352096 * 100, metric = 4.89% * 100;
 Minibatch[1301-1400]: loss = 0.354009 * 100, metric = 4.88% * 100;
 Minibatch[1401-1500]: loss = 0.354763 * 100, metric = 4.76% * 100;
 Minibatch[1501-1600]: loss = 0.356932 * 100, metric = 4.96% * 100;
 Minibatch[1601-1700]: loss = 0.363681 * 100, metric = 5.18% * 100;
 Minibatch[1701-1800]: loss = 0.355656 * 100, metric = 4.99% * 100;
 Minibatch[1801-1900]: loss = 0.356143 * 100, metric = 5.06% * 100;
 Minibatch[1901-2000]: loss = 0.344197 * 100, metric = 4.50% * 100;
Finished Epoch[58 of 200]: [Training] loss = 0.358899 * 2000, metric = 4.98% * 2000 934.498s (  2.1 samples/s);
Finished Evaluation [58]: Minibatch[1-2000]: metric = 14.40% * 2000;
 Minibatch[   1- 100]: loss = 0.365741 * 100, metric = 5.02% * 100;
 Minibatch[ 101- 200]: loss = 0.371697 * 100, metric = 5.36% * 100;
 Minibatch[ 201- 300]: loss = 0.354498 * 100, metric = 5.03% * 100;
 Minibatch[ 301- 400]: loss = 0.344759 * 100, metric = 4.56% * 100;
 Minibatch[ 401- 500]: loss = 0.346678 * 100, metric = 4.72% * 100;
 Minibatch[ 501- 600]: loss = 0.342438 * 100, metric = 4.70% * 100;
 Minibatch[ 601- 700]: loss = 0.354458 * 100, metric = 4.88% * 100;
 Minibatch[ 701- 800]: loss = 0.359492 * 100, metric = 4.84% * 100;
 Minibatch[ 801- 900]: loss = 0.349664 * 100, metric = 4.94% * 100;
 Minibatch[ 901-1000]: loss = 0.359702 * 100, metric = 5.12% * 100;
 Minibatch[1001-1100]: loss = 0.341349 * 100, metric = 4.72% * 100;
 Minibatch[1101-1200]: loss = 0.358270 * 100, metric = 4.93% * 100;
 Minibatch[1201-1300]: loss = 0.365004 * 100, metric = 5.00% * 100;
 Minibatch[1301-1400]: loss = 0.359044 * 100, metric = 4.86% * 100;
 Minibatch[1401-1500]: loss = 0.360254 * 100, metric = 4.99% * 100;
 Minibatch[1501-1600]: loss = 0.351396 * 100, metric = 4.79% * 100;
 Minibatch[1601-1700]: loss = 0.357890 * 100, metric = 4.98% * 100;
 Minibatch[1701-1800]: loss = 0.352650 * 100, metric = 4.78% * 100;
 Minibatch[1801-1900]: loss = 0.354129 * 100, metric = 4.91% * 100;
 Minibatch[1901-2000]: loss = 0.361918 * 100, metric = 4.92% * 100;
Finished Epoch[59 of 200]: [Training] loss = 0.355551 * 2000, metric = 4.90% * 2000 913.565s (  2.2 samples/s);
Finished Evaluation [59]: Minibatch[1-2000]: metric = 14.41% * 2000;
 Minibatch[   1- 100]: loss = 0.347036 * 100, metric = 4.58% * 100;
 Minibatch[ 101- 200]: loss = 0.346002 * 100, metric = 4.69% * 100;
 Minibatch[ 201- 300]: loss = 0.337124 * 100, metric = 4.40% * 100;
 Minibatch[ 301- 400]: loss = 0.361011 * 100, metric = 4.94% * 100;
 Minibatch[ 401- 500]: loss = 0.371856 * 100, metric = 5.23% * 100;
 Minibatch[ 501- 600]: loss = 0.360616 * 100, metric = 5.29% * 100;
 Minibatch[ 601- 700]: loss = 0.340191 * 100, metric = 4.59% * 100;
 Minibatch[ 701- 800]: loss = 0.357397 * 100, metric = 4.76% * 100;
 Minibatch[ 801- 900]: loss = 0.352570 * 100, metric = 4.99% * 100;
 Minibatch[ 901-1000]: loss = 0.354398 * 100, metric = 4.88% * 100;
 Minibatch[1001-1100]: loss = 0.364713 * 100, metric = 5.11% * 100;
 Minibatch[1101-1200]: loss = 0.359978 * 100, metric = 4.84% * 100;
 Minibatch[1201-1300]: loss = 0.367225 * 100, metric = 5.08% * 100;
 Minibatch[1301-1400]: loss = 0.357675 * 100, metric = 5.03% * 100;
 Minibatch[1401-1500]: loss = 0.338962 * 100, metric = 4.57% * 100;
 Minibatch[1501-1600]: loss = 0.360912 * 100, metric = 5.06% * 100;
 Minibatch[1601-1700]: loss = 0.359581 * 100, metric = 5.03% * 100;
 Minibatch[1701-1800]: loss = 0.356974 * 100, metric = 4.80% * 100;
 Minibatch[1801-1900]: loss = 0.359717 * 100, metric = 5.03% * 100;
 Minibatch[1901-2000]: loss = 0.349968 * 100, metric = 4.78% * 100;
Finished Epoch[60 of 200]: [Training] loss = 0.355195 * 2000, metric = 4.88% * 2000 943.389s (  2.1 samples/s);
Finished Evaluation [60]: Minibatch[1-2000]: metric = 14.84% * 2000;
 Minibatch[   1- 100]: loss = 0.361768 * 100, metric = 4.88% * 100;
 Minibatch[ 101- 200]: loss = 0.337540 * 100, metric = 4.45% * 100;
 Minibatch[ 201- 300]: loss = 0.350201 * 100, metric = 4.71% * 100;
 Minibatch[ 301- 400]: loss = 0.353084 * 100, metric = 4.79% * 100;
 Minibatch[ 401- 500]: loss = 0.339747 * 100, metric = 4.69% * 100;
 Minibatch[ 501- 600]: loss = 0.330217 * 100, metric = 4.43% * 100;
 Minibatch[ 601- 700]: loss = 0.350785 * 100, metric = 4.57% * 100;
 Minibatch[ 701- 800]: loss = 0.352804 * 100, metric = 4.85% * 100;
 Minibatch[ 801- 900]: loss = 0.340268 * 100, metric = 4.65% * 100;
 Minibatch[ 901-1000]: loss = 0.343042 * 100, metric = 4.65% * 100;
 Minibatch[1001-1100]: loss = 0.348692 * 100, metric = 4.86% * 100;
 Minibatch[1101-1200]: loss = 0.354059 * 100, metric = 4.99% * 100;
 Minibatch[1201-1300]: loss = 0.339609 * 100, metric = 4.60% * 100;
 Minibatch[1301-1400]: loss = 0.330544 * 100, metric = 4.21% * 100;
 Minibatch[1401-1500]: loss = 0.349303 * 100, metric = 4.72% * 100;
 Minibatch[1501-1600]: loss = 0.355631 * 100, metric = 5.08% * 100;
 Minibatch[1601-1700]: loss = 0.353158 * 100, metric = 5.00% * 100;
 Minibatch[1701-1800]: loss = 0.340903 * 100, metric = 4.40% * 100;
 Minibatch[1801-1900]: loss = 0.346180 * 100, metric = 4.74% * 100;
 Minibatch[1901-2000]: loss = 0.336358 * 100, metric = 4.49% * 100;
Finished Epoch[61 of 200]: [Training] loss = 0.345695 * 2000, metric = 4.69% * 2000 927.664s (  2.2 samples/s);
Finished Evaluation [61]: Minibatch[1-2000]: metric = 13.98% * 2000;
 Minibatch[   1- 100]: loss = 0.337010 * 100, metric = 4.46% * 100;
 Minibatch[ 101- 200]: loss = 0.333868 * 100, metric = 4.39% * 100;
 Minibatch[ 201- 300]: loss = 0.342614 * 100, metric = 4.66% * 100;
 Minibatch[ 301- 400]: loss = 0.341807 * 100, metric = 4.56% * 100;
 Minibatch[ 401- 500]: loss = 0.341332 * 100, metric = 4.36% * 100;
 Minibatch[ 501- 600]: loss = 0.348021 * 100, metric = 4.63% * 100;
 Minibatch[ 601- 700]: loss = 0.344216 * 100, metric = 4.69% * 100;
 Minibatch[ 701- 800]: loss = 0.334137 * 100, metric = 4.52% * 100;
 Minibatch[ 801- 900]: loss = 0.344368 * 100, metric = 4.61% * 100;
 Minibatch[ 901-1000]: loss = 0.347844 * 100, metric = 4.72% * 100;
 Minibatch[1001-1100]: loss = 0.324349 * 100, metric = 4.48% * 100;
 Minibatch[1101-1200]: loss = 0.350246 * 100, metric = 4.84% * 100;
 Minibatch[1201-1300]: loss = 0.340273 * 100, metric = 4.66% * 100;
 Minibatch[1301-1400]: loss = 0.358647 * 100, metric = 4.93% * 100;
 Minibatch[1401-1500]: loss = 0.336114 * 100, metric = 4.48% * 100;
 Minibatch[1501-1600]: loss = 0.334232 * 100, metric = 4.27% * 100;
 Minibatch[1601-1700]: loss = 0.344139 * 100, metric = 4.66% * 100;
 Minibatch[1701-1800]: loss = 0.349997 * 100, metric = 4.78% * 100;
 Minibatch[1801-1900]: loss = 0.347249 * 100, metric = 4.71% * 100;
 Minibatch[1901-2000]: loss = 0.353812 * 100, metric = 4.90% * 100;
Finished Epoch[62 of 200]: [Training] loss = 0.342714 * 2000, metric = 4.62% * 2000 925.152s (  2.2 samples/s);
Finished Evaluation [62]: Minibatch[1-2000]: metric = 13.65% * 2000;
 Minibatch[   1- 100]: loss = 0.348502 * 100, metric = 4.65% * 100;
 Minibatch[ 101- 200]: loss = 0.336067 * 100, metric = 4.44% * 100;
 Minibatch[ 201- 300]: loss = 0.351781 * 100, metric = 4.98% * 100;
 Minibatch[ 301- 400]: loss = 0.338452 * 100, metric = 4.54% * 100;
 Minibatch[ 401- 500]: loss = 0.341261 * 100, metric = 4.65% * 100;
 Minibatch[ 501- 600]: loss = 0.336626 * 100, metric = 4.52% * 100;
 Minibatch[ 601- 700]: loss = 0.345553 * 100, metric = 5.02% * 100;
 Minibatch[ 701- 800]: loss = 0.345901 * 100, metric = 4.70% * 100;
 Minibatch[ 801- 900]: loss = 0.339235 * 100, metric = 4.66% * 100;
 Minibatch[ 901-1000]: loss = 0.333169 * 100, metric = 4.44% * 100;
 Minibatch[1001-1100]: loss = 0.353052 * 100, metric = 4.76% * 100;
 Minibatch[1101-1200]: loss = 0.348265 * 100, metric = 4.74% * 100;
 Minibatch[1201-1300]: loss = 0.343224 * 100, metric = 4.55% * 100;
 Minibatch[1301-1400]: loss = 0.344575 * 100, metric = 4.59% * 100;
 Minibatch[1401-1500]: loss = 0.326275 * 100, metric = 4.36% * 100;
 Minibatch[1501-1600]: loss = 0.346651 * 100, metric = 4.78% * 100;
 Minibatch[1601-1700]: loss = 0.341270 * 100, metric = 4.45% * 100;
 Minibatch[1701-1800]: loss = 0.333750 * 100, metric = 4.64% * 100;
 Minibatch[1801-1900]: loss = 0.348143 * 100, metric = 4.52% * 100;
 Minibatch[1901-2000]: loss = 0.342875 * 100, metric = 4.86% * 100;
Finished Epoch[63 of 200]: [Training] loss = 0.342231 * 2000, metric = 4.64% * 2000 907.024s (  2.2 samples/s);
Finished Evaluation [63]: Minibatch[1-2000]: metric = 13.94% * 2000;
 Minibatch[   1- 100]: loss = 0.341679 * 100, metric = 4.50% * 100;
 Minibatch[ 101- 200]: loss = 0.353050 * 100, metric = 4.78% * 100;
 Minibatch[ 201- 300]: loss = 0.349874 * 100, metric = 4.78% * 100;
 Minibatch[ 301- 400]: loss = 0.355651 * 100, metric = 4.80% * 100;
 Minibatch[ 401- 500]: loss = 0.341753 * 100, metric = 4.59% * 100;
 Minibatch[ 501- 600]: loss = 0.332925 * 100, metric = 4.27% * 100;
 Minibatch[ 601- 700]: loss = 0.335915 * 100, metric = 4.47% * 100;
 Minibatch[ 701- 800]: loss = 0.354750 * 100, metric = 4.79% * 100;
 Minibatch[ 801- 900]: loss = 0.351245 * 100, metric = 4.64% * 100;
 Minibatch[ 901-1000]: loss = 0.339579 * 100, metric = 4.55% * 100;
 Minibatch[1001-1100]: loss = 0.344266 * 100, metric = 4.58% * 100;
 Minibatch[1101-1200]: loss = 0.341641 * 100, metric = 4.64% * 100;
 Minibatch[1201-1300]: loss = 0.335029 * 100, metric = 4.50% * 100;
 Minibatch[1301-1400]: loss = 0.352136 * 100, metric = 5.04% * 100;
 Minibatch[1401-1500]: loss = 0.356250 * 100, metric = 4.91% * 100;
 Minibatch[1501-1600]: loss = 0.344839 * 100, metric = 4.86% * 100;
 Minibatch[1601-1700]: loss = 0.330912 * 100, metric = 4.33% * 100;
 Minibatch[1701-1800]: loss = 0.342545 * 100, metric = 4.59% * 100;
 Minibatch[1801-1900]: loss = 0.353469 * 100, metric = 5.02% * 100;
 Minibatch[1901-2000]: loss = 0.334672 * 100, metric = 4.61% * 100;
Finished Epoch[64 of 200]: [Training] loss = 0.344609 * 2000, metric = 4.66% * 2000 897.243s (  2.2 samples/s);
Finished Evaluation [64]: Minibatch[1-2000]: metric = 16.20% * 2000;
 Minibatch[   1- 100]: loss = 0.324573 * 100, metric = 4.50% * 100;
 Minibatch[ 101- 200]: loss = 0.329482 * 100, metric = 4.23% * 100;
 Minibatch[ 201- 300]: loss = 0.342023 * 100, metric = 4.64% * 100;
 Minibatch[ 301- 400]: loss = 0.342983 * 100, metric = 4.67% * 100;
 Minibatch[ 401- 500]: loss = 0.339816 * 100, metric = 4.36% * 100;
 Minibatch[ 501- 600]: loss = 0.339816 * 100, metric = 4.65% * 100;
 Minibatch[ 601- 700]: loss = 0.340152 * 100, metric = 4.69% * 100;
 Minibatch[ 701- 800]: loss = 0.352936 * 100, metric = 4.84% * 100;
 Minibatch[ 801- 900]: loss = 0.330114 * 100, metric = 4.41% * 100;
 Minibatch[ 901-1000]: loss = 0.334443 * 100, metric = 4.59% * 100;
 Minibatch[1001-1100]: loss = 0.335935 * 100, metric = 4.74% * 100;
 Minibatch[1101-1200]: loss = 0.344498 * 100, metric = 4.62% * 100;
 Minibatch[1201-1300]: loss = 0.346656 * 100, metric = 4.62% * 100;
 Minibatch[1301-1400]: loss = 0.331358 * 100, metric = 4.66% * 100;
 Minibatch[1401-1500]: loss = 0.339382 * 100, metric = 4.64% * 100;
 Minibatch[1501-1600]: loss = 0.335335 * 100, metric = 4.56% * 100;
 Minibatch[1601-1700]: loss = 0.346066 * 100, metric = 4.61% * 100;
 Minibatch[1701-1800]: loss = 0.345474 * 100, metric = 4.78% * 100;
 Minibatch[1801-1900]: loss = 0.340787 * 100, metric = 4.64% * 100;
 Minibatch[1901-2000]: loss = 0.340287 * 100, metric = 4.45% * 100;
Finished Epoch[65 of 200]: [Training] loss = 0.339106 * 2000, metric = 4.59% * 2000 923.930s (  2.2 samples/s);
Finished Evaluation [65]: Minibatch[1-2000]: metric = 13.36% * 2000;
 Minibatch[   1- 100]: loss = 0.336297 * 100, metric = 4.45% * 100;
 Minibatch[ 101- 200]: loss = 0.357242 * 100, metric = 4.56% * 100;
 Minibatch[ 201- 300]: loss = 0.349392 * 100, metric = 4.70% * 100;
 Minibatch[ 301- 400]: loss = 0.336686 * 100, metric = 4.60% * 100;
 Minibatch[ 401- 500]: loss = 0.338997 * 100, metric = 4.54% * 100;
 Minibatch[ 501- 600]: loss = 0.327932 * 100, metric = 4.18% * 100;
 Minibatch[ 601- 700]: loss = 0.330405 * 100, metric = 4.38% * 100;
 Minibatch[ 701- 800]: loss = 0.334652 * 100, metric = 4.62% * 100;
 Minibatch[ 801- 900]: loss = 0.316777 * 100, metric = 4.03% * 100;
 Minibatch[ 901-1000]: loss = 0.328843 * 100, metric = 4.43% * 100;
 Minibatch[1001-1100]: loss = 0.345993 * 100, metric = 4.79% * 100;
 Minibatch[1101-1200]: loss = 0.333207 * 100, metric = 4.53% * 100;
 Minibatch[1201-1300]: loss = 0.338214 * 100, metric = 4.49% * 100;
 Minibatch[1301-1400]: loss = 0.339824 * 100, metric = 4.35% * 100;
 Minibatch[1401-1500]: loss = 0.326957 * 100, metric = 4.27% * 100;
 Minibatch[1501-1600]: loss = 0.337271 * 100, metric = 4.57% * 100;
 Minibatch[1601-1700]: loss = 0.337714 * 100, metric = 4.39% * 100;
 Minibatch[1701-1800]: loss = 0.342520 * 100, metric = 4.81% * 100;
 Minibatch[1801-1900]: loss = 0.334822 * 100, metric = 4.49% * 100;
 Minibatch[1901-2000]: loss = 0.331412 * 100, metric = 4.42% * 100;
Finished Epoch[66 of 200]: [Training] loss = 0.336258 * 2000, metric = 4.48% * 2000 930.868s (  2.1 samples/s);
Finished Evaluation [66]: Minibatch[1-2000]: metric = 13.75% * 2000;
 Minibatch[   1- 100]: loss = 0.332848 * 100, metric = 4.60% * 100;
 Minibatch[ 101- 200]: loss = 0.336286 * 100, metric = 4.58% * 100;
 Minibatch[ 201- 300]: loss = 0.330752 * 100, metric = 4.31% * 100;
 Minibatch[ 301- 400]: loss = 0.345377 * 100, metric = 4.76% * 100;
 Minibatch[ 401- 500]: loss = 0.330803 * 100, metric = 4.52% * 100;
 Minibatch[ 501- 600]: loss = 0.339800 * 100, metric = 4.66% * 100;
 Minibatch[ 601- 700]: loss = 0.339418 * 100, metric = 4.37% * 100;
 Minibatch[ 701- 800]: loss = 0.340548 * 100, metric = 4.70% * 100;
 Minibatch[ 801- 900]: loss = 0.335530 * 100, metric = 4.51% * 100;
 Minibatch[ 901-1000]: loss = 0.336868 * 100, metric = 4.40% * 100;
 Minibatch[1001-1100]: loss = 0.330729 * 100, metric = 4.47% * 100;
 Minibatch[1101-1200]: loss = 0.337418 * 100, metric = 4.62% * 100;
 Minibatch[1201-1300]: loss = 0.340432 * 100, metric = 4.63% * 100;
 Minibatch[1301-1400]: loss = 0.339457 * 100, metric = 4.53% * 100;
 Minibatch[1401-1500]: loss = 0.319499 * 100, metric = 4.22% * 100;
 Minibatch[1501-1600]: loss = 0.323674 * 100, metric = 4.25% * 100;
 Minibatch[1601-1700]: loss = 0.327393 * 100, metric = 4.34% * 100;
 Minibatch[1701-1800]: loss = 0.351314 * 100, metric = 4.73% * 100;
 Minibatch[1801-1900]: loss = 0.325974 * 100, metric = 4.56% * 100;
 Minibatch[1901-2000]: loss = 0.342891 * 100, metric = 4.77% * 100;
Finished Epoch[67 of 200]: [Training] loss = 0.335351 * 2000, metric = 4.53% * 2000 863.179s (  2.3 samples/s);
Finished Evaluation [67]: Minibatch[1-2000]: metric = 12.89% * 2000;
0.6411852292641997
 Minibatch[   1- 100]: loss = 0.320355 * 100, metric = 4.31% * 100;
 Minibatch[ 101- 200]: loss = 0.343465 * 100, metric = 4.70% * 100;
 Minibatch[ 201- 300]: loss = 0.343292 * 100, metric = 4.66% * 100;
 Minibatch[ 301- 400]: loss = 0.329345 * 100, metric = 4.48% * 100;
 Minibatch[ 401- 500]: loss = 0.348876 * 100, metric = 4.73% * 100;
 Minibatch[ 501- 600]: loss = 0.329486 * 100, metric = 4.51% * 100;
 Minibatch[ 601- 700]: loss = 0.333735 * 100, metric = 4.48% * 100;
 Minibatch[ 701- 800]: loss = 0.335165 * 100, metric = 4.57% * 100;
 Minibatch[ 801- 900]: loss = 0.321568 * 100, metric = 4.21% * 100;
 Minibatch[ 901-1000]: loss = 0.335348 * 100, metric = 4.50% * 100;
 Minibatch[1001-1100]: loss = 0.343620 * 100, metric = 4.64% * 100;
 Minibatch[1101-1200]: loss = 0.340629 * 100, metric = 4.79% * 100;
 Minibatch[1201-1300]: loss = 0.331708 * 100, metric = 4.42% * 100;
 Minibatch[1301-1400]: loss = 0.316764 * 100, metric = 4.10% * 100;
 Minibatch[1401-1500]: loss = 0.325594 * 100, metric = 4.27% * 100;
 Minibatch[1501-1600]: loss = 0.326981 * 100, metric = 4.39% * 100;
 Minibatch[1601-1700]: loss = 0.326888 * 100, metric = 4.31% * 100;
 Minibatch[1701-1800]: loss = 0.339169 * 100, metric = 4.62% * 100;
 Minibatch[1801-1900]: loss = 0.342408 * 100, metric = 4.62% * 100;
 Minibatch[1901-2000]: loss = 0.320334 * 100, metric = 4.31% * 100;
Finished Epoch[68 of 200]: [Training] loss = 0.332737 * 2000, metric = 4.48% * 2000 857.927s (  2.3 samples/s);
Finished Evaluation [68]: Minibatch[1-2000]: metric = 12.85% * 2000;
0.6362433788925409
 Minibatch[   1- 100]: loss = 0.324986 * 100, metric = 4.41% * 100;
 Minibatch[ 101- 200]: loss = 0.329508 * 100, metric = 4.57% * 100;
 Minibatch[ 201- 300]: loss = 0.320837 * 100, metric = 4.20% * 100;
 Minibatch[ 301- 400]: loss = 0.335253 * 100, metric = 4.45% * 100;
 Minibatch[ 401- 500]: loss = 0.330906 * 100, metric = 4.52% * 100;
 Minibatch[ 501- 600]: loss = 0.341039 * 100, metric = 4.65% * 100;
 Minibatch[ 601- 700]: loss = 0.331583 * 100, metric = 4.31% * 100;
 Minibatch[ 701- 800]: loss = 0.334071 * 100, metric = 4.53% * 100;
 Minibatch[ 801- 900]: loss = 0.320730 * 100, metric = 4.25% * 100;
 Minibatch[ 901-1000]: loss = 0.334604 * 100, metric = 4.54% * 100;
 Minibatch[1001-1100]: loss = 0.336007 * 100, metric = 4.47% * 100;
 Minibatch[1101-1200]: loss = 0.325854 * 100, metric = 4.16% * 100;
 Minibatch[1201-1300]: loss = 0.334480 * 100, metric = 4.45% * 100;
 Minibatch[1301-1400]: loss = 0.332734 * 100, metric = 4.54% * 100;
 Minibatch[1401-1500]: loss = 0.333812 * 100, metric = 4.40% * 100;
 Minibatch[1501-1600]: loss = 0.326016 * 100, metric = 4.39% * 100;
 Minibatch[1601-1700]: loss = 0.330659 * 100, metric = 4.32% * 100;
 Minibatch[1701-1800]: loss = 0.340787 * 100, metric = 4.59% * 100;
 Minibatch[1801-1900]: loss = 0.325885 * 100, metric = 4.25% * 100;
 Minibatch[1901-2000]: loss = 0.323071 * 100, metric = 4.33% * 100;
Finished Epoch[69 of 200]: [Training] loss = 0.330641 * 2000, metric = 4.42% * 2000 854.332s (  2.3 samples/s);
Finished Evaluation [69]: Minibatch[1-2000]: metric = 13.04% * 2000;
 Minibatch[   1- 100]: loss = 0.330216 * 100, metric = 4.46% * 100;
 Minibatch[ 101- 200]: loss = 0.306828 * 100, metric = 4.09% * 100;
 Minibatch[ 201- 300]: loss = 0.330680 * 100, metric = 4.37% * 100;
 Minibatch[ 301- 400]: loss = 0.314706 * 100, metric = 3.99% * 100;
 Minibatch[ 401- 500]: loss = 0.327374 * 100, metric = 4.36% * 100;
 Minibatch[ 501- 600]: loss = 0.331180 * 100, metric = 4.47% * 100;
 Minibatch[ 601- 700]: loss = 0.330397 * 100, metric = 4.07% * 100;
 Minibatch[ 701- 800]: loss = 0.324935 * 100, metric = 4.35% * 100;
 Minibatch[ 801- 900]: loss = 0.316499 * 100, metric = 4.24% * 100;
 Minibatch[ 901-1000]: loss = 0.330540 * 100, metric = 4.38% * 100;
 Minibatch[1001-1100]: loss = 0.317423 * 100, metric = 4.14% * 100;
 Minibatch[1101-1200]: loss = 0.315295 * 100, metric = 4.19% * 100;
 Minibatch[1201-1300]: loss = 0.324382 * 100, metric = 4.27% * 100;
 Minibatch[1301-1400]: loss = 0.336415 * 100, metric = 4.64% * 100;
 Minibatch[1401-1500]: loss = 0.323247 * 100, metric = 4.22% * 100;
 Minibatch[1501-1600]: loss = 0.323482 * 100, metric = 4.39% * 100;
 Minibatch[1601-1700]: loss = 0.328823 * 100, metric = 4.45% * 100;
 Minibatch[1701-1800]: loss = 0.332231 * 100, metric = 4.48% * 100;
 Minibatch[1801-1900]: loss = 0.316812 * 100, metric = 3.98% * 100;
 Minibatch[1901-2000]: loss = 0.324548 * 100, metric = 4.41% * 100;
Finished Epoch[70 of 200]: [Training] loss = 0.324301 * 2000, metric = 4.30% * 2000 861.255s (  2.3 samples/s);
Finished Evaluation [70]: Minibatch[1-2000]: metric = 12.84% * 2000;
0.6292839991822838
 Minibatch[   1- 100]: loss = 0.335360 * 100, metric = 4.55% * 100;
 Minibatch[ 101- 200]: loss = 0.321618 * 100, metric = 4.14% * 100;
 Minibatch[ 201- 300]: loss = 0.328952 * 100, metric = 4.30% * 100;
 Minibatch[ 301- 400]: loss = 0.324104 * 100, metric = 4.17% * 100;
 Minibatch[ 401- 500]: loss = 0.317517 * 100, metric = 4.21% * 100;
 Minibatch[ 501- 600]: loss = 0.336694 * 100, metric = 4.58% * 100;
 Minibatch[ 601- 700]: loss = 0.316115 * 100, metric = 4.01% * 100;
 Minibatch[ 701- 800]: loss = 0.326288 * 100, metric = 4.36% * 100;
 Minibatch[ 801- 900]: loss = 0.333854 * 100, metric = 4.43% * 100;
 Minibatch[ 901-1000]: loss = 0.325066 * 100, metric = 4.15% * 100;
 Minibatch[1001-1100]: loss = 0.325868 * 100, metric = 4.35% * 100;
 Minibatch[1101-1200]: loss = 0.310545 * 100, metric = 4.01% * 100;
 Minibatch[1201-1300]: loss = 0.312774 * 100, metric = 4.06% * 100;
 Minibatch[1301-1400]: loss = 0.316854 * 100, metric = 4.10% * 100;
 Minibatch[1401-1500]: loss = 0.332801 * 100, metric = 4.29% * 100;
 Minibatch[1501-1600]: loss = 0.338625 * 100, metric = 4.52% * 100;
 Minibatch[1601-1700]: loss = 0.324289 * 100, metric = 4.21% * 100;
 Minibatch[1701-1800]: loss = 0.330756 * 100, metric = 4.33% * 100;
 Minibatch[1801-1900]: loss = 0.330451 * 100, metric = 4.22% * 100;
 Minibatch[1901-2000]: loss = 0.327495 * 100, metric = 4.31% * 100;
Finished Epoch[71 of 200]: [Training] loss = 0.325801 * 2000, metric = 4.26% * 2000 853.018s (  2.3 samples/s);
Finished Evaluation [71]: Minibatch[1-2000]: metric = 12.77% * 2000;
 Minibatch[   1- 100]: loss = 0.334088 * 100, metric = 4.23% * 100;
 Minibatch[ 101- 200]: loss = 0.327526 * 100, metric = 4.39% * 100;
 Minibatch[ 201- 300]: loss = 0.320566 * 100, metric = 4.11% * 100;
 Minibatch[ 301- 400]: loss = 0.318352 * 100, metric = 4.15% * 100;
 Minibatch[ 401- 500]: loss = 0.317649 * 100, metric = 4.23% * 100;
 Minibatch[ 501- 600]: loss = 0.319975 * 100, metric = 4.23% * 100;
 Minibatch[ 601- 700]: loss = 0.317937 * 100, metric = 4.18% * 100;
 Minibatch[ 701- 800]: loss = 0.328599 * 100, metric = 4.27% * 100;
 Minibatch[ 801- 900]: loss = 0.318999 * 100, metric = 4.17% * 100;
 Minibatch[ 901-1000]: loss = 0.313179 * 100, metric = 4.05% * 100;
 Minibatch[1001-1100]: loss = 0.326594 * 100, metric = 4.25% * 100;
 Minibatch[1101-1200]: loss = 0.317083 * 100, metric = 4.02% * 100;
 Minibatch[1201-1300]: loss = 0.314620 * 100, metric = 4.13% * 100;
 Minibatch[1301-1400]: loss = 0.327035 * 100, metric = 4.32% * 100;
 Minibatch[1401-1500]: loss = 0.322970 * 100, metric = 4.03% * 100;
 Minibatch[1501-1600]: loss = 0.321606 * 100, metric = 4.20% * 100;
 Minibatch[1601-1700]: loss = 0.330145 * 100, metric = 4.28% * 100;
 Minibatch[1701-1800]: loss = 0.328959 * 100, metric = 4.23% * 100;
 Minibatch[1801-1900]: loss = 0.327380 * 100, metric = 4.26% * 100;
 Minibatch[1901-2000]: loss = 0.331822 * 100, metric = 4.46% * 100;
Finished Epoch[72 of 200]: [Training] loss = 0.323254 * 2000, metric = 4.21% * 2000 868.859s (  2.3 samples/s);
Finished Evaluation [72]: Minibatch[1-2000]: metric = 13.02% * 2000;
 Minibatch[   1- 100]: loss = 0.324378 * 100, metric = 4.20% * 100;
 Minibatch[ 101- 200]: loss = 0.323440 * 100, metric = 4.18% * 100;
 Minibatch[ 201- 300]: loss = 0.313117 * 100, metric = 4.14% * 100;
 Minibatch[ 301- 400]: loss = 0.323460 * 100, metric = 4.31% * 100;
 Minibatch[ 401- 500]: loss = 0.330174 * 100, metric = 4.40% * 100;
 Minibatch[ 501- 600]: loss = 0.326062 * 100, metric = 4.19% * 100;
 Minibatch[ 601- 700]: loss = 0.313635 * 100, metric = 4.04% * 100;
 Minibatch[ 701- 800]: loss = 0.314840 * 100, metric = 4.16% * 100;
 Minibatch[ 801- 900]: loss = 0.323003 * 100, metric = 3.95% * 100;
 Minibatch[ 901-1000]: loss = 0.331826 * 100, metric = 4.31% * 100;
 Minibatch[1001-1100]: loss = 0.318998 * 100, metric = 4.02% * 100;
 Minibatch[1101-1200]: loss = 0.310843 * 100, metric = 4.02% * 100;
 Minibatch[1201-1300]: loss = 0.328955 * 100, metric = 4.29% * 100;
 Minibatch[1301-1400]: loss = 0.328297 * 100, metric = 4.25% * 100;
 Minibatch[1401-1500]: loss = 0.314187 * 100, metric = 4.08% * 100;
 Minibatch[1501-1600]: loss = 0.324610 * 100, metric = 4.20% * 100;
 Minibatch[1601-1700]: loss = 0.327725 * 100, metric = 4.22% * 100;
 Minibatch[1701-1800]: loss = 0.316719 * 100, metric = 4.19% * 100;
 Minibatch[1801-1900]: loss = 0.316034 * 100, metric = 4.04% * 100;
 Minibatch[1901-2000]: loss = 0.325726 * 100, metric = 4.30% * 100;
Finished Epoch[73 of 200]: [Training] loss = 0.321801 * 2000, metric = 4.17% * 2000 861.518s (  2.3 samples/s);
Finished Evaluation [73]: Minibatch[1-2000]: metric = 13.60% * 2000;
 Minibatch[   1- 100]: loss = 0.316331 * 100, metric = 4.30% * 100;
 Minibatch[ 101- 200]: loss = 0.321584 * 100, metric = 4.24% * 100;
 Minibatch[ 201- 300]: loss = 0.318053 * 100, metric = 4.17% * 100;
 Minibatch[ 301- 400]: loss = 0.318264 * 100, metric = 4.06% * 100;
 Minibatch[ 401- 500]: loss = 0.315834 * 100, metric = 4.15% * 100;
 Minibatch[ 501- 600]: loss = 0.325600 * 100, metric = 4.31% * 100;
 Minibatch[ 601- 700]: loss = 0.322347 * 100, metric = 4.03% * 100;
 Minibatch[ 701- 800]: loss = 0.314874 * 100, metric = 4.17% * 100;
 Minibatch[ 801- 900]: loss = 0.326238 * 100, metric = 4.35% * 100;
 Minibatch[ 901-1000]: loss = 0.326507 * 100, metric = 4.38% * 100;
 Minibatch[1001-1100]: loss = 0.317388 * 100, metric = 4.07% * 100;
 Minibatch[1101-1200]: loss = 0.332870 * 100, metric = 4.52% * 100;
 Minibatch[1201-1300]: loss = 0.312923 * 100, metric = 3.95% * 100;
 Minibatch[1301-1400]: loss = 0.316943 * 100, metric = 4.07% * 100;
 Minibatch[1401-1500]: loss = 0.308561 * 100, metric = 3.71% * 100;
 Minibatch[1501-1600]: loss = 0.325939 * 100, metric = 4.35% * 100;
 Minibatch[1601-1700]: loss = 0.307397 * 100, metric = 3.94% * 100;
 Minibatch[1701-1800]: loss = 0.321929 * 100, metric = 4.05% * 100;
 Minibatch[1801-1900]: loss = 0.308944 * 100, metric = 3.95% * 100;
 Minibatch[1901-2000]: loss = 0.328297 * 100, metric = 4.46% * 100;
Finished Epoch[74 of 200]: [Training] loss = 0.319341 * 2000, metric = 4.16% * 2000 865.845s (  2.3 samples/s);
Finished Evaluation [74]: Minibatch[1-2000]: metric = 14.15% * 2000;
 Minibatch[   1- 100]: loss = 0.314979 * 100, metric = 4.19% * 100;
 Minibatch[ 101- 200]: loss = 0.325527 * 100, metric = 4.51% * 100;
 Minibatch[ 201- 300]: loss = 0.314580 * 100, metric = 3.97% * 100;
 Minibatch[ 301- 400]: loss = 0.304979 * 100, metric = 4.02% * 100;
 Minibatch[ 401- 500]: loss = 0.316234 * 100, metric = 4.00% * 100;
 Minibatch[ 501- 600]: loss = 0.321295 * 100, metric = 4.22% * 100;
 Minibatch[ 601- 700]: loss = 0.325921 * 100, metric = 4.14% * 100;
 Minibatch[ 701- 800]: loss = 0.324977 * 100, metric = 4.36% * 100;
 Minibatch[ 801- 900]: loss = 0.316771 * 100, metric = 4.15% * 100;
 Minibatch[ 901-1000]: loss = 0.312254 * 100, metric = 3.93% * 100;
 Minibatch[1001-1100]: loss = 0.312394 * 100, metric = 4.02% * 100;
 Minibatch[1101-1200]: loss = 0.312217 * 100, metric = 4.14% * 100;
 Minibatch[1201-1300]: loss = 0.317567 * 100, metric = 4.21% * 100;
 Minibatch[1301-1400]: loss = 0.300572 * 100, metric = 3.72% * 100;
 Minibatch[1401-1500]: loss = 0.307438 * 100, metric = 3.95% * 100;
 Minibatch[1501-1600]: loss = 0.311379 * 100, metric = 4.07% * 100;
 Minibatch[1601-1700]: loss = 0.311389 * 100, metric = 4.08% * 100;
 Minibatch[1701-1800]: loss = 0.308472 * 100, metric = 3.90% * 100;
 Minibatch[1801-1900]: loss = 0.309494 * 100, metric = 3.89% * 100;
 Minibatch[1901-2000]: loss = 0.307002 * 100, metric = 3.95% * 100;
Finished Epoch[75 of 200]: [Training] loss = 0.313772 * 2000, metric = 4.07% * 2000 856.030s (  2.3 samples/s);
Finished Evaluation [75]: Minibatch[1-2000]: metric = 13.38% * 2000;
 Minibatch[   1- 100]: loss = 0.305180 * 100, metric = 3.80% * 100;
 Minibatch[ 101- 200]: loss = 0.317767 * 100, metric = 3.98% * 100;
 Minibatch[ 201- 300]: loss = 0.333127 * 100, metric = 4.42% * 100;
 Minibatch[ 301- 400]: loss = 0.314323 * 100, metric = 4.21% * 100;
 Minibatch[ 401- 500]: loss = 0.316586 * 100, metric = 4.07% * 100;
 Minibatch[ 501- 600]: loss = 0.292124 * 100, metric = 3.60% * 100;
 Minibatch[ 601- 700]: loss = 0.307939 * 100, metric = 3.86% * 100;
 Minibatch[ 701- 800]: loss = 0.309766 * 100, metric = 3.98% * 100;
 Minibatch[ 801- 900]: loss = 0.314420 * 100, metric = 4.11% * 100;
 Minibatch[ 901-1000]: loss = 0.309684 * 100, metric = 3.93% * 100;
 Minibatch[1001-1100]: loss = 0.313397 * 100, metric = 4.03% * 100;
 Minibatch[1101-1200]: loss = 0.308642 * 100, metric = 4.02% * 100;
 Minibatch[1201-1300]: loss = 0.314205 * 100, metric = 4.15% * 100;
 Minibatch[1301-1400]: loss = 0.321660 * 100, metric = 4.27% * 100;
 Minibatch[1401-1500]: loss = 0.316941 * 100, metric = 4.11% * 100;
 Minibatch[1501-1600]: loss = 0.311987 * 100, metric = 3.99% * 100;
 Minibatch[1601-1700]: loss = 0.312652 * 100, metric = 3.97% * 100;
 Minibatch[1701-1800]: loss = 0.301496 * 100, metric = 3.70% * 100;
 Minibatch[1801-1900]: loss = 0.314777 * 100, metric = 4.02% * 100;
 Minibatch[1901-2000]: loss = 0.309664 * 100, metric = 3.98% * 100;
Finished Epoch[76 of 200]: [Training] loss = 0.312317 * 2000, metric = 4.01% * 2000 854.858s (  2.3 samples/s);
Finished Evaluation [76]: Minibatch[1-2000]: metric = 12.85% * 2000;
 Minibatch[   1- 100]: loss = 0.317397 * 100, metric = 4.09% * 100;
 Minibatch[ 101- 200]: loss = 0.321324 * 100, metric = 4.08% * 100;
 Minibatch[ 201- 300]: loss = 0.302625 * 100, metric = 3.78% * 100;
 Minibatch[ 301- 400]: loss = 0.324616 * 100, metric = 4.20% * 100;
 Minibatch[ 401- 500]: loss = 0.321130 * 100, metric = 4.17% * 100;
 Minibatch[ 501- 600]: loss = 0.295506 * 100, metric = 3.73% * 100;
 Minibatch[ 601- 700]: loss = 0.319475 * 100, metric = 4.08% * 100;
 Minibatch[ 701- 800]: loss = 0.321028 * 100, metric = 4.05% * 100;
 Minibatch[ 801- 900]: loss = 0.317310 * 100, metric = 4.04% * 100;
 Minibatch[ 901-1000]: loss = 0.304513 * 100, metric = 3.92% * 100;
 Minibatch[1001-1100]: loss = 0.313530 * 100, metric = 4.15% * 100;
 Minibatch[1101-1200]: loss = 0.319773 * 100, metric = 4.08% * 100;
 Minibatch[1201-1300]: loss = 0.325800 * 100, metric = 4.40% * 100;
 Minibatch[1301-1400]: loss = 0.299958 * 100, metric = 3.91% * 100;
 Minibatch[1401-1500]: loss = 0.321052 * 100, metric = 4.28% * 100;
 Minibatch[1501-1600]: loss = 0.315763 * 100, metric = 4.08% * 100;
 Minibatch[1601-1700]: loss = 0.305359 * 100, metric = 3.93% * 100;
 Minibatch[1701-1800]: loss = 0.304155 * 100, metric = 3.87% * 100;
 Minibatch[1801-1900]: loss = 0.318022 * 100, metric = 4.13% * 100;
 Minibatch[1901-2000]: loss = 0.309080 * 100, metric = 4.05% * 100;
Finished Epoch[77 of 200]: [Training] loss = 0.313871 * 2000, metric = 4.05% * 2000 851.548s (  2.3 samples/s);
Finished Evaluation [77]: Minibatch[1-2000]: metric = 12.19% * 2000;
0.617355474896729
 Minibatch[   1- 100]: loss = 0.305608 * 100, metric = 3.94% * 100;
 Minibatch[ 101- 200]: loss = 0.308035 * 100, metric = 3.90% * 100;
 Minibatch[ 201- 300]: loss = 0.294574 * 100, metric = 3.67% * 100;
 Minibatch[ 301- 400]: loss = 0.307657 * 100, metric = 3.88% * 100;
 Minibatch[ 401- 500]: loss = 0.315561 * 100, metric = 3.98% * 100;
 Minibatch[ 501- 600]: loss = 0.317691 * 100, metric = 4.00% * 100;
 Minibatch[ 601- 700]: loss = 0.307311 * 100, metric = 4.03% * 100;
 Minibatch[ 701- 800]: loss = 0.307883 * 100, metric = 3.81% * 100;
 Minibatch[ 801- 900]: loss = 0.297643 * 100, metric = 3.76% * 100;
 Minibatch[ 901-1000]: loss = 0.313591 * 100, metric = 4.00% * 100;
 Minibatch[1001-1100]: loss = 0.318876 * 100, metric = 4.17% * 100;
 Minibatch[1101-1200]: loss = 0.301853 * 100, metric = 3.82% * 100;
 Minibatch[1201-1300]: loss = 0.318778 * 100, metric = 4.34% * 100;
 Minibatch[1301-1400]: loss = 0.305512 * 100, metric = 3.93% * 100;
 Minibatch[1401-1500]: loss = 0.315240 * 100, metric = 4.03% * 100;
 Minibatch[1501-1600]: loss = 0.308581 * 100, metric = 3.97% * 100;
 Minibatch[1601-1700]: loss = 0.313568 * 100, metric = 4.07% * 100;
 Minibatch[1701-1800]: loss = 0.308933 * 100, metric = 3.94% * 100;
 Minibatch[1801-1900]: loss = 0.329176 * 100, metric = 4.50% * 100;
 Minibatch[1901-2000]: loss = 0.317238 * 100, metric = 4.13% * 100;
Finished Epoch[78 of 200]: [Training] loss = 0.310665 * 2000, metric = 3.99% * 2000 869.106s (  2.3 samples/s);
Finished Evaluation [78]: Minibatch[1-2000]: metric = 12.74% * 2000;
 Minibatch[   1- 100]: loss = 0.312133 * 100, metric = 4.08% * 100;
 Minibatch[ 101- 200]: loss = 0.313299 * 100, metric = 3.99% * 100;
 Minibatch[ 201- 300]: loss = 0.310323 * 100, metric = 4.12% * 100;
 Minibatch[ 301- 400]: loss = 0.300711 * 100, metric = 3.75% * 100;
 Minibatch[ 401- 500]: loss = 0.312870 * 100, metric = 4.06% * 100;
 Minibatch[ 501- 600]: loss = 0.318076 * 100, metric = 4.23% * 100;
 Minibatch[ 601- 700]: loss = 0.314273 * 100, metric = 4.11% * 100;
 Minibatch[ 701- 800]: loss = 0.319229 * 100, metric = 4.04% * 100;
 Minibatch[ 801- 900]: loss = 0.321972 * 100, metric = 4.13% * 100;
 Minibatch[ 901-1000]: loss = 0.322870 * 100, metric = 4.12% * 100;
 Minibatch[1001-1100]: loss = 0.324149 * 100, metric = 4.37% * 100;
 Minibatch[1101-1200]: loss = 0.303734 * 100, metric = 3.68% * 100;
 Minibatch[1201-1300]: loss = 0.318442 * 100, metric = 4.14% * 100;
 Minibatch[1301-1400]: loss = 0.314685 * 100, metric = 3.95% * 100;
 Minibatch[1401-1500]: loss = 0.313644 * 100, metric = 4.24% * 100;
 Minibatch[1501-1600]: loss = 0.313543 * 100, metric = 4.07% * 100;
 Minibatch[1601-1700]: loss = 0.306804 * 100, metric = 3.85% * 100;
 Minibatch[1701-1800]: loss = 0.302155 * 100, metric = 3.80% * 100;
 Minibatch[1801-1900]: loss = 0.307551 * 100, metric = 4.00% * 100;
 Minibatch[1901-2000]: loss = 0.324535 * 100, metric = 4.21% * 100;
Finished Epoch[79 of 200]: [Training] loss = 0.313750 * 2000, metric = 4.05% * 2000 853.808s (  2.3 samples/s);
Finished Evaluation [79]: Minibatch[1-2000]: metric = 13.02% * 2000;
 Minibatch[   1- 100]: loss = 0.306464 * 100, metric = 3.81% * 100;
 Minibatch[ 101- 200]: loss = 0.311898 * 100, metric = 4.03% * 100;
 Minibatch[ 201- 300]: loss = 0.303801 * 100, metric = 3.84% * 100;
 Minibatch[ 301- 400]: loss = 0.311174 * 100, metric = 4.01% * 100;
 Minibatch[ 401- 500]: loss = 0.321930 * 100, metric = 4.12% * 100;
 Minibatch[ 501- 600]: loss = 0.312164 * 100, metric = 4.02% * 100;
 Minibatch[ 601- 700]: loss = 0.312280 * 100, metric = 4.16% * 100;
 Minibatch[ 701- 800]: loss = 0.318059 * 100, metric = 4.04% * 100;
 Minibatch[ 801- 900]: loss = 0.317961 * 100, metric = 4.18% * 100;
 Minibatch[ 901-1000]: loss = 0.297657 * 100, metric = 3.86% * 100;
 Minibatch[1001-1100]: loss = 0.299927 * 100, metric = 3.88% * 100;
 Minibatch[1101-1200]: loss = 0.298020 * 100, metric = 3.70% * 100;
 Minibatch[1201-1300]: loss = 0.293376 * 100, metric = 3.71% * 100;
 Minibatch[1301-1400]: loss = 0.318443 * 100, metric = 3.95% * 100;
 Minibatch[1401-1500]: loss = 0.305418 * 100, metric = 3.88% * 100;
 Minibatch[1501-1600]: loss = 0.302193 * 100, metric = 3.91% * 100;
 Minibatch[1601-1700]: loss = 0.314653 * 100, metric = 4.25% * 100;
 Minibatch[1701-1800]: loss = 0.307191 * 100, metric = 3.96% * 100;
 Minibatch[1801-1900]: loss = 0.315422 * 100, metric = 3.99% * 100;
 Minibatch[1901-2000]: loss = 0.310813 * 100, metric = 4.09% * 100;
Finished Epoch[80 of 200]: [Training] loss = 0.308942 * 2000, metric = 3.97% * 2000 867.251s (  2.3 samples/s);
Finished Evaluation [80]: Minibatch[1-2000]: metric = 13.05% * 2000;
 Minibatch[   1- 100]: loss = 0.307462 * 100, metric = 3.89% * 100;
 Minibatch[ 101- 200]: loss = 0.308487 * 100, metric = 3.95% * 100;
 Minibatch[ 201- 300]: loss = 0.309966 * 100, metric = 4.05% * 100;
 Minibatch[ 301- 400]: loss = 0.307610 * 100, metric = 3.84% * 100;
 Minibatch[ 401- 500]: loss = 0.303806 * 100, metric = 4.02% * 100;
 Minibatch[ 501- 600]: loss = 0.317058 * 100, metric = 3.99% * 100;
 Minibatch[ 601- 700]: loss = 0.320470 * 100, metric = 4.21% * 100;
 Minibatch[ 701- 800]: loss = 0.310618 * 100, metric = 3.85% * 100;
 Minibatch[ 801- 900]: loss = 0.324794 * 100, metric = 4.27% * 100;
 Minibatch[ 901-1000]: loss = 0.299535 * 100, metric = 3.92% * 100;
 Minibatch[1001-1100]: loss = 0.318365 * 100, metric = 4.21% * 100;
 Minibatch[1101-1200]: loss = 0.311489 * 100, metric = 4.09% * 100;
 Minibatch[1201-1300]: loss = 0.313587 * 100, metric = 4.13% * 100;
 Minibatch[1301-1400]: loss = 0.310347 * 100, metric = 4.03% * 100;
 Minibatch[1401-1500]: loss = 0.308158 * 100, metric = 3.88% * 100;
 Minibatch[1501-1600]: loss = 0.327293 * 100, metric = 4.15% * 100;
 Minibatch[1601-1700]: loss = 0.312704 * 100, metric = 3.94% * 100;
 Minibatch[1701-1800]: loss = 0.313118 * 100, metric = 4.16% * 100;
 Minibatch[1801-1900]: loss = 0.311414 * 100, metric = 3.96% * 100;
 Minibatch[1901-2000]: loss = 0.318583 * 100, metric = 3.94% * 100;
Finished Epoch[81 of 200]: [Training] loss = 0.312743 * 2000, metric = 4.02% * 2000 871.267s (  2.3 samples/s);
Finished Evaluation [81]: Minibatch[1-2000]: metric = 14.19% * 2000;
 Minibatch[   1- 100]: loss = 0.319042 * 100, metric = 4.30% * 100;
 Minibatch[ 101- 200]: loss = 0.304371 * 100, metric = 3.90% * 100;
 Minibatch[ 201- 300]: loss = 0.313988 * 100, metric = 3.92% * 100;
 Minibatch[ 301- 400]: loss = 0.321456 * 100, metric = 4.15% * 100;
 Minibatch[ 401- 500]: loss = 0.309123 * 100, metric = 3.74% * 100;
 Minibatch[ 501- 600]: loss = 0.305275 * 100, metric = 4.00% * 100;
 Minibatch[ 601- 700]: loss = 0.296545 * 100, metric = 3.60% * 100;
 Minibatch[ 701- 800]: loss = 0.295708 * 100, metric = 3.64% * 100;
 Minibatch[ 801- 900]: loss = 0.317809 * 100, metric = 4.01% * 100;
 Minibatch[ 901-1000]: loss = 0.305530 * 100, metric = 3.97% * 100;
 Minibatch[1001-1100]: loss = 0.312547 * 100, metric = 3.96% * 100;
 Minibatch[1101-1200]: loss = 0.320516 * 100, metric = 4.03% * 100;
 Minibatch[1201-1300]: loss = 0.311452 * 100, metric = 3.92% * 100;
 Minibatch[1301-1400]: loss = 0.312878 * 100, metric = 4.04% * 100;
 Minibatch[1401-1500]: loss = 0.306019 * 100, metric = 3.88% * 100;
 Minibatch[1501-1600]: loss = 0.307761 * 100, metric = 3.95% * 100;
 Minibatch[1601-1700]: loss = 0.309404 * 100, metric = 3.78% * 100;
 Minibatch[1701-1800]: loss = 0.308688 * 100, metric = 4.15% * 100;
 Minibatch[1801-1900]: loss = 0.303201 * 100, metric = 3.84% * 100;
 Minibatch[1901-2000]: loss = 0.306993 * 100, metric = 3.92% * 100;
Finished Epoch[82 of 200]: [Training] loss = 0.309415 * 2000, metric = 3.94% * 2000 869.956s (  2.3 samples/s);
Finished Evaluation [82]: Minibatch[1-2000]: metric = 13.21% * 2000;
 Minibatch[   1- 100]: loss = 0.303547 * 100, metric = 3.74% * 100;
 Minibatch[ 101- 200]: loss = 0.309920 * 100, metric = 4.12% * 100;
 Minibatch[ 201- 300]: loss = 0.298540 * 100, metric = 3.70% * 100;
 Minibatch[ 301- 400]: loss = 0.308185 * 100, metric = 3.86% * 100;
 Minibatch[ 401- 500]: loss = 0.286943 * 100, metric = 3.48% * 100;
 Minibatch[ 501- 600]: loss = 0.300900 * 100, metric = 3.98% * 100;
 Minibatch[ 601- 700]: loss = 0.310271 * 100, metric = 4.01% * 100;
 Minibatch[ 701- 800]: loss = 0.297132 * 100, metric = 3.62% * 100;
 Minibatch[ 801- 900]: loss = 0.306750 * 100, metric = 3.88% * 100;
 Minibatch[ 901-1000]: loss = 0.318228 * 100, metric = 4.12% * 100;
 Minibatch[1001-1100]: loss = 0.313498 * 100, metric = 3.93% * 100;
 Minibatch[1101-1200]: loss = 0.310079 * 100, metric = 3.99% * 100;
 Minibatch[1201-1300]: loss = 0.302156 * 100, metric = 3.95% * 100;
 Minibatch[1301-1400]: loss = 0.280366 * 100, metric = 3.39% * 100;
 Minibatch[1401-1500]: loss = 0.298979 * 100, metric = 3.60% * 100;
 Minibatch[1501-1600]: loss = 0.307154 * 100, metric = 3.87% * 100;
 Minibatch[1601-1700]: loss = 0.304789 * 100, metric = 3.81% * 100;
 Minibatch[1701-1800]: loss = 0.302441 * 100, metric = 3.84% * 100;
 Minibatch[1801-1900]: loss = 0.297715 * 100, metric = 3.77% * 100;
 Minibatch[1901-2000]: loss = 0.297312 * 100, metric = 3.89% * 100;
Finished Epoch[83 of 200]: [Training] loss = 0.302745 * 2000, metric = 3.83% * 2000 836.782s (  2.4 samples/s);
Finished Evaluation [83]: Minibatch[1-2000]: metric = 12.75% * 2000;
 Minibatch[   1- 100]: loss = 0.305691 * 100, metric = 3.75% * 100;
 Minibatch[ 101- 200]: loss = 0.295203 * 100, metric = 3.87% * 100;
 Minibatch[ 201- 300]: loss = 0.300896 * 100, metric = 3.68% * 100;
 Minibatch[ 301- 400]: loss = 0.289903 * 100, metric = 3.68% * 100;
 Minibatch[ 401- 500]: loss = 0.306672 * 100, metric = 3.81% * 100;
 Minibatch[ 501- 600]: loss = 0.307891 * 100, metric = 3.88% * 100;
 Minibatch[ 601- 700]: loss = 0.312724 * 100, metric = 4.08% * 100;
 Minibatch[ 701- 800]: loss = 0.294687 * 100, metric = 3.69% * 100;
 Minibatch[ 801- 900]: loss = 0.297379 * 100, metric = 3.61% * 100;
 Minibatch[ 901-1000]: loss = 0.304777 * 100, metric = 3.93% * 100;
 Minibatch[1001-1100]: loss = 0.297954 * 100, metric = 3.85% * 100;
 Minibatch[1101-1200]: loss = 0.293084 * 100, metric = 3.67% * 100;
 Minibatch[1201-1300]: loss = 0.303757 * 100, metric = 3.82% * 100;
 Minibatch[1301-1400]: loss = 0.312023 * 100, metric = 4.00% * 100;
 Minibatch[1401-1500]: loss = 0.300712 * 100, metric = 3.67% * 100;
 Minibatch[1501-1600]: loss = 0.295705 * 100, metric = 3.64% * 100;
 Minibatch[1601-1700]: loss = 0.308176 * 100, metric = 3.88% * 100;
 Minibatch[1701-1800]: loss = 0.299656 * 100, metric = 3.70% * 100;
 Minibatch[1801-1900]: loss = 0.296488 * 100, metric = 3.82% * 100;
 Minibatch[1901-2000]: loss = 0.302473 * 100, metric = 3.98% * 100;
Finished Epoch[84 of 200]: [Training] loss = 0.301293 * 2000, metric = 3.80% * 2000 861.462s (  2.3 samples/s);
Finished Evaluation [84]: Minibatch[1-2000]: metric = 13.28% * 2000;
 Minibatch[   1- 100]: loss = 0.299416 * 100, metric = 3.69% * 100;
 Minibatch[ 101- 200]: loss = 0.295905 * 100, metric = 3.73% * 100;
 Minibatch[ 201- 300]: loss = 0.303712 * 100, metric = 3.84% * 100;
 Minibatch[ 301- 400]: loss = 0.300054 * 100, metric = 3.73% * 100;
 Minibatch[ 401- 500]: loss = 0.293270 * 100, metric = 3.57% * 100;
 Minibatch[ 501- 600]: loss = 0.304912 * 100, metric = 3.90% * 100;
 Minibatch[ 601- 700]: loss = 0.300049 * 100, metric = 3.77% * 100;
 Minibatch[ 701- 800]: loss = 0.300054 * 100, metric = 3.84% * 100;
 Minibatch[ 801- 900]: loss = 0.303529 * 100, metric = 3.86% * 100;
 Minibatch[ 901-1000]: loss = 0.306805 * 100, metric = 3.88% * 100;
 Minibatch[1001-1100]: loss = 0.315326 * 100, metric = 3.96% * 100;
 Minibatch[1101-1200]: loss = 0.298564 * 100, metric = 3.80% * 100;
 Minibatch[1201-1300]: loss = 0.293501 * 100, metric = 3.47% * 100;
 Minibatch[1301-1400]: loss = 0.296271 * 100, metric = 3.71% * 100;
 Minibatch[1401-1500]: loss = 0.300470 * 100, metric = 3.58% * 100;
 Minibatch[1501-1600]: loss = 0.304708 * 100, metric = 3.77% * 100;
 Minibatch[1601-1700]: loss = 0.301903 * 100, metric = 3.80% * 100;
 Minibatch[1701-1800]: loss = 0.301743 * 100, metric = 3.60% * 100;
 Minibatch[1801-1900]: loss = 0.300376 * 100, metric = 3.75% * 100;
 Minibatch[1901-2000]: loss = 0.299078 * 100, metric = 3.74% * 100;
Finished Epoch[85 of 200]: [Training] loss = 0.300982 * 2000, metric = 3.75% * 2000 853.382s (  2.3 samples/s);
Finished Evaluation [85]: Minibatch[1-2000]: metric = 12.57% * 2000;
 Minibatch[   1- 100]: loss = 0.303002 * 100, metric = 3.81% * 100;
 Minibatch[ 101- 200]: loss = 0.293307 * 100, metric = 3.59% * 100;
 Minibatch[ 201- 300]: loss = 0.311998 * 100, metric = 3.88% * 100;
 Minibatch[ 301- 400]: loss = 0.305722 * 100, metric = 3.80% * 100;
 Minibatch[ 401- 500]: loss = 0.308121 * 100, metric = 3.93% * 100;
 Minibatch[ 501- 600]: loss = 0.299873 * 100, metric = 3.80% * 100;
 Minibatch[ 601- 700]: loss = 0.299765 * 100, metric = 3.81% * 100;
 Minibatch[ 701- 800]: loss = 0.294421 * 100, metric = 3.58% * 100;
 Minibatch[ 801- 900]: loss = 0.276144 * 100, metric = 3.42% * 100;
 Minibatch[ 901-1000]: loss = 0.296926 * 100, metric = 3.87% * 100;
 Minibatch[1001-1100]: loss = 0.287311 * 100, metric = 3.46% * 100;
 Minibatch[1101-1200]: loss = 0.301894 * 100, metric = 3.86% * 100;
 Minibatch[1201-1300]: loss = 0.299101 * 100, metric = 3.71% * 100;
 Minibatch[1301-1400]: loss = 0.301280 * 100, metric = 3.72% * 100;
 Minibatch[1401-1500]: loss = 0.296952 * 100, metric = 3.80% * 100;
 Minibatch[1501-1600]: loss = 0.294048 * 100, metric = 3.68% * 100;
 Minibatch[1601-1700]: loss = 0.308177 * 100, metric = 3.86% * 100;
 Minibatch[1701-1800]: loss = 0.301460 * 100, metric = 3.67% * 100;
 Minibatch[1801-1900]: loss = 0.305840 * 100, metric = 3.78% * 100;
 Minibatch[1901-2000]: loss = 0.304617 * 100, metric = 3.88% * 100;
Finished Epoch[86 of 200]: [Training] loss = 0.299498 * 2000, metric = 3.75% * 2000 853.870s (  2.3 samples/s);
Finished Evaluation [86]: Minibatch[1-2000]: metric = 12.45% * 2000;
 Minibatch[   1- 100]: loss = 0.295001 * 100, metric = 3.55% * 100;
 Minibatch[ 101- 200]: loss = 0.303377 * 100, metric = 3.84% * 100;
 Minibatch[ 201- 300]: loss = 0.291610 * 100, metric = 3.67% * 100;
 Minibatch[ 301- 400]: loss = 0.300093 * 100, metric = 3.80% * 100;
 Minibatch[ 401- 500]: loss = 0.294828 * 100, metric = 3.70% * 100;
 Minibatch[ 501- 600]: loss = 0.300867 * 100, metric = 3.89% * 100;
 Minibatch[ 601- 700]: loss = 0.297369 * 100, metric = 3.89% * 100;
 Minibatch[ 701- 800]: loss = 0.294677 * 100, metric = 3.75% * 100;
 Minibatch[ 801- 900]: loss = 0.287399 * 100, metric = 3.58% * 100;
 Minibatch[ 901-1000]: loss = 0.300484 * 100, metric = 3.72% * 100;
 Minibatch[1001-1100]: loss = 0.297734 * 100, metric = 3.73% * 100;
 Minibatch[1101-1200]: loss = 0.279639 * 100, metric = 3.57% * 100;
 Minibatch[1201-1300]: loss = 0.294711 * 100, metric = 3.69% * 100;
 Minibatch[1301-1400]: loss = 0.289179 * 100, metric = 3.77% * 100;
 Minibatch[1401-1500]: loss = 0.299353 * 100, metric = 3.88% * 100;
 Minibatch[1501-1600]: loss = 0.287077 * 100, metric = 3.38% * 100;
 Minibatch[1601-1700]: loss = 0.303390 * 100, metric = 3.86% * 100;
 Minibatch[1701-1800]: loss = 0.294194 * 100, metric = 3.48% * 100;
 Minibatch[1801-1900]: loss = 0.304523 * 100, metric = 3.79% * 100;
 Minibatch[1901-2000]: loss = 0.300665 * 100, metric = 3.75% * 100;
Finished Epoch[87 of 200]: [Training] loss = 0.295808 * 2000, metric = 3.71% * 2000 840.719s (  2.4 samples/s);
Finished Evaluation [87]: Minibatch[1-2000]: metric = 13.54% * 2000;
 Minibatch[   1- 100]: loss = 0.305570 * 100, metric = 3.87% * 100;
 Minibatch[ 101- 200]: loss = 0.296844 * 100, metric = 3.60% * 100;
 Minibatch[ 201- 300]: loss = 0.288555 * 100, metric = 3.52% * 100;
 Minibatch[ 301- 400]: loss = 0.298565 * 100, metric = 3.82% * 100;
 Minibatch[ 401- 500]: loss = 0.301835 * 100, metric = 3.71% * 100;
 Minibatch[ 501- 600]: loss = 0.288960 * 100, metric = 3.75% * 100;
 Minibatch[ 601- 700]: loss = 0.285724 * 100, metric = 3.52% * 100;
 Minibatch[ 701- 800]: loss = 0.298453 * 100, metric = 3.72% * 100;
 Minibatch[ 801- 900]: loss = 0.307124 * 100, metric = 4.10% * 100;
 Minibatch[ 901-1000]: loss = 0.295542 * 100, metric = 3.74% * 100;
 Minibatch[1001-1100]: loss = 0.299886 * 100, metric = 3.71% * 100;
 Minibatch[1101-1200]: loss = 0.296309 * 100, metric = 3.78% * 100;
 Minibatch[1201-1300]: loss = 0.293313 * 100, metric = 3.60% * 100;
 Minibatch[1301-1400]: loss = 0.298751 * 100, metric = 3.76% * 100;
 Minibatch[1401-1500]: loss = 0.310870 * 100, metric = 4.01% * 100;
 Minibatch[1501-1600]: loss = 0.284360 * 100, metric = 3.47% * 100;
 Minibatch[1601-1700]: loss = 0.291919 * 100, metric = 3.64% * 100;
 Minibatch[1701-1800]: loss = 0.291759 * 100, metric = 3.77% * 100;
 Minibatch[1801-1900]: loss = 0.308063 * 100, metric = 4.00% * 100;
 Minibatch[1901-2000]: loss = 0.277092 * 100, metric = 3.36% * 100;
Finished Epoch[88 of 200]: [Training] loss = 0.295975 * 2000, metric = 3.72% * 2000 843.833s (  2.4 samples/s);
Finished Evaluation [88]: Minibatch[1-2000]: metric = 12.92% * 2000;
 Minibatch[   1- 100]: loss = 0.296842 * 100, metric = 3.94% * 100;
 Minibatch[ 101- 200]: loss = 0.300002 * 100, metric = 3.79% * 100;
 Minibatch[ 201- 300]: loss = 0.280560 * 100, metric = 3.42% * 100;
 Minibatch[ 301- 400]: loss = 0.286297 * 100, metric = 3.59% * 100;
 Minibatch[ 401- 500]: loss = 0.285645 * 100, metric = 3.60% * 100;
 Minibatch[ 501- 600]: loss = 0.295894 * 100, metric = 3.58% * 100;
 Minibatch[ 601- 700]: loss = 0.301562 * 100, metric = 3.95% * 100;
 Minibatch[ 701- 800]: loss = 0.298338 * 100, metric = 3.78% * 100;
 Minibatch[ 801- 900]: loss = 0.302197 * 100, metric = 3.91% * 100;
 Minibatch[ 901-1000]: loss = 0.314159 * 100, metric = 3.91% * 100;
 Minibatch[1001-1100]: loss = 0.299865 * 100, metric = 3.86% * 100;
 Minibatch[1101-1200]: loss = 0.300692 * 100, metric = 3.77% * 100;
 Minibatch[1201-1300]: loss = 0.309405 * 100, metric = 3.92% * 100;
 Minibatch[1301-1400]: loss = 0.296903 * 100, metric = 3.67% * 100;
 Minibatch[1401-1500]: loss = 0.303255 * 100, metric = 3.81% * 100;
 Minibatch[1501-1600]: loss = 0.292666 * 100, metric = 3.72% * 100;
 Minibatch[1601-1700]: loss = 0.301702 * 100, metric = 3.81% * 100;
 Minibatch[1701-1800]: loss = 0.306227 * 100, metric = 3.65% * 100;
 Minibatch[1801-1900]: loss = 0.294079 * 100, metric = 3.75% * 100;
 Minibatch[1901-2000]: loss = 0.294014 * 100, metric = 3.66% * 100;
Finished Epoch[89 of 200]: [Training] loss = 0.298015 * 2000, metric = 3.75% * 2000 844.745s (  2.4 samples/s);
Finished Evaluation [89]: Minibatch[1-2000]: metric = 12.68% * 2000;
 Minibatch[   1- 100]: loss = 0.298187 * 100, metric = 3.86% * 100;
 Minibatch[ 101- 200]: loss = 0.296081 * 100, metric = 3.57% * 100;
 Minibatch[ 201- 300]: loss = 0.303149 * 100, metric = 3.79% * 100;
 Minibatch[ 301- 400]: loss = 0.293384 * 100, metric = 3.76% * 100;
 Minibatch[ 401- 500]: loss = 0.291787 * 100, metric = 3.75% * 100;
 Minibatch[ 501- 600]: loss = 0.301682 * 100, metric = 3.89% * 100;
 Minibatch[ 601- 700]: loss = 0.299757 * 100, metric = 3.74% * 100;
 Minibatch[ 701- 800]: loss = 0.290217 * 100, metric = 3.66% * 100;
 Minibatch[ 801- 900]: loss = 0.299462 * 100, metric = 3.67% * 100;
 Minibatch[ 901-1000]: loss = 0.303613 * 100, metric = 3.74% * 100;
 Minibatch[1001-1100]: loss = 0.283742 * 100, metric = 3.55% * 100;
 Minibatch[1101-1200]: loss = 0.277950 * 100, metric = 3.47% * 100;
 Minibatch[1201-1300]: loss = 0.272294 * 100, metric = 3.23% * 100;
 Minibatch[1301-1400]: loss = 0.284849 * 100, metric = 3.54% * 100;
 Minibatch[1401-1500]: loss = 0.286451 * 100, metric = 3.75% * 100;
 Minibatch[1501-1600]: loss = 0.285361 * 100, metric = 3.46% * 100;
 Minibatch[1601-1700]: loss = 0.277780 * 100, metric = 3.32% * 100;
 Minibatch[1701-1800]: loss = 0.286793 * 100, metric = 3.61% * 100;
 Minibatch[1801-1900]: loss = 0.294355 * 100, metric = 3.86% * 100;
 Minibatch[1901-2000]: loss = 0.295708 * 100, metric = 3.71% * 100;
Finished Epoch[90 of 200]: [Training] loss = 0.291130 * 2000, metric = 3.65% * 2000 846.572s (  2.4 samples/s);
Finished Evaluation [90]: Minibatch[1-2000]: metric = 12.72% * 2000;
 Minibatch[   1- 100]: loss = 0.288493 * 100, metric = 3.43% * 100;
 Minibatch[ 101- 200]: loss = 0.300280 * 100, metric = 3.90% * 100;
 Minibatch[ 201- 300]: loss = 0.288653 * 100, metric = 3.73% * 100;
 Minibatch[ 301- 400]: loss = 0.283150 * 100, metric = 3.49% * 100;
 Minibatch[ 401- 500]: loss = 0.290833 * 100, metric = 3.72% * 100;
 Minibatch[ 501- 600]: loss = 0.307022 * 100, metric = 3.78% * 100;
 Minibatch[ 601- 700]: loss = 0.302154 * 100, metric = 3.70% * 100;
 Minibatch[ 701- 800]: loss = 0.304847 * 100, metric = 4.04% * 100;
 Minibatch[ 801- 900]: loss = 0.288617 * 100, metric = 3.53% * 100;
 Minibatch[ 901-1000]: loss = 0.291397 * 100, metric = 3.69% * 100;
 Minibatch[1001-1100]: loss = 0.298719 * 100, metric = 3.64% * 100;
 Minibatch[1101-1200]: loss = 0.299674 * 100, metric = 3.90% * 100;
 Minibatch[1201-1300]: loss = 0.281881 * 100, metric = 3.50% * 100;
 Minibatch[1301-1400]: loss = 0.291354 * 100, metric = 3.69% * 100;
 Minibatch[1401-1500]: loss = 0.274034 * 100, metric = 3.40% * 100;
 Minibatch[1501-1600]: loss = 0.285796 * 100, metric = 3.59% * 100;
 Minibatch[1601-1700]: loss = 0.281298 * 100, metric = 3.51% * 100;
 Minibatch[1701-1800]: loss = 0.293450 * 100, metric = 3.60% * 100;
 Minibatch[1801-1900]: loss = 0.294943 * 100, metric = 3.66% * 100;
 Minibatch[1901-2000]: loss = 0.290707 * 100, metric = 3.48% * 100;
Finished Epoch[91 of 200]: [Training] loss = 0.291865 * 2000, metric = 3.65% * 2000 846.985s (  2.4 samples/s);
Finished Evaluation [91]: Minibatch[1-2000]: metric = 12.19% * 2000;
 Minibatch[   1- 100]: loss = 0.296232 * 100, metric = 3.69% * 100;
 Minibatch[ 101- 200]: loss = 0.290549 * 100, metric = 3.68% * 100;
 Minibatch[ 201- 300]: loss = 0.297189 * 100, metric = 3.71% * 100;
 Minibatch[ 301- 400]: loss = 0.284303 * 100, metric = 3.54% * 100;
 Minibatch[ 401- 500]: loss = 0.296958 * 100, metric = 3.75% * 100;
 Minibatch[ 501- 600]: loss = 0.303787 * 100, metric = 3.93% * 100;
 Minibatch[ 601- 700]: loss = 0.288650 * 100, metric = 3.60% * 100;
 Minibatch[ 701- 800]: loss = 0.304880 * 100, metric = 3.68% * 100;
 Minibatch[ 801- 900]: loss = 0.294824 * 100, metric = 3.78% * 100;
 Minibatch[ 901-1000]: loss = 0.286765 * 100, metric = 3.63% * 100;
 Minibatch[1001-1100]: loss = 0.289247 * 100, metric = 3.51% * 100;
 Minibatch[1101-1200]: loss = 0.286169 * 100, metric = 3.43% * 100;
 Minibatch[1201-1300]: loss = 0.289492 * 100, metric = 3.58% * 100;
 Minibatch[1301-1400]: loss = 0.285401 * 100, metric = 3.57% * 100;
 Minibatch[1401-1500]: loss = 0.285619 * 100, metric = 3.66% * 100;
 Minibatch[1501-1600]: loss = 0.294123 * 100, metric = 3.76% * 100;
 Minibatch[1601-1700]: loss = 0.279474 * 100, metric = 3.50% * 100;
 Minibatch[1701-1800]: loss = 0.275490 * 100, metric = 3.32% * 100;
 Minibatch[1801-1900]: loss = 0.284050 * 100, metric = 3.49% * 100;
 Minibatch[1901-2000]: loss = 0.292605 * 100, metric = 3.66% * 100;
Finished Epoch[92 of 200]: [Training] loss = 0.290290 * 2000, metric = 3.63% * 2000 839.235s (  2.4 samples/s);
Finished Evaluation [92]: Minibatch[1-2000]: metric = 12.34% * 2000;
 Minibatch[   1- 100]: loss = 0.291176 * 100, metric = 3.59% * 100;
 Minibatch[ 101- 200]: loss = 0.292705 * 100, metric = 3.58% * 100;
 Minibatch[ 201- 300]: loss = 0.293349 * 100, metric = 3.76% * 100;
 Minibatch[ 301- 400]: loss = 0.285153 * 100, metric = 3.46% * 100;
 Minibatch[ 401- 500]: loss = 0.281919 * 100, metric = 3.52% * 100;
 Minibatch[ 501- 600]: loss = 0.287736 * 100, metric = 3.65% * 100;
 Minibatch[ 601- 700]: loss = 0.282261 * 100, metric = 3.50% * 100;
 Minibatch[ 701- 800]: loss = 0.285750 * 100, metric = 3.54% * 100;
 Minibatch[ 801- 900]: loss = 0.285223 * 100, metric = 3.53% * 100;
 Minibatch[ 901-1000]: loss = 0.277220 * 100, metric = 3.34% * 100;
 Minibatch[1001-1100]: loss = 0.281738 * 100, metric = 3.50% * 100;
 Minibatch[1101-1200]: loss = 0.283133 * 100, metric = 3.44% * 100;
 Minibatch[1201-1300]: loss = 0.291333 * 100, metric = 3.64% * 100;
 Minibatch[1301-1400]: loss = 0.281367 * 100, metric = 3.54% * 100;
 Minibatch[1401-1500]: loss = 0.285785 * 100, metric = 3.60% * 100;
 Minibatch[1501-1600]: loss = 0.273402 * 100, metric = 3.24% * 100;
 Minibatch[1601-1700]: loss = 0.292741 * 100, metric = 3.67% * 100;
 Minibatch[1701-1800]: loss = 0.288987 * 100, metric = 3.50% * 100;
 Minibatch[1801-1900]: loss = 0.277381 * 100, metric = 3.28% * 100;
 Minibatch[1901-2000]: loss = 0.300003 * 100, metric = 3.59% * 100;
Finished Epoch[93 of 200]: [Training] loss = 0.285918 * 2000, metric = 3.52% * 2000 840.451s (  2.4 samples/s);
Finished Evaluation [93]: Minibatch[1-2000]: metric = 12.73% * 2000;
 Minibatch[   1- 100]: loss = 0.285169 * 100, metric = 3.46% * 100;
 Minibatch[ 101- 200]: loss = 0.297396 * 100, metric = 3.69% * 100;
 Minibatch[ 201- 300]: loss = 0.284288 * 100, metric = 3.55% * 100;
 Minibatch[ 301- 400]: loss = 0.285063 * 100, metric = 3.47% * 100;
 Minibatch[ 401- 500]: loss = 0.275756 * 100, metric = 3.60% * 100;
 Minibatch[ 501- 600]: loss = 0.271707 * 100, metric = 3.23% * 100;
 Minibatch[ 601- 700]: loss = 0.275733 * 100, metric = 3.40% * 100;
 Minibatch[ 701- 800]: loss = 0.290979 * 100, metric = 3.57% * 100;
 Minibatch[ 801- 900]: loss = 0.276568 * 100, metric = 3.38% * 100;
 Minibatch[ 901-1000]: loss = 0.284115 * 100, metric = 3.47% * 100;
 Minibatch[1001-1100]: loss = 0.294875 * 100, metric = 3.51% * 100;
 Minibatch[1101-1200]: loss = 0.289659 * 100, metric = 3.75% * 100;
 Minibatch[1201-1300]: loss = 0.289122 * 100, metric = 3.43% * 100;
 Minibatch[1301-1400]: loss = 0.274212 * 100, metric = 3.16% * 100;
 Minibatch[1401-1500]: loss = 0.289044 * 100, metric = 3.58% * 100;
 Minibatch[1501-1600]: loss = 0.282331 * 100, metric = 3.60% * 100;
 Minibatch[1601-1700]: loss = 0.276205 * 100, metric = 3.59% * 100;
 Minibatch[1701-1800]: loss = 0.280936 * 100, metric = 3.53% * 100;
 Minibatch[1801-1900]: loss = 0.291035 * 100, metric = 3.65% * 100;
 Minibatch[1901-2000]: loss = 0.281120 * 100, metric = 3.50% * 100;
Finished Epoch[94 of 200]: [Training] loss = 0.283766 * 2000, metric = 3.51% * 2000 835.939s (  2.4 samples/s);
Finished Evaluation [94]: Minibatch[1-2000]: metric = 12.72% * 2000;
 Minibatch[   1- 100]: loss = 0.282890 * 100, metric = 3.47% * 100;
 Minibatch[ 101- 200]: loss = 0.282889 * 100, metric = 3.46% * 100;
 Minibatch[ 201- 300]: loss = 0.274713 * 100, metric = 3.28% * 100;
 Minibatch[ 301- 400]: loss = 0.278862 * 100, metric = 3.59% * 100;
 Minibatch[ 401- 500]: loss = 0.281175 * 100, metric = 3.29% * 100;
 Minibatch[ 501- 600]: loss = 0.283237 * 100, metric = 3.39% * 100;
 Minibatch[ 601- 700]: loss = 0.273685 * 100, metric = 3.26% * 100;
 Minibatch[ 701- 800]: loss = 0.286662 * 100, metric = 3.58% * 100;
 Minibatch[ 801- 900]: loss = 0.281334 * 100, metric = 3.51% * 100;
 Minibatch[ 901-1000]: loss = 0.278346 * 100, metric = 3.37% * 100;
 Minibatch[1001-1100]: loss = 0.274889 * 100, metric = 3.38% * 100;
 Minibatch[1101-1200]: loss = 0.281457 * 100, metric = 3.47% * 100;
 Minibatch[1201-1300]: loss = 0.288133 * 100, metric = 3.63% * 100;
 Minibatch[1301-1400]: loss = 0.288449 * 100, metric = 3.37% * 100;
 Minibatch[1401-1500]: loss = 0.292351 * 100, metric = 3.56% * 100;
 Minibatch[1501-1600]: loss = 0.291187 * 100, metric = 3.57% * 100;
 Minibatch[1601-1700]: loss = 0.289103 * 100, metric = 3.56% * 100;
 Minibatch[1701-1800]: loss = 0.269504 * 100, metric = 3.24% * 100;
 Minibatch[1801-1900]: loss = 0.278041 * 100, metric = 3.46% * 100;
 Minibatch[1901-2000]: loss = 0.290032 * 100, metric = 3.54% * 100;
Finished Epoch[95 of 200]: [Training] loss = 0.282347 * 2000, metric = 3.45% * 2000 836.311s (  2.4 samples/s);
Finished Evaluation [95]: Minibatch[1-2000]: metric = 12.16% * 2000;
 Minibatch[   1- 100]: loss = 0.281867 * 100, metric = 3.45% * 100;
 Minibatch[ 101- 200]: loss = 0.288694 * 100, metric = 3.43% * 100;
 Minibatch[ 201- 300]: loss = 0.286961 * 100, metric = 3.58% * 100;
 Minibatch[ 301- 400]: loss = 0.273559 * 100, metric = 3.34% * 100;
 Minibatch[ 401- 500]: loss = 0.282990 * 100, metric = 3.54% * 100;
 Minibatch[ 501- 600]: loss = 0.271616 * 100, metric = 3.39% * 100;
 Minibatch[ 601- 700]: loss = 0.278785 * 100, metric = 3.34% * 100;
 Minibatch[ 701- 800]: loss = 0.301511 * 100, metric = 3.84% * 100;
 Minibatch[ 801- 900]: loss = 0.286082 * 100, metric = 3.62% * 100;
 Minibatch[ 901-1000]: loss = 0.284614 * 100, metric = 3.48% * 100;
 Minibatch[1001-1100]: loss = 0.294844 * 100, metric = 3.84% * 100;
 Minibatch[1101-1200]: loss = 0.275373 * 100, metric = 3.38% * 100;
 Minibatch[1201-1300]: loss = 0.292842 * 100, metric = 3.53% * 100;
 Minibatch[1301-1400]: loss = 0.286174 * 100, metric = 3.53% * 100;
 Minibatch[1401-1500]: loss = 0.283983 * 100, metric = 3.37% * 100;
 Minibatch[1501-1600]: loss = 0.275311 * 100, metric = 3.26% * 100;
 Minibatch[1601-1700]: loss = 0.280400 * 100, metric = 3.47% * 100;
 Minibatch[1701-1800]: loss = 0.295443 * 100, metric = 3.77% * 100;
 Minibatch[1801-1900]: loss = 0.294616 * 100, metric = 3.67% * 100;
 Minibatch[1901-2000]: loss = 0.296434 * 100, metric = 3.79% * 100;
Finished Epoch[96 of 200]: [Training] loss = 0.285605 * 2000, metric = 3.53% * 2000 846.982s (  2.4 samples/s);
Finished Evaluation [96]: Minibatch[1-2000]: metric = 12.10% * 2000;
 Minibatch[   1- 100]: loss = 0.294420 * 100, metric = 3.92% * 100;
 Minibatch[ 101- 200]: loss = 0.273716 * 100, metric = 3.46% * 100;
 Minibatch[ 201- 300]: loss = 0.273540 * 100, metric = 3.25% * 100;
 Minibatch[ 301- 400]: loss = 0.281537 * 100, metric = 3.56% * 100;
 Minibatch[ 401- 500]: loss = 0.281631 * 100, metric = 3.42% * 100;
 Minibatch[ 501- 600]: loss = 0.287678 * 100, metric = 3.47% * 100;
 Minibatch[ 601- 700]: loss = 0.288864 * 100, metric = 3.48% * 100;
 Minibatch[ 701- 800]: loss = 0.297867 * 100, metric = 3.77% * 100;
 Minibatch[ 801- 900]: loss = 0.293193 * 100, metric = 3.65% * 100;
 Minibatch[ 901-1000]: loss = 0.284525 * 100, metric = 3.55% * 100;
 Minibatch[1001-1100]: loss = 0.275518 * 100, metric = 3.36% * 100;
 Minibatch[1101-1200]: loss = 0.293819 * 100, metric = 3.42% * 100;
 Minibatch[1201-1300]: loss = 0.287641 * 100, metric = 3.51% * 100;
 Minibatch[1301-1400]: loss = 0.277949 * 100, metric = 3.36% * 100;
 Minibatch[1401-1500]: loss = 0.282415 * 100, metric = 3.41% * 100;
 Minibatch[1501-1600]: loss = 0.268596 * 100, metric = 3.34% * 100;
 Minibatch[1601-1700]: loss = 0.282047 * 100, metric = 3.33% * 100;
 Minibatch[1701-1800]: loss = 0.286918 * 100, metric = 3.49% * 100;
 Minibatch[1801-1900]: loss = 0.269664 * 100, metric = 3.34% * 100;
 Minibatch[1901-2000]: loss = 0.280627 * 100, metric = 3.47% * 100;
Finished Epoch[97 of 200]: [Training] loss = 0.283108 * 2000, metric = 3.48% * 2000 821.537s (  2.4 samples/s);
Finished Evaluation [97]: Minibatch[1-2000]: metric = 11.74% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
