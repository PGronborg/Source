Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 0.891419 * 100, metric = 24.03% * 100;
 Minibatch[ 101- 200]: loss = 0.692205 * 100, metric = 22.53% * 100;
 Minibatch[ 201- 300]: loss = 0.600414 * 100, metric = 21.38% * 100;
 Minibatch[ 301- 400]: loss = 0.608690 * 100, metric = 21.73% * 100;
 Minibatch[ 401- 500]: loss = 0.541502 * 100, metric = 20.55% * 100;
 Minibatch[ 501- 600]: loss = 0.527303 * 100, metric = 19.72% * 100;
 Minibatch[ 601- 700]: loss = 0.493112 * 100, metric = 18.54% * 100;
 Minibatch[ 701- 800]: loss = 0.454748 * 100, metric = 17.52% * 100;
 Minibatch[ 801- 900]: loss = 0.466873 * 100, metric = 18.05% * 100;
 Minibatch[ 901-1000]: loss = 0.482756 * 100, metric = 18.53% * 100;
 Minibatch[1001-1100]: loss = 0.455672 * 100, metric = 17.81% * 100;
 Minibatch[1101-1200]: loss = 0.440458 * 100, metric = 16.98% * 100;
 Minibatch[1201-1300]: loss = 0.445671 * 100, metric = 17.83% * 100;
 Minibatch[1301-1400]: loss = 0.424800 * 100, metric = 16.57% * 100;
 Minibatch[1401-1500]: loss = 0.441612 * 100, metric = 16.97% * 100;
 Minibatch[1501-1600]: loss = 0.417276 * 100, metric = 16.71% * 100;
 Minibatch[1601-1700]: loss = 0.416635 * 100, metric = 16.23% * 100;
 Minibatch[1701-1800]: loss = 0.424876 * 100, metric = 16.90% * 100;
 Minibatch[1801-1900]: loss = 0.420709 * 100, metric = 16.29% * 100;
 Minibatch[1901-2000]: loss = 0.409787 * 100, metric = 15.94% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.502826 * 2000, metric = 18.54% * 2000 1181.720s (  1.7 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 23.69% * 2000;
0.5579291137233376
 Minibatch[   1- 100]: loss = 0.407093 * 100, metric = 16.06% * 100;
 Minibatch[ 101- 200]: loss = 0.418214 * 100, metric = 16.58% * 100;
 Minibatch[ 201- 300]: loss = 0.400402 * 100, metric = 15.45% * 100;
 Minibatch[ 301- 400]: loss = 0.417957 * 100, metric = 16.04% * 100;
 Minibatch[ 401- 500]: loss = 0.401414 * 100, metric = 15.57% * 100;
 Minibatch[ 501- 600]: loss = 0.416953 * 100, metric = 15.60% * 100;
 Minibatch[ 601- 700]: loss = 0.399274 * 100, metric = 15.43% * 100;
 Minibatch[ 701- 800]: loss = 0.409019 * 100, metric = 16.38% * 100;
 Minibatch[ 801- 900]: loss = 0.391695 * 100, metric = 15.68% * 100;
 Minibatch[ 901-1000]: loss = 0.378521 * 100, metric = 14.82% * 100;
 Minibatch[1001-1100]: loss = 0.399255 * 100, metric = 15.64% * 100;
 Minibatch[1101-1200]: loss = 0.392430 * 100, metric = 15.41% * 100;
 Minibatch[1201-1300]: loss = 0.382528 * 100, metric = 15.33% * 100;
 Minibatch[1301-1400]: loss = 0.398621 * 100, metric = 15.37% * 100;
 Minibatch[1401-1500]: loss = 0.382773 * 100, metric = 14.73% * 100;
 Minibatch[1501-1600]: loss = 0.375648 * 100, metric = 14.71% * 100;
 Minibatch[1601-1700]: loss = 0.392318 * 100, metric = 14.91% * 100;
 Minibatch[1701-1800]: loss = 0.389779 * 100, metric = 15.22% * 100;
 Minibatch[1801-1900]: loss = 0.382590 * 100, metric = 14.80% * 100;
 Minibatch[1901-2000]: loss = 0.364851 * 100, metric = 14.31% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.395067 * 2000, metric = 15.40% * 2000 1115.166s (  1.8 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 21.59% * 2000;
0.49870618190988897
 Minibatch[   1- 100]: loss = 0.374600 * 100, metric = 14.65% * 100;
 Minibatch[ 101- 200]: loss = 0.386986 * 100, metric = 15.20% * 100;
 Minibatch[ 201- 300]: loss = 0.370009 * 100, metric = 14.59% * 100;
 Minibatch[ 301- 400]: loss = 0.381562 * 100, metric = 14.84% * 100;
 Minibatch[ 401- 500]: loss = 0.389871 * 100, metric = 15.11% * 100;
 Minibatch[ 501- 600]: loss = 0.379495 * 100, metric = 14.71% * 100;
 Minibatch[ 601- 700]: loss = 0.383902 * 100, metric = 14.76% * 100;
 Minibatch[ 701- 800]: loss = 0.357581 * 100, metric = 13.70% * 100;
 Minibatch[ 801- 900]: loss = 0.382803 * 100, metric = 14.50% * 100;
 Minibatch[ 901-1000]: loss = 0.359509 * 100, metric = 14.12% * 100;
 Minibatch[1001-1100]: loss = 0.373047 * 100, metric = 14.78% * 100;
 Minibatch[1101-1200]: loss = 0.358362 * 100, metric = 14.16% * 100;
 Minibatch[1201-1300]: loss = 0.362101 * 100, metric = 14.12% * 100;
 Minibatch[1301-1400]: loss = 0.372042 * 100, metric = 14.56% * 100;
 Minibatch[1401-1500]: loss = 0.374959 * 100, metric = 14.68% * 100;
 Minibatch[1501-1600]: loss = 0.362855 * 100, metric = 14.09% * 100;
 Minibatch[1601-1700]: loss = 0.354545 * 100, metric = 13.66% * 100;
 Minibatch[1701-1800]: loss = 0.372043 * 100, metric = 14.47% * 100;
 Minibatch[1801-1900]: loss = 0.361522 * 100, metric = 14.14% * 100;
 Minibatch[1901-2000]: loss = 0.361009 * 100, metric = 14.48% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.370940 * 2000, metric = 14.47% * 2000 1130.942s (  1.8 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 20.50% * 2000;
0.48147236204147337
 Minibatch[   1- 100]: loss = 0.375975 * 100, metric = 14.30% * 100;
 Minibatch[ 101- 200]: loss = 0.355416 * 100, metric = 13.80% * 100;
 Minibatch[ 201- 300]: loss = 0.363902 * 100, metric = 14.37% * 100;
 Minibatch[ 301- 400]: loss = 0.335578 * 100, metric = 13.18% * 100;
 Minibatch[ 401- 500]: loss = 0.363842 * 100, metric = 13.98% * 100;
 Minibatch[ 501- 600]: loss = 0.340798 * 100, metric = 13.32% * 100;
 Minibatch[ 601- 700]: loss = 0.355861 * 100, metric = 14.25% * 100;
 Minibatch[ 701- 800]: loss = 0.355698 * 100, metric = 13.96% * 100;
 Minibatch[ 801- 900]: loss = 0.354422 * 100, metric = 13.79% * 100;
 Minibatch[ 901-1000]: loss = 0.360009 * 100, metric = 14.26% * 100;
 Minibatch[1001-1100]: loss = 0.369110 * 100, metric = 14.60% * 100;
 Minibatch[1101-1200]: loss = 0.343655 * 100, metric = 13.70% * 100;
 Minibatch[1201-1300]: loss = 0.347159 * 100, metric = 13.61% * 100;
 Minibatch[1301-1400]: loss = 0.361581 * 100, metric = 14.22% * 100;
 Minibatch[1401-1500]: loss = 0.360802 * 100, metric = 14.24% * 100;
 Minibatch[1501-1600]: loss = 0.336999 * 100, metric = 13.29% * 100;
 Minibatch[1601-1700]: loss = 0.354912 * 100, metric = 14.28% * 100;
 Minibatch[1701-1800]: loss = 0.360961 * 100, metric = 14.19% * 100;
 Minibatch[1801-1900]: loss = 0.348295 * 100, metric = 13.55% * 100;
 Minibatch[1901-2000]: loss = 0.344163 * 100, metric = 13.45% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.354457 * 2000, metric = 13.92% * 2000 1141.713s (  1.8 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 22.11% * 2000;
 Minibatch[   1- 100]: loss = 0.364588 * 100, metric = 14.24% * 100;
 Minibatch[ 101- 200]: loss = 0.345451 * 100, metric = 13.75% * 100;
 Minibatch[ 201- 300]: loss = 0.341900 * 100, metric = 13.41% * 100;
 Minibatch[ 301- 400]: loss = 0.366432 * 100, metric = 14.33% * 100;
 Minibatch[ 401- 500]: loss = 0.336105 * 100, metric = 13.23% * 100;
 Minibatch[ 501- 600]: loss = 0.333820 * 100, metric = 12.91% * 100;
 Minibatch[ 601- 700]: loss = 0.343338 * 100, metric = 13.15% * 100;
 Minibatch[ 701- 800]: loss = 0.354203 * 100, metric = 13.59% * 100;
 Minibatch[ 801- 900]: loss = 0.331556 * 100, metric = 13.07% * 100;
 Minibatch[ 901-1000]: loss = 0.338555 * 100, metric = 13.29% * 100;
 Minibatch[1001-1100]: loss = 0.339733 * 100, metric = 13.12% * 100;
 Minibatch[1101-1200]: loss = 0.335468 * 100, metric = 13.21% * 100;
 Minibatch[1201-1300]: loss = 0.343331 * 100, metric = 13.34% * 100;
 Minibatch[1301-1400]: loss = 0.353831 * 100, metric = 13.87% * 100;
 Minibatch[1401-1500]: loss = 0.342633 * 100, metric = 13.58% * 100;
 Minibatch[1501-1600]: loss = 0.343019 * 100, metric = 13.47% * 100;
 Minibatch[1601-1700]: loss = 0.356580 * 100, metric = 14.19% * 100;
 Minibatch[1701-1800]: loss = 0.351107 * 100, metric = 13.74% * 100;
 Minibatch[1801-1900]: loss = 0.349221 * 100, metric = 13.45% * 100;
 Minibatch[1901-2000]: loss = 0.336386 * 100, metric = 13.04% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.345363 * 2000, metric = 13.50% * 2000 1140.428s (  1.8 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 21.03% * 2000;
 Minibatch[   1- 100]: loss = 0.329757 * 100, metric = 12.99% * 100;
 Minibatch[ 101- 200]: loss = 0.334770 * 100, metric = 13.30% * 100;
 Minibatch[ 201- 300]: loss = 0.342807 * 100, metric = 13.43% * 100;
 Minibatch[ 301- 400]: loss = 0.343016 * 100, metric = 13.20% * 100;
 Minibatch[ 401- 500]: loss = 0.321061 * 100, metric = 12.62% * 100;
 Minibatch[ 501- 600]: loss = 0.334060 * 100, metric = 13.10% * 100;
 Minibatch[ 601- 700]: loss = 0.328229 * 100, metric = 13.04% * 100;
 Minibatch[ 701- 800]: loss = 0.335209 * 100, metric = 13.26% * 100;
 Minibatch[ 801- 900]: loss = 0.339132 * 100, metric = 13.31% * 100;
 Minibatch[ 901-1000]: loss = 0.333593 * 100, metric = 12.94% * 100;
 Minibatch[1001-1100]: loss = 0.332934 * 100, metric = 12.78% * 100;
 Minibatch[1101-1200]: loss = 0.343259 * 100, metric = 13.31% * 100;
 Minibatch[1201-1300]: loss = 0.350047 * 100, metric = 13.62% * 100;
 Minibatch[1301-1400]: loss = 0.331957 * 100, metric = 13.00% * 100;
 Minibatch[1401-1500]: loss = 0.338099 * 100, metric = 13.54% * 100;
 Minibatch[1501-1600]: loss = 0.325282 * 100, metric = 12.62% * 100;
 Minibatch[1601-1700]: loss = 0.326224 * 100, metric = 12.69% * 100;
 Minibatch[1701-1800]: loss = 0.316965 * 100, metric = 12.35% * 100;
 Minibatch[1801-1900]: loss = 0.332853 * 100, metric = 13.00% * 100;
 Minibatch[1901-2000]: loss = 0.321526 * 100, metric = 12.54% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.333039 * 2000, metric = 13.03% * 2000 1144.397s (  1.7 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.84% * 2000;
 Minibatch[   1- 100]: loss = 0.322401 * 100, metric = 12.73% * 100;
 Minibatch[ 101- 200]: loss = 0.335808 * 100, metric = 12.82% * 100;
 Minibatch[ 201- 300]: loss = 0.340864 * 100, metric = 13.09% * 100;
 Minibatch[ 301- 400]: loss = 0.322880 * 100, metric = 12.49% * 100;
 Minibatch[ 401- 500]: loss = 0.335750 * 100, metric = 12.98% * 100;
 Minibatch[ 501- 600]: loss = 0.316067 * 100, metric = 12.30% * 100;
 Minibatch[ 601- 700]: loss = 0.324288 * 100, metric = 12.64% * 100;
 Minibatch[ 701- 800]: loss = 0.333963 * 100, metric = 13.01% * 100;
 Minibatch[ 801- 900]: loss = 0.336909 * 100, metric = 13.09% * 100;
 Minibatch[ 901-1000]: loss = 0.329323 * 100, metric = 12.92% * 100;
 Minibatch[1001-1100]: loss = 0.337606 * 100, metric = 13.21% * 100;
 Minibatch[1101-1200]: loss = 0.323502 * 100, metric = 12.56% * 100;
 Minibatch[1201-1300]: loss = 0.330270 * 100, metric = 13.09% * 100;
 Minibatch[1301-1400]: loss = 0.321310 * 100, metric = 12.76% * 100;
 Minibatch[1401-1500]: loss = 0.319619 * 100, metric = 12.33% * 100;
 Minibatch[1501-1600]: loss = 0.328763 * 100, metric = 13.00% * 100;
 Minibatch[1601-1700]: loss = 0.331405 * 100, metric = 13.14% * 100;
 Minibatch[1701-1800]: loss = 0.328946 * 100, metric = 12.57% * 100;
 Minibatch[1801-1900]: loss = 0.327100 * 100, metric = 12.92% * 100;
 Minibatch[1901-2000]: loss = 0.335101 * 100, metric = 13.25% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.329094 * 2000, metric = 12.84% * 2000 1140.002s (  1.8 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 19.18% * 2000;
0.4491767478846014
 Minibatch[   1- 100]: loss = 0.326791 * 100, metric = 12.88% * 100;
 Minibatch[ 101- 200]: loss = 0.327741 * 100, metric = 12.89% * 100;
 Minibatch[ 201- 300]: loss = 0.311760 * 100, metric = 12.32% * 100;
 Minibatch[ 301- 400]: loss = 0.316626 * 100, metric = 12.68% * 100;
 Minibatch[ 401- 500]: loss = 0.328843 * 100, metric = 12.96% * 100;
 Minibatch[ 501- 600]: loss = 0.337373 * 100, metric = 13.31% * 100;
 Minibatch[ 601- 700]: loss = 0.305817 * 100, metric = 12.00% * 100;
 Minibatch[ 701- 800]: loss = 0.330607 * 100, metric = 12.75% * 100;
 Minibatch[ 801- 900]: loss = 0.308529 * 100, metric = 11.88% * 100;
 Minibatch[ 901-1000]: loss = 0.296091 * 100, metric = 11.62% * 100;
 Minibatch[1001-1100]: loss = 0.308983 * 100, metric = 12.28% * 100;
 Minibatch[1101-1200]: loss = 0.311372 * 100, metric = 12.25% * 100;
 Minibatch[1201-1300]: loss = 0.329503 * 100, metric = 12.71% * 100;
 Minibatch[1301-1400]: loss = 0.325670 * 100, metric = 12.70% * 100;
 Minibatch[1401-1500]: loss = 0.310298 * 100, metric = 11.98% * 100;
 Minibatch[1501-1600]: loss = 0.325776 * 100, metric = 12.79% * 100;
 Minibatch[1601-1700]: loss = 0.314398 * 100, metric = 12.25% * 100;
 Minibatch[1701-1800]: loss = 0.316340 * 100, metric = 12.01% * 100;
 Minibatch[1801-1900]: loss = 0.319850 * 100, metric = 12.30% * 100;
 Minibatch[1901-2000]: loss = 0.313456 * 100, metric = 12.47% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.318291 * 2000, metric = 12.45% * 2000 1144.506s (  1.7 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 18.05% * 2000;
0.42534075166657564
 Minibatch[   1- 100]: loss = 0.301744 * 100, metric = 11.74% * 100;
 Minibatch[ 101- 200]: loss = 0.329080 * 100, metric = 12.70% * 100;
 Minibatch[ 201- 300]: loss = 0.305814 * 100, metric = 11.94% * 100;
 Minibatch[ 301- 400]: loss = 0.326763 * 100, metric = 12.45% * 100;
 Minibatch[ 401- 500]: loss = 0.317902 * 100, metric = 12.12% * 100;
 Minibatch[ 501- 600]: loss = 0.306149 * 100, metric = 11.88% * 100;
 Minibatch[ 601- 700]: loss = 0.312380 * 100, metric = 12.11% * 100;
 Minibatch[ 701- 800]: loss = 0.297890 * 100, metric = 11.77% * 100;
 Minibatch[ 801- 900]: loss = 0.300972 * 100, metric = 11.88% * 100;
 Minibatch[ 901-1000]: loss = 0.315876 * 100, metric = 12.28% * 100;
 Minibatch[1001-1100]: loss = 0.286163 * 100, metric = 11.24% * 100;
 Minibatch[1101-1200]: loss = 0.304128 * 100, metric = 11.96% * 100;
 Minibatch[1201-1300]: loss = 0.310897 * 100, metric = 12.38% * 100;
 Minibatch[1301-1400]: loss = 0.304276 * 100, metric = 11.66% * 100;
 Minibatch[1401-1500]: loss = 0.318353 * 100, metric = 12.37% * 100;
 Minibatch[1501-1600]: loss = 0.309720 * 100, metric = 11.99% * 100;
 Minibatch[1601-1700]: loss = 0.312516 * 100, metric = 12.18% * 100;
 Minibatch[1701-1800]: loss = 0.304168 * 100, metric = 11.53% * 100;
 Minibatch[1801-1900]: loss = 0.305322 * 100, metric = 11.93% * 100;
 Minibatch[1901-2000]: loss = 0.305057 * 100, metric = 11.79% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.308759 * 2000, metric = 11.99% * 2000 1144.462s (  1.7 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 17.46% * 2000;
0.4202705355621874
 Minibatch[   1- 100]: loss = 0.322671 * 100, metric = 12.73% * 100;
 Minibatch[ 101- 200]: loss = 0.304158 * 100, metric = 11.79% * 100;
 Minibatch[ 201- 300]: loss = 0.308462 * 100, metric = 11.84% * 100;
 Minibatch[ 301- 400]: loss = 0.300107 * 100, metric = 11.78% * 100;
 Minibatch[ 401- 500]: loss = 0.313373 * 100, metric = 12.31% * 100;
 Minibatch[ 501- 600]: loss = 0.293421 * 100, metric = 11.49% * 100;
 Minibatch[ 601- 700]: loss = 0.291568 * 100, metric = 11.33% * 100;
 Minibatch[ 701- 800]: loss = 0.287763 * 100, metric = 11.03% * 100;
 Minibatch[ 801- 900]: loss = 0.297831 * 100, metric = 11.60% * 100;
 Minibatch[ 901-1000]: loss = 0.305826 * 100, metric = 11.82% * 100;
 Minibatch[1001-1100]: loss = 0.311622 * 100, metric = 12.29% * 100;
 Minibatch[1101-1200]: loss = 0.304498 * 100, metric = 11.69% * 100;
 Minibatch[1201-1300]: loss = 0.302182 * 100, metric = 11.97% * 100;
 Minibatch[1301-1400]: loss = 0.301689 * 100, metric = 11.67% * 100;
 Minibatch[1401-1500]: loss = 0.289644 * 100, metric = 11.31% * 100;
 Minibatch[1501-1600]: loss = 0.301454 * 100, metric = 11.89% * 100;
 Minibatch[1601-1700]: loss = 0.298171 * 100, metric = 11.57% * 100;
 Minibatch[1701-1800]: loss = 0.304626 * 100, metric = 11.59% * 100;
 Minibatch[1801-1900]: loss = 0.304099 * 100, metric = 11.96% * 100;
 Minibatch[1901-2000]: loss = 0.294985 * 100, metric = 11.55% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.301907 * 2000, metric = 11.76% * 2000 1134.721s (  1.8 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 17.37% * 2000;
0.42025322519615294
 Minibatch[   1- 100]: loss = 0.280363 * 100, metric = 10.88% * 100;
 Minibatch[ 101- 200]: loss = 0.292442 * 100, metric = 11.46% * 100;
 Minibatch[ 201- 300]: loss = 0.301832 * 100, metric = 11.88% * 100;
 Minibatch[ 301- 400]: loss = 0.295555 * 100, metric = 11.69% * 100;
 Minibatch[ 401- 500]: loss = 0.298082 * 100, metric = 11.52% * 100;
 Minibatch[ 501- 600]: loss = 0.306664 * 100, metric = 11.80% * 100;
 Minibatch[ 601- 700]: loss = 0.293097 * 100, metric = 11.25% * 100;
 Minibatch[ 701- 800]: loss = 0.301306 * 100, metric = 11.81% * 100;
 Minibatch[ 801- 900]: loss = 0.296496 * 100, metric = 11.37% * 100;
 Minibatch[ 901-1000]: loss = 0.303703 * 100, metric = 11.65% * 100;
 Minibatch[1001-1100]: loss = 0.292432 * 100, metric = 11.47% * 100;
 Minibatch[1101-1200]: loss = 0.299853 * 100, metric = 11.52% * 100;
 Minibatch[1201-1300]: loss = 0.287216 * 100, metric = 11.17% * 100;
 Minibatch[1301-1400]: loss = 0.284786 * 100, metric = 11.25% * 100;
 Minibatch[1401-1500]: loss = 0.298506 * 100, metric = 11.49% * 100;
 Minibatch[1501-1600]: loss = 0.288667 * 100, metric = 11.18% * 100;
 Minibatch[1601-1700]: loss = 0.289738 * 100, metric = 11.31% * 100;
 Minibatch[1701-1800]: loss = 0.296733 * 100, metric = 11.58% * 100;
 Minibatch[1801-1900]: loss = 0.296459 * 100, metric = 11.44% * 100;
 Minibatch[1901-2000]: loss = 0.288345 * 100, metric = 11.27% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.294614 * 2000, metric = 11.45% * 2000 1132.633s (  1.8 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 18.13% * 2000;
 Minibatch[   1- 100]: loss = 0.279911 * 100, metric = 10.80% * 100;
 Minibatch[ 101- 200]: loss = 0.276260 * 100, metric = 10.79% * 100;
 Minibatch[ 201- 300]: loss = 0.288844 * 100, metric = 11.37% * 100;
 Minibatch[ 301- 400]: loss = 0.309621 * 100, metric = 12.12% * 100;
 Minibatch[ 401- 500]: loss = 0.285381 * 100, metric = 11.09% * 100;
 Minibatch[ 501- 600]: loss = 0.277783 * 100, metric = 10.82% * 100;
 Minibatch[ 601- 700]: loss = 0.284127 * 100, metric = 11.29% * 100;
 Minibatch[ 701- 800]: loss = 0.291581 * 100, metric = 11.38% * 100;
 Minibatch[ 801- 900]: loss = 0.285823 * 100, metric = 10.90% * 100;
 Minibatch[ 901-1000]: loss = 0.294338 * 100, metric = 11.35% * 100;
 Minibatch[1001-1100]: loss = 0.289752 * 100, metric = 11.50% * 100;
 Minibatch[1101-1200]: loss = 0.291404 * 100, metric = 11.37% * 100;
 Minibatch[1201-1300]: loss = 0.302105 * 100, metric = 11.74% * 100;
 Minibatch[1301-1400]: loss = 0.286748 * 100, metric = 11.16% * 100;
 Minibatch[1401-1500]: loss = 0.295736 * 100, metric = 11.71% * 100;
 Minibatch[1501-1600]: loss = 0.282452 * 100, metric = 11.00% * 100;
 Minibatch[1601-1700]: loss = 0.293652 * 100, metric = 11.38% * 100;
 Minibatch[1701-1800]: loss = 0.280333 * 100, metric = 11.01% * 100;
 Minibatch[1801-1900]: loss = 0.282790 * 100, metric = 11.00% * 100;
 Minibatch[1901-2000]: loss = 0.298397 * 100, metric = 11.53% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.288852 * 2000, metric = 11.27% * 2000 1125.786s (  1.8 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 18.03% * 2000;
 Minibatch[   1- 100]: loss = 0.289194 * 100, metric = 11.39% * 100;
 Minibatch[ 101- 200]: loss = 0.289358 * 100, metric = 11.26% * 100;
 Minibatch[ 201- 300]: loss = 0.284827 * 100, metric = 11.03% * 100;
 Minibatch[ 301- 400]: loss = 0.284962 * 100, metric = 10.99% * 100;
 Minibatch[ 401- 500]: loss = 0.297241 * 100, metric = 11.69% * 100;
 Minibatch[ 501- 600]: loss = 0.293301 * 100, metric = 11.42% * 100;
 Minibatch[ 601- 700]: loss = 0.277494 * 100, metric = 10.43% * 100;
 Minibatch[ 701- 800]: loss = 0.271166 * 100, metric = 10.60% * 100;
 Minibatch[ 801- 900]: loss = 0.278999 * 100, metric = 10.78% * 100;
 Minibatch[ 901-1000]: loss = 0.290967 * 100, metric = 11.40% * 100;
 Minibatch[1001-1100]: loss = 0.294528 * 100, metric = 11.46% * 100;
 Minibatch[1101-1200]: loss = 0.278463 * 100, metric = 10.82% * 100;
 Minibatch[1201-1300]: loss = 0.283617 * 100, metric = 11.18% * 100;
 Minibatch[1301-1400]: loss = 0.279251 * 100, metric = 10.96% * 100;
 Minibatch[1401-1500]: loss = 0.275978 * 100, metric = 10.69% * 100;
 Minibatch[1501-1600]: loss = 0.274558 * 100, metric = 10.76% * 100;
 Minibatch[1601-1700]: loss = 0.273214 * 100, metric = 10.69% * 100;
 Minibatch[1701-1800]: loss = 0.279661 * 100, metric = 10.64% * 100;
 Minibatch[1801-1900]: loss = 0.271104 * 100, metric = 10.45% * 100;
 Minibatch[1901-2000]: loss = 0.285067 * 100, metric = 11.14% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.282647 * 2000, metric = 10.99% * 2000 1111.799s (  1.8 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 19.44% * 2000;
 Minibatch[   1- 100]: loss = 0.280269 * 100, metric = 10.81% * 100;
 Minibatch[ 101- 200]: loss = 0.271378 * 100, metric = 10.53% * 100;
 Minibatch[ 201- 300]: loss = 0.286302 * 100, metric = 11.26% * 100;
 Minibatch[ 301- 400]: loss = 0.282712 * 100, metric = 10.99% * 100;
 Minibatch[ 401- 500]: loss = 0.280082 * 100, metric = 10.81% * 100;
 Minibatch[ 501- 600]: loss = 0.274431 * 100, metric = 10.73% * 100;
 Minibatch[ 601- 700]: loss = 0.281804 * 100, metric = 10.85% * 100;
 Minibatch[ 701- 800]: loss = 0.287593 * 100, metric = 11.04% * 100;
 Minibatch[ 801- 900]: loss = 0.292031 * 100, metric = 11.32% * 100;
 Minibatch[ 901-1000]: loss = 0.279892 * 100, metric = 11.07% * 100;
 Minibatch[1001-1100]: loss = 0.285838 * 100, metric = 11.09% * 100;
 Minibatch[1101-1200]: loss = 0.276609 * 100, metric = 10.76% * 100;
 Minibatch[1201-1300]: loss = 0.264361 * 100, metric = 10.09% * 100;
 Minibatch[1301-1400]: loss = 0.283374 * 100, metric = 11.08% * 100;
 Minibatch[1401-1500]: loss = 0.276827 * 100, metric = 10.83% * 100;
 Minibatch[1501-1600]: loss = 0.269030 * 100, metric = 10.58% * 100;
 Minibatch[1601-1700]: loss = 0.272473 * 100, metric = 10.69% * 100;
 Minibatch[1701-1800]: loss = 0.266710 * 100, metric = 10.28% * 100;
 Minibatch[1801-1900]: loss = 0.272797 * 100, metric = 10.63% * 100;
 Minibatch[1901-2000]: loss = 0.273231 * 100, metric = 10.50% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.277887 * 2000, metric = 10.80% * 2000 1121.896s (  1.8 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 18.75% * 2000;
 Minibatch[   1- 100]: loss = 0.269726 * 100, metric = 10.41% * 100;
 Minibatch[ 101- 200]: loss = 0.272941 * 100, metric = 10.71% * 100;
 Minibatch[ 201- 300]: loss = 0.277150 * 100, metric = 10.77% * 100;
 Minibatch[ 301- 400]: loss = 0.263896 * 100, metric = 10.06% * 100;
 Minibatch[ 401- 500]: loss = 0.270264 * 100, metric = 10.61% * 100;
 Minibatch[ 501- 600]: loss = 0.261809 * 100, metric = 9.97% * 100;
 Minibatch[ 601- 700]: loss = 0.260512 * 100, metric = 10.12% * 100;
 Minibatch[ 701- 800]: loss = 0.282151 * 100, metric = 10.85% * 100;
 Minibatch[ 801- 900]: loss = 0.288739 * 100, metric = 11.22% * 100;
 Minibatch[ 901-1000]: loss = 0.271403 * 100, metric = 10.85% * 100;
 Minibatch[1001-1100]: loss = 0.272270 * 100, metric = 10.63% * 100;
 Minibatch[1101-1200]: loss = 0.273763 * 100, metric = 10.68% * 100;
 Minibatch[1201-1300]: loss = 0.261132 * 100, metric = 10.14% * 100;
 Minibatch[1301-1400]: loss = 0.289905 * 100, metric = 11.16% * 100;
 Minibatch[1401-1500]: loss = 0.253370 * 100, metric = 10.06% * 100;
 Minibatch[1501-1600]: loss = 0.270200 * 100, metric = 10.35% * 100;
 Minibatch[1601-1700]: loss = 0.267565 * 100, metric = 10.19% * 100;
 Minibatch[1701-1800]: loss = 0.262159 * 100, metric = 10.00% * 100;
 Minibatch[1801-1900]: loss = 0.272386 * 100, metric = 10.42% * 100;
 Minibatch[1901-2000]: loss = 0.262581 * 100, metric = 10.13% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.270196 * 2000, metric = 10.47% * 2000 1113.702s (  1.8 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 16.96% * 2000;
 Minibatch[   1- 100]: loss = 0.278408 * 100, metric = 11.01% * 100;
 Minibatch[ 101- 200]: loss = 0.267753 * 100, metric = 10.56% * 100;
 Minibatch[ 201- 300]: loss = 0.269297 * 100, metric = 10.36% * 100;
 Minibatch[ 301- 400]: loss = 0.271423 * 100, metric = 10.57% * 100;
 Minibatch[ 401- 500]: loss = 0.257802 * 100, metric = 9.94% * 100;
 Minibatch[ 501- 600]: loss = 0.273118 * 100, metric = 10.31% * 100;
 Minibatch[ 601- 700]: loss = 0.265269 * 100, metric = 10.39% * 100;
 Minibatch[ 701- 800]: loss = 0.265079 * 100, metric = 10.30% * 100;
 Minibatch[ 801- 900]: loss = 0.255534 * 100, metric = 10.09% * 100;
 Minibatch[ 901-1000]: loss = 0.270614 * 100, metric = 10.71% * 100;
 Minibatch[1001-1100]: loss = 0.257374 * 100, metric = 9.96% * 100;
 Minibatch[1101-1200]: loss = 0.258471 * 100, metric = 10.23% * 100;
 Minibatch[1201-1300]: loss = 0.255232 * 100, metric = 9.96% * 100;
 Minibatch[1301-1400]: loss = 0.261564 * 100, metric = 10.27% * 100;
 Minibatch[1401-1500]: loss = 0.261099 * 100, metric = 10.28% * 100;
 Minibatch[1501-1600]: loss = 0.262389 * 100, metric = 10.42% * 100;
 Minibatch[1601-1700]: loss = 0.259509 * 100, metric = 10.07% * 100;
 Minibatch[1701-1800]: loss = 0.273135 * 100, metric = 10.48% * 100;
 Minibatch[1801-1900]: loss = 0.269257 * 100, metric = 10.50% * 100;
 Minibatch[1901-2000]: loss = 0.257453 * 100, metric = 10.06% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.264489 * 2000, metric = 10.32% * 2000 1113.959s (  1.8 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 16.98% * 2000;
 Minibatch[   1- 100]: loss = 0.252491 * 100, metric = 10.04% * 100;
 Minibatch[ 101- 200]: loss = 0.266192 * 100, metric = 10.34% * 100;
 Minibatch[ 201- 300]: loss = 0.268157 * 100, metric = 10.37% * 100;
 Minibatch[ 301- 400]: loss = 0.264158 * 100, metric = 10.28% * 100;
 Minibatch[ 401- 500]: loss = 0.261867 * 100, metric = 10.25% * 100;
 Minibatch[ 501- 600]: loss = 0.252697 * 100, metric = 9.83% * 100;
 Minibatch[ 601- 700]: loss = 0.247552 * 100, metric = 9.62% * 100;
 Minibatch[ 701- 800]: loss = 0.258303 * 100, metric = 10.02% * 100;
 Minibatch[ 801- 900]: loss = 0.262442 * 100, metric = 10.08% * 100;
 Minibatch[ 901-1000]: loss = 0.253086 * 100, metric = 9.87% * 100;
 Minibatch[1001-1100]: loss = 0.255220 * 100, metric = 9.72% * 100;
 Minibatch[1101-1200]: loss = 0.263468 * 100, metric = 10.26% * 100;
 Minibatch[1201-1300]: loss = 0.260578 * 100, metric = 10.12% * 100;
 Minibatch[1301-1400]: loss = 0.245555 * 100, metric = 9.47% * 100;
 Minibatch[1401-1500]: loss = 0.258045 * 100, metric = 10.21% * 100;
 Minibatch[1501-1600]: loss = 0.259788 * 100, metric = 10.04% * 100;
 Minibatch[1601-1700]: loss = 0.257428 * 100, metric = 9.93% * 100;
 Minibatch[1701-1800]: loss = 0.253765 * 100, metric = 9.89% * 100;
 Minibatch[1801-1900]: loss = 0.271999 * 100, metric = 10.73% * 100;
 Minibatch[1901-2000]: loss = 0.270962 * 100, metric = 10.65% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.259188 * 2000, metric = 10.09% * 2000 1094.811s (  1.8 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 16.62% * 2000;
 Minibatch[   1- 100]: loss = 0.244635 * 100, metric = 9.40% * 100;
 Minibatch[ 101- 200]: loss = 0.261518 * 100, metric = 10.22% * 100;
 Minibatch[ 201- 300]: loss = 0.245296 * 100, metric = 9.68% * 100;
 Minibatch[ 301- 400]: loss = 0.248001 * 100, metric = 9.65% * 100;
 Minibatch[ 401- 500]: loss = 0.244706 * 100, metric = 9.66% * 100;
 Minibatch[ 501- 600]: loss = 0.248734 * 100, metric = 9.66% * 100;
 Minibatch[ 601- 700]: loss = 0.260206 * 100, metric = 10.26% * 100;
 Minibatch[ 701- 800]: loss = 0.246345 * 100, metric = 9.67% * 100;
 Minibatch[ 801- 900]: loss = 0.259977 * 100, metric = 9.98% * 100;
 Minibatch[ 901-1000]: loss = 0.257153 * 100, metric = 10.05% * 100;
 Minibatch[1001-1100]: loss = 0.264057 * 100, metric = 10.15% * 100;
 Minibatch[1101-1200]: loss = 0.256277 * 100, metric = 10.00% * 100;
 Minibatch[1201-1300]: loss = 0.263199 * 100, metric = 10.34% * 100;
 Minibatch[1301-1400]: loss = 0.266119 * 100, metric = 10.34% * 100;
 Minibatch[1401-1500]: loss = 0.240865 * 100, metric = 9.32% * 100;
 Minibatch[1501-1600]: loss = 0.253865 * 100, metric = 9.90% * 100;
 Minibatch[1601-1700]: loss = 0.239199 * 100, metric = 9.34% * 100;
 Minibatch[1701-1800]: loss = 0.250097 * 100, metric = 9.85% * 100;
 Minibatch[1801-1900]: loss = 0.239815 * 100, metric = 9.43% * 100;
 Minibatch[1901-2000]: loss = 0.240092 * 100, metric = 9.25% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.251508 * 2000, metric = 9.81% * 2000 1092.973s (  1.8 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 17.04% * 2000;
 Minibatch[   1- 100]: loss = 0.257748 * 100, metric = 10.01% * 100;
 Minibatch[ 101- 200]: loss = 0.262171 * 100, metric = 10.12% * 100;
 Minibatch[ 201- 300]: loss = 0.235569 * 100, metric = 9.08% * 100;
 Minibatch[ 301- 400]: loss = 0.252769 * 100, metric = 9.92% * 100;
 Minibatch[ 401- 500]: loss = 0.248334 * 100, metric = 9.68% * 100;
 Minibatch[ 501- 600]: loss = 0.237979 * 100, metric = 9.21% * 100;
 Minibatch[ 601- 700]: loss = 0.255583 * 100, metric = 10.03% * 100;
 Minibatch[ 701- 800]: loss = 0.241421 * 100, metric = 9.32% * 100;
 Minibatch[ 801- 900]: loss = 0.263875 * 100, metric = 10.17% * 100;
 Minibatch[ 901-1000]: loss = 0.241226 * 100, metric = 9.47% * 100;
 Minibatch[1001-1100]: loss = 0.248530 * 100, metric = 9.62% * 100;
 Minibatch[1101-1200]: loss = 0.249446 * 100, metric = 9.84% * 100;
 Minibatch[1201-1300]: loss = 0.240749 * 100, metric = 9.63% * 100;
 Minibatch[1301-1400]: loss = 0.240876 * 100, metric = 9.40% * 100;
 Minibatch[1401-1500]: loss = 0.246833 * 100, metric = 9.70% * 100;
 Minibatch[1501-1600]: loss = 0.253823 * 100, metric = 10.14% * 100;
 Minibatch[1601-1700]: loss = 0.242858 * 100, metric = 9.52% * 100;
 Minibatch[1701-1800]: loss = 0.231544 * 100, metric = 9.01% * 100;
 Minibatch[1801-1900]: loss = 0.236913 * 100, metric = 9.23% * 100;
 Minibatch[1901-2000]: loss = 0.232573 * 100, metric = 8.90% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.246041 * 2000, metric = 9.60% * 2000 1081.210s (  1.8 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 17.04% * 2000;
 Minibatch[   1- 100]: loss = 0.238160 * 100, metric = 9.23% * 100;
 Minibatch[ 101- 200]: loss = 0.243198 * 100, metric = 9.44% * 100;
 Minibatch[ 201- 300]: loss = 0.238333 * 100, metric = 9.18% * 100;
 Minibatch[ 301- 400]: loss = 0.249760 * 100, metric = 9.34% * 100;
 Minibatch[ 401- 500]: loss = 0.241394 * 100, metric = 9.54% * 100;
 Minibatch[ 501- 600]: loss = 0.247495 * 100, metric = 9.61% * 100;
 Minibatch[ 601- 700]: loss = 0.251350 * 100, metric = 9.83% * 100;
 Minibatch[ 701- 800]: loss = 0.241233 * 100, metric = 9.36% * 100;
 Minibatch[ 801- 900]: loss = 0.253742 * 100, metric = 9.86% * 100;
 Minibatch[ 901-1000]: loss = 0.250947 * 100, metric = 9.84% * 100;
 Minibatch[1001-1100]: loss = 0.231239 * 100, metric = 9.08% * 100;
 Minibatch[1101-1200]: loss = 0.239769 * 100, metric = 9.12% * 100;
 Minibatch[1201-1300]: loss = 0.250257 * 100, metric = 9.66% * 100;
 Minibatch[1301-1400]: loss = 0.249297 * 100, metric = 9.65% * 100;
 Minibatch[1401-1500]: loss = 0.239269 * 100, metric = 9.52% * 100;
 Minibatch[1501-1600]: loss = 0.250634 * 100, metric = 9.45% * 100;
 Minibatch[1601-1700]: loss = 0.240680 * 100, metric = 9.18% * 100;
 Minibatch[1701-1800]: loss = 0.246793 * 100, metric = 9.74% * 100;
 Minibatch[1801-1900]: loss = 0.242698 * 100, metric = 9.63% * 100;
 Minibatch[1901-2000]: loss = 0.244274 * 100, metric = 9.56% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.244526 * 2000, metric = 9.49% * 2000 1084.194s (  1.8 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 16.89% * 2000;
 Minibatch[   1- 100]: loss = 0.244127 * 100, metric = 9.61% * 100;
 Minibatch[ 101- 200]: loss = 0.242853 * 100, metric = 9.54% * 100;
 Minibatch[ 201- 300]: loss = 0.240612 * 100, metric = 9.48% * 100;
 Minibatch[ 301- 400]: loss = 0.247731 * 100, metric = 9.80% * 100;
 Minibatch[ 401- 500]: loss = 0.236880 * 100, metric = 9.33% * 100;
 Minibatch[ 501- 600]: loss = 0.231141 * 100, metric = 8.95% * 100;
 Minibatch[ 601- 700]: loss = 0.240461 * 100, metric = 9.21% * 100;
 Minibatch[ 701- 800]: loss = 0.216529 * 100, metric = 8.29% * 100;
 Minibatch[ 801- 900]: loss = 0.242793 * 100, metric = 9.36% * 100;
 Minibatch[ 901-1000]: loss = 0.236700 * 100, metric = 9.20% * 100;
 Minibatch[1001-1100]: loss = 0.234934 * 100, metric = 9.04% * 100;
 Minibatch[1101-1200]: loss = 0.236086 * 100, metric = 8.83% * 100;
 Minibatch[1201-1300]: loss = 0.236693 * 100, metric = 9.06% * 100;
 Minibatch[1301-1400]: loss = 0.226638 * 100, metric = 8.75% * 100;
 Minibatch[1401-1500]: loss = 0.242184 * 100, metric = 9.43% * 100;
 Minibatch[1501-1600]: loss = 0.246609 * 100, metric = 9.73% * 100;
 Minibatch[1601-1700]: loss = 0.240608 * 100, metric = 9.31% * 100;
 Minibatch[1701-1800]: loss = 0.236154 * 100, metric = 9.12% * 100;
 Minibatch[1801-1900]: loss = 0.249814 * 100, metric = 9.73% * 100;
 Minibatch[1901-2000]: loss = 0.230168 * 100, metric = 8.59% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.237986 * 2000, metric = 9.22% * 2000 1075.142s (  1.9 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 16.32% * 2000;
 Minibatch[   1- 100]: loss = 0.244451 * 100, metric = 9.47% * 100;
 Minibatch[ 101- 200]: loss = 0.242068 * 100, metric = 9.37% * 100;
 Minibatch[ 201- 300]: loss = 0.241925 * 100, metric = 9.56% * 100;
 Minibatch[ 301- 400]: loss = 0.235535 * 100, metric = 9.20% * 100;
 Minibatch[ 401- 500]: loss = 0.233492 * 100, metric = 8.96% * 100;
 Minibatch[ 501- 600]: loss = 0.236757 * 100, metric = 9.13% * 100;
 Minibatch[ 601- 700]: loss = 0.233514 * 100, metric = 9.28% * 100;
 Minibatch[ 701- 800]: loss = 0.231390 * 100, metric = 9.00% * 100;
 Minibatch[ 801- 900]: loss = 0.244077 * 100, metric = 9.66% * 100;
 Minibatch[ 901-1000]: loss = 0.239643 * 100, metric = 9.43% * 100;
 Minibatch[1001-1100]: loss = 0.228408 * 100, metric = 8.80% * 100;
 Minibatch[1101-1200]: loss = 0.218093 * 100, metric = 8.38% * 100;
 Minibatch[1201-1300]: loss = 0.231468 * 100, metric = 8.93% * 100;
 Minibatch[1301-1400]: loss = 0.233627 * 100, metric = 8.88% * 100;
 Minibatch[1401-1500]: loss = 0.227769 * 100, metric = 8.81% * 100;
 Minibatch[1501-1600]: loss = 0.224578 * 100, metric = 8.66% * 100;
 Minibatch[1601-1700]: loss = 0.233148 * 100, metric = 9.08% * 100;
 Minibatch[1701-1800]: loss = 0.227307 * 100, metric = 8.85% * 100;
 Minibatch[1801-1900]: loss = 0.235362 * 100, metric = 9.20% * 100;
 Minibatch[1901-2000]: loss = 0.230117 * 100, metric = 8.91% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.233636 * 2000, metric = 9.08% * 2000 1078.001s (  1.9 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 15.76% * 2000;
 Minibatch[   1- 100]: loss = 0.238685 * 100, metric = 9.22% * 100;
 Minibatch[ 101- 200]: loss = 0.238984 * 100, metric = 9.28% * 100;
 Minibatch[ 201- 300]: loss = 0.233679 * 100, metric = 9.23% * 100;
 Minibatch[ 301- 400]: loss = 0.238230 * 100, metric = 9.33% * 100;
 Minibatch[ 401- 500]: loss = 0.237917 * 100, metric = 9.21% * 100;
 Minibatch[ 501- 600]: loss = 0.233294 * 100, metric = 9.09% * 100;
 Minibatch[ 601- 700]: loss = 0.228753 * 100, metric = 8.74% * 100;
 Minibatch[ 701- 800]: loss = 0.219744 * 100, metric = 8.49% * 100;
 Minibatch[ 801- 900]: loss = 0.220780 * 100, metric = 8.60% * 100;
 Minibatch[ 901-1000]: loss = 0.234413 * 100, metric = 8.99% * 100;
 Minibatch[1001-1100]: loss = 0.227684 * 100, metric = 8.73% * 100;
 Minibatch[1101-1200]: loss = 0.232475 * 100, metric = 9.14% * 100;
 Minibatch[1201-1300]: loss = 0.231971 * 100, metric = 9.30% * 100;
 Minibatch[1301-1400]: loss = 0.233468 * 100, metric = 8.94% * 100;
 Minibatch[1401-1500]: loss = 0.227179 * 100, metric = 8.93% * 100;
 Minibatch[1501-1600]: loss = 0.225098 * 100, metric = 8.86% * 100;
 Minibatch[1601-1700]: loss = 0.233359 * 100, metric = 9.22% * 100;
 Minibatch[1701-1800]: loss = 0.237520 * 100, metric = 9.13% * 100;
 Minibatch[1801-1900]: loss = 0.235932 * 100, metric = 9.24% * 100;
 Minibatch[1901-2000]: loss = 0.232206 * 100, metric = 9.06% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.232069 * 2000, metric = 9.04% * 2000 1065.368s (  1.9 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 17.68% * 2000;
 Minibatch[   1- 100]: loss = 0.220899 * 100, metric = 8.58% * 100;
 Minibatch[ 101- 200]: loss = 0.231703 * 100, metric = 9.09% * 100;
 Minibatch[ 201- 300]: loss = 0.225004 * 100, metric = 9.06% * 100;
 Minibatch[ 301- 400]: loss = 0.227850 * 100, metric = 9.00% * 100;
 Minibatch[ 401- 500]: loss = 0.230059 * 100, metric = 9.00% * 100;
 Minibatch[ 501- 600]: loss = 0.221051 * 100, metric = 8.69% * 100;
 Minibatch[ 601- 700]: loss = 0.234873 * 100, metric = 8.78% * 100;
 Minibatch[ 701- 800]: loss = 0.223834 * 100, metric = 8.66% * 100;
 Minibatch[ 801- 900]: loss = 0.234142 * 100, metric = 9.21% * 100;
 Minibatch[ 901-1000]: loss = 0.229353 * 100, metric = 9.11% * 100;
 Minibatch[1001-1100]: loss = 0.221839 * 100, metric = 8.66% * 100;
 Minibatch[1101-1200]: loss = 0.236512 * 100, metric = 9.05% * 100;
 Minibatch[1201-1300]: loss = 0.229346 * 100, metric = 8.82% * 100;
 Minibatch[1301-1400]: loss = 0.222460 * 100, metric = 8.60% * 100;
 Minibatch[1401-1500]: loss = 0.221418 * 100, metric = 8.69% * 100;
 Minibatch[1501-1600]: loss = 0.234177 * 100, metric = 9.12% * 100;
 Minibatch[1601-1700]: loss = 0.221844 * 100, metric = 8.57% * 100;
 Minibatch[1701-1800]: loss = 0.222747 * 100, metric = 8.39% * 100;
 Minibatch[1801-1900]: loss = 0.229280 * 100, metric = 8.87% * 100;
 Minibatch[1901-2000]: loss = 0.232627 * 100, metric = 9.21% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.227551 * 2000, metric = 8.86% * 2000 1075.799s (  1.9 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 15.95% * 2000;
 Minibatch[   1- 100]: loss = 0.232606 * 100, metric = 9.07% * 100;
 Minibatch[ 101- 200]: loss = 0.227320 * 100, metric = 8.83% * 100;
 Minibatch[ 201- 300]: loss = 0.228010 * 100, metric = 8.87% * 100;
 Minibatch[ 301- 400]: loss = 0.228409 * 100, metric = 9.04% * 100;
 Minibatch[ 401- 500]: loss = 0.225676 * 100, metric = 8.68% * 100;
 Minibatch[ 501- 600]: loss = 0.221487 * 100, metric = 8.55% * 100;
 Minibatch[ 601- 700]: loss = 0.228696 * 100, metric = 8.94% * 100;
 Minibatch[ 701- 800]: loss = 0.216304 * 100, metric = 8.33% * 100;
 Minibatch[ 801- 900]: loss = 0.222425 * 100, metric = 8.85% * 100;
 Minibatch[ 901-1000]: loss = 0.230816 * 100, metric = 9.17% * 100;
 Minibatch[1001-1100]: loss = 0.223495 * 100, metric = 8.77% * 100;
 Minibatch[1101-1200]: loss = 0.232011 * 100, metric = 9.02% * 100;
 Minibatch[1201-1300]: loss = 0.241775 * 100, metric = 9.30% * 100;
 Minibatch[1301-1400]: loss = 0.222476 * 100, metric = 8.75% * 100;
 Minibatch[1401-1500]: loss = 0.218445 * 100, metric = 8.42% * 100;
 Minibatch[1501-1600]: loss = 0.231875 * 100, metric = 9.19% * 100;
 Minibatch[1601-1700]: loss = 0.220524 * 100, metric = 8.55% * 100;
 Minibatch[1701-1800]: loss = 0.223434 * 100, metric = 8.88% * 100;
 Minibatch[1801-1900]: loss = 0.214166 * 100, metric = 8.18% * 100;
 Minibatch[1901-2000]: loss = 0.212348 * 100, metric = 8.09% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.225115 * 2000, metric = 8.77% * 2000 1052.553s (  1.9 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 16.29% * 2000;
 Minibatch[   1- 100]: loss = 0.224880 * 100, metric = 8.86% * 100;
 Minibatch[ 101- 200]: loss = 0.215600 * 100, metric = 8.38% * 100;
 Minibatch[ 201- 300]: loss = 0.228670 * 100, metric = 9.04% * 100;
 Minibatch[ 301- 400]: loss = 0.215483 * 100, metric = 8.38% * 100;
 Minibatch[ 401- 500]: loss = 0.224260 * 100, metric = 8.83% * 100;
 Minibatch[ 501- 600]: loss = 0.220526 * 100, metric = 8.45% * 100;
 Minibatch[ 601- 700]: loss = 0.238420 * 100, metric = 9.28% * 100;
 Minibatch[ 701- 800]: loss = 0.220091 * 100, metric = 8.65% * 100;
 Minibatch[ 801- 900]: loss = 0.213744 * 100, metric = 8.50% * 100;
 Minibatch[ 901-1000]: loss = 0.215157 * 100, metric = 8.35% * 100;
 Minibatch[1001-1100]: loss = 0.228672 * 100, metric = 9.07% * 100;
 Minibatch[1101-1200]: loss = 0.227969 * 100, metric = 8.89% * 100;
 Minibatch[1201-1300]: loss = 0.225967 * 100, metric = 8.83% * 100;
 Minibatch[1301-1400]: loss = 0.212486 * 100, metric = 8.09% * 100;
 Minibatch[1401-1500]: loss = 0.220872 * 100, metric = 8.64% * 100;
 Minibatch[1501-1600]: loss = 0.212745 * 100, metric = 8.35% * 100;
 Minibatch[1601-1700]: loss = 0.234110 * 100, metric = 9.14% * 100;
 Minibatch[1701-1800]: loss = 0.227856 * 100, metric = 8.91% * 100;
 Minibatch[1801-1900]: loss = 0.217322 * 100, metric = 8.36% * 100;
 Minibatch[1901-2000]: loss = 0.218244 * 100, metric = 8.46% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.222154 * 2000, metric = 8.67% * 2000 1051.894s (  1.9 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 16.96% * 2000;
 Minibatch[   1- 100]: loss = 0.219269 * 100, metric = 8.37% * 100;
 Minibatch[ 101- 200]: loss = 0.230025 * 100, metric = 8.90% * 100;
 Minibatch[ 201- 300]: loss = 0.219356 * 100, metric = 8.60% * 100;
 Minibatch[ 301- 400]: loss = 0.217258 * 100, metric = 8.51% * 100;
 Minibatch[ 401- 500]: loss = 0.221605 * 100, metric = 8.61% * 100;
 Minibatch[ 501- 600]: loss = 0.211702 * 100, metric = 8.23% * 100;
 Minibatch[ 601- 700]: loss = 0.212423 * 100, metric = 8.26% * 100;
 Minibatch[ 701- 800]: loss = 0.217807 * 100, metric = 8.59% * 100;
 Minibatch[ 801- 900]: loss = 0.225426 * 100, metric = 8.56% * 100;
 Minibatch[ 901-1000]: loss = 0.219285 * 100, metric = 8.59% * 100;
 Minibatch[1001-1100]: loss = 0.209772 * 100, metric = 8.29% * 100;
 Minibatch[1101-1200]: loss = 0.222710 * 100, metric = 8.71% * 100;
 Minibatch[1201-1300]: loss = 0.214442 * 100, metric = 8.25% * 100;
 Minibatch[1301-1400]: loss = 0.227406 * 100, metric = 8.96% * 100;
 Minibatch[1401-1500]: loss = 0.213415 * 100, metric = 8.36% * 100;
 Minibatch[1501-1600]: loss = 0.219985 * 100, metric = 8.49% * 100;
 Minibatch[1601-1700]: loss = 0.206057 * 100, metric = 7.88% * 100;
 Minibatch[1701-1800]: loss = 0.212254 * 100, metric = 8.13% * 100;
 Minibatch[1801-1900]: loss = 0.217133 * 100, metric = 8.30% * 100;
 Minibatch[1901-2000]: loss = 0.217012 * 100, metric = 8.31% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.217717 * 2000, metric = 8.44% * 2000 1045.472s (  1.9 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 15.50% * 2000;
 Minibatch[   1- 100]: loss = 0.222029 * 100, metric = 8.73% * 100;
 Minibatch[ 101- 200]: loss = 0.213646 * 100, metric = 8.32% * 100;
 Minibatch[ 201- 300]: loss = 0.221117 * 100, metric = 8.65% * 100;
 Minibatch[ 301- 400]: loss = 0.221342 * 100, metric = 8.63% * 100;
 Minibatch[ 401- 500]: loss = 0.213259 * 100, metric = 8.36% * 100;
 Minibatch[ 501- 600]: loss = 0.225527 * 100, metric = 8.87% * 100;
 Minibatch[ 601- 700]: loss = 0.206098 * 100, metric = 8.04% * 100;
 Minibatch[ 701- 800]: loss = 0.204067 * 100, metric = 7.92% * 100;
 Minibatch[ 801- 900]: loss = 0.213995 * 100, metric = 8.38% * 100;
 Minibatch[ 901-1000]: loss = 0.229666 * 100, metric = 8.91% * 100;
 Minibatch[1001-1100]: loss = 0.216469 * 100, metric = 8.43% * 100;
 Minibatch[1101-1200]: loss = 0.208448 * 100, metric = 8.16% * 100;
 Minibatch[1201-1300]: loss = 0.220095 * 100, metric = 8.50% * 100;
 Minibatch[1301-1400]: loss = 0.213324 * 100, metric = 8.38% * 100;
 Minibatch[1401-1500]: loss = 0.218920 * 100, metric = 8.43% * 100;
 Minibatch[1501-1600]: loss = 0.208104 * 100, metric = 8.00% * 100;
 Minibatch[1601-1700]: loss = 0.212570 * 100, metric = 8.18% * 100;
 Minibatch[1701-1800]: loss = 0.210123 * 100, metric = 8.28% * 100;
 Minibatch[1801-1900]: loss = 0.212529 * 100, metric = 8.30% * 100;
 Minibatch[1901-2000]: loss = 0.217947 * 100, metric = 8.43% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.215464 * 2000, metric = 8.39% * 2000 1035.972s (  1.9 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 15.62% * 2000;
 Minibatch[   1- 100]: loss = 0.205431 * 100, metric = 7.84% * 100;
 Minibatch[ 101- 200]: loss = 0.215482 * 100, metric = 8.43% * 100;
 Minibatch[ 201- 300]: loss = 0.216544 * 100, metric = 8.32% * 100;
 Minibatch[ 301- 400]: loss = 0.220718 * 100, metric = 8.65% * 100;
 Minibatch[ 401- 500]: loss = 0.201527 * 100, metric = 7.79% * 100;
 Minibatch[ 501- 600]: loss = 0.211823 * 100, metric = 8.31% * 100;
 Minibatch[ 601- 700]: loss = 0.210562 * 100, metric = 8.30% * 100;
 Minibatch[ 701- 800]: loss = 0.220927 * 100, metric = 8.46% * 100;
 Minibatch[ 801- 900]: loss = 0.210311 * 100, metric = 8.35% * 100;
 Minibatch[ 901-1000]: loss = 0.217553 * 100, metric = 8.54% * 100;
 Minibatch[1001-1100]: loss = 0.215108 * 100, metric = 8.40% * 100;
 Minibatch[1101-1200]: loss = 0.202814 * 100, metric = 7.93% * 100;
 Minibatch[1201-1300]: loss = 0.210927 * 100, metric = 8.28% * 100;
 Minibatch[1301-1400]: loss = 0.204841 * 100, metric = 7.99% * 100;
 Minibatch[1401-1500]: loss = 0.222360 * 100, metric = 8.64% * 100;
 Minibatch[1501-1600]: loss = 0.200782 * 100, metric = 7.68% * 100;
 Minibatch[1601-1700]: loss = 0.218395 * 100, metric = 8.73% * 100;
 Minibatch[1701-1800]: loss = 0.200269 * 100, metric = 7.82% * 100;
 Minibatch[1801-1900]: loss = 0.218142 * 100, metric = 8.44% * 100;
 Minibatch[1901-2000]: loss = 0.210275 * 100, metric = 8.29% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.211740 * 2000, metric = 8.26% * 2000 1040.330s (  1.9 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 17.00% * 2000;
 Minibatch[   1- 100]: loss = 0.220355 * 100, metric = 8.66% * 100;
 Minibatch[ 101- 200]: loss = 0.195326 * 100, metric = 7.64% * 100;
 Minibatch[ 201- 300]: loss = 0.203881 * 100, metric = 7.98% * 100;
 Minibatch[ 301- 400]: loss = 0.211826 * 100, metric = 8.24% * 100;
 Minibatch[ 401- 500]: loss = 0.206662 * 100, metric = 8.10% * 100;
 Minibatch[ 501- 600]: loss = 0.193618 * 100, metric = 7.62% * 100;
 Minibatch[ 601- 700]: loss = 0.211195 * 100, metric = 8.30% * 100;
 Minibatch[ 701- 800]: loss = 0.203254 * 100, metric = 8.13% * 100;
 Minibatch[ 801- 900]: loss = 0.216642 * 100, metric = 8.26% * 100;
 Minibatch[ 901-1000]: loss = 0.196959 * 100, metric = 7.70% * 100;
 Minibatch[1001-1100]: loss = 0.207054 * 100, metric = 7.95% * 100;
 Minibatch[1101-1200]: loss = 0.214058 * 100, metric = 8.43% * 100;
 Minibatch[1201-1300]: loss = 0.201579 * 100, metric = 7.76% * 100;
 Minibatch[1301-1400]: loss = 0.206011 * 100, metric = 8.10% * 100;
 Minibatch[1401-1500]: loss = 0.204503 * 100, metric = 7.93% * 100;
 Minibatch[1501-1600]: loss = 0.212230 * 100, metric = 8.30% * 100;
 Minibatch[1601-1700]: loss = 0.207268 * 100, metric = 8.08% * 100;
 Minibatch[1701-1800]: loss = 0.206682 * 100, metric = 8.04% * 100;
 Minibatch[1801-1900]: loss = 0.209039 * 100, metric = 8.28% * 100;
 Minibatch[1901-2000]: loss = 0.218730 * 100, metric = 8.68% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.207344 * 2000, metric = 8.11% * 2000 1042.829s (  1.9 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 15.37% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
