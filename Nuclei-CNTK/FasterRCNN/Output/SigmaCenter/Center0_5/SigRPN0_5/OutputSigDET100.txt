Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.287152 * 100, metric = 23.88% * 100;
 Minibatch[ 101- 200]: loss = 1.160401 * 100, metric = 23.05% * 100;
 Minibatch[ 201- 300]: loss = 1.080264 * 100, metric = 21.80% * 100;
 Minibatch[ 301- 400]: loss = 1.076581 * 100, metric = 21.05% * 100;
 Minibatch[ 401- 500]: loss = 1.017665 * 100, metric = 19.83% * 100;
 Minibatch[ 501- 600]: loss = 0.977508 * 100, metric = 18.52% * 100;
 Minibatch[ 601- 700]: loss = 0.949556 * 100, metric = 17.97% * 100;
 Minibatch[ 701- 800]: loss = 0.900876 * 100, metric = 16.97% * 100;
 Minibatch[ 801- 900]: loss = 0.921432 * 100, metric = 17.13% * 100;
 Minibatch[ 901-1000]: loss = 0.935267 * 100, metric = 17.68% * 100;
 Minibatch[1001-1100]: loss = 0.924766 * 100, metric = 17.17% * 100;
 Minibatch[1101-1200]: loss = 0.890399 * 100, metric = 16.34% * 100;
 Minibatch[1201-1300]: loss = 0.884318 * 100, metric = 16.33% * 100;
 Minibatch[1301-1400]: loss = 0.853958 * 100, metric = 15.55% * 100;
 Minibatch[1401-1500]: loss = 0.883431 * 100, metric = 15.99% * 100;
 Minibatch[1501-1600]: loss = 0.840704 * 100, metric = 15.58% * 100;
 Minibatch[1601-1700]: loss = 0.829308 * 100, metric = 15.15% * 100;
 Minibatch[1701-1800]: loss = 0.845293 * 100, metric = 15.02% * 100;
 Minibatch[1801-1900]: loss = 0.846904 * 100, metric = 15.47% * 100;
 Minibatch[1901-2000]: loss = 0.825443 * 100, metric = 14.70% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.946561 * 2000, metric = 17.76% * 2000 1030.966s (  1.9 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 23.15% * 2000;
0.8284412752836943
 Minibatch[   1- 100]: loss = 0.815293 * 100, metric = 14.73% * 100;
 Minibatch[ 101- 200]: loss = 0.836948 * 100, metric = 15.53% * 100;
 Minibatch[ 201- 300]: loss = 0.813014 * 100, metric = 14.21% * 100;
 Minibatch[ 301- 400]: loss = 0.827352 * 100, metric = 14.72% * 100;
 Minibatch[ 401- 500]: loss = 0.826901 * 100, metric = 14.77% * 100;
 Minibatch[ 501- 600]: loss = 0.842189 * 100, metric = 14.47% * 100;
 Minibatch[ 601- 700]: loss = 0.809303 * 100, metric = 14.61% * 100;
 Minibatch[ 701- 800]: loss = 0.818354 * 100, metric = 14.92% * 100;
 Minibatch[ 801- 900]: loss = 0.804259 * 100, metric = 14.52% * 100;
 Minibatch[ 901-1000]: loss = 0.794927 * 100, metric = 13.93% * 100;
 Minibatch[1001-1100]: loss = 0.806439 * 100, metric = 14.49% * 100;
 Minibatch[1101-1200]: loss = 0.809714 * 100, metric = 14.31% * 100;
 Minibatch[1201-1300]: loss = 0.796841 * 100, metric = 14.39% * 100;
 Minibatch[1301-1400]: loss = 0.800037 * 100, metric = 14.19% * 100;
 Minibatch[1401-1500]: loss = 0.783927 * 100, metric = 13.73% * 100;
 Minibatch[1501-1600]: loss = 0.778872 * 100, metric = 13.48% * 100;
 Minibatch[1601-1700]: loss = 0.787966 * 100, metric = 14.19% * 100;
 Minibatch[1701-1800]: loss = 0.794989 * 100, metric = 14.41% * 100;
 Minibatch[1801-1900]: loss = 0.789677 * 100, metric = 13.72% * 100;
 Minibatch[1901-2000]: loss = 0.770295 * 100, metric = 13.66% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.805365 * 2000, metric = 14.35% * 2000 960.654s (  2.1 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 19.09% * 2000;
0.7646808543428779
 Minibatch[   1- 100]: loss = 0.785676 * 100, metric = 13.81% * 100;
 Minibatch[ 101- 200]: loss = 0.793576 * 100, metric = 14.04% * 100;
 Minibatch[ 201- 300]: loss = 0.779551 * 100, metric = 13.67% * 100;
 Minibatch[ 301- 400]: loss = 0.792546 * 100, metric = 14.18% * 100;
 Minibatch[ 401- 500]: loss = 0.797115 * 100, metric = 14.09% * 100;
 Minibatch[ 501- 600]: loss = 0.786319 * 100, metric = 13.76% * 100;
 Minibatch[ 601- 700]: loss = 0.797717 * 100, metric = 13.74% * 100;
 Minibatch[ 701- 800]: loss = 0.755684 * 100, metric = 12.71% * 100;
 Minibatch[ 801- 900]: loss = 0.781415 * 100, metric = 13.72% * 100;
 Minibatch[ 901-1000]: loss = 0.743101 * 100, metric = 12.91% * 100;
 Minibatch[1001-1100]: loss = 0.778102 * 100, metric = 13.98% * 100;
 Minibatch[1101-1200]: loss = 0.761378 * 100, metric = 13.20% * 100;
 Minibatch[1201-1300]: loss = 0.755433 * 100, metric = 12.87% * 100;
 Minibatch[1301-1400]: loss = 0.778800 * 100, metric = 13.52% * 100;
 Minibatch[1401-1500]: loss = 0.780238 * 100, metric = 13.57% * 100;
 Minibatch[1501-1600]: loss = 0.762350 * 100, metric = 13.32% * 100;
 Minibatch[1601-1700]: loss = 0.758043 * 100, metric = 12.83% * 100;
 Minibatch[1701-1800]: loss = 0.773329 * 100, metric = 13.40% * 100;
 Minibatch[1801-1900]: loss = 0.765045 * 100, metric = 12.93% * 100;
 Minibatch[1901-2000]: loss = 0.751324 * 100, metric = 13.11% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.773837 * 2000, metric = 13.47% * 2000 990.960s (  2.0 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 18.34% * 2000;
0.7540354857966304
 Minibatch[   1- 100]: loss = 0.782451 * 100, metric = 13.14% * 100;
 Minibatch[ 101- 200]: loss = 0.742671 * 100, metric = 12.92% * 100;
 Minibatch[ 201- 300]: loss = 0.762542 * 100, metric = 13.17% * 100;
 Minibatch[ 301- 400]: loss = 0.724884 * 100, metric = 12.11% * 100;
 Minibatch[ 401- 500]: loss = 0.766365 * 100, metric = 12.97% * 100;
 Minibatch[ 501- 600]: loss = 0.728370 * 100, metric = 12.01% * 100;
 Minibatch[ 601- 700]: loss = 0.732790 * 100, metric = 12.65% * 100;
 Minibatch[ 701- 800]: loss = 0.759208 * 100, metric = 12.80% * 100;
 Minibatch[ 801- 900]: loss = 0.750114 * 100, metric = 12.70% * 100;
 Minibatch[ 901-1000]: loss = 0.753480 * 100, metric = 12.96% * 100;
 Minibatch[1001-1100]: loss = 0.769061 * 100, metric = 13.32% * 100;
 Minibatch[1101-1200]: loss = 0.730709 * 100, metric = 12.53% * 100;
 Minibatch[1201-1300]: loss = 0.739484 * 100, metric = 12.38% * 100;
 Minibatch[1301-1400]: loss = 0.759210 * 100, metric = 13.01% * 100;
 Minibatch[1401-1500]: loss = 0.776031 * 100, metric = 13.45% * 100;
 Minibatch[1501-1600]: loss = 0.726696 * 100, metric = 12.06% * 100;
 Minibatch[1601-1700]: loss = 0.756279 * 100, metric = 12.87% * 100;
 Minibatch[1701-1800]: loss = 0.753784 * 100, metric = 12.81% * 100;
 Minibatch[1801-1900]: loss = 0.743815 * 100, metric = 12.67% * 100;
 Minibatch[1901-2000]: loss = 0.743169 * 100, metric = 12.45% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.750056 * 2000, metric = 12.75% * 2000 970.316s (  2.1 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 21.06% * 2000;
 Minibatch[   1- 100]: loss = 0.778743 * 100, metric = 13.13% * 100;
 Minibatch[ 101- 200]: loss = 0.752870 * 100, metric = 12.84% * 100;
 Minibatch[ 201- 300]: loss = 0.735965 * 100, metric = 12.37% * 100;
 Minibatch[ 301- 400]: loss = 0.785975 * 100, metric = 13.60% * 100;
 Minibatch[ 401- 500]: loss = 0.717433 * 100, metric = 11.96% * 100;
 Minibatch[ 501- 600]: loss = 0.735528 * 100, metric = 12.25% * 100;
 Minibatch[ 601- 700]: loss = 0.752482 * 100, metric = 12.38% * 100;
 Minibatch[ 701- 800]: loss = 0.762034 * 100, metric = 12.84% * 100;
 Minibatch[ 801- 900]: loss = 0.734976 * 100, metric = 12.38% * 100;
 Minibatch[ 901-1000]: loss = 0.729142 * 100, metric = 12.25% * 100;
 Minibatch[1001-1100]: loss = 0.738875 * 100, metric = 12.35% * 100;
 Minibatch[1101-1200]: loss = 0.732423 * 100, metric = 12.11% * 100;
 Minibatch[1201-1300]: loss = 0.745898 * 100, metric = 12.61% * 100;
 Minibatch[1301-1400]: loss = 0.771063 * 100, metric = 12.96% * 100;
 Minibatch[1401-1500]: loss = 0.738395 * 100, metric = 12.55% * 100;
 Minibatch[1501-1600]: loss = 0.742361 * 100, metric = 12.80% * 100;
 Minibatch[1601-1700]: loss = 0.762040 * 100, metric = 13.15% * 100;
 Minibatch[1701-1800]: loss = 0.760393 * 100, metric = 13.09% * 100;
 Minibatch[1801-1900]: loss = 0.752216 * 100, metric = 12.96% * 100;
 Minibatch[1901-2000]: loss = 0.728931 * 100, metric = 12.31% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.747887 * 2000, metric = 12.64% * 2000 987.430s (  2.0 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.71% * 2000;
 Minibatch[   1- 100]: loss = 0.726043 * 100, metric = 12.49% * 100;
 Minibatch[ 101- 200]: loss = 0.720369 * 100, metric = 12.18% * 100;
 Minibatch[ 201- 300]: loss = 0.732365 * 100, metric = 12.34% * 100;
 Minibatch[ 301- 400]: loss = 0.734144 * 100, metric = 12.16% * 100;
 Minibatch[ 401- 500]: loss = 0.709563 * 100, metric = 11.71% * 100;
 Minibatch[ 501- 600]: loss = 0.734340 * 100, metric = 12.34% * 100;
 Minibatch[ 601- 700]: loss = 0.727180 * 100, metric = 12.58% * 100;
 Minibatch[ 701- 800]: loss = 0.743387 * 100, metric = 12.88% * 100;
 Minibatch[ 801- 900]: loss = 0.741230 * 100, metric = 12.42% * 100;
 Minibatch[ 901-1000]: loss = 0.718202 * 100, metric = 12.00% * 100;
 Minibatch[1001-1100]: loss = 0.735633 * 100, metric = 11.91% * 100;
 Minibatch[1101-1200]: loss = 0.744172 * 100, metric = 12.40% * 100;
 Minibatch[1201-1300]: loss = 0.760516 * 100, metric = 12.66% * 100;
 Minibatch[1301-1400]: loss = 0.727496 * 100, metric = 12.42% * 100;
 Minibatch[1401-1500]: loss = 0.739271 * 100, metric = 12.72% * 100;
 Minibatch[1501-1600]: loss = 0.716296 * 100, metric = 11.75% * 100;
 Minibatch[1601-1700]: loss = 0.722755 * 100, metric = 11.86% * 100;
 Minibatch[1701-1800]: loss = 0.707043 * 100, metric = 11.69% * 100;
 Minibatch[1801-1900]: loss = 0.733444 * 100, metric = 12.42% * 100;
 Minibatch[1901-2000]: loss = 0.712753 * 100, metric = 11.85% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.729310 * 2000, metric = 12.24% * 2000 975.160s (  2.1 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.26% * 2000;
 Minibatch[   1- 100]: loss = 0.710371 * 100, metric = 11.85% * 100;
 Minibatch[ 101- 200]: loss = 0.729883 * 100, metric = 11.88% * 100;
 Minibatch[ 201- 300]: loss = 0.730055 * 100, metric = 12.20% * 100;
 Minibatch[ 301- 400]: loss = 0.720861 * 100, metric = 11.98% * 100;
 Minibatch[ 401- 500]: loss = 0.723138 * 100, metric = 11.78% * 100;
 Minibatch[ 501- 600]: loss = 0.699091 * 100, metric = 11.33% * 100;
 Minibatch[ 601- 700]: loss = 0.724271 * 100, metric = 11.95% * 100;
 Minibatch[ 701- 800]: loss = 0.726413 * 100, metric = 11.65% * 100;
 Minibatch[ 801- 900]: loss = 0.735413 * 100, metric = 12.27% * 100;
 Minibatch[ 901-1000]: loss = 0.727444 * 100, metric = 12.21% * 100;
 Minibatch[1001-1100]: loss = 0.727944 * 100, metric = 12.49% * 100;
 Minibatch[1101-1200]: loss = 0.712411 * 100, metric = 11.72% * 100;
 Minibatch[1201-1300]: loss = 0.736206 * 100, metric = 12.54% * 100;
 Minibatch[1301-1400]: loss = 0.719052 * 100, metric = 12.07% * 100;
 Minibatch[1401-1500]: loss = 0.711038 * 100, metric = 11.53% * 100;
 Minibatch[1501-1600]: loss = 0.728326 * 100, metric = 12.03% * 100;
 Minibatch[1601-1700]: loss = 0.734719 * 100, metric = 12.39% * 100;
 Minibatch[1701-1800]: loss = 0.714067 * 100, metric = 11.99% * 100;
 Minibatch[1801-1900]: loss = 0.720061 * 100, metric = 11.99% * 100;
 Minibatch[1901-2000]: loss = 0.729299 * 100, metric = 12.52% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.723003 * 2000, metric = 12.02% * 2000 997.879s (  2.0 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.09% * 2000;
0.7439389842897653
 Minibatch[   1- 100]: loss = 0.731896 * 100, metric = 12.38% * 100;
 Minibatch[ 101- 200]: loss = 0.722545 * 100, metric = 12.43% * 100;
 Minibatch[ 201- 300]: loss = 0.709214 * 100, metric = 11.86% * 100;
 Minibatch[ 301- 400]: loss = 0.709253 * 100, metric = 11.93% * 100;
 Minibatch[ 401- 500]: loss = 0.732086 * 100, metric = 12.55% * 100;
 Minibatch[ 501- 600]: loss = 0.751324 * 100, metric = 12.95% * 100;
 Minibatch[ 601- 700]: loss = 0.705365 * 100, metric = 11.69% * 100;
 Minibatch[ 701- 800]: loss = 0.732280 * 100, metric = 12.12% * 100;
 Minibatch[ 801- 900]: loss = 0.708872 * 100, metric = 11.37% * 100;
 Minibatch[ 901-1000]: loss = 0.694890 * 100, metric = 11.32% * 100;
 Minibatch[1001-1100]: loss = 0.699608 * 100, metric = 11.42% * 100;
 Minibatch[1101-1200]: loss = 0.699075 * 100, metric = 11.38% * 100;
 Minibatch[1201-1300]: loss = 0.722608 * 100, metric = 12.16% * 100;
 Minibatch[1301-1400]: loss = 0.742546 * 100, metric = 12.66% * 100;
 Minibatch[1401-1500]: loss = 0.724415 * 100, metric = 12.02% * 100;
 Minibatch[1501-1600]: loss = 0.728772 * 100, metric = 12.17% * 100;
 Minibatch[1601-1700]: loss = 0.709631 * 100, metric = 11.99% * 100;
 Minibatch[1701-1800]: loss = 0.705533 * 100, metric = 11.64% * 100;
 Minibatch[1801-1900]: loss = 0.718687 * 100, metric = 11.91% * 100;
 Minibatch[1901-2000]: loss = 0.716586 * 100, metric = 11.90% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.718259 * 2000, metric = 11.99% * 2000 1022.562s (  2.0 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 18.38% * 2000;
0.7322797803208232
 Minibatch[   1- 100]: loss = 0.689606 * 100, metric = 11.17% * 100;
 Minibatch[ 101- 200]: loss = 0.721954 * 100, metric = 12.09% * 100;
 Minibatch[ 201- 300]: loss = 0.712157 * 100, metric = 11.67% * 100;
 Minibatch[ 301- 400]: loss = 0.737335 * 100, metric = 12.18% * 100;
 Minibatch[ 401- 500]: loss = 0.717189 * 100, metric = 11.51% * 100;
 Minibatch[ 501- 600]: loss = 0.700174 * 100, metric = 11.60% * 100;
 Minibatch[ 601- 700]: loss = 0.699222 * 100, metric = 11.61% * 100;
 Minibatch[ 701- 800]: loss = 0.692530 * 100, metric = 11.31% * 100;
 Minibatch[ 801- 900]: loss = 0.683992 * 100, metric = 11.32% * 100;
 Minibatch[ 901-1000]: loss = 0.713568 * 100, metric = 11.79% * 100;
 Minibatch[1001-1100]: loss = 0.690448 * 100, metric = 11.17% * 100;
 Minibatch[1101-1200]: loss = 0.716175 * 100, metric = 11.89% * 100;
 Minibatch[1201-1300]: loss = 0.704327 * 100, metric = 11.72% * 100;
 Minibatch[1301-1400]: loss = 0.697130 * 100, metric = 11.25% * 100;
 Minibatch[1401-1500]: loss = 0.706010 * 100, metric = 11.79% * 100;
 Minibatch[1501-1600]: loss = 0.700649 * 100, metric = 11.50% * 100;
 Minibatch[1601-1700]: loss = 0.704137 * 100, metric = 11.69% * 100;
 Minibatch[1701-1800]: loss = 0.693938 * 100, metric = 11.13% * 100;
 Minibatch[1801-1900]: loss = 0.694498 * 100, metric = 11.03% * 100;
 Minibatch[1901-2000]: loss = 0.711348 * 100, metric = 11.84% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.704319 * 2000, metric = 11.56% * 2000 1022.109s (  2.0 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 16.70% * 2000;
0.7158113859072328
 Minibatch[   1- 100]: loss = 0.729518 * 100, metric = 12.71% * 100;
 Minibatch[ 101- 200]: loss = 0.689699 * 100, metric = 11.42% * 100;
 Minibatch[ 201- 300]: loss = 0.700688 * 100, metric = 11.73% * 100;
 Minibatch[ 301- 400]: loss = 0.689760 * 100, metric = 11.28% * 100;
 Minibatch[ 401- 500]: loss = 0.703076 * 100, metric = 11.80% * 100;
 Minibatch[ 501- 600]: loss = 0.683198 * 100, metric = 11.12% * 100;
 Minibatch[ 601- 700]: loss = 0.676566 * 100, metric = 11.00% * 100;
 Minibatch[ 701- 800]: loss = 0.674318 * 100, metric = 10.70% * 100;
 Minibatch[ 801- 900]: loss = 0.699517 * 100, metric = 11.55% * 100;
 Minibatch[ 901-1000]: loss = 0.696136 * 100, metric = 11.31% * 100;
 Minibatch[1001-1100]: loss = 0.698668 * 100, metric = 11.78% * 100;
 Minibatch[1101-1200]: loss = 0.695816 * 100, metric = 11.27% * 100;
 Minibatch[1201-1300]: loss = 0.694421 * 100, metric = 11.60% * 100;
 Minibatch[1301-1400]: loss = 0.686938 * 100, metric = 11.41% * 100;
 Minibatch[1401-1500]: loss = 0.678083 * 100, metric = 10.90% * 100;
 Minibatch[1501-1600]: loss = 0.684349 * 100, metric = 11.20% * 100;
 Minibatch[1601-1700]: loss = 0.678807 * 100, metric = 11.12% * 100;
 Minibatch[1701-1800]: loss = 0.689023 * 100, metric = 11.03% * 100;
 Minibatch[1801-1900]: loss = 0.702844 * 100, metric = 11.46% * 100;
 Minibatch[1901-2000]: loss = 0.674645 * 100, metric = 11.08% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.691304 * 2000, metric = 11.37% * 2000 999.425s (  2.0 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 17.34% * 2000;
 Minibatch[   1- 100]: loss = 0.668515 * 100, metric = 10.60% * 100;
 Minibatch[ 101- 200]: loss = 0.685440 * 100, metric = 11.27% * 100;
 Minibatch[ 201- 300]: loss = 0.695886 * 100, metric = 11.55% * 100;
 Minibatch[ 301- 400]: loss = 0.688597 * 100, metric = 11.21% * 100;
 Minibatch[ 401- 500]: loss = 0.676868 * 100, metric = 11.15% * 100;
 Minibatch[ 501- 600]: loss = 0.688835 * 100, metric = 11.46% * 100;
 Minibatch[ 601- 700]: loss = 0.677199 * 100, metric = 11.29% * 100;
 Minibatch[ 701- 800]: loss = 0.687568 * 100, metric = 11.54% * 100;
 Minibatch[ 801- 900]: loss = 0.679186 * 100, metric = 10.95% * 100;
 Minibatch[ 901-1000]: loss = 0.693123 * 100, metric = 11.18% * 100;
 Minibatch[1001-1100]: loss = 0.679417 * 100, metric = 10.85% * 100;
 Minibatch[1101-1200]: loss = 0.684592 * 100, metric = 11.30% * 100;
 Minibatch[1201-1300]: loss = 0.667995 * 100, metric = 11.01% * 100;
 Minibatch[1301-1400]: loss = 0.651064 * 100, metric = 10.62% * 100;
 Minibatch[1401-1500]: loss = 0.681426 * 100, metric = 11.11% * 100;
 Minibatch[1501-1600]: loss = 0.668144 * 100, metric = 10.90% * 100;
 Minibatch[1601-1700]: loss = 0.674624 * 100, metric = 10.98% * 100;
 Minibatch[1701-1800]: loss = 0.685685 * 100, metric = 11.38% * 100;
 Minibatch[1801-1900]: loss = 0.670836 * 100, metric = 11.08% * 100;
 Minibatch[1901-2000]: loss = 0.666614 * 100, metric = 11.18% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.678581 * 2000, metric = 11.13% * 2000 1017.509s (  2.0 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 17.85% * 2000;
 Minibatch[   1- 100]: loss = 0.654278 * 100, metric = 10.55% * 100;
 Minibatch[ 101- 200]: loss = 0.666857 * 100, metric = 10.61% * 100;
 Minibatch[ 201- 300]: loss = 0.656055 * 100, metric = 10.67% * 100;
 Minibatch[ 301- 400]: loss = 0.698338 * 100, metric = 11.74% * 100;
 Minibatch[ 401- 500]: loss = 0.669601 * 100, metric = 10.92% * 100;
 Minibatch[ 501- 600]: loss = 0.649575 * 100, metric = 10.37% * 100;
 Minibatch[ 601- 700]: loss = 0.654188 * 100, metric = 10.46% * 100;
 Minibatch[ 701- 800]: loss = 0.668439 * 100, metric = 11.00% * 100;
 Minibatch[ 801- 900]: loss = 0.669418 * 100, metric = 10.64% * 100;
 Minibatch[ 901-1000]: loss = 0.675552 * 100, metric = 11.11% * 100;
 Minibatch[1001-1100]: loss = 0.679388 * 100, metric = 11.52% * 100;
 Minibatch[1101-1200]: loss = 0.677905 * 100, metric = 11.26% * 100;
 Minibatch[1201-1300]: loss = 0.671135 * 100, metric = 11.24% * 100;
 Minibatch[1301-1400]: loss = 0.670781 * 100, metric = 10.94% * 100;
 Minibatch[1401-1500]: loss = 0.683807 * 100, metric = 11.26% * 100;
 Minibatch[1501-1600]: loss = 0.643310 * 100, metric = 10.41% * 100;
 Minibatch[1601-1700]: loss = 0.678195 * 100, metric = 11.13% * 100;
 Minibatch[1701-1800]: loss = 0.653539 * 100, metric = 10.66% * 100;
 Minibatch[1801-1900]: loss = 0.657145 * 100, metric = 10.77% * 100;
 Minibatch[1901-2000]: loss = 0.675994 * 100, metric = 11.25% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.667675 * 2000, metric = 10.93% * 2000 988.066s (  2.0 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 18.73% * 2000;
 Minibatch[   1- 100]: loss = 0.667662 * 100, metric = 11.09% * 100;
 Minibatch[ 101- 200]: loss = 0.673539 * 100, metric = 11.28% * 100;
 Minibatch[ 201- 300]: loss = 0.658860 * 100, metric = 10.86% * 100;
 Minibatch[ 301- 400]: loss = 0.676552 * 100, metric = 11.01% * 100;
 Minibatch[ 401- 500]: loss = 0.668492 * 100, metric = 11.40% * 100;
 Minibatch[ 501- 600]: loss = 0.683214 * 100, metric = 11.57% * 100;
 Minibatch[ 601- 700]: loss = 0.646334 * 100, metric = 10.35% * 100;
 Minibatch[ 701- 800]: loss = 0.649269 * 100, metric = 10.39% * 100;
 Minibatch[ 801- 900]: loss = 0.657285 * 100, metric = 10.65% * 100;
 Minibatch[ 901-1000]: loss = 0.678245 * 100, metric = 11.26% * 100;
 Minibatch[1001-1100]: loss = 0.668558 * 100, metric = 11.02% * 100;
 Minibatch[1101-1200]: loss = 0.662231 * 100, metric = 10.81% * 100;
 Minibatch[1201-1300]: loss = 0.669597 * 100, metric = 11.07% * 100;
 Minibatch[1301-1400]: loss = 0.657267 * 100, metric = 10.34% * 100;
 Minibatch[1401-1500]: loss = 0.652159 * 100, metric = 10.61% * 100;
 Minibatch[1501-1600]: loss = 0.644159 * 100, metric = 10.21% * 100;
 Minibatch[1601-1700]: loss = 0.635709 * 100, metric = 10.53% * 100;
 Minibatch[1701-1800]: loss = 0.647758 * 100, metric = 10.22% * 100;
 Minibatch[1801-1900]: loss = 0.649060 * 100, metric = 10.17% * 100;
 Minibatch[1901-2000]: loss = 0.657109 * 100, metric = 10.76% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.660153 * 2000, metric = 10.78% * 2000 985.078s (  2.0 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 18.58% * 2000;
 Minibatch[   1- 100]: loss = 0.644726 * 100, metric = 10.28% * 100;
 Minibatch[ 101- 200]: loss = 0.638874 * 100, metric = 10.29% * 100;
 Minibatch[ 201- 300]: loss = 0.657882 * 100, metric = 10.89% * 100;
 Minibatch[ 301- 400]: loss = 0.642934 * 100, metric = 10.56% * 100;
 Minibatch[ 401- 500]: loss = 0.641489 * 100, metric = 10.19% * 100;
 Minibatch[ 501- 600]: loss = 0.653051 * 100, metric = 10.55% * 100;
 Minibatch[ 601- 700]: loss = 0.642477 * 100, metric = 10.31% * 100;
 Minibatch[ 701- 800]: loss = 0.660844 * 100, metric = 11.14% * 100;
 Minibatch[ 801- 900]: loss = 0.660578 * 100, metric = 11.02% * 100;
 Minibatch[ 901-1000]: loss = 0.655746 * 100, metric = 10.45% * 100;
 Minibatch[1001-1100]: loss = 0.650016 * 100, metric = 10.60% * 100;
 Minibatch[1101-1200]: loss = 0.644299 * 100, metric = 10.47% * 100;
 Minibatch[1201-1300]: loss = 0.622935 * 100, metric = 9.85% * 100;
 Minibatch[1301-1400]: loss = 0.649225 * 100, metric = 11.00% * 100;
 Minibatch[1401-1500]: loss = 0.651879 * 100, metric = 10.61% * 100;
 Minibatch[1501-1600]: loss = 0.627912 * 100, metric = 10.32% * 100;
 Minibatch[1601-1700]: loss = 0.654550 * 100, metric = 10.41% * 100;
 Minibatch[1701-1800]: loss = 0.638437 * 100, metric = 10.21% * 100;
 Minibatch[1801-1900]: loss = 0.644402 * 100, metric = 10.44% * 100;
 Minibatch[1901-2000]: loss = 0.656576 * 100, metric = 10.40% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.646942 * 2000, metric = 10.50% * 2000 1015.452s (  2.0 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 19.75% * 2000;
 Minibatch[   1- 100]: loss = 0.631330 * 100, metric = 10.07% * 100;
 Minibatch[ 101- 200]: loss = 0.642699 * 100, metric = 10.36% * 100;
 Minibatch[ 201- 300]: loss = 0.639275 * 100, metric = 10.32% * 100;
 Minibatch[ 301- 400]: loss = 0.618049 * 100, metric = 10.00% * 100;
 Minibatch[ 401- 500]: loss = 0.630690 * 100, metric = 10.23% * 100;
 Minibatch[ 501- 600]: loss = 0.624987 * 100, metric = 9.72% * 100;
 Minibatch[ 601- 700]: loss = 0.609939 * 100, metric = 9.80% * 100;
 Minibatch[ 701- 800]: loss = 0.650080 * 100, metric = 10.67% * 100;
 Minibatch[ 801- 900]: loss = 0.648517 * 100, metric = 10.95% * 100;
 Minibatch[ 901-1000]: loss = 0.635597 * 100, metric = 10.37% * 100;
 Minibatch[1001-1100]: loss = 0.638508 * 100, metric = 10.55% * 100;
 Minibatch[1101-1200]: loss = 0.627625 * 100, metric = 10.27% * 100;
 Minibatch[1201-1300]: loss = 0.619086 * 100, metric = 9.62% * 100;
 Minibatch[1301-1400]: loss = 0.647407 * 100, metric = 10.71% * 100;
 Minibatch[1401-1500]: loss = 0.600873 * 100, metric = 9.77% * 100;
 Minibatch[1501-1600]: loss = 0.616463 * 100, metric = 9.85% * 100;
 Minibatch[1601-1700]: loss = 0.638007 * 100, metric = 10.54% * 100;
 Minibatch[1701-1800]: loss = 0.607468 * 100, metric = 9.50% * 100;
 Minibatch[1801-1900]: loss = 0.620022 * 100, metric = 10.18% * 100;
 Minibatch[1901-2000]: loss = 0.620908 * 100, metric = 9.99% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.628377 * 2000, metric = 10.17% * 2000 1004.859s (  2.0 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 16.79% * 2000;
0.7044607237949967
 Minibatch[   1- 100]: loss = 0.641328 * 100, metric = 10.74% * 100;
 Minibatch[ 101- 200]: loss = 0.639532 * 100, metric = 10.57% * 100;
 Minibatch[ 201- 300]: loss = 0.634851 * 100, metric = 10.34% * 100;
 Minibatch[ 301- 400]: loss = 0.632545 * 100, metric = 10.23% * 100;
 Minibatch[ 401- 500]: loss = 0.604641 * 100, metric = 9.70% * 100;
 Minibatch[ 501- 600]: loss = 0.616276 * 100, metric = 10.03% * 100;
 Minibatch[ 601- 700]: loss = 0.621278 * 100, metric = 9.95% * 100;
 Minibatch[ 701- 800]: loss = 0.620651 * 100, metric = 9.97% * 100;
 Minibatch[ 801- 900]: loss = 0.619173 * 100, metric = 9.92% * 100;
 Minibatch[ 901-1000]: loss = 0.621623 * 100, metric = 9.92% * 100;
 Minibatch[1001-1100]: loss = 0.603027 * 100, metric = 9.78% * 100;
 Minibatch[1101-1200]: loss = 0.622216 * 100, metric = 10.09% * 100;
 Minibatch[1201-1300]: loss = 0.612238 * 100, metric = 9.75% * 100;
 Minibatch[1301-1400]: loss = 0.619288 * 100, metric = 10.06% * 100;
 Minibatch[1401-1500]: loss = 0.611243 * 100, metric = 9.83% * 100;
 Minibatch[1501-1600]: loss = 0.615988 * 100, metric = 10.12% * 100;
 Minibatch[1601-1700]: loss = 0.612919 * 100, metric = 9.85% * 100;
 Minibatch[1701-1800]: loss = 0.636976 * 100, metric = 10.04% * 100;
 Minibatch[1801-1900]: loss = 0.620297 * 100, metric = 10.10% * 100;
 Minibatch[1901-2000]: loss = 0.611594 * 100, metric = 9.96% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.620884 * 2000, metric = 10.05% * 2000 986.837s (  2.0 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 16.32% * 2000;
0.6997226294204593
 Minibatch[   1- 100]: loss = 0.601751 * 100, metric = 9.64% * 100;
 Minibatch[ 101- 200]: loss = 0.621377 * 100, metric = 10.18% * 100;
 Minibatch[ 201- 300]: loss = 0.621608 * 100, metric = 10.33% * 100;
 Minibatch[ 301- 400]: loss = 0.618985 * 100, metric = 10.13% * 100;
 Minibatch[ 401- 500]: loss = 0.629372 * 100, metric = 10.03% * 100;
 Minibatch[ 501- 600]: loss = 0.605683 * 100, metric = 9.69% * 100;
 Minibatch[ 601- 700]: loss = 0.589770 * 100, metric = 9.21% * 100;
 Minibatch[ 701- 800]: loss = 0.602719 * 100, metric = 9.64% * 100;
 Minibatch[ 801- 900]: loss = 0.616170 * 100, metric = 10.01% * 100;
 Minibatch[ 901-1000]: loss = 0.605740 * 100, metric = 9.71% * 100;
 Minibatch[1001-1100]: loss = 0.599189 * 100, metric = 9.64% * 100;
 Minibatch[1101-1200]: loss = 0.627833 * 100, metric = 10.17% * 100;
 Minibatch[1201-1300]: loss = 0.619005 * 100, metric = 10.12% * 100;
 Minibatch[1301-1400]: loss = 0.596019 * 100, metric = 9.44% * 100;
 Minibatch[1401-1500]: loss = 0.614655 * 100, metric = 9.89% * 100;
 Minibatch[1501-1600]: loss = 0.616492 * 100, metric = 9.86% * 100;
 Minibatch[1601-1700]: loss = 0.612103 * 100, metric = 9.65% * 100;
 Minibatch[1701-1800]: loss = 0.594058 * 100, metric = 9.26% * 100;
 Minibatch[1801-1900]: loss = 0.628662 * 100, metric = 10.26% * 100;
 Minibatch[1901-2000]: loss = 0.634117 * 100, metric = 10.47% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.612765 * 2000, metric = 9.87% * 2000 1005.197s (  2.0 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 16.93% * 2000;
 Minibatch[   1- 100]: loss = 0.594482 * 100, metric = 9.37% * 100;
 Minibatch[ 101- 200]: loss = 0.628780 * 100, metric = 10.05% * 100;
 Minibatch[ 201- 300]: loss = 0.601917 * 100, metric = 9.83% * 100;
 Minibatch[ 301- 400]: loss = 0.610416 * 100, metric = 9.72% * 100;
 Minibatch[ 401- 500]: loss = 0.589765 * 100, metric = 9.22% * 100;
 Minibatch[ 501- 600]: loss = 0.594177 * 100, metric = 9.35% * 100;
 Minibatch[ 601- 700]: loss = 0.603908 * 100, metric = 9.56% * 100;
 Minibatch[ 701- 800]: loss = 0.592071 * 100, metric = 9.54% * 100;
 Minibatch[ 801- 900]: loss = 0.610858 * 100, metric = 9.94% * 100;
 Minibatch[ 901-1000]: loss = 0.610639 * 100, metric = 9.84% * 100;
 Minibatch[1001-1100]: loss = 0.619560 * 100, metric = 10.16% * 100;
 Minibatch[1101-1200]: loss = 0.609152 * 100, metric = 9.86% * 100;
 Minibatch[1201-1300]: loss = 0.621740 * 100, metric = 10.46% * 100;
 Minibatch[1301-1400]: loss = 0.625252 * 100, metric = 10.12% * 100;
 Minibatch[1401-1500]: loss = 0.590919 * 100, metric = 9.43% * 100;
 Minibatch[1501-1600]: loss = 0.602263 * 100, metric = 9.62% * 100;
 Minibatch[1601-1700]: loss = 0.581958 * 100, metric = 9.13% * 100;
 Minibatch[1701-1800]: loss = 0.589736 * 100, metric = 9.04% * 100;
 Minibatch[1801-1900]: loss = 0.583823 * 100, metric = 9.29% * 100;
 Minibatch[1901-2000]: loss = 0.580389 * 100, metric = 9.14% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.602090 * 2000, metric = 9.63% * 2000 959.900s (  2.1 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 17.17% * 2000;
 Minibatch[   1- 100]: loss = 0.604985 * 100, metric = 9.89% * 100;
 Minibatch[ 101- 200]: loss = 0.620910 * 100, metric = 10.00% * 100;
 Minibatch[ 201- 300]: loss = 0.583892 * 100, metric = 9.10% * 100;
 Minibatch[ 301- 400]: loss = 0.597574 * 100, metric = 9.40% * 100;
 Minibatch[ 401- 500]: loss = 0.600156 * 100, metric = 9.53% * 100;
 Minibatch[ 501- 600]: loss = 0.585068 * 100, metric = 8.90% * 100;
 Minibatch[ 601- 700]: loss = 0.604458 * 100, metric = 9.72% * 100;
 Minibatch[ 701- 800]: loss = 0.579058 * 100, metric = 9.20% * 100;
 Minibatch[ 801- 900]: loss = 0.622764 * 100, metric = 10.07% * 100;
 Minibatch[ 901-1000]: loss = 0.591179 * 100, metric = 9.22% * 100;
 Minibatch[1001-1100]: loss = 0.607803 * 100, metric = 9.42% * 100;
 Minibatch[1101-1200]: loss = 0.594788 * 100, metric = 9.55% * 100;
 Minibatch[1201-1300]: loss = 0.599665 * 100, metric = 9.57% * 100;
 Minibatch[1301-1400]: loss = 0.580289 * 100, metric = 9.18% * 100;
 Minibatch[1401-1500]: loss = 0.600493 * 100, metric = 9.74% * 100;
 Minibatch[1501-1600]: loss = 0.602763 * 100, metric = 9.83% * 100;
 Minibatch[1601-1700]: loss = 0.583910 * 100, metric = 9.45% * 100;
 Minibatch[1701-1800]: loss = 0.569336 * 100, metric = 8.88% * 100;
 Minibatch[1801-1900]: loss = 0.579362 * 100, metric = 9.27% * 100;
 Minibatch[1901-2000]: loss = 0.575662 * 100, metric = 8.76% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.594206 * 2000, metric = 9.43% * 2000 987.294s (  2.0 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 17.94% * 2000;
 Minibatch[   1- 100]: loss = 0.577494 * 100, metric = 8.85% * 100;
 Minibatch[ 101- 200]: loss = 0.585006 * 100, metric = 9.35% * 100;
 Minibatch[ 201- 300]: loss = 0.582400 * 100, metric = 9.16% * 100;
 Minibatch[ 301- 400]: loss = 0.598566 * 100, metric = 9.34% * 100;
 Minibatch[ 401- 500]: loss = 0.589494 * 100, metric = 9.28% * 100;
 Minibatch[ 501- 600]: loss = 0.593253 * 100, metric = 9.44% * 100;
 Minibatch[ 601- 700]: loss = 0.600416 * 100, metric = 9.79% * 100;
 Minibatch[ 701- 800]: loss = 0.589937 * 100, metric = 9.40% * 100;
 Minibatch[ 801- 900]: loss = 0.598221 * 100, metric = 9.55% * 100;
 Minibatch[ 901-1000]: loss = 0.603003 * 100, metric = 9.68% * 100;
 Minibatch[1001-1100]: loss = 0.571260 * 100, metric = 9.13% * 100;
 Minibatch[1101-1200]: loss = 0.582975 * 100, metric = 9.15% * 100;
 Minibatch[1201-1300]: loss = 0.592569 * 100, metric = 9.56% * 100;
 Minibatch[1301-1400]: loss = 0.590156 * 100, metric = 9.68% * 100;
 Minibatch[1401-1500]: loss = 0.572538 * 100, metric = 9.31% * 100;
 Minibatch[1501-1600]: loss = 0.606380 * 100, metric = 9.76% * 100;
 Minibatch[1601-1700]: loss = 0.577138 * 100, metric = 9.03% * 100;
 Minibatch[1701-1800]: loss = 0.590432 * 100, metric = 9.72% * 100;
 Minibatch[1801-1900]: loss = 0.578654 * 100, metric = 9.57% * 100;
 Minibatch[1901-2000]: loss = 0.581176 * 100, metric = 9.28% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.588053 * 2000, metric = 9.40% * 2000 970.027s (  2.1 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 16.94% * 2000;
 Minibatch[   1- 100]: loss = 0.592154 * 100, metric = 9.28% * 100;
 Minibatch[ 101- 200]: loss = 0.583716 * 100, metric = 9.23% * 100;
 Minibatch[ 201- 300]: loss = 0.581516 * 100, metric = 9.29% * 100;
 Minibatch[ 301- 400]: loss = 0.588654 * 100, metric = 9.71% * 100;
 Minibatch[ 401- 500]: loss = 0.570821 * 100, metric = 8.97% * 100;
 Minibatch[ 501- 600]: loss = 0.569434 * 100, metric = 8.88% * 100;
 Minibatch[ 601- 700]: loss = 0.567974 * 100, metric = 9.22% * 100;
 Minibatch[ 701- 800]: loss = 0.536091 * 100, metric = 8.34% * 100;
 Minibatch[ 801- 900]: loss = 0.578177 * 100, metric = 8.89% * 100;
 Minibatch[ 901-1000]: loss = 0.558737 * 100, metric = 8.87% * 100;
 Minibatch[1001-1100]: loss = 0.565674 * 100, metric = 8.91% * 100;
 Minibatch[1101-1200]: loss = 0.563249 * 100, metric = 8.86% * 100;
 Minibatch[1201-1300]: loss = 0.571978 * 100, metric = 8.90% * 100;
 Minibatch[1301-1400]: loss = 0.559092 * 100, metric = 8.79% * 100;
 Minibatch[1401-1500]: loss = 0.574735 * 100, metric = 9.04% * 100;
 Minibatch[1501-1600]: loss = 0.580684 * 100, metric = 9.47% * 100;
 Minibatch[1601-1700]: loss = 0.565800 * 100, metric = 9.03% * 100;
 Minibatch[1701-1800]: loss = 0.560860 * 100, metric = 8.54% * 100;
 Minibatch[1801-1900]: loss = 0.589114 * 100, metric = 9.74% * 100;
 Minibatch[1901-2000]: loss = 0.548812 * 100, metric = 8.60% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.570364 * 2000, metric = 9.03% * 2000 976.966s (  2.0 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 15.72% * 2000;
0.6717191610559821
 Minibatch[   1- 100]: loss = 0.584268 * 100, metric = 9.38% * 100;
 Minibatch[ 101- 200]: loss = 0.576877 * 100, metric = 9.11% * 100;
 Minibatch[ 201- 300]: loss = 0.573642 * 100, metric = 9.29% * 100;
 Minibatch[ 301- 400]: loss = 0.558996 * 100, metric = 8.89% * 100;
 Minibatch[ 401- 500]: loss = 0.556201 * 100, metric = 8.88% * 100;
 Minibatch[ 501- 600]: loss = 0.573468 * 100, metric = 9.06% * 100;
 Minibatch[ 601- 700]: loss = 0.558983 * 100, metric = 8.75% * 100;
 Minibatch[ 701- 800]: loss = 0.559471 * 100, metric = 8.79% * 100;
 Minibatch[ 801- 900]: loss = 0.569633 * 100, metric = 8.94% * 100;
 Minibatch[ 901-1000]: loss = 0.569449 * 100, metric = 9.08% * 100;
 Minibatch[1001-1100]: loss = 0.552666 * 100, metric = 8.60% * 100;
 Minibatch[1101-1200]: loss = 0.541343 * 100, metric = 8.37% * 100;
 Minibatch[1201-1300]: loss = 0.556894 * 100, metric = 8.56% * 100;
 Minibatch[1301-1400]: loss = 0.563141 * 100, metric = 8.84% * 100;
 Minibatch[1401-1500]: loss = 0.557979 * 100, metric = 8.59% * 100;
 Minibatch[1501-1600]: loss = 0.550628 * 100, metric = 8.42% * 100;
 Minibatch[1601-1700]: loss = 0.563111 * 100, metric = 8.72% * 100;
 Minibatch[1701-1800]: loss = 0.556671 * 100, metric = 8.70% * 100;
 Minibatch[1801-1900]: loss = 0.552265 * 100, metric = 8.60% * 100;
 Minibatch[1901-2000]: loss = 0.558933 * 100, metric = 8.52% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.561731 * 2000, metric = 8.80% * 2000 976.681s (  2.0 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 16.96% * 2000;
 Minibatch[   1- 100]: loss = 0.571913 * 100, metric = 8.85% * 100;
 Minibatch[ 101- 200]: loss = 0.575821 * 100, metric = 9.21% * 100;
 Minibatch[ 201- 300]: loss = 0.567553 * 100, metric = 8.77% * 100;
 Minibatch[ 301- 400]: loss = 0.572811 * 100, metric = 8.90% * 100;
 Minibatch[ 401- 500]: loss = 0.570675 * 100, metric = 8.92% * 100;
 Minibatch[ 501- 600]: loss = 0.563817 * 100, metric = 8.92% * 100;
 Minibatch[ 601- 700]: loss = 0.558315 * 100, metric = 8.72% * 100;
 Minibatch[ 701- 800]: loss = 0.538664 * 100, metric = 8.07% * 100;
 Minibatch[ 801- 900]: loss = 0.546300 * 100, metric = 8.56% * 100;
 Minibatch[ 901-1000]: loss = 0.559297 * 100, metric = 8.74% * 100;
 Minibatch[1001-1100]: loss = 0.549821 * 100, metric = 8.40% * 100;
 Minibatch[1101-1200]: loss = 0.555756 * 100, metric = 8.76% * 100;
 Minibatch[1201-1300]: loss = 0.562977 * 100, metric = 8.91% * 100;
 Minibatch[1301-1400]: loss = 0.563939 * 100, metric = 8.97% * 100;
 Minibatch[1401-1500]: loss = 0.538932 * 100, metric = 8.48% * 100;
 Minibatch[1501-1600]: loss = 0.550175 * 100, metric = 8.55% * 100;
 Minibatch[1601-1700]: loss = 0.547775 * 100, metric = 8.60% * 100;
 Minibatch[1701-1800]: loss = 0.563832 * 100, metric = 8.74% * 100;
 Minibatch[1801-1900]: loss = 0.555927 * 100, metric = 8.95% * 100;
 Minibatch[1901-2000]: loss = 0.559006 * 100, metric = 8.67% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.558665 * 2000, metric = 8.73% * 2000 951.588s (  2.1 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 16.64% * 2000;
 Minibatch[   1- 100]: loss = 0.537436 * 100, metric = 8.19% * 100;
 Minibatch[ 101- 200]: loss = 0.559995 * 100, metric = 8.86% * 100;
 Minibatch[ 201- 300]: loss = 0.543402 * 100, metric = 8.60% * 100;
 Minibatch[ 301- 400]: loss = 0.557775 * 100, metric = 8.56% * 100;
 Minibatch[ 401- 500]: loss = 0.545879 * 100, metric = 8.38% * 100;
 Minibatch[ 501- 600]: loss = 0.538010 * 100, metric = 8.39% * 100;
 Minibatch[ 601- 700]: loss = 0.562662 * 100, metric = 8.89% * 100;
 Minibatch[ 701- 800]: loss = 0.543965 * 100, metric = 8.45% * 100;
 Minibatch[ 801- 900]: loss = 0.564214 * 100, metric = 9.01% * 100;
 Minibatch[ 901-1000]: loss = 0.548399 * 100, metric = 8.50% * 100;
 Minibatch[1001-1100]: loss = 0.554919 * 100, metric = 8.64% * 100;
 Minibatch[1101-1200]: loss = 0.566705 * 100, metric = 9.05% * 100;
 Minibatch[1201-1300]: loss = 0.555015 * 100, metric = 8.82% * 100;
 Minibatch[1301-1400]: loss = 0.542901 * 100, metric = 8.36% * 100;
 Minibatch[1401-1500]: loss = 0.543518 * 100, metric = 8.33% * 100;
 Minibatch[1501-1600]: loss = 0.552568 * 100, metric = 8.83% * 100;
 Minibatch[1601-1700]: loss = 0.534349 * 100, metric = 8.19% * 100;
 Minibatch[1701-1800]: loss = 0.540421 * 100, metric = 8.34% * 100;
 Minibatch[1801-1900]: loss = 0.550577 * 100, metric = 8.57% * 100;
 Minibatch[1901-2000]: loss = 0.555687 * 100, metric = 8.63% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.549920 * 2000, metric = 8.58% * 2000 963.809s (  2.1 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 15.57% * 2000;
 Minibatch[   1- 100]: loss = 0.551242 * 100, metric = 8.48% * 100;
 Minibatch[ 101- 200]: loss = 0.544410 * 100, metric = 8.73% * 100;
 Minibatch[ 201- 300]: loss = 0.551745 * 100, metric = 8.68% * 100;
 Minibatch[ 301- 400]: loss = 0.553062 * 100, metric = 8.47% * 100;
 Minibatch[ 401- 500]: loss = 0.546326 * 100, metric = 8.60% * 100;
 Minibatch[ 501- 600]: loss = 0.552727 * 100, metric = 8.42% * 100;
 Minibatch[ 601- 700]: loss = 0.553121 * 100, metric = 8.52% * 100;
 Minibatch[ 701- 800]: loss = 0.531569 * 100, metric = 8.31% * 100;
 Minibatch[ 801- 900]: loss = 0.541542 * 100, metric = 8.56% * 100;
 Minibatch[ 901-1000]: loss = 0.548334 * 100, metric = 8.51% * 100;
 Minibatch[1001-1100]: loss = 0.545741 * 100, metric = 8.47% * 100;
 Minibatch[1101-1200]: loss = 0.557827 * 100, metric = 8.75% * 100;
 Minibatch[1201-1300]: loss = 0.571580 * 100, metric = 9.11% * 100;
 Minibatch[1301-1400]: loss = 0.543582 * 100, metric = 8.29% * 100;
 Minibatch[1401-1500]: loss = 0.538890 * 100, metric = 8.15% * 100;
 Minibatch[1501-1600]: loss = 0.559327 * 100, metric = 8.88% * 100;
 Minibatch[1601-1700]: loss = 0.546096 * 100, metric = 8.43% * 100;
 Minibatch[1701-1800]: loss = 0.544990 * 100, metric = 8.45% * 100;
 Minibatch[1801-1900]: loss = 0.538133 * 100, metric = 8.00% * 100;
 Minibatch[1901-2000]: loss = 0.522777 * 100, metric = 7.79% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.547151 * 2000, metric = 8.48% * 2000 971.582s (  2.1 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 15.82% * 2000;
 Minibatch[   1- 100]: loss = 0.547511 * 100, metric = 8.56% * 100;
 Minibatch[ 101- 200]: loss = 0.521144 * 100, metric = 7.89% * 100;
 Minibatch[ 201- 300]: loss = 0.544934 * 100, metric = 8.55% * 100;
 Minibatch[ 301- 400]: loss = 0.538716 * 100, metric = 8.01% * 100;
 Minibatch[ 401- 500]: loss = 0.538742 * 100, metric = 8.35% * 100;
 Minibatch[ 501- 600]: loss = 0.542403 * 100, metric = 8.04% * 100;
 Minibatch[ 601- 700]: loss = 0.559023 * 100, metric = 8.79% * 100;
 Minibatch[ 701- 800]: loss = 0.533203 * 100, metric = 8.47% * 100;
 Minibatch[ 801- 900]: loss = 0.529016 * 100, metric = 8.07% * 100;
 Minibatch[ 901-1000]: loss = 0.527256 * 100, metric = 8.14% * 100;
 Minibatch[1001-1100]: loss = 0.543270 * 100, metric = 8.67% * 100;
 Minibatch[1101-1200]: loss = 0.552518 * 100, metric = 8.62% * 100;
 Minibatch[1201-1300]: loss = 0.537073 * 100, metric = 8.25% * 100;
 Minibatch[1301-1400]: loss = 0.521628 * 100, metric = 7.80% * 100;
 Minibatch[1401-1500]: loss = 0.532392 * 100, metric = 8.34% * 100;
 Minibatch[1501-1600]: loss = 0.530462 * 100, metric = 8.04% * 100;
 Minibatch[1601-1700]: loss = 0.556892 * 100, metric = 9.05% * 100;
 Minibatch[1701-1800]: loss = 0.549097 * 100, metric = 8.54% * 100;
 Minibatch[1801-1900]: loss = 0.531016 * 100, metric = 8.11% * 100;
 Minibatch[1901-2000]: loss = 0.535001 * 100, metric = 8.27% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.538565 * 2000, metric = 8.33% * 2000 962.972s (  2.1 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 17.48% * 2000;
 Minibatch[   1- 100]: loss = 0.536177 * 100, metric = 8.10% * 100;
 Minibatch[ 101- 200]: loss = 0.547879 * 100, metric = 8.19% * 100;
 Minibatch[ 201- 300]: loss = 0.530384 * 100, metric = 8.28% * 100;
 Minibatch[ 301- 400]: loss = 0.525813 * 100, metric = 8.12% * 100;
 Minibatch[ 401- 500]: loss = 0.529433 * 100, metric = 7.84% * 100;
 Minibatch[ 501- 600]: loss = 0.533029 * 100, metric = 8.21% * 100;
 Minibatch[ 601- 700]: loss = 0.521831 * 100, metric = 8.00% * 100;
 Minibatch[ 701- 800]: loss = 0.530384 * 100, metric = 8.12% * 100;
 Minibatch[ 801- 900]: loss = 0.539902 * 100, metric = 8.30% * 100;
 Minibatch[ 901-1000]: loss = 0.533735 * 100, metric = 8.35% * 100;
 Minibatch[1001-1100]: loss = 0.525453 * 100, metric = 7.71% * 100;
 Minibatch[1101-1200]: loss = 0.554617 * 100, metric = 8.56% * 100;
 Minibatch[1201-1300]: loss = 0.530020 * 100, metric = 8.21% * 100;
 Minibatch[1301-1400]: loss = 0.543448 * 100, metric = 8.55% * 100;
 Minibatch[1401-1500]: loss = 0.524059 * 100, metric = 8.04% * 100;
 Minibatch[1501-1600]: loss = 0.533566 * 100, metric = 8.24% * 100;
 Minibatch[1601-1700]: loss = 0.507468 * 100, metric = 7.53% * 100;
 Minibatch[1701-1800]: loss = 0.528098 * 100, metric = 7.91% * 100;
 Minibatch[1801-1900]: loss = 0.525226 * 100, metric = 7.86% * 100;
 Minibatch[1901-2000]: loss = 0.531965 * 100, metric = 8.19% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.531624 * 2000, metric = 8.11% * 2000 958.964s (  2.1 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 15.58% * 2000;
 Minibatch[   1- 100]: loss = 0.536564 * 100, metric = 8.54% * 100;
 Minibatch[ 101- 200]: loss = 0.517194 * 100, metric = 7.59% * 100;
 Minibatch[ 201- 300]: loss = 0.531259 * 100, metric = 8.10% * 100;
 Minibatch[ 301- 400]: loss = 0.530611 * 100, metric = 8.02% * 100;
 Minibatch[ 401- 500]: loss = 0.527334 * 100, metric = 8.09% * 100;
 Minibatch[ 501- 600]: loss = 0.543743 * 100, metric = 8.63% * 100;
 Minibatch[ 601- 700]: loss = 0.523719 * 100, metric = 7.80% * 100;
 Minibatch[ 701- 800]: loss = 0.505829 * 100, metric = 7.50% * 100;
 Minibatch[ 801- 900]: loss = 0.522377 * 100, metric = 7.97% * 100;
 Minibatch[ 901-1000]: loss = 0.531957 * 100, metric = 8.49% * 100;
 Minibatch[1001-1100]: loss = 0.526433 * 100, metric = 8.03% * 100;
 Minibatch[1101-1200]: loss = 0.518554 * 100, metric = 7.62% * 100;
 Minibatch[1201-1300]: loss = 0.528975 * 100, metric = 8.13% * 100;
 Minibatch[1301-1400]: loss = 0.521641 * 100, metric = 7.81% * 100;
 Minibatch[1401-1500]: loss = 0.537715 * 100, metric = 8.05% * 100;
 Minibatch[1501-1600]: loss = 0.520273 * 100, metric = 7.71% * 100;
 Minibatch[1601-1700]: loss = 0.528755 * 100, metric = 7.77% * 100;
 Minibatch[1701-1800]: loss = 0.519386 * 100, metric = 7.68% * 100;
 Minibatch[1801-1900]: loss = 0.515955 * 100, metric = 7.93% * 100;
 Minibatch[1901-2000]: loss = 0.528546 * 100, metric = 8.02% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.525841 * 2000, metric = 7.97% * 2000 939.297s (  2.1 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 14.36% * 2000;
0.651956493139267
 Minibatch[   1- 100]: loss = 0.510080 * 100, metric = 7.54% * 100;
 Minibatch[ 101- 200]: loss = 0.509635 * 100, metric = 7.76% * 100;
 Minibatch[ 201- 300]: loss = 0.522325 * 100, metric = 8.19% * 100;
 Minibatch[ 301- 400]: loss = 0.546877 * 100, metric = 8.52% * 100;
 Minibatch[ 401- 500]: loss = 0.515025 * 100, metric = 7.60% * 100;
 Minibatch[ 501- 600]: loss = 0.516949 * 100, metric = 7.77% * 100;
 Minibatch[ 601- 700]: loss = 0.514897 * 100, metric = 7.92% * 100;
 Minibatch[ 701- 800]: loss = 0.526606 * 100, metric = 7.96% * 100;
 Minibatch[ 801- 900]: loss = 0.515052 * 100, metric = 7.93% * 100;
 Minibatch[ 901-1000]: loss = 0.527661 * 100, metric = 8.26% * 100;
 Minibatch[1001-1100]: loss = 0.528314 * 100, metric = 8.29% * 100;
 Minibatch[1101-1200]: loss = 0.513132 * 100, metric = 7.62% * 100;
 Minibatch[1201-1300]: loss = 0.526251 * 100, metric = 7.83% * 100;
 Minibatch[1301-1400]: loss = 0.514325 * 100, metric = 7.64% * 100;
 Minibatch[1401-1500]: loss = 0.533511 * 100, metric = 8.31% * 100;
 Minibatch[1501-1600]: loss = 0.501458 * 100, metric = 7.50% * 100;
 Minibatch[1601-1700]: loss = 0.535050 * 100, metric = 8.30% * 100;
 Minibatch[1701-1800]: loss = 0.504361 * 100, metric = 7.41% * 100;
 Minibatch[1801-1900]: loss = 0.532408 * 100, metric = 8.28% * 100;
 Minibatch[1901-2000]: loss = 0.515783 * 100, metric = 7.73% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.520485 * 2000, metric = 7.92% * 2000 947.411s (  2.1 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 16.08% * 2000;
 Minibatch[   1- 100]: loss = 0.532005 * 100, metric = 8.22% * 100;
 Minibatch[ 101- 200]: loss = 0.500389 * 100, metric = 7.16% * 100;
 Minibatch[ 201- 300]: loss = 0.511625 * 100, metric = 7.62% * 100;
 Minibatch[ 301- 400]: loss = 0.520853 * 100, metric = 7.97% * 100;
 Minibatch[ 401- 500]: loss = 0.514779 * 100, metric = 7.86% * 100;
 Minibatch[ 501- 600]: loss = 0.496906 * 100, metric = 7.20% * 100;
 Minibatch[ 601- 700]: loss = 0.514036 * 100, metric = 7.81% * 100;
 Minibatch[ 701- 800]: loss = 0.509781 * 100, metric = 7.64% * 100;
 Minibatch[ 801- 900]: loss = 0.518433 * 100, metric = 7.85% * 100;
 Minibatch[ 901-1000]: loss = 0.495020 * 100, metric = 7.33% * 100;
 Minibatch[1001-1100]: loss = 0.513599 * 100, metric = 7.78% * 100;
 Minibatch[1101-1200]: loss = 0.529054 * 100, metric = 7.84% * 100;
 Minibatch[1201-1300]: loss = 0.497739 * 100, metric = 7.33% * 100;
 Minibatch[1301-1400]: loss = 0.510394 * 100, metric = 7.66% * 100;
 Minibatch[1401-1500]: loss = 0.509189 * 100, metric = 7.43% * 100;
 Minibatch[1501-1600]: loss = 0.522686 * 100, metric = 8.13% * 100;
 Minibatch[1601-1700]: loss = 0.521796 * 100, metric = 7.89% * 100;
 Minibatch[1701-1800]: loss = 0.522910 * 100, metric = 7.90% * 100;
 Minibatch[1801-1900]: loss = 0.509969 * 100, metric = 7.76% * 100;
 Minibatch[1901-2000]: loss = 0.523962 * 100, metric = 7.88% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.513756 * 2000, metric = 7.71% * 2000 955.188s (  2.1 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 16.49% * 2000;
 Minibatch[   1- 100]: loss = 0.512986 * 100, metric = 7.47% * 100;
 Minibatch[ 101- 200]: loss = 0.529262 * 100, metric = 8.26% * 100;
 Minibatch[ 201- 300]: loss = 0.511633 * 100, metric = 7.68% * 100;
 Minibatch[ 301- 400]: loss = 0.504518 * 100, metric = 7.41% * 100;
 Minibatch[ 401- 500]: loss = 0.510579 * 100, metric = 7.48% * 100;
 Minibatch[ 501- 600]: loss = 0.507223 * 100, metric = 7.45% * 100;
 Minibatch[ 601- 700]: loss = 0.517015 * 100, metric = 7.89% * 100;
 Minibatch[ 701- 800]: loss = 0.519197 * 100, metric = 7.89% * 100;
 Minibatch[ 801- 900]: loss = 0.511276 * 100, metric = 7.69% * 100;
 Minibatch[ 901-1000]: loss = 0.501158 * 100, metric = 7.76% * 100;
 Minibatch[1001-1100]: loss = 0.499404 * 100, metric = 7.23% * 100;
 Minibatch[1101-1200]: loss = 0.513953 * 100, metric = 7.81% * 100;
 Minibatch[1201-1300]: loss = 0.504480 * 100, metric = 7.59% * 100;
 Minibatch[1301-1400]: loss = 0.503207 * 100, metric = 7.62% * 100;
 Minibatch[1401-1500]: loss = 0.510245 * 100, metric = 7.55% * 100;
 Minibatch[1501-1600]: loss = 0.488681 * 100, metric = 7.34% * 100;
 Minibatch[1601-1700]: loss = 0.513185 * 100, metric = 7.62% * 100;
 Minibatch[1701-1800]: loss = 0.502505 * 100, metric = 7.58% * 100;
 Minibatch[1801-1900]: loss = 0.512361 * 100, metric = 7.84% * 100;
 Minibatch[1901-2000]: loss = 0.505814 * 100, metric = 7.45% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.508934 * 2000, metric = 7.63% * 2000 946.706s (  2.1 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 15.18% * 2000;
 Minibatch[   1- 100]: loss = 0.514453 * 100, metric = 7.74% * 100;
 Minibatch[ 101- 200]: loss = 0.507583 * 100, metric = 7.68% * 100;
 Minibatch[ 201- 300]: loss = 0.516523 * 100, metric = 7.85% * 100;
 Minibatch[ 301- 400]: loss = 0.530794 * 100, metric = 7.96% * 100;
 Minibatch[ 401- 500]: loss = 0.509411 * 100, metric = 7.80% * 100;
 Minibatch[ 501- 600]: loss = 0.509047 * 100, metric = 7.88% * 100;
 Minibatch[ 601- 700]: loss = 0.494998 * 100, metric = 7.16% * 100;
 Minibatch[ 701- 800]: loss = 0.499525 * 100, metric = 7.32% * 100;
 Minibatch[ 801- 900]: loss = 0.489072 * 100, metric = 7.30% * 100;
 Minibatch[ 901-1000]: loss = 0.496292 * 100, metric = 7.21% * 100;
 Minibatch[1001-1100]: loss = 0.494633 * 100, metric = 7.27% * 100;
 Minibatch[1101-1200]: loss = 0.506751 * 100, metric = 7.75% * 100;
 Minibatch[1201-1300]: loss = 0.516924 * 100, metric = 7.80% * 100;
 Minibatch[1301-1400]: loss = 0.498871 * 100, metric = 7.58% * 100;
 Minibatch[1401-1500]: loss = 0.507567 * 100, metric = 7.81% * 100;
 Minibatch[1501-1600]: loss = 0.512913 * 100, metric = 7.66% * 100;
 Minibatch[1601-1700]: loss = 0.494004 * 100, metric = 7.28% * 100;
 Minibatch[1701-1800]: loss = 0.514183 * 100, metric = 7.58% * 100;
 Minibatch[1801-1900]: loss = 0.496375 * 100, metric = 7.29% * 100;
 Minibatch[1901-2000]: loss = 0.508674 * 100, metric = 8.07% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.505930 * 2000, metric = 7.60% * 2000 966.910s (  2.1 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 14.98% * 2000;
 Minibatch[   1- 100]: loss = 0.528828 * 100, metric = 8.25% * 100;
 Minibatch[ 101- 200]: loss = 0.496052 * 100, metric = 7.39% * 100;
 Minibatch[ 201- 300]: loss = 0.498499 * 100, metric = 7.38% * 100;
 Minibatch[ 301- 400]: loss = 0.504452 * 100, metric = 7.68% * 100;
 Minibatch[ 401- 500]: loss = 0.494828 * 100, metric = 7.44% * 100;
 Minibatch[ 501- 600]: loss = 0.503671 * 100, metric = 7.48% * 100;
 Minibatch[ 601- 700]: loss = 0.516317 * 100, metric = 7.92% * 100;
 Minibatch[ 701- 800]: loss = 0.498629 * 100, metric = 7.45% * 100;
 Minibatch[ 801- 900]: loss = 0.499707 * 100, metric = 7.24% * 100;
 Minibatch[ 901-1000]: loss = 0.485462 * 100, metric = 7.06% * 100;
 Minibatch[1001-1100]: loss = 0.494622 * 100, metric = 7.37% * 100;
 Minibatch[1101-1200]: loss = 0.481721 * 100, metric = 7.10% * 100;
 Minibatch[1201-1300]: loss = 0.515034 * 100, metric = 7.60% * 100;
 Minibatch[1301-1400]: loss = 0.483069 * 100, metric = 6.81% * 100;
 Minibatch[1401-1500]: loss = 0.514354 * 100, metric = 7.90% * 100;
 Minibatch[1501-1600]: loss = 0.512286 * 100, metric = 7.77% * 100;
 Minibatch[1601-1700]: loss = 0.501617 * 100, metric = 7.26% * 100;
 Minibatch[1701-1800]: loss = 0.489652 * 100, metric = 6.87% * 100;
 Minibatch[1801-1900]: loss = 0.492874 * 100, metric = 7.22% * 100;
 Minibatch[1901-2000]: loss = 0.510582 * 100, metric = 7.74% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.501113 * 2000, metric = 7.45% * 2000 950.593s (  2.1 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 14.66% * 2000;
 Minibatch[   1- 100]: loss = 0.493303 * 100, metric = 7.49% * 100;
 Minibatch[ 101- 200]: loss = 0.509979 * 100, metric = 7.51% * 100;
 Minibatch[ 201- 300]: loss = 0.490982 * 100, metric = 7.19% * 100;
 Minibatch[ 301- 400]: loss = 0.502926 * 100, metric = 7.74% * 100;
 Minibatch[ 401- 500]: loss = 0.485170 * 100, metric = 7.17% * 100;
 Minibatch[ 501- 600]: loss = 0.497623 * 100, metric = 7.42% * 100;
 Minibatch[ 601- 700]: loss = 0.503920 * 100, metric = 7.66% * 100;
 Minibatch[ 701- 800]: loss = 0.495381 * 100, metric = 7.42% * 100;
 Minibatch[ 801- 900]: loss = 0.481479 * 100, metric = 6.87% * 100;
 Minibatch[ 901-1000]: loss = 0.486619 * 100, metric = 7.43% * 100;
 Minibatch[1001-1100]: loss = 0.493834 * 100, metric = 7.47% * 100;
 Minibatch[1101-1200]: loss = 0.484183 * 100, metric = 7.13% * 100;
 Minibatch[1201-1300]: loss = 0.497173 * 100, metric = 7.42% * 100;
 Minibatch[1301-1400]: loss = 0.497305 * 100, metric = 7.49% * 100;
 Minibatch[1401-1500]: loss = 0.509641 * 100, metric = 7.80% * 100;
 Minibatch[1501-1600]: loss = 0.500079 * 100, metric = 7.35% * 100;
 Minibatch[1601-1700]: loss = 0.503724 * 100, metric = 7.59% * 100;
 Minibatch[1701-1800]: loss = 0.499089 * 100, metric = 7.64% * 100;
 Minibatch[1801-1900]: loss = 0.486259 * 100, metric = 7.14% * 100;
 Minibatch[1901-2000]: loss = 0.493387 * 100, metric = 7.21% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.495603 * 2000, metric = 7.41% * 2000 945.186s (  2.1 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 15.15% * 2000;
 Minibatch[   1- 100]: loss = 0.468734 * 100, metric = 6.67% * 100;
 Minibatch[ 101- 200]: loss = 0.491435 * 100, metric = 7.39% * 100;
 Minibatch[ 201- 300]: loss = 0.492477 * 100, metric = 7.35% * 100;
 Minibatch[ 301- 400]: loss = 0.475597 * 100, metric = 6.91% * 100;
 Minibatch[ 401- 500]: loss = 0.485553 * 100, metric = 7.08% * 100;
 Minibatch[ 501- 600]: loss = 0.467654 * 100, metric = 6.82% * 100;
 Minibatch[ 601- 700]: loss = 0.507830 * 100, metric = 7.54% * 100;
 Minibatch[ 701- 800]: loss = 0.474083 * 100, metric = 6.88% * 100;
 Minibatch[ 801- 900]: loss = 0.502092 * 100, metric = 7.63% * 100;
 Minibatch[ 901-1000]: loss = 0.482313 * 100, metric = 7.16% * 100;
 Minibatch[1001-1100]: loss = 0.504782 * 100, metric = 7.62% * 100;
 Minibatch[1101-1200]: loss = 0.489658 * 100, metric = 7.03% * 100;
 Minibatch[1201-1300]: loss = 0.489564 * 100, metric = 7.38% * 100;
 Minibatch[1301-1400]: loss = 0.501066 * 100, metric = 7.60% * 100;
 Minibatch[1401-1500]: loss = 0.481517 * 100, metric = 6.82% * 100;
 Minibatch[1501-1600]: loss = 0.494196 * 100, metric = 7.08% * 100;
 Minibatch[1601-1700]: loss = 0.492266 * 100, metric = 7.34% * 100;
 Minibatch[1701-1800]: loss = 0.481177 * 100, metric = 7.07% * 100;
 Minibatch[1801-1900]: loss = 0.497243 * 100, metric = 7.71% * 100;
 Minibatch[1901-2000]: loss = 0.490532 * 100, metric = 7.14% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.488488 * 2000, metric = 7.21% * 2000 953.563s (  2.1 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 14.63% * 2000;
 Minibatch[   1- 100]: loss = 0.484754 * 100, metric = 6.82% * 100;
 Minibatch[ 101- 200]: loss = 0.460197 * 100, metric = 6.41% * 100;
 Minibatch[ 201- 300]: loss = 0.501426 * 100, metric = 7.69% * 100;
 Minibatch[ 301- 400]: loss = 0.481840 * 100, metric = 6.99% * 100;
 Minibatch[ 401- 500]: loss = 0.477881 * 100, metric = 6.89% * 100;
 Minibatch[ 501- 600]: loss = 0.486246 * 100, metric = 6.92% * 100;
 Minibatch[ 601- 700]: loss = 0.498055 * 100, metric = 7.26% * 100;
 Minibatch[ 701- 800]: loss = 0.466194 * 100, metric = 6.56% * 100;
 Minibatch[ 801- 900]: loss = 0.472982 * 100, metric = 6.84% * 100;
 Minibatch[ 901-1000]: loss = 0.492475 * 100, metric = 7.33% * 100;
 Minibatch[1001-1100]: loss = 0.495631 * 100, metric = 7.31% * 100;
 Minibatch[1101-1200]: loss = 0.487945 * 100, metric = 7.26% * 100;
 Minibatch[1201-1300]: loss = 0.481613 * 100, metric = 7.17% * 100;
 Minibatch[1301-1400]: loss = 0.466733 * 100, metric = 6.68% * 100;
 Minibatch[1401-1500]: loss = 0.473397 * 100, metric = 6.93% * 100;
 Minibatch[1501-1600]: loss = 0.481586 * 100, metric = 7.22% * 100;
 Minibatch[1601-1700]: loss = 0.491246 * 100, metric = 7.40% * 100;
 Minibatch[1701-1800]: loss = 0.490427 * 100, metric = 7.17% * 100;
 Minibatch[1801-1900]: loss = 0.482936 * 100, metric = 6.70% * 100;
 Minibatch[1901-2000]: loss = 0.471124 * 100, metric = 6.78% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.482234 * 2000, metric = 7.02% * 2000 940.169s (  2.1 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 14.84% * 2000;
 Minibatch[   1- 100]: loss = 0.481316 * 100, metric = 7.09% * 100;
 Minibatch[ 101- 200]: loss = 0.483522 * 100, metric = 7.20% * 100;
 Minibatch[ 201- 300]: loss = 0.486464 * 100, metric = 7.35% * 100;
 Minibatch[ 301- 400]: loss = 0.488255 * 100, metric = 7.16% * 100;
 Minibatch[ 401- 500]: loss = 0.479101 * 100, metric = 7.28% * 100;
 Minibatch[ 501- 600]: loss = 0.466816 * 100, metric = 6.87% * 100;
 Minibatch[ 601- 700]: loss = 0.479538 * 100, metric = 7.08% * 100;
 Minibatch[ 701- 800]: loss = 0.490045 * 100, metric = 7.39% * 100;
 Minibatch[ 801- 900]: loss = 0.485918 * 100, metric = 7.05% * 100;
 Minibatch[ 901-1000]: loss = 0.465189 * 100, metric = 6.33% * 100;
 Minibatch[1001-1100]: loss = 0.471397 * 100, metric = 6.85% * 100;
 Minibatch[1101-1200]: loss = 0.491354 * 100, metric = 7.38% * 100;
 Minibatch[1201-1300]: loss = 0.496446 * 100, metric = 7.45% * 100;
 Minibatch[1301-1400]: loss = 0.486119 * 100, metric = 6.96% * 100;
 Minibatch[1401-1500]: loss = 0.475083 * 100, metric = 7.03% * 100;
 Minibatch[1501-1600]: loss = 0.468103 * 100, metric = 6.68% * 100;
 Minibatch[1601-1700]: loss = 0.472894 * 100, metric = 7.16% * 100;
 Minibatch[1701-1800]: loss = 0.477415 * 100, metric = 6.86% * 100;
 Minibatch[1801-1900]: loss = 0.477170 * 100, metric = 7.24% * 100;
 Minibatch[1901-2000]: loss = 0.474504 * 100, metric = 7.10% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.479832 * 2000, metric = 7.08% * 2000 944.361s (  2.1 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 14.46% * 2000;
 Minibatch[   1- 100]: loss = 0.490375 * 100, metric = 7.31% * 100;
 Minibatch[ 101- 200]: loss = 0.473743 * 100, metric = 6.93% * 100;
 Minibatch[ 201- 300]: loss = 0.464800 * 100, metric = 6.78% * 100;
 Minibatch[ 301- 400]: loss = 0.472284 * 100, metric = 6.99% * 100;
 Minibatch[ 401- 500]: loss = 0.475404 * 100, metric = 6.99% * 100;
 Minibatch[ 501- 600]: loss = 0.476604 * 100, metric = 7.12% * 100;
 Minibatch[ 601- 700]: loss = 0.474402 * 100, metric = 7.07% * 100;
 Minibatch[ 701- 800]: loss = 0.468188 * 100, metric = 6.81% * 100;
 Minibatch[ 801- 900]: loss = 0.473857 * 100, metric = 6.86% * 100;
 Minibatch[ 901-1000]: loss = 0.477223 * 100, metric = 7.01% * 100;
 Minibatch[1001-1100]: loss = 0.484816 * 100, metric = 7.13% * 100;
 Minibatch[1101-1200]: loss = 0.465052 * 100, metric = 6.99% * 100;
 Minibatch[1201-1300]: loss = 0.472587 * 100, metric = 6.88% * 100;
 Minibatch[1301-1400]: loss = 0.479078 * 100, metric = 6.97% * 100;
 Minibatch[1401-1500]: loss = 0.480601 * 100, metric = 7.20% * 100;
 Minibatch[1501-1600]: loss = 0.485388 * 100, metric = 7.14% * 100;
 Minibatch[1601-1700]: loss = 0.466303 * 100, metric = 6.78% * 100;
 Minibatch[1701-1800]: loss = 0.468342 * 100, metric = 7.03% * 100;
 Minibatch[1801-1900]: loss = 0.476119 * 100, metric = 7.13% * 100;
 Minibatch[1901-2000]: loss = 0.485471 * 100, metric = 7.28% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.475532 * 2000, metric = 7.02% * 2000 935.688s (  2.1 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 14.43% * 2000;
 Minibatch[   1- 100]: loss = 0.466303 * 100, metric = 6.90% * 100;
 Minibatch[ 101- 200]: loss = 0.479456 * 100, metric = 6.98% * 100;
 Minibatch[ 201- 300]: loss = 0.470053 * 100, metric = 6.74% * 100;
 Minibatch[ 301- 400]: loss = 0.467990 * 100, metric = 6.76% * 100;
 Minibatch[ 401- 500]: loss = 0.465467 * 100, metric = 6.92% * 100;
 Minibatch[ 501- 600]: loss = 0.483158 * 100, metric = 7.03% * 100;
 Minibatch[ 601- 700]: loss = 0.473971 * 100, metric = 6.97% * 100;
 Minibatch[ 701- 800]: loss = 0.480648 * 100, metric = 6.91% * 100;
 Minibatch[ 801- 900]: loss = 0.457509 * 100, metric = 6.44% * 100;
 Minibatch[ 901-1000]: loss = 0.463314 * 100, metric = 6.68% * 100;
 Minibatch[1001-1100]: loss = 0.476434 * 100, metric = 7.00% * 100;
 Minibatch[1101-1200]: loss = 0.471344 * 100, metric = 7.01% * 100;
 Minibatch[1201-1300]: loss = 0.477231 * 100, metric = 6.71% * 100;
 Minibatch[1301-1400]: loss = 0.482928 * 100, metric = 7.03% * 100;
 Minibatch[1401-1500]: loss = 0.480046 * 100, metric = 7.20% * 100;
 Minibatch[1501-1600]: loss = 0.477874 * 100, metric = 6.87% * 100;
 Minibatch[1601-1700]: loss = 0.473318 * 100, metric = 6.72% * 100;
 Minibatch[1701-1800]: loss = 0.477094 * 100, metric = 7.01% * 100;
 Minibatch[1801-1900]: loss = 0.472695 * 100, metric = 6.84% * 100;
 Minibatch[1901-2000]: loss = 0.459608 * 100, metric = 6.48% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.472822 * 2000, metric = 6.86% * 2000 906.506s (  2.2 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 14.13% * 2000;
 Minibatch[   1- 100]: loss = 0.462538 * 100, metric = 6.84% * 100;
 Minibatch[ 101- 200]: loss = 0.456990 * 100, metric = 6.66% * 100;
 Minibatch[ 201- 300]: loss = 0.473360 * 100, metric = 6.79% * 100;
 Minibatch[ 301- 400]: loss = 0.468570 * 100, metric = 6.93% * 100;
 Minibatch[ 401- 500]: loss = 0.468915 * 100, metric = 6.77% * 100;
 Minibatch[ 501- 600]: loss = 0.467009 * 100, metric = 7.10% * 100;
 Minibatch[ 601- 700]: loss = 0.485195 * 100, metric = 7.19% * 100;
 Minibatch[ 701- 800]: loss = 0.466382 * 100, metric = 6.66% * 100;
 Minibatch[ 801- 900]: loss = 0.470991 * 100, metric = 6.75% * 100;
 Minibatch[ 901-1000]: loss = 0.470388 * 100, metric = 6.78% * 100;
 Minibatch[1001-1100]: loss = 0.475107 * 100, metric = 6.98% * 100;
 Minibatch[1101-1200]: loss = 0.469871 * 100, metric = 6.92% * 100;
 Minibatch[1201-1300]: loss = 0.466955 * 100, metric = 6.82% * 100;
 Minibatch[1301-1400]: loss = 0.471105 * 100, metric = 6.79% * 100;
 Minibatch[1401-1500]: loss = 0.465330 * 100, metric = 6.66% * 100;
 Minibatch[1501-1600]: loss = 0.481697 * 100, metric = 7.19% * 100;
 Minibatch[1601-1700]: loss = 0.473074 * 100, metric = 6.89% * 100;
 Minibatch[1701-1800]: loss = 0.458294 * 100, metric = 6.52% * 100;
 Minibatch[1801-1900]: loss = 0.466512 * 100, metric = 6.74% * 100;
 Minibatch[1901-2000]: loss = 0.469224 * 100, metric = 6.80% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.469375 * 2000, metric = 6.84% * 2000 938.343s (  2.1 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 14.43% * 2000;
 Minibatch[   1- 100]: loss = 0.465142 * 100, metric = 6.96% * 100;
 Minibatch[ 101- 200]: loss = 0.452925 * 100, metric = 6.46% * 100;
 Minibatch[ 201- 300]: loss = 0.471072 * 100, metric = 6.74% * 100;
 Minibatch[ 301- 400]: loss = 0.465072 * 100, metric = 6.80% * 100;
 Minibatch[ 401- 500]: loss = 0.463096 * 100, metric = 6.83% * 100;
 Minibatch[ 501- 600]: loss = 0.458734 * 100, metric = 6.39% * 100;
 Minibatch[ 601- 700]: loss = 0.472049 * 100, metric = 7.03% * 100;
 Minibatch[ 701- 800]: loss = 0.463939 * 100, metric = 6.80% * 100;
 Minibatch[ 801- 900]: loss = 0.454952 * 100, metric = 6.69% * 100;
 Minibatch[ 901-1000]: loss = 0.465420 * 100, metric = 6.89% * 100;
 Minibatch[1001-1100]: loss = 0.462990 * 100, metric = 6.62% * 100;
 Minibatch[1101-1200]: loss = 0.475570 * 100, metric = 7.13% * 100;
 Minibatch[1201-1300]: loss = 0.470500 * 100, metric = 6.83% * 100;
 Minibatch[1301-1400]: loss = 0.454368 * 100, metric = 6.53% * 100;
 Minibatch[1401-1500]: loss = 0.455696 * 100, metric = 6.72% * 100;
 Minibatch[1501-1600]: loss = 0.464061 * 100, metric = 6.76% * 100;
 Minibatch[1601-1700]: loss = 0.465869 * 100, metric = 6.67% * 100;
 Minibatch[1701-1800]: loss = 0.465235 * 100, metric = 6.88% * 100;
 Minibatch[1801-1900]: loss = 0.458954 * 100, metric = 6.63% * 100;
 Minibatch[1901-2000]: loss = 0.450014 * 100, metric = 6.29% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.462783 * 2000, metric = 6.73% * 2000 931.662s (  2.1 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 14.98% * 2000;
 Minibatch[   1- 100]: loss = 0.451041 * 100, metric = 6.42% * 100;
 Minibatch[ 101- 200]: loss = 0.455605 * 100, metric = 6.64% * 100;
 Minibatch[ 201- 300]: loss = 0.457152 * 100, metric = 6.58% * 100;
 Minibatch[ 301- 400]: loss = 0.454960 * 100, metric = 6.40% * 100;
 Minibatch[ 401- 500]: loss = 0.471170 * 100, metric = 6.59% * 100;
 Minibatch[ 501- 600]: loss = 0.465914 * 100, metric = 6.79% * 100;
 Minibatch[ 601- 700]: loss = 0.461558 * 100, metric = 6.69% * 100;
 Minibatch[ 701- 800]: loss = 0.444398 * 100, metric = 6.46% * 100;
 Minibatch[ 801- 900]: loss = 0.449514 * 100, metric = 6.55% * 100;
 Minibatch[ 901-1000]: loss = 0.476741 * 100, metric = 7.07% * 100;
 Minibatch[1001-1100]: loss = 0.456365 * 100, metric = 6.66% * 100;
 Minibatch[1101-1200]: loss = 0.448646 * 100, metric = 6.44% * 100;
 Minibatch[1201-1300]: loss = 0.447892 * 100, metric = 6.60% * 100;
 Minibatch[1301-1400]: loss = 0.462290 * 100, metric = 6.71% * 100;
 Minibatch[1401-1500]: loss = 0.451182 * 100, metric = 6.51% * 100;
 Minibatch[1501-1600]: loss = 0.458542 * 100, metric = 6.46% * 100;
 Minibatch[1601-1700]: loss = 0.460923 * 100, metric = 6.55% * 100;
 Minibatch[1701-1800]: loss = 0.457046 * 100, metric = 6.56% * 100;
 Minibatch[1801-1900]: loss = 0.456501 * 100, metric = 6.57% * 100;
 Minibatch[1901-2000]: loss = 0.450999 * 100, metric = 6.33% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.456922 * 2000, metric = 6.58% * 2000 926.163s (  2.2 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 13.83% * 2000;
 Minibatch[   1- 100]: loss = 0.469700 * 100, metric = 7.05% * 100;
 Minibatch[ 101- 200]: loss = 0.439086 * 100, metric = 6.03% * 100;
 Minibatch[ 201- 300]: loss = 0.459415 * 100, metric = 6.66% * 100;
 Minibatch[ 301- 400]: loss = 0.454412 * 100, metric = 6.51% * 100;
 Minibatch[ 401- 500]: loss = 0.453918 * 100, metric = 6.54% * 100;
 Minibatch[ 501- 600]: loss = 0.448801 * 100, metric = 6.55% * 100;
 Minibatch[ 601- 700]: loss = 0.463898 * 100, metric = 6.67% * 100;
 Minibatch[ 701- 800]: loss = 0.450064 * 100, metric = 6.58% * 100;
 Minibatch[ 801- 900]: loss = 0.454537 * 100, metric = 6.54% * 100;
 Minibatch[ 901-1000]: loss = 0.452337 * 100, metric = 6.48% * 100;
 Minibatch[1001-1100]: loss = 0.462907 * 100, metric = 6.77% * 100;
 Minibatch[1101-1200]: loss = 0.447827 * 100, metric = 6.54% * 100;
 Minibatch[1201-1300]: loss = 0.460284 * 100, metric = 6.85% * 100;
 Minibatch[1301-1400]: loss = 0.459803 * 100, metric = 6.67% * 100;
 Minibatch[1401-1500]: loss = 0.442487 * 100, metric = 6.32% * 100;
 Minibatch[1501-1600]: loss = 0.469055 * 100, metric = 6.89% * 100;
 Minibatch[1601-1700]: loss = 0.451899 * 100, metric = 6.79% * 100;
 Minibatch[1701-1800]: loss = 0.449828 * 100, metric = 6.44% * 100;
 Minibatch[1801-1900]: loss = 0.462847 * 100, metric = 6.83% * 100;
 Minibatch[1901-2000]: loss = 0.452742 * 100, metric = 6.54% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.455292 * 2000, metric = 6.61% * 2000 937.218s (  2.1 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 14.51% * 2000;
 Minibatch[   1- 100]: loss = 0.452242 * 100, metric = 6.41% * 100;
 Minibatch[ 101- 200]: loss = 0.455173 * 100, metric = 6.58% * 100;
 Minibatch[ 201- 300]: loss = 0.448562 * 100, metric = 6.53% * 100;
 Minibatch[ 301- 400]: loss = 0.466174 * 100, metric = 6.84% * 100;
 Minibatch[ 401- 500]: loss = 0.460888 * 100, metric = 6.47% * 100;
 Minibatch[ 501- 600]: loss = 0.447509 * 100, metric = 6.62% * 100;
 Minibatch[ 601- 700]: loss = 0.464315 * 100, metric = 6.91% * 100;
 Minibatch[ 701- 800]: loss = 0.434470 * 100, metric = 5.99% * 100;
 Minibatch[ 801- 900]: loss = 0.443435 * 100, metric = 6.09% * 100;
 Minibatch[ 901-1000]: loss = 0.442570 * 100, metric = 6.22% * 100;
 Minibatch[1001-1100]: loss = 0.442489 * 100, metric = 6.16% * 100;
 Minibatch[1101-1200]: loss = 0.430087 * 100, metric = 5.93% * 100;
 Minibatch[1201-1300]: loss = 0.441194 * 100, metric = 6.25% * 100;
 Minibatch[1301-1400]: loss = 0.439039 * 100, metric = 6.05% * 100;
 Minibatch[1401-1500]: loss = 0.434791 * 100, metric = 6.03% * 100;
 Minibatch[1501-1600]: loss = 0.432469 * 100, metric = 6.08% * 100;
 Minibatch[1601-1700]: loss = 0.444024 * 100, metric = 6.33% * 100;
 Minibatch[1701-1800]: loss = 0.450905 * 100, metric = 6.52% * 100;
 Minibatch[1801-1900]: loss = 0.451737 * 100, metric = 6.32% * 100;
 Minibatch[1901-2000]: loss = 0.440368 * 100, metric = 6.27% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.446122 * 2000, metric = 6.33% * 2000 926.282s (  2.2 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 14.75% * 2000;
 Minibatch[   1- 100]: loss = 0.455352 * 100, metric = 6.48% * 100;
 Minibatch[ 101- 200]: loss = 0.442382 * 100, metric = 6.10% * 100;
 Minibatch[ 201- 300]: loss = 0.439309 * 100, metric = 6.23% * 100;
 Minibatch[ 301- 400]: loss = 0.448302 * 100, metric = 6.40% * 100;
 Minibatch[ 401- 500]: loss = 0.439258 * 100, metric = 6.31% * 100;
 Minibatch[ 501- 600]: loss = 0.429196 * 100, metric = 5.93% * 100;
 Minibatch[ 601- 700]: loss = 0.439409 * 100, metric = 6.16% * 100;
 Minibatch[ 701- 800]: loss = 0.429474 * 100, metric = 6.19% * 100;
 Minibatch[ 801- 900]: loss = 0.460066 * 100, metric = 6.78% * 100;
 Minibatch[ 901-1000]: loss = 0.434771 * 100, metric = 6.07% * 100;
 Minibatch[1001-1100]: loss = 0.435362 * 100, metric = 6.15% * 100;
 Minibatch[1101-1200]: loss = 0.452827 * 100, metric = 6.32% * 100;
 Minibatch[1201-1300]: loss = 0.447286 * 100, metric = 6.29% * 100;
 Minibatch[1301-1400]: loss = 0.440925 * 100, metric = 6.16% * 100;
 Minibatch[1401-1500]: loss = 0.451069 * 100, metric = 6.15% * 100;
 Minibatch[1501-1600]: loss = 0.442067 * 100, metric = 6.31% * 100;
 Minibatch[1601-1700]: loss = 0.438354 * 100, metric = 6.37% * 100;
 Minibatch[1701-1800]: loss = 0.450218 * 100, metric = 6.46% * 100;
 Minibatch[1801-1900]: loss = 0.442469 * 100, metric = 6.32% * 100;
 Minibatch[1901-2000]: loss = 0.446954 * 100, metric = 6.19% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.443253 * 2000, metric = 6.27% * 2000 926.841s (  2.2 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 13.91% * 2000;
 Minibatch[   1- 100]: loss = 0.431373 * 100, metric = 6.23% * 100;
 Minibatch[ 101- 200]: loss = 0.452494 * 100, metric = 6.34% * 100;
 Minibatch[ 201- 300]: loss = 0.439737 * 100, metric = 6.14% * 100;
 Minibatch[ 301- 400]: loss = 0.451223 * 100, metric = 6.53% * 100;
 Minibatch[ 401- 500]: loss = 0.452050 * 100, metric = 6.30% * 100;
 Minibatch[ 501- 600]: loss = 0.441260 * 100, metric = 6.26% * 100;
 Minibatch[ 601- 700]: loss = 0.429247 * 100, metric = 5.92% * 100;
 Minibatch[ 701- 800]: loss = 0.436418 * 100, metric = 6.05% * 100;
 Minibatch[ 801- 900]: loss = 0.429204 * 100, metric = 5.96% * 100;
 Minibatch[ 901-1000]: loss = 0.442370 * 100, metric = 6.25% * 100;
 Minibatch[1001-1100]: loss = 0.435974 * 100, metric = 6.21% * 100;
 Minibatch[1101-1200]: loss = 0.445231 * 100, metric = 6.38% * 100;
 Minibatch[1201-1300]: loss = 0.450192 * 100, metric = 6.25% * 100;
 Minibatch[1301-1400]: loss = 0.442861 * 100, metric = 6.19% * 100;
 Minibatch[1401-1500]: loss = 0.437697 * 100, metric = 5.98% * 100;
 Minibatch[1501-1600]: loss = 0.439562 * 100, metric = 6.18% * 100;
 Minibatch[1601-1700]: loss = 0.432402 * 100, metric = 5.99% * 100;
 Minibatch[1701-1800]: loss = 0.448599 * 100, metric = 6.25% * 100;
 Minibatch[1801-1900]: loss = 0.431598 * 100, metric = 5.83% * 100;
 Minibatch[1901-2000]: loss = 0.436556 * 100, metric = 6.24% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.440302 * 2000, metric = 6.17% * 2000 925.632s (  2.2 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 13.79% * 2000;
 Minibatch[   1- 100]: loss = 0.441385 * 100, metric = 6.18% * 100;
 Minibatch[ 101- 200]: loss = 0.429962 * 100, metric = 6.23% * 100;
 Minibatch[ 201- 300]: loss = 0.442917 * 100, metric = 6.29% * 100;
 Minibatch[ 301- 400]: loss = 0.428296 * 100, metric = 5.91% * 100;
 Minibatch[ 401- 500]: loss = 0.429969 * 100, metric = 5.97% * 100;
 Minibatch[ 501- 600]: loss = 0.428674 * 100, metric = 6.09% * 100;
 Minibatch[ 601- 700]: loss = 0.444972 * 100, metric = 6.38% * 100;
 Minibatch[ 701- 800]: loss = 0.447918 * 100, metric = 6.38% * 100;
 Minibatch[ 801- 900]: loss = 0.433575 * 100, metric = 6.07% * 100;
 Minibatch[ 901-1000]: loss = 0.444316 * 100, metric = 6.25% * 100;
 Minibatch[1001-1100]: loss = 0.451247 * 100, metric = 6.40% * 100;
 Minibatch[1101-1200]: loss = 0.433745 * 100, metric = 5.89% * 100;
 Minibatch[1201-1300]: loss = 0.414459 * 100, metric = 5.70% * 100;
 Minibatch[1301-1400]: loss = 0.424762 * 100, metric = 6.18% * 100;
 Minibatch[1401-1500]: loss = 0.441454 * 100, metric = 6.24% * 100;
 Minibatch[1501-1600]: loss = 0.443693 * 100, metric = 6.17% * 100;
 Minibatch[1601-1700]: loss = 0.431116 * 100, metric = 6.04% * 100;
 Minibatch[1701-1800]: loss = 0.449951 * 100, metric = 6.34% * 100;
 Minibatch[1801-1900]: loss = 0.443105 * 100, metric = 6.28% * 100;
 Minibatch[1901-2000]: loss = 0.448177 * 100, metric = 6.47% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.437685 * 2000, metric = 6.17% * 2000 907.420s (  2.2 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 13.33% * 2000;
 Minibatch[   1- 100]: loss = 0.445383 * 100, metric = 6.39% * 100;
 Minibatch[ 101- 200]: loss = 0.446321 * 100, metric = 6.27% * 100;
 Minibatch[ 201- 300]: loss = 0.426741 * 100, metric = 6.25% * 100;
 Minibatch[ 301- 400]: loss = 0.425062 * 100, metric = 6.13% * 100;
 Minibatch[ 401- 500]: loss = 0.434380 * 100, metric = 6.05% * 100;
 Minibatch[ 501- 600]: loss = 0.456787 * 100, metric = 6.59% * 100;
 Minibatch[ 601- 700]: loss = 0.456661 * 100, metric = 6.51% * 100;
 Minibatch[ 701- 800]: loss = 0.431563 * 100, metric = 5.81% * 100;
 Minibatch[ 801- 900]: loss = 0.422167 * 100, metric = 5.69% * 100;
 Minibatch[ 901-1000]: loss = 0.438541 * 100, metric = 6.49% * 100;
 Minibatch[1001-1100]: loss = 0.435265 * 100, metric = 6.21% * 100;
 Minibatch[1101-1200]: loss = 0.439980 * 100, metric = 5.99% * 100;
 Minibatch[1201-1300]: loss = 0.429882 * 100, metric = 6.01% * 100;
 Minibatch[1301-1400]: loss = 0.431522 * 100, metric = 6.09% * 100;
 Minibatch[1401-1500]: loss = 0.437411 * 100, metric = 6.33% * 100;
 Minibatch[1501-1600]: loss = 0.423604 * 100, metric = 5.96% * 100;
 Minibatch[1601-1700]: loss = 0.419376 * 100, metric = 5.82% * 100;
 Minibatch[1701-1800]: loss = 0.428498 * 100, metric = 5.98% * 100;
 Minibatch[1801-1900]: loss = 0.438830 * 100, metric = 6.28% * 100;
 Minibatch[1901-2000]: loss = 0.418197 * 100, metric = 5.65% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.434308 * 2000, metric = 6.12% * 2000 926.805s (  2.2 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 13.64% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
