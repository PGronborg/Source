Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.203469 * 100, metric = 24.03% * 100;
 Minibatch[ 101- 200]: loss = 1.020654 * 100, metric = 22.44% * 100;
 Minibatch[ 201- 300]: loss = 0.907066 * 100, metric = 21.73% * 100;
 Minibatch[ 301- 400]: loss = 0.912968 * 100, metric = 21.30% * 100;
 Minibatch[ 401- 500]: loss = 0.847419 * 100, metric = 20.17% * 100;
 Minibatch[ 501- 600]: loss = 0.827490 * 100, metric = 18.78% * 100;
 Minibatch[ 601- 700]: loss = 0.815277 * 100, metric = 18.62% * 100;
 Minibatch[ 701- 800]: loss = 0.746494 * 100, metric = 17.06% * 100;
 Minibatch[ 801- 900]: loss = 0.760549 * 100, metric = 17.18% * 100;
 Minibatch[ 901-1000]: loss = 0.763661 * 100, metric = 17.56% * 100;
 Minibatch[1001-1100]: loss = 0.748588 * 100, metric = 17.30% * 100;
 Minibatch[1101-1200]: loss = 0.723508 * 100, metric = 16.25% * 100;
 Minibatch[1201-1300]: loss = 0.727006 * 100, metric = 16.80% * 100;
 Minibatch[1301-1400]: loss = 0.695026 * 100, metric = 16.45% * 100;
 Minibatch[1401-1500]: loss = 0.700760 * 100, metric = 15.66% * 100;
 Minibatch[1501-1600]: loss = 0.683433 * 100, metric = 15.79% * 100;
 Minibatch[1601-1700]: loss = 0.671737 * 100, metric = 15.40% * 100;
 Minibatch[1701-1800]: loss = 0.673413 * 100, metric = 15.22% * 100;
 Minibatch[1801-1900]: loss = 0.684412 * 100, metric = 15.56% * 100;
 Minibatch[1901-2000]: loss = 0.666965 * 100, metric = 14.93% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.788995 * 2000, metric = 17.91% * 2000 1064.863s (  1.9 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 23.87% * 2000;
0.7316918787807226
 Minibatch[   1- 100]: loss = 0.653440 * 100, metric = 14.71% * 100;
 Minibatch[ 101- 200]: loss = 0.666330 * 100, metric = 15.16% * 100;
 Minibatch[ 201- 300]: loss = 0.651680 * 100, metric = 14.16% * 100;
 Minibatch[ 301- 400]: loss = 0.659247 * 100, metric = 14.67% * 100;
 Minibatch[ 401- 500]: loss = 0.657422 * 100, metric = 14.88% * 100;
 Minibatch[ 501- 600]: loss = 0.667036 * 100, metric = 14.37% * 100;
 Minibatch[ 601- 700]: loss = 0.632736 * 100, metric = 14.38% * 100;
 Minibatch[ 701- 800]: loss = 0.647947 * 100, metric = 14.70% * 100;
 Minibatch[ 801- 900]: loss = 0.637876 * 100, metric = 14.31% * 100;
 Minibatch[ 901-1000]: loss = 0.614214 * 100, metric = 13.75% * 100;
 Minibatch[1001-1100]: loss = 0.633498 * 100, metric = 14.39% * 100;
 Minibatch[1101-1200]: loss = 0.628637 * 100, metric = 14.07% * 100;
 Minibatch[1201-1300]: loss = 0.609355 * 100, metric = 13.74% * 100;
 Minibatch[1301-1400]: loss = 0.627485 * 100, metric = 13.99% * 100;
 Minibatch[1401-1500]: loss = 0.605685 * 100, metric = 13.18% * 100;
 Minibatch[1501-1600]: loss = 0.606168 * 100, metric = 13.43% * 100;
 Minibatch[1601-1700]: loss = 0.607309 * 100, metric = 13.75% * 100;
 Minibatch[1701-1800]: loss = 0.624346 * 100, metric = 14.26% * 100;
 Minibatch[1801-1900]: loss = 0.622378 * 100, metric = 13.93% * 100;
 Minibatch[1901-2000]: loss = 0.594281 * 100, metric = 13.51% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.632353 * 2000, metric = 14.17% * 2000 977.148s (  2.0 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 19.84% * 2000;
0.6384979792013764
 Minibatch[   1- 100]: loss = 0.604771 * 100, metric = 13.51% * 100;
 Minibatch[ 101- 200]: loss = 0.615012 * 100, metric = 14.07% * 100;
 Minibatch[ 201- 300]: loss = 0.595443 * 100, metric = 13.30% * 100;
 Minibatch[ 301- 400]: loss = 0.614013 * 100, metric = 14.00% * 100;
 Minibatch[ 401- 500]: loss = 0.615900 * 100, metric = 14.28% * 100;
 Minibatch[ 501- 600]: loss = 0.611611 * 100, metric = 13.78% * 100;
 Minibatch[ 601- 700]: loss = 0.610702 * 100, metric = 13.55% * 100;
 Minibatch[ 701- 800]: loss = 0.590019 * 100, metric = 12.79% * 100;
 Minibatch[ 801- 900]: loss = 0.618153 * 100, metric = 14.24% * 100;
 Minibatch[ 901-1000]: loss = 0.586734 * 100, metric = 13.36% * 100;
 Minibatch[1001-1100]: loss = 0.598771 * 100, metric = 13.74% * 100;
 Minibatch[1101-1200]: loss = 0.586196 * 100, metric = 13.39% * 100;
 Minibatch[1201-1300]: loss = 0.588127 * 100, metric = 13.29% * 100;
 Minibatch[1301-1400]: loss = 0.602068 * 100, metric = 13.41% * 100;
 Minibatch[1401-1500]: loss = 0.600858 * 100, metric = 13.52% * 100;
 Minibatch[1501-1600]: loss = 0.583143 * 100, metric = 13.25% * 100;
 Minibatch[1601-1700]: loss = 0.582502 * 100, metric = 12.96% * 100;
 Minibatch[1701-1800]: loss = 0.597280 * 100, metric = 13.50% * 100;
 Minibatch[1801-1900]: loss = 0.578309 * 100, metric = 12.71% * 100;
 Minibatch[1901-2000]: loss = 0.580298 * 100, metric = 13.01% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.597995 * 2000, metric = 13.48% * 2000 989.174s (  2.0 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 19.23% * 2000;
0.6332748589962721
 Minibatch[   1- 100]: loss = 0.595644 * 100, metric = 12.93% * 100;
 Minibatch[ 101- 200]: loss = 0.565339 * 100, metric = 12.61% * 100;
 Minibatch[ 201- 300]: loss = 0.582710 * 100, metric = 13.18% * 100;
 Minibatch[ 301- 400]: loss = 0.553094 * 100, metric = 12.27% * 100;
 Minibatch[ 401- 500]: loss = 0.586499 * 100, metric = 13.21% * 100;
 Minibatch[ 501- 600]: loss = 0.566101 * 100, metric = 12.73% * 100;
 Minibatch[ 601- 700]: loss = 0.573040 * 100, metric = 12.99% * 100;
 Minibatch[ 701- 800]: loss = 0.583398 * 100, metric = 13.23% * 100;
 Minibatch[ 801- 900]: loss = 0.583205 * 100, metric = 13.08% * 100;
 Minibatch[ 901-1000]: loss = 0.581989 * 100, metric = 13.30% * 100;
 Minibatch[1001-1100]: loss = 0.590405 * 100, metric = 13.43% * 100;
 Minibatch[1101-1200]: loss = 0.566195 * 100, metric = 12.78% * 100;
 Minibatch[1201-1300]: loss = 0.572293 * 100, metric = 12.65% * 100;
 Minibatch[1301-1400]: loss = 0.583045 * 100, metric = 13.06% * 100;
 Minibatch[1401-1500]: loss = 0.588098 * 100, metric = 13.25% * 100;
 Minibatch[1501-1600]: loss = 0.561558 * 100, metric = 12.59% * 100;
 Minibatch[1601-1700]: loss = 0.583118 * 100, metric = 13.33% * 100;
 Minibatch[1701-1800]: loss = 0.580295 * 100, metric = 13.20% * 100;
 Minibatch[1801-1900]: loss = 0.567567 * 100, metric = 12.57% * 100;
 Minibatch[1901-2000]: loss = 0.560483 * 100, metric = 12.55% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.576204 * 2000, metric = 12.95% * 2000 984.868s (  2.0 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 19.73% * 2000;
 Minibatch[   1- 100]: loss = 0.578382 * 100, metric = 12.86% * 100;
 Minibatch[ 101- 200]: loss = 0.564090 * 100, metric = 12.50% * 100;
 Minibatch[ 201- 300]: loss = 0.562979 * 100, metric = 12.59% * 100;
 Minibatch[ 301- 400]: loss = 0.595657 * 100, metric = 13.68% * 100;
 Minibatch[ 401- 500]: loss = 0.538750 * 100, metric = 11.82% * 100;
 Minibatch[ 501- 600]: loss = 0.551001 * 100, metric = 11.98% * 100;
 Minibatch[ 601- 700]: loss = 0.557707 * 100, metric = 12.09% * 100;
 Minibatch[ 701- 800]: loss = 0.570274 * 100, metric = 12.70% * 100;
 Minibatch[ 801- 900]: loss = 0.548291 * 100, metric = 11.94% * 100;
 Minibatch[ 901-1000]: loss = 0.537853 * 100, metric = 12.04% * 100;
 Minibatch[1001-1100]: loss = 0.557116 * 100, metric = 12.19% * 100;
 Minibatch[1101-1200]: loss = 0.533891 * 100, metric = 11.82% * 100;
 Minibatch[1201-1300]: loss = 0.556025 * 100, metric = 12.41% * 100;
 Minibatch[1301-1400]: loss = 0.567532 * 100, metric = 12.65% * 100;
 Minibatch[1401-1500]: loss = 0.547729 * 100, metric = 12.27% * 100;
 Minibatch[1501-1600]: loss = 0.553015 * 100, metric = 12.35% * 100;
 Minibatch[1601-1700]: loss = 0.565474 * 100, metric = 12.91% * 100;
 Minibatch[1701-1800]: loss = 0.562857 * 100, metric = 12.67% * 100;
 Minibatch[1801-1900]: loss = 0.566888 * 100, metric = 12.45% * 100;
 Minibatch[1901-2000]: loss = 0.538441 * 100, metric = 11.91% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.557698 * 2000, metric = 12.39% * 2000 998.860s (  2.0 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 21.31% * 2000;
 Minibatch[   1- 100]: loss = 0.533405 * 100, metric = 11.83% * 100;
 Minibatch[ 101- 200]: loss = 0.530735 * 100, metric = 11.99% * 100;
 Minibatch[ 201- 300]: loss = 0.546212 * 100, metric = 12.24% * 100;
 Minibatch[ 301- 400]: loss = 0.545970 * 100, metric = 11.88% * 100;
 Minibatch[ 401- 500]: loss = 0.521825 * 100, metric = 11.56% * 100;
 Minibatch[ 501- 600]: loss = 0.535729 * 100, metric = 11.82% * 100;
 Minibatch[ 601- 700]: loss = 0.531705 * 100, metric = 11.86% * 100;
 Minibatch[ 701- 800]: loss = 0.544153 * 100, metric = 12.02% * 100;
 Minibatch[ 801- 900]: loss = 0.543186 * 100, metric = 11.94% * 100;
 Minibatch[ 901-1000]: loss = 0.536524 * 100, metric = 11.95% * 100;
 Minibatch[1001-1100]: loss = 0.539459 * 100, metric = 11.90% * 100;
 Minibatch[1101-1200]: loss = 0.541322 * 100, metric = 11.89% * 100;
 Minibatch[1201-1300]: loss = 0.551120 * 100, metric = 12.23% * 100;
 Minibatch[1301-1400]: loss = 0.539142 * 100, metric = 11.89% * 100;
 Minibatch[1401-1500]: loss = 0.542804 * 100, metric = 12.01% * 100;
 Minibatch[1501-1600]: loss = 0.536926 * 100, metric = 12.04% * 100;
 Minibatch[1601-1700]: loss = 0.533573 * 100, metric = 11.55% * 100;
 Minibatch[1701-1800]: loss = 0.539819 * 100, metric = 11.91% * 100;
 Minibatch[1801-1900]: loss = 0.550886 * 100, metric = 12.37% * 100;
 Minibatch[1901-2000]: loss = 0.524351 * 100, metric = 11.67% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.538442 * 2000, metric = 11.93% * 2000 1005.019s (  2.0 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 21.68% * 2000;
 Minibatch[   1- 100]: loss = 0.529052 * 100, metric = 11.56% * 100;
 Minibatch[ 101- 200]: loss = 0.539244 * 100, metric = 11.68% * 100;
 Minibatch[ 201- 300]: loss = 0.543753 * 100, metric = 12.15% * 100;
 Minibatch[ 301- 400]: loss = 0.532445 * 100, metric = 11.74% * 100;
 Minibatch[ 401- 500]: loss = 0.539719 * 100, metric = 11.82% * 100;
 Minibatch[ 501- 600]: loss = 0.525295 * 100, metric = 11.54% * 100;
 Minibatch[ 601- 700]: loss = 0.534896 * 100, metric = 11.63% * 100;
 Minibatch[ 701- 800]: loss = 0.540959 * 100, metric = 11.86% * 100;
 Minibatch[ 801- 900]: loss = 0.545117 * 100, metric = 12.22% * 100;
 Minibatch[ 901-1000]: loss = 0.532661 * 100, metric = 12.06% * 100;
 Minibatch[1001-1100]: loss = 0.544977 * 100, metric = 12.13% * 100;
 Minibatch[1101-1200]: loss = 0.525689 * 100, metric = 11.96% * 100;
 Minibatch[1201-1300]: loss = 0.544207 * 100, metric = 12.43% * 100;
 Minibatch[1301-1400]: loss = 0.531116 * 100, metric = 11.94% * 100;
 Minibatch[1401-1500]: loss = 0.523557 * 100, metric = 11.48% * 100;
 Minibatch[1501-1600]: loss = 0.533125 * 100, metric = 11.88% * 100;
 Minibatch[1601-1700]: loss = 0.541771 * 100, metric = 12.26% * 100;
 Minibatch[1701-1800]: loss = 0.526910 * 100, metric = 11.72% * 100;
 Minibatch[1801-1900]: loss = 0.531879 * 100, metric = 12.01% * 100;
 Minibatch[1901-2000]: loss = 0.534778 * 100, metric = 12.05% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.535057 * 2000, metric = 11.91% * 2000 1016.126s (  2.0 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.90% * 2000;
0.6073406505063176
 Minibatch[   1- 100]: loss = 0.535875 * 100, metric = 12.00% * 100;
 Minibatch[ 101- 200]: loss = 0.527445 * 100, metric = 11.93% * 100;
 Minibatch[ 201- 300]: loss = 0.516029 * 100, metric = 11.32% * 100;
 Minibatch[ 301- 400]: loss = 0.519465 * 100, metric = 11.77% * 100;
 Minibatch[ 401- 500]: loss = 0.529135 * 100, metric = 12.04% * 100;
 Minibatch[ 501- 600]: loss = 0.543654 * 100, metric = 12.20% * 100;
 Minibatch[ 601- 700]: loss = 0.509163 * 100, metric = 11.25% * 100;
 Minibatch[ 701- 800]: loss = 0.526107 * 100, metric = 11.32% * 100;
 Minibatch[ 801- 900]: loss = 0.509626 * 100, metric = 11.04% * 100;
 Minibatch[ 901-1000]: loss = 0.495367 * 100, metric = 10.87% * 100;
 Minibatch[1001-1100]: loss = 0.509839 * 100, metric = 11.37% * 100;
 Minibatch[1101-1200]: loss = 0.505703 * 100, metric = 11.12% * 100;
 Minibatch[1201-1300]: loss = 0.525986 * 100, metric = 11.68% * 100;
 Minibatch[1301-1400]: loss = 0.531057 * 100, metric = 12.02% * 100;
 Minibatch[1401-1500]: loss = 0.518807 * 100, metric = 11.41% * 100;
 Minibatch[1501-1600]: loss = 0.524864 * 100, metric = 11.76% * 100;
 Minibatch[1601-1700]: loss = 0.519826 * 100, metric = 11.54% * 100;
 Minibatch[1701-1800]: loss = 0.511190 * 100, metric = 11.39% * 100;
 Minibatch[1801-1900]: loss = 0.508864 * 100, metric = 11.41% * 100;
 Minibatch[1901-2000]: loss = 0.517565 * 100, metric = 11.38% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.519278 * 2000, metric = 11.54% * 2000 1002.030s (  2.0 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 19.35% * 2000;
0.5980927248075605
 Minibatch[   1- 100]: loss = 0.496844 * 100, metric = 10.91% * 100;
 Minibatch[ 101- 200]: loss = 0.536284 * 100, metric = 11.88% * 100;
 Minibatch[ 201- 300]: loss = 0.522375 * 100, metric = 11.70% * 100;
 Minibatch[ 301- 400]: loss = 0.525949 * 100, metric = 11.70% * 100;
 Minibatch[ 401- 500]: loss = 0.509613 * 100, metric = 11.07% * 100;
 Minibatch[ 501- 600]: loss = 0.507622 * 100, metric = 11.21% * 100;
 Minibatch[ 601- 700]: loss = 0.500779 * 100, metric = 10.93% * 100;
 Minibatch[ 701- 800]: loss = 0.490687 * 100, metric = 10.62% * 100;
 Minibatch[ 801- 900]: loss = 0.494683 * 100, metric = 11.07% * 100;
 Minibatch[ 901-1000]: loss = 0.503786 * 100, metric = 11.25% * 100;
 Minibatch[1001-1100]: loss = 0.480154 * 100, metric = 10.44% * 100;
 Minibatch[1101-1200]: loss = 0.505358 * 100, metric = 11.24% * 100;
 Minibatch[1201-1300]: loss = 0.497324 * 100, metric = 11.13% * 100;
 Minibatch[1301-1400]: loss = 0.492426 * 100, metric = 10.79% * 100;
 Minibatch[1401-1500]: loss = 0.514107 * 100, metric = 11.50% * 100;
 Minibatch[1501-1600]: loss = 0.505034 * 100, metric = 11.08% * 100;
 Minibatch[1601-1700]: loss = 0.507221 * 100, metric = 11.37% * 100;
 Minibatch[1701-1800]: loss = 0.491129 * 100, metric = 10.70% * 100;
 Minibatch[1801-1900]: loss = 0.488439 * 100, metric = 10.61% * 100;
 Minibatch[1901-2000]: loss = 0.500822 * 100, metric = 11.10% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.503532 * 2000, metric = 11.12% * 2000 1009.646s (  2.0 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 17.13% * 2000;
0.5675949795097113
 Minibatch[   1- 100]: loss = 0.517085 * 100, metric = 11.90% * 100;
 Minibatch[ 101- 200]: loss = 0.483169 * 100, metric = 10.69% * 100;
 Minibatch[ 201- 300]: loss = 0.495317 * 100, metric = 11.19% * 100;
 Minibatch[ 301- 400]: loss = 0.483683 * 100, metric = 10.69% * 100;
 Minibatch[ 401- 500]: loss = 0.502196 * 100, metric = 11.20% * 100;
 Minibatch[ 501- 600]: loss = 0.478737 * 100, metric = 10.39% * 100;
 Minibatch[ 601- 700]: loss = 0.476807 * 100, metric = 10.46% * 100;
 Minibatch[ 701- 800]: loss = 0.477502 * 100, metric = 10.33% * 100;
 Minibatch[ 801- 900]: loss = 0.490635 * 100, metric = 10.97% * 100;
 Minibatch[ 901-1000]: loss = 0.490714 * 100, metric = 10.85% * 100;
 Minibatch[1001-1100]: loss = 0.496500 * 100, metric = 11.32% * 100;
 Minibatch[1101-1200]: loss = 0.493958 * 100, metric = 10.82% * 100;
 Minibatch[1201-1300]: loss = 0.488414 * 100, metric = 10.97% * 100;
 Minibatch[1301-1400]: loss = 0.481731 * 100, metric = 10.67% * 100;
 Minibatch[1401-1500]: loss = 0.468767 * 100, metric = 10.27% * 100;
 Minibatch[1501-1600]: loss = 0.475165 * 100, metric = 10.48% * 100;
 Minibatch[1601-1700]: loss = 0.474457 * 100, metric = 10.28% * 100;
 Minibatch[1701-1800]: loss = 0.493973 * 100, metric = 10.80% * 100;
 Minibatch[1801-1900]: loss = 0.491949 * 100, metric = 10.85% * 100;
 Minibatch[1901-2000]: loss = 0.477098 * 100, metric = 10.61% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.486893 * 2000, metric = 10.79% * 2000 1022.784s (  2.0 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 17.58% * 2000;
 Minibatch[   1- 100]: loss = 0.473090 * 100, metric = 10.31% * 100;
 Minibatch[ 101- 200]: loss = 0.482541 * 100, metric = 10.56% * 100;
 Minibatch[ 201- 300]: loss = 0.488796 * 100, metric = 10.99% * 100;
 Minibatch[ 301- 400]: loss = 0.479970 * 100, metric = 10.54% * 100;
 Minibatch[ 401- 500]: loss = 0.477183 * 100, metric = 10.80% * 100;
 Minibatch[ 501- 600]: loss = 0.486307 * 100, metric = 10.73% * 100;
 Minibatch[ 601- 700]: loss = 0.481116 * 100, metric = 10.53% * 100;
 Minibatch[ 701- 800]: loss = 0.489808 * 100, metric = 10.82% * 100;
 Minibatch[ 801- 900]: loss = 0.484706 * 100, metric = 10.54% * 100;
 Minibatch[ 901-1000]: loss = 0.486983 * 100, metric = 10.86% * 100;
 Minibatch[1001-1100]: loss = 0.482706 * 100, metric = 10.75% * 100;
 Minibatch[1101-1200]: loss = 0.486447 * 100, metric = 11.13% * 100;
 Minibatch[1201-1300]: loss = 0.476155 * 100, metric = 10.66% * 100;
 Minibatch[1301-1400]: loss = 0.466011 * 100, metric = 10.43% * 100;
 Minibatch[1401-1500]: loss = 0.485308 * 100, metric = 10.95% * 100;
 Minibatch[1501-1600]: loss = 0.472426 * 100, metric = 10.68% * 100;
 Minibatch[1601-1700]: loss = 0.472503 * 100, metric = 10.48% * 100;
 Minibatch[1701-1800]: loss = 0.488590 * 100, metric = 10.85% * 100;
 Minibatch[1801-1900]: loss = 0.471700 * 100, metric = 10.57% * 100;
 Minibatch[1901-2000]: loss = 0.473497 * 100, metric = 10.60% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.480292 * 2000, metric = 10.69% * 2000 1009.576s (  2.0 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 18.53% * 2000;
 Minibatch[   1- 100]: loss = 0.465321 * 100, metric = 10.21% * 100;
 Minibatch[ 101- 200]: loss = 0.465156 * 100, metric = 10.21% * 100;
 Minibatch[ 201- 300]: loss = 0.467788 * 100, metric = 10.55% * 100;
 Minibatch[ 301- 400]: loss = 0.491809 * 100, metric = 11.31% * 100;
 Minibatch[ 401- 500]: loss = 0.465456 * 100, metric = 10.37% * 100;
 Minibatch[ 501- 600]: loss = 0.465960 * 100, metric = 10.22% * 100;
 Minibatch[ 601- 700]: loss = 0.466805 * 100, metric = 10.46% * 100;
 Minibatch[ 701- 800]: loss = 0.469557 * 100, metric = 10.54% * 100;
 Minibatch[ 801- 900]: loss = 0.462841 * 100, metric = 10.18% * 100;
 Minibatch[ 901-1000]: loss = 0.479877 * 100, metric = 10.84% * 100;
 Minibatch[1001-1100]: loss = 0.475460 * 100, metric = 10.71% * 100;
 Minibatch[1101-1200]: loss = 0.470101 * 100, metric = 10.51% * 100;
 Minibatch[1201-1300]: loss = 0.471523 * 100, metric = 10.71% * 100;
 Minibatch[1301-1400]: loss = 0.458553 * 100, metric = 10.06% * 100;
 Minibatch[1401-1500]: loss = 0.476558 * 100, metric = 10.70% * 100;
 Minibatch[1501-1600]: loss = 0.451528 * 100, metric = 9.95% * 100;
 Minibatch[1601-1700]: loss = 0.470846 * 100, metric = 10.62% * 100;
 Minibatch[1701-1800]: loss = 0.460630 * 100, metric = 10.06% * 100;
 Minibatch[1801-1900]: loss = 0.464253 * 100, metric = 10.38% * 100;
 Minibatch[1901-2000]: loss = 0.479016 * 100, metric = 10.82% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.468952 * 2000, metric = 10.47% * 2000 1023.838s (  2.0 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 19.21% * 2000;
 Minibatch[   1- 100]: loss = 0.465824 * 100, metric = 10.41% * 100;
 Minibatch[ 101- 200]: loss = 0.464218 * 100, metric = 10.30% * 100;
 Minibatch[ 201- 300]: loss = 0.455150 * 100, metric = 10.32% * 100;
 Minibatch[ 301- 400]: loss = 0.474505 * 100, metric = 10.68% * 100;
 Minibatch[ 401- 500]: loss = 0.472078 * 100, metric = 11.04% * 100;
 Minibatch[ 501- 600]: loss = 0.481572 * 100, metric = 10.91% * 100;
 Minibatch[ 601- 700]: loss = 0.451149 * 100, metric = 10.03% * 100;
 Minibatch[ 701- 800]: loss = 0.454017 * 100, metric = 10.06% * 100;
 Minibatch[ 801- 900]: loss = 0.454941 * 100, metric = 10.03% * 100;
 Minibatch[ 901-1000]: loss = 0.475067 * 100, metric = 10.45% * 100;
 Minibatch[1001-1100]: loss = 0.477611 * 100, metric = 10.96% * 100;
 Minibatch[1101-1200]: loss = 0.460709 * 100, metric = 10.46% * 100;
 Minibatch[1201-1300]: loss = 0.466372 * 100, metric = 10.45% * 100;
 Minibatch[1301-1400]: loss = 0.456199 * 100, metric = 10.19% * 100;
 Minibatch[1401-1500]: loss = 0.455222 * 100, metric = 10.06% * 100;
 Minibatch[1501-1600]: loss = 0.440168 * 100, metric = 9.84% * 100;
 Minibatch[1601-1700]: loss = 0.437539 * 100, metric = 9.79% * 100;
 Minibatch[1701-1800]: loss = 0.457164 * 100, metric = 10.06% * 100;
 Minibatch[1801-1900]: loss = 0.450530 * 100, metric = 10.00% * 100;
 Minibatch[1901-2000]: loss = 0.459157 * 100, metric = 10.45% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.460460 * 2000, metric = 10.32% * 2000 1017.289s (  2.0 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 19.80% * 2000;
 Minibatch[   1- 100]: loss = 0.443888 * 100, metric = 9.79% * 100;
 Minibatch[ 101- 200]: loss = 0.438779 * 100, metric = 9.64% * 100;
 Minibatch[ 201- 300]: loss = 0.454347 * 100, metric = 10.46% * 100;
 Minibatch[ 301- 400]: loss = 0.443176 * 100, metric = 9.97% * 100;
 Minibatch[ 401- 500]: loss = 0.443204 * 100, metric = 9.75% * 100;
 Minibatch[ 501- 600]: loss = 0.446579 * 100, metric = 9.86% * 100;
 Minibatch[ 601- 700]: loss = 0.442566 * 100, metric = 9.89% * 100;
 Minibatch[ 701- 800]: loss = 0.450048 * 100, metric = 10.04% * 100;
 Minibatch[ 801- 900]: loss = 0.454602 * 100, metric = 10.32% * 100;
 Minibatch[ 901-1000]: loss = 0.454656 * 100, metric = 10.24% * 100;
 Minibatch[1001-1100]: loss = 0.445516 * 100, metric = 10.00% * 100;
 Minibatch[1101-1200]: loss = 0.433915 * 100, metric = 9.59% * 100;
 Minibatch[1201-1300]: loss = 0.429034 * 100, metric = 9.38% * 100;
 Minibatch[1301-1400]: loss = 0.442759 * 100, metric = 10.15% * 100;
 Minibatch[1401-1500]: loss = 0.439697 * 100, metric = 9.88% * 100;
 Minibatch[1501-1600]: loss = 0.427578 * 100, metric = 9.63% * 100;
 Minibatch[1601-1700]: loss = 0.439422 * 100, metric = 9.79% * 100;
 Minibatch[1701-1800]: loss = 0.438819 * 100, metric = 9.98% * 100;
 Minibatch[1801-1900]: loss = 0.445288 * 100, metric = 9.97% * 100;
 Minibatch[1901-2000]: loss = 0.444504 * 100, metric = 10.04% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.442919 * 2000, metric = 9.92% * 2000 995.345s (  2.0 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 19.45% * 2000;
 Minibatch[   1- 100]: loss = 0.435654 * 100, metric = 9.78% * 100;
 Minibatch[ 101- 200]: loss = 0.441046 * 100, metric = 9.74% * 100;
 Minibatch[ 201- 300]: loss = 0.443825 * 100, metric = 9.94% * 100;
 Minibatch[ 301- 400]: loss = 0.426046 * 100, metric = 9.47% * 100;
 Minibatch[ 401- 500]: loss = 0.436170 * 100, metric = 9.65% * 100;
 Minibatch[ 501- 600]: loss = 0.434153 * 100, metric = 9.55% * 100;
 Minibatch[ 601- 700]: loss = 0.420677 * 100, metric = 9.29% * 100;
 Minibatch[ 701- 800]: loss = 0.444213 * 100, metric = 9.95% * 100;
 Minibatch[ 801- 900]: loss = 0.443287 * 100, metric = 10.28% * 100;
 Minibatch[ 901-1000]: loss = 0.437386 * 100, metric = 9.96% * 100;
 Minibatch[1001-1100]: loss = 0.448142 * 100, metric = 9.93% * 100;
 Minibatch[1101-1200]: loss = 0.436223 * 100, metric = 9.78% * 100;
 Minibatch[1201-1300]: loss = 0.423987 * 100, metric = 9.34% * 100;
 Minibatch[1301-1400]: loss = 0.451160 * 100, metric = 10.20% * 100;
 Minibatch[1401-1500]: loss = 0.412700 * 100, metric = 9.21% * 100;
 Minibatch[1501-1600]: loss = 0.421332 * 100, metric = 9.40% * 100;
 Minibatch[1601-1700]: loss = 0.436702 * 100, metric = 9.67% * 100;
 Minibatch[1701-1800]: loss = 0.421360 * 100, metric = 9.22% * 100;
 Minibatch[1801-1900]: loss = 0.425457 * 100, metric = 9.56% * 100;
 Minibatch[1901-2000]: loss = 0.426927 * 100, metric = 9.69% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.433322 * 2000, metric = 9.68% * 2000 1018.773s (  2.0 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 17.56% * 2000;
0.5569175403118134
 Minibatch[   1- 100]: loss = 0.445553 * 100, metric = 10.25% * 100;
 Minibatch[ 101- 200]: loss = 0.435367 * 100, metric = 9.61% * 100;
 Minibatch[ 201- 300]: loss = 0.441669 * 100, metric = 9.79% * 100;
 Minibatch[ 301- 400]: loss = 0.433454 * 100, metric = 9.60% * 100;
 Minibatch[ 401- 500]: loss = 0.411097 * 100, metric = 9.01% * 100;
 Minibatch[ 501- 600]: loss = 0.436821 * 100, metric = 9.78% * 100;
 Minibatch[ 601- 700]: loss = 0.428117 * 100, metric = 9.59% * 100;
 Minibatch[ 701- 800]: loss = 0.417436 * 100, metric = 9.17% * 100;
 Minibatch[ 801- 900]: loss = 0.411097 * 100, metric = 9.24% * 100;
 Minibatch[ 901-1000]: loss = 0.425226 * 100, metric = 9.59% * 100;
 Minibatch[1001-1100]: loss = 0.412251 * 100, metric = 9.36% * 100;
 Minibatch[1101-1200]: loss = 0.416461 * 100, metric = 9.10% * 100;
 Minibatch[1201-1300]: loss = 0.411093 * 100, metric = 9.05% * 100;
 Minibatch[1301-1400]: loss = 0.411352 * 100, metric = 9.05% * 100;
 Minibatch[1401-1500]: loss = 0.413041 * 100, metric = 9.40% * 100;
 Minibatch[1501-1600]: loss = 0.412339 * 100, metric = 9.25% * 100;
 Minibatch[1601-1700]: loss = 0.423381 * 100, metric = 9.40% * 100;
 Minibatch[1701-1800]: loss = 0.431019 * 100, metric = 9.74% * 100;
 Minibatch[1801-1900]: loss = 0.427001 * 100, metric = 9.58% * 100;
 Minibatch[1901-2000]: loss = 0.406934 * 100, metric = 9.11% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.422535 * 2000, metric = 9.43% * 2000 1004.159s (  2.0 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 17.18% * 2000;
 Minibatch[   1- 100]: loss = 0.409919 * 100, metric = 9.20% * 100;
 Minibatch[ 101- 200]: loss = 0.433358 * 100, metric = 9.80% * 100;
 Minibatch[ 201- 300]: loss = 0.422803 * 100, metric = 9.39% * 100;
 Minibatch[ 301- 400]: loss = 0.414233 * 100, metric = 9.47% * 100;
 Minibatch[ 401- 500]: loss = 0.418758 * 100, metric = 9.18% * 100;
 Minibatch[ 501- 600]: loss = 0.419856 * 100, metric = 9.27% * 100;
 Minibatch[ 601- 700]: loss = 0.395080 * 100, metric = 8.70% * 100;
 Minibatch[ 701- 800]: loss = 0.411063 * 100, metric = 9.09% * 100;
 Minibatch[ 801- 900]: loss = 0.417189 * 100, metric = 9.15% * 100;
 Minibatch[ 901-1000]: loss = 0.404528 * 100, metric = 8.93% * 100;
 Minibatch[1001-1100]: loss = 0.404908 * 100, metric = 9.00% * 100;
 Minibatch[1101-1200]: loss = 0.425422 * 100, metric = 9.51% * 100;
 Minibatch[1201-1300]: loss = 0.415740 * 100, metric = 9.30% * 100;
 Minibatch[1301-1400]: loss = 0.407006 * 100, metric = 9.03% * 100;
 Minibatch[1401-1500]: loss = 0.414539 * 100, metric = 9.57% * 100;
 Minibatch[1501-1600]: loss = 0.419507 * 100, metric = 9.35% * 100;
 Minibatch[1601-1700]: loss = 0.413884 * 100, metric = 9.19% * 100;
 Minibatch[1701-1800]: loss = 0.399044 * 100, metric = 8.78% * 100;
 Minibatch[1801-1900]: loss = 0.423977 * 100, metric = 9.68% * 100;
 Minibatch[1901-2000]: loss = 0.427664 * 100, metric = 9.78% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.414924 * 2000, metric = 9.27% * 2000 1011.498s (  2.0 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 17.62% * 2000;
 Minibatch[   1- 100]: loss = 0.402564 * 100, metric = 8.78% * 100;
 Minibatch[ 101- 200]: loss = 0.422954 * 100, metric = 9.38% * 100;
 Minibatch[ 201- 300]: loss = 0.397370 * 100, metric = 8.96% * 100;
 Minibatch[ 301- 400]: loss = 0.405499 * 100, metric = 8.99% * 100;
 Minibatch[ 401- 500]: loss = 0.394726 * 100, metric = 8.69% * 100;
 Minibatch[ 501- 600]: loss = 0.401935 * 100, metric = 8.89% * 100;
 Minibatch[ 601- 700]: loss = 0.407553 * 100, metric = 9.19% * 100;
 Minibatch[ 701- 800]: loss = 0.400215 * 100, metric = 8.85% * 100;
 Minibatch[ 801- 900]: loss = 0.406612 * 100, metric = 9.09% * 100;
 Minibatch[ 901-1000]: loss = 0.406105 * 100, metric = 9.03% * 100;
 Minibatch[1001-1100]: loss = 0.419621 * 100, metric = 9.67% * 100;
 Minibatch[1101-1200]: loss = 0.414133 * 100, metric = 9.14% * 100;
 Minibatch[1201-1300]: loss = 0.420250 * 100, metric = 9.58% * 100;
 Minibatch[1301-1400]: loss = 0.423032 * 100, metric = 9.36% * 100;
 Minibatch[1401-1500]: loss = 0.392417 * 100, metric = 8.76% * 100;
 Minibatch[1501-1600]: loss = 0.406202 * 100, metric = 9.01% * 100;
 Minibatch[1601-1700]: loss = 0.391198 * 100, metric = 8.69% * 100;
 Minibatch[1701-1800]: loss = 0.403192 * 100, metric = 8.95% * 100;
 Minibatch[1801-1900]: loss = 0.389975 * 100, metric = 8.66% * 100;
 Minibatch[1901-2000]: loss = 0.400074 * 100, metric = 8.92% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.405281 * 2000, metric = 9.03% * 2000 971.145s (  2.1 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 18.72% * 2000;
 Minibatch[   1- 100]: loss = 0.411294 * 100, metric = 9.46% * 100;
 Minibatch[ 101- 200]: loss = 0.420352 * 100, metric = 9.57% * 100;
 Minibatch[ 201- 300]: loss = 0.392875 * 100, metric = 8.72% * 100;
 Minibatch[ 301- 400]: loss = 0.406585 * 100, metric = 8.96% * 100;
 Minibatch[ 401- 500]: loss = 0.401724 * 100, metric = 8.79% * 100;
 Minibatch[ 501- 600]: loss = 0.395892 * 100, metric = 8.76% * 100;
 Minibatch[ 601- 700]: loss = 0.411127 * 100, metric = 9.22% * 100;
 Minibatch[ 701- 800]: loss = 0.392437 * 100, metric = 8.64% * 100;
 Minibatch[ 801- 900]: loss = 0.426932 * 100, metric = 9.52% * 100;
 Minibatch[ 901-1000]: loss = 0.397878 * 100, metric = 8.88% * 100;
 Minibatch[1001-1100]: loss = 0.408671 * 100, metric = 9.03% * 100;
 Minibatch[1101-1200]: loss = 0.396211 * 100, metric = 8.97% * 100;
 Minibatch[1201-1300]: loss = 0.401850 * 100, metric = 9.07% * 100;
 Minibatch[1301-1400]: loss = 0.398978 * 100, metric = 8.87% * 100;
 Minibatch[1401-1500]: loss = 0.411230 * 100, metric = 9.47% * 100;
 Minibatch[1501-1600]: loss = 0.410745 * 100, metric = 9.37% * 100;
 Minibatch[1601-1700]: loss = 0.389034 * 100, metric = 8.64% * 100;
 Minibatch[1701-1800]: loss = 0.383181 * 100, metric = 8.56% * 100;
 Minibatch[1801-1900]: loss = 0.389590 * 100, metric = 8.78% * 100;
 Minibatch[1901-2000]: loss = 0.386808 * 100, metric = 8.56% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.401670 * 2000, metric = 8.99% * 2000 993.549s (  2.0 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 17.98% * 2000;
 Minibatch[   1- 100]: loss = 0.391292 * 100, metric = 8.64% * 100;
 Minibatch[ 101- 200]: loss = 0.391575 * 100, metric = 8.96% * 100;
 Minibatch[ 201- 300]: loss = 0.390349 * 100, metric = 8.54% * 100;
 Minibatch[ 301- 400]: loss = 0.406699 * 100, metric = 8.97% * 100;
 Minibatch[ 401- 500]: loss = 0.386160 * 100, metric = 8.59% * 100;
 Minibatch[ 501- 600]: loss = 0.397849 * 100, metric = 8.96% * 100;
 Minibatch[ 601- 700]: loss = 0.402568 * 100, metric = 9.17% * 100;
 Minibatch[ 701- 800]: loss = 0.395581 * 100, metric = 8.85% * 100;
 Minibatch[ 801- 900]: loss = 0.405714 * 100, metric = 9.17% * 100;
 Minibatch[ 901-1000]: loss = 0.403127 * 100, metric = 9.27% * 100;
 Minibatch[1001-1100]: loss = 0.382524 * 100, metric = 8.42% * 100;
 Minibatch[1101-1200]: loss = 0.392822 * 100, metric = 8.83% * 100;
 Minibatch[1201-1300]: loss = 0.394388 * 100, metric = 8.87% * 100;
 Minibatch[1301-1400]: loss = 0.397761 * 100, metric = 8.88% * 100;
 Minibatch[1401-1500]: loss = 0.394966 * 100, metric = 9.05% * 100;
 Minibatch[1501-1600]: loss = 0.414102 * 100, metric = 9.37% * 100;
 Minibatch[1601-1700]: loss = 0.394676 * 100, metric = 8.83% * 100;
 Minibatch[1701-1800]: loss = 0.404185 * 100, metric = 9.52% * 100;
 Minibatch[1801-1900]: loss = 0.400763 * 100, metric = 9.00% * 100;
 Minibatch[1901-2000]: loss = 0.389517 * 100, metric = 8.90% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.396831 * 2000, metric = 8.94% * 2000 993.492s (  2.0 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 17.15% * 2000;
0.5558019100949169
 Minibatch[   1- 100]: loss = 0.399858 * 100, metric = 9.07% * 100;
 Minibatch[ 101- 200]: loss = 0.390120 * 100, metric = 8.72% * 100;
 Minibatch[ 201- 300]: loss = 0.390338 * 100, metric = 8.87% * 100;
 Minibatch[ 301- 400]: loss = 0.390204 * 100, metric = 8.72% * 100;
 Minibatch[ 401- 500]: loss = 0.380070 * 100, metric = 8.62% * 100;
 Minibatch[ 501- 600]: loss = 0.378456 * 100, metric = 8.34% * 100;
 Minibatch[ 601- 700]: loss = 0.379301 * 100, metric = 8.46% * 100;
 Minibatch[ 701- 800]: loss = 0.366113 * 100, metric = 8.05% * 100;
 Minibatch[ 801- 900]: loss = 0.391014 * 100, metric = 8.67% * 100;
 Minibatch[ 901-1000]: loss = 0.378356 * 100, metric = 8.43% * 100;
 Minibatch[1001-1100]: loss = 0.380645 * 100, metric = 8.61% * 100;
 Minibatch[1101-1200]: loss = 0.380485 * 100, metric = 8.53% * 100;
 Minibatch[1201-1300]: loss = 0.390629 * 100, metric = 8.75% * 100;
 Minibatch[1301-1400]: loss = 0.376532 * 100, metric = 8.42% * 100;
 Minibatch[1401-1500]: loss = 0.384271 * 100, metric = 8.56% * 100;
 Minibatch[1501-1600]: loss = 0.394474 * 100, metric = 9.10% * 100;
 Minibatch[1601-1700]: loss = 0.379427 * 100, metric = 8.68% * 100;
 Minibatch[1701-1800]: loss = 0.376823 * 100, metric = 8.53% * 100;
 Minibatch[1801-1900]: loss = 0.396337 * 100, metric = 9.09% * 100;
 Minibatch[1901-2000]: loss = 0.368715 * 100, metric = 8.20% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.383608 * 2000, metric = 8.62% * 2000 999.980s (  2.0 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 16.50% * 2000;
0.5302858789935708
 Minibatch[   1- 100]: loss = 0.398280 * 100, metric = 8.99% * 100;
 Minibatch[ 101- 200]: loss = 0.388958 * 100, metric = 8.47% * 100;
 Minibatch[ 201- 300]: loss = 0.384305 * 100, metric = 8.67% * 100;
 Minibatch[ 301- 400]: loss = 0.379521 * 100, metric = 8.62% * 100;
 Minibatch[ 401- 500]: loss = 0.378939 * 100, metric = 8.46% * 100;
 Minibatch[ 501- 600]: loss = 0.392752 * 100, metric = 8.89% * 100;
 Minibatch[ 601- 700]: loss = 0.377403 * 100, metric = 8.37% * 100;
 Minibatch[ 701- 800]: loss = 0.370603 * 100, metric = 8.21% * 100;
 Minibatch[ 801- 900]: loss = 0.377253 * 100, metric = 8.49% * 100;
 Minibatch[ 901-1000]: loss = 0.391851 * 100, metric = 8.83% * 100;
 Minibatch[1001-1100]: loss = 0.368243 * 100, metric = 8.09% * 100;
 Minibatch[1101-1200]: loss = 0.348542 * 100, metric = 7.56% * 100;
 Minibatch[1201-1300]: loss = 0.380370 * 100, metric = 8.45% * 100;
 Minibatch[1301-1400]: loss = 0.378179 * 100, metric = 8.62% * 100;
 Minibatch[1401-1500]: loss = 0.376672 * 100, metric = 8.39% * 100;
 Minibatch[1501-1600]: loss = 0.360137 * 100, metric = 8.02% * 100;
 Minibatch[1601-1700]: loss = 0.370097 * 100, metric = 8.30% * 100;
 Minibatch[1701-1800]: loss = 0.369294 * 100, metric = 8.20% * 100;
 Minibatch[1801-1900]: loss = 0.367838 * 100, metric = 8.26% * 100;
 Minibatch[1901-2000]: loss = 0.372982 * 100, metric = 8.20% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.376611 * 2000, metric = 8.40% * 2000 969.861s (  2.1 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 17.14% * 2000;
 Minibatch[   1- 100]: loss = 0.379902 * 100, metric = 8.42% * 100;
 Minibatch[ 101- 200]: loss = 0.380903 * 100, metric = 8.78% * 100;
 Minibatch[ 201- 300]: loss = 0.376266 * 100, metric = 8.49% * 100;
 Minibatch[ 301- 400]: loss = 0.383651 * 100, metric = 8.46% * 100;
 Minibatch[ 401- 500]: loss = 0.390053 * 100, metric = 8.82% * 100;
 Minibatch[ 501- 600]: loss = 0.373448 * 100, metric = 8.50% * 100;
 Minibatch[ 601- 700]: loss = 0.367757 * 100, metric = 8.24% * 100;
 Minibatch[ 701- 800]: loss = 0.357143 * 100, metric = 7.76% * 100;
 Minibatch[ 801- 900]: loss = 0.363270 * 100, metric = 8.19% * 100;
 Minibatch[ 901-1000]: loss = 0.382557 * 100, metric = 8.53% * 100;
 Minibatch[1001-1100]: loss = 0.370584 * 100, metric = 8.12% * 100;
 Minibatch[1101-1200]: loss = 0.377593 * 100, metric = 8.47% * 100;
 Minibatch[1201-1300]: loss = 0.379745 * 100, metric = 8.68% * 100;
 Minibatch[1301-1400]: loss = 0.385261 * 100, metric = 8.92% * 100;
 Minibatch[1401-1500]: loss = 0.365240 * 100, metric = 8.17% * 100;
 Minibatch[1501-1600]: loss = 0.377438 * 100, metric = 8.36% * 100;
 Minibatch[1601-1700]: loss = 0.365975 * 100, metric = 8.26% * 100;
 Minibatch[1701-1800]: loss = 0.371581 * 100, metric = 8.35% * 100;
 Minibatch[1801-1900]: loss = 0.373801 * 100, metric = 8.49% * 100;
 Minibatch[1901-2000]: loss = 0.377684 * 100, metric = 8.34% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.374993 * 2000, metric = 8.42% * 2000 984.828s (  2.0 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 16.82% * 2000;
 Minibatch[   1- 100]: loss = 0.352880 * 100, metric = 7.78% * 100;
 Minibatch[ 101- 200]: loss = 0.374264 * 100, metric = 8.47% * 100;
 Minibatch[ 201- 300]: loss = 0.361606 * 100, metric = 8.01% * 100;
 Minibatch[ 301- 400]: loss = 0.366204 * 100, metric = 8.26% * 100;
 Minibatch[ 401- 500]: loss = 0.370002 * 100, metric = 8.34% * 100;
 Minibatch[ 501- 600]: loss = 0.356114 * 100, metric = 7.92% * 100;
 Minibatch[ 601- 700]: loss = 0.371107 * 100, metric = 8.20% * 100;
 Minibatch[ 701- 800]: loss = 0.361697 * 100, metric = 8.07% * 100;
 Minibatch[ 801- 900]: loss = 0.377824 * 100, metric = 8.54% * 100;
 Minibatch[ 901-1000]: loss = 0.363994 * 100, metric = 8.12% * 100;
 Minibatch[1001-1100]: loss = 0.366393 * 100, metric = 8.14% * 100;
 Minibatch[1101-1200]: loss = 0.375631 * 100, metric = 8.36% * 100;
 Minibatch[1201-1300]: loss = 0.370546 * 100, metric = 8.47% * 100;
 Minibatch[1301-1400]: loss = 0.367184 * 100, metric = 8.22% * 100;
 Minibatch[1401-1500]: loss = 0.362734 * 100, metric = 8.21% * 100;
 Minibatch[1501-1600]: loss = 0.372648 * 100, metric = 8.52% * 100;
 Minibatch[1601-1700]: loss = 0.360008 * 100, metric = 8.07% * 100;
 Minibatch[1701-1800]: loss = 0.360359 * 100, metric = 8.12% * 100;
 Minibatch[1801-1900]: loss = 0.364499 * 100, metric = 8.16% * 100;
 Minibatch[1901-2000]: loss = 0.362279 * 100, metric = 8.21% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.365899 * 2000, metric = 8.21% * 2000 1006.051s (  2.0 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 16.68% * 2000;
 Minibatch[   1- 100]: loss = 0.368355 * 100, metric = 8.26% * 100;
 Minibatch[ 101- 200]: loss = 0.367589 * 100, metric = 8.44% * 100;
 Minibatch[ 201- 300]: loss = 0.367047 * 100, metric = 8.42% * 100;
 Minibatch[ 301- 400]: loss = 0.376147 * 100, metric = 8.45% * 100;
 Minibatch[ 401- 500]: loss = 0.363417 * 100, metric = 8.10% * 100;
 Minibatch[ 501- 600]: loss = 0.366344 * 100, metric = 8.25% * 100;
 Minibatch[ 601- 700]: loss = 0.364834 * 100, metric = 8.09% * 100;
 Minibatch[ 701- 800]: loss = 0.356830 * 100, metric = 7.88% * 100;
 Minibatch[ 801- 900]: loss = 0.348752 * 100, metric = 7.84% * 100;
 Minibatch[ 901-1000]: loss = 0.366702 * 100, metric = 8.21% * 100;
 Minibatch[1001-1100]: loss = 0.361949 * 100, metric = 8.13% * 100;
 Minibatch[1101-1200]: loss = 0.374264 * 100, metric = 8.36% * 100;
 Minibatch[1201-1300]: loss = 0.383821 * 100, metric = 8.61% * 100;
 Minibatch[1301-1400]: loss = 0.367711 * 100, metric = 8.27% * 100;
 Minibatch[1401-1500]: loss = 0.348557 * 100, metric = 7.62% * 100;
 Minibatch[1501-1600]: loss = 0.375256 * 100, metric = 8.57% * 100;
 Minibatch[1601-1700]: loss = 0.352319 * 100, metric = 7.97% * 100;
 Minibatch[1701-1800]: loss = 0.360710 * 100, metric = 8.09% * 100;
 Minibatch[1801-1900]: loss = 0.349859 * 100, metric = 7.80% * 100;
 Minibatch[1901-2000]: loss = 0.342863 * 100, metric = 7.55% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.363166 * 2000, metric = 8.15% * 2000 963.674s (  2.1 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 16.81% * 2000;
 Minibatch[   1- 100]: loss = 0.354448 * 100, metric = 7.79% * 100;
 Minibatch[ 101- 200]: loss = 0.342666 * 100, metric = 7.62% * 100;
 Minibatch[ 201- 300]: loss = 0.364581 * 100, metric = 8.32% * 100;
 Minibatch[ 301- 400]: loss = 0.348399 * 100, metric = 7.63% * 100;
 Minibatch[ 401- 500]: loss = 0.354413 * 100, metric = 7.92% * 100;
 Minibatch[ 501- 600]: loss = 0.351558 * 100, metric = 7.82% * 100;
 Minibatch[ 601- 700]: loss = 0.372203 * 100, metric = 8.36% * 100;
 Minibatch[ 701- 800]: loss = 0.354958 * 100, metric = 8.08% * 100;
 Minibatch[ 801- 900]: loss = 0.352560 * 100, metric = 7.76% * 100;
 Minibatch[ 901-1000]: loss = 0.353569 * 100, metric = 7.82% * 100;
 Minibatch[1001-1100]: loss = 0.361828 * 100, metric = 8.29% * 100;
 Minibatch[1101-1200]: loss = 0.371745 * 100, metric = 8.39% * 100;
 Minibatch[1201-1300]: loss = 0.347101 * 100, metric = 7.76% * 100;
 Minibatch[1301-1400]: loss = 0.339455 * 100, metric = 7.43% * 100;
 Minibatch[1401-1500]: loss = 0.351191 * 100, metric = 7.79% * 100;
 Minibatch[1501-1600]: loss = 0.339893 * 100, metric = 7.42% * 100;
 Minibatch[1601-1700]: loss = 0.367382 * 100, metric = 8.30% * 100;
 Minibatch[1701-1800]: loss = 0.358962 * 100, metric = 8.01% * 100;
 Minibatch[1801-1900]: loss = 0.350933 * 100, metric = 7.68% * 100;
 Minibatch[1901-2000]: loss = 0.353340 * 100, metric = 7.78% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.354559 * 2000, metric = 7.90% * 2000 947.400s (  2.1 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 17.18% * 2000;
 Minibatch[   1- 100]: loss = 0.355283 * 100, metric = 7.74% * 100;
 Minibatch[ 101- 200]: loss = 0.363747 * 100, metric = 7.95% * 100;
 Minibatch[ 201- 300]: loss = 0.354728 * 100, metric = 7.88% * 100;
 Minibatch[ 301- 400]: loss = 0.344863 * 100, metric = 7.68% * 100;
 Minibatch[ 401- 500]: loss = 0.349845 * 100, metric = 7.80% * 100;
 Minibatch[ 501- 600]: loss = 0.351231 * 100, metric = 7.85% * 100;
 Minibatch[ 601- 700]: loss = 0.338904 * 100, metric = 7.60% * 100;
 Minibatch[ 701- 800]: loss = 0.351315 * 100, metric = 8.00% * 100;
 Minibatch[ 801- 900]: loss = 0.357893 * 100, metric = 8.03% * 100;
 Minibatch[ 901-1000]: loss = 0.354767 * 100, metric = 8.00% * 100;
 Minibatch[1001-1100]: loss = 0.344654 * 100, metric = 7.55% * 100;
 Minibatch[1101-1200]: loss = 0.366132 * 100, metric = 8.12% * 100;
 Minibatch[1201-1300]: loss = 0.352589 * 100, metric = 7.96% * 100;
 Minibatch[1301-1400]: loss = 0.362951 * 100, metric = 8.19% * 100;
 Minibatch[1401-1500]: loss = 0.345536 * 100, metric = 7.53% * 100;
 Minibatch[1501-1600]: loss = 0.348227 * 100, metric = 7.64% * 100;
 Minibatch[1601-1700]: loss = 0.340785 * 100, metric = 7.39% * 100;
 Minibatch[1701-1800]: loss = 0.351302 * 100, metric = 7.61% * 100;
 Minibatch[1801-1900]: loss = 0.344191 * 100, metric = 7.53% * 100;
 Minibatch[1901-2000]: loss = 0.347002 * 100, metric = 7.60% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.351297 * 2000, metric = 7.78% * 2000 982.763s (  2.0 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 16.24% * 2000;
 Minibatch[   1- 100]: loss = 0.355805 * 100, metric = 8.04% * 100;
 Minibatch[ 101- 200]: loss = 0.342909 * 100, metric = 7.48% * 100;
 Minibatch[ 201- 300]: loss = 0.360849 * 100, metric = 8.04% * 100;
 Minibatch[ 301- 400]: loss = 0.354893 * 100, metric = 7.79% * 100;
 Minibatch[ 401- 500]: loss = 0.353461 * 100, metric = 8.10% * 100;
 Minibatch[ 501- 600]: loss = 0.363489 * 100, metric = 8.30% * 100;
 Minibatch[ 601- 700]: loss = 0.342215 * 100, metric = 7.41% * 100;
 Minibatch[ 701- 800]: loss = 0.333562 * 100, metric = 7.21% * 100;
 Minibatch[ 801- 900]: loss = 0.353716 * 100, metric = 7.92% * 100;
 Minibatch[ 901-1000]: loss = 0.356243 * 100, metric = 8.08% * 100;
 Minibatch[1001-1100]: loss = 0.351819 * 100, metric = 8.07% * 100;
 Minibatch[1101-1200]: loss = 0.344295 * 100, metric = 7.52% * 100;
 Minibatch[1201-1300]: loss = 0.349480 * 100, metric = 7.89% * 100;
 Minibatch[1301-1400]: loss = 0.347030 * 100, metric = 7.68% * 100;
 Minibatch[1401-1500]: loss = 0.354036 * 100, metric = 7.87% * 100;
 Minibatch[1501-1600]: loss = 0.347702 * 100, metric = 7.85% * 100;
 Minibatch[1601-1700]: loss = 0.351761 * 100, metric = 7.76% * 100;
 Minibatch[1701-1800]: loss = 0.346014 * 100, metric = 7.56% * 100;
 Minibatch[1801-1900]: loss = 0.356058 * 100, metric = 8.11% * 100;
 Minibatch[1901-2000]: loss = 0.351750 * 100, metric = 7.83% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.350854 * 2000, metric = 7.83% * 2000 965.455s (  2.1 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 16.23% * 2000;
 Minibatch[   1- 100]: loss = 0.341242 * 100, metric = 7.46% * 100;
 Minibatch[ 101- 200]: loss = 0.346827 * 100, metric = 7.68% * 100;
 Minibatch[ 201- 300]: loss = 0.352449 * 100, metric = 7.99% * 100;
 Minibatch[ 301- 400]: loss = 0.368910 * 100, metric = 8.35% * 100;
 Minibatch[ 401- 500]: loss = 0.344962 * 100, metric = 7.71% * 100;
 Minibatch[ 501- 600]: loss = 0.342612 * 100, metric = 7.64% * 100;
 Minibatch[ 601- 700]: loss = 0.341243 * 100, metric = 7.76% * 100;
 Minibatch[ 701- 800]: loss = 0.346689 * 100, metric = 7.78% * 100;
 Minibatch[ 801- 900]: loss = 0.341424 * 100, metric = 7.80% * 100;
 Minibatch[ 901-1000]: loss = 0.350785 * 100, metric = 7.88% * 100;
 Minibatch[1001-1100]: loss = 0.339250 * 100, metric = 7.67% * 100;
 Minibatch[1101-1200]: loss = 0.332824 * 100, metric = 7.42% * 100;
 Minibatch[1201-1300]: loss = 0.343871 * 100, metric = 7.64% * 100;
 Minibatch[1301-1400]: loss = 0.337473 * 100, metric = 7.36% * 100;
 Minibatch[1401-1500]: loss = 0.352459 * 100, metric = 7.83% * 100;
 Minibatch[1501-1600]: loss = 0.329948 * 100, metric = 7.47% * 100;
 Minibatch[1601-1700]: loss = 0.349108 * 100, metric = 7.86% * 100;
 Minibatch[1701-1800]: loss = 0.331253 * 100, metric = 7.36% * 100;
 Minibatch[1801-1900]: loss = 0.353721 * 100, metric = 7.94% * 100;
 Minibatch[1901-2000]: loss = 0.341039 * 100, metric = 7.86% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.344404 * 2000, metric = 7.72% * 2000 985.859s (  2.0 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 17.66% * 2000;
 Minibatch[   1- 100]: loss = 0.351873 * 100, metric = 7.94% * 100;
 Minibatch[ 101- 200]: loss = 0.320429 * 100, metric = 7.10% * 100;
 Minibatch[ 201- 300]: loss = 0.332498 * 100, metric = 7.32% * 100;
 Minibatch[ 301- 400]: loss = 0.341264 * 100, metric = 7.59% * 100;
 Minibatch[ 401- 500]: loss = 0.339887 * 100, metric = 7.50% * 100;
 Minibatch[ 501- 600]: loss = 0.317079 * 100, metric = 6.78% * 100;
 Minibatch[ 601- 700]: loss = 0.333035 * 100, metric = 7.45% * 100;
 Minibatch[ 701- 800]: loss = 0.331880 * 100, metric = 7.30% * 100;
 Minibatch[ 801- 900]: loss = 0.343817 * 100, metric = 7.49% * 100;
 Minibatch[ 901-1000]: loss = 0.326389 * 100, metric = 6.96% * 100;
 Minibatch[1001-1100]: loss = 0.345952 * 100, metric = 7.37% * 100;
 Minibatch[1101-1200]: loss = 0.342548 * 100, metric = 7.44% * 100;
 Minibatch[1201-1300]: loss = 0.337330 * 100, metric = 7.45% * 100;
 Minibatch[1301-1400]: loss = 0.336641 * 100, metric = 7.42% * 100;
 Minibatch[1401-1500]: loss = 0.332787 * 100, metric = 7.36% * 100;
 Minibatch[1501-1600]: loss = 0.338469 * 100, metric = 7.71% * 100;
 Minibatch[1601-1700]: loss = 0.340059 * 100, metric = 7.45% * 100;
 Minibatch[1701-1800]: loss = 0.341990 * 100, metric = 7.67% * 100;
 Minibatch[1801-1900]: loss = 0.339247 * 100, metric = 7.65% * 100;
 Minibatch[1901-2000]: loss = 0.350797 * 100, metric = 7.93% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.337198 * 2000, metric = 7.44% * 2000 959.688s (  2.1 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 15.82% * 2000;
 Minibatch[   1- 100]: loss = 0.329661 * 100, metric = 7.12% * 100;
 Minibatch[ 101- 200]: loss = 0.350182 * 100, metric = 8.01% * 100;
 Minibatch[ 201- 300]: loss = 0.332958 * 100, metric = 7.24% * 100;
 Minibatch[ 301- 400]: loss = 0.334141 * 100, metric = 7.34% * 100;
 Minibatch[ 401- 500]: loss = 0.335923 * 100, metric = 7.38% * 100;
 Minibatch[ 501- 600]: loss = 0.330382 * 100, metric = 7.14% * 100;
 Minibatch[ 601- 700]: loss = 0.339632 * 100, metric = 7.71% * 100;
 Minibatch[ 701- 800]: loss = 0.338990 * 100, metric = 7.66% * 100;
 Minibatch[ 801- 900]: loss = 0.334298 * 100, metric = 7.28% * 100;
 Minibatch[ 901-1000]: loss = 0.321956 * 100, metric = 7.06% * 100;
 Minibatch[1001-1100]: loss = 0.328452 * 100, metric = 7.23% * 100;
 Minibatch[1101-1200]: loss = 0.329193 * 100, metric = 7.31% * 100;
 Minibatch[1201-1300]: loss = 0.328789 * 100, metric = 7.52% * 100;
 Minibatch[1301-1400]: loss = 0.324861 * 100, metric = 7.20% * 100;
 Minibatch[1401-1500]: loss = 0.338523 * 100, metric = 7.58% * 100;
 Minibatch[1501-1600]: loss = 0.320397 * 100, metric = 7.24% * 100;
 Minibatch[1601-1700]: loss = 0.332752 * 100, metric = 7.36% * 100;
 Minibatch[1701-1800]: loss = 0.326948 * 100, metric = 7.17% * 100;
 Minibatch[1801-1900]: loss = 0.339049 * 100, metric = 7.52% * 100;
 Minibatch[1901-2000]: loss = 0.325961 * 100, metric = 7.18% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.332152 * 2000, metric = 7.36% * 2000 966.285s (  2.1 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 16.53% * 2000;
 Minibatch[   1- 100]: loss = 0.327722 * 100, metric = 7.18% * 100;
 Minibatch[ 101- 200]: loss = 0.331324 * 100, metric = 7.32% * 100;
 Minibatch[ 201- 300]: loss = 0.341747 * 100, metric = 7.62% * 100;
 Minibatch[ 301- 400]: loss = 0.340980 * 100, metric = 7.54% * 100;
 Minibatch[ 401- 500]: loss = 0.332757 * 100, metric = 7.54% * 100;
 Minibatch[ 501- 600]: loss = 0.329561 * 100, metric = 7.32% * 100;
 Minibatch[ 601- 700]: loss = 0.324255 * 100, metric = 7.09% * 100;
 Minibatch[ 701- 800]: loss = 0.326550 * 100, metric = 7.16% * 100;
 Minibatch[ 801- 900]: loss = 0.326744 * 100, metric = 7.13% * 100;
 Minibatch[ 901-1000]: loss = 0.318767 * 100, metric = 6.92% * 100;
 Minibatch[1001-1100]: loss = 0.319657 * 100, metric = 6.95% * 100;
 Minibatch[1101-1200]: loss = 0.329815 * 100, metric = 7.33% * 100;
 Minibatch[1201-1300]: loss = 0.334855 * 100, metric = 7.45% * 100;
 Minibatch[1301-1400]: loss = 0.328423 * 100, metric = 7.39% * 100;
 Minibatch[1401-1500]: loss = 0.322713 * 100, metric = 7.36% * 100;
 Minibatch[1501-1600]: loss = 0.334519 * 100, metric = 7.29% * 100;
 Minibatch[1601-1700]: loss = 0.317056 * 100, metric = 7.03% * 100;
 Minibatch[1701-1800]: loss = 0.339966 * 100, metric = 7.50% * 100;
 Minibatch[1801-1900]: loss = 0.317969 * 100, metric = 6.93% * 100;
 Minibatch[1901-2000]: loss = 0.329658 * 100, metric = 7.57% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.328752 * 2000, metric = 7.28% * 2000 980.173s (  2.0 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 15.70% * 2000;
 Minibatch[   1- 100]: loss = 0.341448 * 100, metric = 7.57% * 100;
 Minibatch[ 101- 200]: loss = 0.326999 * 100, metric = 7.39% * 100;
 Minibatch[ 201- 300]: loss = 0.318932 * 100, metric = 7.08% * 100;
 Minibatch[ 301- 400]: loss = 0.323700 * 100, metric = 7.22% * 100;
 Minibatch[ 401- 500]: loss = 0.324179 * 100, metric = 7.29% * 100;
 Minibatch[ 501- 600]: loss = 0.328831 * 100, metric = 7.12% * 100;
 Minibatch[ 601- 700]: loss = 0.329329 * 100, metric = 7.40% * 100;
 Minibatch[ 701- 800]: loss = 0.328776 * 100, metric = 7.29% * 100;
 Minibatch[ 801- 900]: loss = 0.325574 * 100, metric = 7.13% * 100;
 Minibatch[ 901-1000]: loss = 0.314898 * 100, metric = 6.68% * 100;
 Minibatch[1001-1100]: loss = 0.323428 * 100, metric = 7.17% * 100;
 Minibatch[1101-1200]: loss = 0.316120 * 100, metric = 6.90% * 100;
 Minibatch[1201-1300]: loss = 0.333643 * 100, metric = 7.33% * 100;
 Minibatch[1301-1400]: loss = 0.314415 * 100, metric = 6.64% * 100;
 Minibatch[1401-1500]: loss = 0.334948 * 100, metric = 7.52% * 100;
 Minibatch[1501-1600]: loss = 0.333455 * 100, metric = 7.40% * 100;
 Minibatch[1601-1700]: loss = 0.324048 * 100, metric = 7.00% * 100;
 Minibatch[1701-1800]: loss = 0.318022 * 100, metric = 7.03% * 100;
 Minibatch[1801-1900]: loss = 0.319439 * 100, metric = 6.94% * 100;
 Minibatch[1901-2000]: loss = 0.339000 * 100, metric = 7.73% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.325959 * 2000, metric = 7.19% * 2000 962.598s (  2.1 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 15.86% * 2000;
 Minibatch[   1- 100]: loss = 0.320973 * 100, metric = 7.03% * 100;
 Minibatch[ 101- 200]: loss = 0.327149 * 100, metric = 7.08% * 100;
 Minibatch[ 201- 300]: loss = 0.317508 * 100, metric = 7.05% * 100;
 Minibatch[ 301- 400]: loss = 0.333493 * 100, metric = 7.47% * 100;
 Minibatch[ 401- 500]: loss = 0.312057 * 100, metric = 6.93% * 100;
 Minibatch[ 501- 600]: loss = 0.328340 * 100, metric = 7.32% * 100;
 Minibatch[ 601- 700]: loss = 0.331076 * 100, metric = 7.42% * 100;
 Minibatch[ 701- 800]: loss = 0.318978 * 100, metric = 7.01% * 100;
 Minibatch[ 801- 900]: loss = 0.307491 * 100, metric = 6.62% * 100;
 Minibatch[ 901-1000]: loss = 0.315128 * 100, metric = 7.01% * 100;
 Minibatch[1001-1100]: loss = 0.325843 * 100, metric = 7.12% * 100;
 Minibatch[1101-1200]: loss = 0.311350 * 100, metric = 6.84% * 100;
 Minibatch[1201-1300]: loss = 0.323280 * 100, metric = 7.10% * 100;
 Minibatch[1301-1400]: loss = 0.322259 * 100, metric = 6.98% * 100;
 Minibatch[1401-1500]: loss = 0.326613 * 100, metric = 7.32% * 100;
 Minibatch[1501-1600]: loss = 0.327423 * 100, metric = 7.09% * 100;
 Minibatch[1601-1700]: loss = 0.333312 * 100, metric = 7.49% * 100;
 Minibatch[1701-1800]: loss = 0.320829 * 100, metric = 7.18% * 100;
 Minibatch[1801-1900]: loss = 0.317070 * 100, metric = 7.06% * 100;
 Minibatch[1901-2000]: loss = 0.318193 * 100, metric = 7.12% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.321918 * 2000, metric = 7.11% * 2000 947.244s (  2.1 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 16.56% * 2000;
 Minibatch[   1- 100]: loss = 0.306645 * 100, metric = 6.64% * 100;
 Minibatch[ 101- 200]: loss = 0.316706 * 100, metric = 7.00% * 100;
 Minibatch[ 201- 300]: loss = 0.320043 * 100, metric = 7.10% * 100;
 Minibatch[ 301- 400]: loss = 0.308941 * 100, metric = 6.62% * 100;
 Minibatch[ 401- 500]: loss = 0.312968 * 100, metric = 6.81% * 100;
 Minibatch[ 501- 600]: loss = 0.300826 * 100, metric = 6.51% * 100;
 Minibatch[ 601- 700]: loss = 0.326320 * 100, metric = 7.33% * 100;
 Minibatch[ 701- 800]: loss = 0.306831 * 100, metric = 6.84% * 100;
 Minibatch[ 801- 900]: loss = 0.324911 * 100, metric = 7.22% * 100;
 Minibatch[ 901-1000]: loss = 0.302843 * 100, metric = 6.68% * 100;
 Minibatch[1001-1100]: loss = 0.327901 * 100, metric = 7.31% * 100;
 Minibatch[1101-1200]: loss = 0.311805 * 100, metric = 6.83% * 100;
 Minibatch[1201-1300]: loss = 0.317217 * 100, metric = 7.10% * 100;
 Minibatch[1301-1400]: loss = 0.318407 * 100, metric = 7.15% * 100;
 Minibatch[1401-1500]: loss = 0.302920 * 100, metric = 6.48% * 100;
 Minibatch[1501-1600]: loss = 0.313280 * 100, metric = 7.12% * 100;
 Minibatch[1601-1700]: loss = 0.317275 * 100, metric = 7.09% * 100;
 Minibatch[1701-1800]: loss = 0.304380 * 100, metric = 6.53% * 100;
 Minibatch[1801-1900]: loss = 0.320356 * 100, metric = 7.18% * 100;
 Minibatch[1901-2000]: loss = 0.311481 * 100, metric = 7.13% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.313603 * 2000, metric = 6.93% * 2000 950.796s (  2.1 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 14.69% * 2000;
0.5234363019727171
 Minibatch[   1- 100]: loss = 0.311617 * 100, metric = 6.76% * 100;
 Minibatch[ 101- 200]: loss = 0.299161 * 100, metric = 6.43% * 100;
 Minibatch[ 201- 300]: loss = 0.322726 * 100, metric = 7.23% * 100;
 Minibatch[ 301- 400]: loss = 0.303005 * 100, metric = 6.60% * 100;
 Minibatch[ 401- 500]: loss = 0.304365 * 100, metric = 6.60% * 100;
 Minibatch[ 501- 600]: loss = 0.308535 * 100, metric = 6.68% * 100;
 Minibatch[ 601- 700]: loss = 0.309758 * 100, metric = 6.85% * 100;
 Minibatch[ 701- 800]: loss = 0.299876 * 100, metric = 6.51% * 100;
 Minibatch[ 801- 900]: loss = 0.302260 * 100, metric = 6.50% * 100;
 Minibatch[ 901-1000]: loss = 0.318173 * 100, metric = 6.98% * 100;
 Minibatch[1001-1100]: loss = 0.323939 * 100, metric = 7.23% * 100;
 Minibatch[1101-1200]: loss = 0.300781 * 100, metric = 6.57% * 100;
 Minibatch[1201-1300]: loss = 0.312979 * 100, metric = 6.87% * 100;
 Minibatch[1301-1400]: loss = 0.294316 * 100, metric = 6.34% * 100;
 Minibatch[1401-1500]: loss = 0.308488 * 100, metric = 6.62% * 100;
 Minibatch[1501-1600]: loss = 0.305599 * 100, metric = 6.72% * 100;
 Minibatch[1601-1700]: loss = 0.311418 * 100, metric = 6.87% * 100;
 Minibatch[1701-1800]: loss = 0.312313 * 100, metric = 6.86% * 100;
 Minibatch[1801-1900]: loss = 0.306701 * 100, metric = 6.62% * 100;
 Minibatch[1901-2000]: loss = 0.302347 * 100, metric = 6.49% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.307918 * 2000, metric = 6.72% * 2000 946.217s (  2.1 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 15.22% * 2000;
 Minibatch[   1- 100]: loss = 0.304506 * 100, metric = 6.73% * 100;
 Minibatch[ 101- 200]: loss = 0.315271 * 100, metric = 7.03% * 100;
 Minibatch[ 201- 300]: loss = 0.309404 * 100, metric = 6.88% * 100;
 Minibatch[ 301- 400]: loss = 0.309009 * 100, metric = 6.83% * 100;
 Minibatch[ 401- 500]: loss = 0.305292 * 100, metric = 6.81% * 100;
 Minibatch[ 501- 600]: loss = 0.296372 * 100, metric = 6.59% * 100;
 Minibatch[ 601- 700]: loss = 0.303853 * 100, metric = 6.71% * 100;
 Minibatch[ 701- 800]: loss = 0.312163 * 100, metric = 6.85% * 100;
 Minibatch[ 801- 900]: loss = 0.305517 * 100, metric = 6.72% * 100;
 Minibatch[ 901-1000]: loss = 0.294793 * 100, metric = 6.23% * 100;
 Minibatch[1001-1100]: loss = 0.297935 * 100, metric = 6.54% * 100;
 Minibatch[1101-1200]: loss = 0.323530 * 100, metric = 7.33% * 100;
 Minibatch[1201-1300]: loss = 0.319163 * 100, metric = 7.05% * 100;
 Minibatch[1301-1400]: loss = 0.312342 * 100, metric = 6.71% * 100;
 Minibatch[1401-1500]: loss = 0.308587 * 100, metric = 6.83% * 100;
 Minibatch[1501-1600]: loss = 0.295819 * 100, metric = 6.41% * 100;
 Minibatch[1601-1700]: loss = 0.307362 * 100, metric = 6.69% * 100;
 Minibatch[1701-1800]: loss = 0.307045 * 100, metric = 6.69% * 100;
 Minibatch[1801-1900]: loss = 0.315953 * 100, metric = 7.01% * 100;
 Minibatch[1901-2000]: loss = 0.310751 * 100, metric = 6.81% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.307733 * 2000, metric = 6.77% * 2000 950.907s (  2.1 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 15.45% * 2000;
 Minibatch[   1- 100]: loss = 0.314952 * 100, metric = 6.93% * 100;
 Minibatch[ 101- 200]: loss = 0.310490 * 100, metric = 6.90% * 100;
 Minibatch[ 201- 300]: loss = 0.300119 * 100, metric = 6.38% * 100;
 Minibatch[ 301- 400]: loss = 0.297227 * 100, metric = 6.57% * 100;
 Minibatch[ 401- 500]: loss = 0.302169 * 100, metric = 6.62% * 100;
 Minibatch[ 501- 600]: loss = 0.297527 * 100, metric = 6.27% * 100;
 Minibatch[ 601- 700]: loss = 0.307750 * 100, metric = 6.85% * 100;
 Minibatch[ 701- 800]: loss = 0.305280 * 100, metric = 6.79% * 100;
 Minibatch[ 801- 900]: loss = 0.304107 * 100, metric = 6.73% * 100;
 Minibatch[ 901-1000]: loss = 0.298276 * 100, metric = 6.39% * 100;
 Minibatch[1001-1100]: loss = 0.308906 * 100, metric = 6.93% * 100;
 Minibatch[1101-1200]: loss = 0.298467 * 100, metric = 6.51% * 100;
 Minibatch[1201-1300]: loss = 0.304327 * 100, metric = 6.63% * 100;
 Minibatch[1301-1400]: loss = 0.315699 * 100, metric = 6.74% * 100;
 Minibatch[1401-1500]: loss = 0.307442 * 100, metric = 6.76% * 100;
 Minibatch[1501-1600]: loss = 0.312241 * 100, metric = 6.85% * 100;
 Minibatch[1601-1700]: loss = 0.293508 * 100, metric = 6.28% * 100;
 Minibatch[1701-1800]: loss = 0.300073 * 100, metric = 6.66% * 100;
 Minibatch[1801-1900]: loss = 0.308580 * 100, metric = 6.84% * 100;
 Minibatch[1901-2000]: loss = 0.309715 * 100, metric = 6.72% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.304843 * 2000, metric = 6.67% * 2000 923.248s (  2.2 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 14.51% * 2000;
 Minibatch[   1- 100]: loss = 0.298661 * 100, metric = 6.52% * 100;
 Minibatch[ 101- 200]: loss = 0.307170 * 100, metric = 6.60% * 100;
 Minibatch[ 201- 300]: loss = 0.300171 * 100, metric = 6.41% * 100;
 Minibatch[ 301- 400]: loss = 0.297288 * 100, metric = 6.42% * 100;
 Minibatch[ 401- 500]: loss = 0.302697 * 100, metric = 6.62% * 100;
 Minibatch[ 501- 600]: loss = 0.304010 * 100, metric = 6.68% * 100;
 Minibatch[ 601- 700]: loss = 0.310672 * 100, metric = 6.94% * 100;
 Minibatch[ 701- 800]: loss = 0.310318 * 100, metric = 6.65% * 100;
 Minibatch[ 801- 900]: loss = 0.293204 * 100, metric = 6.35% * 100;
 Minibatch[ 901-1000]: loss = 0.297573 * 100, metric = 6.32% * 100;
 Minibatch[1001-1100]: loss = 0.310747 * 100, metric = 6.88% * 100;
 Minibatch[1101-1200]: loss = 0.301210 * 100, metric = 6.73% * 100;
 Minibatch[1201-1300]: loss = 0.304708 * 100, metric = 6.45% * 100;
 Minibatch[1301-1400]: loss = 0.315586 * 100, metric = 6.82% * 100;
 Minibatch[1401-1500]: loss = 0.303331 * 100, metric = 6.74% * 100;
 Minibatch[1501-1600]: loss = 0.306666 * 100, metric = 6.65% * 100;
 Minibatch[1601-1700]: loss = 0.296768 * 100, metric = 6.34% * 100;
 Minibatch[1701-1800]: loss = 0.311602 * 100, metric = 6.82% * 100;
 Minibatch[1801-1900]: loss = 0.293104 * 100, metric = 6.45% * 100;
 Minibatch[1901-2000]: loss = 0.294323 * 100, metric = 6.31% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.302990 * 2000, metric = 6.58% * 2000 949.699s (  2.1 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 14.83% * 2000;
 Minibatch[   1- 100]: loss = 0.291321 * 100, metric = 6.43% * 100;
 Minibatch[ 101- 200]: loss = 0.289353 * 100, metric = 6.37% * 100;
 Minibatch[ 201- 300]: loss = 0.304761 * 100, metric = 6.62% * 100;
 Minibatch[ 301- 400]: loss = 0.300308 * 100, metric = 6.68% * 100;
 Minibatch[ 401- 500]: loss = 0.287942 * 100, metric = 6.21% * 100;
 Minibatch[ 501- 600]: loss = 0.295650 * 100, metric = 6.43% * 100;
 Minibatch[ 601- 700]: loss = 0.301294 * 100, metric = 6.49% * 100;
 Minibatch[ 701- 800]: loss = 0.294509 * 100, metric = 6.34% * 100;
 Minibatch[ 801- 900]: loss = 0.295055 * 100, metric = 6.51% * 100;
 Minibatch[ 901-1000]: loss = 0.294999 * 100, metric = 6.35% * 100;
 Minibatch[1001-1100]: loss = 0.306066 * 100, metric = 6.73% * 100;
 Minibatch[1101-1200]: loss = 0.295572 * 100, metric = 6.49% * 100;
 Minibatch[1201-1300]: loss = 0.294483 * 100, metric = 6.33% * 100;
 Minibatch[1301-1400]: loss = 0.300155 * 100, metric = 6.60% * 100;
 Minibatch[1401-1500]: loss = 0.290439 * 100, metric = 6.25% * 100;
 Minibatch[1501-1600]: loss = 0.298120 * 100, metric = 6.55% * 100;
 Minibatch[1601-1700]: loss = 0.297101 * 100, metric = 6.52% * 100;
 Minibatch[1701-1800]: loss = 0.289287 * 100, metric = 6.10% * 100;
 Minibatch[1801-1900]: loss = 0.294111 * 100, metric = 6.31% * 100;
 Minibatch[1901-2000]: loss = 0.303408 * 100, metric = 6.58% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.296197 * 2000, metric = 6.44% * 2000 936.036s (  2.1 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 15.19% * 2000;
 Minibatch[   1- 100]: loss = 0.296602 * 100, metric = 6.62% * 100;
 Minibatch[ 101- 200]: loss = 0.292743 * 100, metric = 6.38% * 100;
 Minibatch[ 201- 300]: loss = 0.306479 * 100, metric = 6.62% * 100;
 Minibatch[ 301- 400]: loss = 0.302557 * 100, metric = 6.73% * 100;
 Minibatch[ 401- 500]: loss = 0.299413 * 100, metric = 6.55% * 100;
 Minibatch[ 501- 600]: loss = 0.291055 * 100, metric = 6.18% * 100;
 Minibatch[ 601- 700]: loss = 0.300182 * 100, metric = 6.47% * 100;
 Minibatch[ 701- 800]: loss = 0.296083 * 100, metric = 6.55% * 100;
 Minibatch[ 801- 900]: loss = 0.292785 * 100, metric = 6.36% * 100;
 Minibatch[ 901-1000]: loss = 0.297701 * 100, metric = 6.58% * 100;
 Minibatch[1001-1100]: loss = 0.290228 * 100, metric = 6.24% * 100;
 Minibatch[1101-1200]: loss = 0.308366 * 100, metric = 6.74% * 100;
 Minibatch[1201-1300]: loss = 0.296769 * 100, metric = 6.57% * 100;
 Minibatch[1301-1400]: loss = 0.284755 * 100, metric = 6.05% * 100;
 Minibatch[1401-1500]: loss = 0.292510 * 100, metric = 6.27% * 100;
 Minibatch[1501-1600]: loss = 0.290568 * 100, metric = 6.31% * 100;
 Minibatch[1601-1700]: loss = 0.293246 * 100, metric = 6.34% * 100;
 Minibatch[1701-1800]: loss = 0.296489 * 100, metric = 6.47% * 100;
 Minibatch[1801-1900]: loss = 0.292173 * 100, metric = 6.44% * 100;
 Minibatch[1901-2000]: loss = 0.289612 * 100, metric = 6.22% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.295516 * 2000, metric = 6.43% * 2000 948.333s (  2.1 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 15.06% * 2000;
 Minibatch[   1- 100]: loss = 0.293001 * 100, metric = 6.35% * 100;
 Minibatch[ 101- 200]: loss = 0.289512 * 100, metric = 6.41% * 100;
 Minibatch[ 201- 300]: loss = 0.285445 * 100, metric = 6.11% * 100;
 Minibatch[ 301- 400]: loss = 0.283285 * 100, metric = 6.09% * 100;
 Minibatch[ 401- 500]: loss = 0.290227 * 100, metric = 6.21% * 100;
 Minibatch[ 501- 600]: loss = 0.294345 * 100, metric = 6.46% * 100;
 Minibatch[ 601- 700]: loss = 0.292125 * 100, metric = 6.36% * 100;
 Minibatch[ 701- 800]: loss = 0.283260 * 100, metric = 6.29% * 100;
 Minibatch[ 801- 900]: loss = 0.279973 * 100, metric = 5.97% * 100;
 Minibatch[ 901-1000]: loss = 0.298920 * 100, metric = 6.60% * 100;
 Minibatch[1001-1100]: loss = 0.288002 * 100, metric = 6.26% * 100;
 Minibatch[1101-1200]: loss = 0.287388 * 100, metric = 6.25% * 100;
 Minibatch[1201-1300]: loss = 0.286906 * 100, metric = 6.25% * 100;
 Minibatch[1301-1400]: loss = 0.286628 * 100, metric = 6.10% * 100;
 Minibatch[1401-1500]: loss = 0.281078 * 100, metric = 6.01% * 100;
 Minibatch[1501-1600]: loss = 0.290131 * 100, metric = 6.25% * 100;
 Minibatch[1601-1700]: loss = 0.294417 * 100, metric = 6.25% * 100;
 Minibatch[1701-1800]: loss = 0.289375 * 100, metric = 6.28% * 100;
 Minibatch[1801-1900]: loss = 0.289918 * 100, metric = 6.42% * 100;
 Minibatch[1901-2000]: loss = 0.286526 * 100, metric = 6.28% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.288523 * 2000, metric = 6.26% * 2000 909.586s (  2.2 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 14.79% * 2000;
 Minibatch[   1- 100]: loss = 0.302520 * 100, metric = 6.72% * 100;
 Minibatch[ 101- 200]: loss = 0.277177 * 100, metric = 5.87% * 100;
 Minibatch[ 201- 300]: loss = 0.288875 * 100, metric = 6.25% * 100;
 Minibatch[ 301- 400]: loss = 0.294515 * 100, metric = 6.56% * 100;
 Minibatch[ 401- 500]: loss = 0.285050 * 100, metric = 6.19% * 100;
 Minibatch[ 501- 600]: loss = 0.284074 * 100, metric = 6.06% * 100;
 Minibatch[ 601- 700]: loss = 0.296263 * 100, metric = 6.63% * 100;
 Minibatch[ 701- 800]: loss = 0.285635 * 100, metric = 6.25% * 100;
 Minibatch[ 801- 900]: loss = 0.287784 * 100, metric = 6.33% * 100;
 Minibatch[ 901-1000]: loss = 0.290278 * 100, metric = 6.28% * 100;
 Minibatch[1001-1100]: loss = 0.287149 * 100, metric = 6.41% * 100;
 Minibatch[1101-1200]: loss = 0.278673 * 100, metric = 5.96% * 100;
 Minibatch[1201-1300]: loss = 0.294999 * 100, metric = 6.67% * 100;
 Minibatch[1301-1400]: loss = 0.295056 * 100, metric = 6.62% * 100;
 Minibatch[1401-1500]: loss = 0.282468 * 100, metric = 6.21% * 100;
 Minibatch[1501-1600]: loss = 0.294650 * 100, metric = 6.48% * 100;
 Minibatch[1601-1700]: loss = 0.288689 * 100, metric = 6.35% * 100;
 Minibatch[1701-1800]: loss = 0.285594 * 100, metric = 6.29% * 100;
 Minibatch[1801-1900]: loss = 0.288152 * 100, metric = 6.17% * 100;
 Minibatch[1901-2000]: loss = 0.286126 * 100, metric = 6.32% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.288686 * 2000, metric = 6.33% * 2000 916.987s (  2.2 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 15.10% * 2000;
 Minibatch[   1- 100]: loss = 0.284035 * 100, metric = 6.18% * 100;
 Minibatch[ 101- 200]: loss = 0.282409 * 100, metric = 6.02% * 100;
 Minibatch[ 201- 300]: loss = 0.285117 * 100, metric = 6.02% * 100;
 Minibatch[ 301- 400]: loss = 0.291578 * 100, metric = 6.29% * 100;
 Minibatch[ 401- 500]: loss = 0.282924 * 100, metric = 6.02% * 100;
 Minibatch[ 501- 600]: loss = 0.282146 * 100, metric = 6.03% * 100;
 Minibatch[ 601- 700]: loss = 0.295614 * 100, metric = 6.64% * 100;
 Minibatch[ 701- 800]: loss = 0.268371 * 100, metric = 5.61% * 100;
 Minibatch[ 801- 900]: loss = 0.279962 * 100, metric = 5.75% * 100;
 Minibatch[ 901-1000]: loss = 0.274052 * 100, metric = 5.75% * 100;
 Minibatch[1001-1100]: loss = 0.273677 * 100, metric = 5.59% * 100;
 Minibatch[1101-1200]: loss = 0.271827 * 100, metric = 5.78% * 100;
 Minibatch[1201-1300]: loss = 0.281873 * 100, metric = 5.94% * 100;
 Minibatch[1301-1400]: loss = 0.275375 * 100, metric = 5.84% * 100;
 Minibatch[1401-1500]: loss = 0.268959 * 100, metric = 5.63% * 100;
 Minibatch[1501-1600]: loss = 0.267150 * 100, metric = 5.59% * 100;
 Minibatch[1601-1700]: loss = 0.280387 * 100, metric = 6.05% * 100;
 Minibatch[1701-1800]: loss = 0.283736 * 100, metric = 6.10% * 100;
 Minibatch[1801-1900]: loss = 0.279103 * 100, metric = 6.00% * 100;
 Minibatch[1901-2000]: loss = 0.268671 * 100, metric = 5.67% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.278848 * 2000, metric = 5.92% * 2000 923.558s (  2.2 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 16.09% * 2000;
 Minibatch[   1- 100]: loss = 0.282613 * 100, metric = 6.06% * 100;
 Minibatch[ 101- 200]: loss = 0.279081 * 100, metric = 5.80% * 100;
 Minibatch[ 201- 300]: loss = 0.276886 * 100, metric = 5.79% * 100;
 Minibatch[ 301- 400]: loss = 0.290485 * 100, metric = 6.28% * 100;
 Minibatch[ 401- 500]: loss = 0.276277 * 100, metric = 6.05% * 100;
 Minibatch[ 501- 600]: loss = 0.271240 * 100, metric = 5.64% * 100;
 Minibatch[ 601- 700]: loss = 0.272672 * 100, metric = 5.78% * 100;
 Minibatch[ 701- 800]: loss = 0.270903 * 100, metric = 5.89% * 100;
 Minibatch[ 801- 900]: loss = 0.290844 * 100, metric = 6.41% * 100;
 Minibatch[ 901-1000]: loss = 0.271222 * 100, metric = 5.76% * 100;
 Minibatch[1001-1100]: loss = 0.272688 * 100, metric = 5.81% * 100;
 Minibatch[1101-1200]: loss = 0.285377 * 100, metric = 6.26% * 100;
 Minibatch[1201-1300]: loss = 0.273656 * 100, metric = 5.87% * 100;
 Minibatch[1301-1400]: loss = 0.273568 * 100, metric = 5.73% * 100;
 Minibatch[1401-1500]: loss = 0.279862 * 100, metric = 6.05% * 100;
 Minibatch[1501-1600]: loss = 0.279845 * 100, metric = 6.06% * 100;
 Minibatch[1601-1700]: loss = 0.271508 * 100, metric = 6.04% * 100;
 Minibatch[1701-1800]: loss = 0.284273 * 100, metric = 6.20% * 100;
 Minibatch[1801-1900]: loss = 0.281432 * 100, metric = 6.42% * 100;
 Minibatch[1901-2000]: loss = 0.273927 * 100, metric = 5.75% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.277918 * 2000, metric = 5.98% * 2000 937.439s (  2.1 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 15.08% * 2000;
 Minibatch[   1- 100]: loss = 0.275478 * 100, metric = 6.11% * 100;
 Minibatch[ 101- 200]: loss = 0.289251 * 100, metric = 6.36% * 100;
 Minibatch[ 201- 300]: loss = 0.280180 * 100, metric = 5.87% * 100;
 Minibatch[ 301- 400]: loss = 0.296667 * 100, metric = 6.41% * 100;
 Minibatch[ 401- 500]: loss = 0.279019 * 100, metric = 5.96% * 100;
 Minibatch[ 501- 600]: loss = 0.274201 * 100, metric = 5.88% * 100;
 Minibatch[ 601- 700]: loss = 0.270001 * 100, metric = 5.68% * 100;
 Minibatch[ 701- 800]: loss = 0.270639 * 100, metric = 5.74% * 100;
 Minibatch[ 801- 900]: loss = 0.275781 * 100, metric = 5.82% * 100;
 Minibatch[ 901-1000]: loss = 0.277115 * 100, metric = 6.00% * 100;
 Minibatch[1001-1100]: loss = 0.268979 * 100, metric = 5.54% * 100;
 Minibatch[1101-1200]: loss = 0.281914 * 100, metric = 6.22% * 100;
 Minibatch[1201-1300]: loss = 0.279268 * 100, metric = 5.93% * 100;
 Minibatch[1301-1400]: loss = 0.277915 * 100, metric = 6.15% * 100;
 Minibatch[1401-1500]: loss = 0.266349 * 100, metric = 5.68% * 100;
 Minibatch[1501-1600]: loss = 0.271272 * 100, metric = 5.71% * 100;
 Minibatch[1601-1700]: loss = 0.270844 * 100, metric = 5.85% * 100;
 Minibatch[1701-1800]: loss = 0.285740 * 100, metric = 6.22% * 100;
 Minibatch[1801-1900]: loss = 0.263578 * 100, metric = 5.58% * 100;
 Minibatch[1901-2000]: loss = 0.271512 * 100, metric = 5.76% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.276285 * 2000, metric = 5.92% * 2000 918.430s (  2.2 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 14.54% * 2000;
 Minibatch[   1- 100]: loss = 0.273894 * 100, metric = 5.77% * 100;
 Minibatch[ 101- 200]: loss = 0.269447 * 100, metric = 5.83% * 100;
 Minibatch[ 201- 300]: loss = 0.273871 * 100, metric = 5.87% * 100;
 Minibatch[ 301- 400]: loss = 0.266289 * 100, metric = 5.66% * 100;
 Minibatch[ 401- 500]: loss = 0.262349 * 100, metric = 5.65% * 100;
 Minibatch[ 501- 600]: loss = 0.267381 * 100, metric = 5.86% * 100;
 Minibatch[ 601- 700]: loss = 0.275496 * 100, metric = 5.94% * 100;
 Minibatch[ 701- 800]: loss = 0.276911 * 100, metric = 6.15% * 100;
 Minibatch[ 801- 900]: loss = 0.265638 * 100, metric = 5.46% * 100;
 Minibatch[ 901-1000]: loss = 0.267661 * 100, metric = 5.82% * 100;
 Minibatch[1001-1100]: loss = 0.284155 * 100, metric = 6.04% * 100;
 Minibatch[1101-1200]: loss = 0.264981 * 100, metric = 5.59% * 100;
 Minibatch[1201-1300]: loss = 0.257188 * 100, metric = 5.27% * 100;
 Minibatch[1301-1400]: loss = 0.272277 * 100, metric = 6.03% * 100;
 Minibatch[1401-1500]: loss = 0.274769 * 100, metric = 5.92% * 100;
 Minibatch[1501-1600]: loss = 0.277674 * 100, metric = 5.87% * 100;
 Minibatch[1601-1700]: loss = 0.263672 * 100, metric = 5.50% * 100;
 Minibatch[1701-1800]: loss = 0.268179 * 100, metric = 5.68% * 100;
 Minibatch[1801-1900]: loss = 0.278017 * 100, metric = 6.08% * 100;
 Minibatch[1901-2000]: loss = 0.280433 * 100, metric = 6.08% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.271014 * 2000, metric = 5.80% * 2000 943.542s (  2.1 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 13.95% * 2000;
0.5184254651032388
 Minibatch[   1- 100]: loss = 0.271133 * 100, metric = 5.83% * 100;
 Minibatch[ 101- 200]: loss = 0.269052 * 100, metric = 5.76% * 100;
 Minibatch[ 201- 300]: loss = 0.267671 * 100, metric = 5.87% * 100;
 Minibatch[ 301- 400]: loss = 0.262098 * 100, metric = 5.60% * 100;
 Minibatch[ 401- 500]: loss = 0.271676 * 100, metric = 5.85% * 100;
 Minibatch[ 501- 600]: loss = 0.286640 * 100, metric = 6.09% * 100;
 Minibatch[ 601- 700]: loss = 0.284212 * 100, metric = 6.02% * 100;
 Minibatch[ 701- 800]: loss = 0.272981 * 100, metric = 5.64% * 100;
 Minibatch[ 801- 900]: loss = 0.266424 * 100, metric = 5.45% * 100;
 Minibatch[ 901-1000]: loss = 0.276067 * 100, metric = 5.93% * 100;
 Minibatch[1001-1100]: loss = 0.269992 * 100, metric = 5.97% * 100;
 Minibatch[1101-1200]: loss = 0.267124 * 100, metric = 5.62% * 100;
 Minibatch[1201-1300]: loss = 0.271046 * 100, metric = 5.93% * 100;
 Minibatch[1301-1400]: loss = 0.270176 * 100, metric = 5.84% * 100;
 Minibatch[1401-1500]: loss = 0.268782 * 100, metric = 5.75% * 100;
 Minibatch[1501-1600]: loss = 0.271006 * 100, metric = 5.97% * 100;
 Minibatch[1601-1700]: loss = 0.258922 * 100, metric = 5.52% * 100;
 Minibatch[1701-1800]: loss = 0.267993 * 100, metric = 5.65% * 100;
 Minibatch[1801-1900]: loss = 0.270810 * 100, metric = 5.75% * 100;
 Minibatch[1901-2000]: loss = 0.257821 * 100, metric = 5.43% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.270081 * 2000, metric = 5.77% * 2000 929.489s (  2.2 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 15.44% * 2000;
 Minibatch[   1- 100]: loss = 0.279361 * 100, metric = 5.86% * 100;
 Minibatch[ 101- 200]: loss = 0.263689 * 100, metric = 5.59% * 100;
 Minibatch[ 201- 300]: loss = 0.268195 * 100, metric = 5.71% * 100;
 Minibatch[ 301- 400]: loss = 0.269691 * 100, metric = 5.77% * 100;
 Minibatch[ 401- 500]: loss = 0.275238 * 100, metric = 5.98% * 100;
 Minibatch[ 501- 600]: loss = 0.265387 * 100, metric = 5.64% * 100;
 Minibatch[ 601- 700]: loss = 0.266079 * 100, metric = 5.74% * 100;
 Minibatch[ 701- 800]: loss = 0.267405 * 100, metric = 5.69% * 100;
 Minibatch[ 801- 900]: loss = 0.260725 * 100, metric = 5.63% * 100;
 Minibatch[ 901-1000]: loss = 0.277329 * 100, metric = 6.13% * 100;
 Minibatch[1001-1100]: loss = 0.264650 * 100, metric = 5.66% * 100;
 Minibatch[1101-1200]: loss = 0.270215 * 100, metric = 5.93% * 100;
 Minibatch[1201-1300]: loss = 0.251080 * 100, metric = 5.59% * 100;
 Minibatch[1301-1400]: loss = 0.269687 * 100, metric = 5.99% * 100;
 Minibatch[1401-1500]: loss = 0.267948 * 100, metric = 5.86% * 100;
 Minibatch[1501-1600]: loss = 0.246983 * 100, metric = 5.12% * 100;
 Minibatch[1601-1700]: loss = 0.277923 * 100, metric = 6.23% * 100;
 Minibatch[1701-1800]: loss = 0.268283 * 100, metric = 5.85% * 100;
 Minibatch[1801-1900]: loss = 0.270688 * 100, metric = 5.92% * 100;
 Minibatch[1901-2000]: loss = 0.255773 * 100, metric = 5.33% * 100;
Finished Epoch[49 of 200]: [Training] loss = 0.266816 * 2000, metric = 5.76% * 2000 936.669s (  2.1 samples/s);
Finished Evaluation [49]: Minibatch[1-2000]: metric = 13.62% * 2000;
 Minibatch[   1- 100]: loss = 0.273263 * 100, metric = 5.90% * 100;
 Minibatch[ 101- 200]: loss = 0.262213 * 100, metric = 5.76% * 100;
 Minibatch[ 201- 300]: loss = 0.258033 * 100, metric = 5.49% * 100;
 Minibatch[ 301- 400]: loss = 0.255053 * 100, metric = 5.26% * 100;
 Minibatch[ 401- 500]: loss = 0.266097 * 100, metric = 5.76% * 100;
 Minibatch[ 501- 600]: loss = 0.277113 * 100, metric = 6.03% * 100;
 Minibatch[ 601- 700]: loss = 0.258228 * 100, metric = 5.49% * 100;
 Minibatch[ 701- 800]: loss = 0.254979 * 100, metric = 5.40% * 100;
 Minibatch[ 801- 900]: loss = 0.259012 * 100, metric = 5.41% * 100;
 Minibatch[ 901-1000]: loss = 0.259602 * 100, metric = 5.34% * 100;
 Minibatch[1001-1100]: loss = 0.256066 * 100, metric = 5.53% * 100;
 Minibatch[1101-1200]: loss = 0.262702 * 100, metric = 5.70% * 100;
 Minibatch[1201-1300]: loss = 0.263752 * 100, metric = 5.67% * 100;
 Minibatch[1301-1400]: loss = 0.255374 * 100, metric = 5.53% * 100;
 Minibatch[1401-1500]: loss = 0.262592 * 100, metric = 5.81% * 100;
 Minibatch[1501-1600]: loss = 0.252867 * 100, metric = 5.31% * 100;
 Minibatch[1601-1700]: loss = 0.252614 * 100, metric = 5.34% * 100;
 Minibatch[1701-1800]: loss = 0.261043 * 100, metric = 5.69% * 100;
 Minibatch[1801-1900]: loss = 0.267497 * 100, metric = 5.69% * 100;
 Minibatch[1901-2000]: loss = 0.263845 * 100, metric = 5.73% * 100;
Finished Epoch[50 of 200]: [Training] loss = 0.261097 * 2000, metric = 5.59% * 2000 918.141s (  2.2 samples/s);
Finished Evaluation [50]: Minibatch[1-2000]: metric = 14.68% * 2000;
 Minibatch[   1- 100]: loss = 0.255557 * 100, metric = 5.60% * 100;
 Minibatch[ 101- 200]: loss = 0.260418 * 100, metric = 5.60% * 100;
 Minibatch[ 201- 300]: loss = 0.260049 * 100, metric = 5.43% * 100;
 Minibatch[ 301- 400]: loss = 0.254944 * 100, metric = 5.46% * 100;
 Minibatch[ 401- 500]: loss = 0.258211 * 100, metric = 5.43% * 100;
 Minibatch[ 501- 600]: loss = 0.267213 * 100, metric = 5.77% * 100;
 Minibatch[ 601- 700]: loss = 0.249071 * 100, metric = 5.39% * 100;
 Minibatch[ 701- 800]: loss = 0.258918 * 100, metric = 5.47% * 100;
 Minibatch[ 801- 900]: loss = 0.263913 * 100, metric = 5.54% * 100;
 Minibatch[ 901-1000]: loss = 0.258683 * 100, metric = 5.47% * 100;
 Minibatch[1001-1100]: loss = 0.260198 * 100, metric = 5.62% * 100;
 Minibatch[1101-1200]: loss = 0.261261 * 100, metric = 5.54% * 100;
 Minibatch[1201-1300]: loss = 0.275529 * 100, metric = 5.67% * 100;
 Minibatch[1301-1400]: loss = 0.261138 * 100, metric = 5.49% * 100;
 Minibatch[1401-1500]: loss = 0.257128 * 100, metric = 5.49% * 100;
 Minibatch[1501-1600]: loss = 0.269684 * 100, metric = 5.65% * 100;
 Minibatch[1601-1700]: loss = 0.251472 * 100, metric = 5.40% * 100;
 Minibatch[1701-1800]: loss = 0.259366 * 100, metric = 5.56% * 100;
 Minibatch[1801-1900]: loss = 0.242636 * 100, metric = 5.08% * 100;
 Minibatch[1901-2000]: loss = 0.255261 * 100, metric = 5.31% * 100;
Finished Epoch[51 of 200]: [Training] loss = 0.259033 * 2000, metric = 5.50% * 2000 925.589s (  2.2 samples/s);
Finished Evaluation [51]: Minibatch[1-2000]: metric = 15.54% * 2000;
 Minibatch[   1- 100]: loss = 0.247164 * 100, metric = 5.17% * 100;
 Minibatch[ 101- 200]: loss = 0.255549 * 100, metric = 5.35% * 100;
 Minibatch[ 201- 300]: loss = 0.269707 * 100, metric = 5.96% * 100;
 Minibatch[ 301- 400]: loss = 0.250151 * 100, metric = 5.23% * 100;
 Minibatch[ 401- 500]: loss = 0.260688 * 100, metric = 5.50% * 100;
 Minibatch[ 501- 600]: loss = 0.261237 * 100, metric = 5.55% * 100;
 Minibatch[ 601- 700]: loss = 0.256086 * 100, metric = 5.37% * 100;
 Minibatch[ 701- 800]: loss = 0.268117 * 100, metric = 5.69% * 100;
 Minibatch[ 801- 900]: loss = 0.259776 * 100, metric = 5.59% * 100;
 Minibatch[ 901-1000]: loss = 0.263658 * 100, metric = 5.75% * 100;
 Minibatch[1001-1100]: loss = 0.255889 * 100, metric = 5.43% * 100;
 Minibatch[1101-1200]: loss = 0.241949 * 100, metric = 4.93% * 100;
 Minibatch[1201-1300]: loss = 0.250125 * 100, metric = 5.19% * 100;
 Minibatch[1301-1400]: loss = 0.254039 * 100, metric = 5.16% * 100;
 Minibatch[1401-1500]: loss = 0.247087 * 100, metric = 5.19% * 100;
 Minibatch[1501-1600]: loss = 0.243535 * 100, metric = 5.04% * 100;
 Minibatch[1601-1700]: loss = 0.257876 * 100, metric = 5.53% * 100;
 Minibatch[1701-1800]: loss = 0.254343 * 100, metric = 5.52% * 100;
 Minibatch[1801-1900]: loss = 0.247570 * 100, metric = 5.09% * 100;
 Minibatch[1901-2000]: loss = 0.257193 * 100, metric = 5.51% * 100;
Finished Epoch[52 of 200]: [Training] loss = 0.255087 * 2000, metric = 5.39% * 2000 908.362s (  2.2 samples/s);
Finished Evaluation [52]: Minibatch[1-2000]: metric = 14.49% * 2000;
 Minibatch[   1- 100]: loss = 0.256928 * 100, metric = 5.44% * 100;
 Minibatch[ 101- 200]: loss = 0.241780 * 100, metric = 4.85% * 100;
 Minibatch[ 201- 300]: loss = 0.251569 * 100, metric = 5.37% * 100;
 Minibatch[ 301- 400]: loss = 0.252210 * 100, metric = 5.42% * 100;
 Minibatch[ 401- 500]: loss = 0.259882 * 100, metric = 5.63% * 100;
 Minibatch[ 501- 600]: loss = 0.256443 * 100, metric = 5.52% * 100;
 Minibatch[ 601- 700]: loss = 0.252764 * 100, metric = 5.23% * 100;
 Minibatch[ 701- 800]: loss = 0.250925 * 100, metric = 5.22% * 100;
 Minibatch[ 801- 900]: loss = 0.256970 * 100, metric = 5.49% * 100;
 Minibatch[ 901-1000]: loss = 0.252628 * 100, metric = 5.41% * 100;
 Minibatch[1001-1100]: loss = 0.256139 * 100, metric = 5.45% * 100;
 Minibatch[1101-1200]: loss = 0.252613 * 100, metric = 5.54% * 100;
 Minibatch[1201-1300]: loss = 0.243490 * 100, metric = 5.13% * 100;
 Minibatch[1301-1400]: loss = 0.252933 * 100, metric = 5.17% * 100;
 Minibatch[1401-1500]: loss = 0.245844 * 100, metric = 5.12% * 100;
 Minibatch[1501-1600]: loss = 0.257090 * 100, metric = 5.44% * 100;
 Minibatch[1601-1700]: loss = 0.247601 * 100, metric = 5.18% * 100;
 Minibatch[1701-1800]: loss = 0.263325 * 100, metric = 5.69% * 100;
 Minibatch[1801-1900]: loss = 0.262560 * 100, metric = 5.67% * 100;
 Minibatch[1901-2000]: loss = 0.240107 * 100, metric = 5.17% * 100;
Finished Epoch[53 of 200]: [Training] loss = 0.252690 * 2000, metric = 5.36% * 2000 915.326s (  2.2 samples/s);
Finished Evaluation [53]: Minibatch[1-2000]: metric = 13.65% * 2000;
 Minibatch[   1- 100]: loss = 0.252560 * 100, metric = 5.47% * 100;
 Minibatch[ 101- 200]: loss = 0.249637 * 100, metric = 5.42% * 100;
 Minibatch[ 201- 300]: loss = 0.248779 * 100, metric = 5.21% * 100;
 Minibatch[ 301- 400]: loss = 0.244967 * 100, metric = 4.99% * 100;
 Minibatch[ 401- 500]: loss = 0.246799 * 100, metric = 5.22% * 100;
 Minibatch[ 501- 600]: loss = 0.241814 * 100, metric = 5.12% * 100;
 Minibatch[ 601- 700]: loss = 0.255416 * 100, metric = 5.42% * 100;
 Minibatch[ 701- 800]: loss = 0.253258 * 100, metric = 5.36% * 100;
 Minibatch[ 801- 900]: loss = 0.241918 * 100, metric = 5.10% * 100;
 Minibatch[ 901-1000]: loss = 0.252579 * 100, metric = 5.22% * 100;
 Minibatch[1001-1100]: loss = 0.243591 * 100, metric = 5.09% * 100;
 Minibatch[1101-1200]: loss = 0.242194 * 100, metric = 5.18% * 100;
 Minibatch[1201-1300]: loss = 0.247031 * 100, metric = 5.18% * 100;
 Minibatch[1301-1400]: loss = 0.246436 * 100, metric = 5.35% * 100;
 Minibatch[1401-1500]: loss = 0.255948 * 100, metric = 5.42% * 100;
 Minibatch[1501-1600]: loss = 0.255487 * 100, metric = 5.46% * 100;
 Minibatch[1601-1700]: loss = 0.253953 * 100, metric = 5.38% * 100;
 Minibatch[1701-1800]: loss = 0.252516 * 100, metric = 5.27% * 100;
 Minibatch[1801-1900]: loss = 0.256174 * 100, metric = 5.54% * 100;
 Minibatch[1901-2000]: loss = 0.253463 * 100, metric = 5.37% * 100;
Finished Epoch[54 of 200]: [Training] loss = 0.249726 * 2000, metric = 5.29% * 2000 923.505s (  2.2 samples/s);
Finished Evaluation [54]: Minibatch[1-2000]: metric = 13.54% * 2000;
 Minibatch[   1- 100]: loss = 0.260167 * 100, metric = 5.49% * 100;
 Minibatch[ 101- 200]: loss = 0.247736 * 100, metric = 5.12% * 100;
 Minibatch[ 201- 300]: loss = 0.246882 * 100, metric = 5.14% * 100;
 Minibatch[ 301- 400]: loss = 0.240726 * 100, metric = 4.91% * 100;
 Minibatch[ 401- 500]: loss = 0.247358 * 100, metric = 5.29% * 100;
 Minibatch[ 501- 600]: loss = 0.252224 * 100, metric = 5.34% * 100;
 Minibatch[ 601- 700]: loss = 0.254216 * 100, metric = 5.49% * 100;
 Minibatch[ 701- 800]: loss = 0.250733 * 100, metric = 5.28% * 100;
 Minibatch[ 801- 900]: loss = 0.251704 * 100, metric = 5.19% * 100;
 Minibatch[ 901-1000]: loss = 0.249848 * 100, metric = 5.24% * 100;
 Minibatch[1001-1100]: loss = 0.255284 * 100, metric = 5.51% * 100;
 Minibatch[1101-1200]: loss = 0.253391 * 100, metric = 5.44% * 100;
 Minibatch[1201-1300]: loss = 0.251526 * 100, metric = 5.24% * 100;
 Minibatch[1301-1400]: loss = 0.241163 * 100, metric = 5.06% * 100;
 Minibatch[1401-1500]: loss = 0.244760 * 100, metric = 5.21% * 100;
 Minibatch[1501-1600]: loss = 0.252105 * 100, metric = 5.25% * 100;
 Minibatch[1601-1700]: loss = 0.250907 * 100, metric = 5.38% * 100;
 Minibatch[1701-1800]: loss = 0.253768 * 100, metric = 5.42% * 100;
 Minibatch[1801-1900]: loss = 0.241969 * 100, metric = 5.01% * 100;
 Minibatch[1901-2000]: loss = 0.249831 * 100, metric = 5.36% * 100;
Finished Epoch[55 of 200]: [Training] loss = 0.249815 * 2000, metric = 5.27% * 2000 922.831s (  2.2 samples/s);
Finished Evaluation [55]: Minibatch[1-2000]: metric = 14.17% * 2000;
 Minibatch[   1- 100]: loss = 0.257387 * 100, metric = 5.52% * 100;
 Minibatch[ 101- 200]: loss = 0.241004 * 100, metric = 4.98% * 100;
 Minibatch[ 201- 300]: loss = 0.257583 * 100, metric = 5.46% * 100;
 Minibatch[ 301- 400]: loss = 0.248437 * 100, metric = 5.21% * 100;
 Minibatch[ 401- 500]: loss = 0.252353 * 100, metric = 5.49% * 100;
 Minibatch[ 501- 600]: loss = 0.250553 * 100, metric = 5.15% * 100;
 Minibatch[ 601- 700]: loss = 0.249068 * 100, metric = 5.32% * 100;
 Minibatch[ 701- 800]: loss = 0.243437 * 100, metric = 5.18% * 100;
 Minibatch[ 801- 900]: loss = 0.245376 * 100, metric = 5.13% * 100;
 Minibatch[ 901-1000]: loss = 0.252888 * 100, metric = 5.46% * 100;
 Minibatch[1001-1100]: loss = 0.260458 * 100, metric = 5.50% * 100;
 Minibatch[1101-1200]: loss = 0.252071 * 100, metric = 5.33% * 100;
 Minibatch[1201-1300]: loss = 0.249081 * 100, metric = 5.11% * 100;
 Minibatch[1301-1400]: loss = 0.236115 * 100, metric = 5.01% * 100;
 Minibatch[1401-1500]: loss = 0.247625 * 100, metric = 5.27% * 100;
 Minibatch[1501-1600]: loss = 0.244391 * 100, metric = 5.17% * 100;
 Minibatch[1601-1700]: loss = 0.248751 * 100, metric = 5.00% * 100;
 Minibatch[1701-1800]: loss = 0.243482 * 100, metric = 5.12% * 100;
 Minibatch[1801-1900]: loss = 0.236184 * 100, metric = 4.96% * 100;
 Minibatch[1901-2000]: loss = 0.256607 * 100, metric = 5.59% * 100;
Finished Epoch[56 of 200]: [Training] loss = 0.248643 * 2000, metric = 5.25% * 2000 923.688s (  2.2 samples/s);
Finished Evaluation [56]: Minibatch[1-2000]: metric = 13.64% * 2000;
 Minibatch[   1- 100]: loss = 0.251532 * 100, metric = 5.27% * 100;
 Minibatch[ 101- 200]: loss = 0.239905 * 100, metric = 5.04% * 100;
 Minibatch[ 201- 300]: loss = 0.244287 * 100, metric = 5.14% * 100;
 Minibatch[ 301- 400]: loss = 0.243421 * 100, metric = 4.99% * 100;
 Minibatch[ 401- 500]: loss = 0.243681 * 100, metric = 5.17% * 100;
 Minibatch[ 501- 600]: loss = 0.235958 * 100, metric = 5.07% * 100;
 Minibatch[ 601- 700]: loss = 0.241397 * 100, metric = 4.91% * 100;
 Minibatch[ 701- 800]: loss = 0.237410 * 100, metric = 4.93% * 100;
 Minibatch[ 801- 900]: loss = 0.240503 * 100, metric = 5.11% * 100;
 Minibatch[ 901-1000]: loss = 0.245612 * 100, metric = 5.13% * 100;
 Minibatch[1001-1100]: loss = 0.251971 * 100, metric = 5.36% * 100;
 Minibatch[1101-1200]: loss = 0.242974 * 100, metric = 4.99% * 100;
 Minibatch[1201-1300]: loss = 0.245094 * 100, metric = 5.12% * 100;
 Minibatch[1301-1400]: loss = 0.239926 * 100, metric = 5.01% * 100;
 Minibatch[1401-1500]: loss = 0.252072 * 100, metric = 5.36% * 100;
 Minibatch[1501-1600]: loss = 0.243239 * 100, metric = 5.17% * 100;
 Minibatch[1601-1700]: loss = 0.241454 * 100, metric = 4.98% * 100;
 Minibatch[1701-1800]: loss = 0.236650 * 100, metric = 5.12% * 100;
 Minibatch[1801-1900]: loss = 0.246724 * 100, metric = 5.11% * 100;
 Minibatch[1901-2000]: loss = 0.248174 * 100, metric = 5.21% * 100;
Finished Epoch[57 of 200]: [Training] loss = 0.243599 * 2000, metric = 5.11% * 2000 922.069s (  2.2 samples/s);
Finished Evaluation [57]: Minibatch[1-2000]: metric = 13.14% * 2000;
 Minibatch[   1- 100]: loss = 0.238756 * 100, metric = 4.86% * 100;
 Minibatch[ 101- 200]: loss = 0.248599 * 100, metric = 5.24% * 100;
 Minibatch[ 201- 300]: loss = 0.236761 * 100, metric = 5.09% * 100;
 Minibatch[ 301- 400]: loss = 0.251280 * 100, metric = 5.20% * 100;
 Minibatch[ 401- 500]: loss = 0.254799 * 100, metric = 5.54% * 100;
 Minibatch[ 501- 600]: loss = 0.238538 * 100, metric = 4.93% * 100;
 Minibatch[ 601- 700]: loss = 0.249758 * 100, metric = 5.09% * 100;
 Minibatch[ 701- 800]: loss = 0.255652 * 100, metric = 5.43% * 100;
 Minibatch[ 801- 900]: loss = 0.245590 * 100, metric = 5.15% * 100;
 Minibatch[ 901-1000]: loss = 0.242912 * 100, metric = 5.19% * 100;
 Minibatch[1001-1100]: loss = 0.250602 * 100, metric = 5.35% * 100;
 Minibatch[1101-1200]: loss = 0.248040 * 100, metric = 5.23% * 100;
 Minibatch[1201-1300]: loss = 0.241016 * 100, metric = 5.21% * 100;
 Minibatch[1301-1400]: loss = 0.246049 * 100, metric = 5.24% * 100;
 Minibatch[1401-1500]: loss = 0.234478 * 100, metric = 4.80% * 100;
 Minibatch[1501-1600]: loss = 0.243007 * 100, metric = 5.22% * 100;
 Minibatch[1601-1700]: loss = 0.248477 * 100, metric = 5.26% * 100;
 Minibatch[1701-1800]: loss = 0.238535 * 100, metric = 4.92% * 100;
 Minibatch[1801-1900]: loss = 0.247726 * 100, metric = 5.33% * 100;
 Minibatch[1901-2000]: loss = 0.233738 * 100, metric = 4.77% * 100;
Finished Epoch[58 of 200]: [Training] loss = 0.244716 * 2000, metric = 5.15% * 2000 913.840s (  2.2 samples/s);
Finished Evaluation [58]: Minibatch[1-2000]: metric = 13.19% * 2000;
 Minibatch[   1- 100]: loss = 0.250981 * 100, metric = 5.35% * 100;
 Minibatch[ 101- 200]: loss = 0.255325 * 100, metric = 5.47% * 100;
 Minibatch[ 201- 300]: loss = 0.239257 * 100, metric = 5.00% * 100;
 Minibatch[ 301- 400]: loss = 0.241616 * 100, metric = 4.88% * 100;
 Minibatch[ 401- 500]: loss = 0.247487 * 100, metric = 5.21% * 100;
 Minibatch[ 501- 600]: loss = 0.235334 * 100, metric = 4.96% * 100;
 Minibatch[ 601- 700]: loss = 0.238040 * 100, metric = 5.03% * 100;
 Minibatch[ 701- 800]: loss = 0.243278 * 100, metric = 5.09% * 100;
 Minibatch[ 801- 900]: loss = 0.236830 * 100, metric = 4.98% * 100;
 Minibatch[ 901-1000]: loss = 0.237965 * 100, metric = 5.07% * 100;
 Minibatch[1001-1100]: loss = 0.233461 * 100, metric = 4.87% * 100;
 Minibatch[1101-1200]: loss = 0.246785 * 100, metric = 5.10% * 100;
 Minibatch[1201-1300]: loss = 0.244683 * 100, metric = 5.13% * 100;
 Minibatch[1301-1400]: loss = 0.235377 * 100, metric = 4.87% * 100;
 Minibatch[1401-1500]: loss = 0.235804 * 100, metric = 4.92% * 100;
 Minibatch[1501-1600]: loss = 0.237109 * 100, metric = 4.94% * 100;
 Minibatch[1601-1700]: loss = 0.240550 * 100, metric = 5.07% * 100;
 Minibatch[1701-1800]: loss = 0.235435 * 100, metric = 4.94% * 100;
 Minibatch[1801-1900]: loss = 0.239715 * 100, metric = 4.99% * 100;
 Minibatch[1901-2000]: loss = 0.244016 * 100, metric = 5.03% * 100;
Finished Epoch[59 of 200]: [Training] loss = 0.240952 * 2000, metric = 5.05% * 2000 916.496s (  2.2 samples/s);
Finished Evaluation [59]: Minibatch[1-2000]: metric = 14.22% * 2000;
 Minibatch[   1- 100]: loss = 0.239644 * 100, metric = 5.08% * 100;
 Minibatch[ 101- 200]: loss = 0.230506 * 100, metric = 4.90% * 100;
 Minibatch[ 201- 300]: loss = 0.228675 * 100, metric = 4.69% * 100;
 Minibatch[ 301- 400]: loss = 0.243524 * 100, metric = 5.08% * 100;
 Minibatch[ 401- 500]: loss = 0.246390 * 100, metric = 5.41% * 100;
 Minibatch[ 501- 600]: loss = 0.246449 * 100, metric = 5.32% * 100;
 Minibatch[ 601- 700]: loss = 0.230515 * 100, metric = 4.79% * 100;
 Minibatch[ 701- 800]: loss = 0.238858 * 100, metric = 4.98% * 100;
 Minibatch[ 801- 900]: loss = 0.234468 * 100, metric = 4.90% * 100;
 Minibatch[ 901-1000]: loss = 0.244489 * 100, metric = 5.28% * 100;
 Minibatch[1001-1100]: loss = 0.249828 * 100, metric = 5.42% * 100;
 Minibatch[1101-1200]: loss = 0.239001 * 100, metric = 5.01% * 100;
 Minibatch[1201-1300]: loss = 0.242054 * 100, metric = 5.23% * 100;
 Minibatch[1301-1400]: loss = 0.243044 * 100, metric = 5.24% * 100;
 Minibatch[1401-1500]: loss = 0.226711 * 100, metric = 4.61% * 100;
 Minibatch[1501-1600]: loss = 0.237610 * 100, metric = 4.96% * 100;
 Minibatch[1601-1700]: loss = 0.235300 * 100, metric = 4.94% * 100;
 Minibatch[1701-1800]: loss = 0.242607 * 100, metric = 5.03% * 100;
 Minibatch[1801-1900]: loss = 0.243129 * 100, metric = 5.21% * 100;
 Minibatch[1901-2000]: loss = 0.234747 * 100, metric = 5.02% * 100;
Finished Epoch[60 of 200]: [Training] loss = 0.238877 * 2000, metric = 5.05% * 2000 925.645s (  2.2 samples/s);
Finished Evaluation [60]: Minibatch[1-2000]: metric = 13.51% * 2000;
 Minibatch[   1- 100]: loss = 0.240701 * 100, metric = 5.02% * 100;
 Minibatch[ 101- 200]: loss = 0.227730 * 100, metric = 4.72% * 100;
 Minibatch[ 201- 300]: loss = 0.230946 * 100, metric = 4.94% * 100;
 Minibatch[ 301- 400]: loss = 0.244137 * 100, metric = 5.18% * 100;
 Minibatch[ 401- 500]: loss = 0.233725 * 100, metric = 4.96% * 100;
 Minibatch[ 501- 600]: loss = 0.220852 * 100, metric = 4.52% * 100;
 Minibatch[ 601- 700]: loss = 0.237527 * 100, metric = 4.86% * 100;
 Minibatch[ 701- 800]: loss = 0.237448 * 100, metric = 5.07% * 100;
 Minibatch[ 801- 900]: loss = 0.231654 * 100, metric = 4.64% * 100;
 Minibatch[ 901-1000]: loss = 0.232957 * 100, metric = 5.04% * 100;
 Minibatch[1001-1100]: loss = 0.230453 * 100, metric = 4.87% * 100;
 Minibatch[1101-1200]: loss = 0.240132 * 100, metric = 5.21% * 100;
 Minibatch[1201-1300]: loss = 0.227166 * 100, metric = 4.66% * 100;
 Minibatch[1301-1400]: loss = 0.225813 * 100, metric = 4.58% * 100;
 Minibatch[1401-1500]: loss = 0.239270 * 100, metric = 5.20% * 100;
 Minibatch[1501-1600]: loss = 0.246339 * 100, metric = 5.29% * 100;
 Minibatch[1601-1700]: loss = 0.247637 * 100, metric = 5.08% * 100;
 Minibatch[1701-1800]: loss = 0.229785 * 100, metric = 4.61% * 100;
 Minibatch[1801-1900]: loss = 0.237333 * 100, metric = 5.08% * 100;
 Minibatch[1901-2000]: loss = 0.230314 * 100, metric = 4.91% * 100;
Finished Epoch[61 of 200]: [Training] loss = 0.234596 * 2000, metric = 4.92% * 2000 929.664s (  2.2 samples/s);
Finished Evaluation [61]: Minibatch[1-2000]: metric = 13.13% * 2000;
 Minibatch[   1- 100]: loss = 0.229571 * 100, metric = 4.71% * 100;
 Minibatch[ 101- 200]: loss = 0.229114 * 100, metric = 4.75% * 100;
 Minibatch[ 201- 300]: loss = 0.235823 * 100, metric = 4.95% * 100;
 Minibatch[ 301- 400]: loss = 0.233633 * 100, metric = 4.95% * 100;
 Minibatch[ 401- 500]: loss = 0.233789 * 100, metric = 4.88% * 100;
 Minibatch[ 501- 600]: loss = 0.234834 * 100, metric = 4.81% * 100;
 Minibatch[ 601- 700]: loss = 0.237767 * 100, metric = 5.17% * 100;
 Minibatch[ 701- 800]: loss = 0.231901 * 100, metric = 4.97% * 100;
 Minibatch[ 801- 900]: loss = 0.233154 * 100, metric = 4.90% * 100;
 Minibatch[ 901-1000]: loss = 0.240609 * 100, metric = 5.07% * 100;
 Minibatch[1001-1100]: loss = 0.221616 * 100, metric = 4.62% * 100;
 Minibatch[1101-1200]: loss = 0.243003 * 100, metric = 5.23% * 100;
 Minibatch[1201-1300]: loss = 0.230855 * 100, metric = 4.95% * 100;
 Minibatch[1301-1400]: loss = 0.249135 * 100, metric = 5.19% * 100;
 Minibatch[1401-1500]: loss = 0.226448 * 100, metric = 4.64% * 100;
 Minibatch[1501-1600]: loss = 0.227170 * 100, metric = 4.57% * 100;
 Minibatch[1601-1700]: loss = 0.234547 * 100, metric = 4.97% * 100;
 Minibatch[1701-1800]: loss = 0.237192 * 100, metric = 4.89% * 100;
 Minibatch[1801-1900]: loss = 0.236615 * 100, metric = 5.03% * 100;
 Minibatch[1901-2000]: loss = 0.235841 * 100, metric = 5.04% * 100;
Finished Epoch[62 of 200]: [Training] loss = 0.234131 * 2000, metric = 4.92% * 2000 907.755s (  2.2 samples/s);
Finished Evaluation [62]: Minibatch[1-2000]: metric = 13.61% * 2000;
 Minibatch[   1- 100]: loss = 0.230095 * 100, metric = 4.73% * 100;
 Minibatch[ 101- 200]: loss = 0.223394 * 100, metric = 4.55% * 100;
 Minibatch[ 201- 300]: loss = 0.239747 * 100, metric = 5.07% * 100;
 Minibatch[ 301- 400]: loss = 0.223289 * 100, metric = 4.61% * 100;
 Minibatch[ 401- 500]: loss = 0.226376 * 100, metric = 4.74% * 100;
 Minibatch[ 501- 600]: loss = 0.229065 * 100, metric = 4.69% * 100;
 Minibatch[ 601- 700]: loss = 0.235392 * 100, metric = 5.06% * 100;
 Minibatch[ 701- 800]: loss = 0.233608 * 100, metric = 4.99% * 100;
 Minibatch[ 801- 900]: loss = 0.230804 * 100, metric = 4.88% * 100;
 Minibatch[ 901-1000]: loss = 0.224330 * 100, metric = 4.62% * 100;
 Minibatch[1001-1100]: loss = 0.234187 * 100, metric = 4.71% * 100;
 Minibatch[1101-1200]: loss = 0.224312 * 100, metric = 4.80% * 100;
 Minibatch[1201-1300]: loss = 0.235693 * 100, metric = 4.78% * 100;
 Minibatch[1301-1400]: loss = 0.233254 * 100, metric = 4.85% * 100;
 Minibatch[1401-1500]: loss = 0.219792 * 100, metric = 4.59% * 100;
 Minibatch[1501-1600]: loss = 0.237094 * 100, metric = 4.99% * 100;
 Minibatch[1601-1700]: loss = 0.229127 * 100, metric = 4.65% * 100;
 Minibatch[1701-1800]: loss = 0.225636 * 100, metric = 4.77% * 100;
 Minibatch[1801-1900]: loss = 0.227662 * 100, metric = 4.51% * 100;
 Minibatch[1901-2000]: loss = 0.232486 * 100, metric = 4.92% * 100;
Finished Epoch[63 of 200]: [Training] loss = 0.229767 * 2000, metric = 4.78% * 2000 894.762s (  2.2 samples/s);
Finished Evaluation [63]: Minibatch[1-2000]: metric = 13.96% * 2000;
 Minibatch[   1- 100]: loss = 0.228306 * 100, metric = 4.61% * 100;
 Minibatch[ 101- 200]: loss = 0.228281 * 100, metric = 4.86% * 100;
 Minibatch[ 201- 300]: loss = 0.231152 * 100, metric = 4.69% * 100;
 Minibatch[ 301- 400]: loss = 0.239219 * 100, metric = 4.93% * 100;
 Minibatch[ 401- 500]: loss = 0.231529 * 100, metric = 4.93% * 100;
 Minibatch[ 501- 600]: loss = 0.227752 * 100, metric = 4.76% * 100;
 Minibatch[ 601- 700]: loss = 0.223943 * 100, metric = 4.54% * 100;
 Minibatch[ 701- 800]: loss = 0.238130 * 100, metric = 4.95% * 100;
 Minibatch[ 801- 900]: loss = 0.233049 * 100, metric = 4.83% * 100;
 Minibatch[ 901-1000]: loss = 0.222268 * 100, metric = 4.66% * 100;
 Minibatch[1001-1100]: loss = 0.224391 * 100, metric = 4.68% * 100;
 Minibatch[1101-1200]: loss = 0.226791 * 100, metric = 4.83% * 100;
 Minibatch[1201-1300]: loss = 0.222344 * 100, metric = 4.70% * 100;
 Minibatch[1301-1400]: loss = 0.236092 * 100, metric = 5.04% * 100;
 Minibatch[1401-1500]: loss = 0.235631 * 100, metric = 5.03% * 100;
 Minibatch[1501-1600]: loss = 0.235692 * 100, metric = 5.00% * 100;
 Minibatch[1601-1700]: loss = 0.219562 * 100, metric = 4.53% * 100;
 Minibatch[1701-1800]: loss = 0.224171 * 100, metric = 4.70% * 100;
 Minibatch[1801-1900]: loss = 0.233976 * 100, metric = 5.04% * 100;
 Minibatch[1901-2000]: loss = 0.227886 * 100, metric = 4.82% * 100;
Finished Epoch[64 of 200]: [Training] loss = 0.229508 * 2000, metric = 4.81% * 2000 908.193s (  2.2 samples/s);
Finished Evaluation [64]: Minibatch[1-2000]: metric = 14.55% * 2000;
 Minibatch[   1- 100]: loss = 0.222869 * 100, metric = 4.73% * 100;
 Minibatch[ 101- 200]: loss = 0.225918 * 100, metric = 4.73% * 100;
 Minibatch[ 201- 300]: loss = 0.236840 * 100, metric = 5.01% * 100;
 Minibatch[ 301- 400]: loss = 0.232393 * 100, metric = 4.97% * 100;
 Minibatch[ 401- 500]: loss = 0.232050 * 100, metric = 4.72% * 100;
 Minibatch[ 501- 600]: loss = 0.225886 * 100, metric = 4.77% * 100;
 Minibatch[ 601- 700]: loss = 0.235897 * 100, metric = 4.83% * 100;
 Minibatch[ 701- 800]: loss = 0.241005 * 100, metric = 5.21% * 100;
 Minibatch[ 801- 900]: loss = 0.230255 * 100, metric = 4.79% * 100;
 Minibatch[ 901-1000]: loss = 0.233752 * 100, metric = 4.99% * 100;
 Minibatch[1001-1100]: loss = 0.229974 * 100, metric = 4.84% * 100;
 Minibatch[1101-1200]: loss = 0.228898 * 100, metric = 4.73% * 100;
 Minibatch[1201-1300]: loss = 0.235201 * 100, metric = 4.91% * 100;
 Minibatch[1301-1400]: loss = 0.227769 * 100, metric = 4.77% * 100;
 Minibatch[1401-1500]: loss = 0.226110 * 100, metric = 4.63% * 100;
 Minibatch[1501-1600]: loss = 0.224977 * 100, metric = 4.75% * 100;
 Minibatch[1601-1700]: loss = 0.233979 * 100, metric = 4.85% * 100;
 Minibatch[1701-1800]: loss = 0.229116 * 100, metric = 4.76% * 100;
 Minibatch[1801-1900]: loss = 0.236784 * 100, metric = 5.11% * 100;
 Minibatch[1901-2000]: loss = 0.225445 * 100, metric = 4.72% * 100;
Finished Epoch[65 of 200]: [Training] loss = 0.230756 * 2000, metric = 4.84% * 2000 902.429s (  2.2 samples/s);
Finished Evaluation [65]: Minibatch[1-2000]: metric = 12.92% * 2000;
 Minibatch[   1- 100]: loss = 0.221067 * 100, metric = 4.64% * 100;
 Minibatch[ 101- 200]: loss = 0.237212 * 100, metric = 5.08% * 100;
 Minibatch[ 201- 300]: loss = 0.231563 * 100, metric = 4.68% * 100;
 Minibatch[ 301- 400]: loss = 0.225007 * 100, metric = 4.83% * 100;
 Minibatch[ 401- 500]: loss = 0.232194 * 100, metric = 4.86% * 100;
 Minibatch[ 501- 600]: loss = 0.216880 * 100, metric = 4.39% * 100;
 Minibatch[ 601- 700]: loss = 0.220188 * 100, metric = 4.53% * 100;
 Minibatch[ 701- 800]: loss = 0.228421 * 100, metric = 4.72% * 100;
 Minibatch[ 801- 900]: loss = 0.210319 * 100, metric = 4.38% * 100;
 Minibatch[ 901-1000]: loss = 0.218243 * 100, metric = 4.35% * 100;
 Minibatch[1001-1100]: loss = 0.223710 * 100, metric = 4.56% * 100;
 Minibatch[1101-1200]: loss = 0.224735 * 100, metric = 4.85% * 100;
 Minibatch[1201-1300]: loss = 0.232477 * 100, metric = 4.83% * 100;
 Minibatch[1301-1400]: loss = 0.218430 * 100, metric = 4.46% * 100;
 Minibatch[1401-1500]: loss = 0.216396 * 100, metric = 4.39% * 100;
 Minibatch[1501-1600]: loss = 0.222686 * 100, metric = 4.64% * 100;
 Minibatch[1601-1700]: loss = 0.221866 * 100, metric = 4.54% * 100;
 Minibatch[1701-1800]: loss = 0.231863 * 100, metric = 4.89% * 100;
 Minibatch[1801-1900]: loss = 0.222744 * 100, metric = 4.74% * 100;
 Minibatch[1901-2000]: loss = 0.221644 * 100, metric = 4.80% * 100;
Finished Epoch[66 of 200]: [Training] loss = 0.223882 * 2000, metric = 4.66% * 2000 906.578s (  2.2 samples/s);
Finished Evaluation [66]: Minibatch[1-2000]: metric = 13.95% * 2000;
 Minibatch[   1- 100]: loss = 0.222157 * 100, metric = 4.55% * 100;
 Minibatch[ 101- 200]: loss = 0.216092 * 100, metric = 4.54% * 100;
 Minibatch[ 201- 300]: loss = 0.227886 * 100, metric = 4.73% * 100;
 Minibatch[ 301- 400]: loss = 0.229428 * 100, metric = 4.87% * 100;
 Minibatch[ 401- 500]: loss = 0.227213 * 100, metric = 4.69% * 100;
 Minibatch[ 501- 600]: loss = 0.227056 * 100, metric = 4.80% * 100;
 Minibatch[ 601- 700]: loss = 0.212220 * 100, metric = 4.46% * 100;
 Minibatch[ 701- 800]: loss = 0.222994 * 100, metric = 4.76% * 100;
 Minibatch[ 801- 900]: loss = 0.222984 * 100, metric = 4.67% * 100;
 Minibatch[ 901-1000]: loss = 0.228961 * 100, metric = 4.68% * 100;
 Minibatch[1001-1100]: loss = 0.220272 * 100, metric = 4.60% * 100;
 Minibatch[1101-1200]: loss = 0.225727 * 100, metric = 4.60% * 100;
 Minibatch[1201-1300]: loss = 0.221357 * 100, metric = 4.55% * 100;
 Minibatch[1301-1400]: loss = 0.226614 * 100, metric = 4.69% * 100;
 Minibatch[1401-1500]: loss = 0.212671 * 100, metric = 4.41% * 100;
 Minibatch[1501-1600]: loss = 0.222443 * 100, metric = 4.58% * 100;
 Minibatch[1601-1700]: loss = 0.213314 * 100, metric = 4.43% * 100;
 Minibatch[1701-1800]: loss = 0.229063 * 100, metric = 4.87% * 100;
 Minibatch[1801-1900]: loss = 0.215050 * 100, metric = 4.41% * 100;
 Minibatch[1901-2000]: loss = 0.229852 * 100, metric = 4.77% * 100;
Finished Epoch[67 of 200]: [Training] loss = 0.222668 * 2000, metric = 4.63% * 2000 912.146s (  2.2 samples/s);
Finished Evaluation [67]: Minibatch[1-2000]: metric = 13.13% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
