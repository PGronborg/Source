Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.304093 * 100, metric = 23.38% * 100;
 Minibatch[ 101- 200]: loss = 1.139855 * 100, metric = 22.47% * 100;
 Minibatch[ 201- 300]: loss = 1.068213 * 100, metric = 22.28% * 100;
 Minibatch[ 301- 400]: loss = 1.041923 * 100, metric = 20.94% * 100;
 Minibatch[ 401- 500]: loss = 0.997223 * 100, metric = 20.16% * 100;
 Minibatch[ 501- 600]: loss = 0.955132 * 100, metric = 18.78% * 100;
 Minibatch[ 601- 700]: loss = 0.912804 * 100, metric = 17.31% * 100;
 Minibatch[ 701- 800]: loss = 0.869075 * 100, metric = 16.35% * 100;
 Minibatch[ 801- 900]: loss = 0.906100 * 100, metric = 16.75% * 100;
 Minibatch[ 901-1000]: loss = 0.916940 * 100, metric = 17.33% * 100;
 Minibatch[1001-1100]: loss = 0.913943 * 100, metric = 16.70% * 100;
 Minibatch[1101-1200]: loss = 0.879943 * 100, metric = 16.26% * 100;
 Minibatch[1201-1300]: loss = 0.894277 * 100, metric = 17.09% * 100;
 Minibatch[1301-1400]: loss = 0.858466 * 100, metric = 16.05% * 100;
 Minibatch[1401-1500]: loss = 0.885015 * 100, metric = 16.29% * 100;
 Minibatch[1501-1600]: loss = 0.841775 * 100, metric = 15.81% * 100;
 Minibatch[1601-1700]: loss = 0.846486 * 100, metric = 15.89% * 100;
 Minibatch[1701-1800]: loss = 0.869984 * 100, metric = 16.05% * 100;
 Minibatch[1801-1900]: loss = 0.862607 * 100, metric = 16.02% * 100;
 Minibatch[1901-2000]: loss = 0.847554 * 100, metric = 15.47% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.940570 * 2000, metric = 17.87% * 2000 1039.422s (  1.9 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 22.80% * 2000;
0.8250247448906303
 Minibatch[   1- 100]: loss = 0.838862 * 100, metric = 15.13% * 100;
 Minibatch[ 101- 200]: loss = 0.851446 * 100, metric = 15.60% * 100;
 Minibatch[ 201- 300]: loss = 0.839312 * 100, metric = 15.23% * 100;
 Minibatch[ 301- 400]: loss = 0.861994 * 100, metric = 15.50% * 100;
 Minibatch[ 401- 500]: loss = 0.844309 * 100, metric = 15.38% * 100;
 Minibatch[ 501- 600]: loss = 0.864042 * 100, metric = 15.23% * 100;
 Minibatch[ 601- 700]: loss = 0.820461 * 100, metric = 15.06% * 100;
 Minibatch[ 701- 800]: loss = 0.838564 * 100, metric = 15.70% * 100;
 Minibatch[ 801- 900]: loss = 0.824977 * 100, metric = 15.06% * 100;
 Minibatch[ 901-1000]: loss = 0.793450 * 100, metric = 14.07% * 100;
 Minibatch[1001-1100]: loss = 0.829305 * 100, metric = 15.23% * 100;
 Minibatch[1101-1200]: loss = 0.815217 * 100, metric = 14.62% * 100;
 Minibatch[1201-1300]: loss = 0.809203 * 100, metric = 14.49% * 100;
 Minibatch[1301-1400]: loss = 0.822524 * 100, metric = 15.09% * 100;
 Minibatch[1401-1500]: loss = 0.796805 * 100, metric = 14.24% * 100;
 Minibatch[1501-1600]: loss = 0.791467 * 100, metric = 13.83% * 100;
 Minibatch[1601-1700]: loss = 0.799744 * 100, metric = 14.21% * 100;
 Minibatch[1701-1800]: loss = 0.805322 * 100, metric = 14.49% * 100;
 Minibatch[1801-1900]: loss = 0.807950 * 100, metric = 14.31% * 100;
 Minibatch[1901-2000]: loss = 0.780375 * 100, metric = 13.93% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.821767 * 2000, metric = 14.82% * 2000 993.466s (  2.0 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 19.16% * 2000;
0.7706148394048215
 Minibatch[   1- 100]: loss = 0.791948 * 100, metric = 14.20% * 100;
 Minibatch[ 101- 200]: loss = 0.805283 * 100, metric = 14.56% * 100;
 Minibatch[ 201- 300]: loss = 0.801646 * 100, metric = 14.36% * 100;
 Minibatch[ 301- 400]: loss = 0.811539 * 100, metric = 14.70% * 100;
 Minibatch[ 401- 500]: loss = 0.818765 * 100, metric = 14.91% * 100;
 Minibatch[ 501- 600]: loss = 0.808849 * 100, metric = 14.42% * 100;
 Minibatch[ 601- 700]: loss = 0.812955 * 100, metric = 14.22% * 100;
 Minibatch[ 701- 800]: loss = 0.771752 * 100, metric = 13.30% * 100;
 Minibatch[ 801- 900]: loss = 0.801925 * 100, metric = 14.41% * 100;
 Minibatch[ 901-1000]: loss = 0.770562 * 100, metric = 13.80% * 100;
 Minibatch[1001-1100]: loss = 0.793745 * 100, metric = 14.46% * 100;
 Minibatch[1101-1200]: loss = 0.782805 * 100, metric = 13.87% * 100;
 Minibatch[1201-1300]: loss = 0.771726 * 100, metric = 13.71% * 100;
 Minibatch[1301-1400]: loss = 0.789653 * 100, metric = 14.03% * 100;
 Minibatch[1401-1500]: loss = 0.801851 * 100, metric = 14.20% * 100;
 Minibatch[1501-1600]: loss = 0.779038 * 100, metric = 13.67% * 100;
 Minibatch[1601-1700]: loss = 0.762098 * 100, metric = 13.21% * 100;
 Minibatch[1701-1800]: loss = 0.793984 * 100, metric = 13.99% * 100;
 Minibatch[1801-1900]: loss = 0.773961 * 100, metric = 13.44% * 100;
 Minibatch[1901-2000]: loss = 0.778536 * 100, metric = 13.55% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.791131 * 2000, metric = 14.05% * 2000 985.943s (  2.0 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 20.41% * 2000;
 Minibatch[   1- 100]: loss = 0.799338 * 100, metric = 13.59% * 100;
 Minibatch[ 101- 200]: loss = 0.761143 * 100, metric = 13.25% * 100;
 Minibatch[ 201- 300]: loss = 0.781558 * 100, metric = 13.90% * 100;
 Minibatch[ 301- 400]: loss = 0.747484 * 100, metric = 12.94% * 100;
 Minibatch[ 401- 500]: loss = 0.775496 * 100, metric = 13.83% * 100;
 Minibatch[ 501- 600]: loss = 0.755870 * 100, metric = 12.96% * 100;
 Minibatch[ 601- 700]: loss = 0.760423 * 100, metric = 13.47% * 100;
 Minibatch[ 701- 800]: loss = 0.774310 * 100, metric = 13.54% * 100;
 Minibatch[ 801- 900]: loss = 0.769028 * 100, metric = 13.45% * 100;
 Minibatch[ 901-1000]: loss = 0.766697 * 100, metric = 13.48% * 100;
 Minibatch[1001-1100]: loss = 0.779456 * 100, metric = 13.97% * 100;
 Minibatch[1101-1200]: loss = 0.760193 * 100, metric = 13.18% * 100;
 Minibatch[1201-1300]: loss = 0.764260 * 100, metric = 13.14% * 100;
 Minibatch[1301-1400]: loss = 0.786205 * 100, metric = 13.79% * 100;
 Minibatch[1401-1500]: loss = 0.782222 * 100, metric = 13.73% * 100;
 Minibatch[1501-1600]: loss = 0.747305 * 100, metric = 12.98% * 100;
 Minibatch[1601-1700]: loss = 0.777396 * 100, metric = 13.71% * 100;
 Minibatch[1701-1800]: loss = 0.778942 * 100, metric = 13.73% * 100;
 Minibatch[1801-1900]: loss = 0.763689 * 100, metric = 13.53% * 100;
 Minibatch[1901-2000]: loss = 0.758456 * 100, metric = 13.13% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.769474 * 2000, metric = 13.46% * 2000 999.702s (  2.0 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 20.43% * 2000;
 Minibatch[   1- 100]: loss = 0.793858 * 100, metric = 13.97% * 100;
 Minibatch[ 101- 200]: loss = 0.764836 * 100, metric = 13.50% * 100;
 Minibatch[ 201- 300]: loss = 0.754358 * 100, metric = 13.33% * 100;
 Minibatch[ 301- 400]: loss = 0.798652 * 100, metric = 14.28% * 100;
 Minibatch[ 401- 500]: loss = 0.740522 * 100, metric = 12.52% * 100;
 Minibatch[ 501- 600]: loss = 0.751413 * 100, metric = 12.82% * 100;
 Minibatch[ 601- 700]: loss = 0.766496 * 100, metric = 13.10% * 100;
 Minibatch[ 701- 800]: loss = 0.775916 * 100, metric = 13.44% * 100;
 Minibatch[ 801- 900]: loss = 0.750447 * 100, metric = 12.76% * 100;
 Minibatch[ 901-1000]: loss = 0.750961 * 100, metric = 13.04% * 100;
 Minibatch[1001-1100]: loss = 0.757683 * 100, metric = 13.04% * 100;
 Minibatch[1101-1200]: loss = 0.742106 * 100, metric = 12.62% * 100;
 Minibatch[1201-1300]: loss = 0.760873 * 100, metric = 12.97% * 100;
 Minibatch[1301-1400]: loss = 0.791369 * 100, metric = 13.70% * 100;
 Minibatch[1401-1500]: loss = 0.754850 * 100, metric = 12.81% * 100;
 Minibatch[1501-1600]: loss = 0.758065 * 100, metric = 13.12% * 100;
 Minibatch[1601-1700]: loss = 0.775270 * 100, metric = 13.63% * 100;
 Minibatch[1701-1800]: loss = 0.770801 * 100, metric = 13.42% * 100;
 Minibatch[1801-1900]: loss = 0.769226 * 100, metric = 13.34% * 100;
 Minibatch[1901-2000]: loss = 0.748926 * 100, metric = 12.88% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.763831 * 2000, metric = 13.21% * 2000 1010.022s (  2.0 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.85% * 2000;
 Minibatch[   1- 100]: loss = 0.748908 * 100, metric = 12.88% * 100;
 Minibatch[ 101- 200]: loss = 0.738251 * 100, metric = 12.81% * 100;
 Minibatch[ 201- 300]: loss = 0.751036 * 100, metric = 12.85% * 100;
 Minibatch[ 301- 400]: loss = 0.751840 * 100, metric = 12.64% * 100;
 Minibatch[ 401- 500]: loss = 0.731597 * 100, metric = 12.33% * 100;
 Minibatch[ 501- 600]: loss = 0.750048 * 100, metric = 13.14% * 100;
 Minibatch[ 601- 700]: loss = 0.743502 * 100, metric = 12.76% * 100;
 Minibatch[ 701- 800]: loss = 0.753236 * 100, metric = 13.08% * 100;
 Minibatch[ 801- 900]: loss = 0.747585 * 100, metric = 12.86% * 100;
 Minibatch[ 901-1000]: loss = 0.736165 * 100, metric = 12.90% * 100;
 Minibatch[1001-1100]: loss = 0.749304 * 100, metric = 12.53% * 100;
 Minibatch[1101-1200]: loss = 0.755205 * 100, metric = 12.98% * 100;
 Minibatch[1201-1300]: loss = 0.770869 * 100, metric = 13.39% * 100;
 Minibatch[1301-1400]: loss = 0.743101 * 100, metric = 12.89% * 100;
 Minibatch[1401-1500]: loss = 0.750032 * 100, metric = 12.92% * 100;
 Minibatch[1501-1600]: loss = 0.739154 * 100, metric = 12.52% * 100;
 Minibatch[1601-1700]: loss = 0.735352 * 100, metric = 12.37% * 100;
 Minibatch[1701-1800]: loss = 0.723965 * 100, metric = 12.27% * 100;
 Minibatch[1801-1900]: loss = 0.744442 * 100, metric = 12.82% * 100;
 Minibatch[1901-2000]: loss = 0.726902 * 100, metric = 12.32% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.744525 * 2000, metric = 12.76% * 2000 998.620s (  2.0 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.74% * 2000;
 Minibatch[   1- 100]: loss = 0.737631 * 100, metric = 12.59% * 100;
 Minibatch[ 101- 200]: loss = 0.745593 * 100, metric = 12.74% * 100;
 Minibatch[ 201- 300]: loss = 0.744552 * 100, metric = 12.79% * 100;
 Minibatch[ 301- 400]: loss = 0.731102 * 100, metric = 12.57% * 100;
 Minibatch[ 401- 500]: loss = 0.742173 * 100, metric = 12.59% * 100;
 Minibatch[ 501- 600]: loss = 0.722722 * 100, metric = 12.28% * 100;
 Minibatch[ 601- 700]: loss = 0.736859 * 100, metric = 12.24% * 100;
 Minibatch[ 701- 800]: loss = 0.740927 * 100, metric = 12.47% * 100;
 Minibatch[ 801- 900]: loss = 0.737929 * 100, metric = 12.67% * 100;
 Minibatch[ 901-1000]: loss = 0.729385 * 100, metric = 12.45% * 100;
 Minibatch[1001-1100]: loss = 0.728402 * 100, metric = 12.24% * 100;
 Minibatch[1101-1200]: loss = 0.712712 * 100, metric = 11.96% * 100;
 Minibatch[1201-1300]: loss = 0.736685 * 100, metric = 12.66% * 100;
 Minibatch[1301-1400]: loss = 0.725755 * 100, metric = 12.38% * 100;
 Minibatch[1401-1500]: loss = 0.711973 * 100, metric = 12.08% * 100;
 Minibatch[1501-1600]: loss = 0.729277 * 100, metric = 12.25% * 100;
 Minibatch[1601-1700]: loss = 0.740956 * 100, metric = 12.75% * 100;
 Minibatch[1701-1800]: loss = 0.718961 * 100, metric = 11.98% * 100;
 Minibatch[1801-1900]: loss = 0.724392 * 100, metric = 12.67% * 100;
 Minibatch[1901-2000]: loss = 0.730652 * 100, metric = 12.69% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.731432 * 2000, metric = 12.45% * 2000 991.018s (  2.0 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 19.03% * 2000;
0.762887881822884
 Minibatch[   1- 100]: loss = 0.732645 * 100, metric = 12.46% * 100;
 Minibatch[ 101- 200]: loss = 0.730414 * 100, metric = 12.35% * 100;
 Minibatch[ 201- 300]: loss = 0.713648 * 100, metric = 12.04% * 100;
 Minibatch[ 301- 400]: loss = 0.717305 * 100, metric = 12.23% * 100;
 Minibatch[ 401- 500]: loss = 0.723442 * 100, metric = 12.56% * 100;
 Minibatch[ 501- 600]: loss = 0.745383 * 100, metric = 12.84% * 100;
 Minibatch[ 601- 700]: loss = 0.707497 * 100, metric = 12.24% * 100;
 Minibatch[ 701- 800]: loss = 0.729556 * 100, metric = 12.19% * 100;
 Minibatch[ 801- 900]: loss = 0.699019 * 100, metric = 11.56% * 100;
 Minibatch[ 901-1000]: loss = 0.690905 * 100, metric = 11.34% * 100;
 Minibatch[1001-1100]: loss = 0.696012 * 100, metric = 11.71% * 100;
 Minibatch[1101-1200]: loss = 0.699338 * 100, metric = 11.84% * 100;
 Minibatch[1201-1300]: loss = 0.719404 * 100, metric = 12.13% * 100;
 Minibatch[1301-1400]: loss = 0.726906 * 100, metric = 12.40% * 100;
 Minibatch[1401-1500]: loss = 0.709082 * 100, metric = 11.91% * 100;
 Minibatch[1501-1600]: loss = 0.720845 * 100, metric = 12.15% * 100;
 Minibatch[1601-1700]: loss = 0.708246 * 100, metric = 11.94% * 100;
 Minibatch[1701-1800]: loss = 0.701499 * 100, metric = 11.68% * 100;
 Minibatch[1801-1900]: loss = 0.713262 * 100, metric = 12.00% * 100;
 Minibatch[1901-2000]: loss = 0.701626 * 100, metric = 11.64% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.714302 * 2000, metric = 12.06% * 2000 988.206s (  2.0 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 18.75% * 2000;
0.7421471998021006
 Minibatch[   1- 100]: loss = 0.683628 * 100, metric = 11.09% * 100;
 Minibatch[ 101- 200]: loss = 0.723634 * 100, metric = 12.25% * 100;
 Minibatch[ 201- 300]: loss = 0.706158 * 100, metric = 11.66% * 100;
 Minibatch[ 301- 400]: loss = 0.724113 * 100, metric = 12.49% * 100;
 Minibatch[ 401- 500]: loss = 0.705375 * 100, metric = 11.63% * 100;
 Minibatch[ 501- 600]: loss = 0.686649 * 100, metric = 11.48% * 100;
 Minibatch[ 601- 700]: loss = 0.683511 * 100, metric = 11.61% * 100;
 Minibatch[ 701- 800]: loss = 0.676278 * 100, metric = 11.21% * 100;
 Minibatch[ 801- 900]: loss = 0.683690 * 100, metric = 11.58% * 100;
 Minibatch[ 901-1000]: loss = 0.699294 * 100, metric = 11.80% * 100;
 Minibatch[1001-1100]: loss = 0.674202 * 100, metric = 11.11% * 100;
 Minibatch[1101-1200]: loss = 0.699525 * 100, metric = 11.62% * 100;
 Minibatch[1201-1300]: loss = 0.702117 * 100, metric = 12.02% * 100;
 Minibatch[1301-1400]: loss = 0.688373 * 100, metric = 11.18% * 100;
 Minibatch[1401-1500]: loss = 0.700967 * 100, metric = 11.86% * 100;
 Minibatch[1501-1600]: loss = 0.702732 * 100, metric = 11.62% * 100;
 Minibatch[1601-1700]: loss = 0.696554 * 100, metric = 11.69% * 100;
 Minibatch[1701-1800]: loss = 0.687500 * 100, metric = 11.28% * 100;
 Minibatch[1801-1900]: loss = 0.695479 * 100, metric = 11.84% * 100;
 Minibatch[1901-2000]: loss = 0.704895 * 100, metric = 11.97% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.696234 * 2000, metric = 11.65% * 2000 999.648s (  2.0 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 17.52% * 2000;
0.7254744999930263
 Minibatch[   1- 100]: loss = 0.726668 * 100, metric = 12.76% * 100;
 Minibatch[ 101- 200]: loss = 0.686097 * 100, metric = 11.54% * 100;
 Minibatch[ 201- 300]: loss = 0.700269 * 100, metric = 11.93% * 100;
 Minibatch[ 301- 400]: loss = 0.690673 * 100, metric = 11.58% * 100;
 Minibatch[ 401- 500]: loss = 0.697447 * 100, metric = 11.88% * 100;
 Minibatch[ 501- 600]: loss = 0.679975 * 100, metric = 11.24% * 100;
 Minibatch[ 601- 700]: loss = 0.676201 * 100, metric = 11.11% * 100;
 Minibatch[ 701- 800]: loss = 0.678760 * 100, metric = 11.03% * 100;
 Minibatch[ 801- 900]: loss = 0.693557 * 100, metric = 11.46% * 100;
 Minibatch[ 901-1000]: loss = 0.697941 * 100, metric = 11.69% * 100;
 Minibatch[1001-1100]: loss = 0.694664 * 100, metric = 11.90% * 100;
 Minibatch[1101-1200]: loss = 0.693645 * 100, metric = 11.39% * 100;
 Minibatch[1201-1300]: loss = 0.691855 * 100, metric = 11.66% * 100;
 Minibatch[1301-1400]: loss = 0.691381 * 100, metric = 11.84% * 100;
 Minibatch[1401-1500]: loss = 0.676908 * 100, metric = 11.26% * 100;
 Minibatch[1501-1600]: loss = 0.685546 * 100, metric = 11.92% * 100;
 Minibatch[1601-1700]: loss = 0.682611 * 100, metric = 11.14% * 100;
 Minibatch[1701-1800]: loss = 0.688922 * 100, metric = 11.66% * 100;
 Minibatch[1801-1900]: loss = 0.693801 * 100, metric = 11.73% * 100;
 Minibatch[1901-2000]: loss = 0.673416 * 100, metric = 11.49% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.690017 * 2000, metric = 11.61% * 2000 997.572s (  2.0 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 17.07% * 2000;
0.7186775793433189
 Minibatch[   1- 100]: loss = 0.678374 * 100, metric = 11.17% * 100;
 Minibatch[ 101- 200]: loss = 0.681061 * 100, metric = 11.11% * 100;
 Minibatch[ 201- 300]: loss = 0.693827 * 100, metric = 11.76% * 100;
 Minibatch[ 301- 400]: loss = 0.683508 * 100, metric = 11.26% * 100;
 Minibatch[ 401- 500]: loss = 0.681093 * 100, metric = 11.31% * 100;
 Minibatch[ 501- 600]: loss = 0.691251 * 100, metric = 11.78% * 100;
 Minibatch[ 601- 700]: loss = 0.676376 * 100, metric = 11.40% * 100;
 Minibatch[ 701- 800]: loss = 0.685698 * 100, metric = 11.72% * 100;
 Minibatch[ 801- 900]: loss = 0.681085 * 100, metric = 11.51% * 100;
 Minibatch[ 901-1000]: loss = 0.692867 * 100, metric = 11.68% * 100;
 Minibatch[1001-1100]: loss = 0.676543 * 100, metric = 11.34% * 100;
 Minibatch[1101-1200]: loss = 0.684763 * 100, metric = 11.53% * 100;
 Minibatch[1201-1300]: loss = 0.670406 * 100, metric = 11.18% * 100;
 Minibatch[1301-1400]: loss = 0.659494 * 100, metric = 10.98% * 100;
 Minibatch[1401-1500]: loss = 0.682742 * 100, metric = 11.47% * 100;
 Minibatch[1501-1600]: loss = 0.673727 * 100, metric = 11.16% * 100;
 Minibatch[1601-1700]: loss = 0.667271 * 100, metric = 11.07% * 100;
 Minibatch[1701-1800]: loss = 0.687687 * 100, metric = 11.51% * 100;
 Minibatch[1801-1900]: loss = 0.669581 * 100, metric = 11.30% * 100;
 Minibatch[1901-2000]: loss = 0.670037 * 100, metric = 11.24% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.679370 * 2000, metric = 11.37% * 2000 992.441s (  2.0 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 17.66% * 2000;
 Minibatch[   1- 100]: loss = 0.653121 * 100, metric = 11.03% * 100;
 Minibatch[ 101- 200]: loss = 0.665883 * 100, metric = 10.91% * 100;
 Minibatch[ 201- 300]: loss = 0.666055 * 100, metric = 11.21% * 100;
 Minibatch[ 301- 400]: loss = 0.701210 * 100, metric = 12.14% * 100;
 Minibatch[ 401- 500]: loss = 0.670624 * 100, metric = 11.21% * 100;
 Minibatch[ 501- 600]: loss = 0.652193 * 100, metric = 10.53% * 100;
 Minibatch[ 601- 700]: loss = 0.653501 * 100, metric = 10.93% * 100;
 Minibatch[ 701- 800]: loss = 0.669283 * 100, metric = 11.24% * 100;
 Minibatch[ 801- 900]: loss = 0.661340 * 100, metric = 10.76% * 100;
 Minibatch[ 901-1000]: loss = 0.676275 * 100, metric = 11.28% * 100;
 Minibatch[1001-1100]: loss = 0.673678 * 100, metric = 11.22% * 100;
 Minibatch[1101-1200]: loss = 0.669270 * 100, metric = 11.06% * 100;
 Minibatch[1201-1300]: loss = 0.676897 * 100, metric = 11.42% * 100;
 Minibatch[1301-1400]: loss = 0.664012 * 100, metric = 10.79% * 100;
 Minibatch[1401-1500]: loss = 0.675602 * 100, metric = 11.40% * 100;
 Minibatch[1501-1600]: loss = 0.640703 * 100, metric = 10.55% * 100;
 Minibatch[1601-1700]: loss = 0.665677 * 100, metric = 11.08% * 100;
 Minibatch[1701-1800]: loss = 0.653300 * 100, metric = 10.69% * 100;
 Minibatch[1801-1900]: loss = 0.656116 * 100, metric = 10.80% * 100;
 Minibatch[1901-2000]: loss = 0.671223 * 100, metric = 11.51% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.665798 * 2000, metric = 11.09% * 2000 979.750s (  2.0 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 18.40% * 2000;
 Minibatch[   1- 100]: loss = 0.664748 * 100, metric = 11.12% * 100;
 Minibatch[ 101- 200]: loss = 0.668005 * 100, metric = 11.21% * 100;
 Minibatch[ 201- 300]: loss = 0.662659 * 100, metric = 11.27% * 100;
 Minibatch[ 301- 400]: loss = 0.668768 * 100, metric = 11.04% * 100;
 Minibatch[ 401- 500]: loss = 0.667689 * 100, metric = 11.52% * 100;
 Minibatch[ 501- 600]: loss = 0.673537 * 100, metric = 11.57% * 100;
 Minibatch[ 601- 700]: loss = 0.643850 * 100, metric = 10.24% * 100;
 Minibatch[ 701- 800]: loss = 0.648244 * 100, metric = 10.59% * 100;
 Minibatch[ 801- 900]: loss = 0.653484 * 100, metric = 10.73% * 100;
 Minibatch[ 901-1000]: loss = 0.667377 * 100, metric = 11.04% * 100;
 Minibatch[1001-1100]: loss = 0.661484 * 100, metric = 10.82% * 100;
 Minibatch[1101-1200]: loss = 0.657392 * 100, metric = 10.88% * 100;
 Minibatch[1201-1300]: loss = 0.659020 * 100, metric = 11.11% * 100;
 Minibatch[1301-1400]: loss = 0.654014 * 100, metric = 10.72% * 100;
 Minibatch[1401-1500]: loss = 0.644130 * 100, metric = 10.55% * 100;
 Minibatch[1501-1600]: loss = 0.644532 * 100, metric = 10.43% * 100;
 Minibatch[1601-1700]: loss = 0.633951 * 100, metric = 10.31% * 100;
 Minibatch[1701-1800]: loss = 0.648729 * 100, metric = 10.52% * 100;
 Minibatch[1801-1900]: loss = 0.647998 * 100, metric = 10.75% * 100;
 Minibatch[1901-2000]: loss = 0.652308 * 100, metric = 11.01% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.656096 * 2000, metric = 10.87% * 2000 1004.607s (  2.0 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 18.98% * 2000;
 Minibatch[   1- 100]: loss = 0.649152 * 100, metric = 10.62% * 100;
 Minibatch[ 101- 200]: loss = 0.636821 * 100, metric = 10.41% * 100;
 Minibatch[ 201- 300]: loss = 0.662050 * 100, metric = 11.13% * 100;
 Minibatch[ 301- 400]: loss = 0.651388 * 100, metric = 10.88% * 100;
 Minibatch[ 401- 500]: loss = 0.634369 * 100, metric = 10.54% * 100;
 Minibatch[ 501- 600]: loss = 0.651447 * 100, metric = 11.03% * 100;
 Minibatch[ 601- 700]: loss = 0.637918 * 100, metric = 10.63% * 100;
 Minibatch[ 701- 800]: loss = 0.658599 * 100, metric = 11.12% * 100;
 Minibatch[ 801- 900]: loss = 0.662469 * 100, metric = 11.25% * 100;
 Minibatch[ 901-1000]: loss = 0.658498 * 100, metric = 11.18% * 100;
 Minibatch[1001-1100]: loss = 0.652866 * 100, metric = 11.06% * 100;
 Minibatch[1101-1200]: loss = 0.640316 * 100, metric = 10.54% * 100;
 Minibatch[1201-1300]: loss = 0.625079 * 100, metric = 10.03% * 100;
 Minibatch[1301-1400]: loss = 0.649728 * 100, metric = 10.89% * 100;
 Minibatch[1401-1500]: loss = 0.649512 * 100, metric = 10.84% * 100;
 Minibatch[1501-1600]: loss = 0.624514 * 100, metric = 10.15% * 100;
 Minibatch[1601-1700]: loss = 0.639702 * 100, metric = 10.32% * 100;
 Minibatch[1701-1800]: loss = 0.639824 * 100, metric = 10.50% * 100;
 Minibatch[1801-1900]: loss = 0.638899 * 100, metric = 10.52% * 100;
 Minibatch[1901-2000]: loss = 0.644501 * 100, metric = 10.38% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.645383 * 2000, metric = 10.70% * 2000 981.327s (  2.0 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 18.89% * 2000;
 Minibatch[   1- 100]: loss = 0.630904 * 100, metric = 10.49% * 100;
 Minibatch[ 101- 200]: loss = 0.641958 * 100, metric = 10.97% * 100;
 Minibatch[ 201- 300]: loss = 0.639240 * 100, metric = 10.70% * 100;
 Minibatch[ 301- 400]: loss = 0.617981 * 100, metric = 10.13% * 100;
 Minibatch[ 401- 500]: loss = 0.626971 * 100, metric = 10.49% * 100;
 Minibatch[ 501- 600]: loss = 0.619768 * 100, metric = 9.90% * 100;
 Minibatch[ 601- 700]: loss = 0.614110 * 100, metric = 10.18% * 100;
 Minibatch[ 701- 800]: loss = 0.639897 * 100, metric = 10.56% * 100;
 Minibatch[ 801- 900]: loss = 0.639940 * 100, metric = 10.84% * 100;
 Minibatch[ 901-1000]: loss = 0.631492 * 100, metric = 10.51% * 100;
 Minibatch[1001-1100]: loss = 0.633664 * 100, metric = 10.17% * 100;
 Minibatch[1101-1200]: loss = 0.624378 * 100, metric = 10.21% * 100;
 Minibatch[1201-1300]: loss = 0.613522 * 100, metric = 9.59% * 100;
 Minibatch[1301-1400]: loss = 0.644835 * 100, metric = 10.86% * 100;
 Minibatch[1401-1500]: loss = 0.597627 * 100, metric = 9.74% * 100;
 Minibatch[1501-1600]: loss = 0.618275 * 100, metric = 10.14% * 100;
 Minibatch[1601-1700]: loss = 0.626057 * 100, metric = 10.18% * 100;
 Minibatch[1701-1800]: loss = 0.606010 * 100, metric = 9.77% * 100;
 Minibatch[1801-1900]: loss = 0.621749 * 100, metric = 10.44% * 100;
 Minibatch[1901-2000]: loss = 0.608328 * 100, metric = 10.06% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.624835 * 2000, metric = 10.30% * 2000 995.621s (  2.0 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 17.09% * 2000;
0.7162480318024754
 Minibatch[   1- 100]: loss = 0.642484 * 100, metric = 10.96% * 100;
 Minibatch[ 101- 200]: loss = 0.637157 * 100, metric = 10.44% * 100;
 Minibatch[ 201- 300]: loss = 0.618499 * 100, metric = 10.28% * 100;
 Minibatch[ 301- 400]: loss = 0.628354 * 100, metric = 10.27% * 100;
 Minibatch[ 401- 500]: loss = 0.591714 * 100, metric = 9.53% * 100;
 Minibatch[ 501- 600]: loss = 0.612990 * 100, metric = 9.91% * 100;
 Minibatch[ 601- 700]: loss = 0.614503 * 100, metric = 9.96% * 100;
 Minibatch[ 701- 800]: loss = 0.600882 * 100, metric = 9.70% * 100;
 Minibatch[ 801- 900]: loss = 0.603730 * 100, metric = 9.84% * 100;
 Minibatch[ 901-1000]: loss = 0.622475 * 100, metric = 10.59% * 100;
 Minibatch[1001-1100]: loss = 0.606194 * 100, metric = 10.03% * 100;
 Minibatch[1101-1200]: loss = 0.611493 * 100, metric = 10.03% * 100;
 Minibatch[1201-1300]: loss = 0.611683 * 100, metric = 9.90% * 100;
 Minibatch[1301-1400]: loss = 0.611782 * 100, metric = 10.04% * 100;
 Minibatch[1401-1500]: loss = 0.604598 * 100, metric = 10.15% * 100;
 Minibatch[1501-1600]: loss = 0.611912 * 100, metric = 10.12% * 100;
 Minibatch[1601-1700]: loss = 0.620087 * 100, metric = 10.37% * 100;
 Minibatch[1701-1800]: loss = 0.632633 * 100, metric = 10.36% * 100;
 Minibatch[1801-1900]: loss = 0.618262 * 100, metric = 10.32% * 100;
 Minibatch[1901-2000]: loss = 0.599290 * 100, metric = 9.91% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.615036 * 2000, metric = 10.14% * 2000 980.406s (  2.0 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 16.98% * 2000;
0.7039068268984556
 Minibatch[   1- 100]: loss = 0.595946 * 100, metric = 9.59% * 100;
 Minibatch[ 101- 200]: loss = 0.623985 * 100, metric = 10.54% * 100;
 Minibatch[ 201- 300]: loss = 0.619592 * 100, metric = 10.28% * 100;
 Minibatch[ 301- 400]: loss = 0.619204 * 100, metric = 10.45% * 100;
 Minibatch[ 401- 500]: loss = 0.625460 * 100, metric = 10.19% * 100;
 Minibatch[ 501- 600]: loss = 0.604060 * 100, metric = 9.76% * 100;
 Minibatch[ 601- 700]: loss = 0.583926 * 100, metric = 9.24% * 100;
 Minibatch[ 701- 800]: loss = 0.603795 * 100, metric = 9.88% * 100;
 Minibatch[ 801- 900]: loss = 0.607539 * 100, metric = 10.22% * 100;
 Minibatch[ 901-1000]: loss = 0.603804 * 100, metric = 9.98% * 100;
 Minibatch[1001-1100]: loss = 0.599653 * 100, metric = 9.80% * 100;
 Minibatch[1101-1200]: loss = 0.622284 * 100, metric = 10.28% * 100;
 Minibatch[1201-1300]: loss = 0.612466 * 100, metric = 10.18% * 100;
 Minibatch[1301-1400]: loss = 0.599417 * 100, metric = 9.57% * 100;
 Minibatch[1401-1500]: loss = 0.607090 * 100, metric = 10.20% * 100;
 Minibatch[1501-1600]: loss = 0.609083 * 100, metric = 9.99% * 100;
 Minibatch[1601-1700]: loss = 0.607934 * 100, metric = 9.87% * 100;
 Minibatch[1701-1800]: loss = 0.595275 * 100, metric = 9.71% * 100;
 Minibatch[1801-1900]: loss = 0.621445 * 100, metric = 10.37% * 100;
 Minibatch[1901-2000]: loss = 0.622355 * 100, metric = 10.43% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.609216 * 2000, metric = 10.03% * 2000 989.242s (  2.0 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 16.17% * 2000;
0.6899878970384598
 Minibatch[   1- 100]: loss = 0.588969 * 100, metric = 9.42% * 100;
 Minibatch[ 101- 200]: loss = 0.617296 * 100, metric = 10.23% * 100;
 Minibatch[ 201- 300]: loss = 0.594670 * 100, metric = 9.72% * 100;
 Minibatch[ 301- 400]: loss = 0.603676 * 100, metric = 9.86% * 100;
 Minibatch[ 401- 500]: loss = 0.586781 * 100, metric = 9.44% * 100;
 Minibatch[ 501- 600]: loss = 0.592637 * 100, metric = 9.58% * 100;
 Minibatch[ 601- 700]: loss = 0.597720 * 100, metric = 9.70% * 100;
 Minibatch[ 701- 800]: loss = 0.582330 * 100, metric = 9.43% * 100;
 Minibatch[ 801- 900]: loss = 0.600854 * 100, metric = 9.54% * 100;
 Minibatch[ 901-1000]: loss = 0.609551 * 100, metric = 9.93% * 100;
 Minibatch[1001-1100]: loss = 0.601335 * 100, metric = 10.00% * 100;
 Minibatch[1101-1200]: loss = 0.601417 * 100, metric = 9.85% * 100;
 Minibatch[1201-1300]: loss = 0.610958 * 100, metric = 10.44% * 100;
 Minibatch[1301-1400]: loss = 0.609273 * 100, metric = 10.07% * 100;
 Minibatch[1401-1500]: loss = 0.580532 * 100, metric = 9.14% * 100;
 Minibatch[1501-1600]: loss = 0.590403 * 100, metric = 9.50% * 100;
 Minibatch[1601-1700]: loss = 0.578380 * 100, metric = 9.27% * 100;
 Minibatch[1701-1800]: loss = 0.588225 * 100, metric = 9.60% * 100;
 Minibatch[1801-1900]: loss = 0.569089 * 100, metric = 9.46% * 100;
 Minibatch[1901-2000]: loss = 0.578745 * 100, metric = 9.20% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.594142 * 2000, metric = 9.67% * 2000 998.505s (  2.0 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 17.90% * 2000;
 Minibatch[   1- 100]: loss = 0.598390 * 100, metric = 9.97% * 100;
 Minibatch[ 101- 200]: loss = 0.600910 * 100, metric = 9.84% * 100;
 Minibatch[ 201- 300]: loss = 0.572392 * 100, metric = 8.94% * 100;
 Minibatch[ 301- 400]: loss = 0.593492 * 100, metric = 9.51% * 100;
 Minibatch[ 401- 500]: loss = 0.587862 * 100, metric = 9.46% * 100;
 Minibatch[ 501- 600]: loss = 0.578097 * 100, metric = 9.06% * 100;
 Minibatch[ 601- 700]: loss = 0.590339 * 100, metric = 9.72% * 100;
 Minibatch[ 701- 800]: loss = 0.567899 * 100, metric = 9.07% * 100;
 Minibatch[ 801- 900]: loss = 0.611013 * 100, metric = 10.12% * 100;
 Minibatch[ 901-1000]: loss = 0.582669 * 100, metric = 9.37% * 100;
 Minibatch[1001-1100]: loss = 0.601517 * 100, metric = 10.04% * 100;
 Minibatch[1101-1200]: loss = 0.591274 * 100, metric = 9.79% * 100;
 Minibatch[1201-1300]: loss = 0.581481 * 100, metric = 9.45% * 100;
 Minibatch[1301-1400]: loss = 0.571913 * 100, metric = 9.21% * 100;
 Minibatch[1401-1500]: loss = 0.594906 * 100, metric = 9.70% * 100;
 Minibatch[1501-1600]: loss = 0.596584 * 100, metric = 9.77% * 100;
 Minibatch[1601-1700]: loss = 0.573654 * 100, metric = 9.40% * 100;
 Minibatch[1701-1800]: loss = 0.556375 * 100, metric = 8.67% * 100;
 Minibatch[1801-1900]: loss = 0.571912 * 100, metric = 9.18% * 100;
 Minibatch[1901-2000]: loss = 0.565474 * 100, metric = 9.02% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.584408 * 2000, metric = 9.46% * 2000 977.775s (  2.0 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 17.70% * 2000;
 Minibatch[   1- 100]: loss = 0.571311 * 100, metric = 8.85% * 100;
 Minibatch[ 101- 200]: loss = 0.576552 * 100, metric = 9.25% * 100;
 Minibatch[ 201- 300]: loss = 0.574972 * 100, metric = 9.19% * 100;
 Minibatch[ 301- 400]: loss = 0.595234 * 100, metric = 9.57% * 100;
 Minibatch[ 401- 500]: loss = 0.570913 * 100, metric = 9.05% * 100;
 Minibatch[ 501- 600]: loss = 0.588138 * 100, metric = 9.66% * 100;
 Minibatch[ 601- 700]: loss = 0.586474 * 100, metric = 9.51% * 100;
 Minibatch[ 701- 800]: loss = 0.583902 * 100, metric = 9.46% * 100;
 Minibatch[ 801- 900]: loss = 0.587593 * 100, metric = 9.44% * 100;
 Minibatch[ 901-1000]: loss = 0.591951 * 100, metric = 9.54% * 100;
 Minibatch[1001-1100]: loss = 0.558324 * 100, metric = 8.73% * 100;
 Minibatch[1101-1200]: loss = 0.573221 * 100, metric = 9.02% * 100;
 Minibatch[1201-1300]: loss = 0.576559 * 100, metric = 9.26% * 100;
 Minibatch[1301-1400]: loss = 0.579429 * 100, metric = 9.56% * 100;
 Minibatch[1401-1500]: loss = 0.558909 * 100, metric = 8.92% * 100;
 Minibatch[1501-1600]: loss = 0.585338 * 100, metric = 9.29% * 100;
 Minibatch[1601-1700]: loss = 0.567069 * 100, metric = 9.12% * 100;
 Minibatch[1701-1800]: loss = 0.579200 * 100, metric = 9.58% * 100;
 Minibatch[1801-1900]: loss = 0.567966 * 100, metric = 9.32% * 100;
 Minibatch[1901-2000]: loss = 0.569694 * 100, metric = 9.09% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.577137 * 2000, metric = 9.27% * 2000 957.152s (  2.1 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 17.12% * 2000;
 Minibatch[   1- 100]: loss = 0.576569 * 100, metric = 9.39% * 100;
 Minibatch[ 101- 200]: loss = 0.583368 * 100, metric = 9.52% * 100;
 Minibatch[ 201- 300]: loss = 0.572044 * 100, metric = 9.18% * 100;
 Minibatch[ 301- 400]: loss = 0.583129 * 100, metric = 9.59% * 100;
 Minibatch[ 401- 500]: loss = 0.573595 * 100, metric = 9.09% * 100;
 Minibatch[ 501- 600]: loss = 0.567661 * 100, metric = 9.10% * 100;
 Minibatch[ 601- 700]: loss = 0.563597 * 100, metric = 9.11% * 100;
 Minibatch[ 701- 800]: loss = 0.538795 * 100, metric = 8.45% * 100;
 Minibatch[ 801- 900]: loss = 0.573277 * 100, metric = 9.16% * 100;
 Minibatch[ 901-1000]: loss = 0.561594 * 100, metric = 9.09% * 100;
 Minibatch[1001-1100]: loss = 0.568313 * 100, metric = 9.26% * 100;
 Minibatch[1101-1200]: loss = 0.553682 * 100, metric = 8.82% * 100;
 Minibatch[1201-1300]: loss = 0.563723 * 100, metric = 9.00% * 100;
 Minibatch[1301-1400]: loss = 0.550090 * 100, metric = 8.82% * 100;
 Minibatch[1401-1500]: loss = 0.566626 * 100, metric = 9.13% * 100;
 Minibatch[1501-1600]: loss = 0.576796 * 100, metric = 9.52% * 100;
 Minibatch[1601-1700]: loss = 0.561675 * 100, metric = 9.26% * 100;
 Minibatch[1701-1800]: loss = 0.560380 * 100, metric = 9.02% * 100;
 Minibatch[1801-1900]: loss = 0.585020 * 100, metric = 9.77% * 100;
 Minibatch[1901-2000]: loss = 0.546447 * 100, metric = 8.67% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.566319 * 2000, metric = 9.15% * 2000 984.287s (  2.0 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 15.80% * 2000;
0.6686700993403792
 Minibatch[   1- 100]: loss = 0.577377 * 100, metric = 9.16% * 100;
 Minibatch[ 101- 200]: loss = 0.568385 * 100, metric = 9.01% * 100;
 Minibatch[ 201- 300]: loss = 0.583065 * 100, metric = 9.65% * 100;
 Minibatch[ 301- 400]: loss = 0.559001 * 100, metric = 8.95% * 100;
 Minibatch[ 401- 500]: loss = 0.563407 * 100, metric = 9.07% * 100;
 Minibatch[ 501- 600]: loss = 0.570193 * 100, metric = 9.04% * 100;
 Minibatch[ 601- 700]: loss = 0.555595 * 100, metric = 8.89% * 100;
 Minibatch[ 701- 800]: loss = 0.566655 * 100, metric = 9.09% * 100;
 Minibatch[ 801- 900]: loss = 0.575739 * 100, metric = 9.28% * 100;
 Minibatch[ 901-1000]: loss = 0.572516 * 100, metric = 9.32% * 100;
 Minibatch[1001-1100]: loss = 0.547951 * 100, metric = 8.74% * 100;
 Minibatch[1101-1200]: loss = 0.539984 * 100, metric = 8.54% * 100;
 Minibatch[1201-1300]: loss = 0.556678 * 100, metric = 8.96% * 100;
 Minibatch[1301-1400]: loss = 0.562039 * 100, metric = 9.16% * 100;
 Minibatch[1401-1500]: loss = 0.548996 * 100, metric = 8.74% * 100;
 Minibatch[1501-1600]: loss = 0.543390 * 100, metric = 8.63% * 100;
 Minibatch[1601-1700]: loss = 0.547407 * 100, metric = 8.77% * 100;
 Minibatch[1701-1800]: loss = 0.552974 * 100, metric = 8.65% * 100;
 Minibatch[1801-1900]: loss = 0.553444 * 100, metric = 8.89% * 100;
 Minibatch[1901-2000]: loss = 0.555957 * 100, metric = 8.87% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.560038 * 2000, metric = 8.97% * 2000 974.852s (  2.1 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 16.58% * 2000;
 Minibatch[   1- 100]: loss = 0.570025 * 100, metric = 9.20% * 100;
 Minibatch[ 101- 200]: loss = 0.566285 * 100, metric = 9.38% * 100;
 Minibatch[ 201- 300]: loss = 0.567479 * 100, metric = 9.16% * 100;
 Minibatch[ 301- 400]: loss = 0.575107 * 100, metric = 9.23% * 100;
 Minibatch[ 401- 500]: loss = 0.571171 * 100, metric = 9.20% * 100;
 Minibatch[ 501- 600]: loss = 0.564276 * 100, metric = 8.96% * 100;
 Minibatch[ 601- 700]: loss = 0.560005 * 100, metric = 9.00% * 100;
 Minibatch[ 701- 800]: loss = 0.541841 * 100, metric = 8.34% * 100;
 Minibatch[ 801- 900]: loss = 0.535201 * 100, metric = 8.63% * 100;
 Minibatch[ 901-1000]: loss = 0.558476 * 100, metric = 8.81% * 100;
 Minibatch[1001-1100]: loss = 0.546243 * 100, metric = 8.68% * 100;
 Minibatch[1101-1200]: loss = 0.558334 * 100, metric = 8.86% * 100;
 Minibatch[1201-1300]: loss = 0.559998 * 100, metric = 9.09% * 100;
 Minibatch[1301-1400]: loss = 0.552928 * 100, metric = 8.77% * 100;
 Minibatch[1401-1500]: loss = 0.545511 * 100, metric = 8.90% * 100;
 Minibatch[1501-1600]: loss = 0.551696 * 100, metric = 8.62% * 100;
 Minibatch[1601-1700]: loss = 0.558051 * 100, metric = 8.84% * 100;
 Minibatch[1701-1800]: loss = 0.561841 * 100, metric = 9.06% * 100;
 Minibatch[1801-1900]: loss = 0.554748 * 100, metric = 9.10% * 100;
 Minibatch[1901-2000]: loss = 0.557623 * 100, metric = 8.67% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.557842 * 2000, metric = 8.93% * 2000 980.802s (  2.0 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 17.29% * 2000;
 Minibatch[   1- 100]: loss = 0.534741 * 100, metric = 8.43% * 100;
 Minibatch[ 101- 200]: loss = 0.550709 * 100, metric = 8.93% * 100;
 Minibatch[ 201- 300]: loss = 0.541262 * 100, metric = 8.71% * 100;
 Minibatch[ 301- 400]: loss = 0.549899 * 100, metric = 8.72% * 100;
 Minibatch[ 401- 500]: loss = 0.553150 * 100, metric = 8.96% * 100;
 Minibatch[ 501- 600]: loss = 0.537444 * 100, metric = 8.38% * 100;
 Minibatch[ 601- 700]: loss = 0.564827 * 100, metric = 9.01% * 100;
 Minibatch[ 701- 800]: loss = 0.545685 * 100, metric = 8.72% * 100;
 Minibatch[ 801- 900]: loss = 0.565236 * 100, metric = 9.32% * 100;
 Minibatch[ 901-1000]: loss = 0.549672 * 100, metric = 8.75% * 100;
 Minibatch[1001-1100]: loss = 0.548782 * 100, metric = 8.72% * 100;
 Minibatch[1101-1200]: loss = 0.568589 * 100, metric = 9.12% * 100;
 Minibatch[1201-1300]: loss = 0.557298 * 100, metric = 8.90% * 100;
 Minibatch[1301-1400]: loss = 0.548929 * 100, metric = 8.68% * 100;
 Minibatch[1401-1500]: loss = 0.551357 * 100, metric = 8.79% * 100;
 Minibatch[1501-1600]: loss = 0.555808 * 100, metric = 8.85% * 100;
 Minibatch[1601-1700]: loss = 0.535736 * 100, metric = 8.55% * 100;
 Minibatch[1701-1800]: loss = 0.534878 * 100, metric = 8.43% * 100;
 Minibatch[1801-1900]: loss = 0.553488 * 100, metric = 8.96% * 100;
 Minibatch[1901-2000]: loss = 0.560082 * 100, metric = 8.94% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.550379 * 2000, metric = 8.79% * 2000 962.423s (  2.1 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 16.15% * 2000;
 Minibatch[   1- 100]: loss = 0.557187 * 100, metric = 8.88% * 100;
 Minibatch[ 101- 200]: loss = 0.556342 * 100, metric = 9.05% * 100;
 Minibatch[ 201- 300]: loss = 0.551375 * 100, metric = 8.96% * 100;
 Minibatch[ 301- 400]: loss = 0.554729 * 100, metric = 9.01% * 100;
 Minibatch[ 401- 500]: loss = 0.547907 * 100, metric = 8.73% * 100;
 Minibatch[ 501- 600]: loss = 0.551193 * 100, metric = 8.77% * 100;
 Minibatch[ 601- 700]: loss = 0.548756 * 100, metric = 8.83% * 100;
 Minibatch[ 701- 800]: loss = 0.536269 * 100, metric = 8.42% * 100;
 Minibatch[ 801- 900]: loss = 0.538267 * 100, metric = 8.53% * 100;
 Minibatch[ 901-1000]: loss = 0.544843 * 100, metric = 8.77% * 100;
 Minibatch[1001-1100]: loss = 0.549561 * 100, metric = 8.78% * 100;
 Minibatch[1101-1200]: loss = 0.555399 * 100, metric = 8.89% * 100;
 Minibatch[1201-1300]: loss = 0.560786 * 100, metric = 9.10% * 100;
 Minibatch[1301-1400]: loss = 0.536354 * 100, metric = 8.35% * 100;
 Minibatch[1401-1500]: loss = 0.533596 * 100, metric = 8.27% * 100;
 Minibatch[1501-1600]: loss = 0.551934 * 100, metric = 8.92% * 100;
 Minibatch[1601-1700]: loss = 0.540010 * 100, metric = 8.57% * 100;
 Minibatch[1701-1800]: loss = 0.543892 * 100, metric = 8.75% * 100;
 Minibatch[1801-1900]: loss = 0.535974 * 100, metric = 8.51% * 100;
 Minibatch[1901-2000]: loss = 0.525673 * 100, metric = 8.15% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.546002 * 2000, metric = 8.71% * 2000 969.125s (  2.1 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 16.45% * 2000;
 Minibatch[   1- 100]: loss = 0.536339 * 100, metric = 8.58% * 100;
 Minibatch[ 101- 200]: loss = 0.518191 * 100, metric = 7.96% * 100;
 Minibatch[ 201- 300]: loss = 0.536675 * 100, metric = 8.60% * 100;
 Minibatch[ 301- 400]: loss = 0.537976 * 100, metric = 8.28% * 100;
 Minibatch[ 401- 500]: loss = 0.535824 * 100, metric = 8.57% * 100;
 Minibatch[ 501- 600]: loss = 0.532112 * 100, metric = 8.24% * 100;
 Minibatch[ 601- 700]: loss = 0.551595 * 100, metric = 8.82% * 100;
 Minibatch[ 701- 800]: loss = 0.532532 * 100, metric = 8.61% * 100;
 Minibatch[ 801- 900]: loss = 0.515869 * 100, metric = 8.02% * 100;
 Minibatch[ 901-1000]: loss = 0.520140 * 100, metric = 8.21% * 100;
 Minibatch[1001-1100]: loss = 0.548836 * 100, metric = 8.89% * 100;
 Minibatch[1101-1200]: loss = 0.557247 * 100, metric = 8.90% * 100;
 Minibatch[1201-1300]: loss = 0.538819 * 100, metric = 8.46% * 100;
 Minibatch[1301-1400]: loss = 0.514843 * 100, metric = 7.79% * 100;
 Minibatch[1401-1500]: loss = 0.537104 * 100, metric = 8.71% * 100;
 Minibatch[1501-1600]: loss = 0.530139 * 100, metric = 7.93% * 100;
 Minibatch[1601-1700]: loss = 0.547239 * 100, metric = 8.84% * 100;
 Minibatch[1701-1800]: loss = 0.545111 * 100, metric = 8.84% * 100;
 Minibatch[1801-1900]: loss = 0.531660 * 100, metric = 8.32% * 100;
 Minibatch[1901-2000]: loss = 0.533773 * 100, metric = 8.37% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.535101 * 2000, metric = 8.45% * 2000 955.915s (  2.1 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 17.49% * 2000;
 Minibatch[   1- 100]: loss = 0.530420 * 100, metric = 8.29% * 100;
 Minibatch[ 101- 200]: loss = 0.547345 * 100, metric = 8.52% * 100;
 Minibatch[ 201- 300]: loss = 0.524370 * 100, metric = 8.43% * 100;
 Minibatch[ 301- 400]: loss = 0.520183 * 100, metric = 8.06% * 100;
 Minibatch[ 401- 500]: loss = 0.526686 * 100, metric = 8.18% * 100;
 Minibatch[ 501- 600]: loss = 0.524114 * 100, metric = 8.24% * 100;
 Minibatch[ 601- 700]: loss = 0.523794 * 100, metric = 8.25% * 100;
 Minibatch[ 701- 800]: loss = 0.533077 * 100, metric = 8.32% * 100;
 Minibatch[ 801- 900]: loss = 0.529573 * 100, metric = 8.05% * 100;
 Minibatch[ 901-1000]: loss = 0.532593 * 100, metric = 8.70% * 100;
 Minibatch[1001-1100]: loss = 0.519931 * 100, metric = 7.87% * 100;
 Minibatch[1101-1200]: loss = 0.541055 * 100, metric = 8.29% * 100;
 Minibatch[1201-1300]: loss = 0.527055 * 100, metric = 8.24% * 100;
 Minibatch[1301-1400]: loss = 0.542053 * 100, metric = 8.63% * 100;
 Minibatch[1401-1500]: loss = 0.521012 * 100, metric = 8.34% * 100;
 Minibatch[1501-1600]: loss = 0.531213 * 100, metric = 8.37% * 100;
 Minibatch[1601-1700]: loss = 0.508589 * 100, metric = 7.65% * 100;
 Minibatch[1701-1800]: loss = 0.523548 * 100, metric = 7.93% * 100;
 Minibatch[1801-1900]: loss = 0.521938 * 100, metric = 8.21% * 100;
 Minibatch[1901-2000]: loss = 0.535130 * 100, metric = 8.37% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.528184 * 2000, metric = 8.25% * 2000 947.047s (  2.1 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 16.30% * 2000;
 Minibatch[   1- 100]: loss = 0.538141 * 100, metric = 8.62% * 100;
 Minibatch[ 101- 200]: loss = 0.521251 * 100, metric = 7.96% * 100;
 Minibatch[ 201- 300]: loss = 0.531682 * 100, metric = 8.53% * 100;
 Minibatch[ 301- 400]: loss = 0.526683 * 100, metric = 8.07% * 100;
 Minibatch[ 401- 500]: loss = 0.521535 * 100, metric = 8.15% * 100;
 Minibatch[ 501- 600]: loss = 0.549496 * 100, metric = 9.11% * 100;
 Minibatch[ 601- 700]: loss = 0.523996 * 100, metric = 8.26% * 100;
 Minibatch[ 701- 800]: loss = 0.510791 * 100, metric = 7.94% * 100;
 Minibatch[ 801- 900]: loss = 0.526824 * 100, metric = 8.21% * 100;
 Minibatch[ 901-1000]: loss = 0.540618 * 100, metric = 8.73% * 100;
 Minibatch[1001-1100]: loss = 0.525814 * 100, metric = 8.23% * 100;
 Minibatch[1101-1200]: loss = 0.518658 * 100, metric = 7.87% * 100;
 Minibatch[1201-1300]: loss = 0.536495 * 100, metric = 8.52% * 100;
 Minibatch[1301-1400]: loss = 0.521226 * 100, metric = 8.25% * 100;
 Minibatch[1401-1500]: loss = 0.531320 * 100, metric = 8.29% * 100;
 Minibatch[1501-1600]: loss = 0.519558 * 100, metric = 8.13% * 100;
 Minibatch[1601-1700]: loss = 0.525098 * 100, metric = 8.01% * 100;
 Minibatch[1701-1800]: loss = 0.518543 * 100, metric = 8.04% * 100;
 Minibatch[1801-1900]: loss = 0.526557 * 100, metric = 8.34% * 100;
 Minibatch[1901-2000]: loss = 0.520546 * 100, metric = 8.20% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.526741 * 2000, metric = 8.27% * 2000 944.973s (  2.1 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 15.16% * 2000;
0.6619768910706043
 Minibatch[   1- 100]: loss = 0.512694 * 100, metric = 8.04% * 100;
 Minibatch[ 101- 200]: loss = 0.514679 * 100, metric = 8.11% * 100;
 Minibatch[ 201- 300]: loss = 0.522850 * 100, metric = 8.37% * 100;
 Minibatch[ 301- 400]: loss = 0.542871 * 100, metric = 8.62% * 100;
 Minibatch[ 401- 500]: loss = 0.507847 * 100, metric = 7.70% * 100;
 Minibatch[ 501- 600]: loss = 0.514571 * 100, metric = 7.96% * 100;
 Minibatch[ 601- 700]: loss = 0.514021 * 100, metric = 8.08% * 100;
 Minibatch[ 701- 800]: loss = 0.526255 * 100, metric = 8.45% * 100;
 Minibatch[ 801- 900]: loss = 0.519597 * 100, metric = 8.24% * 100;
 Minibatch[ 901-1000]: loss = 0.526839 * 100, metric = 8.50% * 100;
 Minibatch[1001-1100]: loss = 0.516216 * 100, metric = 8.21% * 100;
 Minibatch[1101-1200]: loss = 0.510656 * 100, metric = 7.90% * 100;
 Minibatch[1201-1300]: loss = 0.528445 * 100, metric = 8.03% * 100;
 Minibatch[1301-1400]: loss = 0.502141 * 100, metric = 7.80% * 100;
 Minibatch[1401-1500]: loss = 0.530269 * 100, metric = 8.51% * 100;
 Minibatch[1501-1600]: loss = 0.502838 * 100, metric = 7.90% * 100;
 Minibatch[1601-1700]: loss = 0.526912 * 100, metric = 8.33% * 100;
 Minibatch[1701-1800]: loss = 0.500436 * 100, metric = 7.62% * 100;
 Minibatch[1801-1900]: loss = 0.526797 * 100, metric = 8.27% * 100;
 Minibatch[1901-2000]: loss = 0.516658 * 100, metric = 8.06% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.518180 * 2000, metric = 8.13% * 2000 932.312s (  2.1 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 17.13% * 2000;
 Minibatch[   1- 100]: loss = 0.530280 * 100, metric = 8.23% * 100;
 Minibatch[ 101- 200]: loss = 0.499200 * 100, metric = 7.46% * 100;
 Minibatch[ 201- 300]: loss = 0.506997 * 100, metric = 7.82% * 100;
 Minibatch[ 301- 400]: loss = 0.523817 * 100, metric = 8.27% * 100;
 Minibatch[ 401- 500]: loss = 0.515198 * 100, metric = 8.07% * 100;
 Minibatch[ 501- 600]: loss = 0.491922 * 100, metric = 7.41% * 100;
 Minibatch[ 601- 700]: loss = 0.518119 * 100, metric = 8.21% * 100;
 Minibatch[ 701- 800]: loss = 0.504161 * 100, metric = 7.65% * 100;
 Minibatch[ 801- 900]: loss = 0.521707 * 100, metric = 8.03% * 100;
 Minibatch[ 901-1000]: loss = 0.495141 * 100, metric = 7.68% * 100;
 Minibatch[1001-1100]: loss = 0.515079 * 100, metric = 7.82% * 100;
 Minibatch[1101-1200]: loss = 0.521946 * 100, metric = 8.21% * 100;
 Minibatch[1201-1300]: loss = 0.506193 * 100, metric = 7.79% * 100;
 Minibatch[1301-1400]: loss = 0.510675 * 100, metric = 7.97% * 100;
 Minibatch[1401-1500]: loss = 0.510851 * 100, metric = 7.88% * 100;
 Minibatch[1501-1600]: loss = 0.522822 * 100, metric = 8.24% * 100;
 Minibatch[1601-1700]: loss = 0.523766 * 100, metric = 8.22% * 100;
 Minibatch[1701-1800]: loss = 0.520369 * 100, metric = 8.09% * 100;
 Minibatch[1801-1900]: loss = 0.514922 * 100, metric = 8.16% * 100;
 Minibatch[1901-2000]: loss = 0.529542 * 100, metric = 8.42% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.514135 * 2000, metric = 7.98% * 2000 962.600s (  2.1 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 16.81% * 2000;
 Minibatch[   1- 100]: loss = 0.513995 * 100, metric = 7.95% * 100;
 Minibatch[ 101- 200]: loss = 0.530521 * 100, metric = 8.48% * 100;
 Minibatch[ 201- 300]: loss = 0.513351 * 100, metric = 7.97% * 100;
 Minibatch[ 301- 400]: loss = 0.510749 * 100, metric = 7.81% * 100;
 Minibatch[ 401- 500]: loss = 0.505103 * 100, metric = 7.83% * 100;
 Minibatch[ 501- 600]: loss = 0.506149 * 100, metric = 7.80% * 100;
 Minibatch[ 601- 700]: loss = 0.525316 * 100, metric = 8.50% * 100;
 Minibatch[ 701- 800]: loss = 0.522883 * 100, metric = 8.15% * 100;
 Minibatch[ 801- 900]: loss = 0.514642 * 100, metric = 8.01% * 100;
 Minibatch[ 901-1000]: loss = 0.496901 * 100, metric = 7.72% * 100;
 Minibatch[1001-1100]: loss = 0.498605 * 100, metric = 7.70% * 100;
 Minibatch[1101-1200]: loss = 0.505092 * 100, metric = 7.91% * 100;
 Minibatch[1201-1300]: loss = 0.506765 * 100, metric = 7.93% * 100;
 Minibatch[1301-1400]: loss = 0.508457 * 100, metric = 8.16% * 100;
 Minibatch[1401-1500]: loss = 0.508450 * 100, metric = 7.82% * 100;
 Minibatch[1501-1600]: loss = 0.495051 * 100, metric = 7.77% * 100;
 Minibatch[1601-1700]: loss = 0.510828 * 100, metric = 8.00% * 100;
 Minibatch[1701-1800]: loss = 0.500214 * 100, metric = 7.89% * 100;
 Minibatch[1801-1900]: loss = 0.507176 * 100, metric = 7.87% * 100;
 Minibatch[1901-2000]: loss = 0.503214 * 100, metric = 7.97% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.509173 * 2000, metric = 7.96% * 2000 943.318s (  2.1 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 15.29% * 2000;
 Minibatch[   1- 100]: loss = 0.509342 * 100, metric = 7.99% * 100;
 Minibatch[ 101- 200]: loss = 0.507023 * 100, metric = 7.88% * 100;
 Minibatch[ 201- 300]: loss = 0.513067 * 100, metric = 8.15% * 100;
 Minibatch[ 301- 400]: loss = 0.525304 * 100, metric = 8.29% * 100;
 Minibatch[ 401- 500]: loss = 0.514792 * 100, metric = 8.23% * 100;
 Minibatch[ 501- 600]: loss = 0.504309 * 100, metric = 7.89% * 100;
 Minibatch[ 601- 700]: loss = 0.489102 * 100, metric = 7.39% * 100;
 Minibatch[ 701- 800]: loss = 0.497984 * 100, metric = 7.82% * 100;
 Minibatch[ 801- 900]: loss = 0.496847 * 100, metric = 7.67% * 100;
 Minibatch[ 901-1000]: loss = 0.489822 * 100, metric = 7.42% * 100;
 Minibatch[1001-1100]: loss = 0.493622 * 100, metric = 7.52% * 100;
 Minibatch[1101-1200]: loss = 0.502459 * 100, metric = 8.00% * 100;
 Minibatch[1201-1300]: loss = 0.516566 * 100, metric = 8.10% * 100;
 Minibatch[1301-1400]: loss = 0.498013 * 100, metric = 7.80% * 100;
 Minibatch[1401-1500]: loss = 0.493922 * 100, metric = 7.77% * 100;
 Minibatch[1501-1600]: loss = 0.507197 * 100, metric = 7.77% * 100;
 Minibatch[1601-1700]: loss = 0.491628 * 100, metric = 7.72% * 100;
 Minibatch[1701-1800]: loss = 0.515708 * 100, metric = 8.14% * 100;
 Minibatch[1801-1900]: loss = 0.490864 * 100, metric = 7.25% * 100;
 Minibatch[1901-2000]: loss = 0.509131 * 100, metric = 8.35% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.503335 * 2000, metric = 7.86% * 2000 940.237s (  2.1 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 15.73% * 2000;
 Minibatch[   1- 100]: loss = 0.523884 * 100, metric = 8.51% * 100;
 Minibatch[ 101- 200]: loss = 0.497753 * 100, metric = 7.89% * 100;
 Minibatch[ 201- 300]: loss = 0.493175 * 100, metric = 7.70% * 100;
 Minibatch[ 301- 400]: loss = 0.509972 * 100, metric = 8.14% * 100;
 Minibatch[ 401- 500]: loss = 0.501994 * 100, metric = 7.88% * 100;
 Minibatch[ 501- 600]: loss = 0.502660 * 100, metric = 7.72% * 100;
 Minibatch[ 601- 700]: loss = 0.509538 * 100, metric = 8.00% * 100;
 Minibatch[ 701- 800]: loss = 0.497920 * 100, metric = 7.58% * 100;
 Minibatch[ 801- 900]: loss = 0.499074 * 100, metric = 7.54% * 100;
 Minibatch[ 901-1000]: loss = 0.481209 * 100, metric = 7.30% * 100;
 Minibatch[1001-1100]: loss = 0.489377 * 100, metric = 7.51% * 100;
 Minibatch[1101-1200]: loss = 0.479295 * 100, metric = 7.20% * 100;
 Minibatch[1201-1300]: loss = 0.507428 * 100, metric = 7.66% * 100;
 Minibatch[1301-1400]: loss = 0.481343 * 100, metric = 7.04% * 100;
 Minibatch[1401-1500]: loss = 0.509498 * 100, metric = 7.91% * 100;
 Minibatch[1501-1600]: loss = 0.509474 * 100, metric = 8.02% * 100;
 Minibatch[1601-1700]: loss = 0.490875 * 100, metric = 7.41% * 100;
 Minibatch[1701-1800]: loss = 0.489469 * 100, metric = 7.42% * 100;
 Minibatch[1801-1900]: loss = 0.488759 * 100, metric = 7.46% * 100;
 Minibatch[1901-2000]: loss = 0.508743 * 100, metric = 8.05% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.498572 * 2000, metric = 7.70% * 2000 934.300s (  2.1 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 14.90% * 2000;
 Minibatch[   1- 100]: loss = 0.494003 * 100, metric = 7.64% * 100;
 Minibatch[ 101- 200]: loss = 0.497854 * 100, metric = 7.59% * 100;
 Minibatch[ 201- 300]: loss = 0.482995 * 100, metric = 7.23% * 100;
 Minibatch[ 301- 400]: loss = 0.494556 * 100, metric = 7.78% * 100;
 Minibatch[ 401- 500]: loss = 0.481819 * 100, metric = 7.46% * 100;
 Minibatch[ 501- 600]: loss = 0.496731 * 100, metric = 7.64% * 100;
 Minibatch[ 601- 700]: loss = 0.507272 * 100, metric = 7.93% * 100;
 Minibatch[ 701- 800]: loss = 0.488540 * 100, metric = 7.38% * 100;
 Minibatch[ 801- 900]: loss = 0.474548 * 100, metric = 6.81% * 100;
 Minibatch[ 901-1000]: loss = 0.480940 * 100, metric = 7.30% * 100;
 Minibatch[1001-1100]: loss = 0.496977 * 100, metric = 7.77% * 100;
 Minibatch[1101-1200]: loss = 0.492802 * 100, metric = 7.77% * 100;
 Minibatch[1201-1300]: loss = 0.497832 * 100, metric = 7.71% * 100;
 Minibatch[1301-1400]: loss = 0.489427 * 100, metric = 7.73% * 100;
 Minibatch[1401-1500]: loss = 0.504788 * 100, metric = 7.91% * 100;
 Minibatch[1501-1600]: loss = 0.500355 * 100, metric = 7.85% * 100;
 Minibatch[1601-1700]: loss = 0.511449 * 100, metric = 8.16% * 100;
 Minibatch[1701-1800]: loss = 0.498979 * 100, metric = 7.92% * 100;
 Minibatch[1801-1900]: loss = 0.489791 * 100, metric = 7.53% * 100;
 Minibatch[1901-2000]: loss = 0.498818 * 100, metric = 7.76% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.494024 * 2000, metric = 7.64% * 2000 932.358s (  2.1 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 15.34% * 2000;
 Minibatch[   1- 100]: loss = 0.470436 * 100, metric = 7.02% * 100;
 Minibatch[ 101- 200]: loss = 0.502363 * 100, metric = 7.81% * 100;
 Minibatch[ 201- 300]: loss = 0.494872 * 100, metric = 7.52% * 100;
 Minibatch[ 301- 400]: loss = 0.476089 * 100, metric = 7.07% * 100;
 Minibatch[ 401- 500]: loss = 0.488785 * 100, metric = 7.39% * 100;
 Minibatch[ 501- 600]: loss = 0.465344 * 100, metric = 6.83% * 100;
 Minibatch[ 601- 700]: loss = 0.498679 * 100, metric = 7.73% * 100;
 Minibatch[ 701- 800]: loss = 0.466441 * 100, metric = 7.08% * 100;
 Minibatch[ 801- 900]: loss = 0.493564 * 100, metric = 7.69% * 100;
 Minibatch[ 901-1000]: loss = 0.469669 * 100, metric = 7.18% * 100;
 Minibatch[1001-1100]: loss = 0.501364 * 100, metric = 7.84% * 100;
 Minibatch[1101-1200]: loss = 0.484760 * 100, metric = 7.32% * 100;
 Minibatch[1201-1300]: loss = 0.490375 * 100, metric = 7.67% * 100;
 Minibatch[1301-1400]: loss = 0.493620 * 100, metric = 7.65% * 100;
 Minibatch[1401-1500]: loss = 0.483246 * 100, metric = 7.33% * 100;
 Minibatch[1501-1600]: loss = 0.488944 * 100, metric = 7.61% * 100;
 Minibatch[1601-1700]: loss = 0.490480 * 100, metric = 7.62% * 100;
 Minibatch[1701-1800]: loss = 0.478586 * 100, metric = 7.18% * 100;
 Minibatch[1801-1900]: loss = 0.493543 * 100, metric = 7.54% * 100;
 Minibatch[1901-2000]: loss = 0.479299 * 100, metric = 7.33% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.485523 * 2000, metric = 7.42% * 2000 969.983s (  2.1 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 15.43% * 2000;
 Minibatch[   1- 100]: loss = 0.476752 * 100, metric = 7.28% * 100;
 Minibatch[ 101- 200]: loss = 0.463428 * 100, metric = 6.93% * 100;
 Minibatch[ 201- 300]: loss = 0.493846 * 100, metric = 7.66% * 100;
 Minibatch[ 301- 400]: loss = 0.478177 * 100, metric = 7.21% * 100;
 Minibatch[ 401- 500]: loss = 0.474365 * 100, metric = 7.07% * 100;
 Minibatch[ 501- 600]: loss = 0.482313 * 100, metric = 7.37% * 100;
 Minibatch[ 601- 700]: loss = 0.496060 * 100, metric = 7.32% * 100;
 Minibatch[ 701- 800]: loss = 0.466294 * 100, metric = 6.96% * 100;
 Minibatch[ 801- 900]: loss = 0.460840 * 100, metric = 6.88% * 100;
 Minibatch[ 901-1000]: loss = 0.487497 * 100, metric = 7.56% * 100;
 Minibatch[1001-1100]: loss = 0.493815 * 100, metric = 7.78% * 100;
 Minibatch[1101-1200]: loss = 0.481376 * 100, metric = 7.36% * 100;
 Minibatch[1201-1300]: loss = 0.485020 * 100, metric = 7.61% * 100;
 Minibatch[1301-1400]: loss = 0.461176 * 100, metric = 6.84% * 100;
 Minibatch[1401-1500]: loss = 0.465768 * 100, metric = 7.02% * 100;
 Minibatch[1501-1600]: loss = 0.479062 * 100, metric = 7.38% * 100;
 Minibatch[1601-1700]: loss = 0.496777 * 100, metric = 7.95% * 100;
 Minibatch[1701-1800]: loss = 0.482351 * 100, metric = 7.35% * 100;
 Minibatch[1801-1900]: loss = 0.479038 * 100, metric = 7.20% * 100;
 Minibatch[1901-2000]: loss = 0.473188 * 100, metric = 7.30% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.478857 * 2000, metric = 7.30% * 2000 950.113s (  2.1 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 14.72% * 2000;
0.6604950691238046
 Minibatch[   1- 100]: loss = 0.471108 * 100, metric = 7.09% * 100;
 Minibatch[ 101- 200]: loss = 0.487036 * 100, metric = 7.56% * 100;
 Minibatch[ 201- 300]: loss = 0.480259 * 100, metric = 7.47% * 100;
 Minibatch[ 301- 400]: loss = 0.474875 * 100, metric = 7.13% * 100;
 Minibatch[ 401- 500]: loss = 0.476467 * 100, metric = 7.33% * 100;
 Minibatch[ 501- 600]: loss = 0.462386 * 100, metric = 7.08% * 100;
 Minibatch[ 601- 700]: loss = 0.474608 * 100, metric = 7.38% * 100;
 Minibatch[ 701- 800]: loss = 0.485804 * 100, metric = 7.63% * 100;
 Minibatch[ 801- 900]: loss = 0.480756 * 100, metric = 7.23% * 100;
 Minibatch[ 901-1000]: loss = 0.467457 * 100, metric = 6.67% * 100;
 Minibatch[1001-1100]: loss = 0.471895 * 100, metric = 7.29% * 100;
 Minibatch[1101-1200]: loss = 0.493425 * 100, metric = 7.83% * 100;
 Minibatch[1201-1300]: loss = 0.489144 * 100, metric = 7.62% * 100;
 Minibatch[1301-1400]: loss = 0.482641 * 100, metric = 7.21% * 100;
 Minibatch[1401-1500]: loss = 0.476153 * 100, metric = 7.43% * 100;
 Minibatch[1501-1600]: loss = 0.468171 * 100, metric = 6.97% * 100;
 Minibatch[1601-1700]: loss = 0.475147 * 100, metric = 7.51% * 100;
 Minibatch[1701-1800]: loss = 0.473330 * 100, metric = 7.13% * 100;
 Minibatch[1801-1900]: loss = 0.477698 * 100, metric = 7.25% * 100;
 Minibatch[1901-2000]: loss = 0.478976 * 100, metric = 7.23% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.477367 * 2000, metric = 7.30% * 2000 944.764s (  2.1 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 14.34% * 2000;
0.6512438779398799
 Minibatch[   1- 100]: loss = 0.480350 * 100, metric = 7.29% * 100;
 Minibatch[ 101- 200]: loss = 0.479021 * 100, metric = 7.32% * 100;
 Minibatch[ 201- 300]: loss = 0.457318 * 100, metric = 6.48% * 100;
 Minibatch[ 301- 400]: loss = 0.464506 * 100, metric = 6.93% * 100;
 Minibatch[ 401- 500]: loss = 0.474453 * 100, metric = 7.05% * 100;
 Minibatch[ 501- 600]: loss = 0.467392 * 100, metric = 6.96% * 100;
 Minibatch[ 601- 700]: loss = 0.475608 * 100, metric = 7.49% * 100;
 Minibatch[ 701- 800]: loss = 0.472374 * 100, metric = 7.10% * 100;
 Minibatch[ 801- 900]: loss = 0.470971 * 100, metric = 7.18% * 100;
 Minibatch[ 901-1000]: loss = 0.472490 * 100, metric = 6.90% * 100;
 Minibatch[1001-1100]: loss = 0.477378 * 100, metric = 7.56% * 100;
 Minibatch[1101-1200]: loss = 0.461351 * 100, metric = 7.01% * 100;
 Minibatch[1201-1300]: loss = 0.470184 * 100, metric = 7.27% * 100;
 Minibatch[1301-1400]: loss = 0.484782 * 100, metric = 7.33% * 100;
 Minibatch[1401-1500]: loss = 0.479469 * 100, metric = 7.29% * 100;
 Minibatch[1501-1600]: loss = 0.478394 * 100, metric = 7.39% * 100;
 Minibatch[1601-1700]: loss = 0.455362 * 100, metric = 7.03% * 100;
 Minibatch[1701-1800]: loss = 0.464686 * 100, metric = 7.12% * 100;
 Minibatch[1801-1900]: loss = 0.474017 * 100, metric = 7.27% * 100;
 Minibatch[1901-2000]: loss = 0.474249 * 100, metric = 7.11% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.471718 * 2000, metric = 7.15% * 2000 932.110s (  2.1 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 14.08% * 2000;
 Minibatch[   1- 100]: loss = 0.468732 * 100, metric = 7.12% * 100;
 Minibatch[ 101- 200]: loss = 0.477543 * 100, metric = 7.30% * 100;
 Minibatch[ 201- 300]: loss = 0.465157 * 100, metric = 6.90% * 100;
 Minibatch[ 301- 400]: loss = 0.461053 * 100, metric = 6.97% * 100;
 Minibatch[ 401- 500]: loss = 0.461315 * 100, metric = 7.07% * 100;
 Minibatch[ 501- 600]: loss = 0.477210 * 100, metric = 6.97% * 100;
 Minibatch[ 601- 700]: loss = 0.471872 * 100, metric = 7.27% * 100;
 Minibatch[ 701- 800]: loss = 0.472270 * 100, metric = 7.13% * 100;
 Minibatch[ 801- 900]: loss = 0.455237 * 100, metric = 6.82% * 100;
 Minibatch[ 901-1000]: loss = 0.459643 * 100, metric = 6.77% * 100;
 Minibatch[1001-1100]: loss = 0.468748 * 100, metric = 7.28% * 100;
 Minibatch[1101-1200]: loss = 0.468743 * 100, metric = 7.22% * 100;
 Minibatch[1201-1300]: loss = 0.468550 * 100, metric = 6.95% * 100;
 Minibatch[1301-1400]: loss = 0.482000 * 100, metric = 7.28% * 100;
 Minibatch[1401-1500]: loss = 0.479254 * 100, metric = 7.12% * 100;
 Minibatch[1501-1600]: loss = 0.476166 * 100, metric = 7.03% * 100;
 Minibatch[1601-1700]: loss = 0.472491 * 100, metric = 7.17% * 100;
 Minibatch[1701-1800]: loss = 0.480601 * 100, metric = 7.43% * 100;
 Minibatch[1801-1900]: loss = 0.472908 * 100, metric = 7.18% * 100;
 Minibatch[1901-2000]: loss = 0.461895 * 100, metric = 6.86% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.470069 * 2000, metric = 7.09% * 2000 909.155s (  2.2 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 15.60% * 2000;
 Minibatch[   1- 100]: loss = 0.455604 * 100, metric = 6.83% * 100;
 Minibatch[ 101- 200]: loss = 0.454246 * 100, metric = 6.75% * 100;
 Minibatch[ 201- 300]: loss = 0.469976 * 100, metric = 7.08% * 100;
 Minibatch[ 301- 400]: loss = 0.471817 * 100, metric = 7.17% * 100;
 Minibatch[ 401- 500]: loss = 0.467935 * 100, metric = 7.01% * 100;
 Minibatch[ 501- 600]: loss = 0.465618 * 100, metric = 7.23% * 100;
 Minibatch[ 601- 700]: loss = 0.479181 * 100, metric = 6.98% * 100;
 Minibatch[ 701- 800]: loss = 0.459481 * 100, metric = 6.75% * 100;
 Minibatch[ 801- 900]: loss = 0.465506 * 100, metric = 6.93% * 100;
 Minibatch[ 901-1000]: loss = 0.467572 * 100, metric = 7.10% * 100;
 Minibatch[1001-1100]: loss = 0.471899 * 100, metric = 7.37% * 100;
 Minibatch[1101-1200]: loss = 0.469118 * 100, metric = 7.00% * 100;
 Minibatch[1201-1300]: loss = 0.464844 * 100, metric = 6.98% * 100;
 Minibatch[1301-1400]: loss = 0.470998 * 100, metric = 7.21% * 100;
 Minibatch[1401-1500]: loss = 0.462134 * 100, metric = 7.06% * 100;
 Minibatch[1501-1600]: loss = 0.473576 * 100, metric = 7.22% * 100;
 Minibatch[1601-1700]: loss = 0.466152 * 100, metric = 7.05% * 100;
 Minibatch[1701-1800]: loss = 0.454709 * 100, metric = 7.04% * 100;
 Minibatch[1801-1900]: loss = 0.459608 * 100, metric = 6.82% * 100;
 Minibatch[1901-2000]: loss = 0.470802 * 100, metric = 7.15% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.466039 * 2000, metric = 7.04% * 2000 929.569s (  2.2 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 14.56% * 2000;
 Minibatch[   1- 100]: loss = 0.462887 * 100, metric = 7.18% * 100;
 Minibatch[ 101- 200]: loss = 0.460589 * 100, metric = 6.94% * 100;
 Minibatch[ 201- 300]: loss = 0.468474 * 100, metric = 6.99% * 100;
 Minibatch[ 301- 400]: loss = 0.472034 * 100, metric = 7.18% * 100;
 Minibatch[ 401- 500]: loss = 0.466260 * 100, metric = 7.11% * 100;
 Minibatch[ 501- 600]: loss = 0.456295 * 100, metric = 6.60% * 100;
 Minibatch[ 601- 700]: loss = 0.477299 * 100, metric = 7.29% * 100;
 Minibatch[ 701- 800]: loss = 0.467295 * 100, metric = 7.19% * 100;
 Minibatch[ 801- 900]: loss = 0.454513 * 100, metric = 6.82% * 100;
 Minibatch[ 901-1000]: loss = 0.459185 * 100, metric = 7.01% * 100;
 Minibatch[1001-1100]: loss = 0.466311 * 100, metric = 7.07% * 100;
 Minibatch[1101-1200]: loss = 0.476172 * 100, metric = 7.16% * 100;
 Minibatch[1201-1300]: loss = 0.479080 * 100, metric = 7.23% * 100;
 Minibatch[1301-1400]: loss = 0.449263 * 100, metric = 6.81% * 100;
 Minibatch[1401-1500]: loss = 0.457246 * 100, metric = 6.92% * 100;
 Minibatch[1501-1600]: loss = 0.461940 * 100, metric = 6.92% * 100;
 Minibatch[1601-1700]: loss = 0.465317 * 100, metric = 7.13% * 100;
 Minibatch[1701-1800]: loss = 0.466791 * 100, metric = 7.10% * 100;
 Minibatch[1801-1900]: loss = 0.459671 * 100, metric = 7.11% * 100;
 Minibatch[1901-2000]: loss = 0.456627 * 100, metric = 6.81% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.464162 * 2000, metric = 7.03% * 2000 919.721s (  2.2 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 15.50% * 2000;
 Minibatch[   1- 100]: loss = 0.449264 * 100, metric = 6.49% * 100;
 Minibatch[ 101- 200]: loss = 0.457888 * 100, metric = 6.96% * 100;
 Minibatch[ 201- 300]: loss = 0.461489 * 100, metric = 6.96% * 100;
 Minibatch[ 301- 400]: loss = 0.458506 * 100, metric = 6.89% * 100;
 Minibatch[ 401- 500]: loss = 0.455397 * 100, metric = 6.75% * 100;
 Minibatch[ 501- 600]: loss = 0.458795 * 100, metric = 6.87% * 100;
 Minibatch[ 601- 700]: loss = 0.460481 * 100, metric = 7.03% * 100;
 Minibatch[ 701- 800]: loss = 0.446989 * 100, metric = 6.74% * 100;
 Minibatch[ 801- 900]: loss = 0.451874 * 100, metric = 6.92% * 100;
 Minibatch[ 901-1000]: loss = 0.467343 * 100, metric = 7.05% * 100;
 Minibatch[1001-1100]: loss = 0.458295 * 100, metric = 6.97% * 100;
 Minibatch[1101-1200]: loss = 0.454227 * 100, metric = 6.96% * 100;
 Minibatch[1201-1300]: loss = 0.452241 * 100, metric = 6.72% * 100;
 Minibatch[1301-1400]: loss = 0.468234 * 100, metric = 7.24% * 100;
 Minibatch[1401-1500]: loss = 0.457577 * 100, metric = 6.77% * 100;
 Minibatch[1501-1600]: loss = 0.448999 * 100, metric = 6.48% * 100;
 Minibatch[1601-1700]: loss = 0.469752 * 100, metric = 6.95% * 100;
 Minibatch[1701-1800]: loss = 0.463696 * 100, metric = 7.02% * 100;
 Minibatch[1801-1900]: loss = 0.456416 * 100, metric = 6.95% * 100;
 Minibatch[1901-2000]: loss = 0.450771 * 100, metric = 6.68% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.457412 * 2000, metric = 6.87% * 2000 929.723s (  2.2 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 14.85% * 2000;
 Minibatch[   1- 100]: loss = 0.472111 * 100, metric = 7.50% * 100;
 Minibatch[ 101- 200]: loss = 0.444455 * 100, metric = 6.48% * 100;
 Minibatch[ 201- 300]: loss = 0.461610 * 100, metric = 6.89% * 100;
 Minibatch[ 301- 400]: loss = 0.459151 * 100, metric = 6.82% * 100;
 Minibatch[ 401- 500]: loss = 0.450714 * 100, metric = 6.65% * 100;
 Minibatch[ 501- 600]: loss = 0.445174 * 100, metric = 6.73% * 100;
 Minibatch[ 601- 700]: loss = 0.466597 * 100, metric = 7.10% * 100;
 Minibatch[ 701- 800]: loss = 0.446943 * 100, metric = 6.87% * 100;
 Minibatch[ 801- 900]: loss = 0.451650 * 100, metric = 6.86% * 100;
 Minibatch[ 901-1000]: loss = 0.451535 * 100, metric = 6.55% * 100;
 Minibatch[1001-1100]: loss = 0.456507 * 100, metric = 6.82% * 100;
 Minibatch[1101-1200]: loss = 0.444129 * 100, metric = 6.66% * 100;
 Minibatch[1201-1300]: loss = 0.460322 * 100, metric = 7.17% * 100;
 Minibatch[1301-1400]: loss = 0.456879 * 100, metric = 7.00% * 100;
 Minibatch[1401-1500]: loss = 0.439097 * 100, metric = 6.41% * 100;
 Minibatch[1501-1600]: loss = 0.463852 * 100, metric = 6.94% * 100;
 Minibatch[1601-1700]: loss = 0.448334 * 100, metric = 6.87% * 100;
 Minibatch[1701-1800]: loss = 0.452007 * 100, metric = 6.96% * 100;
 Minibatch[1801-1900]: loss = 0.458387 * 100, metric = 6.96% * 100;
 Minibatch[1901-2000]: loss = 0.445347 * 100, metric = 6.49% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.453740 * 2000, metric = 6.84% * 2000 917.386s (  2.2 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 14.51% * 2000;
 Minibatch[   1- 100]: loss = 0.450346 * 100, metric = 6.69% * 100;
 Minibatch[ 101- 200]: loss = 0.450228 * 100, metric = 6.89% * 100;
 Minibatch[ 201- 300]: loss = 0.445235 * 100, metric = 6.67% * 100;
 Minibatch[ 301- 400]: loss = 0.462151 * 100, metric = 6.84% * 100;
 Minibatch[ 401- 500]: loss = 0.453400 * 100, metric = 6.73% * 100;
 Minibatch[ 501- 600]: loss = 0.445232 * 100, metric = 6.77% * 100;
 Minibatch[ 601- 700]: loss = 0.459976 * 100, metric = 7.08% * 100;
 Minibatch[ 701- 800]: loss = 0.430946 * 100, metric = 6.34% * 100;
 Minibatch[ 801- 900]: loss = 0.447981 * 100, metric = 6.47% * 100;
 Minibatch[ 901-1000]: loss = 0.442444 * 100, metric = 6.49% * 100;
 Minibatch[1001-1100]: loss = 0.445886 * 100, metric = 6.49% * 100;
 Minibatch[1101-1200]: loss = 0.433361 * 100, metric = 6.47% * 100;
 Minibatch[1201-1300]: loss = 0.443083 * 100, metric = 6.62% * 100;
 Minibatch[1301-1400]: loss = 0.438395 * 100, metric = 6.48% * 100;
 Minibatch[1401-1500]: loss = 0.441332 * 100, metric = 6.44% * 100;
 Minibatch[1501-1600]: loss = 0.430019 * 100, metric = 6.15% * 100;
 Minibatch[1601-1700]: loss = 0.442861 * 100, metric = 6.35% * 100;
 Minibatch[1701-1800]: loss = 0.452766 * 100, metric = 6.93% * 100;
 Minibatch[1801-1900]: loss = 0.447600 * 100, metric = 6.49% * 100;
 Minibatch[1901-2000]: loss = 0.434962 * 100, metric = 6.42% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.444910 * 2000, metric = 6.59% * 2000 910.015s (  2.2 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 14.81% * 2000;
 Minibatch[   1- 100]: loss = 0.452491 * 100, metric = 6.80% * 100;
 Minibatch[ 101- 200]: loss = 0.448364 * 100, metric = 6.69% * 100;
 Minibatch[ 201- 300]: loss = 0.441309 * 100, metric = 6.54% * 100;
 Minibatch[ 301- 400]: loss = 0.449671 * 100, metric = 6.84% * 100;
 Minibatch[ 401- 500]: loss = 0.442207 * 100, metric = 6.71% * 100;
 Minibatch[ 501- 600]: loss = 0.425990 * 100, metric = 6.13% * 100;
 Minibatch[ 601- 700]: loss = 0.435456 * 100, metric = 6.45% * 100;
 Minibatch[ 701- 800]: loss = 0.427013 * 100, metric = 6.47% * 100;
 Minibatch[ 801- 900]: loss = 0.460050 * 100, metric = 7.12% * 100;
 Minibatch[ 901-1000]: loss = 0.435284 * 100, metric = 6.49% * 100;
 Minibatch[1001-1100]: loss = 0.432480 * 100, metric = 6.26% * 100;
 Minibatch[1101-1200]: loss = 0.447132 * 100, metric = 6.45% * 100;
 Minibatch[1201-1300]: loss = 0.443915 * 100, metric = 6.65% * 100;
 Minibatch[1301-1400]: loss = 0.438821 * 100, metric = 6.45% * 100;
 Minibatch[1401-1500]: loss = 0.443463 * 100, metric = 6.61% * 100;
 Minibatch[1501-1600]: loss = 0.438448 * 100, metric = 6.50% * 100;
 Minibatch[1601-1700]: loss = 0.435159 * 100, metric = 6.33% * 100;
 Minibatch[1701-1800]: loss = 0.446649 * 100, metric = 6.76% * 100;
 Minibatch[1801-1900]: loss = 0.447905 * 100, metric = 6.79% * 100;
 Minibatch[1901-2000]: loss = 0.440696 * 100, metric = 6.36% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.441625 * 2000, metric = 6.57% * 2000 917.270s (  2.2 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 14.76% * 2000;
 Minibatch[   1- 100]: loss = 0.431850 * 100, metric = 6.60% * 100;
 Minibatch[ 101- 200]: loss = 0.453741 * 100, metric = 7.01% * 100;
 Minibatch[ 201- 300]: loss = 0.443904 * 100, metric = 6.60% * 100;
 Minibatch[ 301- 400]: loss = 0.458799 * 100, metric = 7.13% * 100;
 Minibatch[ 401- 500]: loss = 0.440887 * 100, metric = 6.31% * 100;
 Minibatch[ 501- 600]: loss = 0.438756 * 100, metric = 6.40% * 100;
 Minibatch[ 601- 700]: loss = 0.422182 * 100, metric = 6.07% * 100;
 Minibatch[ 701- 800]: loss = 0.426481 * 100, metric = 6.26% * 100;
 Minibatch[ 801- 900]: loss = 0.433176 * 100, metric = 6.50% * 100;
 Minibatch[ 901-1000]: loss = 0.450466 * 100, metric = 6.72% * 100;
 Minibatch[1001-1100]: loss = 0.434788 * 100, metric = 6.29% * 100;
 Minibatch[1101-1200]: loss = 0.441136 * 100, metric = 6.77% * 100;
 Minibatch[1201-1300]: loss = 0.446700 * 100, metric = 6.62% * 100;
 Minibatch[1301-1400]: loss = 0.434850 * 100, metric = 6.36% * 100;
 Minibatch[1401-1500]: loss = 0.429213 * 100, metric = 6.40% * 100;
 Minibatch[1501-1600]: loss = 0.444753 * 100, metric = 6.47% * 100;
 Minibatch[1601-1700]: loss = 0.421208 * 100, metric = 5.94% * 100;
 Minibatch[1701-1800]: loss = 0.444866 * 100, metric = 6.67% * 100;
 Minibatch[1801-1900]: loss = 0.419334 * 100, metric = 6.13% * 100;
 Minibatch[1901-2000]: loss = 0.434333 * 100, metric = 6.22% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.437571 * 2000, metric = 6.47% * 2000 925.766s (  2.2 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 14.73% * 2000;
 Minibatch[   1- 100]: loss = 0.436341 * 100, metric = 6.37% * 100;
 Minibatch[ 101- 200]: loss = 0.427280 * 100, metric = 6.20% * 100;
 Minibatch[ 201- 300]: loss = 0.431477 * 100, metric = 6.39% * 100;
 Minibatch[ 301- 400]: loss = 0.423423 * 100, metric = 5.92% * 100;
 Minibatch[ 401- 500]: loss = 0.424050 * 100, metric = 6.40% * 100;
 Minibatch[ 501- 600]: loss = 0.427144 * 100, metric = 6.42% * 100;
 Minibatch[ 601- 700]: loss = 0.449636 * 100, metric = 6.86% * 100;
 Minibatch[ 701- 800]: loss = 0.443000 * 100, metric = 6.73% * 100;
 Minibatch[ 801- 900]: loss = 0.437871 * 100, metric = 6.29% * 100;
 Minibatch[ 901-1000]: loss = 0.441228 * 100, metric = 6.46% * 100;
 Minibatch[1001-1100]: loss = 0.453818 * 100, metric = 6.88% * 100;
 Minibatch[1101-1200]: loss = 0.436970 * 100, metric = 6.39% * 100;
 Minibatch[1201-1300]: loss = 0.413370 * 100, metric = 6.18% * 100;
 Minibatch[1301-1400]: loss = 0.430030 * 100, metric = 6.52% * 100;
 Minibatch[1401-1500]: loss = 0.443909 * 100, metric = 6.53% * 100;
 Minibatch[1501-1600]: loss = 0.443856 * 100, metric = 6.56% * 100;
 Minibatch[1601-1700]: loss = 0.438032 * 100, metric = 6.46% * 100;
 Minibatch[1701-1800]: loss = 0.440884 * 100, metric = 6.67% * 100;
 Minibatch[1801-1900]: loss = 0.440471 * 100, metric = 6.73% * 100;
 Minibatch[1901-2000]: loss = 0.447771 * 100, metric = 6.83% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.436528 * 2000, metric = 6.49% * 2000 901.697s (  2.2 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 13.65% * 2000;
0.6458406287506223
 Minibatch[   1- 100]: loss = 0.442459 * 100, metric = 6.72% * 100;
 Minibatch[ 101- 200]: loss = 0.442600 * 100, metric = 6.67% * 100;
 Minibatch[ 201- 300]: loss = 0.430351 * 100, metric = 6.54% * 100;
 Minibatch[ 301- 400]: loss = 0.422349 * 100, metric = 6.18% * 100;
 Minibatch[ 401- 500]: loss = 0.443775 * 100, metric = 6.65% * 100;
 Minibatch[ 501- 600]: loss = 0.447651 * 100, metric = 6.82% * 100;
 Minibatch[ 601- 700]: loss = 0.455229 * 100, metric = 6.73% * 100;
 Minibatch[ 701- 800]: loss = 0.441335 * 100, metric = 6.25% * 100;
 Minibatch[ 801- 900]: loss = 0.430435 * 100, metric = 6.34% * 100;
 Minibatch[ 901-1000]: loss = 0.443735 * 100, metric = 6.72% * 100;
 Minibatch[1001-1100]: loss = 0.429666 * 100, metric = 6.51% * 100;
 Minibatch[1101-1200]: loss = 0.439279 * 100, metric = 6.50% * 100;
 Minibatch[1201-1300]: loss = 0.428795 * 100, metric = 6.55% * 100;
 Minibatch[1301-1400]: loss = 0.430400 * 100, metric = 6.40% * 100;
 Minibatch[1401-1500]: loss = 0.428157 * 100, metric = 6.45% * 100;
 Minibatch[1501-1600]: loss = 0.432147 * 100, metric = 6.46% * 100;
 Minibatch[1601-1700]: loss = 0.426949 * 100, metric = 6.42% * 100;
 Minibatch[1701-1800]: loss = 0.433966 * 100, metric = 6.29% * 100;
 Minibatch[1801-1900]: loss = 0.441210 * 100, metric = 6.59% * 100;
 Minibatch[1901-2000]: loss = 0.425329 * 100, metric = 6.10% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.435791 * 2000, metric = 6.50% * 2000 916.367s (  2.2 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 14.22% * 2000;
 Minibatch[   1- 100]: loss = 0.444698 * 100, metric = 6.65% * 100;
 Minibatch[ 101- 200]: loss = 0.424846 * 100, metric = 6.21% * 100;
 Minibatch[ 201- 300]: loss = 0.440958 * 100, metric = 6.69% * 100;
 Minibatch[ 301- 400]: loss = 0.433288 * 100, metric = 6.60% * 100;
 Minibatch[ 401- 500]: loss = 0.447329 * 100, metric = 6.79% * 100;
 Minibatch[ 501- 600]: loss = 0.432276 * 100, metric = 6.45% * 100;
 Minibatch[ 601- 700]: loss = 0.435330 * 100, metric = 6.50% * 100;
 Minibatch[ 701- 800]: loss = 0.432102 * 100, metric = 6.39% * 100;
 Minibatch[ 801- 900]: loss = 0.422428 * 100, metric = 6.17% * 100;
 Minibatch[ 901-1000]: loss = 0.447332 * 100, metric = 6.81% * 100;
 Minibatch[1001-1100]: loss = 0.435907 * 100, metric = 6.36% * 100;
 Minibatch[1101-1200]: loss = 0.441856 * 100, metric = 6.64% * 100;
 Minibatch[1201-1300]: loss = 0.414131 * 100, metric = 5.96% * 100;
 Minibatch[1301-1400]: loss = 0.437266 * 100, metric = 6.65% * 100;
 Minibatch[1401-1500]: loss = 0.426989 * 100, metric = 6.64% * 100;
 Minibatch[1501-1600]: loss = 0.415737 * 100, metric = 5.86% * 100;
 Minibatch[1601-1700]: loss = 0.442551 * 100, metric = 6.92% * 100;
 Minibatch[1701-1800]: loss = 0.430336 * 100, metric = 6.58% * 100;
 Minibatch[1801-1900]: loss = 0.431635 * 100, metric = 6.47% * 100;
 Minibatch[1901-2000]: loss = 0.422972 * 100, metric = 6.19% * 100;
Finished Epoch[49 of 200]: [Training] loss = 0.432998 * 2000, metric = 6.48% * 2000 903.340s (  2.2 samples/s);
Finished Evaluation [49]: Minibatch[1-2000]: metric = 13.95% * 2000;
 Minibatch[   1- 100]: loss = 0.438512 * 100, metric = 6.57% * 100;
 Minibatch[ 101- 200]: loss = 0.431184 * 100, metric = 6.33% * 100;
 Minibatch[ 201- 300]: loss = 0.423758 * 100, metric = 6.37% * 100;
 Minibatch[ 301- 400]: loss = 0.430885 * 100, metric = 6.25% * 100;
 Minibatch[ 401- 500]: loss = 0.439272 * 100, metric = 6.78% * 100;
 Minibatch[ 501- 600]: loss = 0.445986 * 100, metric = 7.01% * 100;
 Minibatch[ 601- 700]: loss = 0.422265 * 100, metric = 6.41% * 100;
 Minibatch[ 701- 800]: loss = 0.420561 * 100, metric = 6.32% * 100;
 Minibatch[ 801- 900]: loss = 0.432672 * 100, metric = 6.27% * 100;
 Minibatch[ 901-1000]: loss = 0.432900 * 100, metric = 6.29% * 100;
 Minibatch[1001-1100]: loss = 0.420730 * 100, metric = 6.22% * 100;
 Minibatch[1101-1200]: loss = 0.426692 * 100, metric = 6.36% * 100;
 Minibatch[1201-1300]: loss = 0.435720 * 100, metric = 6.90% * 100;
 Minibatch[1301-1400]: loss = 0.417018 * 100, metric = 6.18% * 100;
 Minibatch[1401-1500]: loss = 0.428244 * 100, metric = 6.47% * 100;
 Minibatch[1501-1600]: loss = 0.418851 * 100, metric = 6.15% * 100;
 Minibatch[1601-1700]: loss = 0.423721 * 100, metric = 6.23% * 100;
 Minibatch[1701-1800]: loss = 0.429024 * 100, metric = 6.38% * 100;
 Minibatch[1801-1900]: loss = 0.437287 * 100, metric = 6.40% * 100;
 Minibatch[1901-2000]: loss = 0.431802 * 100, metric = 6.53% * 100;
Finished Epoch[50 of 200]: [Training] loss = 0.429354 * 2000, metric = 6.42% * 2000 906.995s (  2.2 samples/s);
Finished Evaluation [50]: Minibatch[1-2000]: metric = 14.66% * 2000;
 Minibatch[   1- 100]: loss = 0.420236 * 100, metric = 6.19% * 100;
 Minibatch[ 101- 200]: loss = 0.431165 * 100, metric = 6.56% * 100;
 Minibatch[ 201- 300]: loss = 0.431638 * 100, metric = 6.36% * 100;
 Minibatch[ 301- 400]: loss = 0.423252 * 100, metric = 6.19% * 100;
 Minibatch[ 401- 500]: loss = 0.423534 * 100, metric = 6.23% * 100;
 Minibatch[ 501- 600]: loss = 0.435672 * 100, metric = 6.61% * 100;
 Minibatch[ 601- 700]: loss = 0.413709 * 100, metric = 6.08% * 100;
 Minibatch[ 701- 800]: loss = 0.418253 * 100, metric = 6.08% * 100;
 Minibatch[ 801- 900]: loss = 0.424984 * 100, metric = 6.40% * 100;
 Minibatch[ 901-1000]: loss = 0.424772 * 100, metric = 6.27% * 100;
 Minibatch[1001-1100]: loss = 0.424610 * 100, metric = 6.22% * 100;
 Minibatch[1101-1200]: loss = 0.431169 * 100, metric = 6.40% * 100;
 Minibatch[1201-1300]: loss = 0.445320 * 100, metric = 6.50% * 100;
 Minibatch[1301-1400]: loss = 0.431336 * 100, metric = 6.36% * 100;
 Minibatch[1401-1500]: loss = 0.420609 * 100, metric = 6.07% * 100;
 Minibatch[1501-1600]: loss = 0.433672 * 100, metric = 6.25% * 100;
 Minibatch[1601-1700]: loss = 0.416163 * 100, metric = 6.25% * 100;
 Minibatch[1701-1800]: loss = 0.425901 * 100, metric = 6.41% * 100;
 Minibatch[1801-1900]: loss = 0.406722 * 100, metric = 5.95% * 100;
 Minibatch[1901-2000]: loss = 0.422036 * 100, metric = 6.26% * 100;
Finished Epoch[51 of 200]: [Training] loss = 0.425238 * 2000, metric = 6.28% * 2000 907.883s (  2.2 samples/s);
Finished Evaluation [51]: Minibatch[1-2000]: metric = 14.03% * 2000;
 Minibatch[   1- 100]: loss = 0.411877 * 100, metric = 5.98% * 100;
 Minibatch[ 101- 200]: loss = 0.423212 * 100, metric = 6.01% * 100;
 Minibatch[ 201- 300]: loss = 0.432333 * 100, metric = 6.50% * 100;
 Minibatch[ 301- 400]: loss = 0.409747 * 100, metric = 6.11% * 100;
 Minibatch[ 401- 500]: loss = 0.432007 * 100, metric = 6.19% * 100;
 Minibatch[ 501- 600]: loss = 0.429348 * 100, metric = 6.43% * 100;
 Minibatch[ 601- 700]: loss = 0.419030 * 100, metric = 6.17% * 100;
 Minibatch[ 701- 800]: loss = 0.434711 * 100, metric = 6.59% * 100;
 Minibatch[ 801- 900]: loss = 0.431865 * 100, metric = 6.43% * 100;
 Minibatch[ 901-1000]: loss = 0.443439 * 100, metric = 6.62% * 100;
 Minibatch[1001-1100]: loss = 0.424399 * 100, metric = 6.28% * 100;
 Minibatch[1101-1200]: loss = 0.418079 * 100, metric = 5.79% * 100;
 Minibatch[1201-1300]: loss = 0.415945 * 100, metric = 5.97% * 100;
 Minibatch[1301-1400]: loss = 0.427247 * 100, metric = 6.27% * 100;
 Minibatch[1401-1500]: loss = 0.411115 * 100, metric = 6.03% * 100;
 Minibatch[1501-1600]: loss = 0.414567 * 100, metric = 6.03% * 100;
 Minibatch[1601-1700]: loss = 0.430652 * 100, metric = 6.48% * 100;
 Minibatch[1701-1800]: loss = 0.411707 * 100, metric = 6.29% * 100;
 Minibatch[1801-1900]: loss = 0.414467 * 100, metric = 5.96% * 100;
 Minibatch[1901-2000]: loss = 0.424167 * 100, metric = 6.40% * 100;
Finished Epoch[52 of 200]: [Training] loss = 0.422996 * 2000, metric = 6.23% * 2000 903.850s (  2.2 samples/s);
Finished Evaluation [52]: Minibatch[1-2000]: metric = 14.36% * 2000;
 Minibatch[   1- 100]: loss = 0.427800 * 100, metric = 6.29% * 100;
 Minibatch[ 101- 200]: loss = 0.410958 * 100, metric = 6.00% * 100;
 Minibatch[ 201- 300]: loss = 0.425409 * 100, metric = 6.34% * 100;
 Minibatch[ 301- 400]: loss = 0.425980 * 100, metric = 6.36% * 100;
 Minibatch[ 401- 500]: loss = 0.418985 * 100, metric = 6.30% * 100;
 Minibatch[ 501- 600]: loss = 0.425025 * 100, metric = 6.26% * 100;
 Minibatch[ 601- 700]: loss = 0.417302 * 100, metric = 6.10% * 100;
 Minibatch[ 701- 800]: loss = 0.421943 * 100, metric = 6.25% * 100;
 Minibatch[ 801- 900]: loss = 0.421560 * 100, metric = 6.28% * 100;
 Minibatch[ 901-1000]: loss = 0.415035 * 100, metric = 6.07% * 100;
 Minibatch[1001-1100]: loss = 0.430363 * 100, metric = 6.46% * 100;
 Minibatch[1101-1200]: loss = 0.418623 * 100, metric = 6.27% * 100;
 Minibatch[1201-1300]: loss = 0.412976 * 100, metric = 6.13% * 100;
 Minibatch[1301-1400]: loss = 0.424109 * 100, metric = 6.02% * 100;
 Minibatch[1401-1500]: loss = 0.411497 * 100, metric = 6.13% * 100;
 Minibatch[1501-1600]: loss = 0.431528 * 100, metric = 6.35% * 100;
 Minibatch[1601-1700]: loss = 0.415955 * 100, metric = 6.12% * 100;
 Minibatch[1701-1800]: loss = 0.432611 * 100, metric = 6.45% * 100;
 Minibatch[1801-1900]: loss = 0.439337 * 100, metric = 6.72% * 100;
 Minibatch[1901-2000]: loss = 0.404944 * 100, metric = 5.84% * 100;
Finished Epoch[53 of 200]: [Training] loss = 0.421597 * 2000, metric = 6.24% * 2000 914.393s (  2.2 samples/s);
Finished Evaluation [53]: Minibatch[1-2000]: metric = 14.10% * 2000;
 Minibatch[   1- 100]: loss = 0.418980 * 100, metric = 6.10% * 100;
 Minibatch[ 101- 200]: loss = 0.422108 * 100, metric = 6.37% * 100;
 Minibatch[ 201- 300]: loss = 0.411117 * 100, metric = 6.23% * 100;
 Minibatch[ 301- 400]: loss = 0.409375 * 100, metric = 5.81% * 100;
 Minibatch[ 401- 500]: loss = 0.414678 * 100, metric = 6.09% * 100;
 Minibatch[ 501- 600]: loss = 0.405837 * 100, metric = 5.77% * 100;
 Minibatch[ 601- 700]: loss = 0.425974 * 100, metric = 6.35% * 100;
 Minibatch[ 701- 800]: loss = 0.418956 * 100, metric = 6.36% * 100;
 Minibatch[ 801- 900]: loss = 0.400796 * 100, metric = 5.72% * 100;
 Minibatch[ 901-1000]: loss = 0.422167 * 100, metric = 6.25% * 100;
 Minibatch[1001-1100]: loss = 0.403809 * 100, metric = 5.83% * 100;
 Minibatch[1101-1200]: loss = 0.413071 * 100, metric = 6.26% * 100;
 Minibatch[1201-1300]: loss = 0.409781 * 100, metric = 6.02% * 100;
 Minibatch[1301-1400]: loss = 0.410922 * 100, metric = 6.19% * 100;
 Minibatch[1401-1500]: loss = 0.419439 * 100, metric = 6.13% * 100;
 Minibatch[1501-1600]: loss = 0.427073 * 100, metric = 6.37% * 100;
 Minibatch[1601-1700]: loss = 0.415801 * 100, metric = 6.18% * 100;
 Minibatch[1701-1800]: loss = 0.422508 * 100, metric = 6.05% * 100;
 Minibatch[1801-1900]: loss = 0.422552 * 100, metric = 6.43% * 100;
 Minibatch[1901-2000]: loss = 0.421486 * 100, metric = 6.29% * 100;
Finished Epoch[54 of 200]: [Training] loss = 0.415821 * 2000, metric = 6.14% * 2000 916.562s (  2.2 samples/s);
Finished Evaluation [54]: Minibatch[1-2000]: metric = 14.00% * 2000;
 Minibatch[   1- 100]: loss = 0.424172 * 100, metric = 6.36% * 100;
 Minibatch[ 101- 200]: loss = 0.423522 * 100, metric = 6.20% * 100;
 Minibatch[ 201- 300]: loss = 0.420352 * 100, metric = 6.02% * 100;
 Minibatch[ 301- 400]: loss = 0.412196 * 100, metric = 5.96% * 100;
 Minibatch[ 401- 500]: loss = 0.422354 * 100, metric = 6.10% * 100;
 Minibatch[ 501- 600]: loss = 0.430822 * 100, metric = 6.42% * 100;
 Minibatch[ 601- 700]: loss = 0.418423 * 100, metric = 6.43% * 100;
 Minibatch[ 701- 800]: loss = 0.428221 * 100, metric = 6.50% * 100;
 Minibatch[ 801- 900]: loss = 0.418243 * 100, metric = 6.18% * 100;
 Minibatch[ 901-1000]: loss = 0.414253 * 100, metric = 6.00% * 100;
 Minibatch[1001-1100]: loss = 0.421732 * 100, metric = 6.22% * 100;
 Minibatch[1101-1200]: loss = 0.425276 * 100, metric = 6.11% * 100;
 Minibatch[1201-1300]: loss = 0.414376 * 100, metric = 6.02% * 100;
 Minibatch[1301-1400]: loss = 0.404845 * 100, metric = 5.99% * 100;
 Minibatch[1401-1500]: loss = 0.407216 * 100, metric = 5.95% * 100;
 Minibatch[1501-1600]: loss = 0.415364 * 100, metric = 6.02% * 100;
 Minibatch[1601-1700]: loss = 0.418132 * 100, metric = 6.17% * 100;
 Minibatch[1701-1800]: loss = 0.421993 * 100, metric = 6.20% * 100;
 Minibatch[1801-1900]: loss = 0.402451 * 100, metric = 5.73% * 100;
 Minibatch[1901-2000]: loss = 0.413912 * 100, metric = 6.16% * 100;
Finished Epoch[55 of 200]: [Training] loss = 0.417893 * 2000, metric = 6.14% * 2000 910.763s (  2.2 samples/s);
Finished Evaluation [55]: Minibatch[1-2000]: metric = 14.37% * 2000;
 Minibatch[   1- 100]: loss = 0.414363 * 100, metric = 6.34% * 100;
 Minibatch[ 101- 200]: loss = 0.406662 * 100, metric = 5.95% * 100;
 Minibatch[ 201- 300]: loss = 0.422375 * 100, metric = 6.28% * 100;
 Minibatch[ 301- 400]: loss = 0.415035 * 100, metric = 6.00% * 100;
 Minibatch[ 401- 500]: loss = 0.420279 * 100, metric = 6.43% * 100;
 Minibatch[ 501- 600]: loss = 0.422860 * 100, metric = 6.39% * 100;
 Minibatch[ 601- 700]: loss = 0.419158 * 100, metric = 6.15% * 100;
 Minibatch[ 701- 800]: loss = 0.412043 * 100, metric = 6.11% * 100;
 Minibatch[ 801- 900]: loss = 0.412505 * 100, metric = 5.77% * 100;
 Minibatch[ 901-1000]: loss = 0.417395 * 100, metric = 6.29% * 100;
 Minibatch[1001-1100]: loss = 0.427051 * 100, metric = 6.48% * 100;
 Minibatch[1101-1200]: loss = 0.423944 * 100, metric = 6.30% * 100;
 Minibatch[1201-1300]: loss = 0.408575 * 100, metric = 5.90% * 100;
 Minibatch[1301-1400]: loss = 0.411573 * 100, metric = 5.98% * 100;
 Minibatch[1401-1500]: loss = 0.424039 * 100, metric = 6.27% * 100;
 Minibatch[1501-1600]: loss = 0.408680 * 100, metric = 5.79% * 100;
 Minibatch[1601-1700]: loss = 0.411073 * 100, metric = 5.77% * 100;
 Minibatch[1701-1800]: loss = 0.412477 * 100, metric = 5.92% * 100;
 Minibatch[1801-1900]: loss = 0.403785 * 100, metric = 5.80% * 100;
 Minibatch[1901-2000]: loss = 0.425824 * 100, metric = 6.47% * 100;
Finished Epoch[56 of 200]: [Training] loss = 0.415985 * 2000, metric = 6.12% * 2000 906.715s (  2.2 samples/s);
Finished Evaluation [56]: Minibatch[1-2000]: metric = 13.84% * 2000;
 Minibatch[   1- 100]: loss = 0.414885 * 100, metric = 5.92% * 100;
 Minibatch[ 101- 200]: loss = 0.410306 * 100, metric = 6.00% * 100;
 Minibatch[ 201- 300]: loss = 0.407271 * 100, metric = 5.85% * 100;
 Minibatch[ 301- 400]: loss = 0.410707 * 100, metric = 5.87% * 100;
 Minibatch[ 401- 500]: loss = 0.410022 * 100, metric = 5.94% * 100;
 Minibatch[ 501- 600]: loss = 0.395886 * 100, metric = 5.75% * 100;
 Minibatch[ 601- 700]: loss = 0.419891 * 100, metric = 6.05% * 100;
 Minibatch[ 701- 800]: loss = 0.396981 * 100, metric = 5.65% * 100;
 Minibatch[ 801- 900]: loss = 0.413520 * 100, metric = 6.02% * 100;
 Minibatch[ 901-1000]: loss = 0.409875 * 100, metric = 6.02% * 100;
 Minibatch[1001-1100]: loss = 0.425865 * 100, metric = 6.26% * 100;
 Minibatch[1101-1200]: loss = 0.407646 * 100, metric = 5.97% * 100;
 Minibatch[1201-1300]: loss = 0.408145 * 100, metric = 6.11% * 100;
 Minibatch[1301-1400]: loss = 0.400945 * 100, metric = 5.96% * 100;
 Minibatch[1401-1500]: loss = 0.421967 * 100, metric = 6.27% * 100;
 Minibatch[1501-1600]: loss = 0.405203 * 100, metric = 5.77% * 100;
 Minibatch[1601-1700]: loss = 0.411263 * 100, metric = 5.82% * 100;
 Minibatch[1701-1800]: loss = 0.405852 * 100, metric = 6.02% * 100;
 Minibatch[1801-1900]: loss = 0.417204 * 100, metric = 6.12% * 100;
 Minibatch[1901-2000]: loss = 0.418950 * 100, metric = 6.09% * 100;
Finished Epoch[57 of 200]: [Training] loss = 0.410619 * 2000, metric = 5.97% * 2000 897.473s (  2.2 samples/s);
Finished Evaluation [57]: Minibatch[1-2000]: metric = 13.80% * 2000;
 Minibatch[   1- 100]: loss = 0.413786 * 100, metric = 5.74% * 100;
 Minibatch[ 101- 200]: loss = 0.414764 * 100, metric = 6.03% * 100;
 Minibatch[ 201- 300]: loss = 0.406697 * 100, metric = 6.04% * 100;
 Minibatch[ 301- 400]: loss = 0.414305 * 100, metric = 6.22% * 100;
 Minibatch[ 401- 500]: loss = 0.434184 * 100, metric = 6.56% * 100;
 Minibatch[ 501- 600]: loss = 0.411052 * 100, metric = 5.94% * 100;
 Minibatch[ 601- 700]: loss = 0.419627 * 100, metric = 6.30% * 100;
 Minibatch[ 701- 800]: loss = 0.420319 * 100, metric = 6.21% * 100;
 Minibatch[ 801- 900]: loss = 0.419529 * 100, metric = 6.12% * 100;
 Minibatch[ 901-1000]: loss = 0.405059 * 100, metric = 5.88% * 100;
 Minibatch[1001-1100]: loss = 0.423179 * 100, metric = 6.24% * 100;
 Minibatch[1101-1200]: loss = 0.424137 * 100, metric = 6.41% * 100;
 Minibatch[1201-1300]: loss = 0.408624 * 100, metric = 5.86% * 100;
 Minibatch[1301-1400]: loss = 0.418274 * 100, metric = 6.20% * 100;
 Minibatch[1401-1500]: loss = 0.404653 * 100, metric = 5.88% * 100;
 Minibatch[1501-1600]: loss = 0.412513 * 100, metric = 6.15% * 100;
 Minibatch[1601-1700]: loss = 0.420767 * 100, metric = 6.22% * 100;
 Minibatch[1701-1800]: loss = 0.405652 * 100, metric = 5.69% * 100;
 Minibatch[1801-1900]: loss = 0.412580 * 100, metric = 6.16% * 100;
 Minibatch[1901-2000]: loss = 0.391542 * 100, metric = 5.49% * 100;
Finished Epoch[58 of 200]: [Training] loss = 0.414062 * 2000, metric = 6.07% * 2000 898.841s (  2.2 samples/s);
Finished Evaluation [58]: Minibatch[1-2000]: metric = 13.58% * 2000;
 Minibatch[   1- 100]: loss = 0.418225 * 100, metric = 6.26% * 100;
 Minibatch[ 101- 200]: loss = 0.423064 * 100, metric = 6.40% * 100;
 Minibatch[ 201- 300]: loss = 0.403050 * 100, metric = 5.95% * 100;
 Minibatch[ 301- 400]: loss = 0.406252 * 100, metric = 5.84% * 100;
 Minibatch[ 401- 500]: loss = 0.409300 * 100, metric = 6.09% * 100;
 Minibatch[ 501- 600]: loss = 0.398332 * 100, metric = 5.70% * 100;
 Minibatch[ 601- 700]: loss = 0.400796 * 100, metric = 5.75% * 100;
 Minibatch[ 701- 800]: loss = 0.409242 * 100, metric = 5.72% * 100;
 Minibatch[ 801- 900]: loss = 0.404779 * 100, metric = 6.02% * 100;
 Minibatch[ 901-1000]: loss = 0.409104 * 100, metric = 5.98% * 100;
 Minibatch[1001-1100]: loss = 0.396369 * 100, metric = 5.70% * 100;
 Minibatch[1101-1200]: loss = 0.409117 * 100, metric = 5.91% * 100;
 Minibatch[1201-1300]: loss = 0.409654 * 100, metric = 5.82% * 100;
 Minibatch[1301-1400]: loss = 0.399991 * 100, metric = 5.58% * 100;
 Minibatch[1401-1500]: loss = 0.403262 * 100, metric = 5.83% * 100;
 Minibatch[1501-1600]: loss = 0.402397 * 100, metric = 5.84% * 100;
 Minibatch[1601-1700]: loss = 0.411779 * 100, metric = 5.97% * 100;
 Minibatch[1701-1800]: loss = 0.413535 * 100, metric = 6.01% * 100;
 Minibatch[1801-1900]: loss = 0.411352 * 100, metric = 5.87% * 100;
 Minibatch[1901-2000]: loss = 0.415856 * 100, metric = 6.02% * 100;
Finished Epoch[59 of 200]: [Training] loss = 0.407773 * 2000, metric = 5.91% * 2000 915.883s (  2.2 samples/s);
Finished Evaluation [59]: Minibatch[1-2000]: metric = 14.27% * 2000;
 Minibatch[   1- 100]: loss = 0.402622 * 100, metric = 5.73% * 100;
 Minibatch[ 101- 200]: loss = 0.396555 * 100, metric = 5.66% * 100;
 Minibatch[ 201- 300]: loss = 0.395851 * 100, metric = 5.46% * 100;
 Minibatch[ 301- 400]: loss = 0.409166 * 100, metric = 5.75% * 100;
 Minibatch[ 401- 500]: loss = 0.412825 * 100, metric = 6.08% * 100;
 Minibatch[ 501- 600]: loss = 0.417385 * 100, metric = 6.20% * 100;
 Minibatch[ 601- 700]: loss = 0.392097 * 100, metric = 5.63% * 100;
 Minibatch[ 701- 800]: loss = 0.409364 * 100, metric = 5.96% * 100;
 Minibatch[ 801- 900]: loss = 0.404312 * 100, metric = 5.97% * 100;
 Minibatch[ 901-1000]: loss = 0.411064 * 100, metric = 6.06% * 100;
 Minibatch[1001-1100]: loss = 0.416927 * 100, metric = 6.20% * 100;
 Minibatch[1101-1200]: loss = 0.411619 * 100, metric = 6.02% * 100;
 Minibatch[1201-1300]: loss = 0.407660 * 100, metric = 6.02% * 100;
 Minibatch[1301-1400]: loss = 0.399835 * 100, metric = 5.80% * 100;
 Minibatch[1401-1500]: loss = 0.389923 * 100, metric = 5.46% * 100;
 Minibatch[1501-1600]: loss = 0.405126 * 100, metric = 5.71% * 100;
 Minibatch[1601-1700]: loss = 0.405831 * 100, metric = 6.04% * 100;
 Minibatch[1701-1800]: loss = 0.413161 * 100, metric = 5.98% * 100;
 Minibatch[1801-1900]: loss = 0.412070 * 100, metric = 6.16% * 100;
 Minibatch[1901-2000]: loss = 0.401943 * 100, metric = 5.95% * 100;
Finished Epoch[60 of 200]: [Training] loss = 0.405767 * 2000, metric = 5.89% * 2000 933.241s (  2.1 samples/s);
Finished Evaluation [60]: Minibatch[1-2000]: metric = 13.64% * 2000;
 Minibatch[   1- 100]: loss = 0.413061 * 100, metric = 6.09% * 100;
 Minibatch[ 101- 200]: loss = 0.396487 * 100, metric = 5.55% * 100;
 Minibatch[ 201- 300]: loss = 0.401626 * 100, metric = 5.99% * 100;
 Minibatch[ 301- 400]: loss = 0.407985 * 100, metric = 6.07% * 100;
 Minibatch[ 401- 500]: loss = 0.396663 * 100, metric = 5.82% * 100;
 Minibatch[ 501- 600]: loss = 0.378709 * 100, metric = 5.28% * 100;
 Minibatch[ 601- 700]: loss = 0.405479 * 100, metric = 5.65% * 100;
 Minibatch[ 701- 800]: loss = 0.405494 * 100, metric = 5.96% * 100;
 Minibatch[ 801- 900]: loss = 0.394056 * 100, metric = 5.61% * 100;
 Minibatch[ 901-1000]: loss = 0.389772 * 100, metric = 5.59% * 100;
 Minibatch[1001-1100]: loss = 0.395153 * 100, metric = 5.76% * 100;
 Minibatch[1101-1200]: loss = 0.404923 * 100, metric = 6.01% * 100;
 Minibatch[1201-1300]: loss = 0.389560 * 100, metric = 5.59% * 100;
 Minibatch[1301-1400]: loss = 0.382906 * 100, metric = 5.15% * 100;
 Minibatch[1401-1500]: loss = 0.403587 * 100, metric = 6.02% * 100;
 Minibatch[1501-1600]: loss = 0.412585 * 100, metric = 6.29% * 100;
 Minibatch[1601-1700]: loss = 0.407381 * 100, metric = 5.88% * 100;
 Minibatch[1701-1800]: loss = 0.396691 * 100, metric = 5.57% * 100;
 Minibatch[1801-1900]: loss = 0.401771 * 100, metric = 5.87% * 100;
 Minibatch[1901-2000]: loss = 0.401045 * 100, metric = 5.75% * 100;
Finished Epoch[61 of 200]: [Training] loss = 0.399247 * 2000, metric = 5.77% * 2000 896.470s (  2.2 samples/s);
Finished Evaluation [61]: Minibatch[1-2000]: metric = 13.71% * 2000;
 Minibatch[   1- 100]: loss = 0.392986 * 100, metric = 5.70% * 100;
 Minibatch[ 101- 200]: loss = 0.399060 * 100, metric = 5.60% * 100;
 Minibatch[ 201- 300]: loss = 0.396277 * 100, metric = 5.80% * 100;
 Minibatch[ 301- 400]: loss = 0.404352 * 100, metric = 5.86% * 100;
 Minibatch[ 401- 500]: loss = 0.399503 * 100, metric = 5.62% * 100;
 Minibatch[ 501- 600]: loss = 0.398738 * 100, metric = 5.71% * 100;
 Minibatch[ 601- 700]: loss = 0.399270 * 100, metric = 5.77% * 100;
 Minibatch[ 701- 800]: loss = 0.396015 * 100, metric = 5.79% * 100;
 Minibatch[ 801- 900]: loss = 0.399699 * 100, metric = 5.72% * 100;
 Minibatch[ 901-1000]: loss = 0.403042 * 100, metric = 5.88% * 100;
 Minibatch[1001-1100]: loss = 0.374565 * 100, metric = 5.24% * 100;
 Minibatch[1101-1200]: loss = 0.411014 * 100, metric = 5.95% * 100;
 Minibatch[1201-1300]: loss = 0.388839 * 100, metric = 5.72% * 100;
 Minibatch[1301-1400]: loss = 0.408060 * 100, metric = 5.94% * 100;
 Minibatch[1401-1500]: loss = 0.386177 * 100, metric = 5.58% * 100;
 Minibatch[1501-1600]: loss = 0.387785 * 100, metric = 5.24% * 100;
 Minibatch[1601-1700]: loss = 0.396931 * 100, metric = 5.79% * 100;
 Minibatch[1701-1800]: loss = 0.405352 * 100, metric = 5.83% * 100;
 Minibatch[1801-1900]: loss = 0.408929 * 100, metric = 6.07% * 100;
 Minibatch[1901-2000]: loss = 0.402728 * 100, metric = 5.96% * 100;
Finished Epoch[62 of 200]: [Training] loss = 0.397966 * 2000, metric = 5.74% * 2000 887.419s (  2.3 samples/s);
Finished Evaluation [62]: Minibatch[1-2000]: metric = 13.99% * 2000;
 Minibatch[   1- 100]: loss = 0.401472 * 100, metric = 5.87% * 100;
 Minibatch[ 101- 200]: loss = 0.388731 * 100, metric = 5.45% * 100;
 Minibatch[ 201- 300]: loss = 0.412532 * 100, metric = 6.21% * 100;
 Minibatch[ 301- 400]: loss = 0.383191 * 100, metric = 5.60% * 100;
 Minibatch[ 401- 500]: loss = 0.389982 * 100, metric = 5.54% * 100;
 Minibatch[ 501- 600]: loss = 0.393266 * 100, metric = 5.49% * 100;
 Minibatch[ 601- 700]: loss = 0.406374 * 100, metric = 6.03% * 100;
 Minibatch[ 701- 800]: loss = 0.401854 * 100, metric = 6.05% * 100;
 Minibatch[ 801- 900]: loss = 0.394928 * 100, metric = 5.67% * 100;
 Minibatch[ 901-1000]: loss = 0.383354 * 100, metric = 5.11% * 100;
 Minibatch[1001-1100]: loss = 0.397365 * 100, metric = 5.66% * 100;
 Minibatch[1101-1200]: loss = 0.395919 * 100, metric = 5.72% * 100;
 Minibatch[1201-1300]: loss = 0.400594 * 100, metric = 5.81% * 100;
 Minibatch[1301-1400]: loss = 0.404856 * 100, metric = 5.79% * 100;
 Minibatch[1401-1500]: loss = 0.385859 * 100, metric = 5.52% * 100;
 Minibatch[1501-1600]: loss = 0.395523 * 100, metric = 5.81% * 100;
 Minibatch[1601-1700]: loss = 0.401934 * 100, metric = 5.84% * 100;
 Minibatch[1701-1800]: loss = 0.387593 * 100, metric = 5.60% * 100;
 Minibatch[1801-1900]: loss = 0.395245 * 100, metric = 5.40% * 100;
 Minibatch[1901-2000]: loss = 0.399930 * 100, metric = 5.86% * 100;
Finished Epoch[63 of 200]: [Training] loss = 0.396025 * 2000, metric = 5.70% * 2000 885.310s (  2.3 samples/s);
Finished Evaluation [63]: Minibatch[1-2000]: metric = 13.47% * 2000;
 Minibatch[   1- 100]: loss = 0.394341 * 100, metric = 5.63% * 100;
 Minibatch[ 101- 200]: loss = 0.405960 * 100, metric = 5.77% * 100;
 Minibatch[ 201- 300]: loss = 0.401908 * 100, metric = 5.85% * 100;
 Minibatch[ 301- 400]: loss = 0.414407 * 100, metric = 6.01% * 100;
 Minibatch[ 401- 500]: loss = 0.397151 * 100, metric = 6.02% * 100;
 Minibatch[ 501- 600]: loss = 0.394868 * 100, metric = 5.52% * 100;
 Minibatch[ 601- 700]: loss = 0.389122 * 100, metric = 5.40% * 100;
 Minibatch[ 701- 800]: loss = 0.397865 * 100, metric = 5.68% * 100;
 Minibatch[ 801- 900]: loss = 0.400674 * 100, metric = 5.76% * 100;
 Minibatch[ 901-1000]: loss = 0.391379 * 100, metric = 5.45% * 100;
 Minibatch[1001-1100]: loss = 0.392941 * 100, metric = 5.67% * 100;
 Minibatch[1101-1200]: loss = 0.393282 * 100, metric = 5.80% * 100;
 Minibatch[1201-1300]: loss = 0.387755 * 100, metric = 5.45% * 100;
 Minibatch[1301-1400]: loss = 0.404102 * 100, metric = 6.05% * 100;
 Minibatch[1401-1500]: loss = 0.406205 * 100, metric = 5.88% * 100;
 Minibatch[1501-1600]: loss = 0.404031 * 100, metric = 6.00% * 100;
 Minibatch[1601-1700]: loss = 0.390056 * 100, metric = 5.40% * 100;
 Minibatch[1701-1800]: loss = 0.396661 * 100, metric = 5.61% * 100;
 Minibatch[1801-1900]: loss = 0.408561 * 100, metric = 5.96% * 100;
 Minibatch[1901-2000]: loss = 0.397696 * 100, metric = 5.90% * 100;
Finished Epoch[64 of 200]: [Training] loss = 0.398448 * 2000, metric = 5.74% * 2000 906.737s (  2.2 samples/s);
Finished Evaluation [64]: Minibatch[1-2000]: metric = 15.50% * 2000;
 Minibatch[   1- 100]: loss = 0.386822 * 100, metric = 5.41% * 100;
 Minibatch[ 101- 200]: loss = 0.384234 * 100, metric = 5.39% * 100;
 Minibatch[ 201- 300]: loss = 0.401036 * 100, metric = 5.65% * 100;
 Minibatch[ 301- 400]: loss = 0.393585 * 100, metric = 5.74% * 100;
 Minibatch[ 401- 500]: loss = 0.394556 * 100, metric = 5.57% * 100;
 Minibatch[ 501- 600]: loss = 0.397625 * 100, metric = 5.84% * 100;
 Minibatch[ 601- 700]: loss = 0.399487 * 100, metric = 5.96% * 100;
 Minibatch[ 701- 800]: loss = 0.406823 * 100, metric = 6.09% * 100;
 Minibatch[ 801- 900]: loss = 0.394099 * 100, metric = 5.87% * 100;
 Minibatch[ 901-1000]: loss = 0.401051 * 100, metric = 5.90% * 100;
 Minibatch[1001-1100]: loss = 0.396255 * 100, metric = 5.85% * 100;
 Minibatch[1101-1200]: loss = 0.401789 * 100, metric = 5.78% * 100;
 Minibatch[1201-1300]: loss = 0.407714 * 100, metric = 5.98% * 100;
 Minibatch[1301-1400]: loss = 0.391871 * 100, metric = 5.67% * 100;
 Minibatch[1401-1500]: loss = 0.393732 * 100, metric = 5.62% * 100;
 Minibatch[1501-1600]: loss = 0.389740 * 100, metric = 5.58% * 100;
 Minibatch[1601-1700]: loss = 0.408278 * 100, metric = 5.90% * 100;
 Minibatch[1701-1800]: loss = 0.406473 * 100, metric = 5.94% * 100;
 Minibatch[1801-1900]: loss = 0.403149 * 100, metric = 5.90% * 100;
 Minibatch[1901-2000]: loss = 0.392153 * 100, metric = 5.58% * 100;
Finished Epoch[65 of 200]: [Training] loss = 0.397524 * 2000, metric = 5.76% * 2000 907.136s (  2.2 samples/s);
Finished Evaluation [65]: Minibatch[1-2000]: metric = 13.55% * 2000;
 Minibatch[   1- 100]: loss = 0.395257 * 100, metric = 5.76% * 100;
 Minibatch[ 101- 200]: loss = 0.402788 * 100, metric = 5.92% * 100;
 Minibatch[ 201- 300]: loss = 0.401300 * 100, metric = 5.88% * 100;
 Minibatch[ 301- 400]: loss = 0.387810 * 100, metric = 5.66% * 100;
 Minibatch[ 401- 500]: loss = 0.396731 * 100, metric = 5.94% * 100;
 Minibatch[ 501- 600]: loss = 0.384355 * 100, metric = 5.56% * 100;
 Minibatch[ 601- 700]: loss = 0.382300 * 100, metric = 5.32% * 100;
 Minibatch[ 701- 800]: loss = 0.391175 * 100, metric = 5.65% * 100;
 Minibatch[ 801- 900]: loss = 0.372500 * 100, metric = 5.25% * 100;
 Minibatch[ 901-1000]: loss = 0.376960 * 100, metric = 5.29% * 100;
 Minibatch[1001-1100]: loss = 0.394221 * 100, metric = 5.67% * 100;
 Minibatch[1101-1200]: loss = 0.391906 * 100, metric = 5.78% * 100;
 Minibatch[1201-1300]: loss = 0.396209 * 100, metric = 5.68% * 100;
 Minibatch[1301-1400]: loss = 0.390221 * 100, metric = 5.48% * 100;
 Minibatch[1401-1500]: loss = 0.383493 * 100, metric = 5.46% * 100;
 Minibatch[1501-1600]: loss = 0.390143 * 100, metric = 5.54% * 100;
 Minibatch[1601-1700]: loss = 0.387676 * 100, metric = 5.44% * 100;
 Minibatch[1701-1800]: loss = 0.395927 * 100, metric = 5.86% * 100;
 Minibatch[1801-1900]: loss = 0.395858 * 100, metric = 5.70% * 100;
 Minibatch[1901-2000]: loss = 0.387822 * 100, metric = 5.44% * 100;
Finished Epoch[66 of 200]: [Training] loss = 0.390233 * 2000, metric = 5.62% * 2000 921.968s (  2.2 samples/s);
Finished Evaluation [66]: Minibatch[1-2000]: metric = 14.23% * 2000;
 Minibatch[   1- 100]: loss = 0.393342 * 100, metric = 5.65% * 100;
 Minibatch[ 101- 200]: loss = 0.391882 * 100, metric = 5.59% * 100;
 Minibatch[ 201- 300]: loss = 0.390007 * 100, metric = 5.70% * 100;
 Minibatch[ 301- 400]: loss = 0.399100 * 100, metric = 6.09% * 100;
 Minibatch[ 401- 500]: loss = 0.393494 * 100, metric = 5.87% * 100;
 Minibatch[ 501- 600]: loss = 0.391907 * 100, metric = 5.69% * 100;
 Minibatch[ 601- 700]: loss = 0.384074 * 100, metric = 5.48% * 100;
 Minibatch[ 701- 800]: loss = 0.392794 * 100, metric = 5.68% * 100;
 Minibatch[ 801- 900]: loss = 0.388665 * 100, metric = 5.63% * 100;
 Minibatch[ 901-1000]: loss = 0.390514 * 100, metric = 5.55% * 100;
 Minibatch[1001-1100]: loss = 0.380916 * 100, metric = 5.51% * 100;
 Minibatch[1101-1200]: loss = 0.392457 * 100, metric = 5.80% * 100;
 Minibatch[1201-1300]: loss = 0.394938 * 100, metric = 5.69% * 100;
 Minibatch[1301-1400]: loss = 0.392681 * 100, metric = 5.56% * 100;
 Minibatch[1401-1500]: loss = 0.366797 * 100, metric = 5.10% * 100;
 Minibatch[1501-1600]: loss = 0.387025 * 100, metric = 5.52% * 100;
 Minibatch[1601-1700]: loss = 0.380685 * 100, metric = 5.42% * 100;
 Minibatch[1701-1800]: loss = 0.400348 * 100, metric = 5.96% * 100;
 Minibatch[1801-1900]: loss = 0.383701 * 100, metric = 5.46% * 100;
 Minibatch[1901-2000]: loss = 0.400588 * 100, metric = 5.98% * 100;
Finished Epoch[67 of 200]: [Training] loss = 0.389796 * 2000, metric = 5.65% * 2000 893.524s (  2.2 samples/s);
Finished Evaluation [67]: Minibatch[1-2000]: metric = 13.28% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
