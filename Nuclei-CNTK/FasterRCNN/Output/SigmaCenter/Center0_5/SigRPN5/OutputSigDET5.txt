Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.353124 * 100, metric = 24.79% * 100;
 Minibatch[ 101- 200]: loss = 1.091265 * 100, metric = 23.05% * 100;
 Minibatch[ 201- 300]: loss = 0.963230 * 100, metric = 20.85% * 100;
 Minibatch[ 301- 400]: loss = 0.966804 * 100, metric = 19.58% * 100;
 Minibatch[ 401- 500]: loss = 0.880352 * 100, metric = 17.85% * 100;
 Minibatch[ 501- 600]: loss = 0.849982 * 100, metric = 16.39% * 100;
 Minibatch[ 601- 700]: loss = 0.824779 * 100, metric = 15.82% * 100;
 Minibatch[ 701- 800]: loss = 0.761690 * 100, metric = 14.71% * 100;
 Minibatch[ 801- 900]: loss = 0.796630 * 100, metric = 15.50% * 100;
 Minibatch[ 901-1000]: loss = 0.803428 * 100, metric = 15.54% * 100;
 Minibatch[1001-1100]: loss = 0.789627 * 100, metric = 15.17% * 100;
 Minibatch[1101-1200]: loss = 0.786013 * 100, metric = 14.68% * 100;
 Minibatch[1201-1300]: loss = 0.777230 * 100, metric = 14.77% * 100;
 Minibatch[1301-1400]: loss = 0.763258 * 100, metric = 14.13% * 100;
 Minibatch[1401-1500]: loss = 0.771743 * 100, metric = 14.52% * 100;
 Minibatch[1501-1600]: loss = 0.754030 * 100, metric = 14.20% * 100;
 Minibatch[1601-1700]: loss = 0.735458 * 100, metric = 13.84% * 100;
 Minibatch[1701-1800]: loss = 0.739777 * 100, metric = 14.00% * 100;
 Minibatch[1801-1900]: loss = 0.736471 * 100, metric = 13.72% * 100;
 Minibatch[1901-2000]: loss = 0.720236 * 100, metric = 13.05% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.843256 * 2000, metric = 16.31% * 2000 1035.473s (  1.9 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 27.29% * 2000;
0.8740673185735941
 Minibatch[   1- 100]: loss = 0.711077 * 100, metric = 12.97% * 100;
 Minibatch[ 101- 200]: loss = 0.746220 * 100, metric = 13.84% * 100;
 Minibatch[ 201- 300]: loss = 0.722314 * 100, metric = 12.98% * 100;
 Minibatch[ 301- 400]: loss = 0.722022 * 100, metric = 13.17% * 100;
 Minibatch[ 401- 500]: loss = 0.696066 * 100, metric = 12.46% * 100;
 Minibatch[ 501- 600]: loss = 0.699020 * 100, metric = 12.30% * 100;
 Minibatch[ 601- 700]: loss = 0.680500 * 100, metric = 12.17% * 100;
 Minibatch[ 701- 800]: loss = 0.681901 * 100, metric = 12.65% * 100;
 Minibatch[ 801- 900]: loss = 0.665466 * 100, metric = 11.90% * 100;
 Minibatch[ 901-1000]: loss = 0.646441 * 100, metric = 11.30% * 100;
 Minibatch[1001-1100]: loss = 0.666892 * 100, metric = 12.23% * 100;
 Minibatch[1101-1200]: loss = 0.665970 * 100, metric = 11.57% * 100;
 Minibatch[1201-1300]: loss = 0.659849 * 100, metric = 11.83% * 100;
 Minibatch[1301-1400]: loss = 0.664697 * 100, metric = 11.67% * 100;
 Minibatch[1401-1500]: loss = 0.641516 * 100, metric = 11.27% * 100;
 Minibatch[1501-1600]: loss = 0.643796 * 100, metric = 11.36% * 100;
 Minibatch[1601-1700]: loss = 0.657047 * 100, metric = 11.61% * 100;
 Minibatch[1701-1800]: loss = 0.658800 * 100, metric = 11.76% * 100;
 Minibatch[1801-1900]: loss = 0.662167 * 100, metric = 11.47% * 100;
 Minibatch[1901-2000]: loss = 0.622480 * 100, metric = 11.03% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.675712 * 2000, metric = 12.08% * 2000 988.579s (  2.0 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 21.52% * 2000;
0.7699660240784287
 Minibatch[   1- 100]: loss = 0.638124 * 100, metric = 11.19% * 100;
 Minibatch[ 101- 200]: loss = 0.639555 * 100, metric = 11.35% * 100;
 Minibatch[ 201- 300]: loss = 0.629053 * 100, metric = 11.13% * 100;
 Minibatch[ 301- 400]: loss = 0.646104 * 100, metric = 11.71% * 100;
 Minibatch[ 401- 500]: loss = 0.654191 * 100, metric = 11.89% * 100;
 Minibatch[ 501- 600]: loss = 0.650700 * 100, metric = 11.53% * 100;
 Minibatch[ 601- 700]: loss = 0.644582 * 100, metric = 11.51% * 100;
 Minibatch[ 701- 800]: loss = 0.611674 * 100, metric = 10.43% * 100;
 Minibatch[ 801- 900]: loss = 0.631866 * 100, metric = 11.06% * 100;
 Minibatch[ 901-1000]: loss = 0.609628 * 100, metric = 11.05% * 100;
 Minibatch[1001-1100]: loss = 0.625286 * 100, metric = 11.05% * 100;
 Minibatch[1101-1200]: loss = 0.605984 * 100, metric = 10.71% * 100;
 Minibatch[1201-1300]: loss = 0.609263 * 100, metric = 10.66% * 100;
 Minibatch[1301-1400]: loss = 0.627621 * 100, metric = 10.97% * 100;
 Minibatch[1401-1500]: loss = 0.627736 * 100, metric = 11.03% * 100;
 Minibatch[1501-1600]: loss = 0.608324 * 100, metric = 10.49% * 100;
 Minibatch[1601-1700]: loss = 0.599224 * 100, metric = 10.01% * 100;
 Minibatch[1701-1800]: loss = 0.620609 * 100, metric = 10.87% * 100;
 Minibatch[1801-1900]: loss = 0.605168 * 100, metric = 10.41% * 100;
 Minibatch[1901-2000]: loss = 0.601599 * 100, metric = 10.47% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.624315 * 2000, metric = 10.98% * 2000 959.277s (  2.1 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 19.95% * 2000;
0.7182286698073149
 Minibatch[   1- 100]: loss = 0.630837 * 100, metric = 10.82% * 100;
 Minibatch[ 101- 200]: loss = 0.593554 * 100, metric = 10.06% * 100;
 Minibatch[ 201- 300]: loss = 0.613317 * 100, metric = 10.69% * 100;
 Minibatch[ 301- 400]: loss = 0.578914 * 100, metric = 10.12% * 100;
 Minibatch[ 401- 500]: loss = 0.613989 * 100, metric = 10.70% * 100;
 Minibatch[ 501- 600]: loss = 0.594049 * 100, metric = 10.08% * 100;
 Minibatch[ 601- 700]: loss = 0.599038 * 100, metric = 10.43% * 100;
 Minibatch[ 701- 800]: loss = 0.602740 * 100, metric = 10.45% * 100;
 Minibatch[ 801- 900]: loss = 0.603308 * 100, metric = 10.67% * 100;
 Minibatch[ 901-1000]: loss = 0.606339 * 100, metric = 10.77% * 100;
 Minibatch[1001-1100]: loss = 0.615618 * 100, metric = 10.76% * 100;
 Minibatch[1101-1200]: loss = 0.594597 * 100, metric = 10.59% * 100;
 Minibatch[1201-1300]: loss = 0.590760 * 100, metric = 10.23% * 100;
 Minibatch[1301-1400]: loss = 0.621301 * 100, metric = 10.94% * 100;
 Minibatch[1401-1500]: loss = 0.616932 * 100, metric = 10.61% * 100;
 Minibatch[1501-1600]: loss = 0.581495 * 100, metric = 9.76% * 100;
 Minibatch[1601-1700]: loss = 0.611899 * 100, metric = 10.72% * 100;
 Minibatch[1701-1800]: loss = 0.606903 * 100, metric = 10.68% * 100;
 Minibatch[1801-1900]: loss = 0.586602 * 100, metric = 9.88% * 100;
 Minibatch[1901-2000]: loss = 0.575206 * 100, metric = 9.94% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.601870 * 2000, metric = 10.44% * 2000 950.805s (  2.1 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 21.34% * 2000;
 Minibatch[   1- 100]: loss = 0.591667 * 100, metric = 10.26% * 100;
 Minibatch[ 101- 200]: loss = 0.588939 * 100, metric = 10.18% * 100;
 Minibatch[ 201- 300]: loss = 0.573841 * 100, metric = 9.90% * 100;
 Minibatch[ 301- 400]: loss = 0.600511 * 100, metric = 10.71% * 100;
 Minibatch[ 401- 500]: loss = 0.562558 * 100, metric = 9.34% * 100;
 Minibatch[ 501- 600]: loss = 0.565125 * 100, metric = 9.54% * 100;
 Minibatch[ 601- 700]: loss = 0.581107 * 100, metric = 9.60% * 100;
 Minibatch[ 701- 800]: loss = 0.591363 * 100, metric = 9.99% * 100;
 Minibatch[ 801- 900]: loss = 0.569327 * 100, metric = 9.42% * 100;
 Minibatch[ 901-1000]: loss = 0.568792 * 100, metric = 9.84% * 100;
 Minibatch[1001-1100]: loss = 0.578860 * 100, metric = 9.89% * 100;
 Minibatch[1101-1200]: loss = 0.570839 * 100, metric = 9.67% * 100;
 Minibatch[1201-1300]: loss = 0.585557 * 100, metric = 9.78% * 100;
 Minibatch[1301-1400]: loss = 0.611052 * 100, metric = 10.65% * 100;
 Minibatch[1401-1500]: loss = 0.591173 * 100, metric = 10.03% * 100;
 Minibatch[1501-1600]: loss = 0.581400 * 100, metric = 9.84% * 100;
 Minibatch[1601-1700]: loss = 0.593383 * 100, metric = 10.28% * 100;
 Minibatch[1701-1800]: loss = 0.596409 * 100, metric = 10.15% * 100;
 Minibatch[1801-1900]: loss = 0.586530 * 100, metric = 10.06% * 100;
 Minibatch[1901-2000]: loss = 0.560222 * 100, metric = 9.52% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.582433 * 2000, metric = 9.93% * 2000 940.483s (  2.1 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 17.88% * 2000;
0.6710283964201808
 Minibatch[   1- 100]: loss = 0.565249 * 100, metric = 9.46% * 100;
 Minibatch[ 101- 200]: loss = 0.564209 * 100, metric = 9.71% * 100;
 Minibatch[ 201- 300]: loss = 0.579625 * 100, metric = 9.76% * 100;
 Minibatch[ 301- 400]: loss = 0.575107 * 100, metric = 9.36% * 100;
 Minibatch[ 401- 500]: loss = 0.547446 * 100, metric = 9.18% * 100;
 Minibatch[ 501- 600]: loss = 0.563001 * 100, metric = 9.82% * 100;
 Minibatch[ 601- 700]: loss = 0.558100 * 100, metric = 9.45% * 100;
 Minibatch[ 701- 800]: loss = 0.571586 * 100, metric = 9.56% * 100;
 Minibatch[ 801- 900]: loss = 0.574225 * 100, metric = 9.90% * 100;
 Minibatch[ 901-1000]: loss = 0.556873 * 100, metric = 9.41% * 100;
 Minibatch[1001-1100]: loss = 0.567484 * 100, metric = 9.29% * 100;
 Minibatch[1101-1200]: loss = 0.580534 * 100, metric = 9.78% * 100;
 Minibatch[1201-1300]: loss = 0.588932 * 100, metric = 10.15% * 100;
 Minibatch[1301-1400]: loss = 0.567802 * 100, metric = 9.47% * 100;
 Minibatch[1401-1500]: loss = 0.586471 * 100, metric = 10.31% * 100;
 Minibatch[1501-1600]: loss = 0.560286 * 100, metric = 9.26% * 100;
 Minibatch[1601-1700]: loss = 0.562186 * 100, metric = 9.32% * 100;
 Minibatch[1701-1800]: loss = 0.540828 * 100, metric = 9.09% * 100;
 Minibatch[1801-1900]: loss = 0.571708 * 100, metric = 9.52% * 100;
 Minibatch[1901-2000]: loss = 0.559572 * 100, metric = 9.44% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.567061 * 2000, metric = 9.56% * 2000 946.463s (  2.1 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 19.05% * 2000;
 Minibatch[   1- 100]: loss = 0.560945 * 100, metric = 9.51% * 100;
 Minibatch[ 101- 200]: loss = 0.564325 * 100, metric = 9.23% * 100;
 Minibatch[ 201- 300]: loss = 0.564559 * 100, metric = 9.52% * 100;
 Minibatch[ 301- 400]: loss = 0.556411 * 100, metric = 9.16% * 100;
 Minibatch[ 401- 500]: loss = 0.555022 * 100, metric = 9.16% * 100;
 Minibatch[ 501- 600]: loss = 0.531519 * 100, metric = 8.62% * 100;
 Minibatch[ 601- 700]: loss = 0.547754 * 100, metric = 8.76% * 100;
 Minibatch[ 701- 800]: loss = 0.554823 * 100, metric = 8.95% * 100;
 Minibatch[ 801- 900]: loss = 0.551811 * 100, metric = 9.05% * 100;
 Minibatch[ 901-1000]: loss = 0.546136 * 100, metric = 8.99% * 100;
 Minibatch[1001-1100]: loss = 0.549636 * 100, metric = 9.31% * 100;
 Minibatch[1101-1200]: loss = 0.541705 * 100, metric = 8.86% * 100;
 Minibatch[1201-1300]: loss = 0.552942 * 100, metric = 9.40% * 100;
 Minibatch[1301-1400]: loss = 0.535837 * 100, metric = 8.79% * 100;
 Minibatch[1401-1500]: loss = 0.534238 * 100, metric = 8.62% * 100;
 Minibatch[1501-1600]: loss = 0.546058 * 100, metric = 9.07% * 100;
 Minibatch[1601-1700]: loss = 0.554681 * 100, metric = 9.24% * 100;
 Minibatch[1701-1800]: loss = 0.535968 * 100, metric = 8.71% * 100;
 Minibatch[1801-1900]: loss = 0.541870 * 100, metric = 9.10% * 100;
 Minibatch[1901-2000]: loss = 0.543315 * 100, metric = 9.05% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.548478 * 2000, metric = 9.05% * 2000 940.235s (  2.1 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 16.60% * 2000;
0.646775083296001
 Minibatch[   1- 100]: loss = 0.554276 * 100, metric = 9.13% * 100;
 Minibatch[ 101- 200]: loss = 0.540178 * 100, metric = 8.76% * 100;
 Minibatch[ 201- 300]: loss = 0.534549 * 100, metric = 8.95% * 100;
 Minibatch[ 301- 400]: loss = 0.533131 * 100, metric = 8.73% * 100;
 Minibatch[ 401- 500]: loss = 0.547375 * 100, metric = 9.14% * 100;
 Minibatch[ 501- 600]: loss = 0.559224 * 100, metric = 9.28% * 100;
 Minibatch[ 601- 700]: loss = 0.518495 * 100, metric = 8.35% * 100;
 Minibatch[ 701- 800]: loss = 0.540639 * 100, metric = 8.73% * 100;
 Minibatch[ 801- 900]: loss = 0.519450 * 100, metric = 8.35% * 100;
 Minibatch[ 901-1000]: loss = 0.520177 * 100, metric = 8.42% * 100;
 Minibatch[1001-1100]: loss = 0.521627 * 100, metric = 8.46% * 100;
 Minibatch[1101-1200]: loss = 0.511740 * 100, metric = 8.20% * 100;
 Minibatch[1201-1300]: loss = 0.530134 * 100, metric = 8.76% * 100;
 Minibatch[1301-1400]: loss = 0.534616 * 100, metric = 8.78% * 100;
 Minibatch[1401-1500]: loss = 0.525746 * 100, metric = 8.42% * 100;
 Minibatch[1501-1600]: loss = 0.538541 * 100, metric = 8.78% * 100;
 Minibatch[1601-1700]: loss = 0.527106 * 100, metric = 8.52% * 100;
 Minibatch[1701-1800]: loss = 0.522950 * 100, metric = 8.46% * 100;
 Minibatch[1801-1900]: loss = 0.519613 * 100, metric = 8.38% * 100;
 Minibatch[1901-2000]: loss = 0.526235 * 100, metric = 8.48% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.531290 * 2000, metric = 8.65% * 2000 938.486s (  2.1 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 16.07% * 2000;
0.6320422312989831
 Minibatch[   1- 100]: loss = 0.503824 * 100, metric = 8.00% * 100;
 Minibatch[ 101- 200]: loss = 0.530169 * 100, metric = 8.74% * 100;
 Minibatch[ 201- 300]: loss = 0.530518 * 100, metric = 8.59% * 100;
 Minibatch[ 301- 400]: loss = 0.535934 * 100, metric = 8.74% * 100;
 Minibatch[ 401- 500]: loss = 0.518662 * 100, metric = 8.22% * 100;
 Minibatch[ 501- 600]: loss = 0.506545 * 100, metric = 8.06% * 100;
 Minibatch[ 601- 700]: loss = 0.511847 * 100, metric = 8.17% * 100;
 Minibatch[ 701- 800]: loss = 0.501516 * 100, metric = 7.91% * 100;
 Minibatch[ 801- 900]: loss = 0.501193 * 100, metric = 7.88% * 100;
 Minibatch[ 901-1000]: loss = 0.517664 * 100, metric = 8.43% * 100;
 Minibatch[1001-1100]: loss = 0.487891 * 100, metric = 7.59% * 100;
 Minibatch[1101-1200]: loss = 0.511334 * 100, metric = 8.00% * 100;
 Minibatch[1201-1300]: loss = 0.507643 * 100, metric = 8.23% * 100;
 Minibatch[1301-1400]: loss = 0.497521 * 100, metric = 7.70% * 100;
 Minibatch[1401-1500]: loss = 0.517866 * 100, metric = 8.40% * 100;
 Minibatch[1501-1600]: loss = 0.514653 * 100, metric = 7.98% * 100;
 Minibatch[1601-1700]: loss = 0.517813 * 100, metric = 8.30% * 100;
 Minibatch[1701-1800]: loss = 0.511813 * 100, metric = 8.01% * 100;
 Minibatch[1801-1900]: loss = 0.502161 * 100, metric = 7.91% * 100;
 Minibatch[1901-2000]: loss = 0.523911 * 100, metric = 8.38% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.512524 * 2000, metric = 8.16% * 2000 940.691s (  2.1 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 16.05% * 2000;
0.6302346662133932
 Minibatch[   1- 100]: loss = 0.535937 * 100, metric = 8.97% * 100;
 Minibatch[ 101- 200]: loss = 0.501487 * 100, metric = 8.00% * 100;
 Minibatch[ 201- 300]: loss = 0.519362 * 100, metric = 8.41% * 100;
 Minibatch[ 301- 400]: loss = 0.502893 * 100, metric = 7.90% * 100;
 Minibatch[ 401- 500]: loss = 0.512227 * 100, metric = 8.23% * 100;
 Minibatch[ 501- 600]: loss = 0.493813 * 100, metric = 7.57% * 100;
 Minibatch[ 601- 700]: loss = 0.490685 * 100, metric = 7.67% * 100;
 Minibatch[ 701- 800]: loss = 0.486021 * 100, metric = 7.39% * 100;
 Minibatch[ 801- 900]: loss = 0.501605 * 100, metric = 7.77% * 100;
 Minibatch[ 901-1000]: loss = 0.506695 * 100, metric = 7.98% * 100;
 Minibatch[1001-1100]: loss = 0.499409 * 100, metric = 7.89% * 100;
 Minibatch[1101-1200]: loss = 0.504896 * 100, metric = 7.93% * 100;
 Minibatch[1201-1300]: loss = 0.509351 * 100, metric = 8.17% * 100;
 Minibatch[1301-1400]: loss = 0.501725 * 100, metric = 8.02% * 100;
 Minibatch[1401-1500]: loss = 0.486143 * 100, metric = 7.38% * 100;
 Minibatch[1501-1600]: loss = 0.497684 * 100, metric = 8.01% * 100;
 Minibatch[1601-1700]: loss = 0.493242 * 100, metric = 7.56% * 100;
 Minibatch[1701-1800]: loss = 0.510916 * 100, metric = 7.91% * 100;
 Minibatch[1801-1900]: loss = 0.511968 * 100, metric = 8.09% * 100;
 Minibatch[1901-2000]: loss = 0.492949 * 100, metric = 7.60% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.502950 * 2000, metric = 7.92% * 2000 918.513s (  2.2 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 14.91% * 2000;
0.6118784253001213
 Minibatch[   1- 100]: loss = 0.473422 * 100, metric = 7.22% * 100;
 Minibatch[ 101- 200]: loss = 0.497078 * 100, metric = 7.75% * 100;
 Minibatch[ 201- 300]: loss = 0.507065 * 100, metric = 7.88% * 100;
 Minibatch[ 301- 400]: loss = 0.495691 * 100, metric = 7.48% * 100;
 Minibatch[ 401- 500]: loss = 0.489075 * 100, metric = 7.66% * 100;
 Minibatch[ 501- 600]: loss = 0.500704 * 100, metric = 7.84% * 100;
 Minibatch[ 601- 700]: loss = 0.488114 * 100, metric = 7.56% * 100;
 Minibatch[ 701- 800]: loss = 0.502588 * 100, metric = 8.01% * 100;
 Minibatch[ 801- 900]: loss = 0.496296 * 100, metric = 7.79% * 100;
 Minibatch[ 901-1000]: loss = 0.510078 * 100, metric = 8.21% * 100;
 Minibatch[1001-1100]: loss = 0.499017 * 100, metric = 7.96% * 100;
 Minibatch[1101-1200]: loss = 0.506306 * 100, metric = 8.13% * 100;
 Minibatch[1201-1300]: loss = 0.491756 * 100, metric = 7.89% * 100;
 Minibatch[1301-1400]: loss = 0.476924 * 100, metric = 7.50% * 100;
 Minibatch[1401-1500]: loss = 0.496453 * 100, metric = 7.86% * 100;
 Minibatch[1501-1600]: loss = 0.483641 * 100, metric = 7.38% * 100;
 Minibatch[1601-1700]: loss = 0.495186 * 100, metric = 7.67% * 100;
 Minibatch[1701-1800]: loss = 0.502618 * 100, metric = 7.82% * 100;
 Minibatch[1801-1900]: loss = 0.495148 * 100, metric = 7.78% * 100;
 Minibatch[1901-2000]: loss = 0.491416 * 100, metric = 7.71% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.494929 * 2000, metric = 7.76% * 2000 935.665s (  2.1 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 15.05% * 2000;
 Minibatch[   1- 100]: loss = 0.467463 * 100, metric = 7.10% * 100;
 Minibatch[ 101- 200]: loss = 0.470526 * 100, metric = 7.01% * 100;
 Minibatch[ 201- 300]: loss = 0.471842 * 100, metric = 7.23% * 100;
 Minibatch[ 301- 400]: loss = 0.511800 * 100, metric = 8.12% * 100;
 Minibatch[ 401- 500]: loss = 0.476030 * 100, metric = 7.32% * 100;
 Minibatch[ 501- 600]: loss = 0.466360 * 100, metric = 7.21% * 100;
 Minibatch[ 601- 700]: loss = 0.479622 * 100, metric = 7.42% * 100;
 Minibatch[ 701- 800]: loss = 0.482746 * 100, metric = 7.54% * 100;
 Minibatch[ 801- 900]: loss = 0.475459 * 100, metric = 7.25% * 100;
 Minibatch[ 901-1000]: loss = 0.485032 * 100, metric = 7.77% * 100;
 Minibatch[1001-1100]: loss = 0.485334 * 100, metric = 7.67% * 100;
 Minibatch[1101-1200]: loss = 0.483477 * 100, metric = 7.64% * 100;
 Minibatch[1201-1300]: loss = 0.491621 * 100, metric = 7.83% * 100;
 Minibatch[1301-1400]: loss = 0.474555 * 100, metric = 7.20% * 100;
 Minibatch[1401-1500]: loss = 0.494229 * 100, metric = 7.67% * 100;
 Minibatch[1501-1600]: loss = 0.461117 * 100, metric = 7.18% * 100;
 Minibatch[1601-1700]: loss = 0.495775 * 100, metric = 7.54% * 100;
 Minibatch[1701-1800]: loss = 0.479405 * 100, metric = 7.35% * 100;
 Minibatch[1801-1900]: loss = 0.480396 * 100, metric = 7.53% * 100;
 Minibatch[1901-2000]: loss = 0.489891 * 100, metric = 7.50% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.481134 * 2000, metric = 7.45% * 2000 935.769s (  2.1 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 15.85% * 2000;
 Minibatch[   1- 100]: loss = 0.493672 * 100, metric = 7.65% * 100;
 Minibatch[ 101- 200]: loss = 0.486067 * 100, metric = 7.86% * 100;
 Minibatch[ 201- 300]: loss = 0.479469 * 100, metric = 7.68% * 100;
 Minibatch[ 301- 400]: loss = 0.487533 * 100, metric = 7.62% * 100;
 Minibatch[ 401- 500]: loss = 0.490356 * 100, metric = 7.94% * 100;
 Minibatch[ 501- 600]: loss = 0.486729 * 100, metric = 7.67% * 100;
 Minibatch[ 601- 700]: loss = 0.465883 * 100, metric = 7.23% * 100;
 Minibatch[ 701- 800]: loss = 0.467883 * 100, metric = 7.24% * 100;
 Minibatch[ 801- 900]: loss = 0.469379 * 100, metric = 7.18% * 100;
 Minibatch[ 901-1000]: loss = 0.488366 * 100, metric = 7.71% * 100;
 Minibatch[1001-1100]: loss = 0.483498 * 100, metric = 7.55% * 100;
 Minibatch[1101-1200]: loss = 0.477238 * 100, metric = 7.38% * 100;
 Minibatch[1201-1300]: loss = 0.485406 * 100, metric = 7.64% * 100;
 Minibatch[1301-1400]: loss = 0.473725 * 100, metric = 7.46% * 100;
 Minibatch[1401-1500]: loss = 0.467573 * 100, metric = 7.12% * 100;
 Minibatch[1501-1600]: loss = 0.460015 * 100, metric = 6.97% * 100;
 Minibatch[1601-1700]: loss = 0.455197 * 100, metric = 7.04% * 100;
 Minibatch[1701-1800]: loss = 0.462847 * 100, metric = 6.89% * 100;
 Minibatch[1801-1900]: loss = 0.463192 * 100, metric = 7.02% * 100;
 Minibatch[1901-2000]: loss = 0.481677 * 100, metric = 7.46% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.476285 * 2000, metric = 7.42% * 2000 932.918s (  2.1 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 17.21% * 2000;
 Minibatch[   1- 100]: loss = 0.477232 * 100, metric = 7.50% * 100;
 Minibatch[ 101- 200]: loss = 0.467750 * 100, metric = 7.27% * 100;
 Minibatch[ 201- 300]: loss = 0.484503 * 100, metric = 7.48% * 100;
 Minibatch[ 301- 400]: loss = 0.474171 * 100, metric = 7.12% * 100;
 Minibatch[ 401- 500]: loss = 0.472817 * 100, metric = 7.43% * 100;
 Minibatch[ 501- 600]: loss = 0.485432 * 100, metric = 7.67% * 100;
 Minibatch[ 601- 700]: loss = 0.469846 * 100, metric = 7.31% * 100;
 Minibatch[ 701- 800]: loss = 0.484433 * 100, metric = 7.43% * 100;
 Minibatch[ 801- 900]: loss = 0.483112 * 100, metric = 7.67% * 100;
 Minibatch[ 901-1000]: loss = 0.475591 * 100, metric = 7.35% * 100;
 Minibatch[1001-1100]: loss = 0.473843 * 100, metric = 7.39% * 100;
 Minibatch[1101-1200]: loss = 0.467728 * 100, metric = 7.07% * 100;
 Minibatch[1201-1300]: loss = 0.450844 * 100, metric = 6.85% * 100;
 Minibatch[1301-1400]: loss = 0.476155 * 100, metric = 7.48% * 100;
 Minibatch[1401-1500]: loss = 0.473398 * 100, metric = 7.52% * 100;
 Minibatch[1501-1600]: loss = 0.458203 * 100, metric = 7.14% * 100;
 Minibatch[1601-1700]: loss = 0.467775 * 100, metric = 7.18% * 100;
 Minibatch[1701-1800]: loss = 0.471570 * 100, metric = 7.13% * 100;
 Minibatch[1801-1900]: loss = 0.460248 * 100, metric = 6.99% * 100;
 Minibatch[1901-2000]: loss = 0.477433 * 100, metric = 7.23% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.472604 * 2000, metric = 7.31% * 2000 926.060s (  2.2 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 16.12% * 2000;
 Minibatch[   1- 100]: loss = 0.467719 * 100, metric = 7.11% * 100;
 Minibatch[ 101- 200]: loss = 0.476385 * 100, metric = 7.39% * 100;
 Minibatch[ 201- 300]: loss = 0.469733 * 100, metric = 6.89% * 100;
 Minibatch[ 301- 400]: loss = 0.459595 * 100, metric = 6.97% * 100;
 Minibatch[ 401- 500]: loss = 0.469305 * 100, metric = 7.32% * 100;
 Minibatch[ 501- 600]: loss = 0.454201 * 100, metric = 6.79% * 100;
 Minibatch[ 601- 700]: loss = 0.454904 * 100, metric = 7.11% * 100;
 Minibatch[ 701- 800]: loss = 0.478978 * 100, metric = 7.47% * 100;
 Minibatch[ 801- 900]: loss = 0.495114 * 100, metric = 8.15% * 100;
 Minibatch[ 901-1000]: loss = 0.474743 * 100, metric = 7.49% * 100;
 Minibatch[1001-1100]: loss = 0.478429 * 100, metric = 7.31% * 100;
 Minibatch[1101-1200]: loss = 0.472921 * 100, metric = 7.46% * 100;
 Minibatch[1201-1300]: loss = 0.463356 * 100, metric = 6.90% * 100;
 Minibatch[1301-1400]: loss = 0.479846 * 100, metric = 7.50% * 100;
 Minibatch[1401-1500]: loss = 0.450717 * 100, metric = 7.01% * 100;
 Minibatch[1501-1600]: loss = 0.453599 * 100, metric = 7.05% * 100;
 Minibatch[1601-1700]: loss = 0.471122 * 100, metric = 7.45% * 100;
 Minibatch[1701-1800]: loss = 0.445278 * 100, metric = 6.63% * 100;
 Minibatch[1801-1900]: loss = 0.453875 * 100, metric = 7.10% * 100;
 Minibatch[1901-2000]: loss = 0.451620 * 100, metric = 6.95% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.466072 * 2000, metric = 7.20% * 2000 918.471s (  2.2 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 13.49% * 2000;
0.5843227641135454
 Minibatch[   1- 100]: loss = 0.480395 * 100, metric = 7.59% * 100;
 Minibatch[ 101- 200]: loss = 0.468383 * 100, metric = 7.19% * 100;
 Minibatch[ 201- 300]: loss = 0.466672 * 100, metric = 7.03% * 100;
 Minibatch[ 301- 400]: loss = 0.457719 * 100, metric = 6.83% * 100;
 Minibatch[ 401- 500]: loss = 0.449898 * 100, metric = 7.07% * 100;
 Minibatch[ 501- 600]: loss = 0.453843 * 100, metric = 6.83% * 100;
 Minibatch[ 601- 700]: loss = 0.455513 * 100, metric = 6.95% * 100;
 Minibatch[ 701- 800]: loss = 0.451268 * 100, metric = 6.81% * 100;
 Minibatch[ 801- 900]: loss = 0.443285 * 100, metric = 6.63% * 100;
 Minibatch[ 901-1000]: loss = 0.452900 * 100, metric = 6.95% * 100;
 Minibatch[1001-1100]: loss = 0.437317 * 100, metric = 6.59% * 100;
 Minibatch[1101-1200]: loss = 0.447112 * 100, metric = 6.84% * 100;
 Minibatch[1201-1300]: loss = 0.430836 * 100, metric = 6.33% * 100;
 Minibatch[1301-1400]: loss = 0.444229 * 100, metric = 6.61% * 100;
 Minibatch[1401-1500]: loss = 0.444462 * 100, metric = 6.79% * 100;
 Minibatch[1501-1600]: loss = 0.456834 * 100, metric = 7.10% * 100;
 Minibatch[1601-1700]: loss = 0.459681 * 100, metric = 7.08% * 100;
 Minibatch[1701-1800]: loss = 0.467679 * 100, metric = 7.12% * 100;
 Minibatch[1801-1900]: loss = 0.457245 * 100, metric = 7.04% * 100;
 Minibatch[1901-2000]: loss = 0.443923 * 100, metric = 6.83% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.453460 * 2000, metric = 6.91% * 2000 932.968s (  2.1 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.23% * 2000;
 Minibatch[   1- 100]: loss = 0.444284 * 100, metric = 6.75% * 100;
 Minibatch[ 101- 200]: loss = 0.464800 * 100, metric = 7.12% * 100;
 Minibatch[ 201- 300]: loss = 0.464223 * 100, metric = 7.00% * 100;
 Minibatch[ 301- 400]: loss = 0.457902 * 100, metric = 6.88% * 100;
 Minibatch[ 401- 500]: loss = 0.464827 * 100, metric = 6.92% * 100;
 Minibatch[ 501- 600]: loss = 0.445809 * 100, metric = 6.66% * 100;
 Minibatch[ 601- 700]: loss = 0.430737 * 100, metric = 6.50% * 100;
 Minibatch[ 701- 800]: loss = 0.440276 * 100, metric = 6.60% * 100;
 Minibatch[ 801- 900]: loss = 0.450237 * 100, metric = 6.68% * 100;
 Minibatch[ 901-1000]: loss = 0.441036 * 100, metric = 6.53% * 100;
 Minibatch[1001-1100]: loss = 0.435503 * 100, metric = 6.62% * 100;
 Minibatch[1101-1200]: loss = 0.460620 * 100, metric = 7.13% * 100;
 Minibatch[1201-1300]: loss = 0.453151 * 100, metric = 6.64% * 100;
 Minibatch[1301-1400]: loss = 0.431187 * 100, metric = 6.38% * 100;
 Minibatch[1401-1500]: loss = 0.456979 * 100, metric = 6.96% * 100;
 Minibatch[1501-1600]: loss = 0.456939 * 100, metric = 6.91% * 100;
 Minibatch[1601-1700]: loss = 0.451136 * 100, metric = 6.71% * 100;
 Minibatch[1701-1800]: loss = 0.431989 * 100, metric = 6.63% * 100;
 Minibatch[1801-1900]: loss = 0.456934 * 100, metric = 7.21% * 100;
 Minibatch[1901-2000]: loss = 0.469365 * 100, metric = 7.20% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.450397 * 2000, metric = 6.80% * 2000 920.372s (  2.2 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.12% * 2000;
 Minibatch[   1- 100]: loss = 0.431469 * 100, metric = 6.24% * 100;
 Minibatch[ 101- 200]: loss = 0.455566 * 100, metric = 6.82% * 100;
 Minibatch[ 201- 300]: loss = 0.430222 * 100, metric = 6.58% * 100;
 Minibatch[ 301- 400]: loss = 0.438602 * 100, metric = 6.52% * 100;
 Minibatch[ 401- 500]: loss = 0.433992 * 100, metric = 6.45% * 100;
 Minibatch[ 501- 600]: loss = 0.426889 * 100, metric = 6.24% * 100;
 Minibatch[ 601- 700]: loss = 0.435944 * 100, metric = 6.53% * 100;
 Minibatch[ 701- 800]: loss = 0.417495 * 100, metric = 6.15% * 100;
 Minibatch[ 801- 900]: loss = 0.439214 * 100, metric = 6.48% * 100;
 Minibatch[ 901-1000]: loss = 0.439518 * 100, metric = 6.46% * 100;
 Minibatch[1001-1100]: loss = 0.448047 * 100, metric = 6.78% * 100;
 Minibatch[1101-1200]: loss = 0.450300 * 100, metric = 6.79% * 100;
 Minibatch[1201-1300]: loss = 0.451644 * 100, metric = 6.79% * 100;
 Minibatch[1301-1400]: loss = 0.455063 * 100, metric = 7.09% * 100;
 Minibatch[1401-1500]: loss = 0.425364 * 100, metric = 6.13% * 100;
 Minibatch[1501-1600]: loss = 0.441542 * 100, metric = 6.55% * 100;
 Minibatch[1601-1700]: loss = 0.415432 * 100, metric = 6.01% * 100;
 Minibatch[1701-1800]: loss = 0.430801 * 100, metric = 6.04% * 100;
 Minibatch[1801-1900]: loss = 0.422582 * 100, metric = 6.50% * 100;
 Minibatch[1901-2000]: loss = 0.428996 * 100, metric = 6.19% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.435934 * 2000, metric = 6.47% * 2000 905.818s (  2.2 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.57% * 2000;
 Minibatch[   1- 100]: loss = 0.447017 * 100, metric = 6.58% * 100;
 Minibatch[ 101- 200]: loss = 0.443935 * 100, metric = 6.54% * 100;
 Minibatch[ 201- 300]: loss = 0.424463 * 100, metric = 6.05% * 100;
 Minibatch[ 301- 400]: loss = 0.439427 * 100, metric = 6.59% * 100;
 Minibatch[ 401- 500]: loss = 0.436016 * 100, metric = 6.24% * 100;
 Minibatch[ 501- 600]: loss = 0.426462 * 100, metric = 6.08% * 100;
 Minibatch[ 601- 700]: loss = 0.441760 * 100, metric = 6.60% * 100;
 Minibatch[ 701- 800]: loss = 0.427664 * 100, metric = 6.36% * 100;
 Minibatch[ 801- 900]: loss = 0.460181 * 100, metric = 7.10% * 100;
 Minibatch[ 901-1000]: loss = 0.423468 * 100, metric = 6.00% * 100;
 Minibatch[1001-1100]: loss = 0.446032 * 100, metric = 6.57% * 100;
 Minibatch[1101-1200]: loss = 0.441478 * 100, metric = 6.68% * 100;
 Minibatch[1201-1300]: loss = 0.431396 * 100, metric = 6.35% * 100;
 Minibatch[1301-1400]: loss = 0.426199 * 100, metric = 6.24% * 100;
 Minibatch[1401-1500]: loss = 0.439382 * 100, metric = 6.46% * 100;
 Minibatch[1501-1600]: loss = 0.439149 * 100, metric = 6.59% * 100;
 Minibatch[1601-1700]: loss = 0.430433 * 100, metric = 6.43% * 100;
 Minibatch[1701-1800]: loss = 0.417463 * 100, metric = 6.14% * 100;
 Minibatch[1801-1900]: loss = 0.422330 * 100, metric = 6.20% * 100;
 Minibatch[1901-2000]: loss = 0.418737 * 100, metric = 5.98% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.434150 * 2000, metric = 6.39% * 2000 916.871s (  2.2 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 13.96% * 2000;
 Minibatch[   1- 100]: loss = 0.424795 * 100, metric = 6.11% * 100;
 Minibatch[ 101- 200]: loss = 0.424274 * 100, metric = 6.29% * 100;
 Minibatch[ 201- 300]: loss = 0.424298 * 100, metric = 6.21% * 100;
 Minibatch[ 301- 400]: loss = 0.440297 * 100, metric = 6.33% * 100;
 Minibatch[ 401- 500]: loss = 0.429345 * 100, metric = 6.49% * 100;
 Minibatch[ 501- 600]: loss = 0.431100 * 100, metric = 6.54% * 100;
 Minibatch[ 601- 700]: loss = 0.446035 * 100, metric = 6.85% * 100;
 Minibatch[ 701- 800]: loss = 0.433956 * 100, metric = 6.61% * 100;
 Minibatch[ 801- 900]: loss = 0.437496 * 100, metric = 6.56% * 100;
 Minibatch[ 901-1000]: loss = 0.441567 * 100, metric = 6.75% * 100;
 Minibatch[1001-1100]: loss = 0.414619 * 100, metric = 6.12% * 100;
 Minibatch[1101-1200]: loss = 0.429251 * 100, metric = 6.26% * 100;
 Minibatch[1201-1300]: loss = 0.435714 * 100, metric = 6.42% * 100;
 Minibatch[1301-1400]: loss = 0.430343 * 100, metric = 6.40% * 100;
 Minibatch[1401-1500]: loss = 0.419585 * 100, metric = 6.42% * 100;
 Minibatch[1501-1600]: loss = 0.439957 * 100, metric = 6.57% * 100;
 Minibatch[1601-1700]: loss = 0.430809 * 100, metric = 6.63% * 100;
 Minibatch[1701-1800]: loss = 0.437675 * 100, metric = 6.61% * 100;
 Minibatch[1801-1900]: loss = 0.428121 * 100, metric = 6.44% * 100;
 Minibatch[1901-2000]: loss = 0.425809 * 100, metric = 6.31% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.431252 * 2000, metric = 6.45% * 2000 909.388s (  2.2 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 14.19% * 2000;
 Minibatch[   1- 100]: loss = 0.435759 * 100, metric = 6.46% * 100;
 Minibatch[ 101- 200]: loss = 0.431038 * 100, metric = 6.28% * 100;
 Minibatch[ 201- 300]: loss = 0.428767 * 100, metric = 6.53% * 100;
 Minibatch[ 301- 400]: loss = 0.441116 * 100, metric = 6.84% * 100;
 Minibatch[ 401- 500]: loss = 0.426289 * 100, metric = 6.44% * 100;
 Minibatch[ 501- 600]: loss = 0.425430 * 100, metric = 6.25% * 100;
 Minibatch[ 601- 700]: loss = 0.424774 * 100, metric = 6.43% * 100;
 Minibatch[ 701- 800]: loss = 0.405545 * 100, metric = 5.98% * 100;
 Minibatch[ 801- 900]: loss = 0.434442 * 100, metric = 6.47% * 100;
 Minibatch[ 901-1000]: loss = 0.428050 * 100, metric = 6.48% * 100;
 Minibatch[1001-1100]: loss = 0.428253 * 100, metric = 6.32% * 100;
 Minibatch[1101-1200]: loss = 0.412448 * 100, metric = 5.99% * 100;
 Minibatch[1201-1300]: loss = 0.424006 * 100, metric = 6.14% * 100;
 Minibatch[1301-1400]: loss = 0.411615 * 100, metric = 5.92% * 100;
 Minibatch[1401-1500]: loss = 0.427173 * 100, metric = 6.30% * 100;
 Minibatch[1501-1600]: loss = 0.429597 * 100, metric = 6.54% * 100;
 Minibatch[1601-1700]: loss = 0.418676 * 100, metric = 6.10% * 100;
 Minibatch[1701-1800]: loss = 0.412755 * 100, metric = 6.03% * 100;
 Minibatch[1801-1900]: loss = 0.436050 * 100, metric = 6.35% * 100;
 Minibatch[1901-2000]: loss = 0.407916 * 100, metric = 5.88% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.424485 * 2000, metric = 6.29% * 2000 909.733s (  2.2 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 12.88% * 2000;
 Minibatch[   1- 100]: loss = 0.425247 * 100, metric = 6.20% * 100;
 Minibatch[ 101- 200]: loss = 0.416027 * 100, metric = 6.08% * 100;
 Minibatch[ 201- 300]: loss = 0.422593 * 100, metric = 6.03% * 100;
 Minibatch[ 301- 400]: loss = 0.414905 * 100, metric = 6.16% * 100;
 Minibatch[ 401- 500]: loss = 0.411262 * 100, metric = 5.76% * 100;
 Minibatch[ 501- 600]: loss = 0.429235 * 100, metric = 6.29% * 100;
 Minibatch[ 601- 700]: loss = 0.421109 * 100, metric = 6.11% * 100;
 Minibatch[ 701- 800]: loss = 0.418309 * 100, metric = 6.18% * 100;
 Minibatch[ 801- 900]: loss = 0.425566 * 100, metric = 6.24% * 100;
 Minibatch[ 901-1000]: loss = 0.435309 * 100, metric = 6.53% * 100;
 Minibatch[1001-1100]: loss = 0.405661 * 100, metric = 5.64% * 100;
 Minibatch[1101-1200]: loss = 0.397100 * 100, metric = 5.51% * 100;
 Minibatch[1201-1300]: loss = 0.415605 * 100, metric = 5.99% * 100;
 Minibatch[1301-1400]: loss = 0.417801 * 100, metric = 6.16% * 100;
 Minibatch[1401-1500]: loss = 0.404218 * 100, metric = 5.92% * 100;
 Minibatch[1501-1600]: loss = 0.413008 * 100, metric = 5.92% * 100;
 Minibatch[1601-1700]: loss = 0.413758 * 100, metric = 6.21% * 100;
 Minibatch[1701-1800]: loss = 0.414490 * 100, metric = 6.06% * 100;
 Minibatch[1801-1900]: loss = 0.417715 * 100, metric = 6.14% * 100;
 Minibatch[1901-2000]: loss = 0.410288 * 100, metric = 5.89% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.416460 * 2000, metric = 6.05% * 2000 904.276s (  2.2 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 13.94% * 2000;
 Minibatch[   1- 100]: loss = 0.426493 * 100, metric = 6.26% * 100;
 Minibatch[ 101- 200]: loss = 0.427117 * 100, metric = 6.35% * 100;
 Minibatch[ 201- 300]: loss = 0.414219 * 100, metric = 5.90% * 100;
 Minibatch[ 301- 400]: loss = 0.417435 * 100, metric = 6.06% * 100;
 Minibatch[ 401- 500]: loss = 0.424211 * 100, metric = 6.17% * 100;
 Minibatch[ 501- 600]: loss = 0.425266 * 100, metric = 6.16% * 100;
 Minibatch[ 601- 700]: loss = 0.424720 * 100, metric = 6.23% * 100;
 Minibatch[ 701- 800]: loss = 0.408883 * 100, metric = 5.99% * 100;
 Minibatch[ 801- 900]: loss = 0.403184 * 100, metric = 5.98% * 100;
 Minibatch[ 901-1000]: loss = 0.430620 * 100, metric = 6.34% * 100;
 Minibatch[1001-1100]: loss = 0.421292 * 100, metric = 6.22% * 100;
 Minibatch[1101-1200]: loss = 0.429391 * 100, metric = 6.36% * 100;
 Minibatch[1201-1300]: loss = 0.431698 * 100, metric = 6.46% * 100;
 Minibatch[1301-1400]: loss = 0.432337 * 100, metric = 6.53% * 100;
 Minibatch[1401-1500]: loss = 0.417450 * 100, metric = 6.21% * 100;
 Minibatch[1501-1600]: loss = 0.412196 * 100, metric = 5.85% * 100;
 Minibatch[1601-1700]: loss = 0.412429 * 100, metric = 6.13% * 100;
 Minibatch[1701-1800]: loss = 0.420312 * 100, metric = 6.28% * 100;
 Minibatch[1801-1900]: loss = 0.418123 * 100, metric = 6.32% * 100;
 Minibatch[1901-2000]: loss = 0.419683 * 100, metric = 6.14% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.420853 * 2000, metric = 6.20% * 2000 912.127s (  2.2 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 14.25% * 2000;
 Minibatch[   1- 100]: loss = 0.398077 * 100, metric = 5.97% * 100;
 Minibatch[ 101- 200]: loss = 0.420880 * 100, metric = 6.29% * 100;
 Minibatch[ 201- 300]: loss = 0.415691 * 100, metric = 6.32% * 100;
 Minibatch[ 301- 400]: loss = 0.423116 * 100, metric = 6.20% * 100;
 Minibatch[ 401- 500]: loss = 0.421368 * 100, metric = 6.49% * 100;
 Minibatch[ 501- 600]: loss = 0.402775 * 100, metric = 5.97% * 100;
 Minibatch[ 601- 700]: loss = 0.422246 * 100, metric = 6.35% * 100;
 Minibatch[ 701- 800]: loss = 0.411502 * 100, metric = 6.20% * 100;
 Minibatch[ 801- 900]: loss = 0.429579 * 100, metric = 6.58% * 100;
 Minibatch[ 901-1000]: loss = 0.421637 * 100, metric = 6.24% * 100;
 Minibatch[1001-1100]: loss = 0.411991 * 100, metric = 5.89% * 100;
 Minibatch[1101-1200]: loss = 0.426130 * 100, metric = 6.34% * 100;
 Minibatch[1201-1300]: loss = 0.421286 * 100, metric = 6.35% * 100;
 Minibatch[1301-1400]: loss = 0.406129 * 100, metric = 6.02% * 100;
 Minibatch[1401-1500]: loss = 0.412007 * 100, metric = 5.95% * 100;
 Minibatch[1501-1600]: loss = 0.420134 * 100, metric = 6.07% * 100;
 Minibatch[1601-1700]: loss = 0.403458 * 100, metric = 5.69% * 100;
 Minibatch[1701-1800]: loss = 0.401679 * 100, metric = 5.76% * 100;
 Minibatch[1801-1900]: loss = 0.416454 * 100, metric = 6.18% * 100;
 Minibatch[1901-2000]: loss = 0.422015 * 100, metric = 6.29% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.415408 * 2000, metric = 6.16% * 2000 909.836s (  2.2 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 13.65% * 2000;
 Minibatch[   1- 100]: loss = 0.418215 * 100, metric = 6.04% * 100;
 Minibatch[ 101- 200]: loss = 0.414594 * 100, metric = 6.30% * 100;
 Minibatch[ 201- 300]: loss = 0.416990 * 100, metric = 6.27% * 100;
 Minibatch[ 301- 400]: loss = 0.415323 * 100, metric = 6.27% * 100;
 Minibatch[ 401- 500]: loss = 0.414441 * 100, metric = 6.23% * 100;
 Minibatch[ 501- 600]: loss = 0.418439 * 100, metric = 6.30% * 100;
 Minibatch[ 601- 700]: loss = 0.413725 * 100, metric = 5.88% * 100;
 Minibatch[ 701- 800]: loss = 0.395378 * 100, metric = 5.48% * 100;
 Minibatch[ 801- 900]: loss = 0.402464 * 100, metric = 6.01% * 100;
 Minibatch[ 901-1000]: loss = 0.412962 * 100, metric = 6.17% * 100;
 Minibatch[1001-1100]: loss = 0.414439 * 100, metric = 6.12% * 100;
 Minibatch[1101-1200]: loss = 0.425347 * 100, metric = 6.41% * 100;
 Minibatch[1201-1300]: loss = 0.437370 * 100, metric = 6.61% * 100;
 Minibatch[1301-1400]: loss = 0.410996 * 100, metric = 6.06% * 100;
 Minibatch[1401-1500]: loss = 0.406161 * 100, metric = 6.00% * 100;
 Minibatch[1501-1600]: loss = 0.414389 * 100, metric = 6.15% * 100;
 Minibatch[1601-1700]: loss = 0.407106 * 100, metric = 6.19% * 100;
 Minibatch[1701-1800]: loss = 0.409498 * 100, metric = 6.15% * 100;
 Minibatch[1801-1900]: loss = 0.403720 * 100, metric = 5.99% * 100;
 Minibatch[1901-2000]: loss = 0.394289 * 100, metric = 5.75% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.412292 * 2000, metric = 6.12% * 2000 915.194s (  2.2 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 15.09% * 2000;
 Minibatch[   1- 100]: loss = 0.402924 * 100, metric = 5.99% * 100;
 Minibatch[ 101- 200]: loss = 0.387295 * 100, metric = 5.61% * 100;
 Minibatch[ 201- 300]: loss = 0.411306 * 100, metric = 6.11% * 100;
 Minibatch[ 301- 400]: loss = 0.395118 * 100, metric = 5.63% * 100;
 Minibatch[ 401- 500]: loss = 0.409007 * 100, metric = 6.08% * 100;
 Minibatch[ 501- 600]: loss = 0.401821 * 100, metric = 5.84% * 100;
 Minibatch[ 601- 700]: loss = 0.418303 * 100, metric = 6.06% * 100;
 Minibatch[ 701- 800]: loss = 0.404734 * 100, metric = 6.10% * 100;
 Minibatch[ 801- 900]: loss = 0.394962 * 100, metric = 5.71% * 100;
 Minibatch[ 901-1000]: loss = 0.397984 * 100, metric = 5.87% * 100;
 Minibatch[1001-1100]: loss = 0.409762 * 100, metric = 6.23% * 100;
 Minibatch[1101-1200]: loss = 0.424345 * 100, metric = 6.30% * 100;
 Minibatch[1201-1300]: loss = 0.407754 * 100, metric = 6.16% * 100;
 Minibatch[1301-1400]: loss = 0.400709 * 100, metric = 5.78% * 100;
 Minibatch[1401-1500]: loss = 0.407426 * 100, metric = 6.01% * 100;
 Minibatch[1501-1600]: loss = 0.410840 * 100, metric = 5.89% * 100;
 Minibatch[1601-1700]: loss = 0.426202 * 100, metric = 6.49% * 100;
 Minibatch[1701-1800]: loss = 0.418650 * 100, metric = 6.31% * 100;
 Minibatch[1801-1900]: loss = 0.411947 * 100, metric = 6.25% * 100;
 Minibatch[1901-2000]: loss = 0.414189 * 100, metric = 6.00% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.407764 * 2000, metric = 6.02% * 2000 909.234s (  2.2 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 14.65% * 2000;
 Minibatch[   1- 100]: loss = 0.402946 * 100, metric = 5.79% * 100;
 Minibatch[ 101- 200]: loss = 0.416558 * 100, metric = 6.03% * 100;
 Minibatch[ 201- 300]: loss = 0.410230 * 100, metric = 6.16% * 100;
 Minibatch[ 301- 400]: loss = 0.394594 * 100, metric = 5.63% * 100;
 Minibatch[ 401- 500]: loss = 0.404798 * 100, metric = 5.82% * 100;
 Minibatch[ 501- 600]: loss = 0.394065 * 100, metric = 5.69% * 100;
 Minibatch[ 601- 700]: loss = 0.394474 * 100, metric = 5.63% * 100;
 Minibatch[ 701- 800]: loss = 0.396515 * 100, metric = 5.95% * 100;
 Minibatch[ 801- 900]: loss = 0.414157 * 100, metric = 6.04% * 100;
 Minibatch[ 901-1000]: loss = 0.406501 * 100, metric = 6.11% * 100;
 Minibatch[1001-1100]: loss = 0.394160 * 100, metric = 5.54% * 100;
 Minibatch[1101-1200]: loss = 0.412292 * 100, metric = 6.02% * 100;
 Minibatch[1201-1300]: loss = 0.404247 * 100, metric = 5.89% * 100;
 Minibatch[1301-1400]: loss = 0.410982 * 100, metric = 6.23% * 100;
 Minibatch[1401-1500]: loss = 0.398104 * 100, metric = 5.76% * 100;
 Minibatch[1501-1600]: loss = 0.406710 * 100, metric = 6.10% * 100;
 Minibatch[1601-1700]: loss = 0.383412 * 100, metric = 5.50% * 100;
 Minibatch[1701-1800]: loss = 0.396730 * 100, metric = 5.66% * 100;
 Minibatch[1801-1900]: loss = 0.398358 * 100, metric = 5.91% * 100;
 Minibatch[1901-2000]: loss = 0.406767 * 100, metric = 5.78% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.402330 * 2000, metric = 5.86% * 2000 904.875s (  2.2 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 12.70% * 2000;
 Minibatch[   1- 100]: loss = 0.399821 * 100, metric = 5.98% * 100;
 Minibatch[ 101- 200]: loss = 0.389199 * 100, metric = 5.54% * 100;
 Minibatch[ 201- 300]: loss = 0.410481 * 100, metric = 6.12% * 100;
 Minibatch[ 301- 400]: loss = 0.403558 * 100, metric = 5.77% * 100;
 Minibatch[ 401- 500]: loss = 0.406221 * 100, metric = 6.07% * 100;
 Minibatch[ 501- 600]: loss = 0.420211 * 100, metric = 6.39% * 100;
 Minibatch[ 601- 700]: loss = 0.396798 * 100, metric = 5.73% * 100;
 Minibatch[ 701- 800]: loss = 0.389868 * 100, metric = 5.68% * 100;
 Minibatch[ 801- 900]: loss = 0.401559 * 100, metric = 5.98% * 100;
 Minibatch[ 901-1000]: loss = 0.407675 * 100, metric = 6.22% * 100;
 Minibatch[1001-1100]: loss = 0.400908 * 100, metric = 5.87% * 100;
 Minibatch[1101-1200]: loss = 0.394302 * 100, metric = 5.58% * 100;
 Minibatch[1201-1300]: loss = 0.403267 * 100, metric = 6.00% * 100;
 Minibatch[1301-1400]: loss = 0.405900 * 100, metric = 6.18% * 100;
 Minibatch[1401-1500]: loss = 0.419769 * 100, metric = 6.49% * 100;
 Minibatch[1501-1600]: loss = 0.397448 * 100, metric = 5.78% * 100;
 Minibatch[1601-1700]: loss = 0.398141 * 100, metric = 5.71% * 100;
 Minibatch[1701-1800]: loss = 0.391502 * 100, metric = 5.51% * 100;
 Minibatch[1801-1900]: loss = 0.398659 * 100, metric = 5.92% * 100;
 Minibatch[1901-2000]: loss = 0.402870 * 100, metric = 5.79% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.401908 * 2000, metric = 5.92% * 2000 900.239s (  2.2 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.84% * 2000;
 Minibatch[   1- 100]: loss = 0.386450 * 100, metric = 5.60% * 100;
 Minibatch[ 101- 200]: loss = 0.388926 * 100, metric = 5.80% * 100;
 Minibatch[ 201- 300]: loss = 0.397630 * 100, metric = 5.86% * 100;
 Minibatch[ 301- 400]: loss = 0.431005 * 100, metric = 6.54% * 100;
 Minibatch[ 401- 500]: loss = 0.395329 * 100, metric = 5.76% * 100;
 Minibatch[ 501- 600]: loss = 0.406556 * 100, metric = 6.13% * 100;
 Minibatch[ 601- 700]: loss = 0.398466 * 100, metric = 5.91% * 100;
 Minibatch[ 701- 800]: loss = 0.406778 * 100, metric = 6.11% * 100;
 Minibatch[ 801- 900]: loss = 0.403433 * 100, metric = 6.12% * 100;
 Minibatch[ 901-1000]: loss = 0.403199 * 100, metric = 5.87% * 100;
 Minibatch[1001-1100]: loss = 0.395402 * 100, metric = 5.90% * 100;
 Minibatch[1101-1200]: loss = 0.396516 * 100, metric = 5.95% * 100;
 Minibatch[1201-1300]: loss = 0.395767 * 100, metric = 5.71% * 100;
 Minibatch[1301-1400]: loss = 0.393155 * 100, metric = 5.89% * 100;
 Minibatch[1401-1500]: loss = 0.415782 * 100, metric = 6.01% * 100;
 Minibatch[1501-1600]: loss = 0.387025 * 100, metric = 5.68% * 100;
 Minibatch[1601-1700]: loss = 0.400521 * 100, metric = 5.82% * 100;
 Minibatch[1701-1800]: loss = 0.378860 * 100, metric = 5.41% * 100;
 Minibatch[1801-1900]: loss = 0.407499 * 100, metric = 5.94% * 100;
 Minibatch[1901-2000]: loss = 0.399057 * 100, metric = 5.69% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.399368 * 2000, metric = 5.88% * 2000 905.293s (  2.2 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 15.14% * 2000;
 Minibatch[   1- 100]: loss = 0.416766 * 100, metric = 6.14% * 100;
 Minibatch[ 101- 200]: loss = 0.377162 * 100, metric = 5.28% * 100;
 Minibatch[ 201- 300]: loss = 0.390633 * 100, metric = 5.62% * 100;
 Minibatch[ 301- 400]: loss = 0.388490 * 100, metric = 5.52% * 100;
 Minibatch[ 401- 500]: loss = 0.396983 * 100, metric = 5.73% * 100;
 Minibatch[ 501- 600]: loss = 0.372214 * 100, metric = 5.06% * 100;
 Minibatch[ 601- 700]: loss = 0.396077 * 100, metric = 5.93% * 100;
 Minibatch[ 701- 800]: loss = 0.385871 * 100, metric = 5.54% * 100;
 Minibatch[ 801- 900]: loss = 0.392085 * 100, metric = 5.72% * 100;
 Minibatch[ 901-1000]: loss = 0.377562 * 100, metric = 5.36% * 100;
 Minibatch[1001-1100]: loss = 0.395067 * 100, metric = 5.70% * 100;
 Minibatch[1101-1200]: loss = 0.400696 * 100, metric = 5.79% * 100;
 Minibatch[1201-1300]: loss = 0.378112 * 100, metric = 5.20% * 100;
 Minibatch[1301-1400]: loss = 0.387540 * 100, metric = 5.71% * 100;
 Minibatch[1401-1500]: loss = 0.378605 * 100, metric = 5.31% * 100;
 Minibatch[1501-1600]: loss = 0.396012 * 100, metric = 5.52% * 100;
 Minibatch[1601-1700]: loss = 0.389332 * 100, metric = 5.56% * 100;
 Minibatch[1701-1800]: loss = 0.391032 * 100, metric = 5.62% * 100;
 Minibatch[1801-1900]: loss = 0.395042 * 100, metric = 5.92% * 100;
 Minibatch[1901-2000]: loss = 0.412015 * 100, metric = 6.10% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.390865 * 2000, metric = 5.62% * 2000 907.039s (  2.2 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.52% * 2000;
 Minibatch[   1- 100]: loss = 0.393248 * 100, metric = 5.74% * 100;
 Minibatch[ 101- 200]: loss = 0.409435 * 100, metric = 6.18% * 100;
 Minibatch[ 201- 300]: loss = 0.403212 * 100, metric = 5.86% * 100;
 Minibatch[ 301- 400]: loss = 0.389045 * 100, metric = 5.57% * 100;
 Minibatch[ 401- 500]: loss = 0.389541 * 100, metric = 5.50% * 100;
 Minibatch[ 501- 600]: loss = 0.384296 * 100, metric = 5.64% * 100;
 Minibatch[ 601- 700]: loss = 0.401814 * 100, metric = 5.89% * 100;
 Minibatch[ 701- 800]: loss = 0.406766 * 100, metric = 6.03% * 100;
 Minibatch[ 801- 900]: loss = 0.396183 * 100, metric = 5.64% * 100;
 Minibatch[ 901-1000]: loss = 0.375065 * 100, metric = 5.40% * 100;
 Minibatch[1001-1100]: loss = 0.382898 * 100, metric = 5.48% * 100;
 Minibatch[1101-1200]: loss = 0.387809 * 100, metric = 5.61% * 100;
 Minibatch[1201-1300]: loss = 0.383718 * 100, metric = 5.35% * 100;
 Minibatch[1301-1400]: loss = 0.388549 * 100, metric = 5.61% * 100;
 Minibatch[1401-1500]: loss = 0.394251 * 100, metric = 5.68% * 100;
 Minibatch[1501-1600]: loss = 0.380497 * 100, metric = 5.48% * 100;
 Minibatch[1601-1700]: loss = 0.390537 * 100, metric = 5.80% * 100;
 Minibatch[1701-1800]: loss = 0.382332 * 100, metric = 5.53% * 100;
 Minibatch[1801-1900]: loss = 0.395674 * 100, metric = 5.86% * 100;
 Minibatch[1901-2000]: loss = 0.395085 * 100, metric = 5.70% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.391498 * 2000, metric = 5.68% * 2000 915.206s (  2.2 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 13.49% * 2000;
 Minibatch[   1- 100]: loss = 0.388058 * 100, metric = 5.61% * 100;
 Minibatch[ 101- 200]: loss = 0.391271 * 100, metric = 5.60% * 100;
 Minibatch[ 201- 300]: loss = 0.398966 * 100, metric = 5.74% * 100;
 Minibatch[ 301- 400]: loss = 0.397837 * 100, metric = 5.63% * 100;
 Minibatch[ 401- 500]: loss = 0.388187 * 100, metric = 5.71% * 100;
 Minibatch[ 501- 600]: loss = 0.388098 * 100, metric = 5.65% * 100;
 Minibatch[ 601- 700]: loss = 0.386502 * 100, metric = 5.57% * 100;
 Minibatch[ 701- 800]: loss = 0.383669 * 100, metric = 5.36% * 100;
 Minibatch[ 801- 900]: loss = 0.379987 * 100, metric = 5.50% * 100;
 Minibatch[ 901-1000]: loss = 0.380266 * 100, metric = 5.42% * 100;
 Minibatch[1001-1100]: loss = 0.378970 * 100, metric = 5.19% * 100;
 Minibatch[1101-1200]: loss = 0.391897 * 100, metric = 5.72% * 100;
 Minibatch[1201-1300]: loss = 0.403493 * 100, metric = 6.08% * 100;
 Minibatch[1301-1400]: loss = 0.387058 * 100, metric = 5.57% * 100;
 Minibatch[1401-1500]: loss = 0.383359 * 100, metric = 5.57% * 100;
 Minibatch[1501-1600]: loss = 0.394454 * 100, metric = 5.63% * 100;
 Minibatch[1601-1700]: loss = 0.377014 * 100, metric = 5.37% * 100;
 Minibatch[1701-1800]: loss = 0.398375 * 100, metric = 5.84% * 100;
 Minibatch[1801-1900]: loss = 0.376872 * 100, metric = 5.17% * 100;
 Minibatch[1901-2000]: loss = 0.398696 * 100, metric = 5.91% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.388652 * 2000, metric = 5.59% * 2000 911.918s (  2.2 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.89% * 2000;
 Minibatch[   1- 100]: loss = 0.409483 * 100, metric = 5.99% * 100;
 Minibatch[ 101- 200]: loss = 0.383356 * 100, metric = 5.50% * 100;
 Minibatch[ 201- 300]: loss = 0.381196 * 100, metric = 5.51% * 100;
 Minibatch[ 301- 400]: loss = 0.392810 * 100, metric = 5.80% * 100;
 Minibatch[ 401- 500]: loss = 0.382549 * 100, metric = 5.44% * 100;
 Minibatch[ 501- 600]: loss = 0.391498 * 100, metric = 5.54% * 100;
 Minibatch[ 601- 700]: loss = 0.401890 * 100, metric = 5.80% * 100;
 Minibatch[ 701- 800]: loss = 0.400231 * 100, metric = 6.06% * 100;
 Minibatch[ 801- 900]: loss = 0.383692 * 100, metric = 5.46% * 100;
 Minibatch[ 901-1000]: loss = 0.377933 * 100, metric = 5.39% * 100;
 Minibatch[1001-1100]: loss = 0.391940 * 100, metric = 5.77% * 100;
 Minibatch[1101-1200]: loss = 0.374991 * 100, metric = 5.25% * 100;
 Minibatch[1201-1300]: loss = 0.392214 * 100, metric = 5.47% * 100;
 Minibatch[1301-1400]: loss = 0.375922 * 100, metric = 5.28% * 100;
 Minibatch[1401-1500]: loss = 0.402397 * 100, metric = 5.94% * 100;
 Minibatch[1501-1600]: loss = 0.394131 * 100, metric = 5.71% * 100;
 Minibatch[1601-1700]: loss = 0.386377 * 100, metric = 5.44% * 100;
 Minibatch[1701-1800]: loss = 0.385699 * 100, metric = 5.43% * 100;
 Minibatch[1801-1900]: loss = 0.384900 * 100, metric = 5.36% * 100;
 Minibatch[1901-2000]: loss = 0.392235 * 100, metric = 5.81% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.389272 * 2000, metric = 5.60% * 2000 904.810s (  2.2 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.11% * 2000;
 Minibatch[   1- 100]: loss = 0.379081 * 100, metric = 5.12% * 100;
 Minibatch[ 101- 200]: loss = 0.381546 * 100, metric = 5.33% * 100;
 Minibatch[ 201- 300]: loss = 0.371543 * 100, metric = 5.09% * 100;
 Minibatch[ 301- 400]: loss = 0.388068 * 100, metric = 5.67% * 100;
 Minibatch[ 401- 500]: loss = 0.366075 * 100, metric = 5.04% * 100;
 Minibatch[ 501- 600]: loss = 0.378079 * 100, metric = 5.35% * 100;
 Minibatch[ 601- 700]: loss = 0.383891 * 100, metric = 5.47% * 100;
 Minibatch[ 701- 800]: loss = 0.380331 * 100, metric = 5.40% * 100;
 Minibatch[ 801- 900]: loss = 0.367061 * 100, metric = 5.01% * 100;
 Minibatch[ 901-1000]: loss = 0.371501 * 100, metric = 5.51% * 100;
 Minibatch[1001-1100]: loss = 0.379561 * 100, metric = 5.35% * 100;
 Minibatch[1101-1200]: loss = 0.367007 * 100, metric = 5.39% * 100;
 Minibatch[1201-1300]: loss = 0.383200 * 100, metric = 5.41% * 100;
 Minibatch[1301-1400]: loss = 0.377997 * 100, metric = 5.41% * 100;
 Minibatch[1401-1500]: loss = 0.395998 * 100, metric = 5.82% * 100;
 Minibatch[1501-1600]: loss = 0.383455 * 100, metric = 5.54% * 100;
 Minibatch[1601-1700]: loss = 0.395864 * 100, metric = 5.81% * 100;
 Minibatch[1701-1800]: loss = 0.379536 * 100, metric = 5.36% * 100;
 Minibatch[1801-1900]: loss = 0.383504 * 100, metric = 5.57% * 100;
 Minibatch[1901-2000]: loss = 0.378950 * 100, metric = 5.31% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.379612 * 2000, metric = 5.40% * 2000 922.998s (  2.2 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.48% * 2000;
 Minibatch[   1- 100]: loss = 0.357113 * 100, metric = 4.81% * 100;
 Minibatch[ 101- 200]: loss = 0.374533 * 100, metric = 5.30% * 100;
 Minibatch[ 201- 300]: loss = 0.376918 * 100, metric = 5.23% * 100;
 Minibatch[ 301- 400]: loss = 0.362525 * 100, metric = 4.90% * 100;
 Minibatch[ 401- 500]: loss = 0.368546 * 100, metric = 5.13% * 100;
 Minibatch[ 501- 600]: loss = 0.361105 * 100, metric = 5.01% * 100;
 Minibatch[ 601- 700]: loss = 0.391015 * 100, metric = 5.75% * 100;
 Minibatch[ 701- 800]: loss = 0.365718 * 100, metric = 5.23% * 100;
 Minibatch[ 801- 900]: loss = 0.388051 * 100, metric = 5.58% * 100;
 Minibatch[ 901-1000]: loss = 0.366192 * 100, metric = 5.11% * 100;
 Minibatch[1001-1100]: loss = 0.380723 * 100, metric = 5.41% * 100;
 Minibatch[1101-1200]: loss = 0.368230 * 100, metric = 4.97% * 100;
 Minibatch[1201-1300]: loss = 0.381559 * 100, metric = 5.41% * 100;
 Minibatch[1301-1400]: loss = 0.379316 * 100, metric = 5.50% * 100;
 Minibatch[1401-1500]: loss = 0.375322 * 100, metric = 5.27% * 100;
 Minibatch[1501-1600]: loss = 0.377676 * 100, metric = 5.28% * 100;
 Minibatch[1601-1700]: loss = 0.381649 * 100, metric = 5.65% * 100;
 Minibatch[1701-1800]: loss = 0.377137 * 100, metric = 5.38% * 100;
 Minibatch[1801-1900]: loss = 0.381225 * 100, metric = 5.52% * 100;
 Minibatch[1901-2000]: loss = 0.369866 * 100, metric = 5.18% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.374221 * 2000, metric = 5.28% * 2000 908.976s (  2.2 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 14.52% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
