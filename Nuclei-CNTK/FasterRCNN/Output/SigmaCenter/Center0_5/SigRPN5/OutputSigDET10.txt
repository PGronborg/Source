Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.469827 * 100, metric = 26.36% * 100;
 Minibatch[ 101- 200]: loss = 1.163976 * 100, metric = 22.68% * 100;
 Minibatch[ 201- 300]: loss = 1.055268 * 100, metric = 22.30% * 100;
 Minibatch[ 301- 400]: loss = 1.043397 * 100, metric = 21.96% * 100;
 Minibatch[ 401- 500]: loss = 0.961816 * 100, metric = 20.16% * 100;
 Minibatch[ 501- 600]: loss = 0.950201 * 100, metric = 19.55% * 100;
 Minibatch[ 601- 700]: loss = 0.902499 * 100, metric = 18.27% * 100;
 Minibatch[ 701- 800]: loss = 0.874899 * 100, metric = 17.27% * 100;
 Minibatch[ 801- 900]: loss = 0.879370 * 100, metric = 17.42% * 100;
 Minibatch[ 901-1000]: loss = 0.881418 * 100, metric = 17.49% * 100;
 Minibatch[1001-1100]: loss = 0.862816 * 100, metric = 16.79% * 100;
 Minibatch[1101-1200]: loss = 0.848921 * 100, metric = 16.70% * 100;
 Minibatch[1201-1300]: loss = 0.842921 * 100, metric = 16.67% * 100;
 Minibatch[1301-1400]: loss = 0.814939 * 100, metric = 15.49% * 100;
 Minibatch[1401-1500]: loss = 0.831343 * 100, metric = 15.69% * 100;
 Minibatch[1501-1600]: loss = 0.800341 * 100, metric = 14.86% * 100;
 Minibatch[1601-1700]: loss = 0.787935 * 100, metric = 15.06% * 100;
 Minibatch[1701-1800]: loss = 0.797211 * 100, metric = 14.96% * 100;
 Minibatch[1801-1900]: loss = 0.798103 * 100, metric = 15.04% * 100;
 Minibatch[1901-2000]: loss = 0.752372 * 100, metric = 13.75% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.915979 * 2000, metric = 17.92% * 2000 1026.145s (  1.9 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 26.52% * 2000;
0.88854699896276
 Minibatch[   1- 100]: loss = 0.762731 * 100, metric = 14.13% * 100;
 Minibatch[ 101- 200]: loss = 0.785868 * 100, metric = 14.68% * 100;
 Minibatch[ 201- 300]: loss = 0.762945 * 100, metric = 13.54% * 100;
 Minibatch[ 301- 400]: loss = 0.761851 * 100, metric = 14.04% * 100;
 Minibatch[ 401- 500]: loss = 0.752744 * 100, metric = 13.97% * 100;
 Minibatch[ 501- 600]: loss = 0.760977 * 100, metric = 13.70% * 100;
 Minibatch[ 601- 700]: loss = 0.731378 * 100, metric = 13.44% * 100;
 Minibatch[ 701- 800]: loss = 0.757690 * 100, metric = 14.05% * 100;
 Minibatch[ 801- 900]: loss = 0.738845 * 100, metric = 13.56% * 100;
 Minibatch[ 901-1000]: loss = 0.722246 * 100, metric = 12.84% * 100;
 Minibatch[1001-1100]: loss = 0.743769 * 100, metric = 13.52% * 100;
 Minibatch[1101-1200]: loss = 0.735279 * 100, metric = 13.16% * 100;
 Minibatch[1201-1300]: loss = 0.718339 * 100, metric = 13.07% * 100;
 Minibatch[1301-1400]: loss = 0.745627 * 100, metric = 13.74% * 100;
 Minibatch[1401-1500]: loss = 0.712856 * 100, metric = 12.90% * 100;
 Minibatch[1501-1600]: loss = 0.711327 * 100, metric = 12.87% * 100;
 Minibatch[1601-1700]: loss = 0.714894 * 100, metric = 13.06% * 100;
 Minibatch[1701-1800]: loss = 0.722352 * 100, metric = 13.36% * 100;
 Minibatch[1801-1900]: loss = 0.730033 * 100, metric = 13.04% * 100;
 Minibatch[1901-2000]: loss = 0.696064 * 100, metric = 12.62% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.738391 * 2000, metric = 13.46% * 2000 966.759s (  2.1 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 20.83% * 2000;
0.7718287071436644
 Minibatch[   1- 100]: loss = 0.710845 * 100, metric = 12.93% * 100;
 Minibatch[ 101- 200]: loss = 0.720339 * 100, metric = 13.03% * 100;
 Minibatch[ 201- 300]: loss = 0.696372 * 100, metric = 12.50% * 100;
 Minibatch[ 301- 400]: loss = 0.722154 * 100, metric = 13.24% * 100;
 Minibatch[ 401- 500]: loss = 0.724248 * 100, metric = 13.37% * 100;
 Minibatch[ 501- 600]: loss = 0.710210 * 100, metric = 12.96% * 100;
 Minibatch[ 601- 700]: loss = 0.716163 * 100, metric = 13.05% * 100;
 Minibatch[ 701- 800]: loss = 0.690925 * 100, metric = 12.07% * 100;
 Minibatch[ 801- 900]: loss = 0.713025 * 100, metric = 13.12% * 100;
 Minibatch[ 901-1000]: loss = 0.681220 * 100, metric = 12.34% * 100;
 Minibatch[1001-1100]: loss = 0.707244 * 100, metric = 13.13% * 100;
 Minibatch[1101-1200]: loss = 0.689756 * 100, metric = 12.64% * 100;
 Minibatch[1201-1300]: loss = 0.688795 * 100, metric = 12.53% * 100;
 Minibatch[1301-1400]: loss = 0.709037 * 100, metric = 12.73% * 100;
 Minibatch[1401-1500]: loss = 0.704256 * 100, metric = 12.61% * 100;
 Minibatch[1501-1600]: loss = 0.682788 * 100, metric = 12.23% * 100;
 Minibatch[1601-1700]: loss = 0.666700 * 100, metric = 11.64% * 100;
 Minibatch[1701-1800]: loss = 0.694048 * 100, metric = 12.48% * 100;
 Minibatch[1801-1900]: loss = 0.675205 * 100, metric = 12.04% * 100;
 Minibatch[1901-2000]: loss = 0.687450 * 100, metric = 12.30% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.699539 * 2000, metric = 12.65% * 2000 957.602s (  2.1 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 19.41% * 2000;
0.7539145295843482
 Minibatch[   1- 100]: loss = 0.706864 * 100, metric = 12.46% * 100;
 Minibatch[ 101- 200]: loss = 0.668255 * 100, metric = 11.80% * 100;
 Minibatch[ 201- 300]: loss = 0.690789 * 100, metric = 12.38% * 100;
 Minibatch[ 301- 400]: loss = 0.649949 * 100, metric = 11.40% * 100;
 Minibatch[ 401- 500]: loss = 0.675381 * 100, metric = 12.01% * 100;
 Minibatch[ 501- 600]: loss = 0.647108 * 100, metric = 11.00% * 100;
 Minibatch[ 601- 700]: loss = 0.656742 * 100, metric = 11.39% * 100;
 Minibatch[ 701- 800]: loss = 0.672565 * 100, metric = 11.88% * 100;
 Minibatch[ 801- 900]: loss = 0.663708 * 100, metric = 11.59% * 100;
 Minibatch[ 901-1000]: loss = 0.662863 * 100, metric = 11.95% * 100;
 Minibatch[1001-1100]: loss = 0.673594 * 100, metric = 12.07% * 100;
 Minibatch[1101-1200]: loss = 0.649047 * 100, metric = 11.30% * 100;
 Minibatch[1201-1300]: loss = 0.647740 * 100, metric = 11.21% * 100;
 Minibatch[1301-1400]: loss = 0.669280 * 100, metric = 11.78% * 100;
 Minibatch[1401-1500]: loss = 0.676260 * 100, metric = 11.71% * 100;
 Minibatch[1501-1600]: loss = 0.640846 * 100, metric = 11.14% * 100;
 Minibatch[1601-1700]: loss = 0.662441 * 100, metric = 11.59% * 100;
 Minibatch[1701-1800]: loss = 0.664209 * 100, metric = 11.73% * 100;
 Minibatch[1801-1900]: loss = 0.648729 * 100, metric = 11.04% * 100;
 Minibatch[1901-2000]: loss = 0.645685 * 100, metric = 11.21% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.663603 * 2000, metric = 11.63% * 2000 955.592s (  2.1 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 20.65% * 2000;
 Minibatch[   1- 100]: loss = 0.675402 * 100, metric = 11.72% * 100;
 Minibatch[ 101- 200]: loss = 0.647150 * 100, metric = 11.11% * 100;
 Minibatch[ 201- 300]: loss = 0.649477 * 100, metric = 11.38% * 100;
 Minibatch[ 301- 400]: loss = 0.677360 * 100, metric = 12.14% * 100;
 Minibatch[ 401- 500]: loss = 0.638231 * 100, metric = 10.81% * 100;
 Minibatch[ 501- 600]: loss = 0.628224 * 100, metric = 10.72% * 100;
 Minibatch[ 601- 700]: loss = 0.635282 * 100, metric = 10.48% * 100;
 Minibatch[ 701- 800]: loss = 0.651328 * 100, metric = 11.14% * 100;
 Minibatch[ 801- 900]: loss = 0.638047 * 100, metric = 10.71% * 100;
 Minibatch[ 901-1000]: loss = 0.642585 * 100, metric = 11.18% * 100;
 Minibatch[1001-1100]: loss = 0.650641 * 100, metric = 11.04% * 100;
 Minibatch[1101-1200]: loss = 0.630392 * 100, metric = 10.95% * 100;
 Minibatch[1201-1300]: loss = 0.654022 * 100, metric = 11.32% * 100;
 Minibatch[1301-1400]: loss = 0.659586 * 100, metric = 11.66% * 100;
 Minibatch[1401-1500]: loss = 0.633632 * 100, metric = 10.78% * 100;
 Minibatch[1501-1600]: loss = 0.640767 * 100, metric = 11.19% * 100;
 Minibatch[1601-1700]: loss = 0.652947 * 100, metric = 11.47% * 100;
 Minibatch[1701-1800]: loss = 0.651232 * 100, metric = 11.29% * 100;
 Minibatch[1801-1900]: loss = 0.641484 * 100, metric = 11.17% * 100;
 Minibatch[1901-2000]: loss = 0.625172 * 100, metric = 10.46% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.646148 * 2000, metric = 11.14% * 2000 944.169s (  2.1 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 17.83% * 2000;
0.7013186742514372
 Minibatch[   1- 100]: loss = 0.622407 * 100, metric = 10.61% * 100;
 Minibatch[ 101- 200]: loss = 0.621257 * 100, metric = 10.62% * 100;
 Minibatch[ 201- 300]: loss = 0.631676 * 100, metric = 10.84% * 100;
 Minibatch[ 301- 400]: loss = 0.625795 * 100, metric = 10.62% * 100;
 Minibatch[ 401- 500]: loss = 0.608123 * 100, metric = 10.18% * 100;
 Minibatch[ 501- 600]: loss = 0.612830 * 100, metric = 10.26% * 100;
 Minibatch[ 601- 700]: loss = 0.612108 * 100, metric = 10.46% * 100;
 Minibatch[ 701- 800]: loss = 0.619630 * 100, metric = 10.48% * 100;
 Minibatch[ 801- 900]: loss = 0.624854 * 100, metric = 10.84% * 100;
 Minibatch[ 901-1000]: loss = 0.615524 * 100, metric = 10.52% * 100;
 Minibatch[1001-1100]: loss = 0.609980 * 100, metric = 10.24% * 100;
 Minibatch[1101-1200]: loss = 0.620847 * 100, metric = 10.55% * 100;
 Minibatch[1201-1300]: loss = 0.637487 * 100, metric = 10.96% * 100;
 Minibatch[1301-1400]: loss = 0.616992 * 100, metric = 10.59% * 100;
 Minibatch[1401-1500]: loss = 0.621425 * 100, metric = 10.68% * 100;
 Minibatch[1501-1600]: loss = 0.614387 * 100, metric = 10.34% * 100;
 Minibatch[1601-1700]: loss = 0.607763 * 100, metric = 10.33% * 100;
 Minibatch[1701-1800]: loss = 0.600060 * 100, metric = 10.01% * 100;
 Minibatch[1801-1900]: loss = 0.625839 * 100, metric = 10.76% * 100;
 Minibatch[1901-2000]: loss = 0.605314 * 100, metric = 10.12% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.617715 * 2000, metric = 10.50% * 2000 949.590s (  2.1 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 19.57% * 2000;
 Minibatch[   1- 100]: loss = 0.616474 * 100, metric = 10.26% * 100;
 Minibatch[ 101- 200]: loss = 0.612165 * 100, metric = 10.18% * 100;
 Minibatch[ 201- 300]: loss = 0.609536 * 100, metric = 10.44% * 100;
 Minibatch[ 301- 400]: loss = 0.599876 * 100, metric = 9.95% * 100;
 Minibatch[ 401- 500]: loss = 0.608491 * 100, metric = 9.99% * 100;
 Minibatch[ 501- 600]: loss = 0.600661 * 100, metric = 9.88% * 100;
 Minibatch[ 601- 700]: loss = 0.612016 * 100, metric = 9.96% * 100;
 Minibatch[ 701- 800]: loss = 0.622141 * 100, metric = 10.16% * 100;
 Minibatch[ 801- 900]: loss = 0.612608 * 100, metric = 10.23% * 100;
 Minibatch[ 901-1000]: loss = 0.608257 * 100, metric = 10.15% * 100;
 Minibatch[1001-1100]: loss = 0.616849 * 100, metric = 10.50% * 100;
 Minibatch[1101-1200]: loss = 0.592861 * 100, metric = 9.80% * 100;
 Minibatch[1201-1300]: loss = 0.609227 * 100, metric = 10.57% * 100;
 Minibatch[1301-1400]: loss = 0.603583 * 100, metric = 10.33% * 100;
 Minibatch[1401-1500]: loss = 0.593968 * 100, metric = 9.88% * 100;
 Minibatch[1501-1600]: loss = 0.608227 * 100, metric = 10.14% * 100;
 Minibatch[1601-1700]: loss = 0.603337 * 100, metric = 10.10% * 100;
 Minibatch[1701-1800]: loss = 0.586843 * 100, metric = 9.82% * 100;
 Minibatch[1801-1900]: loss = 0.591970 * 100, metric = 9.96% * 100;
 Minibatch[1901-2000]: loss = 0.600360 * 100, metric = 10.04% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.605473 * 2000, metric = 10.12% * 2000 934.560s (  2.1 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 17.43% * 2000;
0.6803939688801766
 Minibatch[   1- 100]: loss = 0.610028 * 100, metric = 10.33% * 100;
 Minibatch[ 101- 200]: loss = 0.590146 * 100, metric = 10.03% * 100;
 Minibatch[ 201- 300]: loss = 0.571178 * 100, metric = 9.53% * 100;
 Minibatch[ 301- 400]: loss = 0.586366 * 100, metric = 9.81% * 100;
 Minibatch[ 401- 500]: loss = 0.599745 * 100, metric = 10.09% * 100;
 Minibatch[ 501- 600]: loss = 0.619868 * 100, metric = 10.70% * 100;
 Minibatch[ 601- 700]: loss = 0.574157 * 100, metric = 9.66% * 100;
 Minibatch[ 701- 800]: loss = 0.596218 * 100, metric = 9.72% * 100;
 Minibatch[ 801- 900]: loss = 0.575404 * 100, metric = 9.54% * 100;
 Minibatch[ 901-1000]: loss = 0.569142 * 100, metric = 9.36% * 100;
 Minibatch[1001-1100]: loss = 0.577841 * 100, metric = 9.57% * 100;
 Minibatch[1101-1200]: loss = 0.572171 * 100, metric = 9.37% * 100;
 Minibatch[1201-1300]: loss = 0.579376 * 100, metric = 9.84% * 100;
 Minibatch[1301-1400]: loss = 0.597461 * 100, metric = 10.25% * 100;
 Minibatch[1401-1500]: loss = 0.589151 * 100, metric = 9.78% * 100;
 Minibatch[1501-1600]: loss = 0.586186 * 100, metric = 9.86% * 100;
 Minibatch[1601-1700]: loss = 0.580176 * 100, metric = 9.52% * 100;
 Minibatch[1701-1800]: loss = 0.569833 * 100, metric = 9.30% * 100;
 Minibatch[1801-1900]: loss = 0.584553 * 100, metric = 9.67% * 100;
 Minibatch[1901-2000]: loss = 0.591232 * 100, metric = 9.61% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.586012 * 2000, metric = 9.78% * 2000 933.496s (  2.1 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 15.94% * 2000;
0.6545882429480553
 Minibatch[   1- 100]: loss = 0.555909 * 100, metric = 8.81% * 100;
 Minibatch[ 101- 200]: loss = 0.587640 * 100, metric = 9.92% * 100;
 Minibatch[ 201- 300]: loss = 0.584934 * 100, metric = 9.50% * 100;
 Minibatch[ 301- 400]: loss = 0.597813 * 100, metric = 9.83% * 100;
 Minibatch[ 401- 500]: loss = 0.584675 * 100, metric = 9.61% * 100;
 Minibatch[ 501- 600]: loss = 0.567892 * 100, metric = 9.36% * 100;
 Minibatch[ 601- 700]: loss = 0.560554 * 100, metric = 9.21% * 100;
 Minibatch[ 701- 800]: loss = 0.563969 * 100, metric = 9.21% * 100;
 Minibatch[ 801- 900]: loss = 0.564618 * 100, metric = 9.21% * 100;
 Minibatch[ 901-1000]: loss = 0.585522 * 100, metric = 9.67% * 100;
 Minibatch[1001-1100]: loss = 0.543682 * 100, metric = 8.67% * 100;
 Minibatch[1101-1200]: loss = 0.572887 * 100, metric = 9.29% * 100;
 Minibatch[1201-1300]: loss = 0.566404 * 100, metric = 9.23% * 100;
 Minibatch[1301-1400]: loss = 0.557704 * 100, metric = 8.96% * 100;
 Minibatch[1401-1500]: loss = 0.577425 * 100, metric = 9.74% * 100;
 Minibatch[1501-1600]: loss = 0.571094 * 100, metric = 9.33% * 100;
 Minibatch[1601-1700]: loss = 0.575447 * 100, metric = 9.51% * 100;
 Minibatch[1701-1800]: loss = 0.553205 * 100, metric = 8.88% * 100;
 Minibatch[1801-1900]: loss = 0.555162 * 100, metric = 8.99% * 100;
 Minibatch[1901-2000]: loss = 0.572217 * 100, metric = 9.38% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.569938 * 2000, metric = 9.32% * 2000 935.688s (  2.1 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 14.97% * 2000;
0.6334798317626119
 Minibatch[   1- 100]: loss = 0.591293 * 100, metric = 10.09% * 100;
 Minibatch[ 101- 200]: loss = 0.557513 * 100, metric = 9.27% * 100;
 Minibatch[ 201- 300]: loss = 0.566999 * 100, metric = 9.34% * 100;
 Minibatch[ 301- 400]: loss = 0.558499 * 100, metric = 9.01% * 100;
 Minibatch[ 401- 500]: loss = 0.573427 * 100, metric = 9.49% * 100;
 Minibatch[ 501- 600]: loss = 0.545769 * 100, metric = 8.93% * 100;
 Minibatch[ 601- 700]: loss = 0.536464 * 100, metric = 8.50% * 100;
 Minibatch[ 701- 800]: loss = 0.539178 * 100, metric = 8.58% * 100;
 Minibatch[ 801- 900]: loss = 0.562009 * 100, metric = 9.30% * 100;
 Minibatch[ 901-1000]: loss = 0.564207 * 100, metric = 9.18% * 100;
 Minibatch[1001-1100]: loss = 0.568127 * 100, metric = 9.46% * 100;
 Minibatch[1101-1200]: loss = 0.558788 * 100, metric = 9.06% * 100;
 Minibatch[1201-1300]: loss = 0.564628 * 100, metric = 9.25% * 100;
 Minibatch[1301-1400]: loss = 0.552414 * 100, metric = 9.02% * 100;
 Minibatch[1401-1500]: loss = 0.550007 * 100, metric = 8.83% * 100;
 Minibatch[1501-1600]: loss = 0.551180 * 100, metric = 9.04% * 100;
 Minibatch[1601-1700]: loss = 0.547868 * 100, metric = 8.44% * 100;
 Minibatch[1701-1800]: loss = 0.560397 * 100, metric = 8.87% * 100;
 Minibatch[1801-1900]: loss = 0.560204 * 100, metric = 9.26% * 100;
 Minibatch[1901-2000]: loss = 0.542863 * 100, metric = 8.83% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.557592 * 2000, metric = 9.09% * 2000 917.834s (  2.2 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 14.45% * 2000;
0.6200152482539415
 Minibatch[   1- 100]: loss = 0.535583 * 100, metric = 8.44% * 100;
 Minibatch[ 101- 200]: loss = 0.550489 * 100, metric = 9.00% * 100;
 Minibatch[ 201- 300]: loss = 0.554154 * 100, metric = 9.05% * 100;
 Minibatch[ 301- 400]: loss = 0.546752 * 100, metric = 8.69% * 100;
 Minibatch[ 401- 500]: loss = 0.535224 * 100, metric = 8.55% * 100;
 Minibatch[ 501- 600]: loss = 0.548505 * 100, metric = 8.88% * 100;
 Minibatch[ 601- 700]: loss = 0.534094 * 100, metric = 8.48% * 100;
 Minibatch[ 701- 800]: loss = 0.553995 * 100, metric = 9.12% * 100;
 Minibatch[ 801- 900]: loss = 0.547236 * 100, metric = 8.74% * 100;
 Minibatch[ 901-1000]: loss = 0.556299 * 100, metric = 8.83% * 100;
 Minibatch[1001-1100]: loss = 0.546815 * 100, metric = 8.83% * 100;
 Minibatch[1101-1200]: loss = 0.561849 * 100, metric = 9.38% * 100;
 Minibatch[1201-1300]: loss = 0.540154 * 100, metric = 8.89% * 100;
 Minibatch[1301-1400]: loss = 0.527299 * 100, metric = 8.59% * 100;
 Minibatch[1401-1500]: loss = 0.548981 * 100, metric = 9.10% * 100;
 Minibatch[1501-1600]: loss = 0.534848 * 100, metric = 8.55% * 100;
 Minibatch[1601-1700]: loss = 0.536837 * 100, metric = 8.68% * 100;
 Minibatch[1701-1800]: loss = 0.555069 * 100, metric = 9.07% * 100;
 Minibatch[1801-1900]: loss = 0.539029 * 100, metric = 8.67% * 100;
 Minibatch[1901-2000]: loss = 0.537068 * 100, metric = 8.87% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.544514 * 2000, metric = 8.82% * 2000 925.448s (  2.2 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 15.76% * 2000;
 Minibatch[   1- 100]: loss = 0.521870 * 100, metric = 8.37% * 100;
 Minibatch[ 101- 200]: loss = 0.529863 * 100, metric = 8.23% * 100;
 Minibatch[ 201- 300]: loss = 0.528810 * 100, metric = 8.55% * 100;
 Minibatch[ 301- 400]: loss = 0.562024 * 100, metric = 9.31% * 100;
 Minibatch[ 401- 500]: loss = 0.530331 * 100, metric = 8.49% * 100;
 Minibatch[ 501- 600]: loss = 0.521539 * 100, metric = 8.17% * 100;
 Minibatch[ 601- 700]: loss = 0.523047 * 100, metric = 8.22% * 100;
 Minibatch[ 701- 800]: loss = 0.530796 * 100, metric = 8.60% * 100;
 Minibatch[ 801- 900]: loss = 0.532681 * 100, metric = 8.38% * 100;
 Minibatch[ 901-1000]: loss = 0.535955 * 100, metric = 8.55% * 100;
 Minibatch[1001-1100]: loss = 0.534144 * 100, metric = 8.47% * 100;
 Minibatch[1101-1200]: loss = 0.538734 * 100, metric = 8.79% * 100;
 Minibatch[1201-1300]: loss = 0.537292 * 100, metric = 8.94% * 100;
 Minibatch[1301-1400]: loss = 0.519814 * 100, metric = 8.34% * 100;
 Minibatch[1401-1500]: loss = 0.542379 * 100, metric = 8.67% * 100;
 Minibatch[1501-1600]: loss = 0.503862 * 100, metric = 7.94% * 100;
 Minibatch[1601-1700]: loss = 0.539860 * 100, metric = 8.71% * 100;
 Minibatch[1701-1800]: loss = 0.520023 * 100, metric = 8.20% * 100;
 Minibatch[1801-1900]: loss = 0.523031 * 100, metric = 8.32% * 100;
 Minibatch[1901-2000]: loss = 0.539268 * 100, metric = 8.75% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.530766 * 2000, metric = 8.50% * 2000 918.946s (  2.2 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 16.72% * 2000;
 Minibatch[   1- 100]: loss = 0.525509 * 100, metric = 8.15% * 100;
 Minibatch[ 101- 200]: loss = 0.525825 * 100, metric = 8.43% * 100;
 Minibatch[ 201- 300]: loss = 0.528577 * 100, metric = 8.39% * 100;
 Minibatch[ 301- 400]: loss = 0.539000 * 100, metric = 8.70% * 100;
 Minibatch[ 401- 500]: loss = 0.543657 * 100, metric = 9.15% * 100;
 Minibatch[ 501- 600]: loss = 0.546207 * 100, metric = 8.93% * 100;
 Minibatch[ 601- 700]: loss = 0.519538 * 100, metric = 8.11% * 100;
 Minibatch[ 701- 800]: loss = 0.525261 * 100, metric = 8.41% * 100;
 Minibatch[ 801- 900]: loss = 0.525260 * 100, metric = 8.47% * 100;
 Minibatch[ 901-1000]: loss = 0.534459 * 100, metric = 8.68% * 100;
 Minibatch[1001-1100]: loss = 0.532512 * 100, metric = 8.65% * 100;
 Minibatch[1101-1200]: loss = 0.526238 * 100, metric = 8.51% * 100;
 Minibatch[1201-1300]: loss = 0.536533 * 100, metric = 8.84% * 100;
 Minibatch[1301-1400]: loss = 0.520627 * 100, metric = 8.26% * 100;
 Minibatch[1401-1500]: loss = 0.519100 * 100, metric = 8.32% * 100;
 Minibatch[1501-1600]: loss = 0.514232 * 100, metric = 7.98% * 100;
 Minibatch[1601-1700]: loss = 0.500229 * 100, metric = 8.03% * 100;
 Minibatch[1701-1800]: loss = 0.517490 * 100, metric = 8.18% * 100;
 Minibatch[1801-1900]: loss = 0.515156 * 100, metric = 8.09% * 100;
 Minibatch[1901-2000]: loss = 0.525743 * 100, metric = 8.30% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.526058 * 2000, metric = 8.43% * 2000 915.290s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 16.74% * 2000;
 Minibatch[   1- 100]: loss = 0.507774 * 100, metric = 7.73% * 100;
 Minibatch[ 101- 200]: loss = 0.500924 * 100, metric = 7.91% * 100;
 Minibatch[ 201- 300]: loss = 0.528958 * 100, metric = 8.61% * 100;
 Minibatch[ 301- 400]: loss = 0.521134 * 100, metric = 8.44% * 100;
 Minibatch[ 401- 500]: loss = 0.513991 * 100, metric = 8.46% * 100;
 Minibatch[ 501- 600]: loss = 0.523221 * 100, metric = 8.42% * 100;
 Minibatch[ 601- 700]: loss = 0.511161 * 100, metric = 7.96% * 100;
 Minibatch[ 701- 800]: loss = 0.530815 * 100, metric = 8.53% * 100;
 Minibatch[ 801- 900]: loss = 0.527539 * 100, metric = 8.71% * 100;
 Minibatch[ 901-1000]: loss = 0.529341 * 100, metric = 8.58% * 100;
 Minibatch[1001-1100]: loss = 0.520702 * 100, metric = 8.37% * 100;
 Minibatch[1101-1200]: loss = 0.507972 * 100, metric = 8.01% * 100;
 Minibatch[1201-1300]: loss = 0.489965 * 100, metric = 7.59% * 100;
 Minibatch[1301-1400]: loss = 0.513578 * 100, metric = 8.13% * 100;
 Minibatch[1401-1500]: loss = 0.511156 * 100, metric = 8.09% * 100;
 Minibatch[1501-1600]: loss = 0.497586 * 100, metric = 7.92% * 100;
 Minibatch[1601-1700]: loss = 0.510954 * 100, metric = 7.92% * 100;
 Minibatch[1701-1800]: loss = 0.506842 * 100, metric = 7.88% * 100;
 Minibatch[1801-1900]: loss = 0.511201 * 100, metric = 8.07% * 100;
 Minibatch[1901-2000]: loss = 0.512191 * 100, metric = 7.73% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.513850 * 2000, metric = 8.15% * 2000 964.701s (  2.1 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 16.41% * 2000;
 Minibatch[   1- 100]: loss = 0.500402 * 100, metric = 7.80% * 100;
 Minibatch[ 101- 200]: loss = 0.506540 * 100, metric = 7.89% * 100;
 Minibatch[ 201- 300]: loss = 0.511490 * 100, metric = 8.06% * 100;
 Minibatch[ 301- 400]: loss = 0.497434 * 100, metric = 7.83% * 100;
 Minibatch[ 401- 500]: loss = 0.505610 * 100, metric = 7.97% * 100;
 Minibatch[ 501- 600]: loss = 0.489879 * 100, metric = 7.62% * 100;
 Minibatch[ 601- 700]: loss = 0.483726 * 100, metric = 7.52% * 100;
 Minibatch[ 701- 800]: loss = 0.516244 * 100, metric = 8.19% * 100;
 Minibatch[ 801- 900]: loss = 0.525680 * 100, metric = 8.51% * 100;
 Minibatch[ 901-1000]: loss = 0.511306 * 100, metric = 8.05% * 100;
 Minibatch[1001-1100]: loss = 0.512494 * 100, metric = 7.93% * 100;
 Minibatch[1101-1200]: loss = 0.505640 * 100, metric = 8.03% * 100;
 Minibatch[1201-1300]: loss = 0.497541 * 100, metric = 7.69% * 100;
 Minibatch[1301-1400]: loss = 0.522189 * 100, metric = 8.41% * 100;
 Minibatch[1401-1500]: loss = 0.486169 * 100, metric = 7.35% * 100;
 Minibatch[1501-1600]: loss = 0.499509 * 100, metric = 7.94% * 100;
 Minibatch[1601-1700]: loss = 0.509993 * 100, metric = 8.16% * 100;
 Minibatch[1701-1800]: loss = 0.493155 * 100, metric = 7.50% * 100;
 Minibatch[1801-1900]: loss = 0.503273 * 100, metric = 8.04% * 100;
 Minibatch[1901-2000]: loss = 0.499974 * 100, metric = 8.03% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.503912 * 2000, metric = 7.93% * 2000 948.951s (  2.1 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 14.00% * 2000;
0.6175348736643791
 Minibatch[   1- 100]: loss = 0.521108 * 100, metric = 8.52% * 100;
 Minibatch[ 101- 200]: loss = 0.507225 * 100, metric = 7.97% * 100;
 Minibatch[ 201- 300]: loss = 0.515973 * 100, metric = 8.22% * 100;
 Minibatch[ 301- 400]: loss = 0.512448 * 100, metric = 8.12% * 100;
 Minibatch[ 401- 500]: loss = 0.486432 * 100, metric = 7.72% * 100;
 Minibatch[ 501- 600]: loss = 0.500679 * 100, metric = 7.91% * 100;
 Minibatch[ 601- 700]: loss = 0.503844 * 100, metric = 7.80% * 100;
 Minibatch[ 701- 800]: loss = 0.490989 * 100, metric = 7.53% * 100;
 Minibatch[ 801- 900]: loss = 0.488567 * 100, metric = 7.56% * 100;
 Minibatch[ 901-1000]: loss = 0.501225 * 100, metric = 7.80% * 100;
 Minibatch[1001-1100]: loss = 0.485890 * 100, metric = 7.35% * 100;
 Minibatch[1101-1200]: loss = 0.492155 * 100, metric = 7.69% * 100;
 Minibatch[1201-1300]: loss = 0.477838 * 100, metric = 7.31% * 100;
 Minibatch[1301-1400]: loss = 0.490502 * 100, metric = 7.56% * 100;
 Minibatch[1401-1500]: loss = 0.491819 * 100, metric = 7.77% * 100;
 Minibatch[1501-1600]: loss = 0.496934 * 100, metric = 7.71% * 100;
 Minibatch[1601-1700]: loss = 0.498472 * 100, metric = 8.02% * 100;
 Minibatch[1701-1800]: loss = 0.508612 * 100, metric = 7.94% * 100;
 Minibatch[1801-1900]: loss = 0.506038 * 100, metric = 7.93% * 100;
 Minibatch[1901-2000]: loss = 0.485461 * 100, metric = 7.50% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.498111 * 2000, metric = 7.80% * 2000 956.014s (  2.1 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.86% * 2000;
 Minibatch[   1- 100]: loss = 0.483900 * 100, metric = 7.63% * 100;
 Minibatch[ 101- 200]: loss = 0.508524 * 100, metric = 8.14% * 100;
 Minibatch[ 201- 300]: loss = 0.496158 * 100, metric = 7.84% * 100;
 Minibatch[ 301- 400]: loss = 0.491682 * 100, metric = 7.66% * 100;
 Minibatch[ 401- 500]: loss = 0.497053 * 100, metric = 7.59% * 100;
 Minibatch[ 501- 600]: loss = 0.491309 * 100, metric = 7.69% * 100;
 Minibatch[ 601- 700]: loss = 0.462397 * 100, metric = 7.00% * 100;
 Minibatch[ 701- 800]: loss = 0.489138 * 100, metric = 7.67% * 100;
 Minibatch[ 801- 900]: loss = 0.492993 * 100, metric = 7.90% * 100;
 Minibatch[ 901-1000]: loss = 0.479277 * 100, metric = 7.42% * 100;
 Minibatch[1001-1100]: loss = 0.467846 * 100, metric = 7.10% * 100;
 Minibatch[1101-1200]: loss = 0.498196 * 100, metric = 7.81% * 100;
 Minibatch[1201-1300]: loss = 0.491113 * 100, metric = 7.59% * 100;
 Minibatch[1301-1400]: loss = 0.477917 * 100, metric = 7.56% * 100;
 Minibatch[1401-1500]: loss = 0.493128 * 100, metric = 7.94% * 100;
 Minibatch[1501-1600]: loss = 0.484694 * 100, metric = 7.51% * 100;
 Minibatch[1601-1700]: loss = 0.483616 * 100, metric = 7.37% * 100;
 Minibatch[1701-1800]: loss = 0.471145 * 100, metric = 7.24% * 100;
 Minibatch[1801-1900]: loss = 0.492996 * 100, metric = 7.65% * 100;
 Minibatch[1901-2000]: loss = 0.509445 * 100, metric = 8.11% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.488126 * 2000, metric = 7.62% * 2000 945.691s (  2.1 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.37% * 2000;
 Minibatch[   1- 100]: loss = 0.466235 * 100, metric = 6.88% * 100;
 Minibatch[ 101- 200]: loss = 0.497792 * 100, metric = 7.71% * 100;
 Minibatch[ 201- 300]: loss = 0.476153 * 100, metric = 7.43% * 100;
 Minibatch[ 301- 400]: loss = 0.481429 * 100, metric = 7.40% * 100;
 Minibatch[ 401- 500]: loss = 0.463473 * 100, metric = 7.06% * 100;
 Minibatch[ 501- 600]: loss = 0.463533 * 100, metric = 7.10% * 100;
 Minibatch[ 601- 700]: loss = 0.481170 * 100, metric = 7.30% * 100;
 Minibatch[ 701- 800]: loss = 0.460721 * 100, metric = 6.98% * 100;
 Minibatch[ 801- 900]: loss = 0.473400 * 100, metric = 7.19% * 100;
 Minibatch[ 901-1000]: loss = 0.480839 * 100, metric = 7.51% * 100;
 Minibatch[1001-1100]: loss = 0.493500 * 100, metric = 7.68% * 100;
 Minibatch[1101-1200]: loss = 0.487515 * 100, metric = 7.53% * 100;
 Minibatch[1201-1300]: loss = 0.489172 * 100, metric = 7.66% * 100;
 Minibatch[1301-1400]: loss = 0.496683 * 100, metric = 7.71% * 100;
 Minibatch[1401-1500]: loss = 0.459585 * 100, metric = 6.84% * 100;
 Minibatch[1501-1600]: loss = 0.472655 * 100, metric = 7.03% * 100;
 Minibatch[1601-1700]: loss = 0.452450 * 100, metric = 6.76% * 100;
 Minibatch[1701-1800]: loss = 0.471982 * 100, metric = 7.15% * 100;
 Minibatch[1801-1900]: loss = 0.454723 * 100, metric = 6.86% * 100;
 Minibatch[1901-2000]: loss = 0.456464 * 100, metric = 6.94% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.473974 * 2000, metric = 7.24% * 2000 945.909s (  2.1 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.11% * 2000;
 Minibatch[   1- 100]: loss = 0.476947 * 100, metric = 7.39% * 100;
 Minibatch[ 101- 200]: loss = 0.487213 * 100, metric = 7.40% * 100;
 Minibatch[ 201- 300]: loss = 0.454624 * 100, metric = 6.63% * 100;
 Minibatch[ 301- 400]: loss = 0.465158 * 100, metric = 7.10% * 100;
 Minibatch[ 401- 500]: loss = 0.462979 * 100, metric = 6.81% * 100;
 Minibatch[ 501- 600]: loss = 0.464526 * 100, metric = 6.76% * 100;
 Minibatch[ 601- 700]: loss = 0.477242 * 100, metric = 7.28% * 100;
 Minibatch[ 701- 800]: loss = 0.457474 * 100, metric = 7.04% * 100;
 Minibatch[ 801- 900]: loss = 0.503082 * 100, metric = 7.85% * 100;
 Minibatch[ 901-1000]: loss = 0.469149 * 100, metric = 7.05% * 100;
 Minibatch[1001-1100]: loss = 0.481910 * 100, metric = 7.30% * 100;
 Minibatch[1101-1200]: loss = 0.472546 * 100, metric = 7.35% * 100;
 Minibatch[1201-1300]: loss = 0.465966 * 100, metric = 7.17% * 100;
 Minibatch[1301-1400]: loss = 0.460810 * 100, metric = 7.05% * 100;
 Minibatch[1401-1500]: loss = 0.470973 * 100, metric = 7.18% * 100;
 Minibatch[1501-1600]: loss = 0.463966 * 100, metric = 7.01% * 100;
 Minibatch[1601-1700]: loss = 0.453177 * 100, metric = 6.82% * 100;
 Minibatch[1701-1800]: loss = 0.442606 * 100, metric = 6.62% * 100;
 Minibatch[1801-1900]: loss = 0.457473 * 100, metric = 6.82% * 100;
 Minibatch[1901-2000]: loss = 0.448966 * 100, metric = 6.66% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.466839 * 2000, metric = 7.07% * 2000 955.719s (  2.1 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 15.61% * 2000;
 Minibatch[   1- 100]: loss = 0.461497 * 100, metric = 6.68% * 100;
 Minibatch[ 101- 200]: loss = 0.475678 * 100, metric = 7.51% * 100;
 Minibatch[ 201- 300]: loss = 0.469077 * 100, metric = 7.01% * 100;
 Minibatch[ 301- 400]: loss = 0.487876 * 100, metric = 7.22% * 100;
 Minibatch[ 401- 500]: loss = 0.467959 * 100, metric = 6.96% * 100;
 Minibatch[ 501- 600]: loss = 0.473725 * 100, metric = 7.18% * 100;
 Minibatch[ 601- 700]: loss = 0.486779 * 100, metric = 7.46% * 100;
 Minibatch[ 701- 800]: loss = 0.473417 * 100, metric = 7.10% * 100;
 Minibatch[ 801- 900]: loss = 0.476761 * 100, metric = 7.39% * 100;
 Minibatch[ 901-1000]: loss = 0.478943 * 100, metric = 7.34% * 100;
 Minibatch[1001-1100]: loss = 0.453108 * 100, metric = 6.75% * 100;
 Minibatch[1101-1200]: loss = 0.472036 * 100, metric = 7.08% * 100;
 Minibatch[1201-1300]: loss = 0.471820 * 100, metric = 7.03% * 100;
 Minibatch[1301-1400]: loss = 0.478353 * 100, metric = 7.28% * 100;
 Minibatch[1401-1500]: loss = 0.466074 * 100, metric = 7.25% * 100;
 Minibatch[1501-1600]: loss = 0.475417 * 100, metric = 7.26% * 100;
 Minibatch[1601-1700]: loss = 0.462169 * 100, metric = 6.92% * 100;
 Minibatch[1701-1800]: loss = 0.473067 * 100, metric = 7.20% * 100;
 Minibatch[1801-1900]: loss = 0.466945 * 100, metric = 7.14% * 100;
 Minibatch[1901-2000]: loss = 0.457620 * 100, metric = 6.79% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.471416 * 2000, metric = 7.13% * 2000 943.970s (  2.1 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 14.33% * 2000;
 Minibatch[   1- 100]: loss = 0.475158 * 100, metric = 7.12% * 100;
 Minibatch[ 101- 200]: loss = 0.465886 * 100, metric = 7.01% * 100;
 Minibatch[ 201- 300]: loss = 0.453928 * 100, metric = 6.84% * 100;
 Minibatch[ 301- 400]: loss = 0.467976 * 100, metric = 7.29% * 100;
 Minibatch[ 401- 500]: loss = 0.457445 * 100, metric = 6.87% * 100;
 Minibatch[ 501- 600]: loss = 0.452174 * 100, metric = 6.73% * 100;
 Minibatch[ 601- 700]: loss = 0.458037 * 100, metric = 6.94% * 100;
 Minibatch[ 701- 800]: loss = 0.431961 * 100, metric = 6.36% * 100;
 Minibatch[ 801- 900]: loss = 0.467494 * 100, metric = 7.20% * 100;
 Minibatch[ 901-1000]: loss = 0.451448 * 100, metric = 6.79% * 100;
 Minibatch[1001-1100]: loss = 0.452077 * 100, metric = 6.71% * 100;
 Minibatch[1101-1200]: loss = 0.443148 * 100, metric = 6.59% * 100;
 Minibatch[1201-1300]: loss = 0.464641 * 100, metric = 7.13% * 100;
 Minibatch[1301-1400]: loss = 0.455409 * 100, metric = 6.85% * 100;
 Minibatch[1401-1500]: loss = 0.472752 * 100, metric = 7.05% * 100;
 Minibatch[1501-1600]: loss = 0.477753 * 100, metric = 7.64% * 100;
 Minibatch[1601-1700]: loss = 0.466976 * 100, metric = 7.28% * 100;
 Minibatch[1701-1800]: loss = 0.449803 * 100, metric = 6.69% * 100;
 Minibatch[1801-1900]: loss = 0.471541 * 100, metric = 7.37% * 100;
 Minibatch[1901-2000]: loss = 0.443605 * 100, metric = 6.60% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.458961 * 2000, metric = 6.95% * 2000 935.685s (  2.1 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 13.65% * 2000;
 Minibatch[   1- 100]: loss = 0.471061 * 100, metric = 7.15% * 100;
 Minibatch[ 101- 200]: loss = 0.462163 * 100, metric = 7.06% * 100;
 Minibatch[ 201- 300]: loss = 0.470491 * 100, metric = 7.14% * 100;
 Minibatch[ 301- 400]: loss = 0.455751 * 100, metric = 6.90% * 100;
 Minibatch[ 401- 500]: loss = 0.448224 * 100, metric = 6.70% * 100;
 Minibatch[ 501- 600]: loss = 0.466017 * 100, metric = 6.90% * 100;
 Minibatch[ 601- 700]: loss = 0.451836 * 100, metric = 6.62% * 100;
 Minibatch[ 701- 800]: loss = 0.453781 * 100, metric = 6.95% * 100;
 Minibatch[ 801- 900]: loss = 0.459761 * 100, metric = 7.00% * 100;
 Minibatch[ 901-1000]: loss = 0.465491 * 100, metric = 6.99% * 100;
 Minibatch[1001-1100]: loss = 0.441399 * 100, metric = 6.63% * 100;
 Minibatch[1101-1200]: loss = 0.434211 * 100, metric = 6.22% * 100;
 Minibatch[1201-1300]: loss = 0.452463 * 100, metric = 6.86% * 100;
 Minibatch[1301-1400]: loss = 0.453113 * 100, metric = 6.71% * 100;
 Minibatch[1401-1500]: loss = 0.439158 * 100, metric = 6.66% * 100;
 Minibatch[1501-1600]: loss = 0.441059 * 100, metric = 6.45% * 100;
 Minibatch[1601-1700]: loss = 0.449478 * 100, metric = 6.72% * 100;
 Minibatch[1701-1800]: loss = 0.440892 * 100, metric = 6.52% * 100;
 Minibatch[1801-1900]: loss = 0.446059 * 100, metric = 6.67% * 100;
 Minibatch[1901-2000]: loss = 0.449017 * 100, metric = 6.65% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.452571 * 2000, metric = 6.77% * 2000 942.517s (  2.1 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 14.66% * 2000;
 Minibatch[   1- 100]: loss = 0.456436 * 100, metric = 6.91% * 100;
 Minibatch[ 101- 200]: loss = 0.456598 * 100, metric = 6.91% * 100;
 Minibatch[ 201- 300]: loss = 0.458968 * 100, metric = 7.05% * 100;
 Minibatch[ 301- 400]: loss = 0.454341 * 100, metric = 6.76% * 100;
 Minibatch[ 401- 500]: loss = 0.461848 * 100, metric = 7.03% * 100;
 Minibatch[ 501- 600]: loss = 0.452649 * 100, metric = 6.83% * 100;
 Minibatch[ 601- 700]: loss = 0.455044 * 100, metric = 6.71% * 100;
 Minibatch[ 701- 800]: loss = 0.432462 * 100, metric = 6.31% * 100;
 Minibatch[ 801- 900]: loss = 0.430730 * 100, metric = 6.37% * 100;
 Minibatch[ 901-1000]: loss = 0.451579 * 100, metric = 6.80% * 100;
 Minibatch[1001-1100]: loss = 0.433748 * 100, metric = 6.28% * 100;
 Minibatch[1101-1200]: loss = 0.442631 * 100, metric = 6.71% * 100;
 Minibatch[1201-1300]: loss = 0.444431 * 100, metric = 6.58% * 100;
 Minibatch[1301-1400]: loss = 0.456791 * 100, metric = 6.88% * 100;
 Minibatch[1401-1500]: loss = 0.442615 * 100, metric = 6.44% * 100;
 Minibatch[1501-1600]: loss = 0.444854 * 100, metric = 6.62% * 100;
 Minibatch[1601-1700]: loss = 0.440872 * 100, metric = 6.61% * 100;
 Minibatch[1701-1800]: loss = 0.443897 * 100, metric = 6.46% * 100;
 Minibatch[1801-1900]: loss = 0.448235 * 100, metric = 6.98% * 100;
 Minibatch[1901-2000]: loss = 0.451415 * 100, metric = 6.70% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.448007 * 2000, metric = 6.70% * 2000 940.804s (  2.1 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 14.53% * 2000;
 Minibatch[   1- 100]: loss = 0.423209 * 100, metric = 6.28% * 100;
 Minibatch[ 101- 200]: loss = 0.445354 * 100, metric = 6.65% * 100;
 Minibatch[ 201- 300]: loss = 0.439531 * 100, metric = 6.59% * 100;
 Minibatch[ 301- 400]: loss = 0.442355 * 100, metric = 6.36% * 100;
 Minibatch[ 401- 500]: loss = 0.443007 * 100, metric = 6.49% * 100;
 Minibatch[ 501- 600]: loss = 0.429425 * 100, metric = 6.33% * 100;
 Minibatch[ 601- 700]: loss = 0.445423 * 100, metric = 6.74% * 100;
 Minibatch[ 701- 800]: loss = 0.433947 * 100, metric = 6.37% * 100;
 Minibatch[ 801- 900]: loss = 0.451755 * 100, metric = 6.77% * 100;
 Minibatch[ 901-1000]: loss = 0.434491 * 100, metric = 6.35% * 100;
 Minibatch[1001-1100]: loss = 0.437048 * 100, metric = 6.33% * 100;
 Minibatch[1101-1200]: loss = 0.447693 * 100, metric = 6.66% * 100;
 Minibatch[1201-1300]: loss = 0.444800 * 100, metric = 6.52% * 100;
 Minibatch[1301-1400]: loss = 0.433022 * 100, metric = 6.22% * 100;
 Minibatch[1401-1500]: loss = 0.433375 * 100, metric = 6.25% * 100;
 Minibatch[1501-1600]: loss = 0.442496 * 100, metric = 6.51% * 100;
 Minibatch[1601-1700]: loss = 0.429883 * 100, metric = 6.35% * 100;
 Minibatch[1701-1800]: loss = 0.430126 * 100, metric = 6.49% * 100;
 Minibatch[1801-1900]: loss = 0.445432 * 100, metric = 6.75% * 100;
 Minibatch[1901-2000]: loss = 0.442006 * 100, metric = 6.65% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.438719 * 2000, metric = 6.48% * 2000 942.509s (  2.1 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.41% * 2000;
 Minibatch[   1- 100]: loss = 0.444216 * 100, metric = 6.61% * 100;
 Minibatch[ 101- 200]: loss = 0.448722 * 100, metric = 6.72% * 100;
 Minibatch[ 201- 300]: loss = 0.441949 * 100, metric = 6.88% * 100;
 Minibatch[ 301- 400]: loss = 0.440483 * 100, metric = 6.57% * 100;
 Minibatch[ 401- 500]: loss = 0.437049 * 100, metric = 6.60% * 100;
 Minibatch[ 501- 600]: loss = 0.437964 * 100, metric = 6.54% * 100;
 Minibatch[ 601- 700]: loss = 0.436713 * 100, metric = 6.39% * 100;
 Minibatch[ 701- 800]: loss = 0.425782 * 100, metric = 6.18% * 100;
 Minibatch[ 801- 900]: loss = 0.427632 * 100, metric = 6.50% * 100;
 Minibatch[ 901-1000]: loss = 0.438386 * 100, metric = 6.55% * 100;
 Minibatch[1001-1100]: loss = 0.444245 * 100, metric = 6.58% * 100;
 Minibatch[1101-1200]: loss = 0.445615 * 100, metric = 6.72% * 100;
 Minibatch[1201-1300]: loss = 0.467345 * 100, metric = 7.37% * 100;
 Minibatch[1301-1400]: loss = 0.436097 * 100, metric = 6.46% * 100;
 Minibatch[1401-1500]: loss = 0.425849 * 100, metric = 6.06% * 100;
 Minibatch[1501-1600]: loss = 0.446492 * 100, metric = 6.80% * 100;
 Minibatch[1601-1700]: loss = 0.429281 * 100, metric = 6.34% * 100;
 Minibatch[1701-1800]: loss = 0.445717 * 100, metric = 6.77% * 100;
 Minibatch[1801-1900]: loss = 0.425285 * 100, metric = 6.02% * 100;
 Minibatch[1901-2000]: loss = 0.415128 * 100, metric = 5.95% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.437997 * 2000, metric = 6.53% * 2000 946.242s (  2.1 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.52% * 2000;
 Minibatch[   1- 100]: loss = 0.431000 * 100, metric = 6.36% * 100;
 Minibatch[ 101- 200]: loss = 0.413603 * 100, metric = 5.99% * 100;
 Minibatch[ 201- 300]: loss = 0.437342 * 100, metric = 6.63% * 100;
 Minibatch[ 301- 400]: loss = 0.423822 * 100, metric = 6.28% * 100;
 Minibatch[ 401- 500]: loss = 0.431960 * 100, metric = 6.35% * 100;
 Minibatch[ 501- 600]: loss = 0.427727 * 100, metric = 6.01% * 100;
 Minibatch[ 601- 700]: loss = 0.442453 * 100, metric = 6.57% * 100;
 Minibatch[ 701- 800]: loss = 0.428783 * 100, metric = 6.40% * 100;
 Minibatch[ 801- 900]: loss = 0.413513 * 100, metric = 5.94% * 100;
 Minibatch[ 901-1000]: loss = 0.412764 * 100, metric = 6.11% * 100;
 Minibatch[1001-1100]: loss = 0.445320 * 100, metric = 6.96% * 100;
 Minibatch[1101-1200]: loss = 0.448412 * 100, metric = 6.59% * 100;
 Minibatch[1201-1300]: loss = 0.437809 * 100, metric = 6.46% * 100;
 Minibatch[1301-1400]: loss = 0.412186 * 100, metric = 5.86% * 100;
 Minibatch[1401-1500]: loss = 0.427841 * 100, metric = 6.41% * 100;
 Minibatch[1501-1600]: loss = 0.419897 * 100, metric = 5.74% * 100;
 Minibatch[1601-1700]: loss = 0.449332 * 100, metric = 6.78% * 100;
 Minibatch[1701-1800]: loss = 0.438505 * 100, metric = 6.46% * 100;
 Minibatch[1801-1900]: loss = 0.427529 * 100, metric = 6.25% * 100;
 Minibatch[1901-2000]: loss = 0.445436 * 100, metric = 6.77% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.430762 * 2000, metric = 6.35% * 2000 947.021s (  2.1 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 14.52% * 2000;
 Minibatch[   1- 100]: loss = 0.430580 * 100, metric = 6.17% * 100;
 Minibatch[ 101- 200]: loss = 0.451861 * 100, metric = 6.63% * 100;
 Minibatch[ 201- 300]: loss = 0.435515 * 100, metric = 6.54% * 100;
 Minibatch[ 301- 400]: loss = 0.425136 * 100, metric = 6.20% * 100;
 Minibatch[ 401- 500]: loss = 0.429352 * 100, metric = 6.27% * 100;
 Minibatch[ 501- 600]: loss = 0.426725 * 100, metric = 6.28% * 100;
 Minibatch[ 601- 700]: loss = 0.427164 * 100, metric = 6.34% * 100;
 Minibatch[ 701- 800]: loss = 0.433661 * 100, metric = 6.42% * 100;
 Minibatch[ 801- 900]: loss = 0.438478 * 100, metric = 6.44% * 100;
 Minibatch[ 901-1000]: loss = 0.427827 * 100, metric = 6.37% * 100;
 Minibatch[1001-1100]: loss = 0.423576 * 100, metric = 5.96% * 100;
 Minibatch[1101-1200]: loss = 0.434767 * 100, metric = 6.36% * 100;
 Minibatch[1201-1300]: loss = 0.424766 * 100, metric = 6.21% * 100;
 Minibatch[1301-1400]: loss = 0.438699 * 100, metric = 6.72% * 100;
 Minibatch[1401-1500]: loss = 0.419483 * 100, metric = 6.30% * 100;
 Minibatch[1501-1600]: loss = 0.427970 * 100, metric = 6.33% * 100;
 Minibatch[1601-1700]: loss = 0.407651 * 100, metric = 5.83% * 100;
 Minibatch[1701-1800]: loss = 0.427758 * 100, metric = 6.19% * 100;
 Minibatch[1801-1900]: loss = 0.425001 * 100, metric = 6.22% * 100;
 Minibatch[1901-2000]: loss = 0.439017 * 100, metric = 6.39% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.429749 * 2000, metric = 6.31% * 2000 936.536s (  2.1 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.52% * 2000;
 Minibatch[   1- 100]: loss = 0.435767 * 100, metric = 6.49% * 100;
 Minibatch[ 101- 200]: loss = 0.418366 * 100, metric = 5.91% * 100;
 Minibatch[ 201- 300]: loss = 0.431904 * 100, metric = 6.45% * 100;
 Minibatch[ 301- 400]: loss = 0.430697 * 100, metric = 6.23% * 100;
 Minibatch[ 401- 500]: loss = 0.429113 * 100, metric = 6.40% * 100;
 Minibatch[ 501- 600]: loss = 0.448555 * 100, metric = 6.85% * 100;
 Minibatch[ 601- 700]: loss = 0.426954 * 100, metric = 6.26% * 100;
 Minibatch[ 701- 800]: loss = 0.418752 * 100, metric = 6.08% * 100;
 Minibatch[ 801- 900]: loss = 0.431939 * 100, metric = 6.30% * 100;
 Minibatch[ 901-1000]: loss = 0.427857 * 100, metric = 6.40% * 100;
 Minibatch[1001-1100]: loss = 0.426711 * 100, metric = 6.15% * 100;
 Minibatch[1101-1200]: loss = 0.422459 * 100, metric = 5.91% * 100;
 Minibatch[1201-1300]: loss = 0.440430 * 100, metric = 6.61% * 100;
 Minibatch[1301-1400]: loss = 0.428558 * 100, metric = 6.21% * 100;
 Minibatch[1401-1500]: loss = 0.437603 * 100, metric = 6.43% * 100;
 Minibatch[1501-1600]: loss = 0.428459 * 100, metric = 6.11% * 100;
 Minibatch[1601-1700]: loss = 0.429459 * 100, metric = 6.08% * 100;
 Minibatch[1701-1800]: loss = 0.428298 * 100, metric = 6.05% * 100;
 Minibatch[1801-1900]: loss = 0.424476 * 100, metric = 6.10% * 100;
 Minibatch[1901-2000]: loss = 0.430253 * 100, metric = 6.21% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.429831 * 2000, metric = 6.26% * 2000 944.988s (  2.1 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.32% * 2000;
 Minibatch[   1- 100]: loss = 0.407436 * 100, metric = 5.70% * 100;
 Minibatch[ 101- 200]: loss = 0.416297 * 100, metric = 6.18% * 100;
 Minibatch[ 201- 300]: loss = 0.423431 * 100, metric = 6.48% * 100;
 Minibatch[ 301- 400]: loss = 0.441902 * 100, metric = 6.41% * 100;
 Minibatch[ 401- 500]: loss = 0.417175 * 100, metric = 6.07% * 100;
 Minibatch[ 501- 600]: loss = 0.426404 * 100, metric = 6.32% * 100;
 Minibatch[ 601- 700]: loss = 0.425169 * 100, metric = 6.31% * 100;
 Minibatch[ 701- 800]: loss = 0.423493 * 100, metric = 6.17% * 100;
 Minibatch[ 801- 900]: loss = 0.415236 * 100, metric = 5.99% * 100;
 Minibatch[ 901-1000]: loss = 0.429741 * 100, metric = 6.20% * 100;
 Minibatch[1001-1100]: loss = 0.421497 * 100, metric = 6.07% * 100;
 Minibatch[1101-1200]: loss = 0.416244 * 100, metric = 5.89% * 100;
 Minibatch[1201-1300]: loss = 0.423272 * 100, metric = 6.06% * 100;
 Minibatch[1301-1400]: loss = 0.407322 * 100, metric = 5.68% * 100;
 Minibatch[1401-1500]: loss = 0.427661 * 100, metric = 6.19% * 100;
 Minibatch[1501-1600]: loss = 0.409598 * 100, metric = 5.78% * 100;
 Minibatch[1601-1700]: loss = 0.429858 * 100, metric = 6.39% * 100;
 Minibatch[1701-1800]: loss = 0.412483 * 100, metric = 5.98% * 100;
 Minibatch[1801-1900]: loss = 0.432378 * 100, metric = 6.19% * 100;
 Minibatch[1901-2000]: loss = 0.424185 * 100, metric = 5.92% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.421539 * 2000, metric = 6.10% * 2000 941.380s (  2.1 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 15.88% * 2000;
 Minibatch[   1- 100]: loss = 0.436209 * 100, metric = 6.37% * 100;
 Minibatch[ 101- 200]: loss = 0.405545 * 100, metric = 5.73% * 100;
 Minibatch[ 201- 300]: loss = 0.418943 * 100, metric = 6.06% * 100;
 Minibatch[ 301- 400]: loss = 0.428182 * 100, metric = 6.35% * 100;
 Minibatch[ 401- 500]: loss = 0.423840 * 100, metric = 6.07% * 100;
 Minibatch[ 501- 600]: loss = 0.407651 * 100, metric = 5.66% * 100;
 Minibatch[ 601- 700]: loss = 0.418294 * 100, metric = 5.97% * 100;
 Minibatch[ 701- 800]: loss = 0.411806 * 100, metric = 5.78% * 100;
 Minibatch[ 801- 900]: loss = 0.423345 * 100, metric = 6.03% * 100;
 Minibatch[ 901-1000]: loss = 0.402891 * 100, metric = 5.75% * 100;
 Minibatch[1001-1100]: loss = 0.417636 * 100, metric = 5.95% * 100;
 Minibatch[1101-1200]: loss = 0.431145 * 100, metric = 6.25% * 100;
 Minibatch[1201-1300]: loss = 0.410266 * 100, metric = 5.90% * 100;
 Minibatch[1301-1400]: loss = 0.414570 * 100, metric = 6.02% * 100;
 Minibatch[1401-1500]: loss = 0.413650 * 100, metric = 5.87% * 100;
 Minibatch[1501-1600]: loss = 0.428311 * 100, metric = 6.19% * 100;
 Minibatch[1601-1700]: loss = 0.419460 * 100, metric = 6.04% * 100;
 Minibatch[1701-1800]: loss = 0.422159 * 100, metric = 6.15% * 100;
 Minibatch[1801-1900]: loss = 0.419185 * 100, metric = 6.12% * 100;
 Minibatch[1901-2000]: loss = 0.432328 * 100, metric = 6.26% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.419271 * 2000, metric = 6.03% * 2000 941.577s (  2.1 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.44% * 2000;
 Minibatch[   1- 100]: loss = 0.421375 * 100, metric = 5.90% * 100;
 Minibatch[ 101- 200]: loss = 0.426753 * 100, metric = 6.41% * 100;
 Minibatch[ 201- 300]: loss = 0.413563 * 100, metric = 5.84% * 100;
 Minibatch[ 301- 400]: loss = 0.405558 * 100, metric = 5.65% * 100;
 Minibatch[ 401- 500]: loss = 0.407162 * 100, metric = 5.82% * 100;
 Minibatch[ 501- 600]: loss = 0.410818 * 100, metric = 5.88% * 100;
 Minibatch[ 601- 700]: loss = 0.424485 * 100, metric = 6.33% * 100;
 Minibatch[ 701- 800]: loss = 0.423983 * 100, metric = 6.12% * 100;
 Minibatch[ 801- 900]: loss = 0.413291 * 100, metric = 5.81% * 100;
 Minibatch[ 901-1000]: loss = 0.405795 * 100, metric = 5.75% * 100;
 Minibatch[1001-1100]: loss = 0.402458 * 100, metric = 5.53% * 100;
 Minibatch[1101-1200]: loss = 0.419259 * 100, metric = 6.08% * 100;
 Minibatch[1201-1300]: loss = 0.411496 * 100, metric = 5.75% * 100;
 Minibatch[1301-1400]: loss = 0.409774 * 100, metric = 5.87% * 100;
 Minibatch[1401-1500]: loss = 0.411080 * 100, metric = 5.78% * 100;
 Minibatch[1501-1600]: loss = 0.393652 * 100, metric = 5.73% * 100;
 Minibatch[1601-1700]: loss = 0.411884 * 100, metric = 5.97% * 100;
 Minibatch[1701-1800]: loss = 0.400237 * 100, metric = 5.62% * 100;
 Minibatch[1801-1900]: loss = 0.409012 * 100, metric = 5.92% * 100;
 Minibatch[1901-2000]: loss = 0.406214 * 100, metric = 5.81% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.411392 * 2000, metric = 5.88% * 2000 941.162s (  2.1 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 14.40% * 2000;
 Minibatch[   1- 100]: loss = 0.406952 * 100, metric = 5.86% * 100;
 Minibatch[ 101- 200]: loss = 0.416064 * 100, metric = 5.95% * 100;
 Minibatch[ 201- 300]: loss = 0.429423 * 100, metric = 6.21% * 100;
 Minibatch[ 301- 400]: loss = 0.422912 * 100, metric = 6.07% * 100;
 Minibatch[ 401- 500]: loss = 0.416857 * 100, metric = 6.24% * 100;
 Minibatch[ 501- 600]: loss = 0.408896 * 100, metric = 5.78% * 100;
 Minibatch[ 601- 700]: loss = 0.402862 * 100, metric = 5.58% * 100;
 Minibatch[ 701- 800]: loss = 0.413860 * 100, metric = 5.96% * 100;
 Minibatch[ 801- 900]: loss = 0.411470 * 100, metric = 5.91% * 100;
 Minibatch[ 901-1000]: loss = 0.407097 * 100, metric = 5.82% * 100;
 Minibatch[1001-1100]: loss = 0.405299 * 100, metric = 5.57% * 100;
 Minibatch[1101-1200]: loss = 0.411956 * 100, metric = 5.73% * 100;
 Minibatch[1201-1300]: loss = 0.424988 * 100, metric = 6.14% * 100;
 Minibatch[1301-1400]: loss = 0.405734 * 100, metric = 5.84% * 100;
 Minibatch[1401-1500]: loss = 0.400458 * 100, metric = 5.81% * 100;
 Minibatch[1501-1600]: loss = 0.419890 * 100, metric = 6.00% * 100;
 Minibatch[1601-1700]: loss = 0.407902 * 100, metric = 5.86% * 100;
 Minibatch[1701-1800]: loss = 0.415084 * 100, metric = 6.07% * 100;
 Minibatch[1801-1900]: loss = 0.406145 * 100, metric = 5.77% * 100;
 Minibatch[1901-2000]: loss = 0.422332 * 100, metric = 6.37% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.412809 * 2000, metric = 5.93% * 2000 938.205s (  2.1 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.83% * 2000;
 Minibatch[   1- 100]: loss = 0.420687 * 100, metric = 6.08% * 100;
 Minibatch[ 101- 200]: loss = 0.404173 * 100, metric = 5.79% * 100;
 Minibatch[ 201- 300]: loss = 0.402882 * 100, metric = 5.85% * 100;
 Minibatch[ 301- 400]: loss = 0.406033 * 100, metric = 5.92% * 100;
 Minibatch[ 401- 500]: loss = 0.406542 * 100, metric = 5.72% * 100;
 Minibatch[ 501- 600]: loss = 0.412822 * 100, metric = 5.72% * 100;
 Minibatch[ 601- 700]: loss = 0.420842 * 100, metric = 5.95% * 100;
 Minibatch[ 701- 800]: loss = 0.412505 * 100, metric = 5.98% * 100;
 Minibatch[ 801- 900]: loss = 0.401426 * 100, metric = 5.40% * 100;
 Minibatch[ 901-1000]: loss = 0.393599 * 100, metric = 5.38% * 100;
 Minibatch[1001-1100]: loss = 0.397460 * 100, metric = 5.66% * 100;
 Minibatch[1101-1200]: loss = 0.388723 * 100, metric = 5.48% * 100;
 Minibatch[1201-1300]: loss = 0.413260 * 100, metric = 5.86% * 100;
 Minibatch[1301-1400]: loss = 0.395358 * 100, metric = 5.44% * 100;
 Minibatch[1401-1500]: loss = 0.425747 * 100, metric = 6.03% * 100;
 Minibatch[1501-1600]: loss = 0.414030 * 100, metric = 5.80% * 100;
 Minibatch[1601-1700]: loss = 0.395491 * 100, metric = 5.43% * 100;
 Minibatch[1701-1800]: loss = 0.402566 * 100, metric = 5.69% * 100;
 Minibatch[1801-1900]: loss = 0.398199 * 100, metric = 5.49% * 100;
 Minibatch[1901-2000]: loss = 0.405702 * 100, metric = 5.90% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.405902 * 2000, metric = 5.73% * 2000 930.682s (  2.1 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.84% * 2000;
 Minibatch[   1- 100]: loss = 0.401043 * 100, metric = 5.65% * 100;
 Minibatch[ 101- 200]: loss = 0.402424 * 100, metric = 5.57% * 100;
 Minibatch[ 201- 300]: loss = 0.393592 * 100, metric = 5.40% * 100;
 Minibatch[ 301- 400]: loss = 0.403604 * 100, metric = 5.67% * 100;
 Minibatch[ 401- 500]: loss = 0.389074 * 100, metric = 5.47% * 100;
 Minibatch[ 501- 600]: loss = 0.405638 * 100, metric = 5.75% * 100;
 Minibatch[ 601- 700]: loss = 0.399563 * 100, metric = 5.52% * 100;
 Minibatch[ 701- 800]: loss = 0.388446 * 100, metric = 5.35% * 100;
 Minibatch[ 801- 900]: loss = 0.376714 * 100, metric = 5.11% * 100;
 Minibatch[ 901-1000]: loss = 0.388957 * 100, metric = 5.40% * 100;
 Minibatch[1001-1100]: loss = 0.399052 * 100, metric = 5.62% * 100;
 Minibatch[1101-1200]: loss = 0.388853 * 100, metric = 5.67% * 100;
 Minibatch[1201-1300]: loss = 0.404084 * 100, metric = 5.55% * 100;
 Minibatch[1301-1400]: loss = 0.386385 * 100, metric = 5.51% * 100;
 Minibatch[1401-1500]: loss = 0.405818 * 100, metric = 5.87% * 100;
 Minibatch[1501-1600]: loss = 0.400660 * 100, metric = 5.57% * 100;
 Minibatch[1601-1700]: loss = 0.407087 * 100, metric = 5.97% * 100;
 Minibatch[1701-1800]: loss = 0.397896 * 100, metric = 5.44% * 100;
 Minibatch[1801-1900]: loss = 0.395032 * 100, metric = 5.70% * 100;
 Minibatch[1901-2000]: loss = 0.400874 * 100, metric = 5.44% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.396740 * 2000, metric = 5.56% * 2000 945.789s (  2.1 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.55% * 2000;
 Minibatch[   1- 100]: loss = 0.372572 * 100, metric = 4.88% * 100;
 Minibatch[ 101- 200]: loss = 0.399037 * 100, metric = 5.60% * 100;
 Minibatch[ 201- 300]: loss = 0.391288 * 100, metric = 5.43% * 100;
 Minibatch[ 301- 400]: loss = 0.373718 * 100, metric = 5.07% * 100;
 Minibatch[ 401- 500]: loss = 0.387207 * 100, metric = 5.42% * 100;
 Minibatch[ 501- 600]: loss = 0.366802 * 100, metric = 4.95% * 100;
 Minibatch[ 601- 700]: loss = 0.407166 * 100, metric = 5.77% * 100;
 Minibatch[ 701- 800]: loss = 0.382141 * 100, metric = 5.26% * 100;
 Minibatch[ 801- 900]: loss = 0.400129 * 100, metric = 5.76% * 100;
 Minibatch[ 901-1000]: loss = 0.386824 * 100, metric = 5.32% * 100;
 Minibatch[1001-1100]: loss = 0.402602 * 100, metric = 5.69% * 100;
 Minibatch[1101-1200]: loss = 0.392009 * 100, metric = 5.41% * 100;
 Minibatch[1201-1300]: loss = 0.390400 * 100, metric = 5.41% * 100;
 Minibatch[1301-1400]: loss = 0.401591 * 100, metric = 5.49% * 100;
 Minibatch[1401-1500]: loss = 0.394426 * 100, metric = 5.38% * 100;
 Minibatch[1501-1600]: loss = 0.398318 * 100, metric = 5.60% * 100;
 Minibatch[1601-1700]: loss = 0.399202 * 100, metric = 5.68% * 100;
 Minibatch[1701-1800]: loss = 0.389628 * 100, metric = 5.41% * 100;
 Minibatch[1801-1900]: loss = 0.400068 * 100, metric = 5.66% * 100;
 Minibatch[1901-2000]: loss = 0.399890 * 100, metric = 5.67% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.391751 * 2000, metric = 5.44% * 2000 941.714s (  2.1 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.69% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
