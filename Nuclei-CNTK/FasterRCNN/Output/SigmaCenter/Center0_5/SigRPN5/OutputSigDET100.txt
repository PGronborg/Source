Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.378586 * 100, metric = 24.27% * 100;
 Minibatch[ 101- 200]: loss = 1.151310 * 100, metric = 23.10% * 100;
 Minibatch[ 201- 300]: loss = 1.026196 * 100, metric = 21.30% * 100;
 Minibatch[ 301- 400]: loss = 1.025017 * 100, metric = 20.62% * 100;
 Minibatch[ 401- 500]: loss = 0.943047 * 100, metric = 18.94% * 100;
 Minibatch[ 501- 600]: loss = 0.923083 * 100, metric = 17.64% * 100;
 Minibatch[ 601- 700]: loss = 0.875704 * 100, metric = 16.39% * 100;
 Minibatch[ 701- 800]: loss = 0.821198 * 100, metric = 15.41% * 100;
 Minibatch[ 801- 900]: loss = 0.842700 * 100, metric = 15.90% * 100;
 Minibatch[ 901-1000]: loss = 0.847273 * 100, metric = 16.08% * 100;
 Minibatch[1001-1100]: loss = 0.835635 * 100, metric = 15.73% * 100;
 Minibatch[1101-1200]: loss = 0.815166 * 100, metric = 14.85% * 100;
 Minibatch[1201-1300]: loss = 0.825082 * 100, metric = 15.53% * 100;
 Minibatch[1301-1400]: loss = 0.799375 * 100, metric = 14.51% * 100;
 Minibatch[1401-1500]: loss = 0.815560 * 100, metric = 14.65% * 100;
 Minibatch[1501-1600]: loss = 0.786221 * 100, metric = 14.46% * 100;
 Minibatch[1601-1700]: loss = 0.769723 * 100, metric = 14.10% * 100;
 Minibatch[1701-1800]: loss = 0.786591 * 100, metric = 14.00% * 100;
 Minibatch[1801-1900]: loss = 0.785859 * 100, metric = 14.29% * 100;
 Minibatch[1901-2000]: loss = 0.725693 * 100, metric = 12.76% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.888951 * 2000, metric = 16.73% * 2000 1125.318s (  1.8 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 23.06% * 2000;
0.8196031327322125
 Minibatch[   1- 100]: loss = 0.736626 * 100, metric = 13.10% * 100;
 Minibatch[ 101- 200]: loss = 0.762406 * 100, metric = 14.07% * 100;
 Minibatch[ 201- 300]: loss = 0.732562 * 100, metric = 12.89% * 100;
 Minibatch[ 301- 400]: loss = 0.731439 * 100, metric = 13.08% * 100;
 Minibatch[ 401- 500]: loss = 0.723620 * 100, metric = 13.09% * 100;
 Minibatch[ 501- 600]: loss = 0.725868 * 100, metric = 12.67% * 100;
 Minibatch[ 601- 700]: loss = 0.719377 * 100, metric = 12.69% * 100;
 Minibatch[ 701- 800]: loss = 0.724470 * 100, metric = 13.30% * 100;
 Minibatch[ 801- 900]: loss = 0.692332 * 100, metric = 12.19% * 100;
 Minibatch[ 901-1000]: loss = 0.690504 * 100, metric = 12.01% * 100;
 Minibatch[1001-1100]: loss = 0.698725 * 100, metric = 12.53% * 100;
 Minibatch[1101-1200]: loss = 0.713812 * 100, metric = 12.54% * 100;
 Minibatch[1201-1300]: loss = 0.700538 * 100, metric = 12.62% * 100;
 Minibatch[1301-1400]: loss = 0.709255 * 100, metric = 12.46% * 100;
 Minibatch[1401-1500]: loss = 0.700911 * 100, metric = 12.41% * 100;
 Minibatch[1501-1600]: loss = 0.679351 * 100, metric = 11.52% * 100;
 Minibatch[1601-1700]: loss = 0.681537 * 100, metric = 11.87% * 100;
 Minibatch[1701-1800]: loss = 0.675463 * 100, metric = 12.04% * 100;
 Minibatch[1801-1900]: loss = 0.685746 * 100, metric = 11.70% * 100;
 Minibatch[1901-2000]: loss = 0.634580 * 100, metric = 10.73% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.705956 * 2000, metric = 12.48% * 2000 1059.165s (  1.9 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 20.43% * 2000;
0.7549511455148459
 Minibatch[   1- 100]: loss = 0.666777 * 100, metric = 11.69% * 100;
 Minibatch[ 101- 200]: loss = 0.669115 * 100, metric = 11.57% * 100;
 Minibatch[ 201- 300]: loss = 0.649384 * 100, metric = 11.29% * 100;
 Minibatch[ 301- 400]: loss = 0.657652 * 100, metric = 11.53% * 100;
 Minibatch[ 401- 500]: loss = 0.663172 * 100, metric = 11.51% * 100;
 Minibatch[ 501- 600]: loss = 0.658270 * 100, metric = 11.60% * 100;
 Minibatch[ 601- 700]: loss = 0.677293 * 100, metric = 11.75% * 100;
 Minibatch[ 701- 800]: loss = 0.648519 * 100, metric = 10.87% * 100;
 Minibatch[ 801- 900]: loss = 0.689870 * 100, metric = 12.07% * 100;
 Minibatch[ 901-1000]: loss = 0.655475 * 100, metric = 11.36% * 100;
 Minibatch[1001-1100]: loss = 0.664325 * 100, metric = 11.52% * 100;
 Minibatch[1101-1200]: loss = 0.654018 * 100, metric = 11.37% * 100;
 Minibatch[1201-1300]: loss = 0.651331 * 100, metric = 11.19% * 100;
 Minibatch[1301-1400]: loss = 0.666963 * 100, metric = 11.67% * 100;
 Minibatch[1401-1500]: loss = 0.663466 * 100, metric = 11.47% * 100;
 Minibatch[1501-1600]: loss = 0.655668 * 100, metric = 11.10% * 100;
 Minibatch[1601-1700]: loss = 0.629346 * 100, metric = 10.72% * 100;
 Minibatch[1701-1800]: loss = 0.656296 * 100, metric = 11.37% * 100;
 Minibatch[1801-1900]: loss = 0.643317 * 100, metric = 10.72% * 100;
 Minibatch[1901-2000]: loss = 0.643217 * 100, metric = 11.27% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.658174 * 2000, metric = 11.38% * 2000 1038.672s (  1.9 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 21.00% * 2000;
0.7436744490265846
 Minibatch[   1- 100]: loss = 0.677934 * 100, metric = 11.60% * 100;
 Minibatch[ 101- 200]: loss = 0.630301 * 100, metric = 10.81% * 100;
 Minibatch[ 201- 300]: loss = 0.655371 * 100, metric = 11.37% * 100;
 Minibatch[ 301- 400]: loss = 0.621626 * 100, metric = 10.61% * 100;
 Minibatch[ 401- 500]: loss = 0.654137 * 100, metric = 11.38% * 100;
 Minibatch[ 501- 600]: loss = 0.638956 * 100, metric = 10.86% * 100;
 Minibatch[ 601- 700]: loss = 0.638186 * 100, metric = 10.84% * 100;
 Minibatch[ 701- 800]: loss = 0.644806 * 100, metric = 10.74% * 100;
 Minibatch[ 801- 900]: loss = 0.644337 * 100, metric = 11.01% * 100;
 Minibatch[ 901-1000]: loss = 0.641792 * 100, metric = 11.03% * 100;
 Minibatch[1001-1100]: loss = 0.649843 * 100, metric = 11.29% * 100;
 Minibatch[1101-1200]: loss = 0.618725 * 100, metric = 10.47% * 100;
 Minibatch[1201-1300]: loss = 0.624943 * 100, metric = 10.62% * 100;
 Minibatch[1301-1400]: loss = 0.644407 * 100, metric = 10.99% * 100;
 Minibatch[1401-1500]: loss = 0.646354 * 100, metric = 11.12% * 100;
 Minibatch[1501-1600]: loss = 0.609537 * 100, metric = 10.36% * 100;
 Minibatch[1601-1700]: loss = 0.634437 * 100, metric = 10.92% * 100;
 Minibatch[1701-1800]: loss = 0.633984 * 100, metric = 11.08% * 100;
 Minibatch[1801-1900]: loss = 0.616342 * 100, metric = 10.32% * 100;
 Minibatch[1901-2000]: loss = 0.610021 * 100, metric = 10.22% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.636802 * 2000, metric = 10.88% * 2000 1041.025s (  1.9 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 20.70% * 2000;
 Minibatch[   1- 100]: loss = 0.641778 * 100, metric = 10.86% * 100;
 Minibatch[ 101- 200]: loss = 0.620684 * 100, metric = 10.37% * 100;
 Minibatch[ 201- 300]: loss = 0.614073 * 100, metric = 10.43% * 100;
 Minibatch[ 301- 400]: loss = 0.653371 * 100, metric = 11.31% * 100;
 Minibatch[ 401- 500]: loss = 0.609084 * 100, metric = 10.23% * 100;
 Minibatch[ 501- 600]: loss = 0.608273 * 100, metric = 10.18% * 100;
 Minibatch[ 601- 700]: loss = 0.615638 * 100, metric = 10.14% * 100;
 Minibatch[ 701- 800]: loss = 0.618965 * 100, metric = 10.30% * 100;
 Minibatch[ 801- 900]: loss = 0.613671 * 100, metric = 10.26% * 100;
 Minibatch[ 901-1000]: loss = 0.614378 * 100, metric = 10.49% * 100;
 Minibatch[1001-1100]: loss = 0.626313 * 100, metric = 10.46% * 100;
 Minibatch[1101-1200]: loss = 0.611918 * 100, metric = 10.38% * 100;
 Minibatch[1201-1300]: loss = 0.626732 * 100, metric = 10.54% * 100;
 Minibatch[1301-1400]: loss = 0.642858 * 100, metric = 10.93% * 100;
 Minibatch[1401-1500]: loss = 0.614307 * 100, metric = 10.43% * 100;
 Minibatch[1501-1600]: loss = 0.617860 * 100, metric = 10.54% * 100;
 Minibatch[1601-1700]: loss = 0.631167 * 100, metric = 10.97% * 100;
 Minibatch[1701-1800]: loss = 0.623813 * 100, metric = 10.33% * 100;
 Minibatch[1801-1900]: loss = 0.613218 * 100, metric = 10.43% * 100;
 Minibatch[1901-2000]: loss = 0.596298 * 100, metric = 9.97% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.620720 * 2000, metric = 10.48% * 2000 1025.650s (  1.9 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 17.72% * 2000;
0.6817184622436762
 Minibatch[   1- 100]: loss = 0.603602 * 100, metric = 10.02% * 100;
 Minibatch[ 101- 200]: loss = 0.595843 * 100, metric = 9.85% * 100;
 Minibatch[ 201- 300]: loss = 0.604979 * 100, metric = 9.98% * 100;
 Minibatch[ 301- 400]: loss = 0.613280 * 100, metric = 10.09% * 100;
 Minibatch[ 401- 500]: loss = 0.591961 * 100, metric = 9.98% * 100;
 Minibatch[ 501- 600]: loss = 0.610221 * 100, metric = 10.38% * 100;
 Minibatch[ 601- 700]: loss = 0.604018 * 100, metric = 10.21% * 100;
 Minibatch[ 701- 800]: loss = 0.616153 * 100, metric = 10.24% * 100;
 Minibatch[ 801- 900]: loss = 0.616603 * 100, metric = 10.61% * 100;
 Minibatch[ 901-1000]: loss = 0.599194 * 100, metric = 10.33% * 100;
 Minibatch[1001-1100]: loss = 0.609541 * 100, metric = 9.93% * 100;
 Minibatch[1101-1200]: loss = 0.620159 * 100, metric = 10.32% * 100;
 Minibatch[1201-1300]: loss = 0.636155 * 100, metric = 10.51% * 100;
 Minibatch[1301-1400]: loss = 0.614828 * 100, metric = 10.40% * 100;
 Minibatch[1401-1500]: loss = 0.614373 * 100, metric = 10.57% * 100;
 Minibatch[1501-1600]: loss = 0.598775 * 100, metric = 9.81% * 100;
 Minibatch[1601-1700]: loss = 0.604188 * 100, metric = 9.86% * 100;
 Minibatch[1701-1800]: loss = 0.600873 * 100, metric = 10.13% * 100;
 Minibatch[1801-1900]: loss = 0.622545 * 100, metric = 10.52% * 100;
 Minibatch[1901-2000]: loss = 0.599961 * 100, metric = 10.03% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.608862 * 2000, metric = 10.19% * 2000 1015.662s (  2.0 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 17.80% * 2000;
 Minibatch[   1- 100]: loss = 0.607316 * 100, metric = 10.26% * 100;
 Minibatch[ 101- 200]: loss = 0.616962 * 100, metric = 10.31% * 100;
 Minibatch[ 201- 300]: loss = 0.601965 * 100, metric = 10.36% * 100;
 Minibatch[ 301- 400]: loss = 0.594953 * 100, metric = 9.54% * 100;
 Minibatch[ 401- 500]: loss = 0.608878 * 100, metric = 9.95% * 100;
 Minibatch[ 501- 600]: loss = 0.577613 * 100, metric = 9.28% * 100;
 Minibatch[ 601- 700]: loss = 0.597180 * 100, metric = 9.72% * 100;
 Minibatch[ 701- 800]: loss = 0.602174 * 100, metric = 10.05% * 100;
 Minibatch[ 801- 900]: loss = 0.609334 * 100, metric = 10.37% * 100;
 Minibatch[ 901-1000]: loss = 0.597271 * 100, metric = 9.74% * 100;
 Minibatch[1001-1100]: loss = 0.604866 * 100, metric = 10.19% * 100;
 Minibatch[1101-1200]: loss = 0.586670 * 100, metric = 9.56% * 100;
 Minibatch[1201-1300]: loss = 0.611234 * 100, metric = 10.39% * 100;
 Minibatch[1301-1400]: loss = 0.594882 * 100, metric = 9.81% * 100;
 Minibatch[1401-1500]: loss = 0.589823 * 100, metric = 9.55% * 100;
 Minibatch[1501-1600]: loss = 0.602540 * 100, metric = 10.10% * 100;
 Minibatch[1601-1700]: loss = 0.613718 * 100, metric = 10.22% * 100;
 Minibatch[1701-1800]: loss = 0.595229 * 100, metric = 9.77% * 100;
 Minibatch[1801-1900]: loss = 0.604944 * 100, metric = 10.32% * 100;
 Minibatch[1901-2000]: loss = 0.605016 * 100, metric = 10.26% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.601128 * 2000, metric = 9.99% * 2000 1018.041s (  2.0 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 16.15% * 2000;
0.6504361948296428
 Minibatch[   1- 100]: loss = 0.621757 * 100, metric = 10.35% * 100;
 Minibatch[ 101- 200]: loss = 0.608526 * 100, metric = 10.41% * 100;
 Minibatch[ 201- 300]: loss = 0.592554 * 100, metric = 9.84% * 100;
 Minibatch[ 301- 400]: loss = 0.594556 * 100, metric = 10.04% * 100;
 Minibatch[ 401- 500]: loss = 0.618975 * 100, metric = 10.67% * 100;
 Minibatch[ 501- 600]: loss = 0.623716 * 100, metric = 10.83% * 100;
 Minibatch[ 601- 700]: loss = 0.584099 * 100, metric = 9.78% * 100;
 Minibatch[ 701- 800]: loss = 0.602721 * 100, metric = 9.74% * 100;
 Minibatch[ 801- 900]: loss = 0.581231 * 100, metric = 9.46% * 100;
 Minibatch[ 901-1000]: loss = 0.564047 * 100, metric = 8.94% * 100;
 Minibatch[1001-1100]: loss = 0.571581 * 100, metric = 9.24% * 100;
 Minibatch[1101-1200]: loss = 0.567598 * 100, metric = 9.20% * 100;
 Minibatch[1201-1300]: loss = 0.582215 * 100, metric = 9.77% * 100;
 Minibatch[1301-1400]: loss = 0.588497 * 100, metric = 9.88% * 100;
 Minibatch[1401-1500]: loss = 0.584399 * 100, metric = 9.67% * 100;
 Minibatch[1501-1600]: loss = 0.592472 * 100, metric = 9.72% * 100;
 Minibatch[1601-1700]: loss = 0.579906 * 100, metric = 9.49% * 100;
 Minibatch[1701-1800]: loss = 0.573920 * 100, metric = 9.06% * 100;
 Minibatch[1801-1900]: loss = 0.581642 * 100, metric = 9.44% * 100;
 Minibatch[1901-2000]: loss = 0.587461 * 100, metric = 9.62% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.590094 * 2000, metric = 9.76% * 2000 1013.757s (  2.0 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 15.46% * 2000;
0.6308221840187908
 Minibatch[   1- 100]: loss = 0.555593 * 100, metric = 8.80% * 100;
 Minibatch[ 101- 200]: loss = 0.591689 * 100, metric = 9.78% * 100;
 Minibatch[ 201- 300]: loss = 0.580652 * 100, metric = 9.36% * 100;
 Minibatch[ 301- 400]: loss = 0.595332 * 100, metric = 9.96% * 100;
 Minibatch[ 401- 500]: loss = 0.579600 * 100, metric = 9.67% * 100;
 Minibatch[ 501- 600]: loss = 0.577062 * 100, metric = 9.46% * 100;
 Minibatch[ 601- 700]: loss = 0.572162 * 100, metric = 9.39% * 100;
 Minibatch[ 701- 800]: loss = 0.564401 * 100, metric = 9.25% * 100;
 Minibatch[ 801- 900]: loss = 0.564443 * 100, metric = 9.14% * 100;
 Minibatch[ 901-1000]: loss = 0.578160 * 100, metric = 9.63% * 100;
 Minibatch[1001-1100]: loss = 0.546586 * 100, metric = 8.78% * 100;
 Minibatch[1101-1200]: loss = 0.573934 * 100, metric = 9.39% * 100;
 Minibatch[1201-1300]: loss = 0.566572 * 100, metric = 9.29% * 100;
 Minibatch[1301-1400]: loss = 0.561309 * 100, metric = 8.98% * 100;
 Minibatch[1401-1500]: loss = 0.581598 * 100, metric = 9.73% * 100;
 Minibatch[1501-1600]: loss = 0.570388 * 100, metric = 9.10% * 100;
 Minibatch[1601-1700]: loss = 0.575183 * 100, metric = 9.43% * 100;
 Minibatch[1701-1800]: loss = 0.553023 * 100, metric = 8.68% * 100;
 Minibatch[1801-1900]: loss = 0.558842 * 100, metric = 8.86% * 100;
 Minibatch[1901-2000]: loss = 0.564468 * 100, metric = 9.10% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.570550 * 2000, metric = 9.29% * 2000 1008.399s (  2.0 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 14.78% * 2000;
0.612688892789185
 Minibatch[   1- 100]: loss = 0.569842 * 100, metric = 9.47% * 100;
 Minibatch[ 101- 200]: loss = 0.538011 * 100, metric = 8.71% * 100;
 Minibatch[ 201- 300]: loss = 0.562072 * 100, metric = 8.85% * 100;
 Minibatch[ 301- 400]: loss = 0.554389 * 100, metric = 8.74% * 100;
 Minibatch[ 401- 500]: loss = 0.566771 * 100, metric = 9.17% * 100;
 Minibatch[ 501- 600]: loss = 0.547673 * 100, metric = 8.72% * 100;
 Minibatch[ 601- 700]: loss = 0.542503 * 100, metric = 8.46% * 100;
 Minibatch[ 701- 800]: loss = 0.538828 * 100, metric = 8.24% * 100;
 Minibatch[ 801- 900]: loss = 0.553178 * 100, metric = 8.73% * 100;
 Minibatch[ 901-1000]: loss = 0.551788 * 100, metric = 8.77% * 100;
 Minibatch[1001-1100]: loss = 0.555524 * 100, metric = 9.08% * 100;
 Minibatch[1101-1200]: loss = 0.551821 * 100, metric = 8.98% * 100;
 Minibatch[1201-1300]: loss = 0.559117 * 100, metric = 9.06% * 100;
 Minibatch[1301-1400]: loss = 0.557124 * 100, metric = 9.13% * 100;
 Minibatch[1401-1500]: loss = 0.543173 * 100, metric = 8.70% * 100;
 Minibatch[1501-1600]: loss = 0.546265 * 100, metric = 8.99% * 100;
 Minibatch[1601-1700]: loss = 0.548585 * 100, metric = 8.73% * 100;
 Minibatch[1701-1800]: loss = 0.556155 * 100, metric = 8.79% * 100;
 Minibatch[1801-1900]: loss = 0.567851 * 100, metric = 9.06% * 100;
 Minibatch[1901-2000]: loss = 0.545040 * 100, metric = 8.76% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.552786 * 2000, metric = 8.86% * 2000 1010.069s (  2.0 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 14.62% * 2000;
0.6118619484826923
 Minibatch[   1- 100]: loss = 0.536265 * 100, metric = 8.46% * 100;
 Minibatch[ 101- 200]: loss = 0.553250 * 100, metric = 8.86% * 100;
 Minibatch[ 201- 300]: loss = 0.554114 * 100, metric = 9.07% * 100;
 Minibatch[ 301- 400]: loss = 0.545936 * 100, metric = 8.67% * 100;
 Minibatch[ 401- 500]: loss = 0.545786 * 100, metric = 8.74% * 100;
 Minibatch[ 501- 600]: loss = 0.549450 * 100, metric = 8.77% * 100;
 Minibatch[ 601- 700]: loss = 0.536889 * 100, metric = 8.61% * 100;
 Minibatch[ 701- 800]: loss = 0.554178 * 100, metric = 8.90% * 100;
 Minibatch[ 801- 900]: loss = 0.546510 * 100, metric = 8.78% * 100;
 Minibatch[ 901-1000]: loss = 0.550864 * 100, metric = 8.89% * 100;
 Minibatch[1001-1100]: loss = 0.553991 * 100, metric = 8.82% * 100;
 Minibatch[1101-1200]: loss = 0.556517 * 100, metric = 8.92% * 100;
 Minibatch[1201-1300]: loss = 0.535127 * 100, metric = 8.64% * 100;
 Minibatch[1301-1400]: loss = 0.530446 * 100, metric = 8.63% * 100;
 Minibatch[1401-1500]: loss = 0.545778 * 100, metric = 8.83% * 100;
 Minibatch[1501-1600]: loss = 0.531580 * 100, metric = 8.28% * 100;
 Minibatch[1601-1700]: loss = 0.540428 * 100, metric = 8.56% * 100;
 Minibatch[1701-1800]: loss = 0.562839 * 100, metric = 9.21% * 100;
 Minibatch[1801-1900]: loss = 0.538508 * 100, metric = 8.44% * 100;
 Minibatch[1901-2000]: loss = 0.536340 * 100, metric = 8.72% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.545240 * 2000, metric = 8.74% * 2000 1015.512s (  2.0 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 14.78% * 2000;
 Minibatch[   1- 100]: loss = 0.512113 * 100, metric = 7.92% * 100;
 Minibatch[ 101- 200]: loss = 0.527305 * 100, metric = 8.00% * 100;
 Minibatch[ 201- 300]: loss = 0.523607 * 100, metric = 8.25% * 100;
 Minibatch[ 301- 400]: loss = 0.553968 * 100, metric = 9.02% * 100;
 Minibatch[ 401- 500]: loss = 0.536831 * 100, metric = 8.58% * 100;
 Minibatch[ 501- 600]: loss = 0.526880 * 100, metric = 8.24% * 100;
 Minibatch[ 601- 700]: loss = 0.527435 * 100, metric = 8.40% * 100;
 Minibatch[ 701- 800]: loss = 0.534574 * 100, metric = 8.38% * 100;
 Minibatch[ 801- 900]: loss = 0.526621 * 100, metric = 8.15% * 100;
 Minibatch[ 901-1000]: loss = 0.535808 * 100, metric = 8.66% * 100;
 Minibatch[1001-1100]: loss = 0.542349 * 100, metric = 8.67% * 100;
 Minibatch[1101-1200]: loss = 0.542968 * 100, metric = 8.56% * 100;
 Minibatch[1201-1300]: loss = 0.551735 * 100, metric = 9.00% * 100;
 Minibatch[1301-1400]: loss = 0.529799 * 100, metric = 8.29% * 100;
 Minibatch[1401-1500]: loss = 0.547458 * 100, metric = 8.85% * 100;
 Minibatch[1501-1600]: loss = 0.505164 * 100, metric = 7.99% * 100;
 Minibatch[1601-1700]: loss = 0.539991 * 100, metric = 8.66% * 100;
 Minibatch[1701-1800]: loss = 0.528802 * 100, metric = 8.21% * 100;
 Minibatch[1801-1900]: loss = 0.520817 * 100, metric = 8.28% * 100;
 Minibatch[1901-2000]: loss = 0.547973 * 100, metric = 8.83% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.533110 * 2000, metric = 8.45% * 2000 1010.594s (  2.0 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 15.46% * 2000;
 Minibatch[   1- 100]: loss = 0.541635 * 100, metric = 8.58% * 100;
 Minibatch[ 101- 200]: loss = 0.538929 * 100, metric = 8.76% * 100;
 Minibatch[ 201- 300]: loss = 0.517793 * 100, metric = 8.44% * 100;
 Minibatch[ 301- 400]: loss = 0.531786 * 100, metric = 8.43% * 100;
 Minibatch[ 401- 500]: loss = 0.539013 * 100, metric = 8.96% * 100;
 Minibatch[ 501- 600]: loss = 0.550360 * 100, metric = 9.14% * 100;
 Minibatch[ 601- 700]: loss = 0.519259 * 100, metric = 8.05% * 100;
 Minibatch[ 701- 800]: loss = 0.518898 * 100, metric = 8.11% * 100;
 Minibatch[ 801- 900]: loss = 0.514042 * 100, metric = 7.98% * 100;
 Minibatch[ 901-1000]: loss = 0.523857 * 100, metric = 8.26% * 100;
 Minibatch[1001-1100]: loss = 0.536766 * 100, metric = 8.68% * 100;
 Minibatch[1101-1200]: loss = 0.529810 * 100, metric = 8.25% * 100;
 Minibatch[1201-1300]: loss = 0.531340 * 100, metric = 8.54% * 100;
 Minibatch[1301-1400]: loss = 0.522568 * 100, metric = 8.20% * 100;
 Minibatch[1401-1500]: loss = 0.524260 * 100, metric = 8.38% * 100;
 Minibatch[1501-1600]: loss = 0.513209 * 100, metric = 8.15% * 100;
 Minibatch[1601-1700]: loss = 0.514378 * 100, metric = 8.21% * 100;
 Minibatch[1701-1800]: loss = 0.520828 * 100, metric = 8.16% * 100;
 Minibatch[1801-1900]: loss = 0.518630 * 100, metric = 8.01% * 100;
 Minibatch[1901-2000]: loss = 0.530101 * 100, metric = 8.34% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.526873 * 2000, metric = 8.38% * 2000 1002.376s (  2.0 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 17.60% * 2000;
 Minibatch[   1- 100]: loss = 0.515770 * 100, metric = 8.17% * 100;
 Minibatch[ 101- 200]: loss = 0.505754 * 100, metric = 7.96% * 100;
 Minibatch[ 201- 300]: loss = 0.530853 * 100, metric = 8.64% * 100;
 Minibatch[ 301- 400]: loss = 0.514537 * 100, metric = 8.14% * 100;
 Minibatch[ 401- 500]: loss = 0.512027 * 100, metric = 8.12% * 100;
 Minibatch[ 501- 600]: loss = 0.523705 * 100, metric = 8.41% * 100;
 Minibatch[ 601- 700]: loss = 0.512089 * 100, metric = 8.13% * 100;
 Minibatch[ 701- 800]: loss = 0.530174 * 100, metric = 8.51% * 100;
 Minibatch[ 801- 900]: loss = 0.521704 * 100, metric = 8.49% * 100;
 Minibatch[ 901-1000]: loss = 0.524894 * 100, metric = 8.42% * 100;
 Minibatch[1001-1100]: loss = 0.514537 * 100, metric = 8.08% * 100;
 Minibatch[1101-1200]: loss = 0.513940 * 100, metric = 7.91% * 100;
 Minibatch[1201-1300]: loss = 0.491984 * 100, metric = 7.48% * 100;
 Minibatch[1301-1400]: loss = 0.522421 * 100, metric = 8.27% * 100;
 Minibatch[1401-1500]: loss = 0.519200 * 100, metric = 8.25% * 100;
 Minibatch[1501-1600]: loss = 0.502755 * 100, metric = 7.87% * 100;
 Minibatch[1601-1700]: loss = 0.508033 * 100, metric = 7.63% * 100;
 Minibatch[1701-1800]: loss = 0.504536 * 100, metric = 7.88% * 100;
 Minibatch[1801-1900]: loss = 0.506407 * 100, metric = 7.87% * 100;
 Minibatch[1901-2000]: loss = 0.516090 * 100, metric = 7.73% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.514571 * 2000, metric = 8.10% * 2000 1001.623s (  2.0 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 16.43% * 2000;
 Minibatch[   1- 100]: loss = 0.501816 * 100, metric = 7.75% * 100;
 Minibatch[ 101- 200]: loss = 0.520251 * 100, metric = 8.27% * 100;
 Minibatch[ 201- 300]: loss = 0.514090 * 100, metric = 7.99% * 100;
 Minibatch[ 301- 400]: loss = 0.498080 * 100, metric = 7.70% * 100;
 Minibatch[ 401- 500]: loss = 0.508779 * 100, metric = 8.06% * 100;
 Minibatch[ 501- 600]: loss = 0.496096 * 100, metric = 7.59% * 100;
 Minibatch[ 601- 700]: loss = 0.481389 * 100, metric = 7.37% * 100;
 Minibatch[ 701- 800]: loss = 0.512776 * 100, metric = 8.00% * 100;
 Minibatch[ 801- 900]: loss = 0.523904 * 100, metric = 8.65% * 100;
 Minibatch[ 901-1000]: loss = 0.502871 * 100, metric = 7.60% * 100;
 Minibatch[1001-1100]: loss = 0.518768 * 100, metric = 8.09% * 100;
 Minibatch[1101-1200]: loss = 0.508818 * 100, metric = 7.83% * 100;
 Minibatch[1201-1300]: loss = 0.497955 * 100, metric = 7.62% * 100;
 Minibatch[1301-1400]: loss = 0.526992 * 100, metric = 8.54% * 100;
 Minibatch[1401-1500]: loss = 0.484564 * 100, metric = 7.35% * 100;
 Minibatch[1501-1600]: loss = 0.492311 * 100, metric = 7.57% * 100;
 Minibatch[1601-1700]: loss = 0.512742 * 100, metric = 7.97% * 100;
 Minibatch[1701-1800]: loss = 0.486392 * 100, metric = 7.39% * 100;
 Minibatch[1801-1900]: loss = 0.499067 * 100, metric = 7.84% * 100;
 Minibatch[1901-2000]: loss = 0.500189 * 100, metric = 7.74% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.504392 * 2000, metric = 7.85% * 2000 1010.262s (  2.0 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 13.95% * 2000;
0.6031227282658219
 Minibatch[   1- 100]: loss = 0.518844 * 100, metric = 8.22% * 100;
 Minibatch[ 101- 200]: loss = 0.499111 * 100, metric = 7.58% * 100;
 Minibatch[ 201- 300]: loss = 0.512428 * 100, metric = 8.02% * 100;
 Minibatch[ 301- 400]: loss = 0.501803 * 100, metric = 7.79% * 100;
 Minibatch[ 401- 500]: loss = 0.480340 * 100, metric = 7.30% * 100;
 Minibatch[ 501- 600]: loss = 0.498064 * 100, metric = 7.66% * 100;
 Minibatch[ 601- 700]: loss = 0.503587 * 100, metric = 7.68% * 100;
 Minibatch[ 701- 800]: loss = 0.493237 * 100, metric = 7.51% * 100;
 Minibatch[ 801- 900]: loss = 0.488373 * 100, metric = 7.43% * 100;
 Minibatch[ 901-1000]: loss = 0.498791 * 100, metric = 7.90% * 100;
 Minibatch[1001-1100]: loss = 0.483668 * 100, metric = 7.40% * 100;
 Minibatch[1101-1200]: loss = 0.478346 * 100, metric = 7.33% * 100;
 Minibatch[1201-1300]: loss = 0.472011 * 100, metric = 6.95% * 100;
 Minibatch[1301-1400]: loss = 0.485115 * 100, metric = 7.46% * 100;
 Minibatch[1401-1500]: loss = 0.491436 * 100, metric = 7.58% * 100;
 Minibatch[1501-1600]: loss = 0.488238 * 100, metric = 7.38% * 100;
 Minibatch[1601-1700]: loss = 0.489988 * 100, metric = 7.46% * 100;
 Minibatch[1701-1800]: loss = 0.500271 * 100, metric = 7.69% * 100;
 Minibatch[1801-1900]: loss = 0.494324 * 100, metric = 7.71% * 100;
 Minibatch[1901-2000]: loss = 0.480376 * 100, metric = 7.39% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.492918 * 2000, metric = 7.57% * 2000 1008.874s (  2.0 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 15.65% * 2000;
 Minibatch[   1- 100]: loss = 0.472576 * 100, metric = 7.05% * 100;
 Minibatch[ 101- 200]: loss = 0.496421 * 100, metric = 7.54% * 100;
 Minibatch[ 201- 300]: loss = 0.489705 * 100, metric = 7.58% * 100;
 Minibatch[ 301- 400]: loss = 0.489713 * 100, metric = 7.50% * 100;
 Minibatch[ 401- 500]: loss = 0.492084 * 100, metric = 7.33% * 100;
 Minibatch[ 501- 600]: loss = 0.481931 * 100, metric = 7.22% * 100;
 Minibatch[ 601- 700]: loss = 0.467897 * 100, metric = 6.85% * 100;
 Minibatch[ 701- 800]: loss = 0.480640 * 100, metric = 7.20% * 100;
 Minibatch[ 801- 900]: loss = 0.483046 * 100, metric = 7.27% * 100;
 Minibatch[ 901-1000]: loss = 0.474580 * 100, metric = 7.19% * 100;
 Minibatch[1001-1100]: loss = 0.477181 * 100, metric = 7.30% * 100;
 Minibatch[1101-1200]: loss = 0.497011 * 100, metric = 7.75% * 100;
 Minibatch[1201-1300]: loss = 0.488777 * 100, metric = 7.37% * 100;
 Minibatch[1301-1400]: loss = 0.466440 * 100, metric = 7.02% * 100;
 Minibatch[1401-1500]: loss = 0.488826 * 100, metric = 7.73% * 100;
 Minibatch[1501-1600]: loss = 0.487580 * 100, metric = 7.48% * 100;
 Minibatch[1601-1700]: loss = 0.490505 * 100, metric = 7.59% * 100;
 Minibatch[1701-1800]: loss = 0.475020 * 100, metric = 7.20% * 100;
 Minibatch[1801-1900]: loss = 0.502293 * 100, metric = 7.91% * 100;
 Minibatch[1901-2000]: loss = 0.506956 * 100, metric = 7.92% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.485459 * 2000, metric = 7.40% * 2000 1006.583s (  2.0 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.21% * 2000;
 Minibatch[   1- 100]: loss = 0.471664 * 100, metric = 6.92% * 100;
 Minibatch[ 101- 200]: loss = 0.496226 * 100, metric = 7.72% * 100;
 Minibatch[ 201- 300]: loss = 0.475648 * 100, metric = 7.34% * 100;
 Minibatch[ 301- 400]: loss = 0.484591 * 100, metric = 7.36% * 100;
 Minibatch[ 401- 500]: loss = 0.469836 * 100, metric = 7.08% * 100;
 Minibatch[ 501- 600]: loss = 0.477263 * 100, metric = 7.38% * 100;
 Minibatch[ 601- 700]: loss = 0.487255 * 100, metric = 7.67% * 100;
 Minibatch[ 701- 800]: loss = 0.474113 * 100, metric = 7.40% * 100;
 Minibatch[ 801- 900]: loss = 0.490573 * 100, metric = 7.53% * 100;
 Minibatch[ 901-1000]: loss = 0.494709 * 100, metric = 7.69% * 100;
 Minibatch[1001-1100]: loss = 0.503438 * 100, metric = 7.98% * 100;
 Minibatch[1101-1200]: loss = 0.484216 * 100, metric = 7.51% * 100;
 Minibatch[1201-1300]: loss = 0.492930 * 100, metric = 7.63% * 100;
 Minibatch[1301-1400]: loss = 0.491410 * 100, metric = 7.61% * 100;
 Minibatch[1401-1500]: loss = 0.466574 * 100, metric = 6.97% * 100;
 Minibatch[1501-1600]: loss = 0.481775 * 100, metric = 7.19% * 100;
 Minibatch[1601-1700]: loss = 0.453457 * 100, metric = 6.68% * 100;
 Minibatch[1701-1800]: loss = 0.473579 * 100, metric = 7.10% * 100;
 Minibatch[1801-1900]: loss = 0.466527 * 100, metric = 7.17% * 100;
 Minibatch[1901-2000]: loss = 0.480300 * 100, metric = 7.12% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.480804 * 2000, metric = 7.35% * 2000 995.330s (  2.0 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.47% * 2000;
 Minibatch[   1- 100]: loss = 0.499020 * 100, metric = 7.92% * 100;
 Minibatch[ 101- 200]: loss = 0.499963 * 100, metric = 7.83% * 100;
 Minibatch[ 201- 300]: loss = 0.482681 * 100, metric = 7.14% * 100;
 Minibatch[ 301- 400]: loss = 0.485155 * 100, metric = 7.22% * 100;
 Minibatch[ 401- 500]: loss = 0.482582 * 100, metric = 7.23% * 100;
 Minibatch[ 501- 600]: loss = 0.482664 * 100, metric = 7.21% * 100;
 Minibatch[ 601- 700]: loss = 0.494842 * 100, metric = 7.63% * 100;
 Minibatch[ 701- 800]: loss = 0.475025 * 100, metric = 7.24% * 100;
 Minibatch[ 801- 900]: loss = 0.502560 * 100, metric = 7.92% * 100;
 Minibatch[ 901-1000]: loss = 0.471887 * 100, metric = 7.07% * 100;
 Minibatch[1001-1100]: loss = 0.489895 * 100, metric = 7.62% * 100;
 Minibatch[1101-1200]: loss = 0.483497 * 100, metric = 7.45% * 100;
 Minibatch[1201-1300]: loss = 0.477283 * 100, metric = 7.10% * 100;
 Minibatch[1301-1400]: loss = 0.470662 * 100, metric = 7.22% * 100;
 Minibatch[1401-1500]: loss = 0.490209 * 100, metric = 7.49% * 100;
 Minibatch[1501-1600]: loss = 0.484110 * 100, metric = 7.40% * 100;
 Minibatch[1601-1700]: loss = 0.463476 * 100, metric = 7.11% * 100;
 Minibatch[1701-1800]: loss = 0.459755 * 100, metric = 6.90% * 100;
 Minibatch[1801-1900]: loss = 0.471460 * 100, metric = 6.96% * 100;
 Minibatch[1901-2000]: loss = 0.460767 * 100, metric = 6.72% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.481375 * 2000, metric = 7.32% * 2000 999.400s (  2.0 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 15.37% * 2000;
 Minibatch[   1- 100]: loss = 0.481032 * 100, metric = 7.13% * 100;
 Minibatch[ 101- 200]: loss = 0.476095 * 100, metric = 7.19% * 100;
 Minibatch[ 201- 300]: loss = 0.477392 * 100, metric = 7.01% * 100;
 Minibatch[ 301- 400]: loss = 0.490929 * 100, metric = 7.34% * 100;
 Minibatch[ 401- 500]: loss = 0.480138 * 100, metric = 7.23% * 100;
 Minibatch[ 501- 600]: loss = 0.483299 * 100, metric = 7.48% * 100;
 Minibatch[ 601- 700]: loss = 0.491576 * 100, metric = 7.54% * 100;
 Minibatch[ 701- 800]: loss = 0.469178 * 100, metric = 7.14% * 100;
 Minibatch[ 801- 900]: loss = 0.495027 * 100, metric = 7.71% * 100;
 Minibatch[ 901-1000]: loss = 0.479824 * 100, metric = 7.30% * 100;
 Minibatch[1001-1100]: loss = 0.457200 * 100, metric = 6.84% * 100;
 Minibatch[1101-1200]: loss = 0.480641 * 100, metric = 7.40% * 100;
 Minibatch[1201-1300]: loss = 0.485674 * 100, metric = 7.43% * 100;
 Minibatch[1301-1400]: loss = 0.485956 * 100, metric = 7.52% * 100;
 Minibatch[1401-1500]: loss = 0.461332 * 100, metric = 7.09% * 100;
 Minibatch[1501-1600]: loss = 0.479521 * 100, metric = 7.25% * 100;
 Minibatch[1601-1700]: loss = 0.467103 * 100, metric = 7.12% * 100;
 Minibatch[1701-1800]: loss = 0.478074 * 100, metric = 7.28% * 100;
 Minibatch[1801-1900]: loss = 0.467222 * 100, metric = 7.16% * 100;
 Minibatch[1901-2000]: loss = 0.470176 * 100, metric = 7.15% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.477870 * 2000, metric = 7.26% * 2000 990.141s (  2.0 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 14.27% * 2000;
 Minibatch[   1- 100]: loss = 0.469757 * 100, metric = 7.02% * 100;
 Minibatch[ 101- 200]: loss = 0.472848 * 100, metric = 7.21% * 100;
 Minibatch[ 201- 300]: loss = 0.468863 * 100, metric = 7.02% * 100;
 Minibatch[ 301- 400]: loss = 0.473188 * 100, metric = 7.29% * 100;
 Minibatch[ 401- 500]: loss = 0.457993 * 100, metric = 6.68% * 100;
 Minibatch[ 501- 600]: loss = 0.460274 * 100, metric = 6.82% * 100;
 Minibatch[ 601- 700]: loss = 0.454412 * 100, metric = 6.70% * 100;
 Minibatch[ 701- 800]: loss = 0.429989 * 100, metric = 6.21% * 100;
 Minibatch[ 801- 900]: loss = 0.460442 * 100, metric = 6.63% * 100;
 Minibatch[ 901-1000]: loss = 0.451462 * 100, metric = 6.66% * 100;
 Minibatch[1001-1100]: loss = 0.450379 * 100, metric = 6.62% * 100;
 Minibatch[1101-1200]: loss = 0.436879 * 100, metric = 6.34% * 100;
 Minibatch[1201-1300]: loss = 0.447908 * 100, metric = 6.42% * 100;
 Minibatch[1301-1400]: loss = 0.438312 * 100, metric = 6.37% * 100;
 Minibatch[1401-1500]: loss = 0.453588 * 100, metric = 6.65% * 100;
 Minibatch[1501-1600]: loss = 0.470932 * 100, metric = 7.38% * 100;
 Minibatch[1601-1700]: loss = 0.447657 * 100, metric = 6.55% * 100;
 Minibatch[1701-1800]: loss = 0.452805 * 100, metric = 6.54% * 100;
 Minibatch[1801-1900]: loss = 0.473669 * 100, metric = 7.21% * 100;
 Minibatch[1901-2000]: loss = 0.438884 * 100, metric = 6.32% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.455512 * 2000, metric = 6.73% * 2000 992.488s (  2.0 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 13.42% * 2000;
 Minibatch[   1- 100]: loss = 0.465152 * 100, metric = 6.81% * 100;
 Minibatch[ 101- 200]: loss = 0.459549 * 100, metric = 6.65% * 100;
 Minibatch[ 201- 300]: loss = 0.474994 * 100, metric = 7.08% * 100;
 Minibatch[ 301- 400]: loss = 0.458976 * 100, metric = 6.86% * 100;
 Minibatch[ 401- 500]: loss = 0.454509 * 100, metric = 6.57% * 100;
 Minibatch[ 501- 600]: loss = 0.469447 * 100, metric = 6.83% * 100;
 Minibatch[ 601- 700]: loss = 0.459994 * 100, metric = 6.64% * 100;
 Minibatch[ 701- 800]: loss = 0.457101 * 100, metric = 6.76% * 100;
 Minibatch[ 801- 900]: loss = 0.466645 * 100, metric = 6.95% * 100;
 Minibatch[ 901-1000]: loss = 0.478932 * 100, metric = 7.36% * 100;
 Minibatch[1001-1100]: loss = 0.449087 * 100, metric = 6.55% * 100;
 Minibatch[1101-1200]: loss = 0.435899 * 100, metric = 6.38% * 100;
 Minibatch[1201-1300]: loss = 0.462180 * 100, metric = 6.80% * 100;
 Minibatch[1301-1400]: loss = 0.457628 * 100, metric = 6.63% * 100;
 Minibatch[1401-1500]: loss = 0.446384 * 100, metric = 6.79% * 100;
 Minibatch[1501-1600]: loss = 0.437708 * 100, metric = 6.37% * 100;
 Minibatch[1601-1700]: loss = 0.446451 * 100, metric = 6.75% * 100;
 Minibatch[1701-1800]: loss = 0.449708 * 100, metric = 6.59% * 100;
 Minibatch[1801-1900]: loss = 0.447563 * 100, metric = 6.64% * 100;
 Minibatch[1901-2000]: loss = 0.453476 * 100, metric = 6.44% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.456569 * 2000, metric = 6.72% * 2000 959.985s (  2.1 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 14.27% * 2000;
 Minibatch[   1- 100]: loss = 0.460804 * 100, metric = 6.63% * 100;
 Minibatch[ 101- 200]: loss = 0.463876 * 100, metric = 6.88% * 100;
 Minibatch[ 201- 300]: loss = 0.444011 * 100, metric = 6.42% * 100;
 Minibatch[ 301- 400]: loss = 0.462633 * 100, metric = 6.87% * 100;
 Minibatch[ 401- 500]: loss = 0.467863 * 100, metric = 6.92% * 100;
 Minibatch[ 501- 600]: loss = 0.450819 * 100, metric = 6.66% * 100;
 Minibatch[ 601- 700]: loss = 0.455910 * 100, metric = 6.67% * 100;
 Minibatch[ 701- 800]: loss = 0.441630 * 100, metric = 6.58% * 100;
 Minibatch[ 801- 900]: loss = 0.436302 * 100, metric = 6.40% * 100;
 Minibatch[ 901-1000]: loss = 0.459128 * 100, metric = 6.58% * 100;
 Minibatch[1001-1100]: loss = 0.438799 * 100, metric = 6.27% * 100;
 Minibatch[1101-1200]: loss = 0.452832 * 100, metric = 6.87% * 100;
 Minibatch[1201-1300]: loss = 0.463522 * 100, metric = 6.93% * 100;
 Minibatch[1301-1400]: loss = 0.472038 * 100, metric = 7.17% * 100;
 Minibatch[1401-1500]: loss = 0.440902 * 100, metric = 6.49% * 100;
 Minibatch[1501-1600]: loss = 0.462302 * 100, metric = 6.85% * 100;
 Minibatch[1601-1700]: loss = 0.461736 * 100, metric = 6.78% * 100;
 Minibatch[1701-1800]: loss = 0.451971 * 100, metric = 6.81% * 100;
 Minibatch[1801-1900]: loss = 0.446809 * 100, metric = 6.74% * 100;
 Minibatch[1901-2000]: loss = 0.457507 * 100, metric = 6.71% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.454570 * 2000, metric = 6.71% * 2000 953.609s (  2.1 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 14.39% * 2000;
 Minibatch[   1- 100]: loss = 0.434801 * 100, metric = 6.34% * 100;
 Minibatch[ 101- 200]: loss = 0.456709 * 100, metric = 6.85% * 100;
 Minibatch[ 201- 300]: loss = 0.439105 * 100, metric = 6.50% * 100;
 Minibatch[ 301- 400]: loss = 0.447892 * 100, metric = 6.57% * 100;
 Minibatch[ 401- 500]: loss = 0.443829 * 100, metric = 6.58% * 100;
 Minibatch[ 501- 600]: loss = 0.437001 * 100, metric = 6.43% * 100;
 Minibatch[ 601- 700]: loss = 0.451658 * 100, metric = 6.41% * 100;
 Minibatch[ 701- 800]: loss = 0.439459 * 100, metric = 6.44% * 100;
 Minibatch[ 801- 900]: loss = 0.457478 * 100, metric = 6.86% * 100;
 Minibatch[ 901-1000]: loss = 0.445682 * 100, metric = 6.52% * 100;
 Minibatch[1001-1100]: loss = 0.445130 * 100, metric = 6.55% * 100;
 Minibatch[1101-1200]: loss = 0.459539 * 100, metric = 6.85% * 100;
 Minibatch[1201-1300]: loss = 0.442851 * 100, metric = 6.51% * 100;
 Minibatch[1301-1400]: loss = 0.438492 * 100, metric = 6.23% * 100;
 Minibatch[1401-1500]: loss = 0.438744 * 100, metric = 6.37% * 100;
 Minibatch[1501-1600]: loss = 0.445047 * 100, metric = 6.54% * 100;
 Minibatch[1601-1700]: loss = 0.433680 * 100, metric = 6.22% * 100;
 Minibatch[1701-1800]: loss = 0.438654 * 100, metric = 6.51% * 100;
 Minibatch[1801-1900]: loss = 0.445686 * 100, metric = 6.68% * 100;
 Minibatch[1901-2000]: loss = 0.456966 * 100, metric = 7.01% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.444920 * 2000, metric = 6.55% * 2000 958.371s (  2.1 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 15.00% * 2000;
 Minibatch[   1- 100]: loss = 0.447321 * 100, metric = 6.59% * 100;
 Minibatch[ 101- 200]: loss = 0.448327 * 100, metric = 6.82% * 100;
 Minibatch[ 201- 300]: loss = 0.448713 * 100, metric = 6.81% * 100;
 Minibatch[ 301- 400]: loss = 0.442957 * 100, metric = 6.53% * 100;
 Minibatch[ 401- 500]: loss = 0.442150 * 100, metric = 6.70% * 100;
 Minibatch[ 501- 600]: loss = 0.454603 * 100, metric = 6.89% * 100;
 Minibatch[ 601- 700]: loss = 0.449185 * 100, metric = 6.64% * 100;
 Minibatch[ 701- 800]: loss = 0.428037 * 100, metric = 6.09% * 100;
 Minibatch[ 801- 900]: loss = 0.427929 * 100, metric = 6.26% * 100;
 Minibatch[ 901-1000]: loss = 0.438853 * 100, metric = 6.43% * 100;
 Minibatch[1001-1100]: loss = 0.442738 * 100, metric = 6.64% * 100;
 Minibatch[1101-1200]: loss = 0.458954 * 100, metric = 6.88% * 100;
 Minibatch[1201-1300]: loss = 0.465686 * 100, metric = 7.26% * 100;
 Minibatch[1301-1400]: loss = 0.443871 * 100, metric = 6.54% * 100;
 Minibatch[1401-1500]: loss = 0.443472 * 100, metric = 6.46% * 100;
 Minibatch[1501-1600]: loss = 0.455084 * 100, metric = 7.01% * 100;
 Minibatch[1601-1700]: loss = 0.438055 * 100, metric = 6.54% * 100;
 Minibatch[1701-1800]: loss = 0.447977 * 100, metric = 6.64% * 100;
 Minibatch[1801-1900]: loss = 0.433919 * 100, metric = 6.38% * 100;
 Minibatch[1901-2000]: loss = 0.428002 * 100, metric = 6.30% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.444292 * 2000, metric = 6.62% * 2000 946.946s (  2.1 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 15.15% * 2000;
 Minibatch[   1- 100]: loss = 0.436258 * 100, metric = 6.41% * 100;
 Minibatch[ 101- 200]: loss = 0.422725 * 100, metric = 6.19% * 100;
 Minibatch[ 201- 300]: loss = 0.451350 * 100, metric = 6.86% * 100;
 Minibatch[ 301- 400]: loss = 0.437182 * 100, metric = 6.40% * 100;
 Minibatch[ 401- 500]: loss = 0.441009 * 100, metric = 6.71% * 100;
 Minibatch[ 501- 600]: loss = 0.434305 * 100, metric = 6.32% * 100;
 Minibatch[ 601- 700]: loss = 0.449143 * 100, metric = 6.60% * 100;
 Minibatch[ 701- 800]: loss = 0.442108 * 100, metric = 6.77% * 100;
 Minibatch[ 801- 900]: loss = 0.428547 * 100, metric = 6.37% * 100;
 Minibatch[ 901-1000]: loss = 0.427605 * 100, metric = 6.42% * 100;
 Minibatch[1001-1100]: loss = 0.451453 * 100, metric = 6.98% * 100;
 Minibatch[1101-1200]: loss = 0.454403 * 100, metric = 6.81% * 100;
 Minibatch[1201-1300]: loss = 0.439685 * 100, metric = 6.54% * 100;
 Minibatch[1301-1400]: loss = 0.434763 * 100, metric = 6.16% * 100;
 Minibatch[1401-1500]: loss = 0.437396 * 100, metric = 6.44% * 100;
 Minibatch[1501-1600]: loss = 0.435597 * 100, metric = 6.19% * 100;
 Minibatch[1601-1700]: loss = 0.454235 * 100, metric = 6.86% * 100;
 Minibatch[1701-1800]: loss = 0.444259 * 100, metric = 6.54% * 100;
 Minibatch[1801-1900]: loss = 0.428438 * 100, metric = 6.16% * 100;
 Minibatch[1901-2000]: loss = 0.435136 * 100, metric = 6.24% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.439280 * 2000, metric = 6.50% * 2000 945.872s (  2.1 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.88% * 2000;
 Minibatch[   1- 100]: loss = 0.427313 * 100, metric = 6.12% * 100;
 Minibatch[ 101- 200]: loss = 0.443875 * 100, metric = 6.63% * 100;
 Minibatch[ 201- 300]: loss = 0.428293 * 100, metric = 6.40% * 100;
 Minibatch[ 301- 400]: loss = 0.427132 * 100, metric = 6.23% * 100;
 Minibatch[ 401- 500]: loss = 0.430715 * 100, metric = 6.15% * 100;
 Minibatch[ 501- 600]: loss = 0.431267 * 100, metric = 6.37% * 100;
 Minibatch[ 601- 700]: loss = 0.425519 * 100, metric = 6.18% * 100;
 Minibatch[ 701- 800]: loss = 0.430447 * 100, metric = 6.28% * 100;
 Minibatch[ 801- 900]: loss = 0.444920 * 100, metric = 6.59% * 100;
 Minibatch[ 901-1000]: loss = 0.437009 * 100, metric = 6.80% * 100;
 Minibatch[1001-1100]: loss = 0.434066 * 100, metric = 6.30% * 100;
 Minibatch[1101-1200]: loss = 0.445367 * 100, metric = 6.44% * 100;
 Minibatch[1201-1300]: loss = 0.432111 * 100, metric = 6.39% * 100;
 Minibatch[1301-1400]: loss = 0.439102 * 100, metric = 6.61% * 100;
 Minibatch[1401-1500]: loss = 0.431828 * 100, metric = 6.42% * 100;
 Minibatch[1501-1600]: loss = 0.437518 * 100, metric = 6.47% * 100;
 Minibatch[1601-1700]: loss = 0.409222 * 100, metric = 5.84% * 100;
 Minibatch[1701-1800]: loss = 0.427272 * 100, metric = 6.13% * 100;
 Minibatch[1801-1900]: loss = 0.433840 * 100, metric = 6.47% * 100;
 Minibatch[1901-2000]: loss = 0.441531 * 100, metric = 6.61% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.432917 * 2000, metric = 6.37% * 2000 954.171s (  2.1 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.64% * 2000;
 Minibatch[   1- 100]: loss = 0.440810 * 100, metric = 6.70% * 100;
 Minibatch[ 101- 200]: loss = 0.423630 * 100, metric = 6.07% * 100;
 Minibatch[ 201- 300]: loss = 0.435201 * 100, metric = 6.47% * 100;
 Minibatch[ 301- 400]: loss = 0.436622 * 100, metric = 6.38% * 100;
 Minibatch[ 401- 500]: loss = 0.436816 * 100, metric = 6.62% * 100;
 Minibatch[ 501- 600]: loss = 0.448810 * 100, metric = 6.82% * 100;
 Minibatch[ 601- 700]: loss = 0.429689 * 100, metric = 6.18% * 100;
 Minibatch[ 701- 800]: loss = 0.420859 * 100, metric = 6.07% * 100;
 Minibatch[ 801- 900]: loss = 0.436918 * 100, metric = 6.50% * 100;
 Minibatch[ 901-1000]: loss = 0.432645 * 100, metric = 6.48% * 100;
 Minibatch[1001-1100]: loss = 0.431590 * 100, metric = 6.20% * 100;
 Minibatch[1101-1200]: loss = 0.426649 * 100, metric = 6.15% * 100;
 Minibatch[1201-1300]: loss = 0.433409 * 100, metric = 6.51% * 100;
 Minibatch[1301-1400]: loss = 0.429571 * 100, metric = 6.45% * 100;
 Minibatch[1401-1500]: loss = 0.443720 * 100, metric = 6.52% * 100;
 Minibatch[1501-1600]: loss = 0.418785 * 100, metric = 5.94% * 100;
 Minibatch[1601-1700]: loss = 0.431523 * 100, metric = 6.02% * 100;
 Minibatch[1701-1800]: loss = 0.433061 * 100, metric = 6.16% * 100;
 Minibatch[1801-1900]: loss = 0.434440 * 100, metric = 6.47% * 100;
 Minibatch[1901-2000]: loss = 0.439487 * 100, metric = 6.31% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.433212 * 2000, metric = 6.35% * 2000 953.479s (  2.1 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.29% * 2000;
 Minibatch[   1- 100]: loss = 0.423424 * 100, metric = 6.00% * 100;
 Minibatch[ 101- 200]: loss = 0.417514 * 100, metric = 6.13% * 100;
 Minibatch[ 201- 300]: loss = 0.425634 * 100, metric = 6.19% * 100;
 Minibatch[ 301- 400]: loss = 0.457248 * 100, metric = 6.90% * 100;
 Minibatch[ 401- 500]: loss = 0.420542 * 100, metric = 5.94% * 100;
 Minibatch[ 501- 600]: loss = 0.436048 * 100, metric = 6.31% * 100;
 Minibatch[ 601- 700]: loss = 0.429293 * 100, metric = 6.46% * 100;
 Minibatch[ 701- 800]: loss = 0.430895 * 100, metric = 6.37% * 100;
 Minibatch[ 801- 900]: loss = 0.426501 * 100, metric = 6.24% * 100;
 Minibatch[ 901-1000]: loss = 0.435696 * 100, metric = 6.44% * 100;
 Minibatch[1001-1100]: loss = 0.428708 * 100, metric = 6.35% * 100;
 Minibatch[1101-1200]: loss = 0.417036 * 100, metric = 5.99% * 100;
 Minibatch[1201-1300]: loss = 0.428160 * 100, metric = 6.28% * 100;
 Minibatch[1301-1400]: loss = 0.417525 * 100, metric = 6.00% * 100;
 Minibatch[1401-1500]: loss = 0.436191 * 100, metric = 6.37% * 100;
 Minibatch[1501-1600]: loss = 0.409415 * 100, metric = 5.85% * 100;
 Minibatch[1601-1700]: loss = 0.429319 * 100, metric = 6.24% * 100;
 Minibatch[1701-1800]: loss = 0.408365 * 100, metric = 5.72% * 100;
 Minibatch[1801-1900]: loss = 0.434601 * 100, metric = 6.13% * 100;
 Minibatch[1901-2000]: loss = 0.420583 * 100, metric = 5.96% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.426635 * 2000, metric = 6.19% * 2000 951.761s (  2.1 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 14.61% * 2000;
 Minibatch[   1- 100]: loss = 0.443264 * 100, metric = 6.37% * 100;
 Minibatch[ 101- 200]: loss = 0.403252 * 100, metric = 5.48% * 100;
 Minibatch[ 201- 300]: loss = 0.413402 * 100, metric = 5.73% * 100;
 Minibatch[ 301- 400]: loss = 0.416796 * 100, metric = 5.99% * 100;
 Minibatch[ 401- 500]: loss = 0.421266 * 100, metric = 5.93% * 100;
 Minibatch[ 501- 600]: loss = 0.409153 * 100, metric = 5.54% * 100;
 Minibatch[ 601- 700]: loss = 0.426979 * 100, metric = 6.26% * 100;
 Minibatch[ 701- 800]: loss = 0.415625 * 100, metric = 5.70% * 100;
 Minibatch[ 801- 900]: loss = 0.423016 * 100, metric = 5.95% * 100;
 Minibatch[ 901-1000]: loss = 0.403538 * 100, metric = 5.75% * 100;
 Minibatch[1001-1100]: loss = 0.417241 * 100, metric = 5.88% * 100;
 Minibatch[1101-1200]: loss = 0.430171 * 100, metric = 6.12% * 100;
 Minibatch[1201-1300]: loss = 0.411811 * 100, metric = 5.94% * 100;
 Minibatch[1301-1400]: loss = 0.420231 * 100, metric = 6.11% * 100;
 Minibatch[1401-1500]: loss = 0.416664 * 100, metric = 5.91% * 100;
 Minibatch[1501-1600]: loss = 0.431275 * 100, metric = 6.06% * 100;
 Minibatch[1601-1700]: loss = 0.423389 * 100, metric = 6.06% * 100;
 Minibatch[1701-1800]: loss = 0.422570 * 100, metric = 6.07% * 100;
 Minibatch[1801-1900]: loss = 0.420550 * 100, metric = 6.05% * 100;
 Minibatch[1901-2000]: loss = 0.437106 * 100, metric = 6.44% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.420365 * 2000, metric = 5.97% * 2000 946.003s (  2.1 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 15.29% * 2000;
 Minibatch[   1- 100]: loss = 0.417228 * 100, metric = 5.85% * 100;
 Minibatch[ 101- 200]: loss = 0.426619 * 100, metric = 6.32% * 100;
 Minibatch[ 201- 300]: loss = 0.416818 * 100, metric = 6.11% * 100;
 Minibatch[ 301- 400]: loss = 0.422258 * 100, metric = 6.01% * 100;
 Minibatch[ 401- 500]: loss = 0.417475 * 100, metric = 6.04% * 100;
 Minibatch[ 501- 600]: loss = 0.413573 * 100, metric = 6.16% * 100;
 Minibatch[ 601- 700]: loss = 0.431370 * 100, metric = 6.27% * 100;
 Minibatch[ 701- 800]: loss = 0.434406 * 100, metric = 6.22% * 100;
 Minibatch[ 801- 900]: loss = 0.425567 * 100, metric = 5.85% * 100;
 Minibatch[ 901-1000]: loss = 0.414474 * 100, metric = 5.88% * 100;
 Minibatch[1001-1100]: loss = 0.412713 * 100, metric = 5.82% * 100;
 Minibatch[1101-1200]: loss = 0.426122 * 100, metric = 6.18% * 100;
 Minibatch[1201-1300]: loss = 0.411655 * 100, metric = 5.79% * 100;
 Minibatch[1301-1400]: loss = 0.418012 * 100, metric = 5.82% * 100;
 Minibatch[1401-1500]: loss = 0.422437 * 100, metric = 5.95% * 100;
 Minibatch[1501-1600]: loss = 0.412037 * 100, metric = 6.02% * 100;
 Minibatch[1601-1700]: loss = 0.424001 * 100, metric = 6.04% * 100;
 Minibatch[1701-1800]: loss = 0.408752 * 100, metric = 5.80% * 100;
 Minibatch[1801-1900]: loss = 0.420092 * 100, metric = 6.05% * 100;
 Minibatch[1901-2000]: loss = 0.419008 * 100, metric = 5.99% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.419731 * 2000, metric = 6.01% * 2000 954.568s (  2.1 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 14.88% * 2000;
 Minibatch[   1- 100]: loss = 0.419763 * 100, metric = 6.10% * 100;
 Minibatch[ 101- 200]: loss = 0.413180 * 100, metric = 5.79% * 100;
 Minibatch[ 201- 300]: loss = 0.420210 * 100, metric = 5.83% * 100;
 Minibatch[ 301- 400]: loss = 0.424776 * 100, metric = 5.96% * 100;
 Minibatch[ 401- 500]: loss = 0.414229 * 100, metric = 6.04% * 100;
 Minibatch[ 501- 600]: loss = 0.409677 * 100, metric = 5.78% * 100;
 Minibatch[ 601- 700]: loss = 0.406209 * 100, metric = 5.78% * 100;
 Minibatch[ 701- 800]: loss = 0.406821 * 100, metric = 5.56% * 100;
 Minibatch[ 801- 900]: loss = 0.410510 * 100, metric = 5.90% * 100;
 Minibatch[ 901-1000]: loss = 0.401227 * 100, metric = 5.52% * 100;
 Minibatch[1001-1100]: loss = 0.412058 * 100, metric = 5.58% * 100;
 Minibatch[1101-1200]: loss = 0.418762 * 100, metric = 6.08% * 100;
 Minibatch[1201-1300]: loss = 0.427920 * 100, metric = 6.11% * 100;
 Minibatch[1301-1400]: loss = 0.412014 * 100, metric = 6.02% * 100;
 Minibatch[1401-1500]: loss = 0.406952 * 100, metric = 6.17% * 100;
 Minibatch[1501-1600]: loss = 0.417929 * 100, metric = 5.96% * 100;
 Minibatch[1601-1700]: loss = 0.401949 * 100, metric = 5.56% * 100;
 Minibatch[1701-1800]: loss = 0.422978 * 100, metric = 6.09% * 100;
 Minibatch[1801-1900]: loss = 0.401761 * 100, metric = 5.53% * 100;
 Minibatch[1901-2000]: loss = 0.424586 * 100, metric = 6.34% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.413676 * 2000, metric = 5.88% * 2000 950.689s (  2.1 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.83% * 2000;
 Minibatch[   1- 100]: loss = 0.432602 * 100, metric = 6.48% * 100;
 Minibatch[ 101- 200]: loss = 0.406751 * 100, metric = 5.78% * 100;
 Minibatch[ 201- 300]: loss = 0.409743 * 100, metric = 6.02% * 100;
 Minibatch[ 301- 400]: loss = 0.414422 * 100, metric = 6.07% * 100;
 Minibatch[ 401- 500]: loss = 0.409781 * 100, metric = 5.89% * 100;
 Minibatch[ 501- 600]: loss = 0.415178 * 100, metric = 5.79% * 100;
 Minibatch[ 601- 700]: loss = 0.423649 * 100, metric = 6.06% * 100;
 Minibatch[ 701- 800]: loss = 0.419551 * 100, metric = 6.07% * 100;
 Minibatch[ 801- 900]: loss = 0.410751 * 100, metric = 5.92% * 100;
 Minibatch[ 901-1000]: loss = 0.403866 * 100, metric = 5.76% * 100;
 Minibatch[1001-1100]: loss = 0.409497 * 100, metric = 5.97% * 100;
 Minibatch[1101-1200]: loss = 0.396531 * 100, metric = 5.68% * 100;
 Minibatch[1201-1300]: loss = 0.418809 * 100, metric = 5.94% * 100;
 Minibatch[1301-1400]: loss = 0.404372 * 100, metric = 5.64% * 100;
 Minibatch[1401-1500]: loss = 0.427564 * 100, metric = 6.21% * 100;
 Minibatch[1501-1600]: loss = 0.429637 * 100, metric = 6.08% * 100;
 Minibatch[1601-1700]: loss = 0.412869 * 100, metric = 5.60% * 100;
 Minibatch[1701-1800]: loss = 0.412981 * 100, metric = 5.55% * 100;
 Minibatch[1801-1900]: loss = 0.411708 * 100, metric = 5.71% * 100;
 Minibatch[1901-2000]: loss = 0.419178 * 100, metric = 6.18% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.414472 * 2000, metric = 5.92% * 2000 929.491s (  2.2 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.80% * 2000;
 Minibatch[   1- 100]: loss = 0.403763 * 100, metric = 5.62% * 100;
 Minibatch[ 101- 200]: loss = 0.418573 * 100, metric = 5.93% * 100;
 Minibatch[ 201- 300]: loss = 0.408121 * 100, metric = 5.78% * 100;
 Minibatch[ 301- 400]: loss = 0.414707 * 100, metric = 5.93% * 100;
 Minibatch[ 401- 500]: loss = 0.401059 * 100, metric = 5.59% * 100;
 Minibatch[ 501- 600]: loss = 0.412495 * 100, metric = 5.99% * 100;
 Minibatch[ 601- 700]: loss = 0.414942 * 100, metric = 5.93% * 100;
 Minibatch[ 701- 800]: loss = 0.408295 * 100, metric = 5.66% * 100;
 Minibatch[ 801- 900]: loss = 0.390884 * 100, metric = 5.18% * 100;
 Minibatch[ 901-1000]: loss = 0.402780 * 100, metric = 5.79% * 100;
 Minibatch[1001-1100]: loss = 0.411118 * 100, metric = 5.92% * 100;
 Minibatch[1101-1200]: loss = 0.402546 * 100, metric = 5.64% * 100;
 Minibatch[1201-1300]: loss = 0.413302 * 100, metric = 5.92% * 100;
 Minibatch[1301-1400]: loss = 0.408676 * 100, metric = 5.88% * 100;
 Minibatch[1401-1500]: loss = 0.418699 * 100, metric = 5.92% * 100;
 Minibatch[1501-1600]: loss = 0.417807 * 100, metric = 5.95% * 100;
 Minibatch[1601-1700]: loss = 0.423881 * 100, metric = 6.13% * 100;
 Minibatch[1701-1800]: loss = 0.410037 * 100, metric = 5.68% * 100;
 Minibatch[1801-1900]: loss = 0.410904 * 100, metric = 5.79% * 100;
 Minibatch[1901-2000]: loss = 0.414210 * 100, metric = 5.80% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.410340 * 2000, metric = 5.80% * 2000 886.157s (  2.3 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 15.15% * 2000;
 Minibatch[   1- 100]: loss = 0.388467 * 100, metric = 5.23% * 100;
 Minibatch[ 101- 200]: loss = 0.407884 * 100, metric = 5.94% * 100;
 Minibatch[ 201- 300]: loss = 0.407323 * 100, metric = 5.74% * 100;
 Minibatch[ 301- 400]: loss = 0.397368 * 100, metric = 5.53% * 100;
 Minibatch[ 401- 500]: loss = 0.408178 * 100, metric = 5.74% * 100;
 Minibatch[ 501- 600]: loss = 0.386847 * 100, metric = 5.50% * 100;
 Minibatch[ 601- 700]: loss = 0.415771 * 100, metric = 5.99% * 100;
 Minibatch[ 701- 800]: loss = 0.390515 * 100, metric = 5.61% * 100;
 Minibatch[ 801- 900]: loss = 0.411427 * 100, metric = 5.86% * 100;
 Minibatch[ 901-1000]: loss = 0.396211 * 100, metric = 5.66% * 100;
 Minibatch[1001-1100]: loss = 0.417457 * 100, metric = 5.97% * 100;
 Minibatch[1101-1200]: loss = 0.405596 * 100, metric = 5.74% * 100;
 Minibatch[1201-1300]: loss = 0.405657 * 100, metric = 5.85% * 100;
 Minibatch[1301-1400]: loss = 0.410103 * 100, metric = 5.89% * 100;
 Minibatch[1401-1500]: loss = 0.402441 * 100, metric = 5.55% * 100;
 Minibatch[1501-1600]: loss = 0.412365 * 100, metric = 5.97% * 100;
 Minibatch[1601-1700]: loss = 0.411961 * 100, metric = 6.04% * 100;
 Minibatch[1701-1800]: loss = 0.408297 * 100, metric = 5.93% * 100;
 Minibatch[1801-1900]: loss = 0.408401 * 100, metric = 5.90% * 100;
 Minibatch[1901-2000]: loss = 0.403771 * 100, metric = 5.55% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.404802 * 2000, metric = 5.76% * 2000 867.819s (  2.3 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 14.05% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
