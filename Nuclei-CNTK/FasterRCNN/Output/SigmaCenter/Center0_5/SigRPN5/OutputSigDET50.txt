Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.348098 * 100, metric = 24.11% * 100;
 Minibatch[ 101- 200]: loss = 1.152206 * 100, metric = 23.13% * 100;
 Minibatch[ 201- 300]: loss = 1.015413 * 100, metric = 21.31% * 100;
 Minibatch[ 301- 400]: loss = 0.985518 * 100, metric = 20.14% * 100;
 Minibatch[ 401- 500]: loss = 0.884920 * 100, metric = 17.40% * 100;
 Minibatch[ 501- 600]: loss = 0.864735 * 100, metric = 17.05% * 100;
 Minibatch[ 601- 700]: loss = 0.828961 * 100, metric = 16.06% * 100;
 Minibatch[ 701- 800]: loss = 0.772343 * 100, metric = 14.36% * 100;
 Minibatch[ 801- 900]: loss = 0.790084 * 100, metric = 15.19% * 100;
 Minibatch[ 901-1000]: loss = 0.815826 * 100, metric = 15.39% * 100;
 Minibatch[1001-1100]: loss = 0.797690 * 100, metric = 15.18% * 100;
 Minibatch[1101-1200]: loss = 0.798060 * 100, metric = 14.71% * 100;
 Minibatch[1201-1300]: loss = 0.779597 * 100, metric = 14.70% * 100;
 Minibatch[1301-1400]: loss = 0.765366 * 100, metric = 14.19% * 100;
 Minibatch[1401-1500]: loss = 0.781641 * 100, metric = 14.45% * 100;
 Minibatch[1501-1600]: loss = 0.750469 * 100, metric = 13.64% * 100;
 Minibatch[1601-1700]: loss = 0.734430 * 100, metric = 13.34% * 100;
 Minibatch[1701-1800]: loss = 0.747446 * 100, metric = 13.43% * 100;
 Minibatch[1801-1900]: loss = 0.741466 * 100, metric = 13.64% * 100;
 Minibatch[1901-2000]: loss = 0.723938 * 100, metric = 13.12% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.853910 * 2000, metric = 16.23% * 2000 1064.574s (  1.9 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 25.20% * 2000;
0.88045769739151
 Minibatch[   1- 100]: loss = 0.722676 * 100, metric = 13.17% * 100;
 Minibatch[ 101- 200]: loss = 0.740904 * 100, metric = 13.74% * 100;
 Minibatch[ 201- 300]: loss = 0.736163 * 100, metric = 12.88% * 100;
 Minibatch[ 301- 400]: loss = 0.734667 * 100, metric = 13.09% * 100;
 Minibatch[ 401- 500]: loss = 0.720075 * 100, metric = 12.97% * 100;
 Minibatch[ 501- 600]: loss = 0.727778 * 100, metric = 13.06% * 100;
 Minibatch[ 601- 700]: loss = 0.692784 * 100, metric = 12.38% * 100;
 Minibatch[ 701- 800]: loss = 0.717414 * 100, metric = 13.03% * 100;
 Minibatch[ 801- 900]: loss = 0.687399 * 100, metric = 12.28% * 100;
 Minibatch[ 901-1000]: loss = 0.683778 * 100, metric = 12.09% * 100;
 Minibatch[1001-1100]: loss = 0.692711 * 100, metric = 12.65% * 100;
 Minibatch[1101-1200]: loss = 0.694933 * 100, metric = 12.48% * 100;
 Minibatch[1201-1300]: loss = 0.691322 * 100, metric = 12.50% * 100;
 Minibatch[1301-1400]: loss = 0.705364 * 100, metric = 12.68% * 100;
 Minibatch[1401-1500]: loss = 0.673883 * 100, metric = 12.01% * 100;
 Minibatch[1501-1600]: loss = 0.676681 * 100, metric = 11.92% * 100;
 Minibatch[1601-1700]: loss = 0.692142 * 100, metric = 12.29% * 100;
 Minibatch[1701-1800]: loss = 0.690638 * 100, metric = 12.29% * 100;
 Minibatch[1801-1900]: loss = 0.698717 * 100, metric = 11.98% * 100;
 Minibatch[1901-2000]: loss = 0.658280 * 100, metric = 11.79% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.701915 * 2000, metric = 12.56% * 2000 992.692s (  2.0 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 20.05% * 2000;
0.7526459690779448
 Minibatch[   1- 100]: loss = 0.683854 * 100, metric = 12.00% * 100;
 Minibatch[ 101- 200]: loss = 0.689123 * 100, metric = 12.05% * 100;
 Minibatch[ 201- 300]: loss = 0.667912 * 100, metric = 12.02% * 100;
 Minibatch[ 301- 400]: loss = 0.676289 * 100, metric = 12.13% * 100;
 Minibatch[ 401- 500]: loss = 0.682507 * 100, metric = 12.46% * 100;
 Minibatch[ 501- 600]: loss = 0.679672 * 100, metric = 12.34% * 100;
 Minibatch[ 601- 700]: loss = 0.680079 * 100, metric = 11.97% * 100;
 Minibatch[ 701- 800]: loss = 0.650549 * 100, metric = 11.06% * 100;
 Minibatch[ 801- 900]: loss = 0.682697 * 100, metric = 12.38% * 100;
 Minibatch[ 901-1000]: loss = 0.647148 * 100, metric = 11.65% * 100;
 Minibatch[1001-1100]: loss = 0.661820 * 100, metric = 11.83% * 100;
 Minibatch[1101-1200]: loss = 0.643069 * 100, metric = 11.21% * 100;
 Minibatch[1201-1300]: loss = 0.651009 * 100, metric = 11.51% * 100;
 Minibatch[1301-1400]: loss = 0.650074 * 100, metric = 11.24% * 100;
 Minibatch[1401-1500]: loss = 0.665080 * 100, metric = 11.64% * 100;
 Minibatch[1501-1600]: loss = 0.644349 * 100, metric = 11.19% * 100;
 Minibatch[1601-1700]: loss = 0.632094 * 100, metric = 10.54% * 100;
 Minibatch[1701-1800]: loss = 0.657961 * 100, metric = 11.50% * 100;
 Minibatch[1801-1900]: loss = 0.641748 * 100, metric = 10.83% * 100;
 Minibatch[1901-2000]: loss = 0.632778 * 100, metric = 10.68% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.660991 * 2000, metric = 11.61% * 2000 985.183s (  2.0 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 19.89% * 2000;
0.7294131632521749
 Minibatch[   1- 100]: loss = 0.666001 * 100, metric = 10.87% * 100;
 Minibatch[ 101- 200]: loss = 0.629098 * 100, metric = 10.63% * 100;
 Minibatch[ 201- 300]: loss = 0.647775 * 100, metric = 11.19% * 100;
 Minibatch[ 301- 400]: loss = 0.616718 * 100, metric = 10.16% * 100;
 Minibatch[ 401- 500]: loss = 0.639495 * 100, metric = 10.96% * 100;
 Minibatch[ 501- 600]: loss = 0.632966 * 100, metric = 10.54% * 100;
 Minibatch[ 601- 700]: loss = 0.630034 * 100, metric = 10.70% * 100;
 Minibatch[ 701- 800]: loss = 0.642186 * 100, metric = 10.89% * 100;
 Minibatch[ 801- 900]: loss = 0.649385 * 100, metric = 11.09% * 100;
 Minibatch[ 901-1000]: loss = 0.639808 * 100, metric = 11.03% * 100;
 Minibatch[1001-1100]: loss = 0.650712 * 100, metric = 11.23% * 100;
 Minibatch[1101-1200]: loss = 0.619643 * 100, metric = 10.45% * 100;
 Minibatch[1201-1300]: loss = 0.638746 * 100, metric = 10.87% * 100;
 Minibatch[1301-1400]: loss = 0.650020 * 100, metric = 11.15% * 100;
 Minibatch[1401-1500]: loss = 0.653930 * 100, metric = 11.42% * 100;
 Minibatch[1501-1600]: loss = 0.608090 * 100, metric = 10.39% * 100;
 Minibatch[1601-1700]: loss = 0.639533 * 100, metric = 10.92% * 100;
 Minibatch[1701-1800]: loss = 0.635603 * 100, metric = 10.93% * 100;
 Minibatch[1801-1900]: loss = 0.625398 * 100, metric = 10.42% * 100;
 Minibatch[1901-2000]: loss = 0.619042 * 100, metric = 10.46% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.636709 * 2000, metric = 10.81% * 2000 985.667s (  2.0 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 20.37% * 2000;
 Minibatch[   1- 100]: loss = 0.651872 * 100, metric = 11.13% * 100;
 Minibatch[ 101- 200]: loss = 0.623231 * 100, metric = 10.41% * 100;
 Minibatch[ 201- 300]: loss = 0.617391 * 100, metric = 10.47% * 100;
 Minibatch[ 301- 400]: loss = 0.643227 * 100, metric = 11.34% * 100;
 Minibatch[ 401- 500]: loss = 0.613757 * 100, metric = 10.14% * 100;
 Minibatch[ 501- 600]: loss = 0.607246 * 100, metric = 9.92% * 100;
 Minibatch[ 601- 700]: loss = 0.608334 * 100, metric = 9.81% * 100;
 Minibatch[ 701- 800]: loss = 0.624199 * 100, metric = 10.46% * 100;
 Minibatch[ 801- 900]: loss = 0.611997 * 100, metric = 9.87% * 100;
 Minibatch[ 901-1000]: loss = 0.616064 * 100, metric = 10.41% * 100;
 Minibatch[1001-1100]: loss = 0.618904 * 100, metric = 10.38% * 100;
 Minibatch[1101-1200]: loss = 0.608677 * 100, metric = 10.20% * 100;
 Minibatch[1201-1300]: loss = 0.628558 * 100, metric = 10.30% * 100;
 Minibatch[1301-1400]: loss = 0.641172 * 100, metric = 10.54% * 100;
 Minibatch[1401-1500]: loss = 0.622161 * 100, metric = 10.33% * 100;
 Minibatch[1501-1600]: loss = 0.621295 * 100, metric = 10.46% * 100;
 Minibatch[1601-1700]: loss = 0.625767 * 100, metric = 10.39% * 100;
 Minibatch[1701-1800]: loss = 0.630198 * 100, metric = 10.60% * 100;
 Minibatch[1801-1900]: loss = 0.618911 * 100, metric = 10.23% * 100;
 Minibatch[1901-2000]: loss = 0.602466 * 100, metric = 10.09% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.621771 * 2000, metric = 10.37% * 2000 969.284s (  2.1 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 18.30% * 2000;
0.7043747016191483
 Minibatch[   1- 100]: loss = 0.602685 * 100, metric = 10.00% * 100;
 Minibatch[ 101- 200]: loss = 0.584846 * 100, metric = 9.60% * 100;
 Minibatch[ 201- 300]: loss = 0.608458 * 100, metric = 10.02% * 100;
 Minibatch[ 301- 400]: loss = 0.606294 * 100, metric = 9.88% * 100;
 Minibatch[ 401- 500]: loss = 0.593679 * 100, metric = 9.86% * 100;
 Minibatch[ 501- 600]: loss = 0.609106 * 100, metric = 10.20% * 100;
 Minibatch[ 601- 700]: loss = 0.592305 * 100, metric = 9.68% * 100;
 Minibatch[ 701- 800]: loss = 0.598101 * 100, metric = 9.89% * 100;
 Minibatch[ 801- 900]: loss = 0.599583 * 100, metric = 9.96% * 100;
 Minibatch[ 901-1000]: loss = 0.577051 * 100, metric = 9.60% * 100;
 Minibatch[1001-1100]: loss = 0.587101 * 100, metric = 9.40% * 100;
 Minibatch[1101-1200]: loss = 0.605966 * 100, metric = 9.89% * 100;
 Minibatch[1201-1300]: loss = 0.602220 * 100, metric = 9.98% * 100;
 Minibatch[1301-1400]: loss = 0.588070 * 100, metric = 9.87% * 100;
 Minibatch[1401-1500]: loss = 0.606496 * 100, metric = 10.15% * 100;
 Minibatch[1501-1600]: loss = 0.580432 * 100, metric = 9.23% * 100;
 Minibatch[1601-1700]: loss = 0.578079 * 100, metric = 9.40% * 100;
 Minibatch[1701-1800]: loss = 0.566410 * 100, metric = 9.18% * 100;
 Minibatch[1801-1900]: loss = 0.594209 * 100, metric = 9.75% * 100;
 Minibatch[1901-2000]: loss = 0.589343 * 100, metric = 9.70% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.593522 * 2000, metric = 9.76% * 2000 975.730s (  2.0 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 17.86% * 2000;
0.684002532377839
 Minibatch[   1- 100]: loss = 0.584088 * 100, metric = 9.60% * 100;
 Minibatch[ 101- 200]: loss = 0.597244 * 100, metric = 9.65% * 100;
 Minibatch[ 201- 300]: loss = 0.586417 * 100, metric = 9.71% * 100;
 Minibatch[ 301- 400]: loss = 0.587319 * 100, metric = 9.34% * 100;
 Minibatch[ 401- 500]: loss = 0.588776 * 100, metric = 9.61% * 100;
 Minibatch[ 501- 600]: loss = 0.566332 * 100, metric = 8.98% * 100;
 Minibatch[ 601- 700]: loss = 0.576028 * 100, metric = 9.14% * 100;
 Minibatch[ 701- 800]: loss = 0.592988 * 100, metric = 9.67% * 100;
 Minibatch[ 801- 900]: loss = 0.584582 * 100, metric = 9.52% * 100;
 Minibatch[ 901-1000]: loss = 0.584330 * 100, metric = 9.51% * 100;
 Minibatch[1001-1100]: loss = 0.598834 * 100, metric = 10.03% * 100;
 Minibatch[1101-1200]: loss = 0.579258 * 100, metric = 9.38% * 100;
 Minibatch[1201-1300]: loss = 0.593018 * 100, metric = 9.83% * 100;
 Minibatch[1301-1400]: loss = 0.570600 * 100, metric = 9.08% * 100;
 Minibatch[1401-1500]: loss = 0.570737 * 100, metric = 9.09% * 100;
 Minibatch[1501-1600]: loss = 0.580096 * 100, metric = 9.32% * 100;
 Minibatch[1601-1700]: loss = 0.582305 * 100, metric = 9.55% * 100;
 Minibatch[1701-1800]: loss = 0.560640 * 100, metric = 8.98% * 100;
 Minibatch[1801-1900]: loss = 0.570233 * 100, metric = 9.29% * 100;
 Minibatch[1901-2000]: loss = 0.572222 * 100, metric = 9.32% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.581302 * 2000, metric = 9.43% * 2000 961.733s (  2.1 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 16.76% * 2000;
0.6577727219313383
 Minibatch[   1- 100]: loss = 0.580339 * 100, metric = 9.54% * 100;
 Minibatch[ 101- 200]: loss = 0.571896 * 100, metric = 9.40% * 100;
 Minibatch[ 201- 300]: loss = 0.559346 * 100, metric = 9.05% * 100;
 Minibatch[ 301- 400]: loss = 0.562384 * 100, metric = 9.12% * 100;
 Minibatch[ 401- 500]: loss = 0.563394 * 100, metric = 9.25% * 100;
 Minibatch[ 501- 600]: loss = 0.583178 * 100, metric = 9.69% * 100;
 Minibatch[ 601- 700]: loss = 0.545962 * 100, metric = 8.81% * 100;
 Minibatch[ 701- 800]: loss = 0.575472 * 100, metric = 9.08% * 100;
 Minibatch[ 801- 900]: loss = 0.553222 * 100, metric = 8.79% * 100;
 Minibatch[ 901-1000]: loss = 0.538422 * 100, metric = 8.26% * 100;
 Minibatch[1001-1100]: loss = 0.548934 * 100, metric = 8.68% * 100;
 Minibatch[1101-1200]: loss = 0.551907 * 100, metric = 8.90% * 100;
 Minibatch[1201-1300]: loss = 0.564839 * 100, metric = 9.20% * 100;
 Minibatch[1301-1400]: loss = 0.568708 * 100, metric = 9.29% * 100;
 Minibatch[1401-1500]: loss = 0.564589 * 100, metric = 9.29% * 100;
 Minibatch[1501-1600]: loss = 0.575276 * 100, metric = 9.20% * 100;
 Minibatch[1601-1700]: loss = 0.563042 * 100, metric = 8.74% * 100;
 Minibatch[1701-1800]: loss = 0.552185 * 100, metric = 8.48% * 100;
 Minibatch[1801-1900]: loss = 0.557060 * 100, metric = 8.67% * 100;
 Minibatch[1901-2000]: loss = 0.569259 * 100, metric = 8.84% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.562471 * 2000, metric = 9.01% * 2000 962.806s (  2.1 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 15.67% * 2000;
0.6375684439614415
 Minibatch[   1- 100]: loss = 0.544281 * 100, metric = 8.59% * 100;
 Minibatch[ 101- 200]: loss = 0.560168 * 100, metric = 8.95% * 100;
 Minibatch[ 201- 300]: loss = 0.558587 * 100, metric = 8.70% * 100;
 Minibatch[ 301- 400]: loss = 0.567604 * 100, metric = 9.23% * 100;
 Minibatch[ 401- 500]: loss = 0.556454 * 100, metric = 8.79% * 100;
 Minibatch[ 501- 600]: loss = 0.545575 * 100, metric = 8.59% * 100;
 Minibatch[ 601- 700]: loss = 0.550775 * 100, metric = 8.74% * 100;
 Minibatch[ 701- 800]: loss = 0.535315 * 100, metric = 8.10% * 100;
 Minibatch[ 801- 900]: loss = 0.543994 * 100, metric = 8.48% * 100;
 Minibatch[ 901-1000]: loss = 0.552591 * 100, metric = 8.89% * 100;
 Minibatch[1001-1100]: loss = 0.522988 * 100, metric = 7.96% * 100;
 Minibatch[1101-1200]: loss = 0.537076 * 100, metric = 8.38% * 100;
 Minibatch[1201-1300]: loss = 0.548982 * 100, metric = 8.59% * 100;
 Minibatch[1301-1400]: loss = 0.540114 * 100, metric = 8.46% * 100;
 Minibatch[1401-1500]: loss = 0.556036 * 100, metric = 8.88% * 100;
 Minibatch[1501-1600]: loss = 0.554477 * 100, metric = 8.74% * 100;
 Minibatch[1601-1700]: loss = 0.553745 * 100, metric = 8.71% * 100;
 Minibatch[1701-1800]: loss = 0.535415 * 100, metric = 8.19% * 100;
 Minibatch[1801-1900]: loss = 0.536217 * 100, metric = 8.40% * 100;
 Minibatch[1901-2000]: loss = 0.545090 * 100, metric = 8.51% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.547274 * 2000, metric = 8.59% * 2000 964.805s (  2.1 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 15.78% * 2000;
 Minibatch[   1- 100]: loss = 0.559321 * 100, metric = 8.92% * 100;
 Minibatch[ 101- 200]: loss = 0.526147 * 100, metric = 8.17% * 100;
 Minibatch[ 201- 300]: loss = 0.550393 * 100, metric = 8.77% * 100;
 Minibatch[ 301- 400]: loss = 0.540311 * 100, metric = 8.35% * 100;
 Minibatch[ 401- 500]: loss = 0.546247 * 100, metric = 8.48% * 100;
 Minibatch[ 501- 600]: loss = 0.527874 * 100, metric = 8.06% * 100;
 Minibatch[ 601- 700]: loss = 0.521621 * 100, metric = 7.83% * 100;
 Minibatch[ 701- 800]: loss = 0.516144 * 100, metric = 7.62% * 100;
 Minibatch[ 801- 900]: loss = 0.532731 * 100, metric = 8.13% * 100;
 Minibatch[ 901-1000]: loss = 0.542686 * 100, metric = 8.50% * 100;
 Minibatch[1001-1100]: loss = 0.535428 * 100, metric = 8.49% * 100;
 Minibatch[1101-1200]: loss = 0.529003 * 100, metric = 7.98% * 100;
 Minibatch[1201-1300]: loss = 0.532681 * 100, metric = 8.30% * 100;
 Minibatch[1301-1400]: loss = 0.527495 * 100, metric = 8.16% * 100;
 Minibatch[1401-1500]: loss = 0.514205 * 100, metric = 7.84% * 100;
 Minibatch[1501-1600]: loss = 0.527093 * 100, metric = 8.23% * 100;
 Minibatch[1601-1700]: loss = 0.527939 * 100, metric = 8.00% * 100;
 Minibatch[1701-1800]: loss = 0.534982 * 100, metric = 8.07% * 100;
 Minibatch[1801-1900]: loss = 0.538124 * 100, metric = 8.50% * 100;
 Minibatch[1901-2000]: loss = 0.517493 * 100, metric = 7.87% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.532396 * 2000, metric = 8.21% * 2000 955.860s (  2.1 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 15.06% * 2000;
0.6287976594790816
 Minibatch[   1- 100]: loss = 0.505950 * 100, metric = 7.62% * 100;
 Minibatch[ 101- 200]: loss = 0.525887 * 100, metric = 7.80% * 100;
 Minibatch[ 201- 300]: loss = 0.532679 * 100, metric = 8.15% * 100;
 Minibatch[ 301- 400]: loss = 0.519935 * 100, metric = 7.67% * 100;
 Minibatch[ 401- 500]: loss = 0.508400 * 100, metric = 7.60% * 100;
 Minibatch[ 501- 600]: loss = 0.518466 * 100, metric = 7.90% * 100;
 Minibatch[ 601- 700]: loss = 0.511526 * 100, metric = 7.85% * 100;
 Minibatch[ 701- 800]: loss = 0.521729 * 100, metric = 8.14% * 100;
 Minibatch[ 801- 900]: loss = 0.518061 * 100, metric = 7.95% * 100;
 Minibatch[ 901-1000]: loss = 0.527716 * 100, metric = 8.04% * 100;
 Minibatch[1001-1100]: loss = 0.519600 * 100, metric = 7.89% * 100;
 Minibatch[1101-1200]: loss = 0.527380 * 100, metric = 8.13% * 100;
 Minibatch[1201-1300]: loss = 0.512478 * 100, metric = 7.78% * 100;
 Minibatch[1301-1400]: loss = 0.490662 * 100, metric = 7.37% * 100;
 Minibatch[1401-1500]: loss = 0.517762 * 100, metric = 7.92% * 100;
 Minibatch[1501-1600]: loss = 0.504464 * 100, metric = 7.54% * 100;
 Minibatch[1601-1700]: loss = 0.508808 * 100, metric = 7.67% * 100;
 Minibatch[1701-1800]: loss = 0.521213 * 100, metric = 7.90% * 100;
 Minibatch[1801-1900]: loss = 0.510908 * 100, metric = 8.03% * 100;
 Minibatch[1901-2000]: loss = 0.502355 * 100, metric = 7.70% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.515299 * 2000, metric = 7.83% * 2000 966.771s (  2.1 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 14.60% * 2000;
0.6187070587351918
 Minibatch[   1- 100]: loss = 0.494206 * 100, metric = 7.59% * 100;
 Minibatch[ 101- 200]: loss = 0.496224 * 100, metric = 7.29% * 100;
 Minibatch[ 201- 300]: loss = 0.507431 * 100, metric = 7.69% * 100;
 Minibatch[ 301- 400]: loss = 0.531548 * 100, metric = 8.42% * 100;
 Minibatch[ 401- 500]: loss = 0.497895 * 100, metric = 7.45% * 100;
 Minibatch[ 501- 600]: loss = 0.489542 * 100, metric = 7.20% * 100;
 Minibatch[ 601- 700]: loss = 0.497524 * 100, metric = 7.43% * 100;
 Minibatch[ 701- 800]: loss = 0.498611 * 100, metric = 7.61% * 100;
 Minibatch[ 801- 900]: loss = 0.497369 * 100, metric = 7.31% * 100;
 Minibatch[ 901-1000]: loss = 0.495636 * 100, metric = 7.47% * 100;
 Minibatch[1001-1100]: loss = 0.507791 * 100, metric = 7.72% * 100;
 Minibatch[1101-1200]: loss = 0.500898 * 100, metric = 7.59% * 100;
 Minibatch[1201-1300]: loss = 0.509021 * 100, metric = 7.83% * 100;
 Minibatch[1301-1400]: loss = 0.490300 * 100, metric = 7.16% * 100;
 Minibatch[1401-1500]: loss = 0.503744 * 100, metric = 7.61% * 100;
 Minibatch[1501-1600]: loss = 0.477717 * 100, metric = 7.11% * 100;
 Minibatch[1601-1700]: loss = 0.505349 * 100, metric = 7.67% * 100;
 Minibatch[1701-1800]: loss = 0.491982 * 100, metric = 7.22% * 100;
 Minibatch[1801-1900]: loss = 0.487470 * 100, metric = 7.47% * 100;
 Minibatch[1901-2000]: loss = 0.513305 * 100, metric = 7.74% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.499678 * 2000, metric = 7.53% * 2000 955.037s (  2.1 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 15.32% * 2000;
 Minibatch[   1- 100]: loss = 0.512386 * 100, metric = 7.66% * 100;
 Minibatch[ 101- 200]: loss = 0.508500 * 100, metric = 7.58% * 100;
 Minibatch[ 201- 300]: loss = 0.503820 * 100, metric = 7.45% * 100;
 Minibatch[ 301- 400]: loss = 0.496887 * 100, metric = 7.50% * 100;
 Minibatch[ 401- 500]: loss = 0.503135 * 100, metric = 7.82% * 100;
 Minibatch[ 501- 600]: loss = 0.512430 * 100, metric = 7.90% * 100;
 Minibatch[ 601- 700]: loss = 0.482706 * 100, metric = 7.00% * 100;
 Minibatch[ 701- 800]: loss = 0.485602 * 100, metric = 6.90% * 100;
 Minibatch[ 801- 900]: loss = 0.481475 * 100, metric = 6.90% * 100;
 Minibatch[ 901-1000]: loss = 0.501299 * 100, metric = 7.55% * 100;
 Minibatch[1001-1100]: loss = 0.501065 * 100, metric = 7.48% * 100;
 Minibatch[1101-1200]: loss = 0.497011 * 100, metric = 7.39% * 100;
 Minibatch[1201-1300]: loss = 0.500325 * 100, metric = 7.46% * 100;
 Minibatch[1301-1400]: loss = 0.496569 * 100, metric = 7.36% * 100;
 Minibatch[1401-1500]: loss = 0.484047 * 100, metric = 7.22% * 100;
 Minibatch[1501-1600]: loss = 0.476315 * 100, metric = 6.82% * 100;
 Minibatch[1601-1700]: loss = 0.469731 * 100, metric = 7.11% * 100;
 Minibatch[1701-1800]: loss = 0.477874 * 100, metric = 7.07% * 100;
 Minibatch[1801-1900]: loss = 0.479985 * 100, metric = 7.02% * 100;
 Minibatch[1901-2000]: loss = 0.498096 * 100, metric = 7.48% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.493463 * 2000, metric = 7.33% * 2000 949.287s (  2.1 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 16.30% * 2000;
 Minibatch[   1- 100]: loss = 0.483306 * 100, metric = 7.13% * 100;
 Minibatch[ 101- 200]: loss = 0.470648 * 100, metric = 6.78% * 100;
 Minibatch[ 201- 300]: loss = 0.493541 * 100, metric = 7.53% * 100;
 Minibatch[ 301- 400]: loss = 0.477102 * 100, metric = 6.78% * 100;
 Minibatch[ 401- 500]: loss = 0.479303 * 100, metric = 7.19% * 100;
 Minibatch[ 501- 600]: loss = 0.485352 * 100, metric = 7.20% * 100;
 Minibatch[ 601- 700]: loss = 0.481351 * 100, metric = 7.31% * 100;
 Minibatch[ 701- 800]: loss = 0.496267 * 100, metric = 7.45% * 100;
 Minibatch[ 801- 900]: loss = 0.498399 * 100, metric = 7.56% * 100;
 Minibatch[ 901-1000]: loss = 0.499061 * 100, metric = 7.60% * 100;
 Minibatch[1001-1100]: loss = 0.490902 * 100, metric = 7.56% * 100;
 Minibatch[1101-1200]: loss = 0.477856 * 100, metric = 6.91% * 100;
 Minibatch[1201-1300]: loss = 0.469011 * 100, metric = 6.78% * 100;
 Minibatch[1301-1400]: loss = 0.486600 * 100, metric = 7.10% * 100;
 Minibatch[1401-1500]: loss = 0.487381 * 100, metric = 7.30% * 100;
 Minibatch[1501-1600]: loss = 0.468588 * 100, metric = 7.04% * 100;
 Minibatch[1601-1700]: loss = 0.481009 * 100, metric = 7.03% * 100;
 Minibatch[1701-1800]: loss = 0.482833 * 100, metric = 7.10% * 100;
 Minibatch[1801-1900]: loss = 0.483615 * 100, metric = 7.21% * 100;
 Minibatch[1901-2000]: loss = 0.493231 * 100, metric = 7.28% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.484268 * 2000, metric = 7.19% * 2000 945.568s (  2.1 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 16.01% * 2000;
 Minibatch[   1- 100]: loss = 0.474511 * 100, metric = 6.82% * 100;
 Minibatch[ 101- 200]: loss = 0.491012 * 100, metric = 7.24% * 100;
 Minibatch[ 201- 300]: loss = 0.485996 * 100, metric = 7.06% * 100;
 Minibatch[ 301- 400]: loss = 0.482785 * 100, metric = 6.97% * 100;
 Minibatch[ 401- 500]: loss = 0.487524 * 100, metric = 7.32% * 100;
 Minibatch[ 501- 600]: loss = 0.475078 * 100, metric = 6.87% * 100;
 Minibatch[ 601- 700]: loss = 0.456809 * 100, metric = 6.62% * 100;
 Minibatch[ 701- 800]: loss = 0.490138 * 100, metric = 7.22% * 100;
 Minibatch[ 801- 900]: loss = 0.509345 * 100, metric = 7.96% * 100;
 Minibatch[ 901-1000]: loss = 0.492456 * 100, metric = 7.12% * 100;
 Minibatch[1001-1100]: loss = 0.495079 * 100, metric = 7.39% * 100;
 Minibatch[1101-1200]: loss = 0.490931 * 100, metric = 7.38% * 100;
 Minibatch[1201-1300]: loss = 0.475406 * 100, metric = 6.88% * 100;
 Minibatch[1301-1400]: loss = 0.501056 * 100, metric = 7.69% * 100;
 Minibatch[1401-1500]: loss = 0.466219 * 100, metric = 6.74% * 100;
 Minibatch[1501-1600]: loss = 0.464954 * 100, metric = 6.93% * 100;
 Minibatch[1601-1700]: loss = 0.484871 * 100, metric = 7.25% * 100;
 Minibatch[1701-1800]: loss = 0.468743 * 100, metric = 6.89% * 100;
 Minibatch[1801-1900]: loss = 0.470910 * 100, metric = 6.91% * 100;
 Minibatch[1901-2000]: loss = 0.466741 * 100, metric = 6.79% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.481528 * 2000, metric = 7.10% * 2000 945.722s (  2.1 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 13.72% * 2000;
0.6021743892133236
 Minibatch[   1- 100]: loss = 0.501905 * 100, metric = 7.64% * 100;
 Minibatch[ 101- 200]: loss = 0.481850 * 100, metric = 6.75% * 100;
 Minibatch[ 201- 300]: loss = 0.477095 * 100, metric = 6.92% * 100;
 Minibatch[ 301- 400]: loss = 0.482086 * 100, metric = 7.20% * 100;
 Minibatch[ 401- 500]: loss = 0.460535 * 100, metric = 6.72% * 100;
 Minibatch[ 501- 600]: loss = 0.474336 * 100, metric = 7.12% * 100;
 Minibatch[ 601- 700]: loss = 0.480815 * 100, metric = 6.93% * 100;
 Minibatch[ 701- 800]: loss = 0.473181 * 100, metric = 6.96% * 100;
 Minibatch[ 801- 900]: loss = 0.462707 * 100, metric = 6.54% * 100;
 Minibatch[ 901-1000]: loss = 0.475201 * 100, metric = 6.98% * 100;
 Minibatch[1001-1100]: loss = 0.457098 * 100, metric = 6.41% * 100;
 Minibatch[1101-1200]: loss = 0.462213 * 100, metric = 6.74% * 100;
 Minibatch[1201-1300]: loss = 0.460138 * 100, metric = 6.39% * 100;
 Minibatch[1301-1400]: loss = 0.470430 * 100, metric = 6.68% * 100;
 Minibatch[1401-1500]: loss = 0.460502 * 100, metric = 6.78% * 100;
 Minibatch[1501-1600]: loss = 0.467573 * 100, metric = 6.81% * 100;
 Minibatch[1601-1700]: loss = 0.472338 * 100, metric = 7.06% * 100;
 Minibatch[1701-1800]: loss = 0.485919 * 100, metric = 7.08% * 100;
 Minibatch[1801-1900]: loss = 0.481521 * 100, metric = 7.20% * 100;
 Minibatch[1901-2000]: loss = 0.455628 * 100, metric = 6.63% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.472154 * 2000, metric = 6.88% * 2000 953.102s (  2.1 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.68% * 2000;
 Minibatch[   1- 100]: loss = 0.457152 * 100, metric = 6.48% * 100;
 Minibatch[ 101- 200]: loss = 0.479466 * 100, metric = 7.01% * 100;
 Minibatch[ 201- 300]: loss = 0.481689 * 100, metric = 7.08% * 100;
 Minibatch[ 301- 400]: loss = 0.466159 * 100, metric = 6.77% * 100;
 Minibatch[ 401- 500]: loss = 0.480424 * 100, metric = 6.91% * 100;
 Minibatch[ 501- 600]: loss = 0.468761 * 100, metric = 6.73% * 100;
 Minibatch[ 601- 700]: loss = 0.448043 * 100, metric = 6.37% * 100;
 Minibatch[ 701- 800]: loss = 0.470969 * 100, metric = 6.88% * 100;
 Minibatch[ 801- 900]: loss = 0.468803 * 100, metric = 6.88% * 100;
 Minibatch[ 901-1000]: loss = 0.454716 * 100, metric = 6.26% * 100;
 Minibatch[1001-1100]: loss = 0.449497 * 100, metric = 6.46% * 100;
 Minibatch[1101-1200]: loss = 0.472940 * 100, metric = 6.80% * 100;
 Minibatch[1201-1300]: loss = 0.475851 * 100, metric = 6.79% * 100;
 Minibatch[1301-1400]: loss = 0.450037 * 100, metric = 6.34% * 100;
 Minibatch[1401-1500]: loss = 0.466741 * 100, metric = 6.84% * 100;
 Minibatch[1501-1600]: loss = 0.462359 * 100, metric = 6.73% * 100;
 Minibatch[1601-1700]: loss = 0.466984 * 100, metric = 6.53% * 100;
 Minibatch[1701-1800]: loss = 0.454763 * 100, metric = 6.66% * 100;
 Minibatch[1801-1900]: loss = 0.478058 * 100, metric = 7.04% * 100;
 Minibatch[1901-2000]: loss = 0.484496 * 100, metric = 7.07% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.466895 * 2000, metric = 6.73% * 2000 950.375s (  2.1 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 13.82% * 2000;
 Minibatch[   1- 100]: loss = 0.446714 * 100, metric = 6.07% * 100;
 Minibatch[ 101- 200]: loss = 0.474877 * 100, metric = 6.86% * 100;
 Minibatch[ 201- 300]: loss = 0.451965 * 100, metric = 6.51% * 100;
 Minibatch[ 301- 400]: loss = 0.464268 * 100, metric = 6.75% * 100;
 Minibatch[ 401- 500]: loss = 0.450568 * 100, metric = 6.41% * 100;
 Minibatch[ 501- 600]: loss = 0.452792 * 100, metric = 6.44% * 100;
 Minibatch[ 601- 700]: loss = 0.465438 * 100, metric = 6.84% * 100;
 Minibatch[ 701- 800]: loss = 0.444718 * 100, metric = 6.69% * 100;
 Minibatch[ 801- 900]: loss = 0.467631 * 100, metric = 6.85% * 100;
 Minibatch[ 901-1000]: loss = 0.459071 * 100, metric = 6.46% * 100;
 Minibatch[1001-1100]: loss = 0.473281 * 100, metric = 6.88% * 100;
 Minibatch[1101-1200]: loss = 0.462648 * 100, metric = 6.70% * 100;
 Minibatch[1201-1300]: loss = 0.469102 * 100, metric = 7.00% * 100;
 Minibatch[1301-1400]: loss = 0.475096 * 100, metric = 6.88% * 100;
 Minibatch[1401-1500]: loss = 0.447372 * 100, metric = 6.31% * 100;
 Minibatch[1501-1600]: loss = 0.460007 * 100, metric = 6.52% * 100;
 Minibatch[1601-1700]: loss = 0.439929 * 100, metric = 6.11% * 100;
 Minibatch[1701-1800]: loss = 0.454996 * 100, metric = 6.69% * 100;
 Minibatch[1801-1900]: loss = 0.441232 * 100, metric = 6.27% * 100;
 Minibatch[1901-2000]: loss = 0.445358 * 100, metric = 6.21% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.457353 * 2000, metric = 6.57% * 2000 950.100s (  2.1 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 14.74% * 2000;
 Minibatch[   1- 100]: loss = 0.465308 * 100, metric = 6.65% * 100;
 Minibatch[ 101- 200]: loss = 0.466932 * 100, metric = 6.68% * 100;
 Minibatch[ 201- 300]: loss = 0.439011 * 100, metric = 5.99% * 100;
 Minibatch[ 301- 400]: loss = 0.451295 * 100, metric = 6.40% * 100;
 Minibatch[ 401- 500]: loss = 0.451449 * 100, metric = 6.17% * 100;
 Minibatch[ 501- 600]: loss = 0.442335 * 100, metric = 6.06% * 100;
 Minibatch[ 601- 700]: loss = 0.458774 * 100, metric = 6.42% * 100;
 Minibatch[ 701- 800]: loss = 0.438399 * 100, metric = 6.03% * 100;
 Minibatch[ 801- 900]: loss = 0.470653 * 100, metric = 6.85% * 100;
 Minibatch[ 901-1000]: loss = 0.440068 * 100, metric = 6.01% * 100;
 Minibatch[1001-1100]: loss = 0.467086 * 100, metric = 6.65% * 100;
 Minibatch[1101-1200]: loss = 0.452871 * 100, metric = 6.52% * 100;
 Minibatch[1201-1300]: loss = 0.449163 * 100, metric = 6.21% * 100;
 Minibatch[1301-1400]: loss = 0.448153 * 100, metric = 6.52% * 100;
 Minibatch[1401-1500]: loss = 0.452578 * 100, metric = 6.44% * 100;
 Minibatch[1501-1600]: loss = 0.456877 * 100, metric = 6.57% * 100;
 Minibatch[1601-1700]: loss = 0.440032 * 100, metric = 6.14% * 100;
 Minibatch[1701-1800]: loss = 0.431306 * 100, metric = 6.11% * 100;
 Minibatch[1801-1900]: loss = 0.441503 * 100, metric = 6.22% * 100;
 Minibatch[1901-2000]: loss = 0.432622 * 100, metric = 5.88% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.449821 * 2000, metric = 6.33% * 2000 947.868s (  2.1 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 14.68% * 2000;
 Minibatch[   1- 100]: loss = 0.442095 * 100, metric = 6.02% * 100;
 Minibatch[ 101- 200]: loss = 0.440445 * 100, metric = 6.12% * 100;
 Minibatch[ 201- 300]: loss = 0.436633 * 100, metric = 5.94% * 100;
 Minibatch[ 301- 400]: loss = 0.456837 * 100, metric = 6.44% * 100;
 Minibatch[ 401- 500]: loss = 0.443917 * 100, metric = 6.16% * 100;
 Minibatch[ 501- 600]: loss = 0.449909 * 100, metric = 6.70% * 100;
 Minibatch[ 601- 700]: loss = 0.463377 * 100, metric = 6.81% * 100;
 Minibatch[ 701- 800]: loss = 0.443395 * 100, metric = 6.21% * 100;
 Minibatch[ 801- 900]: loss = 0.451589 * 100, metric = 6.45% * 100;
 Minibatch[ 901-1000]: loss = 0.450999 * 100, metric = 6.48% * 100;
 Minibatch[1001-1100]: loss = 0.427192 * 100, metric = 6.05% * 100;
 Minibatch[1101-1200]: loss = 0.440611 * 100, metric = 6.15% * 100;
 Minibatch[1201-1300]: loss = 0.448647 * 100, metric = 6.30% * 100;
 Minibatch[1301-1400]: loss = 0.452167 * 100, metric = 6.35% * 100;
 Minibatch[1401-1500]: loss = 0.434937 * 100, metric = 6.21% * 100;
 Minibatch[1501-1600]: loss = 0.453797 * 100, metric = 6.43% * 100;
 Minibatch[1601-1700]: loss = 0.445215 * 100, metric = 6.26% * 100;
 Minibatch[1701-1800]: loss = 0.454170 * 100, metric = 6.47% * 100;
 Minibatch[1801-1900]: loss = 0.442049 * 100, metric = 6.26% * 100;
 Minibatch[1901-2000]: loss = 0.438658 * 100, metric = 6.21% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.445832 * 2000, metric = 6.30% * 2000 964.481s (  2.1 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 14.41% * 2000;
 Minibatch[   1- 100]: loss = 0.449355 * 100, metric = 6.46% * 100;
 Minibatch[ 101- 200]: loss = 0.439495 * 100, metric = 6.18% * 100;
 Minibatch[ 201- 300]: loss = 0.437860 * 100, metric = 6.29% * 100;
 Minibatch[ 301- 400]: loss = 0.453143 * 100, metric = 6.42% * 100;
 Minibatch[ 401- 500]: loss = 0.433912 * 100, metric = 6.04% * 100;
 Minibatch[ 501- 600]: loss = 0.428642 * 100, metric = 5.80% * 100;
 Minibatch[ 601- 700]: loss = 0.435114 * 100, metric = 6.14% * 100;
 Minibatch[ 701- 800]: loss = 0.410169 * 100, metric = 5.62% * 100;
 Minibatch[ 801- 900]: loss = 0.440613 * 100, metric = 6.21% * 100;
 Minibatch[ 901-1000]: loss = 0.427981 * 100, metric = 6.02% * 100;
 Minibatch[1001-1100]: loss = 0.431808 * 100, metric = 6.07% * 100;
 Minibatch[1101-1200]: loss = 0.424507 * 100, metric = 5.81% * 100;
 Minibatch[1201-1300]: loss = 0.439286 * 100, metric = 6.07% * 100;
 Minibatch[1301-1400]: loss = 0.430076 * 100, metric = 6.07% * 100;
 Minibatch[1401-1500]: loss = 0.445151 * 100, metric = 6.23% * 100;
 Minibatch[1501-1600]: loss = 0.440490 * 100, metric = 6.17% * 100;
 Minibatch[1601-1700]: loss = 0.428654 * 100, metric = 5.91% * 100;
 Minibatch[1701-1800]: loss = 0.423707 * 100, metric = 5.88% * 100;
 Minibatch[1801-1900]: loss = 0.449276 * 100, metric = 6.38% * 100;
 Minibatch[1901-2000]: loss = 0.422283 * 100, metric = 5.83% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.434576 * 2000, metric = 6.08% * 2000 937.161s (  2.1 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 13.44% * 2000;
 Minibatch[   1- 100]: loss = 0.447245 * 100, metric = 6.17% * 100;
 Minibatch[ 101- 200]: loss = 0.434397 * 100, metric = 6.04% * 100;
 Minibatch[ 201- 300]: loss = 0.443024 * 100, metric = 6.22% * 100;
 Minibatch[ 301- 400]: loss = 0.430695 * 100, metric = 6.08% * 100;
 Minibatch[ 401- 500]: loss = 0.425241 * 100, metric = 5.68% * 100;
 Minibatch[ 501- 600]: loss = 0.446257 * 100, metric = 6.20% * 100;
 Minibatch[ 601- 700]: loss = 0.432783 * 100, metric = 6.00% * 100;
 Minibatch[ 701- 800]: loss = 0.432043 * 100, metric = 6.15% * 100;
 Minibatch[ 801- 900]: loss = 0.435959 * 100, metric = 6.18% * 100;
 Minibatch[ 901-1000]: loss = 0.445227 * 100, metric = 6.14% * 100;
 Minibatch[1001-1100]: loss = 0.418553 * 100, metric = 5.70% * 100;
 Minibatch[1101-1200]: loss = 0.415231 * 100, metric = 5.65% * 100;
 Minibatch[1201-1300]: loss = 0.432986 * 100, metric = 5.92% * 100;
 Minibatch[1301-1400]: loss = 0.427514 * 100, metric = 6.09% * 100;
 Minibatch[1401-1500]: loss = 0.425130 * 100, metric = 5.90% * 100;
 Minibatch[1501-1600]: loss = 0.415590 * 100, metric = 5.66% * 100;
 Minibatch[1601-1700]: loss = 0.425123 * 100, metric = 6.16% * 100;
 Minibatch[1701-1800]: loss = 0.425042 * 100, metric = 5.89% * 100;
 Minibatch[1801-1900]: loss = 0.425288 * 100, metric = 6.04% * 100;
 Minibatch[1901-2000]: loss = 0.428922 * 100, metric = 5.90% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.430612 * 2000, metric = 5.99% * 2000 936.752s (  2.1 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 13.61% * 2000;
 Minibatch[   1- 100]: loss = 0.438736 * 100, metric = 6.15% * 100;
 Minibatch[ 101- 200]: loss = 0.438283 * 100, metric = 6.36% * 100;
 Minibatch[ 201- 300]: loss = 0.422554 * 100, metric = 5.68% * 100;
 Minibatch[ 301- 400]: loss = 0.435726 * 100, metric = 6.25% * 100;
 Minibatch[ 401- 500]: loss = 0.439299 * 100, metric = 6.16% * 100;
 Minibatch[ 501- 600]: loss = 0.428383 * 100, metric = 5.75% * 100;
 Minibatch[ 601- 700]: loss = 0.434599 * 100, metric = 5.98% * 100;
 Minibatch[ 701- 800]: loss = 0.415050 * 100, metric = 5.63% * 100;
 Minibatch[ 801- 900]: loss = 0.415186 * 100, metric = 5.89% * 100;
 Minibatch[ 901-1000]: loss = 0.432801 * 100, metric = 5.99% * 100;
 Minibatch[1001-1100]: loss = 0.417084 * 100, metric = 5.68% * 100;
 Minibatch[1101-1200]: loss = 0.429077 * 100, metric = 6.19% * 100;
 Minibatch[1201-1300]: loss = 0.431455 * 100, metric = 5.95% * 100;
 Minibatch[1301-1400]: loss = 0.442507 * 100, metric = 6.16% * 100;
 Minibatch[1401-1500]: loss = 0.417131 * 100, metric = 5.69% * 100;
 Minibatch[1501-1600]: loss = 0.429909 * 100, metric = 5.78% * 100;
 Minibatch[1601-1700]: loss = 0.423295 * 100, metric = 5.74% * 100;
 Minibatch[1701-1800]: loss = 0.423776 * 100, metric = 5.96% * 100;
 Minibatch[1801-1900]: loss = 0.425521 * 100, metric = 6.05% * 100;
 Minibatch[1901-2000]: loss = 0.422746 * 100, metric = 5.59% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.428156 * 2000, metric = 5.93% * 2000 940.240s (  2.1 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 14.42% * 2000;
 Minibatch[   1- 100]: loss = 0.399513 * 100, metric = 5.40% * 100;
 Minibatch[ 101- 200]: loss = 0.421445 * 100, metric = 5.95% * 100;
 Minibatch[ 201- 300]: loss = 0.417307 * 100, metric = 5.90% * 100;
 Minibatch[ 301- 400]: loss = 0.422560 * 100, metric = 5.81% * 100;
 Minibatch[ 401- 500]: loss = 0.425078 * 100, metric = 6.14% * 100;
 Minibatch[ 501- 600]: loss = 0.414722 * 100, metric = 5.83% * 100;
 Minibatch[ 601- 700]: loss = 0.429373 * 100, metric = 6.03% * 100;
 Minibatch[ 701- 800]: loss = 0.415066 * 100, metric = 5.82% * 100;
 Minibatch[ 801- 900]: loss = 0.429071 * 100, metric = 6.22% * 100;
 Minibatch[ 901-1000]: loss = 0.423230 * 100, metric = 5.86% * 100;
 Minibatch[1001-1100]: loss = 0.414902 * 100, metric = 5.78% * 100;
 Minibatch[1101-1200]: loss = 0.427041 * 100, metric = 5.98% * 100;
 Minibatch[1201-1300]: loss = 0.429661 * 100, metric = 5.99% * 100;
 Minibatch[1301-1400]: loss = 0.418589 * 100, metric = 5.78% * 100;
 Minibatch[1401-1500]: loss = 0.416430 * 100, metric = 5.66% * 100;
 Minibatch[1501-1600]: loss = 0.419754 * 100, metric = 5.79% * 100;
 Minibatch[1601-1700]: loss = 0.415727 * 100, metric = 5.71% * 100;
 Minibatch[1701-1800]: loss = 0.406251 * 100, metric = 5.60% * 100;
 Minibatch[1801-1900]: loss = 0.424196 * 100, metric = 6.07% * 100;
 Minibatch[1901-2000]: loss = 0.428577 * 100, metric = 6.17% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.419925 * 2000, metric = 5.88% * 2000 981.519s (  2.0 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 13.95% * 2000;
 Minibatch[   1- 100]: loss = 0.422808 * 100, metric = 5.99% * 100;
 Minibatch[ 101- 200]: loss = 0.418202 * 100, metric = 5.85% * 100;
 Minibatch[ 201- 300]: loss = 0.412423 * 100, metric = 5.76% * 100;
 Minibatch[ 301- 400]: loss = 0.421123 * 100, metric = 5.92% * 100;
 Minibatch[ 401- 500]: loss = 0.421254 * 100, metric = 5.92% * 100;
 Minibatch[ 501- 600]: loss = 0.419971 * 100, metric = 6.06% * 100;
 Minibatch[ 601- 700]: loss = 0.419447 * 100, metric = 5.93% * 100;
 Minibatch[ 701- 800]: loss = 0.406945 * 100, metric = 5.37% * 100;
 Minibatch[ 801- 900]: loss = 0.406803 * 100, metric = 5.43% * 100;
 Minibatch[ 901-1000]: loss = 0.418343 * 100, metric = 5.81% * 100;
 Minibatch[1001-1100]: loss = 0.416159 * 100, metric = 5.87% * 100;
 Minibatch[1101-1200]: loss = 0.426347 * 100, metric = 6.12% * 100;
 Minibatch[1201-1300]: loss = 0.442771 * 100, metric = 6.42% * 100;
 Minibatch[1301-1400]: loss = 0.413461 * 100, metric = 5.77% * 100;
 Minibatch[1401-1500]: loss = 0.410988 * 100, metric = 5.57% * 100;
 Minibatch[1501-1600]: loss = 0.423575 * 100, metric = 6.01% * 100;
 Minibatch[1601-1700]: loss = 0.410520 * 100, metric = 5.66% * 100;
 Minibatch[1701-1800]: loss = 0.422742 * 100, metric = 5.91% * 100;
 Minibatch[1801-1900]: loss = 0.405513 * 100, metric = 5.60% * 100;
 Minibatch[1901-2000]: loss = 0.401215 * 100, metric = 5.51% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.417030 * 2000, metric = 5.82% * 2000 979.874s (  2.0 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 13.79% * 2000;
 Minibatch[   1- 100]: loss = 0.407393 * 100, metric = 5.60% * 100;
 Minibatch[ 101- 200]: loss = 0.390257 * 100, metric = 5.19% * 100;
 Minibatch[ 201- 300]: loss = 0.416419 * 100, metric = 5.93% * 100;
 Minibatch[ 301- 400]: loss = 0.404338 * 100, metric = 5.65% * 100;
 Minibatch[ 401- 500]: loss = 0.407410 * 100, metric = 5.71% * 100;
 Minibatch[ 501- 600]: loss = 0.406366 * 100, metric = 5.50% * 100;
 Minibatch[ 601- 700]: loss = 0.431298 * 100, metric = 5.97% * 100;
 Minibatch[ 701- 800]: loss = 0.405016 * 100, metric = 5.63% * 100;
 Minibatch[ 801- 900]: loss = 0.400267 * 100, metric = 5.41% * 100;
 Minibatch[ 901-1000]: loss = 0.405389 * 100, metric = 5.53% * 100;
 Minibatch[1001-1100]: loss = 0.414514 * 100, metric = 6.07% * 100;
 Minibatch[1101-1200]: loss = 0.423478 * 100, metric = 5.80% * 100;
 Minibatch[1201-1300]: loss = 0.411312 * 100, metric = 5.68% * 100;
 Minibatch[1301-1400]: loss = 0.400637 * 100, metric = 5.62% * 100;
 Minibatch[1401-1500]: loss = 0.412888 * 100, metric = 5.69% * 100;
 Minibatch[1501-1600]: loss = 0.406387 * 100, metric = 5.31% * 100;
 Minibatch[1601-1700]: loss = 0.427269 * 100, metric = 5.96% * 100;
 Minibatch[1701-1800]: loss = 0.425426 * 100, metric = 6.01% * 100;
 Minibatch[1801-1900]: loss = 0.409268 * 100, metric = 5.56% * 100;
 Minibatch[1901-2000]: loss = 0.418871 * 100, metric = 5.77% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.411210 * 2000, metric = 5.68% * 2000 977.702s (  2.0 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.30% * 2000;
 Minibatch[   1- 100]: loss = 0.420722 * 100, metric = 5.75% * 100;
 Minibatch[ 101- 200]: loss = 0.420739 * 100, metric = 5.84% * 100;
 Minibatch[ 201- 300]: loss = 0.409537 * 100, metric = 5.77% * 100;
 Minibatch[ 301- 400]: loss = 0.403612 * 100, metric = 5.52% * 100;
 Minibatch[ 401- 500]: loss = 0.408267 * 100, metric = 5.42% * 100;
 Minibatch[ 501- 600]: loss = 0.409268 * 100, metric = 5.81% * 100;
 Minibatch[ 601- 700]: loss = 0.408168 * 100, metric = 5.48% * 100;
 Minibatch[ 701- 800]: loss = 0.415659 * 100, metric = 5.75% * 100;
 Minibatch[ 801- 900]: loss = 0.419806 * 100, metric = 5.72% * 100;
 Minibatch[ 901-1000]: loss = 0.417746 * 100, metric = 5.94% * 100;
 Minibatch[1001-1100]: loss = 0.407184 * 100, metric = 5.40% * 100;
 Minibatch[1101-1200]: loss = 0.421563 * 100, metric = 5.93% * 100;
 Minibatch[1201-1300]: loss = 0.411805 * 100, metric = 5.89% * 100;
 Minibatch[1301-1400]: loss = 0.419696 * 100, metric = 5.96% * 100;
 Minibatch[1401-1500]: loss = 0.410558 * 100, metric = 5.85% * 100;
 Minibatch[1501-1600]: loss = 0.411979 * 100, metric = 5.73% * 100;
 Minibatch[1601-1700]: loss = 0.395344 * 100, metric = 5.30% * 100;
 Minibatch[1701-1800]: loss = 0.406322 * 100, metric = 5.48% * 100;
 Minibatch[1801-1900]: loss = 0.408593 * 100, metric = 5.60% * 100;
 Minibatch[1901-2000]: loss = 0.416167 * 100, metric = 5.66% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.412137 * 2000, metric = 5.69% * 2000 972.570s (  2.1 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.31% * 2000;
 Minibatch[   1- 100]: loss = 0.422337 * 100, metric = 6.05% * 100;
 Minibatch[ 101- 200]: loss = 0.405666 * 100, metric = 5.47% * 100;
 Minibatch[ 201- 300]: loss = 0.419150 * 100, metric = 5.81% * 100;
 Minibatch[ 301- 400]: loss = 0.412993 * 100, metric = 5.58% * 100;
 Minibatch[ 401- 500]: loss = 0.409691 * 100, metric = 5.70% * 100;
 Minibatch[ 501- 600]: loss = 0.426099 * 100, metric = 6.00% * 100;
 Minibatch[ 601- 700]: loss = 0.408739 * 100, metric = 5.64% * 100;
 Minibatch[ 701- 800]: loss = 0.395747 * 100, metric = 5.26% * 100;
 Minibatch[ 801- 900]: loss = 0.413430 * 100, metric = 5.57% * 100;
 Minibatch[ 901-1000]: loss = 0.407468 * 100, metric = 5.75% * 100;
 Minibatch[1001-1100]: loss = 0.403063 * 100, metric = 5.56% * 100;
 Minibatch[1101-1200]: loss = 0.401483 * 100, metric = 5.30% * 100;
 Minibatch[1201-1300]: loss = 0.415261 * 100, metric = 5.70% * 100;
 Minibatch[1301-1400]: loss = 0.404120 * 100, metric = 5.55% * 100;
 Minibatch[1401-1500]: loss = 0.420359 * 100, metric = 5.94% * 100;
 Minibatch[1501-1600]: loss = 0.404237 * 100, metric = 5.42% * 100;
 Minibatch[1601-1700]: loss = 0.413082 * 100, metric = 5.58% * 100;
 Minibatch[1701-1800]: loss = 0.406063 * 100, metric = 5.42% * 100;
 Minibatch[1801-1900]: loss = 0.405573 * 100, metric = 5.61% * 100;
 Minibatch[1901-2000]: loss = 0.411511 * 100, metric = 5.55% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.410304 * 2000, metric = 5.62% * 2000 976.140s (  2.0 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.51% * 2000;
 Minibatch[   1- 100]: loss = 0.391092 * 100, metric = 5.14% * 100;
 Minibatch[ 101- 200]: loss = 0.399186 * 100, metric = 5.50% * 100;
 Minibatch[ 201- 300]: loss = 0.404518 * 100, metric = 5.59% * 100;
 Minibatch[ 301- 400]: loss = 0.430918 * 100, metric = 6.02% * 100;
 Minibatch[ 401- 500]: loss = 0.401785 * 100, metric = 5.47% * 100;
 Minibatch[ 501- 600]: loss = 0.410054 * 100, metric = 5.52% * 100;
 Minibatch[ 601- 700]: loss = 0.404879 * 100, metric = 5.69% * 100;
 Minibatch[ 701- 800]: loss = 0.412422 * 100, metric = 5.87% * 100;
 Minibatch[ 801- 900]: loss = 0.405129 * 100, metric = 5.42% * 100;
 Minibatch[ 901-1000]: loss = 0.404619 * 100, metric = 5.46% * 100;
 Minibatch[1001-1100]: loss = 0.400676 * 100, metric = 5.50% * 100;
 Minibatch[1101-1200]: loss = 0.394064 * 100, metric = 5.25% * 100;
 Minibatch[1201-1300]: loss = 0.407460 * 100, metric = 5.60% * 100;
 Minibatch[1301-1400]: loss = 0.393013 * 100, metric = 5.19% * 100;
 Minibatch[1401-1500]: loss = 0.411265 * 100, metric = 5.56% * 100;
 Minibatch[1501-1600]: loss = 0.389802 * 100, metric = 5.29% * 100;
 Minibatch[1601-1700]: loss = 0.404451 * 100, metric = 5.47% * 100;
 Minibatch[1701-1800]: loss = 0.396254 * 100, metric = 5.38% * 100;
 Minibatch[1801-1900]: loss = 0.422153 * 100, metric = 5.86% * 100;
 Minibatch[1901-2000]: loss = 0.414325 * 100, metric = 5.55% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.404903 * 2000, metric = 5.52% * 2000 984.558s (  2.0 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 14.74% * 2000;
 Minibatch[   1- 100]: loss = 0.427432 * 100, metric = 5.92% * 100;
 Minibatch[ 101- 200]: loss = 0.386913 * 100, metric = 5.01% * 100;
 Minibatch[ 201- 300]: loss = 0.403214 * 100, metric = 5.58% * 100;
 Minibatch[ 301- 400]: loss = 0.409586 * 100, metric = 5.55% * 100;
 Minibatch[ 401- 500]: loss = 0.398952 * 100, metric = 5.42% * 100;
 Minibatch[ 501- 600]: loss = 0.389124 * 100, metric = 5.03% * 100;
 Minibatch[ 601- 700]: loss = 0.404391 * 100, metric = 5.50% * 100;
 Minibatch[ 701- 800]: loss = 0.392308 * 100, metric = 4.97% * 100;
 Minibatch[ 801- 900]: loss = 0.403996 * 100, metric = 5.52% * 100;
 Minibatch[ 901-1000]: loss = 0.384315 * 100, metric = 5.13% * 100;
 Minibatch[1001-1100]: loss = 0.406021 * 100, metric = 5.41% * 100;
 Minibatch[1101-1200]: loss = 0.408502 * 100, metric = 5.43% * 100;
 Minibatch[1201-1300]: loss = 0.394304 * 100, metric = 5.28% * 100;
 Minibatch[1301-1400]: loss = 0.398528 * 100, metric = 5.43% * 100;
 Minibatch[1401-1500]: loss = 0.398065 * 100, metric = 5.35% * 100;
 Minibatch[1501-1600]: loss = 0.415829 * 100, metric = 5.74% * 100;
 Minibatch[1601-1700]: loss = 0.403386 * 100, metric = 5.37% * 100;
 Minibatch[1701-1800]: loss = 0.406689 * 100, metric = 5.40% * 100;
 Minibatch[1801-1900]: loss = 0.401207 * 100, metric = 5.46% * 100;
 Minibatch[1901-2000]: loss = 0.418642 * 100, metric = 5.84% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.402570 * 2000, metric = 5.42% * 2000 985.996s (  2.0 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 13.95% * 2000;
 Minibatch[   1- 100]: loss = 0.406327 * 100, metric = 5.39% * 100;
 Minibatch[ 101- 200]: loss = 0.413318 * 100, metric = 5.92% * 100;
 Minibatch[ 201- 300]: loss = 0.399087 * 100, metric = 5.43% * 100;
 Minibatch[ 301- 400]: loss = 0.394781 * 100, metric = 5.37% * 100;
 Minibatch[ 401- 500]: loss = 0.396851 * 100, metric = 5.35% * 100;
 Minibatch[ 501- 600]: loss = 0.396969 * 100, metric = 5.41% * 100;
 Minibatch[ 601- 700]: loss = 0.415194 * 100, metric = 5.91% * 100;
 Minibatch[ 701- 800]: loss = 0.415607 * 100, metric = 5.68% * 100;
 Minibatch[ 801- 900]: loss = 0.405373 * 100, metric = 5.44% * 100;
 Minibatch[ 901-1000]: loss = 0.395254 * 100, metric = 5.38% * 100;
 Minibatch[1001-1100]: loss = 0.394039 * 100, metric = 5.19% * 100;
 Minibatch[1101-1200]: loss = 0.401774 * 100, metric = 5.67% * 100;
 Minibatch[1201-1300]: loss = 0.397764 * 100, metric = 5.48% * 100;
 Minibatch[1301-1400]: loss = 0.398951 * 100, metric = 5.34% * 100;
 Minibatch[1401-1500]: loss = 0.412227 * 100, metric = 5.62% * 100;
 Minibatch[1501-1600]: loss = 0.393156 * 100, metric = 5.47% * 100;
 Minibatch[1601-1700]: loss = 0.401539 * 100, metric = 5.53% * 100;
 Minibatch[1701-1800]: loss = 0.391193 * 100, metric = 5.30% * 100;
 Minibatch[1801-1900]: loss = 0.406088 * 100, metric = 5.65% * 100;
 Minibatch[1901-2000]: loss = 0.398021 * 100, metric = 5.44% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.401676 * 2000, metric = 5.50% * 2000 982.745s (  2.0 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 14.01% * 2000;
 Minibatch[   1- 100]: loss = 0.398440 * 100, metric = 5.40% * 100;
 Minibatch[ 101- 200]: loss = 0.399975 * 100, metric = 5.32% * 100;
 Minibatch[ 201- 300]: loss = 0.404972 * 100, metric = 5.48% * 100;
 Minibatch[ 301- 400]: loss = 0.413547 * 100, metric = 5.66% * 100;
 Minibatch[ 401- 500]: loss = 0.400540 * 100, metric = 5.53% * 100;
 Minibatch[ 501- 600]: loss = 0.402970 * 100, metric = 5.69% * 100;
 Minibatch[ 601- 700]: loss = 0.395694 * 100, metric = 5.16% * 100;
 Minibatch[ 701- 800]: loss = 0.393468 * 100, metric = 5.28% * 100;
 Minibatch[ 801- 900]: loss = 0.390278 * 100, metric = 5.15% * 100;
 Minibatch[ 901-1000]: loss = 0.392307 * 100, metric = 5.36% * 100;
 Minibatch[1001-1100]: loss = 0.391583 * 100, metric = 5.16% * 100;
 Minibatch[1101-1200]: loss = 0.392478 * 100, metric = 5.33% * 100;
 Minibatch[1201-1300]: loss = 0.418457 * 100, metric = 5.88% * 100;
 Minibatch[1301-1400]: loss = 0.401624 * 100, metric = 5.69% * 100;
 Minibatch[1401-1500]: loss = 0.393452 * 100, metric = 5.64% * 100;
 Minibatch[1501-1600]: loss = 0.413914 * 100, metric = 5.70% * 100;
 Minibatch[1601-1700]: loss = 0.396573 * 100, metric = 5.49% * 100;
 Minibatch[1701-1800]: loss = 0.406104 * 100, metric = 5.52% * 100;
 Minibatch[1801-1900]: loss = 0.390475 * 100, metric = 5.13% * 100;
 Minibatch[1901-2000]: loss = 0.400847 * 100, metric = 5.59% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.399885 * 2000, metric = 5.46% * 2000 986.876s (  2.0 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.52% * 2000;
 Minibatch[   1- 100]: loss = 0.409657 * 100, metric = 5.75% * 100;
 Minibatch[ 101- 200]: loss = 0.396756 * 100, metric = 5.51% * 100;
 Minibatch[ 201- 300]: loss = 0.390626 * 100, metric = 5.32% * 100;
 Minibatch[ 301- 400]: loss = 0.398787 * 100, metric = 5.55% * 100;
 Minibatch[ 401- 500]: loss = 0.393352 * 100, metric = 5.42% * 100;
 Minibatch[ 501- 600]: loss = 0.403923 * 100, metric = 5.51% * 100;
 Minibatch[ 601- 700]: loss = 0.403618 * 100, metric = 5.50% * 100;
 Minibatch[ 701- 800]: loss = 0.402063 * 100, metric = 5.55% * 100;
 Minibatch[ 801- 900]: loss = 0.396644 * 100, metric = 5.19% * 100;
 Minibatch[ 901-1000]: loss = 0.387570 * 100, metric = 5.15% * 100;
 Minibatch[1001-1100]: loss = 0.394341 * 100, metric = 5.37% * 100;
 Minibatch[1101-1200]: loss = 0.384989 * 100, metric = 5.15% * 100;
 Minibatch[1201-1300]: loss = 0.399763 * 100, metric = 5.30% * 100;
 Minibatch[1301-1400]: loss = 0.384911 * 100, metric = 5.12% * 100;
 Minibatch[1401-1500]: loss = 0.407675 * 100, metric = 5.53% * 100;
 Minibatch[1501-1600]: loss = 0.398467 * 100, metric = 5.31% * 100;
 Minibatch[1601-1700]: loss = 0.393842 * 100, metric = 5.12% * 100;
 Minibatch[1701-1800]: loss = 0.394764 * 100, metric = 5.23% * 100;
 Minibatch[1801-1900]: loss = 0.392449 * 100, metric = 5.17% * 100;
 Minibatch[1901-2000]: loss = 0.405363 * 100, metric = 5.66% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.396978 * 2000, metric = 5.37% * 2000 975.539s (  2.1 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.78% * 2000;
 Minibatch[   1- 100]: loss = 0.392342 * 100, metric = 5.47% * 100;
 Minibatch[ 101- 200]: loss = 0.392659 * 100, metric = 5.27% * 100;
 Minibatch[ 201- 300]: loss = 0.389986 * 100, metric = 5.24% * 100;
 Minibatch[ 301- 400]: loss = 0.398478 * 100, metric = 5.45% * 100;
 Minibatch[ 401- 500]: loss = 0.384270 * 100, metric = 5.12% * 100;
 Minibatch[ 501- 600]: loss = 0.388760 * 100, metric = 5.29% * 100;
 Minibatch[ 601- 700]: loss = 0.398625 * 100, metric = 5.50% * 100;
 Minibatch[ 701- 800]: loss = 0.387166 * 100, metric = 5.08% * 100;
 Minibatch[ 801- 900]: loss = 0.380647 * 100, metric = 4.91% * 100;
 Minibatch[ 901-1000]: loss = 0.390036 * 100, metric = 5.32% * 100;
 Minibatch[1001-1100]: loss = 0.396452 * 100, metric = 5.48% * 100;
 Minibatch[1101-1200]: loss = 0.385219 * 100, metric = 5.22% * 100;
 Minibatch[1201-1300]: loss = 0.398146 * 100, metric = 5.43% * 100;
 Minibatch[1301-1400]: loss = 0.393580 * 100, metric = 5.42% * 100;
 Minibatch[1401-1500]: loss = 0.403940 * 100, metric = 5.69% * 100;
 Minibatch[1501-1600]: loss = 0.395298 * 100, metric = 5.29% * 100;
 Minibatch[1601-1700]: loss = 0.408054 * 100, metric = 5.66% * 100;
 Minibatch[1701-1800]: loss = 0.386273 * 100, metric = 4.94% * 100;
 Minibatch[1801-1900]: loss = 0.391163 * 100, metric = 5.25% * 100;
 Minibatch[1901-2000]: loss = 0.399976 * 100, metric = 5.20% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.393054 * 2000, metric = 5.31% * 2000 984.511s (  2.0 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.23% * 2000;
 Minibatch[   1- 100]: loss = 0.377766 * 100, metric = 4.95% * 100;
 Minibatch[ 101- 200]: loss = 0.399084 * 100, metric = 5.54% * 100;
 Minibatch[ 201- 300]: loss = 0.399241 * 100, metric = 5.56% * 100;
 Minibatch[ 301- 400]: loss = 0.379909 * 100, metric = 5.04% * 100;
 Minibatch[ 401- 500]: loss = 0.394755 * 100, metric = 5.35% * 100;
 Minibatch[ 501- 600]: loss = 0.367143 * 100, metric = 4.83% * 100;
 Minibatch[ 601- 700]: loss = 0.408350 * 100, metric = 5.77% * 100;
 Minibatch[ 701- 800]: loss = 0.374051 * 100, metric = 5.05% * 100;
 Minibatch[ 801- 900]: loss = 0.401158 * 100, metric = 5.39% * 100;
 Minibatch[ 901-1000]: loss = 0.376328 * 100, metric = 5.03% * 100;
 Minibatch[1001-1100]: loss = 0.396154 * 100, metric = 5.35% * 100;
 Minibatch[1101-1200]: loss = 0.388708 * 100, metric = 5.17% * 100;
 Minibatch[1201-1300]: loss = 0.398207 * 100, metric = 5.31% * 100;
 Minibatch[1301-1400]: loss = 0.395580 * 100, metric = 5.48% * 100;
 Minibatch[1401-1500]: loss = 0.393050 * 100, metric = 5.31% * 100;
 Minibatch[1501-1600]: loss = 0.391276 * 100, metric = 5.30% * 100;
 Minibatch[1601-1700]: loss = 0.389611 * 100, metric = 5.30% * 100;
 Minibatch[1701-1800]: loss = 0.383882 * 100, metric = 5.20% * 100;
 Minibatch[1801-1900]: loss = 0.395364 * 100, metric = 5.30% * 100;
 Minibatch[1901-2000]: loss = 0.383553 * 100, metric = 5.12% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.389659 * 2000, metric = 5.27% * 2000 981.078s (  2.0 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.55% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
