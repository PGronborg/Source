Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.207517 * 100, metric = 24.37% * 100;
 Minibatch[ 101- 200]: loss = 1.028328 * 100, metric = 22.97% * 100;
 Minibatch[ 201- 300]: loss = 0.889288 * 100, metric = 21.45% * 100;
 Minibatch[ 301- 400]: loss = 0.816963 * 100, metric = 19.63% * 100;
 Minibatch[ 401- 500]: loss = 0.741780 * 100, metric = 17.69% * 100;
 Minibatch[ 501- 600]: loss = 0.723787 * 100, metric = 17.20% * 100;
 Minibatch[ 601- 700]: loss = 0.695903 * 100, metric = 16.60% * 100;
 Minibatch[ 701- 800]: loss = 0.650828 * 100, metric = 15.54% * 100;
 Minibatch[ 801- 900]: loss = 0.672292 * 100, metric = 15.96% * 100;
 Minibatch[ 901-1000]: loss = 0.679030 * 100, metric = 16.38% * 100;
 Minibatch[1001-1100]: loss = 0.656602 * 100, metric = 16.09% * 100;
 Minibatch[1101-1200]: loss = 0.646443 * 100, metric = 15.03% * 100;
 Minibatch[1201-1300]: loss = 0.640134 * 100, metric = 15.06% * 100;
 Minibatch[1301-1400]: loss = 0.619048 * 100, metric = 14.33% * 100;
 Minibatch[1401-1500]: loss = 0.650906 * 100, metric = 15.22% * 100;
 Minibatch[1501-1600]: loss = 0.616532 * 100, metric = 15.03% * 100;
 Minibatch[1601-1700]: loss = 0.593558 * 100, metric = 14.00% * 100;
 Minibatch[1701-1800]: loss = 0.609790 * 100, metric = 14.52% * 100;
 Minibatch[1801-1900]: loss = 0.604658 * 100, metric = 14.11% * 100;
 Minibatch[1901-2000]: loss = 0.580963 * 100, metric = 13.34% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.716217 * 2000, metric = 16.73% * 2000 994.309s (  2.0 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 23.01% * 2000;
0.6698062666207552
 Minibatch[   1- 100]: loss = 0.597142 * 100, metric = 13.66% * 100;
 Minibatch[ 101- 200]: loss = 0.606718 * 100, metric = 14.34% * 100;
 Minibatch[ 201- 300]: loss = 0.587259 * 100, metric = 13.32% * 100;
 Minibatch[ 301- 400]: loss = 0.580007 * 100, metric = 13.46% * 100;
 Minibatch[ 401- 500]: loss = 0.574285 * 100, metric = 13.31% * 100;
 Minibatch[ 501- 600]: loss = 0.581309 * 100, metric = 13.23% * 100;
 Minibatch[ 601- 700]: loss = 0.562182 * 100, metric = 12.85% * 100;
 Minibatch[ 701- 800]: loss = 0.563488 * 100, metric = 13.31% * 100;
 Minibatch[ 801- 900]: loss = 0.543640 * 100, metric = 12.64% * 100;
 Minibatch[ 901-1000]: loss = 0.540569 * 100, metric = 12.56% * 100;
 Minibatch[1001-1100]: loss = 0.560058 * 100, metric = 13.19% * 100;
 Minibatch[1101-1200]: loss = 0.555236 * 100, metric = 13.05% * 100;
 Minibatch[1201-1300]: loss = 0.550362 * 100, metric = 12.81% * 100;
 Minibatch[1301-1400]: loss = 0.558155 * 100, metric = 12.91% * 100;
 Minibatch[1401-1500]: loss = 0.541158 * 100, metric = 12.27% * 100;
 Minibatch[1501-1600]: loss = 0.536752 * 100, metric = 12.37% * 100;
 Minibatch[1601-1700]: loss = 0.547274 * 100, metric = 12.69% * 100;
 Minibatch[1701-1800]: loss = 0.550190 * 100, metric = 12.76% * 100;
 Minibatch[1801-1900]: loss = 0.551048 * 100, metric = 12.83% * 100;
 Minibatch[1901-2000]: loss = 0.525917 * 100, metric = 12.20% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.560637 * 2000, metric = 12.99% * 2000 937.143s (  2.1 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 19.61% * 2000;
0.5835205296278
 Minibatch[   1- 100]: loss = 0.547526 * 100, metric = 12.99% * 100;
 Minibatch[ 101- 200]: loss = 0.542556 * 100, metric = 12.58% * 100;
 Minibatch[ 201- 300]: loss = 0.533042 * 100, metric = 12.68% * 100;
 Minibatch[ 301- 400]: loss = 0.545336 * 100, metric = 12.79% * 100;
 Minibatch[ 401- 500]: loss = 0.556844 * 100, metric = 12.98% * 100;
 Minibatch[ 501- 600]: loss = 0.545670 * 100, metric = 12.96% * 100;
 Minibatch[ 601- 700]: loss = 0.547611 * 100, metric = 12.72% * 100;
 Minibatch[ 701- 800]: loss = 0.525284 * 100, metric = 11.99% * 100;
 Minibatch[ 801- 900]: loss = 0.554937 * 100, metric = 12.85% * 100;
 Minibatch[ 901-1000]: loss = 0.527639 * 100, metric = 12.52% * 100;
 Minibatch[1001-1100]: loss = 0.529521 * 100, metric = 12.14% * 100;
 Minibatch[1101-1200]: loss = 0.512891 * 100, metric = 11.81% * 100;
 Minibatch[1201-1300]: loss = 0.523759 * 100, metric = 12.00% * 100;
 Minibatch[1301-1400]: loss = 0.530521 * 100, metric = 12.35% * 100;
 Minibatch[1401-1500]: loss = 0.541157 * 100, metric = 12.55% * 100;
 Minibatch[1501-1600]: loss = 0.518875 * 100, metric = 11.92% * 100;
 Minibatch[1601-1700]: loss = 0.516118 * 100, metric = 11.63% * 100;
 Minibatch[1701-1800]: loss = 0.538675 * 100, metric = 12.53% * 100;
 Minibatch[1801-1900]: loss = 0.508783 * 100, metric = 11.92% * 100;
 Minibatch[1901-2000]: loss = 0.517259 * 100, metric = 11.80% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.533200 * 2000, metric = 12.39% * 2000 925.032s (  2.2 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 18.87% * 2000;
0.574496753282845
 Minibatch[   1- 100]: loss = 0.533007 * 100, metric = 11.81% * 100;
 Minibatch[ 101- 200]: loss = 0.511710 * 100, metric = 11.73% * 100;
 Minibatch[ 201- 300]: loss = 0.525333 * 100, metric = 12.13% * 100;
 Minibatch[ 301- 400]: loss = 0.486394 * 100, metric = 10.91% * 100;
 Minibatch[ 401- 500]: loss = 0.521171 * 100, metric = 12.04% * 100;
 Minibatch[ 501- 600]: loss = 0.502624 * 100, metric = 11.29% * 100;
 Minibatch[ 601- 700]: loss = 0.503480 * 100, metric = 11.34% * 100;
 Minibatch[ 701- 800]: loss = 0.518478 * 100, metric = 11.69% * 100;
 Minibatch[ 801- 900]: loss = 0.515657 * 100, metric = 11.78% * 100;
 Minibatch[ 901-1000]: loss = 0.510664 * 100, metric = 11.90% * 100;
 Minibatch[1001-1100]: loss = 0.522913 * 100, metric = 11.99% * 100;
 Minibatch[1101-1200]: loss = 0.487072 * 100, metric = 10.93% * 100;
 Minibatch[1201-1300]: loss = 0.504066 * 100, metric = 11.50% * 100;
 Minibatch[1301-1400]: loss = 0.514116 * 100, metric = 11.71% * 100;
 Minibatch[1401-1500]: loss = 0.516091 * 100, metric = 11.82% * 100;
 Minibatch[1501-1600]: loss = 0.483886 * 100, metric = 10.96% * 100;
 Minibatch[1601-1700]: loss = 0.500969 * 100, metric = 11.64% * 100;
 Minibatch[1701-1800]: loss = 0.510358 * 100, metric = 11.89% * 100;
 Minibatch[1801-1900]: loss = 0.491718 * 100, metric = 11.03% * 100;
 Minibatch[1901-2000]: loss = 0.482855 * 100, metric = 10.89% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.507128 * 2000, metric = 11.55% * 2000 931.047s (  2.1 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 19.97% * 2000;
 Minibatch[   1- 100]: loss = 0.513594 * 100, metric = 11.60% * 100;
 Minibatch[ 101- 200]: loss = 0.490377 * 100, metric = 11.11% * 100;
 Minibatch[ 201- 300]: loss = 0.488674 * 100, metric = 11.16% * 100;
 Minibatch[ 301- 400]: loss = 0.517922 * 100, metric = 11.96% * 100;
 Minibatch[ 401- 500]: loss = 0.479773 * 100, metric = 10.83% * 100;
 Minibatch[ 501- 600]: loss = 0.480410 * 100, metric = 10.64% * 100;
 Minibatch[ 601- 700]: loss = 0.488378 * 100, metric = 10.82% * 100;
 Minibatch[ 701- 800]: loss = 0.495334 * 100, metric = 11.25% * 100;
 Minibatch[ 801- 900]: loss = 0.476401 * 100, metric = 10.74% * 100;
 Minibatch[ 901-1000]: loss = 0.480302 * 100, metric = 10.66% * 100;
 Minibatch[1001-1100]: loss = 0.479544 * 100, metric = 10.69% * 100;
 Minibatch[1101-1200]: loss = 0.468955 * 100, metric = 10.33% * 100;
 Minibatch[1201-1300]: loss = 0.485414 * 100, metric = 10.78% * 100;
 Minibatch[1301-1400]: loss = 0.493981 * 100, metric = 11.24% * 100;
 Minibatch[1401-1500]: loss = 0.480212 * 100, metric = 10.82% * 100;
 Minibatch[1501-1600]: loss = 0.478680 * 100, metric = 10.59% * 100;
 Minibatch[1601-1700]: loss = 0.485259 * 100, metric = 11.04% * 100;
 Minibatch[1701-1800]: loss = 0.479785 * 100, metric = 10.81% * 100;
 Minibatch[1801-1900]: loss = 0.483988 * 100, metric = 10.87% * 100;
 Minibatch[1901-2000]: loss = 0.462549 * 100, metric = 10.09% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.485477 * 2000, metric = 10.90% * 2000 912.072s (  2.2 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 17.34% * 2000;
0.5372944052740931
 Minibatch[   1- 100]: loss = 0.466024 * 100, metric = 10.59% * 100;
 Minibatch[ 101- 200]: loss = 0.457812 * 100, metric = 10.37% * 100;
 Minibatch[ 201- 300]: loss = 0.462975 * 100, metric = 10.35% * 100;
 Minibatch[ 301- 400]: loss = 0.469943 * 100, metric = 10.29% * 100;
 Minibatch[ 401- 500]: loss = 0.451997 * 100, metric = 10.27% * 100;
 Minibatch[ 501- 600]: loss = 0.462379 * 100, metric = 10.49% * 100;
 Minibatch[ 601- 700]: loss = 0.451283 * 100, metric = 10.12% * 100;
 Minibatch[ 701- 800]: loss = 0.466284 * 100, metric = 10.37% * 100;
 Minibatch[ 801- 900]: loss = 0.472345 * 100, metric = 10.84% * 100;
 Minibatch[ 901-1000]: loss = 0.457579 * 100, metric = 10.30% * 100;
 Minibatch[1001-1100]: loss = 0.465193 * 100, metric = 10.35% * 100;
 Minibatch[1101-1200]: loss = 0.475669 * 100, metric = 10.63% * 100;
 Minibatch[1201-1300]: loss = 0.482668 * 100, metric = 10.87% * 100;
 Minibatch[1301-1400]: loss = 0.463426 * 100, metric = 10.46% * 100;
 Minibatch[1401-1500]: loss = 0.469848 * 100, metric = 10.73% * 100;
 Minibatch[1501-1600]: loss = 0.446416 * 100, metric = 10.16% * 100;
 Minibatch[1601-1700]: loss = 0.455224 * 100, metric = 10.29% * 100;
 Minibatch[1701-1800]: loss = 0.448322 * 100, metric = 9.91% * 100;
 Minibatch[1801-1900]: loss = 0.462415 * 100, metric = 10.27% * 100;
 Minibatch[1901-2000]: loss = 0.452390 * 100, metric = 9.98% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.462010 * 2000, metric = 10.38% * 2000 920.326s (  2.2 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 17.80% * 2000;
 Minibatch[   1- 100]: loss = 0.454893 * 100, metric = 10.29% * 100;
 Minibatch[ 101- 200]: loss = 0.468139 * 100, metric = 10.32% * 100;
 Minibatch[ 201- 300]: loss = 0.462896 * 100, metric = 10.18% * 100;
 Minibatch[ 301- 400]: loss = 0.447372 * 100, metric = 9.85% * 100;
 Minibatch[ 401- 500]: loss = 0.457119 * 100, metric = 10.06% * 100;
 Minibatch[ 501- 600]: loss = 0.439106 * 100, metric = 9.64% * 100;
 Minibatch[ 601- 700]: loss = 0.448409 * 100, metric = 9.75% * 100;
 Minibatch[ 701- 800]: loss = 0.458939 * 100, metric = 10.40% * 100;
 Minibatch[ 801- 900]: loss = 0.459421 * 100, metric = 10.27% * 100;
 Minibatch[ 901-1000]: loss = 0.454527 * 100, metric = 10.34% * 100;
 Minibatch[1001-1100]: loss = 0.459518 * 100, metric = 10.41% * 100;
 Minibatch[1101-1200]: loss = 0.444239 * 100, metric = 9.82% * 100;
 Minibatch[1201-1300]: loss = 0.457025 * 100, metric = 10.37% * 100;
 Minibatch[1301-1400]: loss = 0.435825 * 100, metric = 9.81% * 100;
 Minibatch[1401-1500]: loss = 0.434435 * 100, metric = 9.49% * 100;
 Minibatch[1501-1600]: loss = 0.449364 * 100, metric = 10.16% * 100;
 Minibatch[1601-1700]: loss = 0.458322 * 100, metric = 10.23% * 100;
 Minibatch[1701-1800]: loss = 0.446092 * 100, metric = 9.70% * 100;
 Minibatch[1801-1900]: loss = 0.448216 * 100, metric = 9.95% * 100;
 Minibatch[1901-2000]: loss = 0.442129 * 100, metric = 9.88% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.451299 * 2000, metric = 10.05% * 2000 912.756s (  2.2 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 15.68% * 2000;
0.5090274086222053
 Minibatch[   1- 100]: loss = 0.457041 * 100, metric = 10.15% * 100;
 Minibatch[ 101- 200]: loss = 0.446206 * 100, metric = 10.02% * 100;
 Minibatch[ 201- 300]: loss = 0.441504 * 100, metric = 10.12% * 100;
 Minibatch[ 301- 400]: loss = 0.437291 * 100, metric = 9.68% * 100;
 Minibatch[ 401- 500]: loss = 0.449788 * 100, metric = 10.26% * 100;
 Minibatch[ 501- 600]: loss = 0.458368 * 100, metric = 10.38% * 100;
 Minibatch[ 601- 700]: loss = 0.427445 * 100, metric = 9.60% * 100;
 Minibatch[ 701- 800]: loss = 0.438152 * 100, metric = 9.66% * 100;
 Minibatch[ 801- 900]: loss = 0.433170 * 100, metric = 9.61% * 100;
 Minibatch[ 901-1000]: loss = 0.413796 * 100, metric = 9.02% * 100;
 Minibatch[1001-1100]: loss = 0.420497 * 100, metric = 9.22% * 100;
 Minibatch[1101-1200]: loss = 0.428275 * 100, metric = 9.50% * 100;
 Minibatch[1201-1300]: loss = 0.441915 * 100, metric = 10.07% * 100;
 Minibatch[1301-1400]: loss = 0.448821 * 100, metric = 10.10% * 100;
 Minibatch[1401-1500]: loss = 0.427074 * 100, metric = 9.48% * 100;
 Minibatch[1501-1600]: loss = 0.444683 * 100, metric = 9.99% * 100;
 Minibatch[1601-1700]: loss = 0.424603 * 100, metric = 9.28% * 100;
 Minibatch[1701-1800]: loss = 0.431108 * 100, metric = 9.42% * 100;
 Minibatch[1801-1900]: loss = 0.426024 * 100, metric = 9.32% * 100;
 Minibatch[1901-2000]: loss = 0.428404 * 100, metric = 9.47% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.436208 * 2000, metric = 9.72% * 2000 901.759s (  2.2 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 15.13% * 2000;
0.4969611177444458
 Minibatch[   1- 100]: loss = 0.410156 * 100, metric = 8.95% * 100;
 Minibatch[ 101- 200]: loss = 0.441628 * 100, metric = 9.91% * 100;
 Minibatch[ 201- 300]: loss = 0.425002 * 100, metric = 9.31% * 100;
 Minibatch[ 301- 400]: loss = 0.443731 * 100, metric = 9.75% * 100;
 Minibatch[ 401- 500]: loss = 0.425418 * 100, metric = 9.18% * 100;
 Minibatch[ 501- 600]: loss = 0.420629 * 100, metric = 9.36% * 100;
 Minibatch[ 601- 700]: loss = 0.419541 * 100, metric = 9.23% * 100;
 Minibatch[ 701- 800]: loss = 0.402974 * 100, metric = 8.81% * 100;
 Minibatch[ 801- 900]: loss = 0.409832 * 100, metric = 8.93% * 100;
 Minibatch[ 901-1000]: loss = 0.423141 * 100, metric = 9.47% * 100;
 Minibatch[1001-1100]: loss = 0.396657 * 100, metric = 8.58% * 100;
 Minibatch[1101-1200]: loss = 0.423127 * 100, metric = 9.26% * 100;
 Minibatch[1201-1300]: loss = 0.409691 * 100, metric = 9.13% * 100;
 Minibatch[1301-1400]: loss = 0.409769 * 100, metric = 8.83% * 100;
 Minibatch[1401-1500]: loss = 0.422558 * 100, metric = 9.42% * 100;
 Minibatch[1501-1600]: loss = 0.418531 * 100, metric = 9.09% * 100;
 Minibatch[1601-1700]: loss = 0.424672 * 100, metric = 9.48% * 100;
 Minibatch[1701-1800]: loss = 0.406689 * 100, metric = 8.64% * 100;
 Minibatch[1801-1900]: loss = 0.407455 * 100, metric = 8.91% * 100;
 Minibatch[1901-2000]: loss = 0.426852 * 100, metric = 9.46% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.418403 * 2000, metric = 9.19% * 2000 909.536s (  2.2 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 14.46% * 2000;
0.48241469798609615
 Minibatch[   1- 100]: loss = 0.434265 * 100, metric = 9.79% * 100;
 Minibatch[ 101- 200]: loss = 0.407659 * 100, metric = 8.89% * 100;
 Minibatch[ 201- 300]: loss = 0.409241 * 100, metric = 9.01% * 100;
 Minibatch[ 301- 400]: loss = 0.400933 * 100, metric = 8.70% * 100;
 Minibatch[ 401- 500]: loss = 0.416544 * 100, metric = 9.18% * 100;
 Minibatch[ 501- 600]: loss = 0.391360 * 100, metric = 8.62% * 100;
 Minibatch[ 601- 700]: loss = 0.393943 * 100, metric = 8.43% * 100;
 Minibatch[ 701- 800]: loss = 0.385367 * 100, metric = 8.31% * 100;
 Minibatch[ 801- 900]: loss = 0.408937 * 100, metric = 9.03% * 100;
 Minibatch[ 901-1000]: loss = 0.410932 * 100, metric = 9.24% * 100;
 Minibatch[1001-1100]: loss = 0.409252 * 100, metric = 8.96% * 100;
 Minibatch[1101-1200]: loss = 0.400909 * 100, metric = 8.63% * 100;
 Minibatch[1201-1300]: loss = 0.405807 * 100, metric = 8.77% * 100;
 Minibatch[1301-1400]: loss = 0.402884 * 100, metric = 8.80% * 100;
 Minibatch[1401-1500]: loss = 0.385712 * 100, metric = 8.13% * 100;
 Minibatch[1501-1600]: loss = 0.395521 * 100, metric = 8.72% * 100;
 Minibatch[1601-1700]: loss = 0.393659 * 100, metric = 8.65% * 100;
 Minibatch[1701-1800]: loss = 0.406337 * 100, metric = 8.75% * 100;
 Minibatch[1801-1900]: loss = 0.407457 * 100, metric = 9.00% * 100;
 Minibatch[1901-2000]: loss = 0.390459 * 100, metric = 8.51% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.402859 * 2000, metric = 8.80% * 2000 928.008s (  2.2 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 14.50% * 2000;
0.4795922783464193
 Minibatch[   1- 100]: loss = 0.384208 * 100, metric = 8.32% * 100;
 Minibatch[ 101- 200]: loss = 0.392423 * 100, metric = 8.42% * 100;
 Minibatch[ 201- 300]: loss = 0.408471 * 100, metric = 8.76% * 100;
 Minibatch[ 301- 400]: loss = 0.392776 * 100, metric = 8.68% * 100;
 Minibatch[ 401- 500]: loss = 0.394883 * 100, metric = 8.56% * 100;
 Minibatch[ 501- 600]: loss = 0.406532 * 100, metric = 8.94% * 100;
 Minibatch[ 601- 700]: loss = 0.388419 * 100, metric = 8.39% * 100;
 Minibatch[ 701- 800]: loss = 0.391705 * 100, metric = 8.66% * 100;
 Minibatch[ 801- 900]: loss = 0.391996 * 100, metric = 8.46% * 100;
 Minibatch[ 901-1000]: loss = 0.400341 * 100, metric = 8.79% * 100;
 Minibatch[1001-1100]: loss = 0.396316 * 100, metric = 8.58% * 100;
 Minibatch[1101-1200]: loss = 0.399322 * 100, metric = 8.76% * 100;
 Minibatch[1201-1300]: loss = 0.390087 * 100, metric = 8.56% * 100;
 Minibatch[1301-1400]: loss = 0.374938 * 100, metric = 8.23% * 100;
 Minibatch[1401-1500]: loss = 0.398966 * 100, metric = 8.62% * 100;
 Minibatch[1501-1600]: loss = 0.381163 * 100, metric = 8.36% * 100;
 Minibatch[1601-1700]: loss = 0.387876 * 100, metric = 8.53% * 100;
 Minibatch[1701-1800]: loss = 0.398491 * 100, metric = 8.61% * 100;
 Minibatch[1801-1900]: loss = 0.391877 * 100, metric = 8.73% * 100;
 Minibatch[1901-2000]: loss = 0.387851 * 100, metric = 8.71% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.392932 * 2000, metric = 8.58% * 2000 927.431s (  2.2 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 14.44% * 2000;
 Minibatch[   1- 100]: loss = 0.376141 * 100, metric = 8.37% * 100;
 Minibatch[ 101- 200]: loss = 0.390931 * 100, metric = 8.33% * 100;
 Minibatch[ 201- 300]: loss = 0.382973 * 100, metric = 8.63% * 100;
 Minibatch[ 301- 400]: loss = 0.406066 * 100, metric = 9.08% * 100;
 Minibatch[ 401- 500]: loss = 0.383517 * 100, metric = 8.34% * 100;
 Minibatch[ 501- 600]: loss = 0.368324 * 100, metric = 8.00% * 100;
 Minibatch[ 601- 700]: loss = 0.374181 * 100, metric = 8.23% * 100;
 Minibatch[ 701- 800]: loss = 0.379490 * 100, metric = 8.35% * 100;
 Minibatch[ 801- 900]: loss = 0.376111 * 100, metric = 8.14% * 100;
 Minibatch[ 901-1000]: loss = 0.380917 * 100, metric = 8.35% * 100;
 Minibatch[1001-1100]: loss = 0.384752 * 100, metric = 8.39% * 100;
 Minibatch[1101-1200]: loss = 0.385740 * 100, metric = 8.55% * 100;
 Minibatch[1201-1300]: loss = 0.392523 * 100, metric = 8.73% * 100;
 Minibatch[1301-1400]: loss = 0.376450 * 100, metric = 8.19% * 100;
 Minibatch[1401-1500]: loss = 0.391970 * 100, metric = 8.50% * 100;
 Minibatch[1501-1600]: loss = 0.368507 * 100, metric = 7.86% * 100;
 Minibatch[1601-1700]: loss = 0.388300 * 100, metric = 8.58% * 100;
 Minibatch[1701-1800]: loss = 0.373972 * 100, metric = 8.15% * 100;
 Minibatch[1801-1900]: loss = 0.373307 * 100, metric = 8.19% * 100;
 Minibatch[1901-2000]: loss = 0.392493 * 100, metric = 8.74% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.382333 * 2000, metric = 8.38% * 2000 919.270s (  2.2 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 14.95% * 2000;
 Minibatch[   1- 100]: loss = 0.380384 * 100, metric = 8.18% * 100;
 Minibatch[ 101- 200]: loss = 0.377842 * 100, metric = 8.21% * 100;
 Minibatch[ 201- 300]: loss = 0.373876 * 100, metric = 8.13% * 100;
 Minibatch[ 301- 400]: loss = 0.384321 * 100, metric = 8.41% * 100;
 Minibatch[ 401- 500]: loss = 0.383125 * 100, metric = 8.54% * 100;
 Minibatch[ 501- 600]: loss = 0.390397 * 100, metric = 8.93% * 100;
 Minibatch[ 601- 700]: loss = 0.374334 * 100, metric = 7.98% * 100;
 Minibatch[ 701- 800]: loss = 0.370175 * 100, metric = 7.98% * 100;
 Minibatch[ 801- 900]: loss = 0.377888 * 100, metric = 8.29% * 100;
 Minibatch[ 901-1000]: loss = 0.382771 * 100, metric = 8.41% * 100;
 Minibatch[1001-1100]: loss = 0.390210 * 100, metric = 8.64% * 100;
 Minibatch[1101-1200]: loss = 0.373375 * 100, metric = 8.07% * 100;
 Minibatch[1201-1300]: loss = 0.383942 * 100, metric = 8.68% * 100;
 Minibatch[1301-1400]: loss = 0.379379 * 100, metric = 8.32% * 100;
 Minibatch[1401-1500]: loss = 0.370352 * 100, metric = 8.04% * 100;
 Minibatch[1501-1600]: loss = 0.366469 * 100, metric = 7.94% * 100;
 Minibatch[1601-1700]: loss = 0.366177 * 100, metric = 7.87% * 100;
 Minibatch[1701-1800]: loss = 0.374254 * 100, metric = 8.07% * 100;
 Minibatch[1801-1900]: loss = 0.364578 * 100, metric = 7.96% * 100;
 Minibatch[1901-2000]: loss = 0.381392 * 100, metric = 8.60% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.377262 * 2000, metric = 8.26% * 2000 919.472s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 16.60% * 2000;
 Minibatch[   1- 100]: loss = 0.370146 * 100, metric = 7.96% * 100;
 Minibatch[ 101- 200]: loss = 0.359503 * 100, metric = 7.80% * 100;
 Minibatch[ 201- 300]: loss = 0.371088 * 100, metric = 8.23% * 100;
 Minibatch[ 301- 400]: loss = 0.368248 * 100, metric = 8.16% * 100;
 Minibatch[ 401- 500]: loss = 0.366729 * 100, metric = 8.02% * 100;
 Minibatch[ 501- 600]: loss = 0.370541 * 100, metric = 8.11% * 100;
 Minibatch[ 601- 700]: loss = 0.366267 * 100, metric = 8.02% * 100;
 Minibatch[ 701- 800]: loss = 0.386017 * 100, metric = 8.53% * 100;
 Minibatch[ 801- 900]: loss = 0.377579 * 100, metric = 8.40% * 100;
 Minibatch[ 901-1000]: loss = 0.379024 * 100, metric = 8.40% * 100;
 Minibatch[1001-1100]: loss = 0.375886 * 100, metric = 8.36% * 100;
 Minibatch[1101-1200]: loss = 0.369568 * 100, metric = 8.04% * 100;
 Minibatch[1201-1300]: loss = 0.363130 * 100, metric = 7.65% * 100;
 Minibatch[1301-1400]: loss = 0.377198 * 100, metric = 8.37% * 100;
 Minibatch[1401-1500]: loss = 0.371534 * 100, metric = 8.24% * 100;
 Minibatch[1501-1600]: loss = 0.362562 * 100, metric = 7.97% * 100;
 Minibatch[1601-1700]: loss = 0.362221 * 100, metric = 7.70% * 100;
 Minibatch[1701-1800]: loss = 0.365783 * 100, metric = 7.91% * 100;
 Minibatch[1801-1900]: loss = 0.361357 * 100, metric = 7.79% * 100;
 Minibatch[1901-2000]: loss = 0.370645 * 100, metric = 7.95% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.369751 * 2000, metric = 8.08% * 2000 917.889s (  2.2 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 15.07% * 2000;
 Minibatch[   1- 100]: loss = 0.358649 * 100, metric = 7.81% * 100;
 Minibatch[ 101- 200]: loss = 0.361412 * 100, metric = 7.72% * 100;
 Minibatch[ 201- 300]: loss = 0.360415 * 100, metric = 7.86% * 100;
 Minibatch[ 301- 400]: loss = 0.352507 * 100, metric = 7.65% * 100;
 Minibatch[ 401- 500]: loss = 0.359379 * 100, metric = 7.79% * 100;
 Minibatch[ 501- 600]: loss = 0.348755 * 100, metric = 7.54% * 100;
 Minibatch[ 601- 700]: loss = 0.341153 * 100, metric = 7.46% * 100;
 Minibatch[ 701- 800]: loss = 0.371129 * 100, metric = 8.00% * 100;
 Minibatch[ 801- 900]: loss = 0.372235 * 100, metric = 8.26% * 100;
 Minibatch[ 901-1000]: loss = 0.360581 * 100, metric = 8.02% * 100;
 Minibatch[1001-1100]: loss = 0.366533 * 100, metric = 8.03% * 100;
 Minibatch[1101-1200]: loss = 0.354733 * 100, metric = 7.77% * 100;
 Minibatch[1201-1300]: loss = 0.349197 * 100, metric = 7.50% * 100;
 Minibatch[1301-1400]: loss = 0.374047 * 100, metric = 8.45% * 100;
 Minibatch[1401-1500]: loss = 0.344932 * 100, metric = 7.53% * 100;
 Minibatch[1501-1600]: loss = 0.348315 * 100, metric = 7.53% * 100;
 Minibatch[1601-1700]: loss = 0.357346 * 100, metric = 7.78% * 100;
 Minibatch[1701-1800]: loss = 0.339094 * 100, metric = 7.22% * 100;
 Minibatch[1801-1900]: loss = 0.357446 * 100, metric = 7.81% * 100;
 Minibatch[1901-2000]: loss = 0.353217 * 100, metric = 7.74% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.356554 * 2000, metric = 7.77% * 2000 917.687s (  2.2 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 13.63% * 2000;
0.4715245534703135
 Minibatch[   1- 100]: loss = 0.368415 * 100, metric = 8.25% * 100;
 Minibatch[ 101- 200]: loss = 0.357780 * 100, metric = 7.57% * 100;
 Minibatch[ 201- 300]: loss = 0.362886 * 100, metric = 7.96% * 100;
 Minibatch[ 301- 400]: loss = 0.356792 * 100, metric = 7.77% * 100;
 Minibatch[ 401- 500]: loss = 0.348118 * 100, metric = 7.56% * 100;
 Minibatch[ 501- 600]: loss = 0.357156 * 100, metric = 7.90% * 100;
 Minibatch[ 601- 700]: loss = 0.352754 * 100, metric = 7.62% * 100;
 Minibatch[ 701- 800]: loss = 0.353178 * 100, metric = 7.72% * 100;
 Minibatch[ 801- 900]: loss = 0.346911 * 100, metric = 7.45% * 100;
 Minibatch[ 901-1000]: loss = 0.357965 * 100, metric = 7.87% * 100;
 Minibatch[1001-1100]: loss = 0.341318 * 100, metric = 7.36% * 100;
 Minibatch[1101-1200]: loss = 0.343808 * 100, metric = 7.46% * 100;
 Minibatch[1201-1300]: loss = 0.337575 * 100, metric = 7.19% * 100;
 Minibatch[1301-1400]: loss = 0.345388 * 100, metric = 7.61% * 100;
 Minibatch[1401-1500]: loss = 0.344656 * 100, metric = 7.56% * 100;
 Minibatch[1501-1600]: loss = 0.350211 * 100, metric = 7.60% * 100;
 Minibatch[1601-1700]: loss = 0.357589 * 100, metric = 7.88% * 100;
 Minibatch[1701-1800]: loss = 0.357560 * 100, metric = 7.68% * 100;
 Minibatch[1801-1900]: loss = 0.361721 * 100, metric = 8.05% * 100;
 Minibatch[1901-2000]: loss = 0.345396 * 100, metric = 7.50% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.352359 * 2000, metric = 7.68% * 2000 920.531s (  2.2 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.36% * 2000;
 Minibatch[   1- 100]: loss = 0.339319 * 100, metric = 7.32% * 100;
 Minibatch[ 101- 200]: loss = 0.352638 * 100, metric = 7.49% * 100;
 Minibatch[ 201- 300]: loss = 0.346618 * 100, metric = 7.45% * 100;
 Minibatch[ 301- 400]: loss = 0.350077 * 100, metric = 7.85% * 100;
 Minibatch[ 401- 500]: loss = 0.351036 * 100, metric = 7.34% * 100;
 Minibatch[ 501- 600]: loss = 0.339750 * 100, metric = 7.37% * 100;
 Minibatch[ 601- 700]: loss = 0.329014 * 100, metric = 6.92% * 100;
 Minibatch[ 701- 800]: loss = 0.340176 * 100, metric = 7.22% * 100;
 Minibatch[ 801- 900]: loss = 0.347260 * 100, metric = 7.61% * 100;
 Minibatch[ 901-1000]: loss = 0.334502 * 100, metric = 7.23% * 100;
 Minibatch[1001-1100]: loss = 0.331742 * 100, metric = 7.12% * 100;
 Minibatch[1101-1200]: loss = 0.350435 * 100, metric = 7.69% * 100;
 Minibatch[1201-1300]: loss = 0.346746 * 100, metric = 7.57% * 100;
 Minibatch[1301-1400]: loss = 0.327537 * 100, metric = 7.00% * 100;
 Minibatch[1401-1500]: loss = 0.346643 * 100, metric = 7.84% * 100;
 Minibatch[1501-1600]: loss = 0.341138 * 100, metric = 7.29% * 100;
 Minibatch[1601-1700]: loss = 0.340621 * 100, metric = 7.30% * 100;
 Minibatch[1701-1800]: loss = 0.334274 * 100, metric = 7.24% * 100;
 Minibatch[1801-1900]: loss = 0.352075 * 100, metric = 7.95% * 100;
 Minibatch[1901-2000]: loss = 0.359666 * 100, metric = 7.91% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.343063 * 2000, metric = 7.44% * 2000 911.651s (  2.2 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 13.58% * 2000;
 Minibatch[   1- 100]: loss = 0.327866 * 100, metric = 7.05% * 100;
 Minibatch[ 101- 200]: loss = 0.348517 * 100, metric = 7.60% * 100;
 Minibatch[ 201- 300]: loss = 0.331036 * 100, metric = 7.29% * 100;
 Minibatch[ 301- 400]: loss = 0.336519 * 100, metric = 7.23% * 100;
 Minibatch[ 401- 500]: loss = 0.328950 * 100, metric = 7.10% * 100;
 Minibatch[ 501- 600]: loss = 0.334296 * 100, metric = 7.15% * 100;
 Minibatch[ 601- 700]: loss = 0.340206 * 100, metric = 7.43% * 100;
 Minibatch[ 701- 800]: loss = 0.328351 * 100, metric = 7.20% * 100;
 Minibatch[ 801- 900]: loss = 0.343898 * 100, metric = 7.62% * 100;
 Minibatch[ 901-1000]: loss = 0.335739 * 100, metric = 7.39% * 100;
 Minibatch[1001-1100]: loss = 0.350847 * 100, metric = 7.74% * 100;
 Minibatch[1101-1200]: loss = 0.336887 * 100, metric = 7.29% * 100;
 Minibatch[1201-1300]: loss = 0.353880 * 100, metric = 7.79% * 100;
 Minibatch[1301-1400]: loss = 0.348414 * 100, metric = 7.53% * 100;
 Minibatch[1401-1500]: loss = 0.325001 * 100, metric = 7.07% * 100;
 Minibatch[1501-1600]: loss = 0.336517 * 100, metric = 7.30% * 100;
 Minibatch[1601-1700]: loss = 0.320420 * 100, metric = 6.81% * 100;
 Minibatch[1701-1800]: loss = 0.333339 * 100, metric = 7.03% * 100;
 Minibatch[1801-1900]: loss = 0.328260 * 100, metric = 7.13% * 100;
 Minibatch[1901-2000]: loss = 0.329507 * 100, metric = 6.89% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.335922 * 2000, metric = 7.28% * 2000 898.426s (  2.2 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.20% * 2000;
 Minibatch[   1- 100]: loss = 0.341116 * 100, metric = 7.44% * 100;
 Minibatch[ 101- 200]: loss = 0.350507 * 100, metric = 7.58% * 100;
 Minibatch[ 201- 300]: loss = 0.336670 * 100, metric = 7.05% * 100;
 Minibatch[ 301- 400]: loss = 0.346037 * 100, metric = 7.46% * 100;
 Minibatch[ 401- 500]: loss = 0.338431 * 100, metric = 7.26% * 100;
 Minibatch[ 501- 600]: loss = 0.334438 * 100, metric = 7.14% * 100;
 Minibatch[ 601- 700]: loss = 0.343585 * 100, metric = 7.53% * 100;
 Minibatch[ 701- 800]: loss = 0.334019 * 100, metric = 7.25% * 100;
 Minibatch[ 801- 900]: loss = 0.357048 * 100, metric = 7.90% * 100;
 Minibatch[ 901-1000]: loss = 0.325614 * 100, metric = 6.98% * 100;
 Minibatch[1001-1100]: loss = 0.345856 * 100, metric = 7.43% * 100;
 Minibatch[1101-1200]: loss = 0.341867 * 100, metric = 7.49% * 100;
 Minibatch[1201-1300]: loss = 0.331242 * 100, metric = 7.21% * 100;
 Minibatch[1301-1400]: loss = 0.329600 * 100, metric = 7.20% * 100;
 Minibatch[1401-1500]: loss = 0.337668 * 100, metric = 7.52% * 100;
 Minibatch[1501-1600]: loss = 0.335046 * 100, metric = 7.32% * 100;
 Minibatch[1601-1700]: loss = 0.329184 * 100, metric = 7.12% * 100;
 Minibatch[1701-1800]: loss = 0.317687 * 100, metric = 6.80% * 100;
 Minibatch[1801-1900]: loss = 0.323531 * 100, metric = 6.93% * 100;
 Minibatch[1901-2000]: loss = 0.326711 * 100, metric = 6.97% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.336293 * 2000, metric = 7.28% * 2000 909.875s (  2.2 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 13.74% * 2000;
 Minibatch[   1- 100]: loss = 0.333032 * 100, metric = 7.05% * 100;
 Minibatch[ 101- 200]: loss = 0.330253 * 100, metric = 7.22% * 100;
 Minibatch[ 201- 300]: loss = 0.330566 * 100, metric = 7.02% * 100;
 Minibatch[ 301- 400]: loss = 0.337273 * 100, metric = 7.01% * 100;
 Minibatch[ 401- 500]: loss = 0.333183 * 100, metric = 7.35% * 100;
 Minibatch[ 501- 600]: loss = 0.340671 * 100, metric = 7.52% * 100;
 Minibatch[ 601- 700]: loss = 0.343865 * 100, metric = 7.58% * 100;
 Minibatch[ 701- 800]: loss = 0.338716 * 100, metric = 7.27% * 100;
 Minibatch[ 801- 900]: loss = 0.352268 * 100, metric = 7.78% * 100;
 Minibatch[ 901-1000]: loss = 0.344231 * 100, metric = 7.62% * 100;
 Minibatch[1001-1100]: loss = 0.326664 * 100, metric = 6.99% * 100;
 Minibatch[1101-1200]: loss = 0.328089 * 100, metric = 7.00% * 100;
 Minibatch[1201-1300]: loss = 0.334474 * 100, metric = 7.18% * 100;
 Minibatch[1301-1400]: loss = 0.346111 * 100, metric = 7.69% * 100;
 Minibatch[1401-1500]: loss = 0.326605 * 100, metric = 7.34% * 100;
 Minibatch[1501-1600]: loss = 0.340539 * 100, metric = 7.33% * 100;
 Minibatch[1601-1700]: loss = 0.332048 * 100, metric = 7.18% * 100;
 Minibatch[1701-1800]: loss = 0.338613 * 100, metric = 7.51% * 100;
 Minibatch[1801-1900]: loss = 0.327471 * 100, metric = 7.13% * 100;
 Minibatch[1901-2000]: loss = 0.324800 * 100, metric = 6.99% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.335474 * 2000, metric = 7.29% * 2000 911.643s (  2.2 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 14.42% * 2000;
 Minibatch[   1- 100]: loss = 0.329088 * 100, metric = 7.00% * 100;
 Minibatch[ 101- 200]: loss = 0.325488 * 100, metric = 6.98% * 100;
 Minibatch[ 201- 300]: loss = 0.327241 * 100, metric = 7.23% * 100;
 Minibatch[ 301- 400]: loss = 0.330522 * 100, metric = 7.27% * 100;
 Minibatch[ 401- 500]: loss = 0.312326 * 100, metric = 6.61% * 100;
 Minibatch[ 501- 600]: loss = 0.313326 * 100, metric = 6.58% * 100;
 Minibatch[ 601- 700]: loss = 0.319542 * 100, metric = 6.94% * 100;
 Minibatch[ 701- 800]: loss = 0.298115 * 100, metric = 6.18% * 100;
 Minibatch[ 801- 900]: loss = 0.325716 * 100, metric = 7.06% * 100;
 Minibatch[ 901-1000]: loss = 0.312318 * 100, metric = 6.70% * 100;
 Minibatch[1001-1100]: loss = 0.318971 * 100, metric = 6.83% * 100;
 Minibatch[1101-1200]: loss = 0.312092 * 100, metric = 6.71% * 100;
 Minibatch[1201-1300]: loss = 0.317877 * 100, metric = 6.72% * 100;
 Minibatch[1301-1400]: loss = 0.315905 * 100, metric = 6.69% * 100;
 Minibatch[1401-1500]: loss = 0.330843 * 100, metric = 7.21% * 100;
 Minibatch[1501-1600]: loss = 0.332187 * 100, metric = 7.37% * 100;
 Minibatch[1601-1700]: loss = 0.320629 * 100, metric = 6.96% * 100;
 Minibatch[1701-1800]: loss = 0.323945 * 100, metric = 6.88% * 100;
 Minibatch[1801-1900]: loss = 0.334721 * 100, metric = 7.27% * 100;
 Minibatch[1901-2000]: loss = 0.311630 * 100, metric = 6.53% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.320624 * 2000, metric = 6.89% * 2000 901.640s (  2.2 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 12.89% * 2000;
0.46290124805644156
 Minibatch[   1- 100]: loss = 0.333190 * 100, metric = 7.28% * 100;
 Minibatch[ 101- 200]: loss = 0.327809 * 100, metric = 7.00% * 100;
 Minibatch[ 201- 300]: loss = 0.323531 * 100, metric = 7.09% * 100;
 Minibatch[ 301- 400]: loss = 0.323487 * 100, metric = 6.95% * 100;
 Minibatch[ 401- 500]: loss = 0.318633 * 100, metric = 6.85% * 100;
 Minibatch[ 501- 600]: loss = 0.334739 * 100, metric = 7.32% * 100;
 Minibatch[ 601- 700]: loss = 0.318390 * 100, metric = 6.78% * 100;
 Minibatch[ 701- 800]: loss = 0.318115 * 100, metric = 6.88% * 100;
 Minibatch[ 801- 900]: loss = 0.322564 * 100, metric = 6.78% * 100;
 Minibatch[ 901-1000]: loss = 0.333812 * 100, metric = 7.18% * 100;
 Minibatch[1001-1100]: loss = 0.317434 * 100, metric = 6.69% * 100;
 Minibatch[1101-1200]: loss = 0.301425 * 100, metric = 6.37% * 100;
 Minibatch[1201-1300]: loss = 0.319590 * 100, metric = 6.87% * 100;
 Minibatch[1301-1400]: loss = 0.319631 * 100, metric = 6.82% * 100;
 Minibatch[1401-1500]: loss = 0.316983 * 100, metric = 6.74% * 100;
 Minibatch[1501-1600]: loss = 0.313166 * 100, metric = 6.49% * 100;
 Minibatch[1601-1700]: loss = 0.315888 * 100, metric = 6.64% * 100;
 Minibatch[1701-1800]: loss = 0.314997 * 100, metric = 6.57% * 100;
 Minibatch[1801-1900]: loss = 0.320905 * 100, metric = 6.81% * 100;
 Minibatch[1901-2000]: loss = 0.316575 * 100, metric = 6.69% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.320543 * 2000, metric = 6.84% * 2000 897.234s (  2.2 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 13.57% * 2000;
 Minibatch[   1- 100]: loss = 0.328114 * 100, metric = 6.94% * 100;
 Minibatch[ 101- 200]: loss = 0.327557 * 100, metric = 7.27% * 100;
 Minibatch[ 201- 300]: loss = 0.317869 * 100, metric = 6.99% * 100;
 Minibatch[ 301- 400]: loss = 0.320378 * 100, metric = 6.96% * 100;
 Minibatch[ 401- 500]: loss = 0.326427 * 100, metric = 6.96% * 100;
 Minibatch[ 501- 600]: loss = 0.322899 * 100, metric = 6.78% * 100;
 Minibatch[ 601- 700]: loss = 0.318432 * 100, metric = 6.70% * 100;
 Minibatch[ 701- 800]: loss = 0.304700 * 100, metric = 6.35% * 100;
 Minibatch[ 801- 900]: loss = 0.307667 * 100, metric = 6.57% * 100;
 Minibatch[ 901-1000]: loss = 0.324265 * 100, metric = 6.88% * 100;
 Minibatch[1001-1100]: loss = 0.309647 * 100, metric = 6.36% * 100;
 Minibatch[1101-1200]: loss = 0.315576 * 100, metric = 6.72% * 100;
 Minibatch[1201-1300]: loss = 0.319028 * 100, metric = 6.67% * 100;
 Minibatch[1301-1400]: loss = 0.327047 * 100, metric = 7.10% * 100;
 Minibatch[1401-1500]: loss = 0.312471 * 100, metric = 6.58% * 100;
 Minibatch[1501-1600]: loss = 0.318430 * 100, metric = 6.91% * 100;
 Minibatch[1601-1700]: loss = 0.309650 * 100, metric = 6.51% * 100;
 Minibatch[1701-1800]: loss = 0.315795 * 100, metric = 6.93% * 100;
 Minibatch[1801-1900]: loss = 0.309812 * 100, metric = 6.71% * 100;
 Minibatch[1901-2000]: loss = 0.313710 * 100, metric = 6.51% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.317474 * 2000, metric = 6.77% * 2000 905.437s (  2.2 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 14.52% * 2000;
 Minibatch[   1- 100]: loss = 0.301951 * 100, metric = 6.35% * 100;
 Minibatch[ 101- 200]: loss = 0.316964 * 100, metric = 6.90% * 100;
 Minibatch[ 201- 300]: loss = 0.308749 * 100, metric = 6.75% * 100;
 Minibatch[ 301- 400]: loss = 0.312213 * 100, metric = 6.66% * 100;
 Minibatch[ 401- 500]: loss = 0.311342 * 100, metric = 6.74% * 100;
 Minibatch[ 501- 600]: loss = 0.295973 * 100, metric = 6.32% * 100;
 Minibatch[ 601- 700]: loss = 0.317694 * 100, metric = 6.71% * 100;
 Minibatch[ 701- 800]: loss = 0.306015 * 100, metric = 6.76% * 100;
 Minibatch[ 801- 900]: loss = 0.319114 * 100, metric = 6.87% * 100;
 Minibatch[ 901-1000]: loss = 0.311241 * 100, metric = 6.85% * 100;
 Minibatch[1001-1100]: loss = 0.310312 * 100, metric = 6.74% * 100;
 Minibatch[1101-1200]: loss = 0.317655 * 100, metric = 6.81% * 100;
 Minibatch[1201-1300]: loss = 0.305456 * 100, metric = 6.38% * 100;
 Minibatch[1301-1400]: loss = 0.303740 * 100, metric = 6.59% * 100;
 Minibatch[1401-1500]: loss = 0.308706 * 100, metric = 6.54% * 100;
 Minibatch[1501-1600]: loss = 0.313733 * 100, metric = 6.68% * 100;
 Minibatch[1601-1700]: loss = 0.299340 * 100, metric = 6.48% * 100;
 Minibatch[1701-1800]: loss = 0.303147 * 100, metric = 6.46% * 100;
 Minibatch[1801-1900]: loss = 0.312512 * 100, metric = 6.88% * 100;
 Minibatch[1901-2000]: loss = 0.315438 * 100, metric = 6.89% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.309565 * 2000, metric = 6.67% * 2000 902.579s (  2.2 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.09% * 2000;
 Minibatch[   1- 100]: loss = 0.316320 * 100, metric = 6.89% * 100;
 Minibatch[ 101- 200]: loss = 0.308698 * 100, metric = 6.66% * 100;
 Minibatch[ 201- 300]: loss = 0.310037 * 100, metric = 6.72% * 100;
 Minibatch[ 301- 400]: loss = 0.314751 * 100, metric = 6.86% * 100;
 Minibatch[ 401- 500]: loss = 0.306910 * 100, metric = 6.60% * 100;
 Minibatch[ 501- 600]: loss = 0.309994 * 100, metric = 6.71% * 100;
 Minibatch[ 601- 700]: loss = 0.310191 * 100, metric = 6.78% * 100;
 Minibatch[ 701- 800]: loss = 0.302645 * 100, metric = 6.49% * 100;
 Minibatch[ 801- 900]: loss = 0.300052 * 100, metric = 6.51% * 100;
 Minibatch[ 901-1000]: loss = 0.305931 * 100, metric = 6.66% * 100;
 Minibatch[1001-1100]: loss = 0.308624 * 100, metric = 6.91% * 100;
 Minibatch[1101-1200]: loss = 0.316508 * 100, metric = 7.02% * 100;
 Minibatch[1201-1300]: loss = 0.321172 * 100, metric = 7.12% * 100;
 Minibatch[1301-1400]: loss = 0.305197 * 100, metric = 6.63% * 100;
 Minibatch[1401-1500]: loss = 0.304775 * 100, metric = 6.39% * 100;
 Minibatch[1501-1600]: loss = 0.312284 * 100, metric = 6.89% * 100;
 Minibatch[1601-1700]: loss = 0.296985 * 100, metric = 6.33% * 100;
 Minibatch[1701-1800]: loss = 0.303586 * 100, metric = 6.55% * 100;
 Minibatch[1801-1900]: loss = 0.289855 * 100, metric = 6.05% * 100;
 Minibatch[1901-2000]: loss = 0.291312 * 100, metric = 6.26% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.306791 * 2000, metric = 6.65% * 2000 907.338s (  2.2 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.42% * 2000;
 Minibatch[   1- 100]: loss = 0.299575 * 100, metric = 6.37% * 100;
 Minibatch[ 101- 200]: loss = 0.278618 * 100, metric = 5.85% * 100;
 Minibatch[ 201- 300]: loss = 0.301633 * 100, metric = 6.62% * 100;
 Minibatch[ 301- 400]: loss = 0.289672 * 100, metric = 6.17% * 100;
 Minibatch[ 401- 500]: loss = 0.303839 * 100, metric = 6.52% * 100;
 Minibatch[ 501- 600]: loss = 0.291409 * 100, metric = 6.17% * 100;
 Minibatch[ 601- 700]: loss = 0.311026 * 100, metric = 6.54% * 100;
 Minibatch[ 701- 800]: loss = 0.294938 * 100, metric = 6.44% * 100;
 Minibatch[ 801- 900]: loss = 0.291926 * 100, metric = 6.13% * 100;
 Minibatch[ 901-1000]: loss = 0.291815 * 100, metric = 6.32% * 100;
 Minibatch[1001-1100]: loss = 0.302533 * 100, metric = 6.60% * 100;
 Minibatch[1101-1200]: loss = 0.307499 * 100, metric = 6.63% * 100;
 Minibatch[1201-1300]: loss = 0.296542 * 100, metric = 6.41% * 100;
 Minibatch[1301-1400]: loss = 0.284966 * 100, metric = 6.00% * 100;
 Minibatch[1401-1500]: loss = 0.294153 * 100, metric = 6.33% * 100;
 Minibatch[1501-1600]: loss = 0.295426 * 100, metric = 6.08% * 100;
 Minibatch[1601-1700]: loss = 0.310033 * 100, metric = 6.71% * 100;
 Minibatch[1701-1800]: loss = 0.306501 * 100, metric = 6.51% * 100;
 Minibatch[1801-1900]: loss = 0.296522 * 100, metric = 6.25% * 100;
 Minibatch[1901-2000]: loss = 0.301418 * 100, metric = 6.48% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.297502 * 2000, metric = 6.36% * 2000 900.727s (  2.2 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 14.87% * 2000;
 Minibatch[   1- 100]: loss = 0.298166 * 100, metric = 6.31% * 100;
 Minibatch[ 101- 200]: loss = 0.306963 * 100, metric = 6.58% * 100;
 Minibatch[ 201- 300]: loss = 0.294471 * 100, metric = 6.45% * 100;
 Minibatch[ 301- 400]: loss = 0.292380 * 100, metric = 6.26% * 100;
 Minibatch[ 401- 500]: loss = 0.287188 * 100, metric = 5.99% * 100;
 Minibatch[ 501- 600]: loss = 0.290349 * 100, metric = 6.26% * 100;
 Minibatch[ 601- 700]: loss = 0.292686 * 100, metric = 6.19% * 100;
 Minibatch[ 701- 800]: loss = 0.284487 * 100, metric = 6.03% * 100;
 Minibatch[ 801- 900]: loss = 0.295730 * 100, metric = 6.30% * 100;
 Minibatch[ 901-1000]: loss = 0.288953 * 100, metric = 6.32% * 100;
 Minibatch[1001-1100]: loss = 0.285396 * 100, metric = 6.01% * 100;
 Minibatch[1101-1200]: loss = 0.296755 * 100, metric = 6.44% * 100;
 Minibatch[1201-1300]: loss = 0.292884 * 100, metric = 6.24% * 100;
 Minibatch[1301-1400]: loss = 0.299085 * 100, metric = 6.47% * 100;
 Minibatch[1401-1500]: loss = 0.285888 * 100, metric = 6.13% * 100;
 Minibatch[1501-1600]: loss = 0.289525 * 100, metric = 6.10% * 100;
 Minibatch[1601-1700]: loss = 0.274326 * 100, metric = 5.78% * 100;
 Minibatch[1701-1800]: loss = 0.285819 * 100, metric = 6.03% * 100;
 Minibatch[1801-1900]: loss = 0.288020 * 100, metric = 6.09% * 100;
 Minibatch[1901-2000]: loss = 0.293192 * 100, metric = 6.07% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.291113 * 2000, metric = 6.20% * 2000 894.708s (  2.2 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.65% * 2000;
 Minibatch[   1- 100]: loss = 0.299213 * 100, metric = 6.57% * 100;
 Minibatch[ 101- 200]: loss = 0.288704 * 100, metric = 6.06% * 100;
 Minibatch[ 201- 300]: loss = 0.293985 * 100, metric = 6.44% * 100;
 Minibatch[ 301- 400]: loss = 0.290564 * 100, metric = 6.13% * 100;
 Minibatch[ 401- 500]: loss = 0.294834 * 100, metric = 6.43% * 100;
 Minibatch[ 501- 600]: loss = 0.312902 * 100, metric = 6.81% * 100;
 Minibatch[ 601- 700]: loss = 0.293407 * 100, metric = 6.23% * 100;
 Minibatch[ 701- 800]: loss = 0.287162 * 100, metric = 6.03% * 100;
 Minibatch[ 801- 900]: loss = 0.293426 * 100, metric = 6.54% * 100;
 Minibatch[ 901-1000]: loss = 0.305621 * 100, metric = 6.62% * 100;
 Minibatch[1001-1100]: loss = 0.294461 * 100, metric = 6.26% * 100;
 Minibatch[1101-1200]: loss = 0.285261 * 100, metric = 6.00% * 100;
 Minibatch[1201-1300]: loss = 0.297393 * 100, metric = 6.35% * 100;
 Minibatch[1301-1400]: loss = 0.292438 * 100, metric = 6.36% * 100;
 Minibatch[1401-1500]: loss = 0.297940 * 100, metric = 6.41% * 100;
 Minibatch[1501-1600]: loss = 0.285995 * 100, metric = 6.08% * 100;
 Minibatch[1601-1700]: loss = 0.286897 * 100, metric = 5.82% * 100;
 Minibatch[1701-1800]: loss = 0.284185 * 100, metric = 5.97% * 100;
 Minibatch[1801-1900]: loss = 0.284664 * 100, metric = 6.00% * 100;
 Minibatch[1901-2000]: loss = 0.286969 * 100, metric = 5.86% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.292801 * 2000, metric = 6.25% * 2000 904.298s (  2.2 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.20% * 2000;
 Minibatch[   1- 100]: loss = 0.278699 * 100, metric = 5.82% * 100;
 Minibatch[ 101- 200]: loss = 0.280587 * 100, metric = 6.16% * 100;
 Minibatch[ 201- 300]: loss = 0.284930 * 100, metric = 6.10% * 100;
 Minibatch[ 301- 400]: loss = 0.300709 * 100, metric = 6.38% * 100;
 Minibatch[ 401- 500]: loss = 0.280196 * 100, metric = 6.01% * 100;
 Minibatch[ 501- 600]: loss = 0.289706 * 100, metric = 6.17% * 100;
 Minibatch[ 601- 700]: loss = 0.280263 * 100, metric = 6.01% * 100;
 Minibatch[ 701- 800]: loss = 0.292451 * 100, metric = 6.33% * 100;
 Minibatch[ 801- 900]: loss = 0.281913 * 100, metric = 6.11% * 100;
 Minibatch[ 901-1000]: loss = 0.296090 * 100, metric = 6.41% * 100;
 Minibatch[1001-1100]: loss = 0.290706 * 100, metric = 6.29% * 100;
 Minibatch[1101-1200]: loss = 0.286915 * 100, metric = 6.09% * 100;
 Minibatch[1201-1300]: loss = 0.293052 * 100, metric = 6.20% * 100;
 Minibatch[1301-1400]: loss = 0.281775 * 100, metric = 6.02% * 100;
 Minibatch[1401-1500]: loss = 0.290063 * 100, metric = 6.19% * 100;
 Minibatch[1501-1600]: loss = 0.275756 * 100, metric = 5.89% * 100;
 Minibatch[1601-1700]: loss = 0.286032 * 100, metric = 6.08% * 100;
 Minibatch[1701-1800]: loss = 0.278099 * 100, metric = 6.03% * 100;
 Minibatch[1801-1900]: loss = 0.291473 * 100, metric = 6.15% * 100;
 Minibatch[1901-2000]: loss = 0.287924 * 100, metric = 5.98% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.286367 * 2000, metric = 6.12% * 2000 903.219s (  2.2 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 14.20% * 2000;
 Minibatch[   1- 100]: loss = 0.304205 * 100, metric = 6.52% * 100;
 Minibatch[ 101- 200]: loss = 0.276796 * 100, metric = 5.80% * 100;
 Minibatch[ 201- 300]: loss = 0.280382 * 100, metric = 5.87% * 100;
 Minibatch[ 301- 400]: loss = 0.286909 * 100, metric = 6.26% * 100;
 Minibatch[ 401- 500]: loss = 0.285979 * 100, metric = 6.11% * 100;
 Minibatch[ 501- 600]: loss = 0.264741 * 100, metric = 5.33% * 100;
 Minibatch[ 601- 700]: loss = 0.282418 * 100, metric = 6.07% * 100;
 Minibatch[ 701- 800]: loss = 0.269035 * 100, metric = 5.57% * 100;
 Minibatch[ 801- 900]: loss = 0.280019 * 100, metric = 5.82% * 100;
 Minibatch[ 901-1000]: loss = 0.269958 * 100, metric = 5.68% * 100;
 Minibatch[1001-1100]: loss = 0.274973 * 100, metric = 5.67% * 100;
 Minibatch[1101-1200]: loss = 0.286862 * 100, metric = 6.18% * 100;
 Minibatch[1201-1300]: loss = 0.274096 * 100, metric = 5.78% * 100;
 Minibatch[1301-1400]: loss = 0.281389 * 100, metric = 6.05% * 100;
 Minibatch[1401-1500]: loss = 0.280453 * 100, metric = 6.01% * 100;
 Minibatch[1501-1600]: loss = 0.290569 * 100, metric = 6.14% * 100;
 Minibatch[1601-1700]: loss = 0.284110 * 100, metric = 6.05% * 100;
 Minibatch[1701-1800]: loss = 0.285004 * 100, metric = 6.07% * 100;
 Minibatch[1801-1900]: loss = 0.281799 * 100, metric = 5.93% * 100;
 Minibatch[1901-2000]: loss = 0.295254 * 100, metric = 6.32% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.281748 * 2000, metric = 5.96% * 2000 900.224s (  2.2 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 13.97% * 2000;
 Minibatch[   1- 100]: loss = 0.279284 * 100, metric = 5.88% * 100;
 Minibatch[ 101- 200]: loss = 0.292247 * 100, metric = 6.19% * 100;
 Minibatch[ 201- 300]: loss = 0.280340 * 100, metric = 5.98% * 100;
 Minibatch[ 301- 400]: loss = 0.279902 * 100, metric = 6.03% * 100;
 Minibatch[ 401- 500]: loss = 0.272557 * 100, metric = 5.70% * 100;
 Minibatch[ 501- 600]: loss = 0.273172 * 100, metric = 5.81% * 100;
 Minibatch[ 601- 700]: loss = 0.288046 * 100, metric = 6.16% * 100;
 Minibatch[ 701- 800]: loss = 0.289764 * 100, metric = 6.14% * 100;
 Minibatch[ 801- 900]: loss = 0.278650 * 100, metric = 5.82% * 100;
 Minibatch[ 901-1000]: loss = 0.278419 * 100, metric = 5.92% * 100;
 Minibatch[1001-1100]: loss = 0.276110 * 100, metric = 5.85% * 100;
 Minibatch[1101-1200]: loss = 0.278920 * 100, metric = 5.86% * 100;
 Minibatch[1201-1300]: loss = 0.274250 * 100, metric = 5.80% * 100;
 Minibatch[1301-1400]: loss = 0.271544 * 100, metric = 5.83% * 100;
 Minibatch[1401-1500]: loss = 0.286647 * 100, metric = 5.94% * 100;
 Minibatch[1501-1600]: loss = 0.265219 * 100, metric = 5.71% * 100;
 Minibatch[1601-1700]: loss = 0.275090 * 100, metric = 5.96% * 100;
 Minibatch[1701-1800]: loss = 0.279499 * 100, metric = 5.94% * 100;
 Minibatch[1801-1900]: loss = 0.281162 * 100, metric = 6.18% * 100;
 Minibatch[1901-2000]: loss = 0.276188 * 100, metric = 5.86% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.278851 * 2000, metric = 5.93% * 2000 906.834s (  2.2 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 13.95% * 2000;
 Minibatch[   1- 100]: loss = 0.274755 * 100, metric = 5.65% * 100;
 Minibatch[ 101- 200]: loss = 0.277508 * 100, metric = 5.77% * 100;
 Minibatch[ 201- 300]: loss = 0.288247 * 100, metric = 6.12% * 100;
 Minibatch[ 301- 400]: loss = 0.286981 * 100, metric = 6.00% * 100;
 Minibatch[ 401- 500]: loss = 0.279357 * 100, metric = 5.97% * 100;
 Minibatch[ 501- 600]: loss = 0.277359 * 100, metric = 5.84% * 100;
 Minibatch[ 601- 700]: loss = 0.275441 * 100, metric = 5.71% * 100;
 Minibatch[ 701- 800]: loss = 0.268356 * 100, metric = 5.64% * 100;
 Minibatch[ 801- 900]: loss = 0.271823 * 100, metric = 5.82% * 100;
 Minibatch[ 901-1000]: loss = 0.263044 * 100, metric = 5.54% * 100;
 Minibatch[1001-1100]: loss = 0.266526 * 100, metric = 5.59% * 100;
 Minibatch[1101-1200]: loss = 0.275571 * 100, metric = 5.86% * 100;
 Minibatch[1201-1300]: loss = 0.277139 * 100, metric = 5.77% * 100;
 Minibatch[1301-1400]: loss = 0.269693 * 100, metric = 5.59% * 100;
 Minibatch[1401-1500]: loss = 0.268382 * 100, metric = 5.81% * 100;
 Minibatch[1501-1600]: loss = 0.275763 * 100, metric = 5.83% * 100;
 Minibatch[1601-1700]: loss = 0.271525 * 100, metric = 5.74% * 100;
 Minibatch[1701-1800]: loss = 0.282505 * 100, metric = 6.00% * 100;
 Minibatch[1801-1900]: loss = 0.266170 * 100, metric = 5.55% * 100;
 Minibatch[1901-2000]: loss = 0.276232 * 100, metric = 6.03% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.274619 * 2000, metric = 5.79% * 2000 905.696s (  2.2 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.30% * 2000;
 Minibatch[   1- 100]: loss = 0.284768 * 100, metric = 6.21% * 100;
 Minibatch[ 101- 200]: loss = 0.278083 * 100, metric = 6.09% * 100;
 Minibatch[ 201- 300]: loss = 0.273670 * 100, metric = 5.99% * 100;
 Minibatch[ 301- 400]: loss = 0.274834 * 100, metric = 5.93% * 100;
 Minibatch[ 401- 500]: loss = 0.276270 * 100, metric = 5.94% * 100;
 Minibatch[ 501- 600]: loss = 0.277842 * 100, metric = 5.95% * 100;
 Minibatch[ 601- 700]: loss = 0.281601 * 100, metric = 6.13% * 100;
 Minibatch[ 701- 800]: loss = 0.280687 * 100, metric = 5.96% * 100;
 Minibatch[ 801- 900]: loss = 0.274472 * 100, metric = 5.66% * 100;
 Minibatch[ 901-1000]: loss = 0.264938 * 100, metric = 5.67% * 100;
 Minibatch[1001-1100]: loss = 0.271883 * 100, metric = 5.79% * 100;
 Minibatch[1101-1200]: loss = 0.265114 * 100, metric = 5.58% * 100;
 Minibatch[1201-1300]: loss = 0.281539 * 100, metric = 5.72% * 100;
 Minibatch[1301-1400]: loss = 0.263148 * 100, metric = 5.37% * 100;
 Minibatch[1401-1500]: loss = 0.283636 * 100, metric = 5.87% * 100;
 Minibatch[1501-1600]: loss = 0.280486 * 100, metric = 5.83% * 100;
 Minibatch[1601-1700]: loss = 0.269254 * 100, metric = 5.46% * 100;
 Minibatch[1701-1800]: loss = 0.269603 * 100, metric = 5.71% * 100;
 Minibatch[1801-1900]: loss = 0.269241 * 100, metric = 5.75% * 100;
 Minibatch[1901-2000]: loss = 0.284068 * 100, metric = 6.10% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.275257 * 2000, metric = 5.84% * 2000 894.454s (  2.2 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.26% * 2000;
 Minibatch[   1- 100]: loss = 0.265402 * 100, metric = 5.64% * 100;
 Minibatch[ 101- 200]: loss = 0.268133 * 100, metric = 5.56% * 100;
 Minibatch[ 201- 300]: loss = 0.262169 * 100, metric = 5.54% * 100;
 Minibatch[ 301- 400]: loss = 0.270351 * 100, metric = 5.76% * 100;
 Minibatch[ 401- 500]: loss = 0.260785 * 100, metric = 5.53% * 100;
 Minibatch[ 501- 600]: loss = 0.274092 * 100, metric = 5.93% * 100;
 Minibatch[ 601- 700]: loss = 0.269866 * 100, metric = 5.92% * 100;
 Minibatch[ 701- 800]: loss = 0.261562 * 100, metric = 5.52% * 100;
 Minibatch[ 801- 900]: loss = 0.260289 * 100, metric = 5.34% * 100;
 Minibatch[ 901-1000]: loss = 0.262843 * 100, metric = 5.62% * 100;
 Minibatch[1001-1100]: loss = 0.265085 * 100, metric = 5.65% * 100;
 Minibatch[1101-1200]: loss = 0.269066 * 100, metric = 5.76% * 100;
 Minibatch[1201-1300]: loss = 0.270293 * 100, metric = 5.69% * 100;
 Minibatch[1301-1400]: loss = 0.265186 * 100, metric = 5.67% * 100;
 Minibatch[1401-1500]: loss = 0.276517 * 100, metric = 5.87% * 100;
 Minibatch[1501-1600]: loss = 0.272853 * 100, metric = 5.90% * 100;
 Minibatch[1601-1700]: loss = 0.279205 * 100, metric = 6.24% * 100;
 Minibatch[1701-1800]: loss = 0.267832 * 100, metric = 5.71% * 100;
 Minibatch[1801-1900]: loss = 0.263269 * 100, metric = 5.62% * 100;
 Minibatch[1901-2000]: loss = 0.271118 * 100, metric = 5.76% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.267796 * 2000, metric = 5.71% * 2000 899.907s (  2.2 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.61% * 2000;
 Minibatch[   1- 100]: loss = 0.258704 * 100, metric = 5.35% * 100;
 Minibatch[ 101- 200]: loss = 0.270938 * 100, metric = 5.83% * 100;
 Minibatch[ 201- 300]: loss = 0.279420 * 100, metric = 6.00% * 100;
 Minibatch[ 301- 400]: loss = 0.260893 * 100, metric = 5.52% * 100;
 Minibatch[ 401- 500]: loss = 0.264179 * 100, metric = 5.59% * 100;
 Minibatch[ 501- 600]: loss = 0.253179 * 100, metric = 5.35% * 100;
 Minibatch[ 601- 700]: loss = 0.276539 * 100, metric = 6.11% * 100;
 Minibatch[ 701- 800]: loss = 0.255478 * 100, metric = 5.42% * 100;
 Minibatch[ 801- 900]: loss = 0.265799 * 100, metric = 5.68% * 100;
 Minibatch[ 901-1000]: loss = 0.257019 * 100, metric = 5.45% * 100;
 Minibatch[1001-1100]: loss = 0.273554 * 100, metric = 5.94% * 100;
 Minibatch[1101-1200]: loss = 0.267808 * 100, metric = 5.74% * 100;
 Minibatch[1201-1300]: loss = 0.268513 * 100, metric = 5.71% * 100;
 Minibatch[1301-1400]: loss = 0.261004 * 100, metric = 5.57% * 100;
 Minibatch[1401-1500]: loss = 0.266240 * 100, metric = 5.75% * 100;
 Minibatch[1501-1600]: loss = 0.266318 * 100, metric = 5.73% * 100;
 Minibatch[1601-1700]: loss = 0.266070 * 100, metric = 5.71% * 100;
 Minibatch[1701-1800]: loss = 0.262648 * 100, metric = 5.68% * 100;
 Minibatch[1801-1900]: loss = 0.274309 * 100, metric = 6.02% * 100;
 Minibatch[1901-2000]: loss = 0.258864 * 100, metric = 5.59% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.265374 * 2000, metric = 5.69% * 2000 905.614s (  2.2 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.25% * 2000;
 Minibatch[   1- 100]: loss = 0.267277 * 100, metric = 5.60% * 100;
 Minibatch[ 101- 200]: loss = 0.257192 * 100, metric = 5.35% * 100;
 Minibatch[ 201- 300]: loss = 0.275241 * 100, metric = 5.94% * 100;
 Minibatch[ 301- 400]: loss = 0.260408 * 100, metric = 5.57% * 100;
 Minibatch[ 401- 500]: loss = 0.256479 * 100, metric = 5.38% * 100;
 Minibatch[ 501- 600]: loss = 0.264769 * 100, metric = 5.53% * 100;
 Minibatch[ 601- 700]: loss = 0.271083 * 100, metric = 5.60% * 100;
 Minibatch[ 701- 800]: loss = 0.255181 * 100, metric = 5.50% * 100;
 Minibatch[ 801- 900]: loss = 0.253839 * 100, metric = 5.36% * 100;
 Minibatch[ 901-1000]: loss = 0.274115 * 100, metric = 5.89% * 100;
 Minibatch[1001-1100]: loss = 0.276259 * 100, metric = 5.93% * 100;
 Minibatch[1101-1200]: loss = 0.265018 * 100, metric = 5.73% * 100;
 Minibatch[1201-1300]: loss = 0.269898 * 100, metric = 5.84% * 100;
 Minibatch[1301-1400]: loss = 0.253111 * 100, metric = 5.20% * 100;
 Minibatch[1401-1500]: loss = 0.259213 * 100, metric = 5.36% * 100;
 Minibatch[1501-1600]: loss = 0.258580 * 100, metric = 5.47% * 100;
 Minibatch[1601-1700]: loss = 0.268601 * 100, metric = 5.84% * 100;
 Minibatch[1701-1800]: loss = 0.262858 * 100, metric = 5.57% * 100;
 Minibatch[1801-1900]: loss = 0.262004 * 100, metric = 5.43% * 100;
 Minibatch[1901-2000]: loss = 0.261881 * 100, metric = 5.53% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.263650 * 2000, metric = 5.58% * 2000 895.189s (  2.2 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.59% * 2000;
 Minibatch[   1- 100]: loss = 0.261660 * 100, metric = 5.60% * 100;
 Minibatch[ 101- 200]: loss = 0.265427 * 100, metric = 5.81% * 100;
 Minibatch[ 201- 300]: loss = 0.270416 * 100, metric = 5.86% * 100;
 Minibatch[ 301- 400]: loss = 0.265890 * 100, metric = 5.72% * 100;
 Minibatch[ 401- 500]: loss = 0.256602 * 100, metric = 5.56% * 100;
 Minibatch[ 501- 600]: loss = 0.258454 * 100, metric = 5.64% * 100;
 Minibatch[ 601- 700]: loss = 0.258728 * 100, metric = 5.42% * 100;
 Minibatch[ 701- 800]: loss = 0.268911 * 100, metric = 5.69% * 100;
 Minibatch[ 801- 900]: loss = 0.267674 * 100, metric = 5.59% * 100;
 Minibatch[ 901-1000]: loss = 0.249976 * 100, metric = 5.15% * 100;
 Minibatch[1001-1100]: loss = 0.256639 * 100, metric = 5.49% * 100;
 Minibatch[1101-1200]: loss = 0.278918 * 100, metric = 6.01% * 100;
 Minibatch[1201-1300]: loss = 0.272810 * 100, metric = 5.75% * 100;
 Minibatch[1301-1400]: loss = 0.260978 * 100, metric = 5.42% * 100;
 Minibatch[1401-1500]: loss = 0.267609 * 100, metric = 5.90% * 100;
 Minibatch[1501-1600]: loss = 0.248011 * 100, metric = 5.12% * 100;
 Minibatch[1601-1700]: loss = 0.260318 * 100, metric = 5.35% * 100;
 Minibatch[1701-1800]: loss = 0.254684 * 100, metric = 5.25% * 100;
 Minibatch[1801-1900]: loss = 0.261873 * 100, metric = 5.63% * 100;
 Minibatch[1901-2000]: loss = 0.262112 * 100, metric = 5.58% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.262385 * 2000, metric = 5.58% * 2000 896.505s (  2.2 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.53% * 2000;
 Minibatch[   1- 100]: loss = 0.264858 * 100, metric = 5.59% * 100;
 Minibatch[ 101- 200]: loss = 0.260787 * 100, metric = 5.47% * 100;
 Minibatch[ 201- 300]: loss = 0.245958 * 100, metric = 5.08% * 100;
 Minibatch[ 301- 400]: loss = 0.259128 * 100, metric = 5.34% * 100;
 Minibatch[ 401- 500]: loss = 0.255395 * 100, metric = 5.38% * 100;
 Minibatch[ 501- 600]: loss = 0.260794 * 100, metric = 5.43% * 100;
 Minibatch[ 601- 700]: loss = 0.252621 * 100, metric = 5.32% * 100;
 Minibatch[ 701- 800]: loss = 0.253491 * 100, metric = 5.33% * 100;
 Minibatch[ 801- 900]: loss = 0.255849 * 100, metric = 5.34% * 100;
 Minibatch[ 901-1000]: loss = 0.261388 * 100, metric = 5.47% * 100;
 Minibatch[1001-1100]: loss = 0.264291 * 100, metric = 5.65% * 100;
 Minibatch[1101-1200]: loss = 0.251375 * 100, metric = 5.36% * 100;
 Minibatch[1201-1300]: loss = 0.263774 * 100, metric = 5.61% * 100;
 Minibatch[1301-1400]: loss = 0.270331 * 100, metric = 5.77% * 100;
 Minibatch[1401-1500]: loss = 0.261923 * 100, metric = 5.49% * 100;
 Minibatch[1501-1600]: loss = 0.267151 * 100, metric = 5.86% * 100;
 Minibatch[1601-1700]: loss = 0.254242 * 100, metric = 5.40% * 100;
 Minibatch[1701-1800]: loss = 0.261012 * 100, metric = 5.54% * 100;
 Minibatch[1801-1900]: loss = 0.265596 * 100, metric = 5.62% * 100;
 Minibatch[1901-2000]: loss = 0.258592 * 100, metric = 5.46% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.259428 * 2000, metric = 5.47% * 2000 907.849s (  2.2 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 13.22% * 2000;
 Minibatch[   1- 100]: loss = 0.259212 * 100, metric = 5.49% * 100;
 Minibatch[ 101- 200]: loss = 0.265122 * 100, metric = 5.65% * 100;
 Minibatch[ 201- 300]: loss = 0.263807 * 100, metric = 5.47% * 100;
 Minibatch[ 301- 400]: loss = 0.254383 * 100, metric = 5.33% * 100;
 Minibatch[ 401- 500]: loss = 0.251837 * 100, metric = 5.26% * 100;
 Minibatch[ 501- 600]: loss = 0.263114 * 100, metric = 5.49% * 100;
 Minibatch[ 601- 700]: loss = 0.260046 * 100, metric = 5.48% * 100;
 Minibatch[ 701- 800]: loss = 0.262707 * 100, metric = 5.50% * 100;
 Minibatch[ 801- 900]: loss = 0.251657 * 100, metric = 5.29% * 100;
 Minibatch[ 901-1000]: loss = 0.258456 * 100, metric = 5.31% * 100;
 Minibatch[1001-1100]: loss = 0.261752 * 100, metric = 5.66% * 100;
 Minibatch[1101-1200]: loss = 0.257564 * 100, metric = 5.54% * 100;
 Minibatch[1201-1300]: loss = 0.258918 * 100, metric = 5.28% * 100;
 Minibatch[1301-1400]: loss = 0.269025 * 100, metric = 5.64% * 100;
 Minibatch[1401-1500]: loss = 0.265449 * 100, metric = 5.62% * 100;
 Minibatch[1501-1600]: loss = 0.265817 * 100, metric = 5.46% * 100;
 Minibatch[1601-1700]: loss = 0.253560 * 100, metric = 5.21% * 100;
 Minibatch[1701-1800]: loss = 0.264855 * 100, metric = 5.64% * 100;
 Minibatch[1801-1900]: loss = 0.252660 * 100, metric = 5.24% * 100;
 Minibatch[1901-2000]: loss = 0.260861 * 100, metric = 5.28% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.260040 * 2000, metric = 5.44% * 2000 901.980s (  2.2 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.59% * 2000;
 Minibatch[   1- 100]: loss = 0.256978 * 100, metric = 5.48% * 100;
 Minibatch[ 101- 200]: loss = 0.249265 * 100, metric = 5.18% * 100;
 Minibatch[ 201- 300]: loss = 0.263399 * 100, metric = 5.61% * 100;
 Minibatch[ 301- 400]: loss = 0.255788 * 100, metric = 5.35% * 100;
 Minibatch[ 401- 500]: loss = 0.256321 * 100, metric = 5.32% * 100;
 Minibatch[ 501- 600]: loss = 0.254074 * 100, metric = 5.18% * 100;
 Minibatch[ 601- 700]: loss = 0.264866 * 100, metric = 5.57% * 100;
 Minibatch[ 701- 800]: loss = 0.248723 * 100, metric = 5.27% * 100;
 Minibatch[ 801- 900]: loss = 0.247252 * 100, metric = 5.10% * 100;
 Minibatch[ 901-1000]: loss = 0.247048 * 100, metric = 5.04% * 100;
 Minibatch[1001-1100]: loss = 0.259086 * 100, metric = 5.46% * 100;
 Minibatch[1101-1200]: loss = 0.259325 * 100, metric = 5.39% * 100;
 Minibatch[1201-1300]: loss = 0.258333 * 100, metric = 5.39% * 100;
 Minibatch[1301-1400]: loss = 0.254921 * 100, metric = 5.26% * 100;
 Minibatch[1401-1500]: loss = 0.254085 * 100, metric = 5.28% * 100;
 Minibatch[1501-1600]: loss = 0.259498 * 100, metric = 5.20% * 100;
 Minibatch[1601-1700]: loss = 0.260285 * 100, metric = 5.48% * 100;
 Minibatch[1701-1800]: loss = 0.249133 * 100, metric = 4.96% * 100;
 Minibatch[1801-1900]: loss = 0.247233 * 100, metric = 5.00% * 100;
 Minibatch[1901-2000]: loss = 0.249439 * 100, metric = 5.19% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.254753 * 2000, metric = 5.28% * 2000 896.210s (  2.2 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 13.70% * 2000;
 Minibatch[   1- 100]: loss = 0.247680 * 100, metric = 5.26% * 100;
 Minibatch[ 101- 200]: loss = 0.250243 * 100, metric = 5.15% * 100;
 Minibatch[ 201- 300]: loss = 0.257448 * 100, metric = 5.32% * 100;
 Minibatch[ 301- 400]: loss = 0.261033 * 100, metric = 5.47% * 100;
 Minibatch[ 401- 500]: loss = 0.256487 * 100, metric = 5.31% * 100;
 Minibatch[ 501- 600]: loss = 0.245596 * 100, metric = 4.95% * 100;
 Minibatch[ 601- 700]: loss = 0.254177 * 100, metric = 5.17% * 100;
 Minibatch[ 701- 800]: loss = 0.251446 * 100, metric = 5.14% * 100;
 Minibatch[ 801- 900]: loss = 0.244740 * 100, metric = 5.09% * 100;
 Minibatch[ 901-1000]: loss = 0.249290 * 100, metric = 5.05% * 100;
 Minibatch[1001-1100]: loss = 0.252881 * 100, metric = 5.10% * 100;
 Minibatch[1101-1200]: loss = 0.258811 * 100, metric = 5.53% * 100;
 Minibatch[1201-1300]: loss = 0.260244 * 100, metric = 5.45% * 100;
 Minibatch[1301-1400]: loss = 0.240457 * 100, metric = 5.02% * 100;
 Minibatch[1401-1500]: loss = 0.249069 * 100, metric = 5.11% * 100;
 Minibatch[1501-1600]: loss = 0.251371 * 100, metric = 5.20% * 100;
 Minibatch[1601-1700]: loss = 0.247997 * 100, metric = 5.19% * 100;
 Minibatch[1701-1800]: loss = 0.249207 * 100, metric = 5.19% * 100;
 Minibatch[1801-1900]: loss = 0.248224 * 100, metric = 5.23% * 100;
 Minibatch[1901-2000]: loss = 0.243341 * 100, metric = 4.96% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.250987 * 2000, metric = 5.19% * 2000 897.923s (  2.2 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 14.33% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
