Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.253026 * 100, metric = 24.15% * 100;
 Minibatch[ 101- 200]: loss = 1.052974 * 100, metric = 22.70% * 100;
 Minibatch[ 201- 300]: loss = 0.916277 * 100, metric = 20.80% * 100;
 Minibatch[ 301- 400]: loss = 0.860269 * 100, metric = 19.25% * 100;
 Minibatch[ 401- 500]: loss = 0.796709 * 100, metric = 17.85% * 100;
 Minibatch[ 501- 600]: loss = 0.769538 * 100, metric = 16.47% * 100;
 Minibatch[ 601- 700]: loss = 0.729186 * 100, metric = 15.71% * 100;
 Minibatch[ 701- 800]: loss = 0.692747 * 100, metric = 15.21% * 100;
 Minibatch[ 801- 900]: loss = 0.717676 * 100, metric = 15.27% * 100;
 Minibatch[ 901-1000]: loss = 0.728085 * 100, metric = 15.86% * 100;
 Minibatch[1001-1100]: loss = 0.704711 * 100, metric = 15.23% * 100;
 Minibatch[1101-1200]: loss = 0.694295 * 100, metric = 14.56% * 100;
 Minibatch[1201-1300]: loss = 0.675479 * 100, metric = 14.50% * 100;
 Minibatch[1301-1400]: loss = 0.661770 * 100, metric = 13.96% * 100;
 Minibatch[1401-1500]: loss = 0.681776 * 100, metric = 14.17% * 100;
 Minibatch[1501-1600]: loss = 0.649229 * 100, metric = 13.97% * 100;
 Minibatch[1601-1700]: loss = 0.630355 * 100, metric = 13.42% * 100;
 Minibatch[1701-1800]: loss = 0.642396 * 100, metric = 13.82% * 100;
 Minibatch[1801-1900]: loss = 0.643873 * 100, metric = 13.96% * 100;
 Minibatch[1901-2000]: loss = 0.613645 * 100, metric = 13.06% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.755701 * 2000, metric = 16.20% * 2000 1007.908s (  2.0 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 23.24% * 2000;
0.7196739559024572
 Minibatch[   1- 100]: loss = 0.608465 * 100, metric = 12.85% * 100;
 Minibatch[ 101- 200]: loss = 0.630788 * 100, metric = 13.46% * 100;
 Minibatch[ 201- 300]: loss = 0.613381 * 100, metric = 12.53% * 100;
 Minibatch[ 301- 400]: loss = 0.611941 * 100, metric = 12.66% * 100;
 Minibatch[ 401- 500]: loss = 0.598644 * 100, metric = 12.51% * 100;
 Minibatch[ 501- 600]: loss = 0.601909 * 100, metric = 12.29% * 100;
 Minibatch[ 601- 700]: loss = 0.580522 * 100, metric = 12.02% * 100;
 Minibatch[ 701- 800]: loss = 0.594495 * 100, metric = 12.61% * 100;
 Minibatch[ 801- 900]: loss = 0.558772 * 100, metric = 11.80% * 100;
 Minibatch[ 901-1000]: loss = 0.559871 * 100, metric = 11.57% * 100;
 Minibatch[1001-1100]: loss = 0.578752 * 100, metric = 12.21% * 100;
 Minibatch[1101-1200]: loss = 0.576030 * 100, metric = 11.93% * 100;
 Minibatch[1201-1300]: loss = 0.569286 * 100, metric = 11.84% * 100;
 Minibatch[1301-1400]: loss = 0.586412 * 100, metric = 12.24% * 100;
 Minibatch[1401-1500]: loss = 0.559299 * 100, metric = 11.54% * 100;
 Minibatch[1501-1600]: loss = 0.566057 * 100, metric = 11.44% * 100;
 Minibatch[1601-1700]: loss = 0.569262 * 100, metric = 11.76% * 100;
 Minibatch[1701-1800]: loss = 0.580374 * 100, metric = 11.69% * 100;
 Minibatch[1801-1900]: loss = 0.567949 * 100, metric = 11.63% * 100;
 Minibatch[1901-2000]: loss = 0.534834 * 100, metric = 10.99% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.582352 * 2000, metric = 12.08% * 2000 940.721s (  2.1 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 20.68% * 2000;
0.6513319827318191
 Minibatch[   1- 100]: loss = 0.557281 * 100, metric = 11.40% * 100;
 Minibatch[ 101- 200]: loss = 0.561662 * 100, metric = 11.48% * 100;
 Minibatch[ 201- 300]: loss = 0.539394 * 100, metric = 11.13% * 100;
 Minibatch[ 301- 400]: loss = 0.559289 * 100, metric = 11.62% * 100;
 Minibatch[ 401- 500]: loss = 0.556479 * 100, metric = 11.68% * 100;
 Minibatch[ 501- 600]: loss = 0.556386 * 100, metric = 11.55% * 100;
 Minibatch[ 601- 700]: loss = 0.563060 * 100, metric = 11.46% * 100;
 Minibatch[ 701- 800]: loss = 0.533441 * 100, metric = 10.64% * 100;
 Minibatch[ 801- 900]: loss = 0.564859 * 100, metric = 12.00% * 100;
 Minibatch[ 901-1000]: loss = 0.542377 * 100, metric = 11.04% * 100;
 Minibatch[1001-1100]: loss = 0.555707 * 100, metric = 11.53% * 100;
 Minibatch[1101-1200]: loss = 0.535107 * 100, metric = 10.98% * 100;
 Minibatch[1201-1300]: loss = 0.532735 * 100, metric = 10.89% * 100;
 Minibatch[1301-1400]: loss = 0.551566 * 100, metric = 11.33% * 100;
 Minibatch[1401-1500]: loss = 0.556160 * 100, metric = 11.74% * 100;
 Minibatch[1501-1600]: loss = 0.535297 * 100, metric = 10.70% * 100;
 Minibatch[1601-1700]: loss = 0.527615 * 100, metric = 10.66% * 100;
 Minibatch[1701-1800]: loss = 0.542128 * 100, metric = 11.09% * 100;
 Minibatch[1801-1900]: loss = 0.529284 * 100, metric = 10.51% * 100;
 Minibatch[1901-2000]: loss = 0.522546 * 100, metric = 10.39% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.546119 * 2000, metric = 11.19% * 2000 955.480s (  2.1 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 19.09% * 2000;
0.6254874224364757
 Minibatch[   1- 100]: loss = 0.550003 * 100, metric = 10.85% * 100;
 Minibatch[ 101- 200]: loss = 0.517339 * 100, metric = 10.53% * 100;
 Minibatch[ 201- 300]: loss = 0.539853 * 100, metric = 11.07% * 100;
 Minibatch[ 301- 400]: loss = 0.505438 * 100, metric = 10.03% * 100;
 Minibatch[ 401- 500]: loss = 0.533448 * 100, metric = 10.96% * 100;
 Minibatch[ 501- 600]: loss = 0.509135 * 100, metric = 10.06% * 100;
 Minibatch[ 601- 700]: loss = 0.515581 * 100, metric = 10.34% * 100;
 Minibatch[ 701- 800]: loss = 0.523731 * 100, metric = 10.74% * 100;
 Minibatch[ 801- 900]: loss = 0.527206 * 100, metric = 10.52% * 100;
 Minibatch[ 901-1000]: loss = 0.529398 * 100, metric = 10.81% * 100;
 Minibatch[1001-1100]: loss = 0.528610 * 100, metric = 10.80% * 100;
 Minibatch[1101-1200]: loss = 0.499183 * 100, metric = 9.78% * 100;
 Minibatch[1201-1300]: loss = 0.504031 * 100, metric = 9.97% * 100;
 Minibatch[1301-1400]: loss = 0.521622 * 100, metric = 10.26% * 100;
 Minibatch[1401-1500]: loss = 0.522951 * 100, metric = 10.56% * 100;
 Minibatch[1501-1600]: loss = 0.491484 * 100, metric = 9.89% * 100;
 Minibatch[1601-1700]: loss = 0.518896 * 100, metric = 10.51% * 100;
 Minibatch[1701-1800]: loss = 0.523718 * 100, metric = 10.68% * 100;
 Minibatch[1801-1900]: loss = 0.510420 * 100, metric = 10.25% * 100;
 Minibatch[1901-2000]: loss = 0.497424 * 100, metric = 9.91% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.518474 * 2000, metric = 10.43% * 2000 946.653s (  2.1 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 19.53% * 2000;
 Minibatch[   1- 100]: loss = 0.527432 * 100, metric = 10.38% * 100;
 Minibatch[ 101- 200]: loss = 0.502598 * 100, metric = 10.00% * 100;
 Minibatch[ 201- 300]: loss = 0.500177 * 100, metric = 10.00% * 100;
 Minibatch[ 301- 400]: loss = 0.523215 * 100, metric = 10.69% * 100;
 Minibatch[ 401- 500]: loss = 0.487539 * 100, metric = 9.45% * 100;
 Minibatch[ 501- 600]: loss = 0.499629 * 100, metric = 9.72% * 100;
 Minibatch[ 601- 700]: loss = 0.500897 * 100, metric = 9.74% * 100;
 Minibatch[ 701- 800]: loss = 0.512875 * 100, metric = 10.22% * 100;
 Minibatch[ 801- 900]: loss = 0.497318 * 100, metric = 9.86% * 100;
 Minibatch[ 901-1000]: loss = 0.504011 * 100, metric = 10.22% * 100;
 Minibatch[1001-1100]: loss = 0.508349 * 100, metric = 10.26% * 100;
 Minibatch[1101-1200]: loss = 0.499292 * 100, metric = 9.90% * 100;
 Minibatch[1201-1300]: loss = 0.511469 * 100, metric = 10.02% * 100;
 Minibatch[1301-1400]: loss = 0.517610 * 100, metric = 10.33% * 100;
 Minibatch[1401-1500]: loss = 0.504824 * 100, metric = 10.16% * 100;
 Minibatch[1501-1600]: loss = 0.504377 * 100, metric = 10.08% * 100;
 Minibatch[1601-1700]: loss = 0.513778 * 100, metric = 10.37% * 100;
 Minibatch[1701-1800]: loss = 0.517881 * 100, metric = 10.36% * 100;
 Minibatch[1801-1900]: loss = 0.503588 * 100, metric = 10.08% * 100;
 Minibatch[1901-2000]: loss = 0.486155 * 100, metric = 9.61% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.506151 * 2000, metric = 10.07% * 2000 933.789s (  2.1 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 17.88% * 2000;
0.5980150569975377
 Minibatch[   1- 100]: loss = 0.486589 * 100, metric = 9.76% * 100;
 Minibatch[ 101- 200]: loss = 0.482934 * 100, metric = 9.76% * 100;
 Minibatch[ 201- 300]: loss = 0.499947 * 100, metric = 9.91% * 100;
 Minibatch[ 301- 400]: loss = 0.499617 * 100, metric = 9.84% * 100;
 Minibatch[ 401- 500]: loss = 0.474696 * 100, metric = 9.38% * 100;
 Minibatch[ 501- 600]: loss = 0.484308 * 100, metric = 9.79% * 100;
 Minibatch[ 601- 700]: loss = 0.479343 * 100, metric = 9.50% * 100;
 Minibatch[ 701- 800]: loss = 0.486514 * 100, metric = 9.61% * 100;
 Minibatch[ 801- 900]: loss = 0.498059 * 100, metric = 9.72% * 100;
 Minibatch[ 901-1000]: loss = 0.489809 * 100, metric = 9.81% * 100;
 Minibatch[1001-1100]: loss = 0.489821 * 100, metric = 9.38% * 100;
 Minibatch[1101-1200]: loss = 0.495663 * 100, metric = 9.62% * 100;
 Minibatch[1201-1300]: loss = 0.500952 * 100, metric = 10.16% * 100;
 Minibatch[1301-1400]: loss = 0.489052 * 100, metric = 9.87% * 100;
 Minibatch[1401-1500]: loss = 0.498428 * 100, metric = 9.68% * 100;
 Minibatch[1501-1600]: loss = 0.471613 * 100, metric = 9.17% * 100;
 Minibatch[1601-1700]: loss = 0.477874 * 100, metric = 9.21% * 100;
 Minibatch[1701-1800]: loss = 0.466218 * 100, metric = 9.01% * 100;
 Minibatch[1801-1900]: loss = 0.490389 * 100, metric = 9.60% * 100;
 Minibatch[1901-2000]: loss = 0.478506 * 100, metric = 9.42% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.487017 * 2000, metric = 9.61% * 2000 940.273s (  2.1 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 17.24% * 2000;
0.581510683581233
 Minibatch[   1- 100]: loss = 0.478722 * 100, metric = 9.40% * 100;
 Minibatch[ 101- 200]: loss = 0.482833 * 100, metric = 9.22% * 100;
 Minibatch[ 201- 300]: loss = 0.486642 * 100, metric = 9.70% * 100;
 Minibatch[ 301- 400]: loss = 0.471431 * 100, metric = 9.14% * 100;
 Minibatch[ 401- 500]: loss = 0.485031 * 100, metric = 9.36% * 100;
 Minibatch[ 501- 600]: loss = 0.459012 * 100, metric = 9.01% * 100;
 Minibatch[ 601- 700]: loss = 0.475145 * 100, metric = 9.09% * 100;
 Minibatch[ 701- 800]: loss = 0.478256 * 100, metric = 9.18% * 100;
 Minibatch[ 801- 900]: loss = 0.485622 * 100, metric = 9.63% * 100;
 Minibatch[ 901-1000]: loss = 0.481472 * 100, metric = 9.69% * 100;
 Minibatch[1001-1100]: loss = 0.488996 * 100, metric = 9.70% * 100;
 Minibatch[1101-1200]: loss = 0.470975 * 100, metric = 9.16% * 100;
 Minibatch[1201-1300]: loss = 0.487120 * 100, metric = 9.67% * 100;
 Minibatch[1301-1400]: loss = 0.474999 * 100, metric = 9.36% * 100;
 Minibatch[1401-1500]: loss = 0.470886 * 100, metric = 9.14% * 100;
 Minibatch[1501-1600]: loss = 0.484285 * 100, metric = 9.52% * 100;
 Minibatch[1601-1700]: loss = 0.485278 * 100, metric = 9.60% * 100;
 Minibatch[1701-1800]: loss = 0.466921 * 100, metric = 9.02% * 100;
 Minibatch[1801-1900]: loss = 0.473994 * 100, metric = 9.44% * 100;
 Minibatch[1901-2000]: loss = 0.474176 * 100, metric = 9.52% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.478090 * 2000, metric = 9.38% * 2000 929.556s (  2.2 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 15.23% * 2000;
0.5406757258400321
 Minibatch[   1- 100]: loss = 0.479492 * 100, metric = 9.21% * 100;
 Minibatch[ 101- 200]: loss = 0.469696 * 100, metric = 9.14% * 100;
 Minibatch[ 201- 300]: loss = 0.452364 * 100, metric = 9.02% * 100;
 Minibatch[ 301- 400]: loss = 0.465350 * 100, metric = 9.21% * 100;
 Minibatch[ 401- 500]: loss = 0.482957 * 100, metric = 9.79% * 100;
 Minibatch[ 501- 600]: loss = 0.491491 * 100, metric = 9.75% * 100;
 Minibatch[ 601- 700]: loss = 0.455751 * 100, metric = 8.89% * 100;
 Minibatch[ 701- 800]: loss = 0.476328 * 100, metric = 9.34% * 100;
 Minibatch[ 801- 900]: loss = 0.456434 * 100, metric = 8.84% * 100;
 Minibatch[ 901-1000]: loss = 0.439500 * 100, metric = 8.63% * 100;
 Minibatch[1001-1100]: loss = 0.454297 * 100, metric = 8.85% * 100;
 Minibatch[1101-1200]: loss = 0.454225 * 100, metric = 8.86% * 100;
 Minibatch[1201-1300]: loss = 0.475015 * 100, metric = 9.23% * 100;
 Minibatch[1301-1400]: loss = 0.474351 * 100, metric = 9.46% * 100;
 Minibatch[1401-1500]: loss = 0.470833 * 100, metric = 9.28% * 100;
 Minibatch[1501-1600]: loss = 0.474669 * 100, metric = 9.42% * 100;
 Minibatch[1601-1700]: loss = 0.462145 * 100, metric = 9.17% * 100;
 Minibatch[1701-1800]: loss = 0.460550 * 100, metric = 8.79% * 100;
 Minibatch[1801-1900]: loss = 0.454553 * 100, metric = 8.71% * 100;
 Minibatch[1901-2000]: loss = 0.456698 * 100, metric = 8.55% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.465335 * 2000, metric = 9.11% * 2000 937.134s (  2.1 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 15.58% * 2000;
 Minibatch[   1- 100]: loss = 0.440960 * 100, metric = 8.35% * 100;
 Minibatch[ 101- 200]: loss = 0.466587 * 100, metric = 9.12% * 100;
 Minibatch[ 201- 300]: loss = 0.457396 * 100, metric = 8.73% * 100;
 Minibatch[ 301- 400]: loss = 0.467355 * 100, metric = 9.07% * 100;
 Minibatch[ 401- 500]: loss = 0.462227 * 100, metric = 8.91% * 100;
 Minibatch[ 501- 600]: loss = 0.455326 * 100, metric = 8.71% * 100;
 Minibatch[ 601- 700]: loss = 0.455880 * 100, metric = 8.96% * 100;
 Minibatch[ 701- 800]: loss = 0.436724 * 100, metric = 8.61% * 100;
 Minibatch[ 801- 900]: loss = 0.440035 * 100, metric = 8.49% * 100;
 Minibatch[ 901-1000]: loss = 0.457325 * 100, metric = 9.02% * 100;
 Minibatch[1001-1100]: loss = 0.433632 * 100, metric = 8.19% * 100;
 Minibatch[1101-1200]: loss = 0.456932 * 100, metric = 8.74% * 100;
 Minibatch[1201-1300]: loss = 0.443195 * 100, metric = 8.72% * 100;
 Minibatch[1301-1400]: loss = 0.434960 * 100, metric = 8.18% * 100;
 Minibatch[1401-1500]: loss = 0.457791 * 100, metric = 8.90% * 100;
 Minibatch[1501-1600]: loss = 0.448775 * 100, metric = 8.74% * 100;
 Minibatch[1601-1700]: loss = 0.455095 * 100, metric = 8.86% * 100;
 Minibatch[1701-1800]: loss = 0.436951 * 100, metric = 8.25% * 100;
 Minibatch[1801-1900]: loss = 0.436809 * 100, metric = 8.24% * 100;
 Minibatch[1901-2000]: loss = 0.454757 * 100, metric = 8.77% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.449936 * 2000, metric = 8.68% * 2000 921.751s (  2.2 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 14.72% * 2000;
0.5293817030489445
 Minibatch[   1- 100]: loss = 0.463806 * 100, metric = 9.20% * 100;
 Minibatch[ 101- 200]: loss = 0.435357 * 100, metric = 8.43% * 100;
 Minibatch[ 201- 300]: loss = 0.445340 * 100, metric = 8.63% * 100;
 Minibatch[ 301- 400]: loss = 0.433057 * 100, metric = 8.11% * 100;
 Minibatch[ 401- 500]: loss = 0.445343 * 100, metric = 8.56% * 100;
 Minibatch[ 501- 600]: loss = 0.416699 * 100, metric = 7.99% * 100;
 Minibatch[ 601- 700]: loss = 0.426955 * 100, metric = 8.21% * 100;
 Minibatch[ 701- 800]: loss = 0.409664 * 100, metric = 7.60% * 100;
 Minibatch[ 801- 900]: loss = 0.434760 * 100, metric = 8.35% * 100;
 Minibatch[ 901-1000]: loss = 0.440367 * 100, metric = 8.65% * 100;
 Minibatch[1001-1100]: loss = 0.441545 * 100, metric = 8.54% * 100;
 Minibatch[1101-1200]: loss = 0.441571 * 100, metric = 8.27% * 100;
 Minibatch[1201-1300]: loss = 0.446802 * 100, metric = 8.68% * 100;
 Minibatch[1301-1400]: loss = 0.441857 * 100, metric = 8.66% * 100;
 Minibatch[1401-1500]: loss = 0.437045 * 100, metric = 8.32% * 100;
 Minibatch[1501-1600]: loss = 0.434957 * 100, metric = 8.40% * 100;
 Minibatch[1601-1700]: loss = 0.439448 * 100, metric = 8.27% * 100;
 Minibatch[1701-1800]: loss = 0.448321 * 100, metric = 8.39% * 100;
 Minibatch[1801-1900]: loss = 0.447375 * 100, metric = 8.88% * 100;
 Minibatch[1901-2000]: loss = 0.429967 * 100, metric = 8.25% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.438012 * 2000, metric = 8.42% * 2000 922.866s (  2.2 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 14.86% * 2000;
 Minibatch[   1- 100]: loss = 0.425061 * 100, metric = 8.18% * 100;
 Minibatch[ 101- 200]: loss = 0.430044 * 100, metric = 8.09% * 100;
 Minibatch[ 201- 300]: loss = 0.451641 * 100, metric = 8.99% * 100;
 Minibatch[ 301- 400]: loss = 0.441936 * 100, metric = 8.51% * 100;
 Minibatch[ 401- 500]: loss = 0.435654 * 100, metric = 8.35% * 100;
 Minibatch[ 501- 600]: loss = 0.443730 * 100, metric = 8.53% * 100;
 Minibatch[ 601- 700]: loss = 0.429904 * 100, metric = 8.19% * 100;
 Minibatch[ 701- 800]: loss = 0.450149 * 100, metric = 8.61% * 100;
 Minibatch[ 801- 900]: loss = 0.435330 * 100, metric = 8.20% * 100;
 Minibatch[ 901-1000]: loss = 0.438526 * 100, metric = 8.22% * 100;
 Minibatch[1001-1100]: loss = 0.432332 * 100, metric = 7.97% * 100;
 Minibatch[1101-1200]: loss = 0.441566 * 100, metric = 8.69% * 100;
 Minibatch[1201-1300]: loss = 0.420893 * 100, metric = 8.13% * 100;
 Minibatch[1301-1400]: loss = 0.407054 * 100, metric = 7.70% * 100;
 Minibatch[1401-1500]: loss = 0.435156 * 100, metric = 8.44% * 100;
 Minibatch[1501-1600]: loss = 0.421769 * 100, metric = 8.24% * 100;
 Minibatch[1601-1700]: loss = 0.430595 * 100, metric = 8.18% * 100;
 Minibatch[1701-1800]: loss = 0.438227 * 100, metric = 8.60% * 100;
 Minibatch[1801-1900]: loss = 0.428174 * 100, metric = 8.18% * 100;
 Minibatch[1901-2000]: loss = 0.426160 * 100, metric = 8.35% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.433195 * 2000, metric = 8.32% * 2000 919.608s (  2.2 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 14.72% * 2000;
 Minibatch[   1- 100]: loss = 0.415616 * 100, metric = 7.97% * 100;
 Minibatch[ 101- 200]: loss = 0.410528 * 100, metric = 7.75% * 100;
 Minibatch[ 201- 300]: loss = 0.417189 * 100, metric = 8.25% * 100;
 Minibatch[ 301- 400]: loss = 0.445206 * 100, metric = 8.69% * 100;
 Minibatch[ 401- 500]: loss = 0.416597 * 100, metric = 7.74% * 100;
 Minibatch[ 501- 600]: loss = 0.406806 * 100, metric = 7.68% * 100;
 Minibatch[ 601- 700]: loss = 0.409323 * 100, metric = 7.98% * 100;
 Minibatch[ 701- 800]: loss = 0.420471 * 100, metric = 8.07% * 100;
 Minibatch[ 801- 900]: loss = 0.414526 * 100, metric = 7.78% * 100;
 Minibatch[ 901-1000]: loss = 0.422587 * 100, metric = 8.27% * 100;
 Minibatch[1001-1100]: loss = 0.422592 * 100, metric = 8.12% * 100;
 Minibatch[1101-1200]: loss = 0.431371 * 100, metric = 8.47% * 100;
 Minibatch[1201-1300]: loss = 0.427131 * 100, metric = 8.53% * 100;
 Minibatch[1301-1400]: loss = 0.415025 * 100, metric = 7.81% * 100;
 Minibatch[1401-1500]: loss = 0.424876 * 100, metric = 7.99% * 100;
 Minibatch[1501-1600]: loss = 0.398528 * 100, metric = 7.70% * 100;
 Minibatch[1601-1700]: loss = 0.432101 * 100, metric = 8.27% * 100;
 Minibatch[1701-1800]: loss = 0.409266 * 100, metric = 7.79% * 100;
 Minibatch[1801-1900]: loss = 0.415399 * 100, metric = 7.99% * 100;
 Minibatch[1901-2000]: loss = 0.425848 * 100, metric = 8.09% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.419049 * 2000, metric = 8.05% * 2000 903.223s (  2.2 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 15.96% * 2000;
 Minibatch[   1- 100]: loss = 0.425298 * 100, metric = 8.15% * 100;
 Minibatch[ 101- 200]: loss = 0.427449 * 100, metric = 8.60% * 100;
 Minibatch[ 201- 300]: loss = 0.417770 * 100, metric = 8.02% * 100;
 Minibatch[ 301- 400]: loss = 0.429025 * 100, metric = 8.19% * 100;
 Minibatch[ 401- 500]: loss = 0.430398 * 100, metric = 8.69% * 100;
 Minibatch[ 501- 600]: loss = 0.438905 * 100, metric = 8.47% * 100;
 Minibatch[ 601- 700]: loss = 0.408723 * 100, metric = 7.72% * 100;
 Minibatch[ 701- 800]: loss = 0.413038 * 100, metric = 7.88% * 100;
 Minibatch[ 801- 900]: loss = 0.413513 * 100, metric = 7.93% * 100;
 Minibatch[ 901-1000]: loss = 0.425032 * 100, metric = 8.02% * 100;
 Minibatch[1001-1100]: loss = 0.426776 * 100, metric = 8.28% * 100;
 Minibatch[1101-1200]: loss = 0.407071 * 100, metric = 7.76% * 100;
 Minibatch[1201-1300]: loss = 0.421709 * 100, metric = 8.14% * 100;
 Minibatch[1301-1400]: loss = 0.411648 * 100, metric = 7.88% * 100;
 Minibatch[1401-1500]: loss = 0.423171 * 100, metric = 8.20% * 100;
 Minibatch[1501-1600]: loss = 0.406999 * 100, metric = 7.53% * 100;
 Minibatch[1601-1700]: loss = 0.403354 * 100, metric = 7.62% * 100;
 Minibatch[1701-1800]: loss = 0.411313 * 100, metric = 7.90% * 100;
 Minibatch[1801-1900]: loss = 0.408575 * 100, metric = 7.77% * 100;
 Minibatch[1901-2000]: loss = 0.430876 * 100, metric = 8.40% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.419032 * 2000, metric = 8.06% * 2000 908.334s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 15.75% * 2000;
 Minibatch[   1- 100]: loss = 0.409418 * 100, metric = 7.65% * 100;
 Minibatch[ 101- 200]: loss = 0.403260 * 100, metric = 7.75% * 100;
 Minibatch[ 201- 300]: loss = 0.423286 * 100, metric = 8.36% * 100;
 Minibatch[ 301- 400]: loss = 0.416853 * 100, metric = 8.11% * 100;
 Minibatch[ 401- 500]: loss = 0.414208 * 100, metric = 7.94% * 100;
 Minibatch[ 501- 600]: loss = 0.409491 * 100, metric = 7.84% * 100;
 Minibatch[ 601- 700]: loss = 0.401489 * 100, metric = 7.62% * 100;
 Minibatch[ 701- 800]: loss = 0.431223 * 100, metric = 8.27% * 100;
 Minibatch[ 801- 900]: loss = 0.423608 * 100, metric = 8.23% * 100;
 Minibatch[ 901-1000]: loss = 0.413973 * 100, metric = 8.00% * 100;
 Minibatch[1001-1100]: loss = 0.414041 * 100, metric = 8.09% * 100;
 Minibatch[1101-1200]: loss = 0.403810 * 100, metric = 7.61% * 100;
 Minibatch[1201-1300]: loss = 0.390474 * 100, metric = 7.46% * 100;
 Minibatch[1301-1400]: loss = 0.413870 * 100, metric = 8.03% * 100;
 Minibatch[1401-1500]: loss = 0.416285 * 100, metric = 8.20% * 100;
 Minibatch[1501-1600]: loss = 0.399211 * 100, metric = 7.64% * 100;
 Minibatch[1601-1700]: loss = 0.409666 * 100, metric = 7.82% * 100;
 Minibatch[1701-1800]: loss = 0.406528 * 100, metric = 7.69% * 100;
 Minibatch[1801-1900]: loss = 0.412495 * 100, metric = 7.82% * 100;
 Minibatch[1901-2000]: loss = 0.414355 * 100, metric = 7.84% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.411377 * 2000, metric = 7.90% * 2000 909.425s (  2.2 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 15.05% * 2000;
 Minibatch[   1- 100]: loss = 0.403303 * 100, metric = 7.64% * 100;
 Minibatch[ 101- 200]: loss = 0.418384 * 100, metric = 7.96% * 100;
 Minibatch[ 201- 300]: loss = 0.415869 * 100, metric = 8.10% * 100;
 Minibatch[ 301- 400]: loss = 0.399077 * 100, metric = 7.65% * 100;
 Minibatch[ 401- 500]: loss = 0.403946 * 100, metric = 7.78% * 100;
 Minibatch[ 501- 600]: loss = 0.393280 * 100, metric = 7.27% * 100;
 Minibatch[ 601- 700]: loss = 0.385517 * 100, metric = 7.40% * 100;
 Minibatch[ 701- 800]: loss = 0.407511 * 100, metric = 7.83% * 100;
 Minibatch[ 801- 900]: loss = 0.418662 * 100, metric = 8.32% * 100;
 Minibatch[ 901-1000]: loss = 0.410699 * 100, metric = 7.94% * 100;
 Minibatch[1001-1100]: loss = 0.409634 * 100, metric = 7.82% * 100;
 Minibatch[1101-1200]: loss = 0.405458 * 100, metric = 7.82% * 100;
 Minibatch[1201-1300]: loss = 0.397685 * 100, metric = 7.60% * 100;
 Minibatch[1301-1400]: loss = 0.427819 * 100, metric = 8.42% * 100;
 Minibatch[1401-1500]: loss = 0.386882 * 100, metric = 7.31% * 100;
 Minibatch[1501-1600]: loss = 0.393558 * 100, metric = 7.46% * 100;
 Minibatch[1601-1700]: loss = 0.407303 * 100, metric = 7.95% * 100;
 Minibatch[1701-1800]: loss = 0.386553 * 100, metric = 7.24% * 100;
 Minibatch[1801-1900]: loss = 0.395615 * 100, metric = 7.63% * 100;
 Minibatch[1901-2000]: loss = 0.398670 * 100, metric = 7.79% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.403271 * 2000, metric = 7.75% * 2000 906.844s (  2.2 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 13.64% * 2000;
0.5135784811973572
 Minibatch[   1- 100]: loss = 0.413874 * 100, metric = 8.44% * 100;
 Minibatch[ 101- 200]: loss = 0.404724 * 100, metric = 7.66% * 100;
 Minibatch[ 201- 300]: loss = 0.402859 * 100, metric = 7.66% * 100;
 Minibatch[ 301- 400]: loss = 0.404741 * 100, metric = 7.82% * 100;
 Minibatch[ 401- 500]: loss = 0.387098 * 100, metric = 7.42% * 100;
 Minibatch[ 501- 600]: loss = 0.397873 * 100, metric = 7.66% * 100;
 Minibatch[ 601- 700]: loss = 0.396492 * 100, metric = 7.65% * 100;
 Minibatch[ 701- 800]: loss = 0.385992 * 100, metric = 7.32% * 100;
 Minibatch[ 801- 900]: loss = 0.375989 * 100, metric = 6.98% * 100;
 Minibatch[ 901-1000]: loss = 0.400270 * 100, metric = 7.76% * 100;
 Minibatch[1001-1100]: loss = 0.382397 * 100, metric = 7.20% * 100;
 Minibatch[1101-1200]: loss = 0.382933 * 100, metric = 7.23% * 100;
 Minibatch[1201-1300]: loss = 0.378706 * 100, metric = 6.82% * 100;
 Minibatch[1301-1400]: loss = 0.385263 * 100, metric = 7.16% * 100;
 Minibatch[1401-1500]: loss = 0.379579 * 100, metric = 7.36% * 100;
 Minibatch[1501-1600]: loss = 0.385012 * 100, metric = 7.33% * 100;
 Minibatch[1601-1700]: loss = 0.395341 * 100, metric = 7.65% * 100;
 Minibatch[1701-1800]: loss = 0.402201 * 100, metric = 7.59% * 100;
 Minibatch[1801-1900]: loss = 0.400854 * 100, metric = 7.80% * 100;
 Minibatch[1901-2000]: loss = 0.384806 * 100, metric = 7.21% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.392350 * 2000, metric = 7.49% * 2000 912.116s (  2.2 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.44% * 2000;
 Minibatch[   1- 100]: loss = 0.382015 * 100, metric = 7.09% * 100;
 Minibatch[ 101- 200]: loss = 0.400545 * 100, metric = 7.88% * 100;
 Minibatch[ 201- 300]: loss = 0.396189 * 100, metric = 7.54% * 100;
 Minibatch[ 301- 400]: loss = 0.397177 * 100, metric = 7.55% * 100;
 Minibatch[ 401- 500]: loss = 0.394155 * 100, metric = 7.50% * 100;
 Minibatch[ 501- 600]: loss = 0.380993 * 100, metric = 6.94% * 100;
 Minibatch[ 601- 700]: loss = 0.369743 * 100, metric = 6.83% * 100;
 Minibatch[ 701- 800]: loss = 0.386019 * 100, metric = 7.20% * 100;
 Minibatch[ 801- 900]: loss = 0.387849 * 100, metric = 7.48% * 100;
 Minibatch[ 901-1000]: loss = 0.376071 * 100, metric = 6.94% * 100;
 Minibatch[1001-1100]: loss = 0.374000 * 100, metric = 6.98% * 100;
 Minibatch[1101-1200]: loss = 0.399320 * 100, metric = 7.69% * 100;
 Minibatch[1201-1300]: loss = 0.396270 * 100, metric = 7.53% * 100;
 Minibatch[1301-1400]: loss = 0.372097 * 100, metric = 7.05% * 100;
 Minibatch[1401-1500]: loss = 0.386730 * 100, metric = 7.24% * 100;
 Minibatch[1501-1600]: loss = 0.386129 * 100, metric = 7.20% * 100;
 Minibatch[1601-1700]: loss = 0.383480 * 100, metric = 7.17% * 100;
 Minibatch[1701-1800]: loss = 0.374736 * 100, metric = 7.19% * 100;
 Minibatch[1801-1900]: loss = 0.396014 * 100, metric = 7.72% * 100;
 Minibatch[1901-2000]: loss = 0.404080 * 100, metric = 7.77% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.387181 * 2000, metric = 7.32% * 2000 916.759s (  2.2 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 13.63% * 2000;
 Minibatch[   1- 100]: loss = 0.370530 * 100, metric = 6.85% * 100;
 Minibatch[ 101- 200]: loss = 0.392741 * 100, metric = 7.26% * 100;
 Minibatch[ 201- 300]: loss = 0.375347 * 100, metric = 6.97% * 100;
 Minibatch[ 301- 400]: loss = 0.383027 * 100, metric = 7.18% * 100;
 Minibatch[ 401- 500]: loss = 0.369088 * 100, metric = 6.99% * 100;
 Minibatch[ 501- 600]: loss = 0.372518 * 100, metric = 6.96% * 100;
 Minibatch[ 601- 700]: loss = 0.386507 * 100, metric = 7.34% * 100;
 Minibatch[ 701- 800]: loss = 0.371472 * 100, metric = 7.05% * 100;
 Minibatch[ 801- 900]: loss = 0.377708 * 100, metric = 6.87% * 100;
 Minibatch[ 901-1000]: loss = 0.384179 * 100, metric = 7.29% * 100;
 Minibatch[1001-1100]: loss = 0.391157 * 100, metric = 7.49% * 100;
 Minibatch[1101-1200]: loss = 0.383162 * 100, metric = 7.08% * 100;
 Minibatch[1201-1300]: loss = 0.397362 * 100, metric = 7.74% * 100;
 Minibatch[1301-1400]: loss = 0.394907 * 100, metric = 7.59% * 100;
 Minibatch[1401-1500]: loss = 0.366444 * 100, metric = 6.84% * 100;
 Minibatch[1501-1600]: loss = 0.375558 * 100, metric = 7.16% * 100;
 Minibatch[1601-1700]: loss = 0.361083 * 100, metric = 6.59% * 100;
 Minibatch[1701-1800]: loss = 0.378535 * 100, metric = 7.15% * 100;
 Minibatch[1801-1900]: loss = 0.360375 * 100, metric = 6.89% * 100;
 Minibatch[1901-2000]: loss = 0.373217 * 100, metric = 6.89% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.378246 * 2000, metric = 7.11% * 2000 914.344s (  2.2 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 14.88% * 2000;
 Minibatch[   1- 100]: loss = 0.380671 * 100, metric = 7.25% * 100;
 Minibatch[ 101- 200]: loss = 0.386636 * 100, metric = 7.38% * 100;
 Minibatch[ 201- 300]: loss = 0.368023 * 100, metric = 6.85% * 100;
 Minibatch[ 301- 400]: loss = 0.377258 * 100, metric = 6.97% * 100;
 Minibatch[ 401- 500]: loss = 0.377060 * 100, metric = 7.12% * 100;
 Minibatch[ 501- 600]: loss = 0.366771 * 100, metric = 6.71% * 100;
 Minibatch[ 601- 700]: loss = 0.382570 * 100, metric = 7.01% * 100;
 Minibatch[ 701- 800]: loss = 0.362793 * 100, metric = 6.79% * 100;
 Minibatch[ 801- 900]: loss = 0.394031 * 100, metric = 7.43% * 100;
 Minibatch[ 901-1000]: loss = 0.359017 * 100, metric = 6.70% * 100;
 Minibatch[1001-1100]: loss = 0.379658 * 100, metric = 7.19% * 100;
 Minibatch[1101-1200]: loss = 0.374288 * 100, metric = 7.07% * 100;
 Minibatch[1201-1300]: loss = 0.369921 * 100, metric = 6.85% * 100;
 Minibatch[1301-1400]: loss = 0.363047 * 100, metric = 6.64% * 100;
 Minibatch[1401-1500]: loss = 0.374998 * 100, metric = 7.22% * 100;
 Minibatch[1501-1600]: loss = 0.370535 * 100, metric = 6.84% * 100;
 Minibatch[1601-1700]: loss = 0.353970 * 100, metric = 6.57% * 100;
 Minibatch[1701-1800]: loss = 0.350344 * 100, metric = 6.32% * 100;
 Minibatch[1801-1900]: loss = 0.354930 * 100, metric = 6.66% * 100;
 Minibatch[1901-2000]: loss = 0.346823 * 100, metric = 6.25% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.369667 * 2000, metric = 6.89% * 2000 915.837s (  2.2 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 14.19% * 2000;
 Minibatch[   1- 100]: loss = 0.360393 * 100, metric = 6.49% * 100;
 Minibatch[ 101- 200]: loss = 0.360673 * 100, metric = 6.75% * 100;
 Minibatch[ 201- 300]: loss = 0.359462 * 100, metric = 6.45% * 100;
 Minibatch[ 301- 400]: loss = 0.380266 * 100, metric = 7.17% * 100;
 Minibatch[ 401- 500]: loss = 0.364131 * 100, metric = 6.81% * 100;
 Minibatch[ 501- 600]: loss = 0.371247 * 100, metric = 7.11% * 100;
 Minibatch[ 601- 700]: loss = 0.375188 * 100, metric = 7.02% * 100;
 Minibatch[ 701- 800]: loss = 0.366221 * 100, metric = 6.70% * 100;
 Minibatch[ 801- 900]: loss = 0.376327 * 100, metric = 7.15% * 100;
 Minibatch[ 901-1000]: loss = 0.371597 * 100, metric = 7.08% * 100;
 Minibatch[1001-1100]: loss = 0.357142 * 100, metric = 6.60% * 100;
 Minibatch[1101-1200]: loss = 0.373349 * 100, metric = 6.99% * 100;
 Minibatch[1201-1300]: loss = 0.373024 * 100, metric = 6.83% * 100;
 Minibatch[1301-1400]: loss = 0.370974 * 100, metric = 7.08% * 100;
 Minibatch[1401-1500]: loss = 0.352162 * 100, metric = 6.63% * 100;
 Minibatch[1501-1600]: loss = 0.375441 * 100, metric = 7.08% * 100;
 Minibatch[1601-1700]: loss = 0.357764 * 100, metric = 6.61% * 100;
 Minibatch[1701-1800]: loss = 0.370115 * 100, metric = 7.13% * 100;
 Minibatch[1801-1900]: loss = 0.364549 * 100, metric = 6.92% * 100;
 Minibatch[1901-2000]: loss = 0.369355 * 100, metric = 6.97% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.367469 * 2000, metric = 6.88% * 2000 916.153s (  2.2 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 14.35% * 2000;
 Minibatch[   1- 100]: loss = 0.369430 * 100, metric = 6.76% * 100;
 Minibatch[ 101- 200]: loss = 0.374314 * 100, metric = 6.99% * 100;
 Minibatch[ 201- 300]: loss = 0.362840 * 100, metric = 6.86% * 100;
 Minibatch[ 301- 400]: loss = 0.372324 * 100, metric = 7.14% * 100;
 Minibatch[ 401- 500]: loss = 0.360128 * 100, metric = 6.63% * 100;
 Minibatch[ 501- 600]: loss = 0.355119 * 100, metric = 6.59% * 100;
 Minibatch[ 601- 700]: loss = 0.366372 * 100, metric = 6.87% * 100;
 Minibatch[ 701- 800]: loss = 0.333458 * 100, metric = 6.12% * 100;
 Minibatch[ 801- 900]: loss = 0.365957 * 100, metric = 6.91% * 100;
 Minibatch[ 901-1000]: loss = 0.357240 * 100, metric = 6.71% * 100;
 Minibatch[1001-1100]: loss = 0.360347 * 100, metric = 6.78% * 100;
 Minibatch[1101-1200]: loss = 0.353635 * 100, metric = 6.58% * 100;
 Minibatch[1201-1300]: loss = 0.360785 * 100, metric = 6.62% * 100;
 Minibatch[1301-1400]: loss = 0.344494 * 100, metric = 6.39% * 100;
 Minibatch[1401-1500]: loss = 0.366026 * 100, metric = 6.79% * 100;
 Minibatch[1501-1600]: loss = 0.367674 * 100, metric = 7.04% * 100;
 Minibatch[1601-1700]: loss = 0.358966 * 100, metric = 6.75% * 100;
 Minibatch[1701-1800]: loss = 0.355351 * 100, metric = 6.54% * 100;
 Minibatch[1801-1900]: loss = 0.367898 * 100, metric = 6.92% * 100;
 Minibatch[1901-2000]: loss = 0.346920 * 100, metric = 6.43% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.359964 * 2000, metric = 6.72% * 2000 903.440s (  2.2 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 13.52% * 2000;
 Minibatch[   1- 100]: loss = 0.366740 * 100, metric = 6.68% * 100;
 Minibatch[ 101- 200]: loss = 0.361908 * 100, metric = 6.83% * 100;
 Minibatch[ 201- 300]: loss = 0.359562 * 100, metric = 6.69% * 100;
 Minibatch[ 301- 400]: loss = 0.349462 * 100, metric = 6.39% * 100;
 Minibatch[ 401- 500]: loss = 0.346502 * 100, metric = 6.29% * 100;
 Minibatch[ 501- 600]: loss = 0.357907 * 100, metric = 6.56% * 100;
 Minibatch[ 601- 700]: loss = 0.350008 * 100, metric = 6.55% * 100;
 Minibatch[ 701- 800]: loss = 0.354161 * 100, metric = 6.61% * 100;
 Minibatch[ 801- 900]: loss = 0.362270 * 100, metric = 6.64% * 100;
 Minibatch[ 901-1000]: loss = 0.366711 * 100, metric = 6.83% * 100;
 Minibatch[1001-1100]: loss = 0.347586 * 100, metric = 6.26% * 100;
 Minibatch[1101-1200]: loss = 0.333434 * 100, metric = 5.95% * 100;
 Minibatch[1201-1300]: loss = 0.345745 * 100, metric = 6.23% * 100;
 Minibatch[1301-1400]: loss = 0.348287 * 100, metric = 6.40% * 100;
 Minibatch[1401-1500]: loss = 0.340096 * 100, metric = 6.21% * 100;
 Minibatch[1501-1600]: loss = 0.346024 * 100, metric = 6.31% * 100;
 Minibatch[1601-1700]: loss = 0.345409 * 100, metric = 6.41% * 100;
 Minibatch[1701-1800]: loss = 0.346985 * 100, metric = 6.31% * 100;
 Minibatch[1801-1900]: loss = 0.348445 * 100, metric = 6.40% * 100;
 Minibatch[1901-2000]: loss = 0.348479 * 100, metric = 6.40% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.351286 * 2000, metric = 6.45% * 2000 921.544s (  2.2 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 14.42% * 2000;
 Minibatch[   1- 100]: loss = 0.361152 * 100, metric = 6.59% * 100;
 Minibatch[ 101- 200]: loss = 0.361261 * 100, metric = 6.78% * 100;
 Minibatch[ 201- 300]: loss = 0.351984 * 100, metric = 6.45% * 100;
 Minibatch[ 301- 400]: loss = 0.353495 * 100, metric = 6.52% * 100;
 Minibatch[ 401- 500]: loss = 0.356018 * 100, metric = 6.57% * 100;
 Minibatch[ 501- 600]: loss = 0.365254 * 100, metric = 6.72% * 100;
 Minibatch[ 601- 700]: loss = 0.359174 * 100, metric = 6.75% * 100;
 Minibatch[ 701- 800]: loss = 0.343734 * 100, metric = 6.44% * 100;
 Minibatch[ 801- 900]: loss = 0.339131 * 100, metric = 6.40% * 100;
 Minibatch[ 901-1000]: loss = 0.359971 * 100, metric = 6.49% * 100;
 Minibatch[1001-1100]: loss = 0.350503 * 100, metric = 6.30% * 100;
 Minibatch[1101-1200]: loss = 0.350217 * 100, metric = 6.35% * 100;
 Minibatch[1201-1300]: loss = 0.357370 * 100, metric = 6.59% * 100;
 Minibatch[1301-1400]: loss = 0.360253 * 100, metric = 6.65% * 100;
 Minibatch[1401-1500]: loss = 0.342007 * 100, metric = 6.12% * 100;
 Minibatch[1501-1600]: loss = 0.346923 * 100, metric = 6.34% * 100;
 Minibatch[1601-1700]: loss = 0.346579 * 100, metric = 6.43% * 100;
 Minibatch[1701-1800]: loss = 0.356758 * 100, metric = 6.65% * 100;
 Minibatch[1801-1900]: loss = 0.351425 * 100, metric = 6.63% * 100;
 Minibatch[1901-2000]: loss = 0.355200 * 100, metric = 6.52% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.353420 * 2000, metric = 6.52% * 2000 906.509s (  2.2 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 14.39% * 2000;
 Minibatch[   1- 100]: loss = 0.327473 * 100, metric = 5.92% * 100;
 Minibatch[ 101- 200]: loss = 0.350304 * 100, metric = 6.54% * 100;
 Minibatch[ 201- 300]: loss = 0.345484 * 100, metric = 6.31% * 100;
 Minibatch[ 301- 400]: loss = 0.346380 * 100, metric = 6.33% * 100;
 Minibatch[ 401- 500]: loss = 0.347337 * 100, metric = 6.27% * 100;
 Minibatch[ 501- 600]: loss = 0.334911 * 100, metric = 6.10% * 100;
 Minibatch[ 601- 700]: loss = 0.346913 * 100, metric = 6.22% * 100;
 Minibatch[ 701- 800]: loss = 0.338159 * 100, metric = 6.39% * 100;
 Minibatch[ 801- 900]: loss = 0.357915 * 100, metric = 6.88% * 100;
 Minibatch[ 901-1000]: loss = 0.353633 * 100, metric = 6.44% * 100;
 Minibatch[1001-1100]: loss = 0.351443 * 100, metric = 6.43% * 100;
 Minibatch[1101-1200]: loss = 0.360758 * 100, metric = 6.81% * 100;
 Minibatch[1201-1300]: loss = 0.353737 * 100, metric = 6.52% * 100;
 Minibatch[1301-1400]: loss = 0.342850 * 100, metric = 6.22% * 100;
 Minibatch[1401-1500]: loss = 0.338052 * 100, metric = 6.11% * 100;
 Minibatch[1501-1600]: loss = 0.343882 * 100, metric = 6.46% * 100;
 Minibatch[1601-1700]: loss = 0.339628 * 100, metric = 6.27% * 100;
 Minibatch[1701-1800]: loss = 0.336346 * 100, metric = 6.28% * 100;
 Minibatch[1801-1900]: loss = 0.344967 * 100, metric = 6.46% * 100;
 Minibatch[1901-2000]: loss = 0.344077 * 100, metric = 6.47% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.345213 * 2000, metric = 6.37% * 2000 906.201s (  2.2 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.93% * 2000;
 Minibatch[   1- 100]: loss = 0.350809 * 100, metric = 6.50% * 100;
 Minibatch[ 101- 200]: loss = 0.337379 * 100, metric = 6.28% * 100;
 Minibatch[ 201- 300]: loss = 0.345554 * 100, metric = 6.72% * 100;
 Minibatch[ 301- 400]: loss = 0.342863 * 100, metric = 6.41% * 100;
 Minibatch[ 401- 500]: loss = 0.341900 * 100, metric = 6.34% * 100;
 Minibatch[ 501- 600]: loss = 0.344808 * 100, metric = 6.50% * 100;
 Minibatch[ 601- 700]: loss = 0.344461 * 100, metric = 6.13% * 100;
 Minibatch[ 701- 800]: loss = 0.330413 * 100, metric = 5.89% * 100;
 Minibatch[ 801- 900]: loss = 0.329512 * 100, metric = 6.01% * 100;
 Minibatch[ 901-1000]: loss = 0.344887 * 100, metric = 6.25% * 100;
 Minibatch[1001-1100]: loss = 0.344012 * 100, metric = 6.37% * 100;
 Minibatch[1101-1200]: loss = 0.353644 * 100, metric = 6.70% * 100;
 Minibatch[1201-1300]: loss = 0.359151 * 100, metric = 6.80% * 100;
 Minibatch[1301-1400]: loss = 0.339033 * 100, metric = 6.22% * 100;
 Minibatch[1401-1500]: loss = 0.336160 * 100, metric = 6.09% * 100;
 Minibatch[1501-1600]: loss = 0.349120 * 100, metric = 6.54% * 100;
 Minibatch[1601-1700]: loss = 0.336788 * 100, metric = 6.32% * 100;
 Minibatch[1701-1800]: loss = 0.339400 * 100, metric = 6.21% * 100;
 Minibatch[1801-1900]: loss = 0.329939 * 100, metric = 5.80% * 100;
 Minibatch[1901-2000]: loss = 0.324234 * 100, metric = 5.77% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.341203 * 2000, metric = 6.29% * 2000 909.561s (  2.2 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.05% * 2000;
 Minibatch[   1- 100]: loss = 0.341255 * 100, metric = 6.40% * 100;
 Minibatch[ 101- 200]: loss = 0.326800 * 100, metric = 5.88% * 100;
 Minibatch[ 201- 300]: loss = 0.343268 * 100, metric = 6.27% * 100;
 Minibatch[ 301- 400]: loss = 0.331866 * 100, metric = 6.12% * 100;
 Minibatch[ 401- 500]: loss = 0.329818 * 100, metric = 6.04% * 100;
 Minibatch[ 501- 600]: loss = 0.331455 * 100, metric = 5.97% * 100;
 Minibatch[ 601- 700]: loss = 0.342083 * 100, metric = 6.21% * 100;
 Minibatch[ 701- 800]: loss = 0.329669 * 100, metric = 6.13% * 100;
 Minibatch[ 801- 900]: loss = 0.321016 * 100, metric = 5.79% * 100;
 Minibatch[ 901-1000]: loss = 0.325309 * 100, metric = 5.89% * 100;
 Minibatch[1001-1100]: loss = 0.336720 * 100, metric = 6.41% * 100;
 Minibatch[1101-1200]: loss = 0.350086 * 100, metric = 6.58% * 100;
 Minibatch[1201-1300]: loss = 0.334396 * 100, metric = 6.08% * 100;
 Minibatch[1301-1400]: loss = 0.324351 * 100, metric = 5.74% * 100;
 Minibatch[1401-1500]: loss = 0.336883 * 100, metric = 6.12% * 100;
 Minibatch[1501-1600]: loss = 0.325666 * 100, metric = 5.59% * 100;
 Minibatch[1601-1700]: loss = 0.354045 * 100, metric = 6.52% * 100;
 Minibatch[1701-1800]: loss = 0.342336 * 100, metric = 6.34% * 100;
 Minibatch[1801-1900]: loss = 0.330540 * 100, metric = 5.99% * 100;
 Minibatch[1901-2000]: loss = 0.336169 * 100, metric = 6.15% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.334687 * 2000, metric = 6.11% * 2000 910.568s (  2.2 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.17% * 2000;
 Minibatch[   1- 100]: loss = 0.331340 * 100, metric = 5.84% * 100;
 Minibatch[ 101- 200]: loss = 0.336699 * 100, metric = 6.00% * 100;
 Minibatch[ 201- 300]: loss = 0.327831 * 100, metric = 5.95% * 100;
 Minibatch[ 301- 400]: loss = 0.328110 * 100, metric = 6.03% * 100;
 Minibatch[ 401- 500]: loss = 0.331575 * 100, metric = 6.03% * 100;
 Minibatch[ 501- 600]: loss = 0.329870 * 100, metric = 5.99% * 100;
 Minibatch[ 601- 700]: loss = 0.326408 * 100, metric = 5.79% * 100;
 Minibatch[ 701- 800]: loss = 0.332797 * 100, metric = 6.14% * 100;
 Minibatch[ 801- 900]: loss = 0.340912 * 100, metric = 6.02% * 100;
 Minibatch[ 901-1000]: loss = 0.337666 * 100, metric = 6.34% * 100;
 Minibatch[1001-1100]: loss = 0.330669 * 100, metric = 5.83% * 100;
 Minibatch[1101-1200]: loss = 0.344003 * 100, metric = 6.47% * 100;
 Minibatch[1201-1300]: loss = 0.332806 * 100, metric = 6.11% * 100;
 Minibatch[1301-1400]: loss = 0.337320 * 100, metric = 6.39% * 100;
 Minibatch[1401-1500]: loss = 0.327019 * 100, metric = 5.93% * 100;
 Minibatch[1501-1600]: loss = 0.329030 * 100, metric = 6.18% * 100;
 Minibatch[1601-1700]: loss = 0.308813 * 100, metric = 5.36% * 100;
 Minibatch[1701-1800]: loss = 0.312176 * 100, metric = 5.51% * 100;
 Minibatch[1801-1900]: loss = 0.319733 * 100, metric = 5.70% * 100;
 Minibatch[1901-2000]: loss = 0.327547 * 100, metric = 5.82% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.329616 * 2000, metric = 5.97% * 2000 894.416s (  2.2 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.72% * 2000;
 Minibatch[   1- 100]: loss = 0.332465 * 100, metric = 6.08% * 100;
 Minibatch[ 101- 200]: loss = 0.319168 * 100, metric = 5.71% * 100;
 Minibatch[ 201- 300]: loss = 0.327450 * 100, metric = 6.00% * 100;
 Minibatch[ 301- 400]: loss = 0.328022 * 100, metric = 5.96% * 100;
 Minibatch[ 401- 500]: loss = 0.326793 * 100, metric = 5.95% * 100;
 Minibatch[ 501- 600]: loss = 0.340941 * 100, metric = 6.18% * 100;
 Minibatch[ 601- 700]: loss = 0.316935 * 100, metric = 5.69% * 100;
 Minibatch[ 701- 800]: loss = 0.312850 * 100, metric = 5.54% * 100;
 Minibatch[ 801- 900]: loss = 0.330742 * 100, metric = 6.02% * 100;
 Minibatch[ 901-1000]: loss = 0.331297 * 100, metric = 6.22% * 100;
 Minibatch[1001-1100]: loss = 0.318899 * 100, metric = 5.55% * 100;
 Minibatch[1101-1200]: loss = 0.317559 * 100, metric = 5.62% * 100;
 Minibatch[1201-1300]: loss = 0.329919 * 100, metric = 6.10% * 100;
 Minibatch[1301-1400]: loss = 0.322957 * 100, metric = 5.97% * 100;
 Minibatch[1401-1500]: loss = 0.334997 * 100, metric = 6.15% * 100;
 Minibatch[1501-1600]: loss = 0.319578 * 100, metric = 5.71% * 100;
 Minibatch[1601-1700]: loss = 0.329650 * 100, metric = 5.75% * 100;
 Minibatch[1701-1800]: loss = 0.328974 * 100, metric = 5.93% * 100;
 Minibatch[1801-1900]: loss = 0.325870 * 100, metric = 6.10% * 100;
 Minibatch[1901-2000]: loss = 0.327324 * 100, metric = 5.96% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.326119 * 2000, metric = 5.91% * 2000 902.394s (  2.2 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.33% * 2000;
 Minibatch[   1- 100]: loss = 0.318584 * 100, metric = 5.48% * 100;
 Minibatch[ 101- 200]: loss = 0.318395 * 100, metric = 5.85% * 100;
 Minibatch[ 201- 300]: loss = 0.330250 * 100, metric = 6.19% * 100;
 Minibatch[ 301- 400]: loss = 0.344449 * 100, metric = 6.24% * 100;
 Minibatch[ 401- 500]: loss = 0.322712 * 100, metric = 6.05% * 100;
 Minibatch[ 501- 600]: loss = 0.330515 * 100, metric = 6.08% * 100;
 Minibatch[ 601- 700]: loss = 0.325287 * 100, metric = 6.07% * 100;
 Minibatch[ 701- 800]: loss = 0.334727 * 100, metric = 6.26% * 100;
 Minibatch[ 801- 900]: loss = 0.327633 * 100, metric = 6.08% * 100;
 Minibatch[ 901-1000]: loss = 0.331436 * 100, metric = 6.02% * 100;
 Minibatch[1001-1100]: loss = 0.328687 * 100, metric = 6.09% * 100;
 Minibatch[1101-1200]: loss = 0.321369 * 100, metric = 5.71% * 100;
 Minibatch[1201-1300]: loss = 0.325381 * 100, metric = 5.96% * 100;
 Minibatch[1301-1400]: loss = 0.322053 * 100, metric = 6.03% * 100;
 Minibatch[1401-1500]: loss = 0.336587 * 100, metric = 6.10% * 100;
 Minibatch[1501-1600]: loss = 0.307861 * 100, metric = 5.46% * 100;
 Minibatch[1601-1700]: loss = 0.323647 * 100, metric = 5.99% * 100;
 Minibatch[1701-1800]: loss = 0.309915 * 100, metric = 5.57% * 100;
 Minibatch[1801-1900]: loss = 0.334976 * 100, metric = 6.18% * 100;
 Minibatch[1901-2000]: loss = 0.320721 * 100, metric = 5.81% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.325759 * 2000, metric = 5.96% * 2000 906.427s (  2.2 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 14.27% * 2000;
 Minibatch[   1- 100]: loss = 0.335683 * 100, metric = 6.02% * 100;
 Minibatch[ 101- 200]: loss = 0.309397 * 100, metric = 5.47% * 100;
 Minibatch[ 201- 300]: loss = 0.317947 * 100, metric = 5.72% * 100;
 Minibatch[ 301- 400]: loss = 0.326260 * 100, metric = 6.10% * 100;
 Minibatch[ 401- 500]: loss = 0.324403 * 100, metric = 5.79% * 100;
 Minibatch[ 501- 600]: loss = 0.304396 * 100, metric = 5.49% * 100;
 Minibatch[ 601- 700]: loss = 0.322330 * 100, metric = 5.90% * 100;
 Minibatch[ 701- 800]: loss = 0.314548 * 100, metric = 5.67% * 100;
 Minibatch[ 801- 900]: loss = 0.331290 * 100, metric = 6.18% * 100;
 Minibatch[ 901-1000]: loss = 0.306453 * 100, metric = 5.45% * 100;
 Minibatch[1001-1100]: loss = 0.323567 * 100, metric = 5.71% * 100;
 Minibatch[1101-1200]: loss = 0.328124 * 100, metric = 5.97% * 100;
 Minibatch[1201-1300]: loss = 0.308481 * 100, metric = 5.39% * 100;
 Minibatch[1301-1400]: loss = 0.320954 * 100, metric = 5.72% * 100;
 Minibatch[1401-1500]: loss = 0.324208 * 100, metric = 5.85% * 100;
 Minibatch[1501-1600]: loss = 0.337825 * 100, metric = 6.16% * 100;
 Minibatch[1601-1700]: loss = 0.319826 * 100, metric = 5.80% * 100;
 Minibatch[1701-1800]: loss = 0.328581 * 100, metric = 5.95% * 100;
 Minibatch[1801-1900]: loss = 0.325267 * 100, metric = 6.06% * 100;
 Minibatch[1901-2000]: loss = 0.339031 * 100, metric = 6.25% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.322428 * 2000, metric = 5.83% * 2000 898.802s (  2.2 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.23% * 2000;
 Minibatch[   1- 100]: loss = 0.323863 * 100, metric = 5.95% * 100;
 Minibatch[ 101- 200]: loss = 0.329548 * 100, metric = 6.01% * 100;
 Minibatch[ 201- 300]: loss = 0.315151 * 100, metric = 5.85% * 100;
 Minibatch[ 301- 400]: loss = 0.323579 * 100, metric = 5.92% * 100;
 Minibatch[ 401- 500]: loss = 0.315207 * 100, metric = 5.66% * 100;
 Minibatch[ 501- 600]: loss = 0.316318 * 100, metric = 5.71% * 100;
 Minibatch[ 601- 700]: loss = 0.334894 * 100, metric = 6.28% * 100;
 Minibatch[ 701- 800]: loss = 0.336958 * 100, metric = 6.18% * 100;
 Minibatch[ 801- 900]: loss = 0.327643 * 100, metric = 5.96% * 100;
 Minibatch[ 901-1000]: loss = 0.317455 * 100, metric = 5.73% * 100;
 Minibatch[1001-1100]: loss = 0.312120 * 100, metric = 5.67% * 100;
 Minibatch[1101-1200]: loss = 0.316328 * 100, metric = 5.94% * 100;
 Minibatch[1201-1300]: loss = 0.316686 * 100, metric = 5.74% * 100;
 Minibatch[1301-1400]: loss = 0.321701 * 100, metric = 5.85% * 100;
 Minibatch[1401-1500]: loss = 0.325818 * 100, metric = 5.92% * 100;
 Minibatch[1501-1600]: loss = 0.308748 * 100, metric = 5.69% * 100;
 Minibatch[1601-1700]: loss = 0.315244 * 100, metric = 5.81% * 100;
 Minibatch[1701-1800]: loss = 0.314594 * 100, metric = 5.75% * 100;
 Minibatch[1801-1900]: loss = 0.320076 * 100, metric = 6.02% * 100;
 Minibatch[1901-2000]: loss = 0.315375 * 100, metric = 5.88% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.320365 * 2000, metric = 5.87% * 2000 901.260s (  2.2 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 13.94% * 2000;
 Minibatch[   1- 100]: loss = 0.313296 * 100, metric = 5.70% * 100;
 Minibatch[ 101- 200]: loss = 0.320021 * 100, metric = 5.68% * 100;
 Minibatch[ 201- 300]: loss = 0.327640 * 100, metric = 6.10% * 100;
 Minibatch[ 301- 400]: loss = 0.326706 * 100, metric = 5.88% * 100;
 Minibatch[ 401- 500]: loss = 0.323484 * 100, metric = 6.08% * 100;
 Minibatch[ 501- 600]: loss = 0.319072 * 100, metric = 5.97% * 100;
 Minibatch[ 601- 700]: loss = 0.310770 * 100, metric = 5.59% * 100;
 Minibatch[ 701- 800]: loss = 0.314898 * 100, metric = 5.79% * 100;
 Minibatch[ 801- 900]: loss = 0.317651 * 100, metric = 5.80% * 100;
 Minibatch[ 901-1000]: loss = 0.309812 * 100, metric = 5.68% * 100;
 Minibatch[1001-1100]: loss = 0.311606 * 100, metric = 5.52% * 100;
 Minibatch[1101-1200]: loss = 0.321285 * 100, metric = 5.91% * 100;
 Minibatch[1201-1300]: loss = 0.329136 * 100, metric = 6.07% * 100;
 Minibatch[1301-1400]: loss = 0.315625 * 100, metric = 5.75% * 100;
 Minibatch[1401-1500]: loss = 0.318600 * 100, metric = 5.96% * 100;
 Minibatch[1501-1600]: loss = 0.328738 * 100, metric = 5.86% * 100;
 Minibatch[1601-1700]: loss = 0.310010 * 100, metric = 5.65% * 100;
 Minibatch[1701-1800]: loss = 0.322966 * 100, metric = 5.88% * 100;
 Minibatch[1801-1900]: loss = 0.313655 * 100, metric = 5.84% * 100;
 Minibatch[1901-2000]: loss = 0.331238 * 100, metric = 6.43% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.319310 * 2000, metric = 5.86% * 2000 905.896s (  2.2 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.69% * 2000;
 Minibatch[   1- 100]: loss = 0.331281 * 100, metric = 6.26% * 100;
 Minibatch[ 101- 200]: loss = 0.316227 * 100, metric = 5.95% * 100;
 Minibatch[ 201- 300]: loss = 0.311798 * 100, metric = 5.76% * 100;
 Minibatch[ 301- 400]: loss = 0.317732 * 100, metric = 5.96% * 100;
 Minibatch[ 401- 500]: loss = 0.317140 * 100, metric = 6.08% * 100;
 Minibatch[ 501- 600]: loss = 0.320123 * 100, metric = 5.93% * 100;
 Minibatch[ 601- 700]: loss = 0.324465 * 100, metric = 6.20% * 100;
 Minibatch[ 701- 800]: loss = 0.326849 * 100, metric = 6.13% * 100;
 Minibatch[ 801- 900]: loss = 0.319676 * 100, metric = 5.69% * 100;
 Minibatch[ 901-1000]: loss = 0.305164 * 100, metric = 5.46% * 100;
 Minibatch[1001-1100]: loss = 0.316721 * 100, metric = 5.85% * 100;
 Minibatch[1101-1200]: loss = 0.306661 * 100, metric = 5.65% * 100;
 Minibatch[1201-1300]: loss = 0.318053 * 100, metric = 5.80% * 100;
 Minibatch[1301-1400]: loss = 0.303791 * 100, metric = 5.45% * 100;
 Minibatch[1401-1500]: loss = 0.331747 * 100, metric = 6.08% * 100;
 Minibatch[1501-1600]: loss = 0.331387 * 100, metric = 6.30% * 100;
 Minibatch[1601-1700]: loss = 0.315459 * 100, metric = 5.51% * 100;
 Minibatch[1701-1800]: loss = 0.313425 * 100, metric = 5.79% * 100;
 Minibatch[1801-1900]: loss = 0.301808 * 100, metric = 5.34% * 100;
 Minibatch[1901-2000]: loss = 0.326092 * 100, metric = 6.01% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.317780 * 2000, metric = 5.86% * 2000 900.580s (  2.2 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.51% * 2000;
 Minibatch[   1- 100]: loss = 0.313773 * 100, metric = 5.72% * 100;
 Minibatch[ 101- 200]: loss = 0.315203 * 100, metric = 5.82% * 100;
 Minibatch[ 201- 300]: loss = 0.308372 * 100, metric = 5.50% * 100;
 Minibatch[ 301- 400]: loss = 0.320202 * 100, metric = 5.77% * 100;
 Minibatch[ 401- 500]: loss = 0.304179 * 100, metric = 5.57% * 100;
 Minibatch[ 501- 600]: loss = 0.309492 * 100, metric = 5.49% * 100;
 Minibatch[ 601- 700]: loss = 0.322301 * 100, metric = 5.87% * 100;
 Minibatch[ 701- 800]: loss = 0.311743 * 100, metric = 5.70% * 100;
 Minibatch[ 801- 900]: loss = 0.299145 * 100, metric = 5.29% * 100;
 Minibatch[ 901-1000]: loss = 0.311299 * 100, metric = 5.81% * 100;
 Minibatch[1001-1100]: loss = 0.320323 * 100, metric = 5.94% * 100;
 Minibatch[1101-1200]: loss = 0.309188 * 100, metric = 5.80% * 100;
 Minibatch[1201-1300]: loss = 0.316091 * 100, metric = 5.87% * 100;
 Minibatch[1301-1400]: loss = 0.313671 * 100, metric = 5.96% * 100;
 Minibatch[1401-1500]: loss = 0.319356 * 100, metric = 5.96% * 100;
 Minibatch[1501-1600]: loss = 0.320410 * 100, metric = 5.95% * 100;
 Minibatch[1601-1700]: loss = 0.320937 * 100, metric = 6.05% * 100;
 Minibatch[1701-1800]: loss = 0.315651 * 100, metric = 5.69% * 100;
 Minibatch[1801-1900]: loss = 0.317044 * 100, metric = 5.85% * 100;
 Minibatch[1901-2000]: loss = 0.314406 * 100, metric = 5.61% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.314139 * 2000, metric = 5.76% * 2000 907.447s (  2.2 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.34% * 2000;
 Minibatch[   1- 100]: loss = 0.297688 * 100, metric = 5.32% * 100;
 Minibatch[ 101- 200]: loss = 0.319843 * 100, metric = 6.03% * 100;
 Minibatch[ 201- 300]: loss = 0.316780 * 100, metric = 5.83% * 100;
 Minibatch[ 301- 400]: loss = 0.302814 * 100, metric = 5.42% * 100;
 Minibatch[ 401- 500]: loss = 0.313292 * 100, metric = 5.59% * 100;
 Minibatch[ 501- 600]: loss = 0.289028 * 100, metric = 5.18% * 100;
 Minibatch[ 601- 700]: loss = 0.318111 * 100, metric = 5.99% * 100;
 Minibatch[ 701- 800]: loss = 0.289998 * 100, metric = 5.11% * 100;
 Minibatch[ 801- 900]: loss = 0.309089 * 100, metric = 5.58% * 100;
 Minibatch[ 901-1000]: loss = 0.301378 * 100, metric = 5.52% * 100;
 Minibatch[1001-1100]: loss = 0.313990 * 100, metric = 5.64% * 100;
 Minibatch[1101-1200]: loss = 0.298829 * 100, metric = 5.36% * 100;
 Minibatch[1201-1300]: loss = 0.309767 * 100, metric = 5.83% * 100;
 Minibatch[1301-1400]: loss = 0.311217 * 100, metric = 5.79% * 100;
 Minibatch[1401-1500]: loss = 0.301743 * 100, metric = 5.39% * 100;
 Minibatch[1501-1600]: loss = 0.310639 * 100, metric = 5.62% * 100;
 Minibatch[1601-1700]: loss = 0.305444 * 100, metric = 5.60% * 100;
 Minibatch[1701-1800]: loss = 0.301871 * 100, metric = 5.38% * 100;
 Minibatch[1801-1900]: loss = 0.311572 * 100, metric = 5.69% * 100;
 Minibatch[1901-2000]: loss = 0.302725 * 100, metric = 5.41% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.306291 * 2000, metric = 5.56% * 2000 905.922s (  2.2 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.54% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
