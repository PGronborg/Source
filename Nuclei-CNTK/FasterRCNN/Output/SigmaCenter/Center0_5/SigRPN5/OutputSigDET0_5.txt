Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 0.941153 * 100, metric = 25.22% * 100;
 Minibatch[ 101- 200]: loss = 0.718572 * 100, metric = 23.44% * 100;
 Minibatch[ 201- 300]: loss = 0.622481 * 100, metric = 21.98% * 100;
 Minibatch[ 301- 400]: loss = 0.588366 * 100, metric = 20.20% * 100;
 Minibatch[ 401- 500]: loss = 0.537899 * 100, metric = 19.66% * 100;
 Minibatch[ 501- 600]: loss = 0.500635 * 100, metric = 17.80% * 100;
 Minibatch[ 601- 700]: loss = 0.463828 * 100, metric = 16.55% * 100;
 Minibatch[ 701- 800]: loss = 0.435498 * 100, metric = 15.91% * 100;
 Minibatch[ 801- 900]: loss = 0.447364 * 100, metric = 16.11% * 100;
 Minibatch[ 901-1000]: loss = 0.453621 * 100, metric = 16.56% * 100;
 Minibatch[1001-1100]: loss = 0.437504 * 100, metric = 15.62% * 100;
 Minibatch[1101-1200]: loss = 0.422011 * 100, metric = 15.38% * 100;
 Minibatch[1201-1300]: loss = 0.420657 * 100, metric = 15.51% * 100;
 Minibatch[1301-1400]: loss = 0.405217 * 100, metric = 14.64% * 100;
 Minibatch[1401-1500]: loss = 0.412323 * 100, metric = 14.96% * 100;
 Minibatch[1501-1600]: loss = 0.396661 * 100, metric = 14.73% * 100;
 Minibatch[1601-1700]: loss = 0.396812 * 100, metric = 14.41% * 100;
 Minibatch[1701-1800]: loss = 0.394988 * 100, metric = 14.39% * 100;
 Minibatch[1801-1900]: loss = 0.397643 * 100, metric = 14.21% * 100;
 Minibatch[1901-2000]: loss = 0.385407 * 100, metric = 13.72% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.488932 * 2000, metric = 17.05% * 2000 1112.530s (  1.8 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 23.61% * 2000;
0.5537067075371742
 Minibatch[   1- 100]: loss = 0.372324 * 100, metric = 13.14% * 100;
 Minibatch[ 101- 200]: loss = 0.393264 * 100, metric = 14.30% * 100;
 Minibatch[ 201- 300]: loss = 0.376572 * 100, metric = 13.13% * 100;
 Minibatch[ 301- 400]: loss = 0.383177 * 100, metric = 13.49% * 100;
 Minibatch[ 401- 500]: loss = 0.376059 * 100, metric = 13.36% * 100;
 Minibatch[ 501- 600]: loss = 0.384780 * 100, metric = 13.05% * 100;
 Minibatch[ 601- 700]: loss = 0.367479 * 100, metric = 13.02% * 100;
 Minibatch[ 701- 800]: loss = 0.373947 * 100, metric = 13.51% * 100;
 Minibatch[ 801- 900]: loss = 0.353660 * 100, metric = 12.86% * 100;
 Minibatch[ 901-1000]: loss = 0.346664 * 100, metric = 12.33% * 100;
 Minibatch[1001-1100]: loss = 0.359836 * 100, metric = 12.97% * 100;
 Minibatch[1101-1200]: loss = 0.362588 * 100, metric = 12.82% * 100;
 Minibatch[1201-1300]: loss = 0.349114 * 100, metric = 12.82% * 100;
 Minibatch[1301-1400]: loss = 0.365329 * 100, metric = 12.88% * 100;
 Minibatch[1401-1500]: loss = 0.347736 * 100, metric = 12.08% * 100;
 Minibatch[1501-1600]: loss = 0.338752 * 100, metric = 12.17% * 100;
 Minibatch[1601-1700]: loss = 0.357345 * 100, metric = 12.29% * 100;
 Minibatch[1701-1800]: loss = 0.363807 * 100, metric = 12.81% * 100;
 Minibatch[1801-1900]: loss = 0.350332 * 100, metric = 12.27% * 100;
 Minibatch[1901-2000]: loss = 0.327669 * 100, metric = 11.64% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.362522 * 2000, metric = 12.85% * 2000 1028.557s (  1.9 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 20.23% * 2000;
0.4839636739492416
 Minibatch[   1- 100]: loss = 0.342121 * 100, metric = 12.04% * 100;
 Minibatch[ 101- 200]: loss = 0.350714 * 100, metric = 12.08% * 100;
 Minibatch[ 201- 300]: loss = 0.335772 * 100, metric = 11.94% * 100;
 Minibatch[ 301- 400]: loss = 0.348277 * 100, metric = 12.32% * 100;
 Minibatch[ 401- 500]: loss = 0.350062 * 100, metric = 12.39% * 100;
 Minibatch[ 501- 600]: loss = 0.342872 * 100, metric = 11.96% * 100;
 Minibatch[ 601- 700]: loss = 0.352114 * 100, metric = 12.02% * 100;
 Minibatch[ 701- 800]: loss = 0.321354 * 100, metric = 11.17% * 100;
 Minibatch[ 801- 900]: loss = 0.350175 * 100, metric = 12.36% * 100;
 Minibatch[ 901-1000]: loss = 0.327896 * 100, metric = 11.74% * 100;
 Minibatch[1001-1100]: loss = 0.339577 * 100, metric = 12.08% * 100;
 Minibatch[1101-1200]: loss = 0.330927 * 100, metric = 11.78% * 100;
 Minibatch[1201-1300]: loss = 0.329648 * 100, metric = 11.49% * 100;
 Minibatch[1301-1400]: loss = 0.331826 * 100, metric = 11.67% * 100;
 Minibatch[1401-1500]: loss = 0.337749 * 100, metric = 12.14% * 100;
 Minibatch[1501-1600]: loss = 0.321623 * 100, metric = 11.23% * 100;
 Minibatch[1601-1700]: loss = 0.321362 * 100, metric = 11.30% * 100;
 Minibatch[1701-1800]: loss = 0.334186 * 100, metric = 11.85% * 100;
 Minibatch[1801-1900]: loss = 0.318102 * 100, metric = 11.33% * 100;
 Minibatch[1901-2000]: loss = 0.325257 * 100, metric = 11.52% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.335581 * 2000, metric = 11.82% * 2000 1013.278s (  2.0 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 18.92% * 2000;
0.45875404323637486
 Minibatch[   1- 100]: loss = 0.340102 * 100, metric = 11.70% * 100;
 Minibatch[ 101- 200]: loss = 0.318823 * 100, metric = 11.33% * 100;
 Minibatch[ 201- 300]: loss = 0.327112 * 100, metric = 11.54% * 100;
 Minibatch[ 301- 400]: loss = 0.302665 * 100, metric = 10.76% * 100;
 Minibatch[ 401- 500]: loss = 0.326277 * 100, metric = 11.32% * 100;
 Minibatch[ 501- 600]: loss = 0.304078 * 100, metric = 10.64% * 100;
 Minibatch[ 601- 700]: loss = 0.310386 * 100, metric = 11.00% * 100;
 Minibatch[ 701- 800]: loss = 0.313437 * 100, metric = 10.96% * 100;
 Minibatch[ 801- 900]: loss = 0.319063 * 100, metric = 11.22% * 100;
 Minibatch[ 901-1000]: loss = 0.319324 * 100, metric = 11.48% * 100;
 Minibatch[1001-1100]: loss = 0.324410 * 100, metric = 11.55% * 100;
 Minibatch[1101-1200]: loss = 0.307430 * 100, metric = 10.95% * 100;
 Minibatch[1201-1300]: loss = 0.307435 * 100, metric = 10.66% * 100;
 Minibatch[1301-1400]: loss = 0.323118 * 100, metric = 11.35% * 100;
 Minibatch[1401-1500]: loss = 0.323293 * 100, metric = 11.46% * 100;
 Minibatch[1501-1600]: loss = 0.303859 * 100, metric = 10.81% * 100;
 Minibatch[1601-1700]: loss = 0.314272 * 100, metric = 11.25% * 100;
 Minibatch[1701-1800]: loss = 0.321249 * 100, metric = 11.34% * 100;
 Minibatch[1801-1900]: loss = 0.310634 * 100, metric = 10.77% * 100;
 Minibatch[1901-2000]: loss = 0.309246 * 100, metric = 10.99% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.316311 * 2000, metric = 11.15% * 2000 964.449s (  2.1 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 19.67% * 2000;
 Minibatch[   1- 100]: loss = 0.321143 * 100, metric = 11.25% * 100;
 Minibatch[ 101- 200]: loss = 0.306855 * 100, metric = 11.02% * 100;
 Minibatch[ 201- 300]: loss = 0.306584 * 100, metric = 10.86% * 100;
 Minibatch[ 301- 400]: loss = 0.321514 * 100, metric = 11.49% * 100;
 Minibatch[ 401- 500]: loss = 0.292208 * 100, metric = 10.17% * 100;
 Minibatch[ 501- 600]: loss = 0.296162 * 100, metric = 10.15% * 100;
 Minibatch[ 601- 700]: loss = 0.301500 * 100, metric = 10.38% * 100;
 Minibatch[ 701- 800]: loss = 0.311612 * 100, metric = 10.83% * 100;
 Minibatch[ 801- 900]: loss = 0.298202 * 100, metric = 10.32% * 100;
 Minibatch[ 901-1000]: loss = 0.306485 * 100, metric = 10.81% * 100;
 Minibatch[1001-1100]: loss = 0.309890 * 100, metric = 11.03% * 100;
 Minibatch[1101-1200]: loss = 0.289509 * 100, metric = 10.20% * 100;
 Minibatch[1201-1300]: loss = 0.303645 * 100, metric = 10.57% * 100;
 Minibatch[1301-1400]: loss = 0.317613 * 100, metric = 11.15% * 100;
 Minibatch[1401-1500]: loss = 0.302943 * 100, metric = 10.66% * 100;
 Minibatch[1501-1600]: loss = 0.303452 * 100, metric = 10.45% * 100;
 Minibatch[1601-1700]: loss = 0.313551 * 100, metric = 11.27% * 100;
 Minibatch[1701-1800]: loss = 0.314811 * 100, metric = 11.11% * 100;
 Minibatch[1801-1900]: loss = 0.312675 * 100, metric = 10.90% * 100;
 Minibatch[1901-2000]: loss = 0.302574 * 100, metric = 10.49% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.306646 * 2000, metric = 10.76% * 2000 965.860s (  2.1 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 17.66% * 2000;
0.42813376446813345
 Minibatch[   1- 100]: loss = 0.293369 * 100, metric = 10.33% * 100;
 Minibatch[ 101- 200]: loss = 0.290654 * 100, metric = 10.22% * 100;
 Minibatch[ 201- 300]: loss = 0.300017 * 100, metric = 10.53% * 100;
 Minibatch[ 301- 400]: loss = 0.302689 * 100, metric = 10.23% * 100;
 Minibatch[ 401- 500]: loss = 0.286288 * 100, metric = 9.96% * 100;
 Minibatch[ 501- 600]: loss = 0.300040 * 100, metric = 10.53% * 100;
 Minibatch[ 601- 700]: loss = 0.287909 * 100, metric = 10.11% * 100;
 Minibatch[ 701- 800]: loss = 0.296713 * 100, metric = 10.39% * 100;
 Minibatch[ 801- 900]: loss = 0.294740 * 100, metric = 10.34% * 100;
 Minibatch[ 901-1000]: loss = 0.289436 * 100, metric = 10.01% * 100;
 Minibatch[1001-1100]: loss = 0.290342 * 100, metric = 9.77% * 100;
 Minibatch[1101-1200]: loss = 0.300293 * 100, metric = 10.28% * 100;
 Minibatch[1201-1300]: loss = 0.305620 * 100, metric = 10.44% * 100;
 Minibatch[1301-1400]: loss = 0.293728 * 100, metric = 10.20% * 100;
 Minibatch[1401-1500]: loss = 0.294725 * 100, metric = 10.40% * 100;
 Minibatch[1501-1600]: loss = 0.284352 * 100, metric = 9.82% * 100;
 Minibatch[1601-1700]: loss = 0.285686 * 100, metric = 10.12% * 100;
 Minibatch[1701-1800]: loss = 0.281540 * 100, metric = 9.81% * 100;
 Minibatch[1801-1900]: loss = 0.296790 * 100, metric = 10.21% * 100;
 Minibatch[1901-2000]: loss = 0.287942 * 100, metric = 10.15% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.293144 * 2000, metric = 10.19% * 2000 961.396s (  2.1 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 18.09% * 2000;
 Minibatch[   1- 100]: loss = 0.282787 * 100, metric = 9.90% * 100;
 Minibatch[ 101- 200]: loss = 0.289784 * 100, metric = 9.74% * 100;
 Minibatch[ 201- 300]: loss = 0.300175 * 100, metric = 10.21% * 100;
 Minibatch[ 301- 400]: loss = 0.279716 * 100, metric = 9.57% * 100;
 Minibatch[ 401- 500]: loss = 0.296683 * 100, metric = 10.31% * 100;
 Minibatch[ 501- 600]: loss = 0.270113 * 100, metric = 9.35% * 100;
 Minibatch[ 601- 700]: loss = 0.281870 * 100, metric = 9.79% * 100;
 Minibatch[ 701- 800]: loss = 0.285794 * 100, metric = 9.77% * 100;
 Minibatch[ 801- 900]: loss = 0.288635 * 100, metric = 10.10% * 100;
 Minibatch[ 901-1000]: loss = 0.282678 * 100, metric = 9.68% * 100;
 Minibatch[1001-1100]: loss = 0.296865 * 100, metric = 10.13% * 100;
 Minibatch[1101-1200]: loss = 0.274865 * 100, metric = 9.39% * 100;
 Minibatch[1201-1300]: loss = 0.283402 * 100, metric = 10.06% * 100;
 Minibatch[1301-1400]: loss = 0.275418 * 100, metric = 9.65% * 100;
 Minibatch[1401-1500]: loss = 0.275389 * 100, metric = 9.56% * 100;
 Minibatch[1501-1600]: loss = 0.281889 * 100, metric = 9.86% * 100;
 Minibatch[1601-1700]: loss = 0.289355 * 100, metric = 9.93% * 100;
 Minibatch[1701-1800]: loss = 0.281992 * 100, metric = 9.73% * 100;
 Minibatch[1801-1900]: loss = 0.281534 * 100, metric = 9.76% * 100;
 Minibatch[1901-2000]: loss = 0.290125 * 100, metric = 10.17% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.284453 * 2000, metric = 9.83% * 2000 951.311s (  2.1 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 16.20% * 2000;
0.408427543040365
 Minibatch[   1- 100]: loss = 0.288847 * 100, metric = 10.09% * 100;
 Minibatch[ 101- 200]: loss = 0.283436 * 100, metric = 9.86% * 100;
 Minibatch[ 201- 300]: loss = 0.269548 * 100, metric = 9.48% * 100;
 Minibatch[ 301- 400]: loss = 0.276688 * 100, metric = 9.72% * 100;
 Minibatch[ 401- 500]: loss = 0.284662 * 100, metric = 10.16% * 100;
 Minibatch[ 501- 600]: loss = 0.296826 * 100, metric = 10.44% * 100;
 Minibatch[ 601- 700]: loss = 0.272909 * 100, metric = 9.78% * 100;
 Minibatch[ 701- 800]: loss = 0.285156 * 100, metric = 9.70% * 100;
 Minibatch[ 801- 900]: loss = 0.270546 * 100, metric = 9.34% * 100;
 Minibatch[ 901-1000]: loss = 0.262911 * 100, metric = 9.31% * 100;
 Minibatch[1001-1100]: loss = 0.271449 * 100, metric = 9.54% * 100;
 Minibatch[1101-1200]: loss = 0.266025 * 100, metric = 9.10% * 100;
 Minibatch[1201-1300]: loss = 0.279424 * 100, metric = 9.59% * 100;
 Minibatch[1301-1400]: loss = 0.279845 * 100, metric = 9.80% * 100;
 Minibatch[1401-1500]: loss = 0.273046 * 100, metric = 9.44% * 100;
 Minibatch[1501-1600]: loss = 0.277373 * 100, metric = 9.58% * 100;
 Minibatch[1601-1700]: loss = 0.274018 * 100, metric = 9.53% * 100;
 Minibatch[1701-1800]: loss = 0.269035 * 100, metric = 9.14% * 100;
 Minibatch[1801-1900]: loss = 0.268310 * 100, metric = 9.29% * 100;
 Minibatch[1901-2000]: loss = 0.268661 * 100, metric = 9.39% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.275936 * 2000, metric = 9.61% * 2000 950.099s (  2.1 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 15.45% * 2000;
0.4032848787494004
 Minibatch[   1- 100]: loss = 0.259161 * 100, metric = 9.12% * 100;
 Minibatch[ 101- 200]: loss = 0.286522 * 100, metric = 9.92% * 100;
 Minibatch[ 201- 300]: loss = 0.268680 * 100, metric = 9.37% * 100;
 Minibatch[ 301- 400]: loss = 0.285842 * 100, metric = 9.88% * 100;
 Minibatch[ 401- 500]: loss = 0.273646 * 100, metric = 9.46% * 100;
 Minibatch[ 501- 600]: loss = 0.270192 * 100, metric = 9.32% * 100;
 Minibatch[ 601- 700]: loss = 0.271608 * 100, metric = 9.35% * 100;
 Minibatch[ 701- 800]: loss = 0.258567 * 100, metric = 9.01% * 100;
 Minibatch[ 801- 900]: loss = 0.263981 * 100, metric = 9.45% * 100;
 Minibatch[ 901-1000]: loss = 0.272394 * 100, metric = 9.61% * 100;
 Minibatch[1001-1100]: loss = 0.250864 * 100, metric = 8.93% * 100;
 Minibatch[1101-1200]: loss = 0.269877 * 100, metric = 9.44% * 100;
 Minibatch[1201-1300]: loss = 0.262143 * 100, metric = 9.18% * 100;
 Minibatch[1301-1400]: loss = 0.258987 * 100, metric = 8.83% * 100;
 Minibatch[1401-1500]: loss = 0.269353 * 100, metric = 9.25% * 100;
 Minibatch[1501-1600]: loss = 0.264518 * 100, metric = 9.14% * 100;
 Minibatch[1601-1700]: loss = 0.271001 * 100, metric = 9.36% * 100;
 Minibatch[1701-1800]: loss = 0.257552 * 100, metric = 8.68% * 100;
 Minibatch[1801-1900]: loss = 0.254634 * 100, metric = 8.69% * 100;
 Minibatch[1901-2000]: loss = 0.266082 * 100, metric = 9.10% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.266780 * 2000, metric = 9.25% * 2000 945.192s (  2.1 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 14.76% * 2000;
0.38225138703733685
 Minibatch[   1- 100]: loss = 0.275784 * 100, metric = 9.62% * 100;
 Minibatch[ 101- 200]: loss = 0.256910 * 100, metric = 8.71% * 100;
 Minibatch[ 201- 300]: loss = 0.260641 * 100, metric = 8.90% * 100;
 Minibatch[ 301- 400]: loss = 0.254921 * 100, metric = 8.73% * 100;
 Minibatch[ 401- 500]: loss = 0.268079 * 100, metric = 9.04% * 100;
 Minibatch[ 501- 600]: loss = 0.254954 * 100, metric = 8.79% * 100;
 Minibatch[ 601- 700]: loss = 0.245570 * 100, metric = 8.45% * 100;
 Minibatch[ 701- 800]: loss = 0.241040 * 100, metric = 8.06% * 100;
 Minibatch[ 801- 900]: loss = 0.254805 * 100, metric = 8.90% * 100;
 Minibatch[ 901-1000]: loss = 0.260782 * 100, metric = 9.02% * 100;
 Minibatch[1001-1100]: loss = 0.267077 * 100, metric = 9.19% * 100;
 Minibatch[1101-1200]: loss = 0.258245 * 100, metric = 8.84% * 100;
 Minibatch[1201-1300]: loss = 0.262910 * 100, metric = 9.29% * 100;
 Minibatch[1301-1400]: loss = 0.259169 * 100, metric = 8.88% * 100;
 Minibatch[1401-1500]: loss = 0.249633 * 100, metric = 8.67% * 100;
 Minibatch[1501-1600]: loss = 0.256894 * 100, metric = 9.09% * 100;
 Minibatch[1601-1700]: loss = 0.253119 * 100, metric = 8.55% * 100;
 Minibatch[1701-1800]: loss = 0.263180 * 100, metric = 8.87% * 100;
 Minibatch[1801-1900]: loss = 0.263671 * 100, metric = 9.20% * 100;
 Minibatch[1901-2000]: loss = 0.251508 * 100, metric = 8.65% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.257945 * 2000, metric = 8.87% * 2000 910.771s (  2.2 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 14.03% * 2000;
0.3708938391245902
 Minibatch[   1- 100]: loss = 0.239533 * 100, metric = 8.05% * 100;
 Minibatch[ 101- 200]: loss = 0.248153 * 100, metric = 8.50% * 100;
 Minibatch[ 201- 300]: loss = 0.254545 * 100, metric = 8.64% * 100;
 Minibatch[ 301- 400]: loss = 0.250363 * 100, metric = 8.46% * 100;
 Minibatch[ 401- 500]: loss = 0.255215 * 100, metric = 8.71% * 100;
 Minibatch[ 501- 600]: loss = 0.255871 * 100, metric = 8.76% * 100;
 Minibatch[ 601- 700]: loss = 0.249027 * 100, metric = 8.42% * 100;
 Minibatch[ 701- 800]: loss = 0.255451 * 100, metric = 8.84% * 100;
 Minibatch[ 801- 900]: loss = 0.255191 * 100, metric = 8.69% * 100;
 Minibatch[ 901-1000]: loss = 0.262177 * 100, metric = 8.96% * 100;
 Minibatch[1001-1100]: loss = 0.255474 * 100, metric = 8.91% * 100;
 Minibatch[1101-1200]: loss = 0.260619 * 100, metric = 8.92% * 100;
 Minibatch[1201-1300]: loss = 0.250985 * 100, metric = 8.79% * 100;
 Minibatch[1301-1400]: loss = 0.243672 * 100, metric = 8.68% * 100;
 Minibatch[1401-1500]: loss = 0.258512 * 100, metric = 9.09% * 100;
 Minibatch[1501-1600]: loss = 0.244093 * 100, metric = 8.58% * 100;
 Minibatch[1601-1700]: loss = 0.248207 * 100, metric = 8.51% * 100;
 Minibatch[1701-1800]: loss = 0.257841 * 100, metric = 8.90% * 100;
 Minibatch[1801-1900]: loss = 0.255788 * 100, metric = 8.94% * 100;
 Minibatch[1901-2000]: loss = 0.260150 * 100, metric = 9.22% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.253043 * 2000, metric = 8.73% * 2000 937.712s (  2.1 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 14.32% * 2000;
 Minibatch[   1- 100]: loss = 0.243067 * 100, metric = 8.52% * 100;
 Minibatch[ 101- 200]: loss = 0.243153 * 100, metric = 8.41% * 100;
 Minibatch[ 201- 300]: loss = 0.249778 * 100, metric = 8.79% * 100;
 Minibatch[ 301- 400]: loss = 0.272476 * 100, metric = 9.48% * 100;
 Minibatch[ 401- 500]: loss = 0.246088 * 100, metric = 8.69% * 100;
 Minibatch[ 501- 600]: loss = 0.236069 * 100, metric = 8.12% * 100;
 Minibatch[ 601- 700]: loss = 0.237327 * 100, metric = 8.38% * 100;
 Minibatch[ 701- 800]: loss = 0.248131 * 100, metric = 8.54% * 100;
 Minibatch[ 801- 900]: loss = 0.243671 * 100, metric = 8.29% * 100;
 Minibatch[ 901-1000]: loss = 0.253687 * 100, metric = 8.91% * 100;
 Minibatch[1001-1100]: loss = 0.251784 * 100, metric = 8.91% * 100;
 Minibatch[1101-1200]: loss = 0.253332 * 100, metric = 8.76% * 100;
 Minibatch[1201-1300]: loss = 0.252700 * 100, metric = 8.73% * 100;
 Minibatch[1301-1400]: loss = 0.240593 * 100, metric = 8.54% * 100;
 Minibatch[1401-1500]: loss = 0.253055 * 100, metric = 8.81% * 100;
 Minibatch[1501-1600]: loss = 0.231483 * 100, metric = 7.98% * 100;
 Minibatch[1601-1700]: loss = 0.249501 * 100, metric = 8.60% * 100;
 Minibatch[1701-1800]: loss = 0.238019 * 100, metric = 8.19% * 100;
 Minibatch[1801-1900]: loss = 0.244032 * 100, metric = 8.72% * 100;
 Minibatch[1901-2000]: loss = 0.252251 * 100, metric = 8.62% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.247010 * 2000, metric = 8.60% * 2000 935.091s (  2.1 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 15.18% * 2000;
 Minibatch[   1- 100]: loss = 0.245345 * 100, metric = 8.48% * 100;
 Minibatch[ 101- 200]: loss = 0.243551 * 100, metric = 8.59% * 100;
 Minibatch[ 201- 300]: loss = 0.246077 * 100, metric = 8.50% * 100;
 Minibatch[ 301- 400]: loss = 0.250747 * 100, metric = 8.66% * 100;
 Minibatch[ 401- 500]: loss = 0.257257 * 100, metric = 9.01% * 100;
 Minibatch[ 501- 600]: loss = 0.260027 * 100, metric = 9.06% * 100;
 Minibatch[ 601- 700]: loss = 0.240418 * 100, metric = 8.01% * 100;
 Minibatch[ 701- 800]: loss = 0.236276 * 100, metric = 8.23% * 100;
 Minibatch[ 801- 900]: loss = 0.239448 * 100, metric = 8.16% * 100;
 Minibatch[ 901-1000]: loss = 0.248528 * 100, metric = 8.82% * 100;
 Minibatch[1001-1100]: loss = 0.245557 * 100, metric = 8.27% * 100;
 Minibatch[1101-1200]: loss = 0.237685 * 100, metric = 8.18% * 100;
 Minibatch[1201-1300]: loss = 0.240418 * 100, metric = 8.54% * 100;
 Minibatch[1301-1400]: loss = 0.239944 * 100, metric = 8.27% * 100;
 Minibatch[1401-1500]: loss = 0.237000 * 100, metric = 8.33% * 100;
 Minibatch[1501-1600]: loss = 0.230606 * 100, metric = 7.90% * 100;
 Minibatch[1601-1700]: loss = 0.230422 * 100, metric = 7.87% * 100;
 Minibatch[1701-1800]: loss = 0.236347 * 100, metric = 8.06% * 100;
 Minibatch[1801-1900]: loss = 0.227206 * 100, metric = 7.86% * 100;
 Minibatch[1901-2000]: loss = 0.238917 * 100, metric = 8.16% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.241589 * 2000, metric = 8.35% * 2000 910.570s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 16.66% * 2000;
 Minibatch[   1- 100]: loss = 0.236193 * 100, metric = 8.06% * 100;
 Minibatch[ 101- 200]: loss = 0.226329 * 100, metric = 7.85% * 100;
 Minibatch[ 201- 300]: loss = 0.245002 * 100, metric = 8.40% * 100;
 Minibatch[ 301- 400]: loss = 0.234008 * 100, metric = 8.05% * 100;
 Minibatch[ 401- 500]: loss = 0.239674 * 100, metric = 8.29% * 100;
 Minibatch[ 501- 600]: loss = 0.232977 * 100, metric = 7.93% * 100;
 Minibatch[ 601- 700]: loss = 0.233059 * 100, metric = 7.85% * 100;
 Minibatch[ 701- 800]: loss = 0.245645 * 100, metric = 8.32% * 100;
 Minibatch[ 801- 900]: loss = 0.247485 * 100, metric = 8.56% * 100;
 Minibatch[ 901-1000]: loss = 0.247130 * 100, metric = 8.65% * 100;
 Minibatch[1001-1100]: loss = 0.247333 * 100, metric = 8.42% * 100;
 Minibatch[1101-1200]: loss = 0.237474 * 100, metric = 8.18% * 100;
 Minibatch[1201-1300]: loss = 0.222319 * 100, metric = 7.48% * 100;
 Minibatch[1301-1400]: loss = 0.247045 * 100, metric = 8.71% * 100;
 Minibatch[1401-1500]: loss = 0.237671 * 100, metric = 8.37% * 100;
 Minibatch[1501-1600]: loss = 0.225601 * 100, metric = 7.75% * 100;
 Minibatch[1601-1700]: loss = 0.234611 * 100, metric = 8.06% * 100;
 Minibatch[1701-1800]: loss = 0.228259 * 100, metric = 7.64% * 100;
 Minibatch[1801-1900]: loss = 0.229321 * 100, metric = 7.91% * 100;
 Minibatch[1901-2000]: loss = 0.234646 * 100, metric = 8.04% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.236589 * 2000, metric = 8.13% * 2000 913.572s (  2.2 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 15.40% * 2000;
 Minibatch[   1- 100]: loss = 0.229920 * 100, metric = 7.83% * 100;
 Minibatch[ 101- 200]: loss = 0.231411 * 100, metric = 8.08% * 100;
 Minibatch[ 201- 300]: loss = 0.230302 * 100, metric = 7.80% * 100;
 Minibatch[ 301- 400]: loss = 0.222201 * 100, metric = 7.62% * 100;
 Minibatch[ 401- 500]: loss = 0.232808 * 100, metric = 8.17% * 100;
 Minibatch[ 501- 600]: loss = 0.223343 * 100, metric = 7.76% * 100;
 Minibatch[ 601- 700]: loss = 0.217576 * 100, metric = 7.38% * 100;
 Minibatch[ 701- 800]: loss = 0.233311 * 100, metric = 7.85% * 100;
 Minibatch[ 801- 900]: loss = 0.247866 * 100, metric = 8.53% * 100;
 Minibatch[ 901-1000]: loss = 0.231239 * 100, metric = 8.05% * 100;
 Minibatch[1001-1100]: loss = 0.231444 * 100, metric = 7.89% * 100;
 Minibatch[1101-1200]: loss = 0.236353 * 100, metric = 8.08% * 100;
 Minibatch[1201-1300]: loss = 0.220901 * 100, metric = 7.51% * 100;
 Minibatch[1301-1400]: loss = 0.244940 * 100, metric = 8.38% * 100;
 Minibatch[1401-1500]: loss = 0.214688 * 100, metric = 7.40% * 100;
 Minibatch[1501-1600]: loss = 0.226538 * 100, metric = 7.89% * 100;
 Minibatch[1601-1700]: loss = 0.233275 * 100, metric = 8.25% * 100;
 Minibatch[1701-1800]: loss = 0.221202 * 100, metric = 7.49% * 100;
 Minibatch[1801-1900]: loss = 0.232351 * 100, metric = 8.01% * 100;
 Minibatch[1901-2000]: loss = 0.225234 * 100, metric = 7.68% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.229345 * 2000, metric = 7.88% * 2000 889.323s (  2.2 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 13.21% * 2000;
0.36727699691057203
 Minibatch[   1- 100]: loss = 0.239711 * 100, metric = 8.44% * 100;
 Minibatch[ 101- 200]: loss = 0.230481 * 100, metric = 7.99% * 100;
 Minibatch[ 201- 300]: loss = 0.228429 * 100, metric = 7.77% * 100;
 Minibatch[ 301- 400]: loss = 0.229410 * 100, metric = 7.82% * 100;
 Minibatch[ 401- 500]: loss = 0.216252 * 100, metric = 7.28% * 100;
 Minibatch[ 501- 600]: loss = 0.230254 * 100, metric = 7.71% * 100;
 Minibatch[ 601- 700]: loss = 0.221763 * 100, metric = 7.70% * 100;
 Minibatch[ 701- 800]: loss = 0.218426 * 100, metric = 7.39% * 100;
 Minibatch[ 801- 900]: loss = 0.213098 * 100, metric = 7.20% * 100;
 Minibatch[ 901-1000]: loss = 0.223986 * 100, metric = 7.78% * 100;
 Minibatch[1001-1100]: loss = 0.214464 * 100, metric = 7.33% * 100;
 Minibatch[1101-1200]: loss = 0.213012 * 100, metric = 7.30% * 100;
 Minibatch[1201-1300]: loss = 0.202475 * 100, metric = 6.72% * 100;
 Minibatch[1301-1400]: loss = 0.214023 * 100, metric = 7.24% * 100;
 Minibatch[1401-1500]: loss = 0.220760 * 100, metric = 7.65% * 100;
 Minibatch[1501-1600]: loss = 0.219662 * 100, metric = 7.55% * 100;
 Minibatch[1601-1700]: loss = 0.222184 * 100, metric = 7.67% * 100;
 Minibatch[1701-1800]: loss = 0.229695 * 100, metric = 7.83% * 100;
 Minibatch[1801-1900]: loss = 0.231270 * 100, metric = 7.81% * 100;
 Minibatch[1901-2000]: loss = 0.214882 * 100, metric = 7.43% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.221712 * 2000, metric = 7.58% * 2000 921.064s (  2.2 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.67% * 2000;
 Minibatch[   1- 100]: loss = 0.205319 * 100, metric = 7.03% * 100;
 Minibatch[ 101- 200]: loss = 0.230245 * 100, metric = 8.04% * 100;
 Minibatch[ 201- 300]: loss = 0.225893 * 100, metric = 7.55% * 100;
 Minibatch[ 301- 400]: loss = 0.212821 * 100, metric = 7.20% * 100;
 Minibatch[ 401- 500]: loss = 0.220219 * 100, metric = 7.51% * 100;
 Minibatch[ 501- 600]: loss = 0.205779 * 100, metric = 6.75% * 100;
 Minibatch[ 601- 700]: loss = 0.201804 * 100, metric = 6.85% * 100;
 Minibatch[ 701- 800]: loss = 0.210003 * 100, metric = 6.88% * 100;
 Minibatch[ 801- 900]: loss = 0.218311 * 100, metric = 7.20% * 100;
 Minibatch[ 901-1000]: loss = 0.208396 * 100, metric = 7.01% * 100;
 Minibatch[1001-1100]: loss = 0.213024 * 100, metric = 7.08% * 100;
 Minibatch[1101-1200]: loss = 0.226616 * 100, metric = 7.64% * 100;
 Minibatch[1201-1300]: loss = 0.219474 * 100, metric = 7.36% * 100;
 Minibatch[1301-1400]: loss = 0.205089 * 100, metric = 6.98% * 100;
 Minibatch[1401-1500]: loss = 0.216783 * 100, metric = 7.42% * 100;
 Minibatch[1501-1600]: loss = 0.215259 * 100, metric = 7.20% * 100;
 Minibatch[1601-1700]: loss = 0.221582 * 100, metric = 7.68% * 100;
 Minibatch[1701-1800]: loss = 0.210832 * 100, metric = 7.27% * 100;
 Minibatch[1801-1900]: loss = 0.224249 * 100, metric = 7.71% * 100;
 Minibatch[1901-2000]: loss = 0.227715 * 100, metric = 7.85% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.215971 * 2000, metric = 7.31% * 2000 934.694s (  2.1 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 13.19% * 2000;
 Minibatch[   1- 100]: loss = 0.197426 * 100, metric = 6.60% * 100;
 Minibatch[ 101- 200]: loss = 0.221834 * 100, metric = 7.86% * 100;
 Minibatch[ 201- 300]: loss = 0.203424 * 100, metric = 7.09% * 100;
 Minibatch[ 301- 400]: loss = 0.214235 * 100, metric = 7.20% * 100;
 Minibatch[ 401- 500]: loss = 0.202932 * 100, metric = 6.88% * 100;
 Minibatch[ 501- 600]: loss = 0.206965 * 100, metric = 6.83% * 100;
 Minibatch[ 601- 700]: loss = 0.215520 * 100, metric = 7.35% * 100;
 Minibatch[ 701- 800]: loss = 0.204882 * 100, metric = 6.94% * 100;
 Minibatch[ 801- 900]: loss = 0.216821 * 100, metric = 7.41% * 100;
 Minibatch[ 901-1000]: loss = 0.213909 * 100, metric = 7.35% * 100;
 Minibatch[1001-1100]: loss = 0.223427 * 100, metric = 7.73% * 100;
 Minibatch[1101-1200]: loss = 0.212991 * 100, metric = 7.30% * 100;
 Minibatch[1201-1300]: loss = 0.224130 * 100, metric = 7.67% * 100;
 Minibatch[1301-1400]: loss = 0.218484 * 100, metric = 7.26% * 100;
 Minibatch[1401-1500]: loss = 0.198195 * 100, metric = 6.66% * 100;
 Minibatch[1501-1600]: loss = 0.207907 * 100, metric = 6.90% * 100;
 Minibatch[1601-1700]: loss = 0.197549 * 100, metric = 6.61% * 100;
 Minibatch[1701-1800]: loss = 0.206218 * 100, metric = 7.17% * 100;
 Minibatch[1801-1900]: loss = 0.204084 * 100, metric = 7.19% * 100;
 Minibatch[1901-2000]: loss = 0.202104 * 100, metric = 6.89% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.209652 * 2000, metric = 7.14% * 2000 911.478s (  2.2 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 14.45% * 2000;
 Minibatch[   1- 100]: loss = 0.214135 * 100, metric = 7.38% * 100;
 Minibatch[ 101- 200]: loss = 0.218922 * 100, metric = 7.37% * 100;
 Minibatch[ 201- 300]: loss = 0.200140 * 100, metric = 6.76% * 100;
 Minibatch[ 301- 400]: loss = 0.208941 * 100, metric = 7.06% * 100;
 Minibatch[ 401- 500]: loss = 0.211302 * 100, metric = 7.21% * 100;
 Minibatch[ 501- 600]: loss = 0.203624 * 100, metric = 6.80% * 100;
 Minibatch[ 601- 700]: loss = 0.208138 * 100, metric = 7.15% * 100;
 Minibatch[ 701- 800]: loss = 0.207462 * 100, metric = 7.04% * 100;
 Minibatch[ 801- 900]: loss = 0.226864 * 100, metric = 7.68% * 100;
 Minibatch[ 901-1000]: loss = 0.206376 * 100, metric = 7.33% * 100;
 Minibatch[1001-1100]: loss = 0.216020 * 100, metric = 7.43% * 100;
 Minibatch[1101-1200]: loss = 0.211853 * 100, metric = 7.52% * 100;
 Minibatch[1201-1300]: loss = 0.204617 * 100, metric = 7.17% * 100;
 Minibatch[1301-1400]: loss = 0.203933 * 100, metric = 7.02% * 100;
 Minibatch[1401-1500]: loss = 0.207766 * 100, metric = 7.20% * 100;
 Minibatch[1501-1600]: loss = 0.212361 * 100, metric = 7.19% * 100;
 Minibatch[1601-1700]: loss = 0.205792 * 100, metric = 7.11% * 100;
 Minibatch[1701-1800]: loss = 0.196587 * 100, metric = 6.72% * 100;
 Minibatch[1801-1900]: loss = 0.200510 * 100, metric = 6.90% * 100;
 Minibatch[1901-2000]: loss = 0.198207 * 100, metric = 6.68% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.208177 * 2000, metric = 7.14% * 2000 914.612s (  2.2 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 14.61% * 2000;
 Minibatch[   1- 100]: loss = 0.207171 * 100, metric = 7.12% * 100;
 Minibatch[ 101- 200]: loss = 0.204048 * 100, metric = 7.04% * 100;
 Minibatch[ 201- 300]: loss = 0.200315 * 100, metric = 6.87% * 100;
 Minibatch[ 301- 400]: loss = 0.218930 * 100, metric = 7.22% * 100;
 Minibatch[ 401- 500]: loss = 0.207076 * 100, metric = 7.39% * 100;
 Minibatch[ 501- 600]: loss = 0.217087 * 100, metric = 7.50% * 100;
 Minibatch[ 601- 700]: loss = 0.219044 * 100, metric = 7.65% * 100;
 Minibatch[ 701- 800]: loss = 0.210352 * 100, metric = 7.32% * 100;
 Minibatch[ 801- 900]: loss = 0.219512 * 100, metric = 7.58% * 100;
 Minibatch[ 901-1000]: loss = 0.217922 * 100, metric = 7.74% * 100;
 Minibatch[1001-1100]: loss = 0.205249 * 100, metric = 7.18% * 100;
 Minibatch[1101-1200]: loss = 0.208612 * 100, metric = 7.12% * 100;
 Minibatch[1201-1300]: loss = 0.209256 * 100, metric = 6.95% * 100;
 Minibatch[1301-1400]: loss = 0.213790 * 100, metric = 7.35% * 100;
 Minibatch[1401-1500]: loss = 0.206138 * 100, metric = 7.04% * 100;
 Minibatch[1501-1600]: loss = 0.220350 * 100, metric = 7.51% * 100;
 Minibatch[1601-1700]: loss = 0.210434 * 100, metric = 7.34% * 100;
 Minibatch[1701-1800]: loss = 0.211663 * 100, metric = 7.24% * 100;
 Minibatch[1801-1900]: loss = 0.205564 * 100, metric = 6.99% * 100;
 Minibatch[1901-2000]: loss = 0.204121 * 100, metric = 7.02% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.210832 * 2000, metric = 7.26% * 2000 911.538s (  2.2 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 14.12% * 2000;
 Minibatch[   1- 100]: loss = 0.207155 * 100, metric = 7.19% * 100;
 Minibatch[ 101- 200]: loss = 0.210242 * 100, metric = 7.30% * 100;
 Minibatch[ 201- 300]: loss = 0.205878 * 100, metric = 6.98% * 100;
 Minibatch[ 301- 400]: loss = 0.205344 * 100, metric = 6.98% * 100;
 Minibatch[ 401- 500]: loss = 0.199727 * 100, metric = 6.85% * 100;
 Minibatch[ 501- 600]: loss = 0.194872 * 100, metric = 6.67% * 100;
 Minibatch[ 601- 700]: loss = 0.200496 * 100, metric = 6.86% * 100;
 Minibatch[ 701- 800]: loss = 0.187021 * 100, metric = 6.53% * 100;
 Minibatch[ 801- 900]: loss = 0.210141 * 100, metric = 7.12% * 100;
 Minibatch[ 901-1000]: loss = 0.197502 * 100, metric = 6.93% * 100;
 Minibatch[1001-1100]: loss = 0.205496 * 100, metric = 7.12% * 100;
 Minibatch[1101-1200]: loss = 0.205008 * 100, metric = 6.71% * 100;
 Minibatch[1201-1300]: loss = 0.208014 * 100, metric = 7.19% * 100;
 Minibatch[1301-1400]: loss = 0.192887 * 100, metric = 6.53% * 100;
 Minibatch[1401-1500]: loss = 0.202214 * 100, metric = 6.78% * 100;
 Minibatch[1501-1600]: loss = 0.211760 * 100, metric = 7.32% * 100;
 Minibatch[1601-1700]: loss = 0.201446 * 100, metric = 6.90% * 100;
 Minibatch[1701-1800]: loss = 0.201030 * 100, metric = 6.86% * 100;
 Minibatch[1801-1900]: loss = 0.212883 * 100, metric = 7.27% * 100;
 Minibatch[1901-2000]: loss = 0.201812 * 100, metric = 6.71% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.203046 * 2000, metric = 6.94% * 2000 912.818s (  2.2 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 13.20% * 2000;
 Minibatch[   1- 100]: loss = 0.213750 * 100, metric = 7.43% * 100;
 Minibatch[ 101- 200]: loss = 0.202524 * 100, metric = 6.98% * 100;
 Minibatch[ 201- 300]: loss = 0.208234 * 100, metric = 7.26% * 100;
 Minibatch[ 301- 400]: loss = 0.202992 * 100, metric = 6.96% * 100;
 Minibatch[ 401- 500]: loss = 0.198295 * 100, metric = 6.47% * 100;
 Minibatch[ 501- 600]: loss = 0.202589 * 100, metric = 6.81% * 100;
 Minibatch[ 601- 700]: loss = 0.194814 * 100, metric = 6.66% * 100;
 Minibatch[ 701- 800]: loss = 0.202476 * 100, metric = 7.09% * 100;
 Minibatch[ 801- 900]: loss = 0.201582 * 100, metric = 6.92% * 100;
 Minibatch[ 901-1000]: loss = 0.208628 * 100, metric = 7.05% * 100;
 Minibatch[1001-1100]: loss = 0.194250 * 100, metric = 6.50% * 100;
 Minibatch[1101-1200]: loss = 0.184721 * 100, metric = 6.40% * 100;
 Minibatch[1201-1300]: loss = 0.195362 * 100, metric = 6.80% * 100;
 Minibatch[1301-1400]: loss = 0.202484 * 100, metric = 6.81% * 100;
 Minibatch[1401-1500]: loss = 0.193126 * 100, metric = 6.62% * 100;
 Minibatch[1501-1600]: loss = 0.190640 * 100, metric = 6.44% * 100;
 Minibatch[1601-1700]: loss = 0.194286 * 100, metric = 6.65% * 100;
 Minibatch[1701-1800]: loss = 0.190004 * 100, metric = 6.43% * 100;
 Minibatch[1801-1900]: loss = 0.196715 * 100, metric = 6.82% * 100;
 Minibatch[1901-2000]: loss = 0.196143 * 100, metric = 6.72% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.198681 * 2000, metric = 6.79% * 2000 911.078s (  2.2 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 13.56% * 2000;
 Minibatch[   1- 100]: loss = 0.196061 * 100, metric = 6.64% * 100;
 Minibatch[ 101- 200]: loss = 0.203064 * 100, metric = 6.83% * 100;
 Minibatch[ 201- 300]: loss = 0.191700 * 100, metric = 6.66% * 100;
 Minibatch[ 301- 400]: loss = 0.197863 * 100, metric = 6.65% * 100;
 Minibatch[ 401- 500]: loss = 0.204524 * 100, metric = 6.98% * 100;
 Minibatch[ 501- 600]: loss = 0.195356 * 100, metric = 6.71% * 100;
 Minibatch[ 601- 700]: loss = 0.198187 * 100, metric = 6.65% * 100;
 Minibatch[ 701- 800]: loss = 0.185571 * 100, metric = 6.33% * 100;
 Minibatch[ 801- 900]: loss = 0.187622 * 100, metric = 6.68% * 100;
 Minibatch[ 901-1000]: loss = 0.198243 * 100, metric = 6.68% * 100;
 Minibatch[1001-1100]: loss = 0.191828 * 100, metric = 6.52% * 100;
 Minibatch[1101-1200]: loss = 0.195566 * 100, metric = 6.70% * 100;
 Minibatch[1201-1300]: loss = 0.193734 * 100, metric = 6.65% * 100;
 Minibatch[1301-1400]: loss = 0.199786 * 100, metric = 7.03% * 100;
 Minibatch[1401-1500]: loss = 0.191294 * 100, metric = 6.68% * 100;
 Minibatch[1501-1600]: loss = 0.193945 * 100, metric = 6.65% * 100;
 Minibatch[1601-1700]: loss = 0.193145 * 100, metric = 6.70% * 100;
 Minibatch[1701-1800]: loss = 0.195592 * 100, metric = 6.66% * 100;
 Minibatch[1801-1900]: loss = 0.199637 * 100, metric = 6.80% * 100;
 Minibatch[1901-2000]: loss = 0.193083 * 100, metric = 6.61% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.195290 * 2000, metric = 6.69% * 2000 896.830s (  2.2 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 13.97% * 2000;
 Minibatch[   1- 100]: loss = 0.182178 * 100, metric = 6.19% * 100;
 Minibatch[ 101- 200]: loss = 0.190437 * 100, metric = 6.41% * 100;
 Minibatch[ 201- 300]: loss = 0.183806 * 100, metric = 6.28% * 100;
 Minibatch[ 301- 400]: loss = 0.190995 * 100, metric = 6.60% * 100;
 Minibatch[ 401- 500]: loss = 0.187380 * 100, metric = 6.37% * 100;
 Minibatch[ 501- 600]: loss = 0.180096 * 100, metric = 6.11% * 100;
 Minibatch[ 601- 700]: loss = 0.189683 * 100, metric = 6.27% * 100;
 Minibatch[ 701- 800]: loss = 0.180667 * 100, metric = 6.10% * 100;
 Minibatch[ 801- 900]: loss = 0.190957 * 100, metric = 6.56% * 100;
 Minibatch[ 901-1000]: loss = 0.185836 * 100, metric = 6.14% * 100;
 Minibatch[1001-1100]: loss = 0.182821 * 100, metric = 6.09% * 100;
 Minibatch[1101-1200]: loss = 0.194757 * 100, metric = 6.54% * 100;
 Minibatch[1201-1300]: loss = 0.189694 * 100, metric = 6.27% * 100;
 Minibatch[1301-1400]: loss = 0.181042 * 100, metric = 6.06% * 100;
 Minibatch[1401-1500]: loss = 0.183203 * 100, metric = 6.34% * 100;
 Minibatch[1501-1600]: loss = 0.193571 * 100, metric = 6.64% * 100;
 Minibatch[1601-1700]: loss = 0.181992 * 100, metric = 6.18% * 100;
 Minibatch[1701-1800]: loss = 0.184370 * 100, metric = 6.22% * 100;
 Minibatch[1801-1900]: loss = 0.188416 * 100, metric = 6.28% * 100;
 Minibatch[1901-2000]: loss = 0.196051 * 100, metric = 6.76% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.186898 * 2000, metric = 6.32% * 2000 905.574s (  2.2 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.16% * 2000;
 Minibatch[   1- 100]: loss = 0.194684 * 100, metric = 6.54% * 100;
 Minibatch[ 101- 200]: loss = 0.196745 * 100, metric = 6.70% * 100;
 Minibatch[ 201- 300]: loss = 0.191203 * 100, metric = 6.69% * 100;
 Minibatch[ 301- 400]: loss = 0.194437 * 100, metric = 6.71% * 100;
 Minibatch[ 401- 500]: loss = 0.187553 * 100, metric = 6.15% * 100;
 Minibatch[ 501- 600]: loss = 0.189857 * 100, metric = 6.40% * 100;
 Minibatch[ 601- 700]: loss = 0.195025 * 100, metric = 6.67% * 100;
 Minibatch[ 701- 800]: loss = 0.182636 * 100, metric = 6.13% * 100;
 Minibatch[ 801- 900]: loss = 0.182186 * 100, metric = 6.38% * 100;
 Minibatch[ 901-1000]: loss = 0.194524 * 100, metric = 6.70% * 100;
 Minibatch[1001-1100]: loss = 0.190504 * 100, metric = 6.53% * 100;
 Minibatch[1101-1200]: loss = 0.196852 * 100, metric = 6.59% * 100;
 Minibatch[1201-1300]: loss = 0.204401 * 100, metric = 6.89% * 100;
 Minibatch[1301-1400]: loss = 0.183850 * 100, metric = 6.21% * 100;
 Minibatch[1401-1500]: loss = 0.180483 * 100, metric = 6.07% * 100;
 Minibatch[1501-1600]: loss = 0.195911 * 100, metric = 6.62% * 100;
 Minibatch[1601-1700]: loss = 0.184182 * 100, metric = 6.12% * 100;
 Minibatch[1701-1800]: loss = 0.186354 * 100, metric = 6.19% * 100;
 Minibatch[1801-1900]: loss = 0.176256 * 100, metric = 5.84% * 100;
 Minibatch[1901-2000]: loss = 0.171974 * 100, metric = 5.71% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.188981 * 2000, metric = 6.39% * 2000 913.798s (  2.2 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.51% * 2000;
 Minibatch[   1- 100]: loss = 0.185596 * 100, metric = 6.15% * 100;
 Minibatch[ 101- 200]: loss = 0.171793 * 100, metric = 5.84% * 100;
 Minibatch[ 201- 300]: loss = 0.189306 * 100, metric = 6.51% * 100;
 Minibatch[ 301- 400]: loss = 0.178165 * 100, metric = 6.18% * 100;
 Minibatch[ 401- 500]: loss = 0.185716 * 100, metric = 6.07% * 100;
 Minibatch[ 501- 600]: loss = 0.177993 * 100, metric = 5.88% * 100;
 Minibatch[ 601- 700]: loss = 0.194045 * 100, metric = 6.31% * 100;
 Minibatch[ 701- 800]: loss = 0.185821 * 100, metric = 6.38% * 100;
 Minibatch[ 801- 900]: loss = 0.168798 * 100, metric = 5.72% * 100;
 Minibatch[ 901-1000]: loss = 0.177648 * 100, metric = 5.99% * 100;
 Minibatch[1001-1100]: loss = 0.191936 * 100, metric = 6.73% * 100;
 Minibatch[1101-1200]: loss = 0.184743 * 100, metric = 6.15% * 100;
 Minibatch[1201-1300]: loss = 0.184485 * 100, metric = 6.32% * 100;
 Minibatch[1301-1400]: loss = 0.177074 * 100, metric = 5.93% * 100;
 Minibatch[1401-1500]: loss = 0.182782 * 100, metric = 6.24% * 100;
 Minibatch[1501-1600]: loss = 0.179113 * 100, metric = 6.10% * 100;
 Minibatch[1601-1700]: loss = 0.199446 * 100, metric = 6.72% * 100;
 Minibatch[1701-1800]: loss = 0.192164 * 100, metric = 6.49% * 100;
 Minibatch[1801-1900]: loss = 0.181899 * 100, metric = 6.16% * 100;
 Minibatch[1901-2000]: loss = 0.183772 * 100, metric = 6.38% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.183615 * 2000, metric = 6.21% * 2000 922.393s (  2.2 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.14% * 2000;
 Minibatch[   1- 100]: loss = 0.183499 * 100, metric = 6.02% * 100;
 Minibatch[ 101- 200]: loss = 0.188827 * 100, metric = 6.41% * 100;
 Minibatch[ 201- 300]: loss = 0.181063 * 100, metric = 6.23% * 100;
 Minibatch[ 301- 400]: loss = 0.179121 * 100, metric = 6.02% * 100;
 Minibatch[ 401- 500]: loss = 0.182972 * 100, metric = 6.24% * 100;
 Minibatch[ 501- 600]: loss = 0.181612 * 100, metric = 6.04% * 100;
 Minibatch[ 601- 700]: loss = 0.172605 * 100, metric = 5.80% * 100;
 Minibatch[ 701- 800]: loss = 0.179212 * 100, metric = 6.03% * 100;
 Minibatch[ 801- 900]: loss = 0.186270 * 100, metric = 6.18% * 100;
 Minibatch[ 901-1000]: loss = 0.187523 * 100, metric = 6.37% * 100;
 Minibatch[1001-1100]: loss = 0.171225 * 100, metric = 5.74% * 100;
 Minibatch[1101-1200]: loss = 0.181693 * 100, metric = 6.17% * 100;
 Minibatch[1201-1300]: loss = 0.180670 * 100, metric = 5.93% * 100;
 Minibatch[1301-1400]: loss = 0.185136 * 100, metric = 6.23% * 100;
 Minibatch[1401-1500]: loss = 0.178213 * 100, metric = 6.10% * 100;
 Minibatch[1501-1600]: loss = 0.188284 * 100, metric = 6.47% * 100;
 Minibatch[1601-1700]: loss = 0.172013 * 100, metric = 5.81% * 100;
 Minibatch[1701-1800]: loss = 0.178901 * 100, metric = 5.89% * 100;
 Minibatch[1801-1900]: loss = 0.180752 * 100, metric = 6.14% * 100;
 Minibatch[1901-2000]: loss = 0.182602 * 100, metric = 6.07% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.181110 * 2000, metric = 6.09% * 2000 926.903s (  2.2 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.58% * 2000;
 Minibatch[   1- 100]: loss = 0.190158 * 100, metric = 6.61% * 100;
 Minibatch[ 101- 200]: loss = 0.179197 * 100, metric = 5.97% * 100;
 Minibatch[ 201- 300]: loss = 0.189172 * 100, metric = 6.39% * 100;
 Minibatch[ 301- 400]: loss = 0.187163 * 100, metric = 6.30% * 100;
 Minibatch[ 401- 500]: loss = 0.186407 * 100, metric = 6.56% * 100;
 Minibatch[ 501- 600]: loss = 0.195339 * 100, metric = 6.86% * 100;
 Minibatch[ 601- 700]: loss = 0.176370 * 100, metric = 6.07% * 100;
 Minibatch[ 701- 800]: loss = 0.174604 * 100, metric = 5.90% * 100;
 Minibatch[ 801- 900]: loss = 0.187694 * 100, metric = 6.42% * 100;
 Minibatch[ 901-1000]: loss = 0.186535 * 100, metric = 6.15% * 100;
 Minibatch[1001-1100]: loss = 0.184929 * 100, metric = 6.44% * 100;
 Minibatch[1101-1200]: loss = 0.173453 * 100, metric = 5.86% * 100;
 Minibatch[1201-1300]: loss = 0.185280 * 100, metric = 6.31% * 100;
 Minibatch[1301-1400]: loss = 0.183497 * 100, metric = 6.42% * 100;
 Minibatch[1401-1500]: loss = 0.191775 * 100, metric = 6.54% * 100;
 Minibatch[1501-1600]: loss = 0.175285 * 100, metric = 5.79% * 100;
 Minibatch[1601-1700]: loss = 0.180396 * 100, metric = 6.09% * 100;
 Minibatch[1701-1800]: loss = 0.178727 * 100, metric = 6.16% * 100;
 Minibatch[1801-1900]: loss = 0.179814 * 100, metric = 6.13% * 100;
 Minibatch[1901-2000]: loss = 0.181440 * 100, metric = 6.08% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.183362 * 2000, metric = 6.25% * 2000 914.488s (  2.2 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.34% * 2000;
 Minibatch[   1- 100]: loss = 0.170318 * 100, metric = 5.73% * 100;
 Minibatch[ 101- 200]: loss = 0.176129 * 100, metric = 5.88% * 100;
 Minibatch[ 201- 300]: loss = 0.186624 * 100, metric = 6.50% * 100;
 Minibatch[ 301- 400]: loss = 0.192992 * 100, metric = 6.74% * 100;
 Minibatch[ 401- 500]: loss = 0.172225 * 100, metric = 5.85% * 100;
 Minibatch[ 501- 600]: loss = 0.177763 * 100, metric = 6.01% * 100;
 Minibatch[ 601- 700]: loss = 0.182941 * 100, metric = 6.35% * 100;
 Minibatch[ 701- 800]: loss = 0.182014 * 100, metric = 6.04% * 100;
 Minibatch[ 801- 900]: loss = 0.187325 * 100, metric = 6.52% * 100;
 Minibatch[ 901-1000]: loss = 0.184397 * 100, metric = 6.42% * 100;
 Minibatch[1001-1100]: loss = 0.182998 * 100, metric = 6.30% * 100;
 Minibatch[1101-1200]: loss = 0.173285 * 100, metric = 5.93% * 100;
 Minibatch[1201-1300]: loss = 0.179760 * 100, metric = 6.24% * 100;
 Minibatch[1301-1400]: loss = 0.176738 * 100, metric = 6.28% * 100;
 Minibatch[1401-1500]: loss = 0.188188 * 100, metric = 6.36% * 100;
 Minibatch[1501-1600]: loss = 0.172713 * 100, metric = 5.90% * 100;
 Minibatch[1601-1700]: loss = 0.186273 * 100, metric = 6.45% * 100;
 Minibatch[1701-1800]: loss = 0.172607 * 100, metric = 5.97% * 100;
 Minibatch[1801-1900]: loss = 0.183638 * 100, metric = 6.22% * 100;
 Minibatch[1901-2000]: loss = 0.176121 * 100, metric = 6.03% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.180252 * 2000, metric = 6.19% * 2000 910.871s (  2.2 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 15.22% * 2000;
 Minibatch[   1- 100]: loss = 0.186178 * 100, metric = 6.31% * 100;
 Minibatch[ 101- 200]: loss = 0.167987 * 100, metric = 5.74% * 100;
 Minibatch[ 201- 300]: loss = 0.175535 * 100, metric = 5.88% * 100;
 Minibatch[ 301- 400]: loss = 0.184030 * 100, metric = 6.33% * 100;
 Minibatch[ 401- 500]: loss = 0.176935 * 100, metric = 6.01% * 100;
 Minibatch[ 501- 600]: loss = 0.163315 * 100, metric = 5.57% * 100;
 Minibatch[ 601- 700]: loss = 0.175826 * 100, metric = 5.99% * 100;
 Minibatch[ 701- 800]: loss = 0.171968 * 100, metric = 5.97% * 100;
 Minibatch[ 801- 900]: loss = 0.181999 * 100, metric = 6.11% * 100;
 Minibatch[ 901-1000]: loss = 0.166941 * 100, metric = 5.67% * 100;
 Minibatch[1001-1100]: loss = 0.177684 * 100, metric = 5.95% * 100;
 Minibatch[1101-1200]: loss = 0.182255 * 100, metric = 6.21% * 100;
 Minibatch[1201-1300]: loss = 0.181190 * 100, metric = 6.18% * 100;
 Minibatch[1301-1400]: loss = 0.177052 * 100, metric = 6.13% * 100;
 Minibatch[1401-1500]: loss = 0.175978 * 100, metric = 5.94% * 100;
 Minibatch[1501-1600]: loss = 0.180103 * 100, metric = 6.21% * 100;
 Minibatch[1601-1700]: loss = 0.172166 * 100, metric = 5.85% * 100;
 Minibatch[1701-1800]: loss = 0.176462 * 100, metric = 5.98% * 100;
 Minibatch[1801-1900]: loss = 0.177748 * 100, metric = 6.09% * 100;
 Minibatch[1901-2000]: loss = 0.186316 * 100, metric = 6.33% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.176883 * 2000, metric = 6.02% * 2000 901.077s (  2.2 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.87% * 2000;
 Minibatch[   1- 100]: loss = 0.171527 * 100, metric = 5.79% * 100;
 Minibatch[ 101- 200]: loss = 0.185026 * 100, metric = 6.35% * 100;
 Minibatch[ 201- 300]: loss = 0.179629 * 100, metric = 6.28% * 100;
 Minibatch[ 301- 400]: loss = 0.173912 * 100, metric = 6.04% * 100;
 Minibatch[ 401- 500]: loss = 0.174945 * 100, metric = 5.77% * 100;
 Minibatch[ 501- 600]: loss = 0.171633 * 100, metric = 5.72% * 100;
 Minibatch[ 601- 700]: loss = 0.187202 * 100, metric = 6.59% * 100;
 Minibatch[ 701- 800]: loss = 0.183978 * 100, metric = 6.28% * 100;
 Minibatch[ 801- 900]: loss = 0.179978 * 100, metric = 6.17% * 100;
 Minibatch[ 901-1000]: loss = 0.166724 * 100, metric = 5.71% * 100;
 Minibatch[1001-1100]: loss = 0.169466 * 100, metric = 5.82% * 100;
 Minibatch[1101-1200]: loss = 0.173505 * 100, metric = 5.93% * 100;
 Minibatch[1201-1300]: loss = 0.174052 * 100, metric = 6.00% * 100;
 Minibatch[1301-1400]: loss = 0.175402 * 100, metric = 6.01% * 100;
 Minibatch[1401-1500]: loss = 0.177565 * 100, metric = 6.02% * 100;
 Minibatch[1501-1600]: loss = 0.172230 * 100, metric = 5.88% * 100;
 Minibatch[1601-1700]: loss = 0.172726 * 100, metric = 5.95% * 100;
 Minibatch[1701-1800]: loss = 0.168874 * 100, metric = 5.70% * 100;
 Minibatch[1801-1900]: loss = 0.181555 * 100, metric = 6.23% * 100;
 Minibatch[1901-2000]: loss = 0.178520 * 100, metric = 6.18% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.175922 * 2000, metric = 6.02% * 2000 921.039s (  2.2 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 13.62% * 2000;
 Minibatch[   1- 100]: loss = 0.174007 * 100, metric = 5.99% * 100;
 Minibatch[ 101- 200]: loss = 0.170918 * 100, metric = 5.74% * 100;
 Minibatch[ 201- 300]: loss = 0.187570 * 100, metric = 6.38% * 100;
 Minibatch[ 301- 400]: loss = 0.182831 * 100, metric = 6.16% * 100;
 Minibatch[ 401- 500]: loss = 0.179425 * 100, metric = 6.16% * 100;
 Minibatch[ 501- 600]: loss = 0.183262 * 100, metric = 6.23% * 100;
 Minibatch[ 601- 700]: loss = 0.175419 * 100, metric = 6.12% * 100;
 Minibatch[ 701- 800]: loss = 0.169140 * 100, metric = 5.65% * 100;
 Minibatch[ 801- 900]: loss = 0.177178 * 100, metric = 6.06% * 100;
 Minibatch[ 901-1000]: loss = 0.167029 * 100, metric = 5.74% * 100;
 Minibatch[1001-1100]: loss = 0.162045 * 100, metric = 5.47% * 100;
 Minibatch[1101-1200]: loss = 0.177110 * 100, metric = 6.03% * 100;
 Minibatch[1201-1300]: loss = 0.179750 * 100, metric = 6.15% * 100;
 Minibatch[1301-1400]: loss = 0.172744 * 100, metric = 5.79% * 100;
 Minibatch[1401-1500]: loss = 0.176039 * 100, metric = 6.05% * 100;
 Minibatch[1501-1600]: loss = 0.177740 * 100, metric = 6.00% * 100;
 Minibatch[1601-1700]: loss = 0.169863 * 100, metric = 5.78% * 100;
 Minibatch[1701-1800]: loss = 0.177841 * 100, metric = 6.17% * 100;
 Minibatch[1801-1900]: loss = 0.168831 * 100, metric = 5.78% * 100;
 Minibatch[1901-2000]: loss = 0.174543 * 100, metric = 5.95% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.175164 * 2000, metric = 5.97% * 2000 973.652s (  2.1 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.41% * 2000;
 Minibatch[   1- 100]: loss = 0.180970 * 100, metric = 6.14% * 100;
 Minibatch[ 101- 200]: loss = 0.170726 * 100, metric = 5.90% * 100;
 Minibatch[ 201- 300]: loss = 0.170582 * 100, metric = 5.84% * 100;
 Minibatch[ 301- 400]: loss = 0.176096 * 100, metric = 6.06% * 100;
 Minibatch[ 401- 500]: loss = 0.172431 * 100, metric = 5.85% * 100;
 Minibatch[ 501- 600]: loss = 0.175273 * 100, metric = 5.94% * 100;
 Minibatch[ 601- 700]: loss = 0.182889 * 100, metric = 6.44% * 100;
 Minibatch[ 701- 800]: loss = 0.173860 * 100, metric = 6.10% * 100;
 Minibatch[ 801- 900]: loss = 0.169570 * 100, metric = 5.78% * 100;
 Minibatch[ 901-1000]: loss = 0.165570 * 100, metric = 5.82% * 100;
 Minibatch[1001-1100]: loss = 0.172166 * 100, metric = 5.96% * 100;
 Minibatch[1101-1200]: loss = 0.167409 * 100, metric = 5.76% * 100;
 Minibatch[1201-1300]: loss = 0.179567 * 100, metric = 6.12% * 100;
 Minibatch[1301-1400]: loss = 0.168315 * 100, metric = 5.95% * 100;
 Minibatch[1401-1500]: loss = 0.184217 * 100, metric = 6.03% * 100;
 Minibatch[1501-1600]: loss = 0.178609 * 100, metric = 6.01% * 100;
 Minibatch[1601-1700]: loss = 0.171415 * 100, metric = 5.72% * 100;
 Minibatch[1701-1800]: loss = 0.167114 * 100, metric = 5.78% * 100;
 Minibatch[1801-1900]: loss = 0.168008 * 100, metric = 5.73% * 100;
 Minibatch[1901-2000]: loss = 0.177741 * 100, metric = 6.01% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.173626 * 2000, metric = 5.95% * 2000 976.787s (  2.0 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.57% * 2000;
 Minibatch[   1- 100]: loss = 0.170934 * 100, metric = 5.96% * 100;
 Minibatch[ 101- 200]: loss = 0.170321 * 100, metric = 5.77% * 100;
 Minibatch[ 201- 300]: loss = 0.168947 * 100, metric = 5.88% * 100;
 Minibatch[ 301- 400]: loss = 0.176930 * 100, metric = 5.92% * 100;
 Minibatch[ 401- 500]: loss = 0.168119 * 100, metric = 5.71% * 100;
 Minibatch[ 501- 600]: loss = 0.177525 * 100, metric = 6.08% * 100;
 Minibatch[ 601- 700]: loss = 0.174464 * 100, metric = 5.97% * 100;
 Minibatch[ 701- 800]: loss = 0.168253 * 100, metric = 5.73% * 100;
 Minibatch[ 801- 900]: loss = 0.159801 * 100, metric = 5.50% * 100;
 Minibatch[ 901-1000]: loss = 0.170276 * 100, metric = 5.69% * 100;
 Minibatch[1001-1100]: loss = 0.170978 * 100, metric = 5.79% * 100;
 Minibatch[1101-1200]: loss = 0.169330 * 100, metric = 5.92% * 100;
 Minibatch[1201-1300]: loss = 0.171810 * 100, metric = 5.82% * 100;
 Minibatch[1301-1400]: loss = 0.174779 * 100, metric = 5.95% * 100;
 Minibatch[1401-1500]: loss = 0.180416 * 100, metric = 6.09% * 100;
 Minibatch[1501-1600]: loss = 0.169676 * 100, metric = 5.87% * 100;
 Minibatch[1601-1700]: loss = 0.182165 * 100, metric = 6.31% * 100;
 Minibatch[1701-1800]: loss = 0.167763 * 100, metric = 5.71% * 100;
 Minibatch[1801-1900]: loss = 0.167545 * 100, metric = 5.71% * 100;
 Minibatch[1901-2000]: loss = 0.166532 * 100, metric = 5.74% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.171328 * 2000, metric = 5.86% * 2000 975.953s (  2.0 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.68% * 2000;
 Minibatch[   1- 100]: loss = 0.158614 * 100, metric = 5.29% * 100;
 Minibatch[ 101- 200]: loss = 0.167471 * 100, metric = 5.67% * 100;
 Minibatch[ 201- 300]: loss = 0.165609 * 100, metric = 5.48% * 100;
 Minibatch[ 301- 400]: loss = 0.157398 * 100, metric = 5.41% * 100;
 Minibatch[ 401- 500]: loss = 0.166169 * 100, metric = 5.56% * 100;
 Minibatch[ 501- 600]: loss = 0.155235 * 100, metric = 5.26% * 100;
 Minibatch[ 601- 700]: loss = 0.169264 * 100, metric = 5.75% * 100;
 Minibatch[ 701- 800]: loss = 0.160852 * 100, metric = 5.62% * 100;
 Minibatch[ 801- 900]: loss = 0.167601 * 100, metric = 5.66% * 100;
 Minibatch[ 901-1000]: loss = 0.158453 * 100, metric = 5.33% * 100;
 Minibatch[1001-1100]: loss = 0.176131 * 100, metric = 5.94% * 100;
 Minibatch[1101-1200]: loss = 0.163774 * 100, metric = 5.68% * 100;
 Minibatch[1201-1300]: loss = 0.169250 * 100, metric = 5.74% * 100;
 Minibatch[1301-1400]: loss = 0.173073 * 100, metric = 6.16% * 100;
 Minibatch[1401-1500]: loss = 0.164824 * 100, metric = 5.76% * 100;
 Minibatch[1501-1600]: loss = 0.169772 * 100, metric = 5.80% * 100;
 Minibatch[1601-1700]: loss = 0.164576 * 100, metric = 5.60% * 100;
 Minibatch[1701-1800]: loss = 0.167307 * 100, metric = 5.79% * 100;
 Minibatch[1801-1900]: loss = 0.174198 * 100, metric = 6.04% * 100;
 Minibatch[1901-2000]: loss = 0.168798 * 100, metric = 5.91% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.165918 * 2000, metric = 5.67% * 2000 989.769s (  2.0 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.40% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
