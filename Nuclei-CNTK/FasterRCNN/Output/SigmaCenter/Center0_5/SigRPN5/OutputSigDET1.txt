Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.072239 * 100, metric = 24.23% * 100;
 Minibatch[ 101- 200]: loss = 0.835922 * 100, metric = 23.39% * 100;
 Minibatch[ 201- 300]: loss = 0.716405 * 100, metric = 21.26% * 100;
 Minibatch[ 301- 400]: loss = 0.699213 * 100, metric = 20.57% * 100;
 Minibatch[ 401- 500]: loss = 0.634562 * 100, metric = 19.45% * 100;
 Minibatch[ 501- 600]: loss = 0.611964 * 100, metric = 18.28% * 100;
 Minibatch[ 601- 700]: loss = 0.558989 * 100, metric = 16.65% * 100;
 Minibatch[ 701- 800]: loss = 0.522405 * 100, metric = 15.76% * 100;
 Minibatch[ 801- 900]: loss = 0.541181 * 100, metric = 16.08% * 100;
 Minibatch[ 901-1000]: loss = 0.541310 * 100, metric = 16.07% * 100;
 Minibatch[1001-1100]: loss = 0.533405 * 100, metric = 15.71% * 100;
 Minibatch[1101-1200]: loss = 0.506945 * 100, metric = 15.07% * 100;
 Minibatch[1201-1300]: loss = 0.510603 * 100, metric = 15.48% * 100;
 Minibatch[1301-1400]: loss = 0.484233 * 100, metric = 14.42% * 100;
 Minibatch[1401-1500]: loss = 0.510773 * 100, metric = 15.08% * 100;
 Minibatch[1501-1600]: loss = 0.475014 * 100, metric = 14.14% * 100;
 Minibatch[1601-1700]: loss = 0.461377 * 100, metric = 13.54% * 100;
 Minibatch[1701-1800]: loss = 0.468996 * 100, metric = 13.74% * 100;
 Minibatch[1801-1900]: loss = 0.468403 * 100, metric = 13.94% * 100;
 Minibatch[1901-2000]: loss = 0.456271 * 100, metric = 13.44% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.580510 * 2000, metric = 16.81% * 2000 1117.810s (  1.8 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 24.18% * 2000;
0.6363491780757904
 Minibatch[   1- 100]: loss = 0.435794 * 100, metric = 12.98% * 100;
 Minibatch[ 101- 200]: loss = 0.455884 * 100, metric = 13.57% * 100;
 Minibatch[ 201- 300]: loss = 0.449954 * 100, metric = 12.97% * 100;
 Minibatch[ 301- 400]: loss = 0.453956 * 100, metric = 13.34% * 100;
 Minibatch[ 401- 500]: loss = 0.434485 * 100, metric = 12.78% * 100;
 Minibatch[ 501- 600]: loss = 0.444001 * 100, metric = 12.82% * 100;
 Minibatch[ 601- 700]: loss = 0.421201 * 100, metric = 12.33% * 100;
 Minibatch[ 701- 800]: loss = 0.435608 * 100, metric = 12.77% * 100;
 Minibatch[ 801- 900]: loss = 0.405734 * 100, metric = 12.00% * 100;
 Minibatch[ 901-1000]: loss = 0.408390 * 100, metric = 11.97% * 100;
 Minibatch[1001-1100]: loss = 0.421859 * 100, metric = 12.50% * 100;
 Minibatch[1101-1200]: loss = 0.425266 * 100, metric = 12.41% * 100;
 Minibatch[1201-1300]: loss = 0.405345 * 100, metric = 12.20% * 100;
 Minibatch[1301-1400]: loss = 0.421227 * 100, metric = 12.29% * 100;
 Minibatch[1401-1500]: loss = 0.404430 * 100, metric = 11.84% * 100;
 Minibatch[1501-1600]: loss = 0.397650 * 100, metric = 11.55% * 100;
 Minibatch[1601-1700]: loss = 0.409365 * 100, metric = 11.79% * 100;
 Minibatch[1701-1800]: loss = 0.416697 * 100, metric = 12.21% * 100;
 Minibatch[1801-1900]: loss = 0.400830 * 100, metric = 11.72% * 100;
 Minibatch[1901-2000]: loss = 0.387618 * 100, metric = 11.43% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.421765 * 2000, metric = 12.37% * 2000 1037.518s (  1.9 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 20.50% * 2000;
0.5437952893972396
 Minibatch[   1- 100]: loss = 0.398322 * 100, metric = 11.57% * 100;
 Minibatch[ 101- 200]: loss = 0.403378 * 100, metric = 11.68% * 100;
 Minibatch[ 201- 300]: loss = 0.389331 * 100, metric = 11.42% * 100;
 Minibatch[ 301- 400]: loss = 0.404653 * 100, metric = 12.10% * 100;
 Minibatch[ 401- 500]: loss = 0.406040 * 100, metric = 12.07% * 100;
 Minibatch[ 501- 600]: loss = 0.401889 * 100, metric = 11.93% * 100;
 Minibatch[ 601- 700]: loss = 0.402588 * 100, metric = 11.81% * 100;
 Minibatch[ 701- 800]: loss = 0.371965 * 100, metric = 10.80% * 100;
 Minibatch[ 801- 900]: loss = 0.408116 * 100, metric = 12.03% * 100;
 Minibatch[ 901-1000]: loss = 0.381961 * 100, metric = 11.23% * 100;
 Minibatch[1001-1100]: loss = 0.400416 * 100, metric = 11.93% * 100;
 Minibatch[1101-1200]: loss = 0.382137 * 100, metric = 11.40% * 100;
 Minibatch[1201-1300]: loss = 0.380538 * 100, metric = 11.16% * 100;
 Minibatch[1301-1400]: loss = 0.388347 * 100, metric = 11.67% * 100;
 Minibatch[1401-1500]: loss = 0.383517 * 100, metric = 11.21% * 100;
 Minibatch[1501-1600]: loss = 0.369321 * 100, metric = 10.90% * 100;
 Minibatch[1601-1700]: loss = 0.369782 * 100, metric = 10.40% * 100;
 Minibatch[1701-1800]: loss = 0.386958 * 100, metric = 11.55% * 100;
 Minibatch[1801-1900]: loss = 0.365076 * 100, metric = 10.51% * 100;
 Minibatch[1901-2000]: loss = 0.372432 * 100, metric = 11.02% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.388338 * 2000, metric = 11.42% * 2000 1029.381s (  1.9 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 18.85% * 2000;
0.499128454759717
 Minibatch[   1- 100]: loss = 0.386632 * 100, metric = 11.17% * 100;
 Minibatch[ 101- 200]: loss = 0.367457 * 100, metric = 10.68% * 100;
 Minibatch[ 201- 300]: loss = 0.378117 * 100, metric = 11.09% * 100;
 Minibatch[ 301- 400]: loss = 0.344977 * 100, metric = 10.17% * 100;
 Minibatch[ 401- 500]: loss = 0.372356 * 100, metric = 10.94% * 100;
 Minibatch[ 501- 600]: loss = 0.354054 * 100, metric = 10.24% * 100;
 Minibatch[ 601- 700]: loss = 0.359659 * 100, metric = 10.33% * 100;
 Minibatch[ 701- 800]: loss = 0.357867 * 100, metric = 10.51% * 100;
 Minibatch[ 801- 900]: loss = 0.369442 * 100, metric = 10.75% * 100;
 Minibatch[ 901-1000]: loss = 0.368083 * 100, metric = 10.83% * 100;
 Minibatch[1001-1100]: loss = 0.375213 * 100, metric = 10.97% * 100;
 Minibatch[1101-1200]: loss = 0.352134 * 100, metric = 10.34% * 100;
 Minibatch[1201-1300]: loss = 0.355099 * 100, metric = 10.41% * 100;
 Minibatch[1301-1400]: loss = 0.369759 * 100, metric = 10.94% * 100;
 Minibatch[1401-1500]: loss = 0.369762 * 100, metric = 10.85% * 100;
 Minibatch[1501-1600]: loss = 0.337405 * 100, metric = 9.88% * 100;
 Minibatch[1601-1700]: loss = 0.360686 * 100, metric = 10.70% * 100;
 Minibatch[1701-1800]: loss = 0.367366 * 100, metric = 10.88% * 100;
 Minibatch[1801-1900]: loss = 0.355646 * 100, metric = 10.42% * 100;
 Minibatch[1901-2000]: loss = 0.348513 * 100, metric = 10.20% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.362511 * 2000, metric = 10.61% * 2000 1027.141s (  1.9 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 20.08% * 2000;
 Minibatch[   1- 100]: loss = 0.362796 * 100, metric = 10.71% * 100;
 Minibatch[ 101- 200]: loss = 0.353336 * 100, metric = 10.45% * 100;
 Minibatch[ 201- 300]: loss = 0.349000 * 100, metric = 10.41% * 100;
 Minibatch[ 301- 400]: loss = 0.371130 * 100, metric = 11.23% * 100;
 Minibatch[ 401- 500]: loss = 0.337971 * 100, metric = 9.71% * 100;
 Minibatch[ 501- 600]: loss = 0.346028 * 100, metric = 10.20% * 100;
 Minibatch[ 601- 700]: loss = 0.347029 * 100, metric = 9.97% * 100;
 Minibatch[ 701- 800]: loss = 0.353936 * 100, metric = 10.55% * 100;
 Minibatch[ 801- 900]: loss = 0.336141 * 100, metric = 9.74% * 100;
 Minibatch[ 901-1000]: loss = 0.344669 * 100, metric = 10.31% * 100;
 Minibatch[1001-1100]: loss = 0.346293 * 100, metric = 10.20% * 100;
 Minibatch[1101-1200]: loss = 0.332689 * 100, metric = 9.68% * 100;
 Minibatch[1201-1300]: loss = 0.355101 * 100, metric = 10.24% * 100;
 Minibatch[1301-1400]: loss = 0.359281 * 100, metric = 10.80% * 100;
 Minibatch[1401-1500]: loss = 0.351751 * 100, metric = 10.38% * 100;
 Minibatch[1501-1600]: loss = 0.349022 * 100, metric = 10.35% * 100;
 Minibatch[1601-1700]: loss = 0.356025 * 100, metric = 10.81% * 100;
 Minibatch[1701-1800]: loss = 0.354687 * 100, metric = 10.58% * 100;
 Minibatch[1801-1900]: loss = 0.351695 * 100, metric = 10.26% * 100;
 Minibatch[1901-2000]: loss = 0.343242 * 100, metric = 10.01% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.350091 * 2000, metric = 10.33% * 2000 1006.066s (  2.0 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 18.50% * 2000;
0.4918811001330614
 Minibatch[   1- 100]: loss = 0.336685 * 100, metric = 9.86% * 100;
 Minibatch[ 101- 200]: loss = 0.337208 * 100, metric = 10.02% * 100;
 Minibatch[ 201- 300]: loss = 0.348331 * 100, metric = 10.29% * 100;
 Minibatch[ 301- 400]: loss = 0.350163 * 100, metric = 10.12% * 100;
 Minibatch[ 401- 500]: loss = 0.326581 * 100, metric = 9.76% * 100;
 Minibatch[ 501- 600]: loss = 0.335220 * 100, metric = 9.91% * 100;
 Minibatch[ 601- 700]: loss = 0.335069 * 100, metric = 10.31% * 100;
 Minibatch[ 701- 800]: loss = 0.338653 * 100, metric = 9.98% * 100;
 Minibatch[ 801- 900]: loss = 0.341382 * 100, metric = 10.29% * 100;
 Minibatch[ 901-1000]: loss = 0.335046 * 100, metric = 9.88% * 100;
 Minibatch[1001-1100]: loss = 0.339284 * 100, metric = 9.93% * 100;
 Minibatch[1101-1200]: loss = 0.350008 * 100, metric = 10.27% * 100;
 Minibatch[1201-1300]: loss = 0.351030 * 100, metric = 10.45% * 100;
 Minibatch[1301-1400]: loss = 0.329622 * 100, metric = 9.74% * 100;
 Minibatch[1401-1500]: loss = 0.333690 * 100, metric = 9.95% * 100;
 Minibatch[1501-1600]: loss = 0.315906 * 100, metric = 9.30% * 100;
 Minibatch[1601-1700]: loss = 0.314692 * 100, metric = 9.19% * 100;
 Minibatch[1701-1800]: loss = 0.316329 * 100, metric = 9.27% * 100;
 Minibatch[1801-1900]: loss = 0.327502 * 100, metric = 9.64% * 100;
 Minibatch[1901-2000]: loss = 0.318663 * 100, metric = 9.34% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.334053 * 2000, metric = 9.88% * 2000 1008.967s (  2.0 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 18.85% * 2000;
 Minibatch[   1- 100]: loss = 0.317135 * 100, metric = 9.53% * 100;
 Minibatch[ 101- 200]: loss = 0.326007 * 100, metric = 9.40% * 100;
 Minibatch[ 201- 300]: loss = 0.334694 * 100, metric = 9.95% * 100;
 Minibatch[ 301- 400]: loss = 0.321130 * 100, metric = 9.48% * 100;
 Minibatch[ 401- 500]: loss = 0.337264 * 100, metric = 9.79% * 100;
 Minibatch[ 501- 600]: loss = 0.317806 * 100, metric = 9.72% * 100;
 Minibatch[ 601- 700]: loss = 0.319444 * 100, metric = 9.29% * 100;
 Minibatch[ 701- 800]: loss = 0.328897 * 100, metric = 9.58% * 100;
 Minibatch[ 801- 900]: loss = 0.332211 * 100, metric = 9.93% * 100;
 Minibatch[ 901-1000]: loss = 0.323606 * 100, metric = 9.58% * 100;
 Minibatch[1001-1100]: loss = 0.329943 * 100, metric = 9.67% * 100;
 Minibatch[1101-1200]: loss = 0.318852 * 100, metric = 9.29% * 100;
 Minibatch[1201-1300]: loss = 0.325184 * 100, metric = 9.74% * 100;
 Minibatch[1301-1400]: loss = 0.307628 * 100, metric = 8.97% * 100;
 Minibatch[1401-1500]: loss = 0.309862 * 100, metric = 8.83% * 100;
 Minibatch[1501-1600]: loss = 0.313977 * 100, metric = 9.19% * 100;
 Minibatch[1601-1700]: loss = 0.319326 * 100, metric = 9.28% * 100;
 Minibatch[1701-1800]: loss = 0.315482 * 100, metric = 8.92% * 100;
 Minibatch[1801-1900]: loss = 0.314460 * 100, metric = 9.21% * 100;
 Minibatch[1901-2000]: loss = 0.321487 * 100, metric = 9.72% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.321720 * 2000, metric = 9.45% * 2000 1014.238s (  2.0 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 15.97% * 2000;
0.44049469801038504
 Minibatch[   1- 100]: loss = 0.325122 * 100, metric = 9.52% * 100;
 Minibatch[ 101- 200]: loss = 0.321570 * 100, metric = 9.57% * 100;
 Minibatch[ 201- 300]: loss = 0.309199 * 100, metric = 9.16% * 100;
 Minibatch[ 301- 400]: loss = 0.315763 * 100, metric = 9.32% * 100;
 Minibatch[ 401- 500]: loss = 0.325671 * 100, metric = 9.55% * 100;
 Minibatch[ 501- 600]: loss = 0.336582 * 100, metric = 10.00% * 100;
 Minibatch[ 601- 700]: loss = 0.301040 * 100, metric = 8.75% * 100;
 Minibatch[ 701- 800]: loss = 0.317455 * 100, metric = 9.12% * 100;
 Minibatch[ 801- 900]: loss = 0.306312 * 100, metric = 8.83% * 100;
 Minibatch[ 901-1000]: loss = 0.298375 * 100, metric = 8.73% * 100;
 Minibatch[1001-1100]: loss = 0.303370 * 100, metric = 8.93% * 100;
 Minibatch[1101-1200]: loss = 0.302136 * 100, metric = 8.74% * 100;
 Minibatch[1201-1300]: loss = 0.318381 * 100, metric = 9.59% * 100;
 Minibatch[1301-1400]: loss = 0.317066 * 100, metric = 9.36% * 100;
 Minibatch[1401-1500]: loss = 0.302891 * 100, metric = 8.93% * 100;
 Minibatch[1501-1600]: loss = 0.311895 * 100, metric = 9.17% * 100;
 Minibatch[1601-1700]: loss = 0.305610 * 100, metric = 8.93% * 100;
 Minibatch[1701-1800]: loss = 0.308404 * 100, metric = 9.11% * 100;
 Minibatch[1801-1900]: loss = 0.304544 * 100, metric = 8.84% * 100;
 Minibatch[1901-2000]: loss = 0.303528 * 100, metric = 8.93% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.311746 * 2000, metric = 9.15% * 2000 1003.272s (  2.0 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 15.85% * 2000;
 Minibatch[   1- 100]: loss = 0.294363 * 100, metric = 8.69% * 100;
 Minibatch[ 101- 200]: loss = 0.312235 * 100, metric = 8.97% * 100;
 Minibatch[ 201- 300]: loss = 0.303397 * 100, metric = 9.01% * 100;
 Minibatch[ 301- 400]: loss = 0.315414 * 100, metric = 9.21% * 100;
 Minibatch[ 401- 500]: loss = 0.307050 * 100, metric = 8.92% * 100;
 Minibatch[ 501- 600]: loss = 0.295167 * 100, metric = 8.71% * 100;
 Minibatch[ 601- 700]: loss = 0.304771 * 100, metric = 8.99% * 100;
 Minibatch[ 701- 800]: loss = 0.282929 * 100, metric = 8.40% * 100;
 Minibatch[ 801- 900]: loss = 0.288046 * 100, metric = 8.29% * 100;
 Minibatch[ 901-1000]: loss = 0.306373 * 100, metric = 8.93% * 100;
 Minibatch[1001-1100]: loss = 0.277632 * 100, metric = 8.14% * 100;
 Minibatch[1101-1200]: loss = 0.297180 * 100, metric = 8.52% * 100;
 Minibatch[1201-1300]: loss = 0.290366 * 100, metric = 8.60% * 100;
 Minibatch[1301-1400]: loss = 0.290331 * 100, metric = 8.35% * 100;
 Minibatch[1401-1500]: loss = 0.307688 * 100, metric = 9.06% * 100;
 Minibatch[1501-1600]: loss = 0.293304 * 100, metric = 8.57% * 100;
 Minibatch[1601-1700]: loss = 0.297993 * 100, metric = 8.71% * 100;
 Minibatch[1701-1800]: loss = 0.287689 * 100, metric = 8.08% * 100;
 Minibatch[1801-1900]: loss = 0.283895 * 100, metric = 8.22% * 100;
 Minibatch[1901-2000]: loss = 0.296512 * 100, metric = 8.64% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.296617 * 2000, metric = 8.65% * 2000 994.800s (  2.0 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 15.37% * 2000;
 Minibatch[   1- 100]: loss = 0.304276 * 100, metric = 8.92% * 100;
 Minibatch[ 101- 200]: loss = 0.280607 * 100, metric = 8.00% * 100;
 Minibatch[ 201- 300]: loss = 0.293300 * 100, metric = 8.39% * 100;
 Minibatch[ 301- 400]: loss = 0.280725 * 100, metric = 8.18% * 100;
 Minibatch[ 401- 500]: loss = 0.292216 * 100, metric = 8.43% * 100;
 Minibatch[ 501- 600]: loss = 0.274137 * 100, metric = 7.90% * 100;
 Minibatch[ 601- 700]: loss = 0.273089 * 100, metric = 7.75% * 100;
 Minibatch[ 701- 800]: loss = 0.267938 * 100, metric = 7.57% * 100;
 Minibatch[ 801- 900]: loss = 0.281516 * 100, metric = 8.04% * 100;
 Minibatch[ 901-1000]: loss = 0.287020 * 100, metric = 8.32% * 100;
 Minibatch[1001-1100]: loss = 0.290027 * 100, metric = 8.35% * 100;
 Minibatch[1101-1200]: loss = 0.290348 * 100, metric = 8.46% * 100;
 Minibatch[1201-1300]: loss = 0.290144 * 100, metric = 8.45% * 100;
 Minibatch[1301-1400]: loss = 0.294793 * 100, metric = 8.55% * 100;
 Minibatch[1401-1500]: loss = 0.274567 * 100, metric = 7.99% * 100;
 Minibatch[1501-1600]: loss = 0.282118 * 100, metric = 8.22% * 100;
 Minibatch[1601-1700]: loss = 0.286792 * 100, metric = 8.11% * 100;
 Minibatch[1701-1800]: loss = 0.289558 * 100, metric = 8.23% * 100;
 Minibatch[1801-1900]: loss = 0.292401 * 100, metric = 8.63% * 100;
 Minibatch[1901-2000]: loss = 0.284139 * 100, metric = 8.22% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.285485 * 2000, metric = 8.24% * 2000 982.015s (  2.0 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 14.31% * 2000;
0.4151679590679705
 Minibatch[   1- 100]: loss = 0.275630 * 100, metric = 7.97% * 100;
 Minibatch[ 101- 200]: loss = 0.287141 * 100, metric = 8.36% * 100;
 Minibatch[ 201- 300]: loss = 0.295368 * 100, metric = 8.71% * 100;
 Minibatch[ 301- 400]: loss = 0.284577 * 100, metric = 8.22% * 100;
 Minibatch[ 401- 500]: loss = 0.278783 * 100, metric = 8.10% * 100;
 Minibatch[ 501- 600]: loss = 0.293394 * 100, metric = 8.49% * 100;
 Minibatch[ 601- 700]: loss = 0.282038 * 100, metric = 8.12% * 100;
 Minibatch[ 701- 800]: loss = 0.287878 * 100, metric = 8.46% * 100;
 Minibatch[ 801- 900]: loss = 0.286752 * 100, metric = 8.33% * 100;
 Minibatch[ 901-1000]: loss = 0.294076 * 100, metric = 8.66% * 100;
 Minibatch[1001-1100]: loss = 0.291979 * 100, metric = 8.68% * 100;
 Minibatch[1101-1200]: loss = 0.291450 * 100, metric = 8.48% * 100;
 Minibatch[1201-1300]: loss = 0.285714 * 100, metric = 8.51% * 100;
 Minibatch[1301-1400]: loss = 0.273386 * 100, metric = 7.98% * 100;
 Minibatch[1401-1500]: loss = 0.293673 * 100, metric = 8.64% * 100;
 Minibatch[1501-1600]: loss = 0.280026 * 100, metric = 8.10% * 100;
 Minibatch[1601-1700]: loss = 0.283963 * 100, metric = 8.24% * 100;
 Minibatch[1701-1800]: loss = 0.290925 * 100, metric = 8.51% * 100;
 Minibatch[1801-1900]: loss = 0.284238 * 100, metric = 8.18% * 100;
 Minibatch[1901-2000]: loss = 0.281092 * 100, metric = 8.27% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.286104 * 2000, metric = 8.35% * 2000 968.216s (  2.1 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 14.89% * 2000;
 Minibatch[   1- 100]: loss = 0.271925 * 100, metric = 8.07% * 100;
 Minibatch[ 101- 200]: loss = 0.272299 * 100, metric = 7.79% * 100;
 Minibatch[ 201- 300]: loss = 0.273620 * 100, metric = 7.78% * 100;
 Minibatch[ 301- 400]: loss = 0.295895 * 100, metric = 8.57% * 100;
 Minibatch[ 401- 500]: loss = 0.272405 * 100, metric = 7.92% * 100;
 Minibatch[ 501- 600]: loss = 0.260408 * 100, metric = 7.47% * 100;
 Minibatch[ 601- 700]: loss = 0.258521 * 100, metric = 7.48% * 100;
 Minibatch[ 701- 800]: loss = 0.270231 * 100, metric = 7.76% * 100;
 Minibatch[ 801- 900]: loss = 0.266300 * 100, metric = 7.63% * 100;
 Minibatch[ 901-1000]: loss = 0.270853 * 100, metric = 7.85% * 100;
 Minibatch[1001-1100]: loss = 0.277772 * 100, metric = 8.21% * 100;
 Minibatch[1101-1200]: loss = 0.277608 * 100, metric = 8.10% * 100;
 Minibatch[1201-1300]: loss = 0.281846 * 100, metric = 8.20% * 100;
 Minibatch[1301-1400]: loss = 0.266593 * 100, metric = 7.66% * 100;
 Minibatch[1401-1500]: loss = 0.275128 * 100, metric = 8.04% * 100;
 Minibatch[1501-1600]: loss = 0.256989 * 100, metric = 7.23% * 100;
 Minibatch[1601-1700]: loss = 0.280785 * 100, metric = 8.09% * 100;
 Minibatch[1701-1800]: loss = 0.261353 * 100, metric = 7.40% * 100;
 Minibatch[1801-1900]: loss = 0.267803 * 100, metric = 7.83% * 100;
 Minibatch[1901-2000]: loss = 0.275958 * 100, metric = 7.84% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.271715 * 2000, metric = 7.85% * 2000 886.580s (  2.3 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 15.59% * 2000;
 Minibatch[   1- 100]: loss = 0.275316 * 100, metric = 8.05% * 100;
 Minibatch[ 101- 200]: loss = 0.271127 * 100, metric = 7.95% * 100;
 Minibatch[ 201- 300]: loss = 0.269371 * 100, metric = 7.72% * 100;
 Minibatch[ 301- 400]: loss = 0.273988 * 100, metric = 8.02% * 100;
 Minibatch[ 401- 500]: loss = 0.283657 * 100, metric = 8.29% * 100;
 Minibatch[ 501- 600]: loss = 0.287255 * 100, metric = 8.54% * 100;
 Minibatch[ 601- 700]: loss = 0.267604 * 100, metric = 7.48% * 100;
 Minibatch[ 701- 800]: loss = 0.262211 * 100, metric = 7.70% * 100;
 Minibatch[ 801- 900]: loss = 0.276382 * 100, metric = 8.10% * 100;
 Minibatch[ 901-1000]: loss = 0.278743 * 100, metric = 8.11% * 100;
 Minibatch[1001-1100]: loss = 0.279727 * 100, metric = 8.17% * 100;
 Minibatch[1101-1200]: loss = 0.273221 * 100, metric = 7.99% * 100;
 Minibatch[1201-1300]: loss = 0.271773 * 100, metric = 7.82% * 100;
 Minibatch[1301-1400]: loss = 0.266188 * 100, metric = 7.58% * 100;
 Minibatch[1401-1500]: loss = 0.262406 * 100, metric = 7.71% * 100;
 Minibatch[1501-1600]: loss = 0.256804 * 100, metric = 7.50% * 100;
 Minibatch[1601-1700]: loss = 0.259156 * 100, metric = 7.54% * 100;
 Minibatch[1701-1800]: loss = 0.264327 * 100, metric = 7.66% * 100;
 Minibatch[1801-1900]: loss = 0.257426 * 100, metric = 7.44% * 100;
 Minibatch[1901-2000]: loss = 0.271323 * 100, metric = 7.85% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.270400 * 2000, metric = 7.86% * 2000 878.115s (  2.3 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 16.56% * 2000;
 Minibatch[   1- 100]: loss = 0.264032 * 100, metric = 7.40% * 100;
 Minibatch[ 101- 200]: loss = 0.255707 * 100, metric = 7.42% * 100;
 Minibatch[ 201- 300]: loss = 0.267761 * 100, metric = 7.82% * 100;
 Minibatch[ 301- 400]: loss = 0.262035 * 100, metric = 7.67% * 100;
 Minibatch[ 401- 500]: loss = 0.260224 * 100, metric = 7.59% * 100;
 Minibatch[ 501- 600]: loss = 0.260314 * 100, metric = 7.67% * 100;
 Minibatch[ 601- 700]: loss = 0.260550 * 100, metric = 7.45% * 100;
 Minibatch[ 701- 800]: loss = 0.274424 * 100, metric = 7.93% * 100;
 Minibatch[ 801- 900]: loss = 0.279708 * 100, metric = 8.19% * 100;
 Minibatch[ 901-1000]: loss = 0.266751 * 100, metric = 7.80% * 100;
 Minibatch[1001-1100]: loss = 0.266559 * 100, metric = 7.61% * 100;
 Minibatch[1101-1200]: loss = 0.258914 * 100, metric = 7.57% * 100;
 Minibatch[1201-1300]: loss = 0.251167 * 100, metric = 7.06% * 100;
 Minibatch[1301-1400]: loss = 0.267952 * 100, metric = 7.77% * 100;
 Minibatch[1401-1500]: loss = 0.266415 * 100, metric = 7.85% * 100;
 Minibatch[1501-1600]: loss = 0.255619 * 100, metric = 7.51% * 100;
 Minibatch[1601-1700]: loss = 0.260771 * 100, metric = 7.54% * 100;
 Minibatch[1701-1800]: loss = 0.258914 * 100, metric = 7.52% * 100;
 Minibatch[1801-1900]: loss = 0.256770 * 100, metric = 7.53% * 100;
 Minibatch[1901-2000]: loss = 0.254211 * 100, metric = 7.20% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.262440 * 2000, metric = 7.61% * 2000 882.020s (  2.3 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 16.11% * 2000;
 Minibatch[   1- 100]: loss = 0.254931 * 100, metric = 7.24% * 100;
 Minibatch[ 101- 200]: loss = 0.257331 * 100, metric = 7.27% * 100;
 Minibatch[ 201- 300]: loss = 0.256980 * 100, metric = 7.51% * 100;
 Minibatch[ 301- 400]: loss = 0.256724 * 100, metric = 7.47% * 100;
 Minibatch[ 401- 500]: loss = 0.255448 * 100, metric = 7.40% * 100;
 Minibatch[ 501- 600]: loss = 0.244672 * 100, metric = 6.89% * 100;
 Minibatch[ 601- 700]: loss = 0.239727 * 100, metric = 6.85% * 100;
 Minibatch[ 701- 800]: loss = 0.265730 * 100, metric = 7.74% * 100;
 Minibatch[ 801- 900]: loss = 0.277882 * 100, metric = 8.22% * 100;
 Minibatch[ 901-1000]: loss = 0.261140 * 100, metric = 7.89% * 100;
 Minibatch[1001-1100]: loss = 0.257857 * 100, metric = 7.41% * 100;
 Minibatch[1101-1200]: loss = 0.261784 * 100, metric = 7.57% * 100;
 Minibatch[1201-1300]: loss = 0.244926 * 100, metric = 7.00% * 100;
 Minibatch[1301-1400]: loss = 0.272430 * 100, metric = 7.95% * 100;
 Minibatch[1401-1500]: loss = 0.240220 * 100, metric = 7.05% * 100;
 Minibatch[1501-1600]: loss = 0.250520 * 100, metric = 7.27% * 100;
 Minibatch[1601-1700]: loss = 0.255504 * 100, metric = 7.43% * 100;
 Minibatch[1701-1800]: loss = 0.240327 * 100, metric = 6.67% * 100;
 Minibatch[1801-1900]: loss = 0.254015 * 100, metric = 7.29% * 100;
 Minibatch[1901-2000]: loss = 0.251730 * 100, metric = 7.45% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.254994 * 2000, metric = 7.38% * 2000 870.363s (  2.3 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 13.65% * 2000;
0.41108027267083525
 Minibatch[   1- 100]: loss = 0.269266 * 100, metric = 8.19% * 100;
 Minibatch[ 101- 200]: loss = 0.251674 * 100, metric = 7.11% * 100;
 Minibatch[ 201- 300]: loss = 0.251800 * 100, metric = 7.22% * 100;
 Minibatch[ 301- 400]: loss = 0.260387 * 100, metric = 7.70% * 100;
 Minibatch[ 401- 500]: loss = 0.240352 * 100, metric = 7.08% * 100;
 Minibatch[ 501- 600]: loss = 0.255155 * 100, metric = 7.22% * 100;
 Minibatch[ 601- 700]: loss = 0.244283 * 100, metric = 7.21% * 100;
 Minibatch[ 701- 800]: loss = 0.245251 * 100, metric = 7.21% * 100;
 Minibatch[ 801- 900]: loss = 0.237057 * 100, metric = 6.92% * 100;
 Minibatch[ 901-1000]: loss = 0.254975 * 100, metric = 7.61% * 100;
 Minibatch[1001-1100]: loss = 0.239846 * 100, metric = 6.86% * 100;
 Minibatch[1101-1200]: loss = 0.245376 * 100, metric = 7.31% * 100;
 Minibatch[1201-1300]: loss = 0.233566 * 100, metric = 6.77% * 100;
 Minibatch[1301-1400]: loss = 0.247976 * 100, metric = 7.11% * 100;
 Minibatch[1401-1500]: loss = 0.249756 * 100, metric = 7.44% * 100;
 Minibatch[1501-1600]: loss = 0.243921 * 100, metric = 7.10% * 100;
 Minibatch[1601-1700]: loss = 0.246927 * 100, metric = 7.31% * 100;
 Minibatch[1701-1800]: loss = 0.259764 * 100, metric = 7.59% * 100;
 Minibatch[1801-1900]: loss = 0.258443 * 100, metric = 7.47% * 100;
 Minibatch[1901-2000]: loss = 0.247662 * 100, metric = 7.35% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.249172 * 2000, metric = 7.29% * 2000 882.189s (  2.3 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 13.90% * 2000;
 Minibatch[   1- 100]: loss = 0.243703 * 100, metric = 7.24% * 100;
 Minibatch[ 101- 200]: loss = 0.257598 * 100, metric = 7.56% * 100;
 Minibatch[ 201- 300]: loss = 0.253785 * 100, metric = 7.36% * 100;
 Minibatch[ 301- 400]: loss = 0.244517 * 100, metric = 7.15% * 100;
 Minibatch[ 401- 500]: loss = 0.248381 * 100, metric = 7.28% * 100;
 Minibatch[ 501- 600]: loss = 0.237209 * 100, metric = 6.81% * 100;
 Minibatch[ 601- 700]: loss = 0.224686 * 100, metric = 6.38% * 100;
 Minibatch[ 701- 800]: loss = 0.240292 * 100, metric = 6.86% * 100;
 Minibatch[ 801- 900]: loss = 0.241455 * 100, metric = 6.92% * 100;
 Minibatch[ 901-1000]: loss = 0.232417 * 100, metric = 6.79% * 100;
 Minibatch[1001-1100]: loss = 0.237510 * 100, metric = 6.83% * 100;
 Minibatch[1101-1200]: loss = 0.252439 * 100, metric = 7.42% * 100;
 Minibatch[1201-1300]: loss = 0.249094 * 100, metric = 7.39% * 100;
 Minibatch[1301-1400]: loss = 0.226377 * 100, metric = 6.71% * 100;
 Minibatch[1401-1500]: loss = 0.241516 * 100, metric = 6.96% * 100;
 Minibatch[1501-1600]: loss = 0.241012 * 100, metric = 6.99% * 100;
 Minibatch[1601-1700]: loss = 0.244709 * 100, metric = 7.09% * 100;
 Minibatch[1701-1800]: loss = 0.233399 * 100, metric = 6.81% * 100;
 Minibatch[1801-1900]: loss = 0.253163 * 100, metric = 7.51% * 100;
 Minibatch[1901-2000]: loss = 0.256254 * 100, metric = 7.64% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.242976 * 2000, metric = 7.08% * 2000 879.876s (  2.3 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.14% * 2000;
 Minibatch[   1- 100]: loss = 0.227024 * 100, metric = 6.59% * 100;
 Minibatch[ 101- 200]: loss = 0.244053 * 100, metric = 7.28% * 100;
 Minibatch[ 201- 300]: loss = 0.228536 * 100, metric = 6.71% * 100;
 Minibatch[ 301- 400]: loss = 0.238464 * 100, metric = 6.86% * 100;
 Minibatch[ 401- 500]: loss = 0.227373 * 100, metric = 6.71% * 100;
 Minibatch[ 501- 600]: loss = 0.236651 * 100, metric = 6.98% * 100;
 Minibatch[ 601- 700]: loss = 0.240291 * 100, metric = 6.99% * 100;
 Minibatch[ 701- 800]: loss = 0.228079 * 100, metric = 6.79% * 100;
 Minibatch[ 801- 900]: loss = 0.237502 * 100, metric = 6.84% * 100;
 Minibatch[ 901-1000]: loss = 0.242363 * 100, metric = 7.20% * 100;
 Minibatch[1001-1100]: loss = 0.244809 * 100, metric = 7.13% * 100;
 Minibatch[1101-1200]: loss = 0.241652 * 100, metric = 6.95% * 100;
 Minibatch[1201-1300]: loss = 0.249906 * 100, metric = 7.31% * 100;
 Minibatch[1301-1400]: loss = 0.251330 * 100, metric = 7.43% * 100;
 Minibatch[1401-1500]: loss = 0.225978 * 100, metric = 6.65% * 100;
 Minibatch[1501-1600]: loss = 0.237537 * 100, metric = 6.86% * 100;
 Minibatch[1601-1700]: loss = 0.224875 * 100, metric = 6.47% * 100;
 Minibatch[1701-1800]: loss = 0.231973 * 100, metric = 6.90% * 100;
 Minibatch[1801-1900]: loss = 0.226483 * 100, metric = 6.70% * 100;
 Minibatch[1901-2000]: loss = 0.224973 * 100, metric = 6.56% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.235492 * 2000, metric = 6.89% * 2000 866.380s (  2.3 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 14.64% * 2000;
 Minibatch[   1- 100]: loss = 0.242375 * 100, metric = 7.16% * 100;
 Minibatch[ 101- 200]: loss = 0.243588 * 100, metric = 6.91% * 100;
 Minibatch[ 201- 300]: loss = 0.228917 * 100, metric = 6.64% * 100;
 Minibatch[ 301- 400]: loss = 0.240705 * 100, metric = 6.94% * 100;
 Minibatch[ 401- 500]: loss = 0.236356 * 100, metric = 6.76% * 100;
 Minibatch[ 501- 600]: loss = 0.226038 * 100, metric = 6.44% * 100;
 Minibatch[ 601- 700]: loss = 0.242119 * 100, metric = 7.10% * 100;
 Minibatch[ 701- 800]: loss = 0.227565 * 100, metric = 6.67% * 100;
 Minibatch[ 801- 900]: loss = 0.255174 * 100, metric = 7.43% * 100;
 Minibatch[ 901-1000]: loss = 0.228011 * 100, metric = 6.71% * 100;
 Minibatch[1001-1100]: loss = 0.241261 * 100, metric = 7.18% * 100;
 Minibatch[1101-1200]: loss = 0.237267 * 100, metric = 7.08% * 100;
 Minibatch[1201-1300]: loss = 0.230095 * 100, metric = 6.86% * 100;
 Minibatch[1301-1400]: loss = 0.227460 * 100, metric = 6.65% * 100;
 Minibatch[1401-1500]: loss = 0.240292 * 100, metric = 7.20% * 100;
 Minibatch[1501-1600]: loss = 0.234015 * 100, metric = 6.85% * 100;
 Minibatch[1601-1700]: loss = 0.223951 * 100, metric = 6.59% * 100;
 Minibatch[1701-1800]: loss = 0.219328 * 100, metric = 6.35% * 100;
 Minibatch[1801-1900]: loss = 0.224859 * 100, metric = 6.54% * 100;
 Minibatch[1901-2000]: loss = 0.222682 * 100, metric = 6.34% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.233603 * 2000, metric = 6.82% * 2000 871.463s (  2.3 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 14.38% * 2000;
 Minibatch[   1- 100]: loss = 0.229890 * 100, metric = 6.57% * 100;
 Minibatch[ 101- 200]: loss = 0.228453 * 100, metric = 6.59% * 100;
 Minibatch[ 201- 300]: loss = 0.223233 * 100, metric = 6.38% * 100;
 Minibatch[ 301- 400]: loss = 0.244232 * 100, metric = 6.88% * 100;
 Minibatch[ 401- 500]: loss = 0.228301 * 100, metric = 6.82% * 100;
 Minibatch[ 501- 600]: loss = 0.236234 * 100, metric = 7.02% * 100;
 Minibatch[ 601- 700]: loss = 0.238412 * 100, metric = 7.04% * 100;
 Minibatch[ 701- 800]: loss = 0.229638 * 100, metric = 6.74% * 100;
 Minibatch[ 801- 900]: loss = 0.238576 * 100, metric = 6.90% * 100;
 Minibatch[ 901-1000]: loss = 0.237130 * 100, metric = 7.07% * 100;
 Minibatch[1001-1100]: loss = 0.219103 * 100, metric = 6.38% * 100;
 Minibatch[1101-1200]: loss = 0.236460 * 100, metric = 6.96% * 100;
 Minibatch[1201-1300]: loss = 0.239920 * 100, metric = 7.01% * 100;
 Minibatch[1301-1400]: loss = 0.240887 * 100, metric = 7.17% * 100;
 Minibatch[1401-1500]: loss = 0.233210 * 100, metric = 6.95% * 100;
 Minibatch[1501-1600]: loss = 0.238591 * 100, metric = 6.85% * 100;
 Minibatch[1601-1700]: loss = 0.232514 * 100, metric = 6.83% * 100;
 Minibatch[1701-1800]: loss = 0.241212 * 100, metric = 7.15% * 100;
 Minibatch[1801-1900]: loss = 0.232572 * 100, metric = 6.94% * 100;
 Minibatch[1901-2000]: loss = 0.229095 * 100, metric = 6.93% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.233883 * 2000, metric = 6.86% * 2000 867.234s (  2.3 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 14.15% * 2000;
 Minibatch[   1- 100]: loss = 0.228028 * 100, metric = 6.69% * 100;
 Minibatch[ 101- 200]: loss = 0.229417 * 100, metric = 6.65% * 100;
 Minibatch[ 201- 300]: loss = 0.231803 * 100, metric = 6.86% * 100;
 Minibatch[ 301- 400]: loss = 0.231398 * 100, metric = 6.86% * 100;
 Minibatch[ 401- 500]: loss = 0.220460 * 100, metric = 6.44% * 100;
 Minibatch[ 501- 600]: loss = 0.218414 * 100, metric = 6.31% * 100;
 Minibatch[ 601- 700]: loss = 0.226059 * 100, metric = 6.48% * 100;
 Minibatch[ 701- 800]: loss = 0.207197 * 100, metric = 6.06% * 100;
 Minibatch[ 801- 900]: loss = 0.221305 * 100, metric = 6.48% * 100;
 Minibatch[ 901-1000]: loss = 0.217774 * 100, metric = 6.30% * 100;
 Minibatch[1001-1100]: loss = 0.219758 * 100, metric = 6.31% * 100;
 Minibatch[1101-1200]: loss = 0.218416 * 100, metric = 6.18% * 100;
 Minibatch[1201-1300]: loss = 0.222783 * 100, metric = 6.38% * 100;
 Minibatch[1301-1400]: loss = 0.215347 * 100, metric = 6.21% * 100;
 Minibatch[1401-1500]: loss = 0.221998 * 100, metric = 6.44% * 100;
 Minibatch[1501-1600]: loss = 0.233981 * 100, metric = 6.96% * 100;
 Minibatch[1601-1700]: loss = 0.228831 * 100, metric = 6.63% * 100;
 Minibatch[1701-1800]: loss = 0.223983 * 100, metric = 6.55% * 100;
 Minibatch[1801-1900]: loss = 0.241831 * 100, metric = 7.25% * 100;
 Minibatch[1901-2000]: loss = 0.222265 * 100, metric = 6.22% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.224052 * 2000, metric = 6.51% * 2000 866.322s (  2.3 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 13.23% * 2000;
 Minibatch[   1- 100]: loss = 0.233340 * 100, metric = 6.81% * 100;
 Minibatch[ 101- 200]: loss = 0.223499 * 100, metric = 6.48% * 100;
 Minibatch[ 201- 300]: loss = 0.233912 * 100, metric = 7.01% * 100;
 Minibatch[ 301- 400]: loss = 0.219360 * 100, metric = 6.54% * 100;
 Minibatch[ 401- 500]: loss = 0.224213 * 100, metric = 6.48% * 100;
 Minibatch[ 501- 600]: loss = 0.227528 * 100, metric = 6.66% * 100;
 Minibatch[ 601- 700]: loss = 0.214232 * 100, metric = 6.32% * 100;
 Minibatch[ 701- 800]: loss = 0.217224 * 100, metric = 6.40% * 100;
 Minibatch[ 801- 900]: loss = 0.225148 * 100, metric = 6.58% * 100;
 Minibatch[ 901-1000]: loss = 0.226109 * 100, metric = 6.64% * 100;
 Minibatch[1001-1100]: loss = 0.217438 * 100, metric = 6.19% * 100;
 Minibatch[1101-1200]: loss = 0.203234 * 100, metric = 5.95% * 100;
 Minibatch[1201-1300]: loss = 0.212589 * 100, metric = 6.05% * 100;
 Minibatch[1301-1400]: loss = 0.218936 * 100, metric = 6.53% * 100;
 Minibatch[1401-1500]: loss = 0.216606 * 100, metric = 6.27% * 100;
 Minibatch[1501-1600]: loss = 0.215698 * 100, metric = 6.21% * 100;
 Minibatch[1601-1700]: loss = 0.216390 * 100, metric = 6.26% * 100;
 Minibatch[1701-1800]: loss = 0.214614 * 100, metric = 6.15% * 100;
 Minibatch[1801-1900]: loss = 0.214205 * 100, metric = 6.27% * 100;
 Minibatch[1901-2000]: loss = 0.218168 * 100, metric = 6.35% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.219622 * 2000, metric = 6.41% * 2000 865.714s (  2.3 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 14.73% * 2000;
 Minibatch[   1- 100]: loss = 0.222605 * 100, metric = 6.39% * 100;
 Minibatch[ 101- 200]: loss = 0.226052 * 100, metric = 6.67% * 100;
 Minibatch[ 201- 300]: loss = 0.213523 * 100, metric = 6.14% * 100;
 Minibatch[ 301- 400]: loss = 0.219779 * 100, metric = 6.42% * 100;
 Minibatch[ 401- 500]: loss = 0.221529 * 100, metric = 6.42% * 100;
 Minibatch[ 501- 600]: loss = 0.216084 * 100, metric = 6.18% * 100;
 Minibatch[ 601- 700]: loss = 0.217163 * 100, metric = 6.43% * 100;
 Minibatch[ 701- 800]: loss = 0.207306 * 100, metric = 6.08% * 100;
 Minibatch[ 801- 900]: loss = 0.208497 * 100, metric = 6.18% * 100;
 Minibatch[ 901-1000]: loss = 0.223518 * 100, metric = 6.49% * 100;
 Minibatch[1001-1100]: loss = 0.211579 * 100, metric = 6.04% * 100;
 Minibatch[1101-1200]: loss = 0.215257 * 100, metric = 6.48% * 100;
 Minibatch[1201-1300]: loss = 0.216940 * 100, metric = 6.53% * 100;
 Minibatch[1301-1400]: loss = 0.220626 * 100, metric = 6.44% * 100;
 Minibatch[1401-1500]: loss = 0.209380 * 100, metric = 5.98% * 100;
 Minibatch[1501-1600]: loss = 0.216747 * 100, metric = 6.29% * 100;
 Minibatch[1601-1700]: loss = 0.209308 * 100, metric = 6.06% * 100;
 Minibatch[1701-1800]: loss = 0.217383 * 100, metric = 6.28% * 100;
 Minibatch[1801-1900]: loss = 0.216096 * 100, metric = 6.24% * 100;
 Minibatch[1901-2000]: loss = 0.214631 * 100, metric = 6.15% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.216200 * 2000, metric = 6.29% * 2000 861.287s (  2.3 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 14.97% * 2000;
 Minibatch[   1- 100]: loss = 0.202956 * 100, metric = 5.98% * 100;
 Minibatch[ 101- 200]: loss = 0.214953 * 100, metric = 6.38% * 100;
 Minibatch[ 201- 300]: loss = 0.212091 * 100, metric = 6.42% * 100;
 Minibatch[ 301- 400]: loss = 0.208354 * 100, metric = 6.05% * 100;
 Minibatch[ 401- 500]: loss = 0.213765 * 100, metric = 6.34% * 100;
 Minibatch[ 501- 600]: loss = 0.210885 * 100, metric = 6.28% * 100;
 Minibatch[ 601- 700]: loss = 0.217215 * 100, metric = 6.15% * 100;
 Minibatch[ 701- 800]: loss = 0.209609 * 100, metric = 6.17% * 100;
 Minibatch[ 801- 900]: loss = 0.218165 * 100, metric = 6.49% * 100;
 Minibatch[ 901-1000]: loss = 0.213929 * 100, metric = 6.24% * 100;
 Minibatch[1001-1100]: loss = 0.209776 * 100, metric = 6.10% * 100;
 Minibatch[1101-1200]: loss = 0.225994 * 100, metric = 6.61% * 100;
 Minibatch[1201-1300]: loss = 0.215681 * 100, metric = 6.45% * 100;
 Minibatch[1301-1400]: loss = 0.210032 * 100, metric = 6.07% * 100;
 Minibatch[1401-1500]: loss = 0.210131 * 100, metric = 6.01% * 100;
 Minibatch[1501-1600]: loss = 0.215677 * 100, metric = 6.29% * 100;
 Minibatch[1601-1700]: loss = 0.208292 * 100, metric = 6.15% * 100;
 Minibatch[1701-1800]: loss = 0.212436 * 100, metric = 6.16% * 100;
 Minibatch[1801-1900]: loss = 0.219165 * 100, metric = 6.64% * 100;
 Minibatch[1901-2000]: loss = 0.225944 * 100, metric = 6.85% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.213753 * 2000, metric = 6.29% * 2000 868.027s (  2.3 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.11% * 2000;
 Minibatch[   1- 100]: loss = 0.223543 * 100, metric = 6.72% * 100;
 Minibatch[ 101- 200]: loss = 0.222674 * 100, metric = 6.73% * 100;
 Minibatch[ 201- 300]: loss = 0.219309 * 100, metric = 6.75% * 100;
 Minibatch[ 301- 400]: loss = 0.220639 * 100, metric = 6.67% * 100;
 Minibatch[ 401- 500]: loss = 0.220065 * 100, metric = 6.46% * 100;
 Minibatch[ 501- 600]: loss = 0.218853 * 100, metric = 6.56% * 100;
 Minibatch[ 601- 700]: loss = 0.215337 * 100, metric = 6.20% * 100;
 Minibatch[ 701- 800]: loss = 0.208236 * 100, metric = 6.16% * 100;
 Minibatch[ 801- 900]: loss = 0.208236 * 100, metric = 6.23% * 100;
 Minibatch[ 901-1000]: loss = 0.216468 * 100, metric = 6.43% * 100;
 Minibatch[1001-1100]: loss = 0.215226 * 100, metric = 6.26% * 100;
 Minibatch[1101-1200]: loss = 0.220907 * 100, metric = 6.56% * 100;
 Minibatch[1201-1300]: loss = 0.229781 * 100, metric = 6.76% * 100;
 Minibatch[1301-1400]: loss = 0.205835 * 100, metric = 6.14% * 100;
 Minibatch[1401-1500]: loss = 0.205341 * 100, metric = 5.90% * 100;
 Minibatch[1501-1600]: loss = 0.219515 * 100, metric = 6.51% * 100;
 Minibatch[1601-1700]: loss = 0.210646 * 100, metric = 6.17% * 100;
 Minibatch[1701-1800]: loss = 0.214810 * 100, metric = 6.35% * 100;
 Minibatch[1801-1900]: loss = 0.201270 * 100, metric = 5.76% * 100;
 Minibatch[1901-2000]: loss = 0.200009 * 100, metric = 5.83% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.214835 * 2000, metric = 6.36% * 2000 872.236s (  2.3 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 13.54% * 2000;
 Minibatch[   1- 100]: loss = 0.210132 * 100, metric = 6.15% * 100;
 Minibatch[ 101- 200]: loss = 0.199802 * 100, metric = 5.88% * 100;
 Minibatch[ 201- 300]: loss = 0.209357 * 100, metric = 6.22% * 100;
 Minibatch[ 301- 400]: loss = 0.202936 * 100, metric = 6.06% * 100;
 Minibatch[ 401- 500]: loss = 0.209999 * 100, metric = 6.16% * 100;
 Minibatch[ 501- 600]: loss = 0.199086 * 100, metric = 5.80% * 100;
 Minibatch[ 601- 700]: loss = 0.217298 * 100, metric = 6.35% * 100;
 Minibatch[ 701- 800]: loss = 0.204447 * 100, metric = 6.09% * 100;
 Minibatch[ 801- 900]: loss = 0.197209 * 100, metric = 5.84% * 100;
 Minibatch[ 901-1000]: loss = 0.200234 * 100, metric = 5.71% * 100;
 Minibatch[1001-1100]: loss = 0.214808 * 100, metric = 6.54% * 100;
 Minibatch[1101-1200]: loss = 0.213044 * 100, metric = 6.31% * 100;
 Minibatch[1201-1300]: loss = 0.204157 * 100, metric = 6.07% * 100;
 Minibatch[1301-1400]: loss = 0.201545 * 100, metric = 5.86% * 100;
 Minibatch[1401-1500]: loss = 0.211396 * 100, metric = 6.27% * 100;
 Minibatch[1501-1600]: loss = 0.198847 * 100, metric = 5.71% * 100;
 Minibatch[1601-1700]: loss = 0.219441 * 100, metric = 6.33% * 100;
 Minibatch[1701-1800]: loss = 0.215286 * 100, metric = 6.43% * 100;
 Minibatch[1801-1900]: loss = 0.210695 * 100, metric = 6.33% * 100;
 Minibatch[1901-2000]: loss = 0.208380 * 100, metric = 6.05% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.207405 * 2000, metric = 6.11% * 2000 867.235s (  2.3 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 14.41% * 2000;
 Minibatch[   1- 100]: loss = 0.206608 * 100, metric = 5.78% * 100;
 Minibatch[ 101- 200]: loss = 0.217562 * 100, metric = 6.35% * 100;
 Minibatch[ 201- 300]: loss = 0.209686 * 100, metric = 6.19% * 100;
 Minibatch[ 301- 400]: loss = 0.204926 * 100, metric = 6.15% * 100;
 Minibatch[ 401- 500]: loss = 0.210431 * 100, metric = 6.12% * 100;
 Minibatch[ 501- 600]: loss = 0.205293 * 100, metric = 6.02% * 100;
 Minibatch[ 601- 700]: loss = 0.200139 * 100, metric = 5.82% * 100;
 Minibatch[ 701- 800]: loss = 0.208592 * 100, metric = 6.06% * 100;
 Minibatch[ 801- 900]: loss = 0.211874 * 100, metric = 6.23% * 100;
 Minibatch[ 901-1000]: loss = 0.210811 * 100, metric = 6.35% * 100;
 Minibatch[1001-1100]: loss = 0.198247 * 100, metric = 5.69% * 100;
 Minibatch[1101-1200]: loss = 0.207827 * 100, metric = 6.12% * 100;
 Minibatch[1201-1300]: loss = 0.204394 * 100, metric = 5.96% * 100;
 Minibatch[1301-1400]: loss = 0.210323 * 100, metric = 6.37% * 100;
 Minibatch[1401-1500]: loss = 0.201778 * 100, metric = 5.91% * 100;
 Minibatch[1501-1600]: loss = 0.206854 * 100, metric = 6.06% * 100;
 Minibatch[1601-1700]: loss = 0.193380 * 100, metric = 5.53% * 100;
 Minibatch[1701-1800]: loss = 0.198654 * 100, metric = 5.70% * 100;
 Minibatch[1801-1900]: loss = 0.201929 * 100, metric = 6.07% * 100;
 Minibatch[1901-2000]: loss = 0.206164 * 100, metric = 5.95% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.205774 * 2000, metric = 6.02% * 2000 859.496s (  2.3 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.70% * 2000;
 Minibatch[   1- 100]: loss = 0.202666 * 100, metric = 5.88% * 100;
 Minibatch[ 101- 200]: loss = 0.197942 * 100, metric = 5.79% * 100;
 Minibatch[ 201- 300]: loss = 0.205481 * 100, metric = 5.93% * 100;
 Minibatch[ 301- 400]: loss = 0.205150 * 100, metric = 5.98% * 100;
 Minibatch[ 401- 500]: loss = 0.202737 * 100, metric = 5.96% * 100;
 Minibatch[ 501- 600]: loss = 0.214243 * 100, metric = 6.54% * 100;
 Minibatch[ 601- 700]: loss = 0.195505 * 100, metric = 5.78% * 100;
 Minibatch[ 701- 800]: loss = 0.194280 * 100, metric = 5.70% * 100;
 Minibatch[ 801- 900]: loss = 0.204301 * 100, metric = 6.07% * 100;
 Minibatch[ 901-1000]: loss = 0.209617 * 100, metric = 6.16% * 100;
 Minibatch[1001-1100]: loss = 0.198212 * 100, metric = 5.82% * 100;
 Minibatch[1101-1200]: loss = 0.195684 * 100, metric = 5.64% * 100;
 Minibatch[1201-1300]: loss = 0.202002 * 100, metric = 5.93% * 100;
 Minibatch[1301-1400]: loss = 0.196194 * 100, metric = 5.70% * 100;
 Minibatch[1401-1500]: loss = 0.206458 * 100, metric = 6.17% * 100;
 Minibatch[1501-1600]: loss = 0.193990 * 100, metric = 5.70% * 100;
 Minibatch[1601-1700]: loss = 0.197356 * 100, metric = 5.68% * 100;
 Minibatch[1701-1800]: loss = 0.195109 * 100, metric = 5.57% * 100;
 Minibatch[1801-1900]: loss = 0.197057 * 100, metric = 5.79% * 100;
 Minibatch[1901-2000]: loss = 0.199680 * 100, metric = 5.75% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.200683 * 2000, metric = 5.88% * 2000 868.891s (  2.3 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.24% * 2000;
 Minibatch[   1- 100]: loss = 0.187929 * 100, metric = 5.29% * 100;
 Minibatch[ 101- 200]: loss = 0.193017 * 100, metric = 5.63% * 100;
 Minibatch[ 201- 300]: loss = 0.201856 * 100, metric = 6.04% * 100;
 Minibatch[ 301- 400]: loss = 0.210273 * 100, metric = 6.11% * 100;
 Minibatch[ 401- 500]: loss = 0.188150 * 100, metric = 5.48% * 100;
 Minibatch[ 501- 600]: loss = 0.198154 * 100, metric = 5.88% * 100;
 Minibatch[ 601- 700]: loss = 0.192424 * 100, metric = 5.78% * 100;
 Minibatch[ 701- 800]: loss = 0.204644 * 100, metric = 5.81% * 100;
 Minibatch[ 801- 900]: loss = 0.195732 * 100, metric = 5.72% * 100;
 Minibatch[ 901-1000]: loss = 0.202074 * 100, metric = 5.92% * 100;
 Minibatch[1001-1100]: loss = 0.201638 * 100, metric = 6.01% * 100;
 Minibatch[1101-1200]: loss = 0.196127 * 100, metric = 5.74% * 100;
 Minibatch[1201-1300]: loss = 0.199581 * 100, metric = 5.90% * 100;
 Minibatch[1301-1400]: loss = 0.192322 * 100, metric = 5.64% * 100;
 Minibatch[1401-1500]: loss = 0.205603 * 100, metric = 5.90% * 100;
 Minibatch[1501-1600]: loss = 0.187290 * 100, metric = 5.44% * 100;
 Minibatch[1601-1700]: loss = 0.201507 * 100, metric = 6.00% * 100;
 Minibatch[1701-1800]: loss = 0.190747 * 100, metric = 5.59% * 100;
 Minibatch[1801-1900]: loss = 0.209389 * 100, metric = 6.27% * 100;
 Minibatch[1901-2000]: loss = 0.196899 * 100, metric = 5.66% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.197768 * 2000, metric = 5.79% * 2000 865.386s (  2.3 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 14.80% * 2000;
 Minibatch[   1- 100]: loss = 0.207378 * 100, metric = 6.04% * 100;
 Minibatch[ 101- 200]: loss = 0.181794 * 100, metric = 5.11% * 100;
 Minibatch[ 201- 300]: loss = 0.190418 * 100, metric = 5.44% * 100;
 Minibatch[ 301- 400]: loss = 0.200018 * 100, metric = 5.97% * 100;
 Minibatch[ 401- 500]: loss = 0.197342 * 100, metric = 5.83% * 100;
 Minibatch[ 501- 600]: loss = 0.184126 * 100, metric = 5.37% * 100;
 Minibatch[ 601- 700]: loss = 0.199868 * 100, metric = 5.90% * 100;
 Minibatch[ 701- 800]: loss = 0.188438 * 100, metric = 5.43% * 100;
 Minibatch[ 801- 900]: loss = 0.201037 * 100, metric = 5.78% * 100;
 Minibatch[ 901-1000]: loss = 0.181796 * 100, metric = 5.32% * 100;
 Minibatch[1001-1100]: loss = 0.199768 * 100, metric = 5.75% * 100;
 Minibatch[1101-1200]: loss = 0.202857 * 100, metric = 6.06% * 100;
 Minibatch[1201-1300]: loss = 0.193741 * 100, metric = 5.58% * 100;
 Minibatch[1301-1400]: loss = 0.192712 * 100, metric = 5.59% * 100;
 Minibatch[1401-1500]: loss = 0.196958 * 100, metric = 5.75% * 100;
 Minibatch[1501-1600]: loss = 0.197820 * 100, metric = 5.73% * 100;
 Minibatch[1601-1700]: loss = 0.194249 * 100, metric = 5.75% * 100;
 Minibatch[1701-1800]: loss = 0.198790 * 100, metric = 5.83% * 100;
 Minibatch[1801-1900]: loss = 0.202441 * 100, metric = 6.04% * 100;
 Minibatch[1901-2000]: loss = 0.206886 * 100, metric = 6.08% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.195922 * 2000, metric = 5.72% * 2000 863.960s (  2.3 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 13.88% * 2000;
 Minibatch[   1- 100]: loss = 0.192585 * 100, metric = 5.71% * 100;
 Minibatch[ 101- 200]: loss = 0.206582 * 100, metric = 6.13% * 100;
 Minibatch[ 201- 300]: loss = 0.196396 * 100, metric = 5.79% * 100;
 Minibatch[ 301- 400]: loss = 0.194590 * 100, metric = 5.74% * 100;
 Minibatch[ 401- 500]: loss = 0.194409 * 100, metric = 5.68% * 100;
 Minibatch[ 501- 600]: loss = 0.194664 * 100, metric = 5.70% * 100;
 Minibatch[ 601- 700]: loss = 0.201976 * 100, metric = 5.91% * 100;
 Minibatch[ 701- 800]: loss = 0.200072 * 100, metric = 5.76% * 100;
 Minibatch[ 801- 900]: loss = 0.198888 * 100, metric = 5.80% * 100;
 Minibatch[ 901-1000]: loss = 0.189189 * 100, metric = 5.66% * 100;
 Minibatch[1001-1100]: loss = 0.184749 * 100, metric = 5.46% * 100;
 Minibatch[1101-1200]: loss = 0.191002 * 100, metric = 5.71% * 100;
 Minibatch[1201-1300]: loss = 0.188387 * 100, metric = 5.54% * 100;
 Minibatch[1301-1400]: loss = 0.194333 * 100, metric = 5.78% * 100;
 Minibatch[1401-1500]: loss = 0.206319 * 100, metric = 6.15% * 100;
 Minibatch[1501-1600]: loss = 0.189313 * 100, metric = 5.60% * 100;
 Minibatch[1601-1700]: loss = 0.198339 * 100, metric = 5.99% * 100;
 Minibatch[1701-1800]: loss = 0.195619 * 100, metric = 5.88% * 100;
 Minibatch[1801-1900]: loss = 0.198922 * 100, metric = 6.04% * 100;
 Minibatch[1901-2000]: loss = 0.197686 * 100, metric = 6.05% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.195701 * 2000, metric = 5.80% * 2000 865.587s (  2.3 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 13.59% * 2000;
 Minibatch[   1- 100]: loss = 0.193542 * 100, metric = 5.65% * 100;
 Minibatch[ 101- 200]: loss = 0.194434 * 100, metric = 5.73% * 100;
 Minibatch[ 201- 300]: loss = 0.200591 * 100, metric = 5.89% * 100;
 Minibatch[ 301- 400]: loss = 0.205922 * 100, metric = 5.98% * 100;
 Minibatch[ 401- 500]: loss = 0.200547 * 100, metric = 6.00% * 100;
 Minibatch[ 501- 600]: loss = 0.197221 * 100, metric = 5.89% * 100;
 Minibatch[ 601- 700]: loss = 0.188510 * 100, metric = 5.46% * 100;
 Minibatch[ 701- 800]: loss = 0.191297 * 100, metric = 5.62% * 100;
 Minibatch[ 801- 900]: loss = 0.191977 * 100, metric = 5.67% * 100;
 Minibatch[ 901-1000]: loss = 0.183354 * 100, metric = 5.44% * 100;
 Minibatch[1001-1100]: loss = 0.184787 * 100, metric = 5.24% * 100;
 Minibatch[1101-1200]: loss = 0.195866 * 100, metric = 5.77% * 100;
 Minibatch[1201-1300]: loss = 0.194831 * 100, metric = 5.71% * 100;
 Minibatch[1301-1400]: loss = 0.193338 * 100, metric = 5.68% * 100;
 Minibatch[1401-1500]: loss = 0.195609 * 100, metric = 5.89% * 100;
 Minibatch[1501-1600]: loss = 0.195694 * 100, metric = 5.73% * 100;
 Minibatch[1601-1700]: loss = 0.188984 * 100, metric = 5.62% * 100;
 Minibatch[1701-1800]: loss = 0.199193 * 100, metric = 5.96% * 100;
 Minibatch[1801-1900]: loss = 0.189948 * 100, metric = 5.62% * 100;
 Minibatch[1901-2000]: loss = 0.196795 * 100, metric = 5.82% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.194122 * 2000, metric = 5.72% * 2000 867.573s (  2.3 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.15% * 2000;
 Minibatch[   1- 100]: loss = 0.205814 * 100, metric = 6.05% * 100;
 Minibatch[ 101- 200]: loss = 0.191386 * 100, metric = 5.71% * 100;
 Minibatch[ 201- 300]: loss = 0.192747 * 100, metric = 5.72% * 100;
 Minibatch[ 301- 400]: loss = 0.193177 * 100, metric = 5.63% * 100;
 Minibatch[ 401- 500]: loss = 0.183739 * 100, metric = 5.32% * 100;
 Minibatch[ 501- 600]: loss = 0.189407 * 100, metric = 5.55% * 100;
 Minibatch[ 601- 700]: loss = 0.195807 * 100, metric = 5.82% * 100;
 Minibatch[ 701- 800]: loss = 0.189155 * 100, metric = 5.67% * 100;
 Minibatch[ 801- 900]: loss = 0.186403 * 100, metric = 5.33% * 100;
 Minibatch[ 901-1000]: loss = 0.180623 * 100, metric = 5.32% * 100;
 Minibatch[1001-1100]: loss = 0.187907 * 100, metric = 5.62% * 100;
 Minibatch[1101-1200]: loss = 0.181602 * 100, metric = 5.35% * 100;
 Minibatch[1201-1300]: loss = 0.195915 * 100, metric = 5.66% * 100;
 Minibatch[1301-1400]: loss = 0.182522 * 100, metric = 5.43% * 100;
 Minibatch[1401-1500]: loss = 0.206201 * 100, metric = 5.98% * 100;
 Minibatch[1501-1600]: loss = 0.196994 * 100, metric = 5.80% * 100;
 Minibatch[1601-1700]: loss = 0.190044 * 100, metric = 5.40% * 100;
 Minibatch[1701-1800]: loss = 0.185121 * 100, metric = 5.47% * 100;
 Minibatch[1801-1900]: loss = 0.185239 * 100, metric = 5.34% * 100;
 Minibatch[1901-2000]: loss = 0.199435 * 100, metric = 5.86% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.190962 * 2000, metric = 5.60% * 2000 861.686s (  2.3 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.96% * 2000;
 Minibatch[   1- 100]: loss = 0.182449 * 100, metric = 5.37% * 100;
 Minibatch[ 101- 200]: loss = 0.190271 * 100, metric = 5.59% * 100;
 Minibatch[ 201- 300]: loss = 0.179533 * 100, metric = 5.32% * 100;
 Minibatch[ 301- 400]: loss = 0.197514 * 100, metric = 5.76% * 100;
 Minibatch[ 401- 500]: loss = 0.187175 * 100, metric = 5.37% * 100;
 Minibatch[ 501- 600]: loss = 0.192434 * 100, metric = 5.63% * 100;
 Minibatch[ 601- 700]: loss = 0.192242 * 100, metric = 5.77% * 100;
 Minibatch[ 701- 800]: loss = 0.185561 * 100, metric = 5.35% * 100;
 Minibatch[ 801- 900]: loss = 0.179718 * 100, metric = 5.19% * 100;
 Minibatch[ 901-1000]: loss = 0.185138 * 100, metric = 5.61% * 100;
 Minibatch[1001-1100]: loss = 0.191667 * 100, metric = 5.72% * 100;
 Minibatch[1101-1200]: loss = 0.185185 * 100, metric = 5.50% * 100;
 Minibatch[1201-1300]: loss = 0.193108 * 100, metric = 5.71% * 100;
 Minibatch[1301-1400]: loss = 0.188036 * 100, metric = 5.65% * 100;
 Minibatch[1401-1500]: loss = 0.194465 * 100, metric = 5.75% * 100;
 Minibatch[1501-1600]: loss = 0.189578 * 100, metric = 5.56% * 100;
 Minibatch[1601-1700]: loss = 0.194462 * 100, metric = 5.91% * 100;
 Minibatch[1701-1800]: loss = 0.187030 * 100, metric = 5.63% * 100;
 Minibatch[1801-1900]: loss = 0.187982 * 100, metric = 5.49% * 100;
 Minibatch[1901-2000]: loss = 0.187133 * 100, metric = 5.55% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.188534 * 2000, metric = 5.57% * 2000 865.887s (  2.3 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.45% * 2000;
 Minibatch[   1- 100]: loss = 0.172327 * 100, metric = 4.90% * 100;
 Minibatch[ 101- 200]: loss = 0.190340 * 100, metric = 5.66% * 100;
 Minibatch[ 201- 300]: loss = 0.188106 * 100, metric = 5.54% * 100;
 Minibatch[ 301- 400]: loss = 0.177868 * 100, metric = 5.38% * 100;
 Minibatch[ 401- 500]: loss = 0.181626 * 100, metric = 5.13% * 100;
 Minibatch[ 501- 600]: loss = 0.176279 * 100, metric = 5.26% * 100;
 Minibatch[ 601- 700]: loss = 0.192924 * 100, metric = 5.76% * 100;
 Minibatch[ 701- 800]: loss = 0.173118 * 100, metric = 5.22% * 100;
 Minibatch[ 801- 900]: loss = 0.189691 * 100, metric = 5.61% * 100;
 Minibatch[ 901-1000]: loss = 0.177926 * 100, metric = 5.21% * 100;
 Minibatch[1001-1100]: loss = 0.190198 * 100, metric = 5.61% * 100;
 Minibatch[1101-1200]: loss = 0.181662 * 100, metric = 5.39% * 100;
 Minibatch[1201-1300]: loss = 0.187287 * 100, metric = 5.58% * 100;
 Minibatch[1301-1400]: loss = 0.188638 * 100, metric = 5.61% * 100;
 Minibatch[1401-1500]: loss = 0.181747 * 100, metric = 5.49% * 100;
 Minibatch[1501-1600]: loss = 0.185764 * 100, metric = 5.49% * 100;
 Minibatch[1601-1700]: loss = 0.185347 * 100, metric = 5.45% * 100;
 Minibatch[1701-1800]: loss = 0.176863 * 100, metric = 5.20% * 100;
 Minibatch[1801-1900]: loss = 0.191537 * 100, metric = 5.72% * 100;
 Minibatch[1901-2000]: loss = 0.182036 * 100, metric = 5.43% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.183564 * 2000, metric = 5.43% * 2000 862.988s (  2.3 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.55% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
