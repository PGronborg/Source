Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.181557 * 100, metric = 24.82% * 100;
 Minibatch[ 101- 200]: loss = 0.979780 * 100, metric = 23.16% * 100;
 Minibatch[ 201- 300]: loss = 0.874668 * 100, metric = 21.47% * 100;
 Minibatch[ 301- 400]: loss = 0.855797 * 100, metric = 20.49% * 100;
 Minibatch[ 401- 500]: loss = 0.798377 * 100, metric = 19.22% * 100;
 Minibatch[ 501- 600]: loss = 0.784384 * 100, metric = 18.28% * 100;
 Minibatch[ 601- 700]: loss = 0.744395 * 100, metric = 17.43% * 100;
 Minibatch[ 701- 800]: loss = 0.717440 * 100, metric = 16.52% * 100;
 Minibatch[ 801- 900]: loss = 0.724267 * 100, metric = 17.11% * 100;
 Minibatch[ 901-1000]: loss = 0.738333 * 100, metric = 17.79% * 100;
 Minibatch[1001-1100]: loss = 0.718331 * 100, metric = 17.03% * 100;
 Minibatch[1101-1200]: loss = 0.699178 * 100, metric = 16.71% * 100;
 Minibatch[1201-1300]: loss = 0.705809 * 100, metric = 17.25% * 100;
 Minibatch[1301-1400]: loss = 0.676317 * 100, metric = 16.09% * 100;
 Minibatch[1401-1500]: loss = 0.691479 * 100, metric = 16.91% * 100;
 Minibatch[1501-1600]: loss = 0.669286 * 100, metric = 16.05% * 100;
 Minibatch[1601-1700]: loss = 0.659364 * 100, metric = 15.56% * 100;
 Minibatch[1701-1800]: loss = 0.668457 * 100, metric = 15.76% * 100;
 Minibatch[1801-1900]: loss = 0.668971 * 100, metric = 15.82% * 100;
 Minibatch[1901-2000]: loss = 0.660316 * 100, metric = 15.43% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.760825 * 2000, metric = 17.94% * 2000 879.288s (  2.3 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 24.17% * 2000;
0.7219907094240189
 Minibatch[   1- 100]: loss = 0.649792 * 100, metric = 15.19% * 100;
 Minibatch[ 101- 200]: loss = 0.661556 * 100, metric = 16.16% * 100;
 Minibatch[ 201- 300]: loss = 0.650164 * 100, metric = 14.92% * 100;
 Minibatch[ 301- 400]: loss = 0.652627 * 100, metric = 15.31% * 100;
 Minibatch[ 401- 500]: loss = 0.640249 * 100, metric = 15.34% * 100;
 Minibatch[ 501- 600]: loss = 0.652097 * 100, metric = 14.92% * 100;
 Minibatch[ 601- 700]: loss = 0.622862 * 100, metric = 14.71% * 100;
 Minibatch[ 701- 800]: loss = 0.642909 * 100, metric = 15.48% * 100;
 Minibatch[ 801- 900]: loss = 0.617532 * 100, metric = 14.82% * 100;
 Minibatch[ 901-1000]: loss = 0.605363 * 100, metric = 14.04% * 100;
 Minibatch[1001-1100]: loss = 0.618007 * 100, metric = 14.84% * 100;
 Minibatch[1101-1200]: loss = 0.615417 * 100, metric = 14.43% * 100;
 Minibatch[1201-1300]: loss = 0.603347 * 100, metric = 14.25% * 100;
 Minibatch[1301-1400]: loss = 0.615079 * 100, metric = 14.33% * 100;
 Minibatch[1401-1500]: loss = 0.596752 * 100, metric = 13.82% * 100;
 Minibatch[1501-1600]: loss = 0.591288 * 100, metric = 13.75% * 100;
 Minibatch[1601-1700]: loss = 0.609725 * 100, metric = 14.29% * 100;
 Minibatch[1701-1800]: loss = 0.610812 * 100, metric = 14.58% * 100;
 Minibatch[1801-1900]: loss = 0.610118 * 100, metric = 14.45% * 100;
 Minibatch[1901-2000]: loss = 0.586738 * 100, metric = 13.88% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.622622 * 2000, metric = 14.68% * 2000 818.837s (  2.4 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 20.37% * 2000;
0.6285261922031641
 Minibatch[   1- 100]: loss = 0.597920 * 100, metric = 14.14% * 100;
 Minibatch[ 101- 200]: loss = 0.599541 * 100, metric = 14.13% * 100;
 Minibatch[ 201- 300]: loss = 0.581779 * 100, metric = 13.87% * 100;
 Minibatch[ 301- 400]: loss = 0.600541 * 100, metric = 14.25% * 100;
 Minibatch[ 401- 500]: loss = 0.597424 * 100, metric = 14.52% * 100;
 Minibatch[ 501- 600]: loss = 0.597333 * 100, metric = 14.29% * 100;
 Minibatch[ 601- 700]: loss = 0.602807 * 100, metric = 14.27% * 100;
 Minibatch[ 701- 800]: loss = 0.577320 * 100, metric = 13.43% * 100;
 Minibatch[ 801- 900]: loss = 0.590426 * 100, metric = 13.95% * 100;
 Minibatch[ 901-1000]: loss = 0.567175 * 100, metric = 13.66% * 100;
 Minibatch[1001-1100]: loss = 0.587372 * 100, metric = 13.90% * 100;
 Minibatch[1101-1200]: loss = 0.563961 * 100, metric = 13.29% * 100;
 Minibatch[1201-1300]: loss = 0.564176 * 100, metric = 13.12% * 100;
 Minibatch[1301-1400]: loss = 0.574207 * 100, metric = 13.70% * 100;
 Minibatch[1401-1500]: loss = 0.576070 * 100, metric = 13.78% * 100;
 Minibatch[1501-1600]: loss = 0.560221 * 100, metric = 13.16% * 100;
 Minibatch[1601-1700]: loss = 0.553276 * 100, metric = 12.83% * 100;
 Minibatch[1701-1800]: loss = 0.578011 * 100, metric = 13.57% * 100;
 Minibatch[1801-1900]: loss = 0.558866 * 100, metric = 12.82% * 100;
 Minibatch[1901-2000]: loss = 0.562028 * 100, metric = 13.34% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.579523 * 2000, metric = 13.70% * 2000 818.603s (  2.4 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 20.12% * 2000;
0.6161385985538363
 Minibatch[   1- 100]: loss = 0.579743 * 100, metric = 13.33% * 100;
 Minibatch[ 101- 200]: loss = 0.545848 * 100, metric = 12.84% * 100;
 Minibatch[ 201- 300]: loss = 0.561211 * 100, metric = 13.04% * 100;
 Minibatch[ 301- 400]: loss = 0.529710 * 100, metric = 12.21% * 100;
 Minibatch[ 401- 500]: loss = 0.563554 * 100, metric = 13.10% * 100;
 Minibatch[ 501- 600]: loss = 0.539585 * 100, metric = 12.48% * 100;
 Minibatch[ 601- 700]: loss = 0.539605 * 100, metric = 12.74% * 100;
 Minibatch[ 701- 800]: loss = 0.552751 * 100, metric = 13.21% * 100;
 Minibatch[ 801- 900]: loss = 0.543994 * 100, metric = 12.56% * 100;
 Minibatch[ 901-1000]: loss = 0.545051 * 100, metric = 13.01% * 100;
 Minibatch[1001-1100]: loss = 0.554566 * 100, metric = 13.11% * 100;
 Minibatch[1101-1200]: loss = 0.532866 * 100, metric = 12.78% * 100;
 Minibatch[1201-1300]: loss = 0.533290 * 100, metric = 12.55% * 100;
 Minibatch[1301-1400]: loss = 0.556260 * 100, metric = 13.18% * 100;
 Minibatch[1401-1500]: loss = 0.554685 * 100, metric = 13.31% * 100;
 Minibatch[1501-1600]: loss = 0.522087 * 100, metric = 12.12% * 100;
 Minibatch[1601-1700]: loss = 0.540948 * 100, metric = 12.89% * 100;
 Minibatch[1701-1800]: loss = 0.541530 * 100, metric = 12.81% * 100;
 Minibatch[1801-1900]: loss = 0.528162 * 100, metric = 12.33% * 100;
 Minibatch[1901-2000]: loss = 0.526357 * 100, metric = 12.25% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.544590 * 2000, metric = 12.79% * 2000 820.118s (  2.4 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 22.38% * 2000;
 Minibatch[   1- 100]: loss = 0.548313 * 100, metric = 12.80% * 100;
 Minibatch[ 101- 200]: loss = 0.535344 * 100, metric = 12.56% * 100;
 Minibatch[ 201- 300]: loss = 0.518288 * 100, metric = 12.25% * 100;
 Minibatch[ 301- 400]: loss = 0.560246 * 100, metric = 13.49% * 100;
 Minibatch[ 401- 500]: loss = 0.512983 * 100, metric = 11.65% * 100;
 Minibatch[ 501- 600]: loss = 0.516061 * 100, metric = 11.85% * 100;
 Minibatch[ 601- 700]: loss = 0.527358 * 100, metric = 12.02% * 100;
 Minibatch[ 701- 800]: loss = 0.534114 * 100, metric = 12.49% * 100;
 Minibatch[ 801- 900]: loss = 0.508390 * 100, metric = 11.65% * 100;
 Minibatch[ 901-1000]: loss = 0.517624 * 100, metric = 12.10% * 100;
 Minibatch[1001-1100]: loss = 0.530850 * 100, metric = 12.63% * 100;
 Minibatch[1101-1200]: loss = 0.509836 * 100, metric = 11.92% * 100;
 Minibatch[1201-1300]: loss = 0.526359 * 100, metric = 12.24% * 100;
 Minibatch[1301-1400]: loss = 0.535596 * 100, metric = 12.85% * 100;
 Minibatch[1401-1500]: loss = 0.523209 * 100, metric = 12.43% * 100;
 Minibatch[1501-1600]: loss = 0.521961 * 100, metric = 12.19% * 100;
 Minibatch[1601-1700]: loss = 0.525816 * 100, metric = 12.55% * 100;
 Minibatch[1701-1800]: loss = 0.528954 * 100, metric = 12.43% * 100;
 Minibatch[1801-1900]: loss = 0.524230 * 100, metric = 12.39% * 100;
 Minibatch[1901-2000]: loss = 0.512617 * 100, metric = 11.80% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.525907 * 2000, metric = 12.31% * 2000 814.526s (  2.5 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.39% * 2000;
0.6029816707074642
 Minibatch[   1- 100]: loss = 0.514185 * 100, metric = 11.91% * 100;
 Minibatch[ 101- 200]: loss = 0.500754 * 100, metric = 11.85% * 100;
 Minibatch[ 201- 300]: loss = 0.516647 * 100, metric = 12.07% * 100;
 Minibatch[ 301- 400]: loss = 0.516185 * 100, metric = 11.85% * 100;
 Minibatch[ 401- 500]: loss = 0.491358 * 100, metric = 11.49% * 100;
 Minibatch[ 501- 600]: loss = 0.508890 * 100, metric = 12.02% * 100;
 Minibatch[ 601- 700]: loss = 0.506579 * 100, metric = 11.95% * 100;
 Minibatch[ 701- 800]: loss = 0.522447 * 100, metric = 12.41% * 100;
 Minibatch[ 801- 900]: loss = 0.519811 * 100, metric = 12.33% * 100;
 Minibatch[ 901-1000]: loss = 0.513676 * 100, metric = 12.00% * 100;
 Minibatch[1001-1100]: loss = 0.507365 * 100, metric = 11.72% * 100;
 Minibatch[1101-1200]: loss = 0.518743 * 100, metric = 12.19% * 100;
 Minibatch[1201-1300]: loss = 0.525125 * 100, metric = 12.37% * 100;
 Minibatch[1301-1400]: loss = 0.504382 * 100, metric = 12.11% * 100;
 Minibatch[1401-1500]: loss = 0.514512 * 100, metric = 12.44% * 100;
 Minibatch[1501-1600]: loss = 0.497011 * 100, metric = 11.73% * 100;
 Minibatch[1601-1700]: loss = 0.500284 * 100, metric = 11.74% * 100;
 Minibatch[1701-1800]: loss = 0.485102 * 100, metric = 11.35% * 100;
 Minibatch[1801-1900]: loss = 0.506813 * 100, metric = 11.71% * 100;
 Minibatch[1901-2000]: loss = 0.493764 * 100, metric = 11.36% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.508182 * 2000, metric = 11.93% * 2000 813.082s (  2.5 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 21.46% * 2000;
 Minibatch[   1- 100]: loss = 0.493231 * 100, metric = 11.79% * 100;
 Minibatch[ 101- 200]: loss = 0.501682 * 100, metric = 11.57% * 100;
 Minibatch[ 201- 300]: loss = 0.503488 * 100, metric = 11.71% * 100;
 Minibatch[ 301- 400]: loss = 0.488673 * 100, metric = 11.23% * 100;
 Minibatch[ 401- 500]: loss = 0.504557 * 100, metric = 11.85% * 100;
 Minibatch[ 501- 600]: loss = 0.482631 * 100, metric = 11.39% * 100;
 Minibatch[ 601- 700]: loss = 0.494576 * 100, metric = 11.54% * 100;
 Minibatch[ 701- 800]: loss = 0.501414 * 100, metric = 11.53% * 100;
 Minibatch[ 801- 900]: loss = 0.505807 * 100, metric = 11.84% * 100;
 Minibatch[ 901-1000]: loss = 0.493099 * 100, metric = 11.49% * 100;
 Minibatch[1001-1100]: loss = 0.507687 * 100, metric = 11.87% * 100;
 Minibatch[1101-1200]: loss = 0.489553 * 100, metric = 11.29% * 100;
 Minibatch[1201-1300]: loss = 0.505057 * 100, metric = 12.25% * 100;
 Minibatch[1301-1400]: loss = 0.486661 * 100, metric = 11.45% * 100;
 Minibatch[1401-1500]: loss = 0.484298 * 100, metric = 11.32% * 100;
 Minibatch[1501-1600]: loss = 0.494182 * 100, metric = 11.52% * 100;
 Minibatch[1601-1700]: loss = 0.491669 * 100, metric = 11.66% * 100;
 Minibatch[1701-1800]: loss = 0.492111 * 100, metric = 11.49% * 100;
 Minibatch[1801-1900]: loss = 0.488254 * 100, metric = 11.48% * 100;
 Minibatch[1901-2000]: loss = 0.496517 * 100, metric = 11.88% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.495257 * 2000, metric = 11.61% * 2000 812.571s (  2.5 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 17.78% * 2000;
0.548587987549603
 Minibatch[   1- 100]: loss = 0.492295 * 100, metric = 11.45% * 100;
 Minibatch[ 101- 200]: loss = 0.492442 * 100, metric = 11.53% * 100;
 Minibatch[ 201- 300]: loss = 0.466339 * 100, metric = 11.08% * 100;
 Minibatch[ 301- 400]: loss = 0.477995 * 100, metric = 11.18% * 100;
 Minibatch[ 401- 500]: loss = 0.489172 * 100, metric = 11.84% * 100;
 Minibatch[ 501- 600]: loss = 0.505590 * 100, metric = 12.37% * 100;
 Minibatch[ 601- 700]: loss = 0.472636 * 100, metric = 10.98% * 100;
 Minibatch[ 701- 800]: loss = 0.486265 * 100, metric = 11.20% * 100;
 Minibatch[ 801- 900]: loss = 0.466161 * 100, metric = 10.62% * 100;
 Minibatch[ 901-1000]: loss = 0.458850 * 100, metric = 10.71% * 100;
 Minibatch[1001-1100]: loss = 0.471112 * 100, metric = 11.07% * 100;
 Minibatch[1101-1200]: loss = 0.465018 * 100, metric = 10.69% * 100;
 Minibatch[1201-1300]: loss = 0.495736 * 100, metric = 11.79% * 100;
 Minibatch[1301-1400]: loss = 0.485563 * 100, metric = 11.62% * 100;
 Minibatch[1401-1500]: loss = 0.474615 * 100, metric = 10.95% * 100;
 Minibatch[1501-1600]: loss = 0.486804 * 100, metric = 11.64% * 100;
 Minibatch[1601-1700]: loss = 0.472789 * 100, metric = 10.93% * 100;
 Minibatch[1701-1800]: loss = 0.471782 * 100, metric = 11.16% * 100;
 Minibatch[1801-1900]: loss = 0.472143 * 100, metric = 11.09% * 100;
 Minibatch[1901-2000]: loss = 0.465850 * 100, metric = 10.71% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.478458 * 2000, metric = 11.23% * 2000 807.695s (  2.5 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 17.82% * 2000;
0.5458548506647348
 Minibatch[   1- 100]: loss = 0.456510 * 100, metric = 10.57% * 100;
 Minibatch[ 101- 200]: loss = 0.484782 * 100, metric = 11.34% * 100;
 Minibatch[ 201- 300]: loss = 0.478029 * 100, metric = 11.17% * 100;
 Minibatch[ 301- 400]: loss = 0.495830 * 100, metric = 11.70% * 100;
 Minibatch[ 401- 500]: loss = 0.476380 * 100, metric = 10.88% * 100;
 Minibatch[ 501- 600]: loss = 0.464370 * 100, metric = 10.85% * 100;
 Minibatch[ 601- 700]: loss = 0.464854 * 100, metric = 10.92% * 100;
 Minibatch[ 701- 800]: loss = 0.453709 * 100, metric = 10.64% * 100;
 Minibatch[ 801- 900]: loss = 0.451143 * 100, metric = 10.58% * 100;
 Minibatch[ 901-1000]: loss = 0.464941 * 100, metric = 10.93% * 100;
 Minibatch[1001-1100]: loss = 0.437968 * 100, metric = 9.93% * 100;
 Minibatch[1101-1200]: loss = 0.458427 * 100, metric = 10.63% * 100;
 Minibatch[1201-1300]: loss = 0.451459 * 100, metric = 10.52% * 100;
 Minibatch[1301-1400]: loss = 0.448115 * 100, metric = 10.05% * 100;
 Minibatch[1401-1500]: loss = 0.467919 * 100, metric = 10.94% * 100;
 Minibatch[1501-1600]: loss = 0.456144 * 100, metric = 10.61% * 100;
 Minibatch[1601-1700]: loss = 0.458422 * 100, metric = 10.76% * 100;
 Minibatch[1701-1800]: loss = 0.446965 * 100, metric = 10.22% * 100;
 Minibatch[1801-1900]: loss = 0.454059 * 100, metric = 10.53% * 100;
 Minibatch[1901-2000]: loss = 0.467497 * 100, metric = 10.87% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.461876 * 2000, metric = 10.73% * 2000 811.145s (  2.5 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 16.76% * 2000;
0.5274107920750976
 Minibatch[   1- 100]: loss = 0.472966 * 100, metric = 11.41% * 100;
 Minibatch[ 101- 200]: loss = 0.444883 * 100, metric = 10.42% * 100;
 Minibatch[ 201- 300]: loss = 0.452202 * 100, metric = 10.58% * 100;
 Minibatch[ 301- 400]: loss = 0.439758 * 100, metric = 10.27% * 100;
 Minibatch[ 401- 500]: loss = 0.455986 * 100, metric = 10.57% * 100;
 Minibatch[ 501- 600]: loss = 0.428846 * 100, metric = 9.82% * 100;
 Minibatch[ 601- 700]: loss = 0.430224 * 100, metric = 9.87% * 100;
 Minibatch[ 701- 800]: loss = 0.426366 * 100, metric = 9.40% * 100;
 Minibatch[ 801- 900]: loss = 0.451574 * 100, metric = 10.37% * 100;
 Minibatch[ 901-1000]: loss = 0.443616 * 100, metric = 10.20% * 100;
 Minibatch[1001-1100]: loss = 0.441288 * 100, metric = 10.42% * 100;
 Minibatch[1101-1200]: loss = 0.445599 * 100, metric = 10.19% * 100;
 Minibatch[1201-1300]: loss = 0.443489 * 100, metric = 10.21% * 100;
 Minibatch[1301-1400]: loss = 0.441196 * 100, metric = 10.21% * 100;
 Minibatch[1401-1500]: loss = 0.427690 * 100, metric = 9.63% * 100;
 Minibatch[1501-1600]: loss = 0.441147 * 100, metric = 10.00% * 100;
 Minibatch[1601-1700]: loss = 0.436177 * 100, metric = 10.08% * 100;
 Minibatch[1701-1800]: loss = 0.447621 * 100, metric = 10.28% * 100;
 Minibatch[1801-1900]: loss = 0.441320 * 100, metric = 10.40% * 100;
 Minibatch[1901-2000]: loss = 0.432878 * 100, metric = 10.05% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.442241 * 2000, metric = 10.22% * 2000 806.951s (  2.5 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 16.85% * 2000;
 Minibatch[   1- 100]: loss = 0.417800 * 100, metric = 9.58% * 100;
 Minibatch[ 101- 200]: loss = 0.432623 * 100, metric = 10.19% * 100;
 Minibatch[ 201- 300]: loss = 0.437168 * 100, metric = 10.14% * 100;
 Minibatch[ 301- 400]: loss = 0.430288 * 100, metric = 9.77% * 100;
 Minibatch[ 401- 500]: loss = 0.435269 * 100, metric = 10.40% * 100;
 Minibatch[ 501- 600]: loss = 0.440300 * 100, metric = 9.96% * 100;
 Minibatch[ 601- 700]: loss = 0.434565 * 100, metric = 9.90% * 100;
 Minibatch[ 701- 800]: loss = 0.429353 * 100, metric = 9.90% * 100;
 Minibatch[ 801- 900]: loss = 0.428665 * 100, metric = 9.63% * 100;
 Minibatch[ 901-1000]: loss = 0.435278 * 100, metric = 9.95% * 100;
 Minibatch[1001-1100]: loss = 0.430105 * 100, metric = 9.86% * 100;
 Minibatch[1101-1200]: loss = 0.436542 * 100, metric = 10.03% * 100;
 Minibatch[1201-1300]: loss = 0.426565 * 100, metric = 9.87% * 100;
 Minibatch[1301-1400]: loss = 0.412450 * 100, metric = 9.47% * 100;
 Minibatch[1401-1500]: loss = 0.435420 * 100, metric = 10.17% * 100;
 Minibatch[1501-1600]: loss = 0.418451 * 100, metric = 9.74% * 100;
 Minibatch[1601-1700]: loss = 0.423148 * 100, metric = 9.63% * 100;
 Minibatch[1701-1800]: loss = 0.426407 * 100, metric = 9.74% * 100;
 Minibatch[1801-1900]: loss = 0.424784 * 100, metric = 9.62% * 100;
 Minibatch[1901-2000]: loss = 0.424717 * 100, metric = 9.92% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.428995 * 2000, metric = 9.87% * 2000 806.550s (  2.5 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 16.52% * 2000;
0.5187893265858292
 Minibatch[   1- 100]: loss = 0.415933 * 100, metric = 9.58% * 100;
 Minibatch[ 101- 200]: loss = 0.413370 * 100, metric = 9.24% * 100;
 Minibatch[ 201- 300]: loss = 0.416511 * 100, metric = 9.72% * 100;
 Minibatch[ 301- 400]: loss = 0.442406 * 100, metric = 10.26% * 100;
 Minibatch[ 401- 500]: loss = 0.412431 * 100, metric = 9.44% * 100;
 Minibatch[ 501- 600]: loss = 0.404390 * 100, metric = 9.05% * 100;
 Minibatch[ 601- 700]: loss = 0.411673 * 100, metric = 9.33% * 100;
 Minibatch[ 701- 800]: loss = 0.419054 * 100, metric = 9.63% * 100;
 Minibatch[ 801- 900]: loss = 0.406591 * 100, metric = 9.12% * 100;
 Minibatch[ 901-1000]: loss = 0.419814 * 100, metric = 9.69% * 100;
 Minibatch[1001-1100]: loss = 0.427593 * 100, metric = 9.96% * 100;
 Minibatch[1101-1200]: loss = 0.420834 * 100, metric = 9.59% * 100;
 Minibatch[1201-1300]: loss = 0.424044 * 100, metric = 10.01% * 100;
 Minibatch[1301-1400]: loss = 0.412447 * 100, metric = 9.43% * 100;
 Minibatch[1401-1500]: loss = 0.423732 * 100, metric = 9.77% * 100;
 Minibatch[1501-1600]: loss = 0.394570 * 100, metric = 9.08% * 100;
 Minibatch[1601-1700]: loss = 0.424138 * 100, metric = 9.76% * 100;
 Minibatch[1701-1800]: loss = 0.404669 * 100, metric = 9.11% * 100;
 Minibatch[1801-1900]: loss = 0.412639 * 100, metric = 9.46% * 100;
 Minibatch[1901-2000]: loss = 0.421444 * 100, metric = 9.69% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.416414 * 2000, metric = 9.55% * 2000 809.782s (  2.5 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 17.26% * 2000;
 Minibatch[   1- 100]: loss = 0.413359 * 100, metric = 9.62% * 100;
 Minibatch[ 101- 200]: loss = 0.411295 * 100, metric = 9.51% * 100;
 Minibatch[ 201- 300]: loss = 0.412212 * 100, metric = 9.48% * 100;
 Minibatch[ 301- 400]: loss = 0.418258 * 100, metric = 9.61% * 100;
 Minibatch[ 401- 500]: loss = 0.422074 * 100, metric = 9.92% * 100;
 Minibatch[ 501- 600]: loss = 0.434242 * 100, metric = 10.32% * 100;
 Minibatch[ 601- 700]: loss = 0.408842 * 100, metric = 9.11% * 100;
 Minibatch[ 701- 800]: loss = 0.409358 * 100, metric = 9.13% * 100;
 Minibatch[ 801- 900]: loss = 0.413832 * 100, metric = 9.69% * 100;
 Minibatch[ 901-1000]: loss = 0.426235 * 100, metric = 9.91% * 100;
 Minibatch[1001-1100]: loss = 0.428562 * 100, metric = 9.79% * 100;
 Minibatch[1101-1200]: loss = 0.409940 * 100, metric = 9.33% * 100;
 Minibatch[1201-1300]: loss = 0.415638 * 100, metric = 9.67% * 100;
 Minibatch[1301-1400]: loss = 0.409448 * 100, metric = 9.48% * 100;
 Minibatch[1401-1500]: loss = 0.399486 * 100, metric = 9.18% * 100;
 Minibatch[1501-1600]: loss = 0.396429 * 100, metric = 8.80% * 100;
 Minibatch[1601-1700]: loss = 0.391954 * 100, metric = 8.98% * 100;
 Minibatch[1701-1800]: loss = 0.407281 * 100, metric = 9.33% * 100;
 Minibatch[1801-1900]: loss = 0.392169 * 100, metric = 8.88% * 100;
 Minibatch[1901-2000]: loss = 0.410140 * 100, metric = 9.65% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.411538 * 2000, metric = 9.47% * 2000 798.603s (  2.5 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 18.52% * 2000;
 Minibatch[   1- 100]: loss = 0.407411 * 100, metric = 9.13% * 100;
 Minibatch[ 101- 200]: loss = 0.394962 * 100, metric = 9.08% * 100;
 Minibatch[ 201- 300]: loss = 0.407773 * 100, metric = 9.34% * 100;
 Minibatch[ 301- 400]: loss = 0.404428 * 100, metric = 9.26% * 100;
 Minibatch[ 401- 500]: loss = 0.399109 * 100, metric = 9.25% * 100;
 Minibatch[ 501- 600]: loss = 0.396949 * 100, metric = 9.21% * 100;
 Minibatch[ 601- 700]: loss = 0.399711 * 100, metric = 8.88% * 100;
 Minibatch[ 701- 800]: loss = 0.416703 * 100, metric = 9.59% * 100;
 Minibatch[ 801- 900]: loss = 0.421701 * 100, metric = 9.94% * 100;
 Minibatch[ 901-1000]: loss = 0.409929 * 100, metric = 9.60% * 100;
 Minibatch[1001-1100]: loss = 0.405601 * 100, metric = 9.42% * 100;
 Minibatch[1101-1200]: loss = 0.398101 * 100, metric = 9.08% * 100;
 Minibatch[1201-1300]: loss = 0.378963 * 100, metric = 8.66% * 100;
 Minibatch[1301-1400]: loss = 0.397094 * 100, metric = 9.39% * 100;
 Minibatch[1401-1500]: loss = 0.399836 * 100, metric = 9.28% * 100;
 Minibatch[1501-1600]: loss = 0.386928 * 100, metric = 8.82% * 100;
 Minibatch[1601-1700]: loss = 0.395217 * 100, metric = 9.19% * 100;
 Minibatch[1701-1800]: loss = 0.392007 * 100, metric = 8.68% * 100;
 Minibatch[1801-1900]: loss = 0.392615 * 100, metric = 9.02% * 100;
 Minibatch[1901-2000]: loss = 0.399922 * 100, metric = 9.16% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.400248 * 2000, metric = 9.20% * 2000 801.515s (  2.5 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 17.70% * 2000;
 Minibatch[   1- 100]: loss = 0.385883 * 100, metric = 8.81% * 100;
 Minibatch[ 101- 200]: loss = 0.400498 * 100, metric = 9.14% * 100;
 Minibatch[ 201- 300]: loss = 0.395375 * 100, metric = 8.94% * 100;
 Minibatch[ 301- 400]: loss = 0.383452 * 100, metric = 8.58% * 100;
 Minibatch[ 401- 500]: loss = 0.388391 * 100, metric = 9.05% * 100;
 Minibatch[ 501- 600]: loss = 0.379372 * 100, metric = 8.47% * 100;
 Minibatch[ 601- 700]: loss = 0.376685 * 100, metric = 8.72% * 100;
 Minibatch[ 701- 800]: loss = 0.395758 * 100, metric = 8.98% * 100;
 Minibatch[ 801- 900]: loss = 0.408244 * 100, metric = 9.52% * 100;
 Minibatch[ 901-1000]: loss = 0.394444 * 100, metric = 9.06% * 100;
 Minibatch[1001-1100]: loss = 0.393617 * 100, metric = 9.18% * 100;
 Minibatch[1101-1200]: loss = 0.390392 * 100, metric = 8.88% * 100;
 Minibatch[1201-1300]: loss = 0.378045 * 100, metric = 8.33% * 100;
 Minibatch[1301-1400]: loss = 0.399805 * 100, metric = 9.45% * 100;
 Minibatch[1401-1500]: loss = 0.366596 * 100, metric = 8.24% * 100;
 Minibatch[1501-1600]: loss = 0.381551 * 100, metric = 8.70% * 100;
 Minibatch[1601-1700]: loss = 0.391265 * 100, metric = 9.17% * 100;
 Minibatch[1701-1800]: loss = 0.378518 * 100, metric = 8.44% * 100;
 Minibatch[1801-1900]: loss = 0.382839 * 100, metric = 8.70% * 100;
 Minibatch[1901-2000]: loss = 0.384512 * 100, metric = 8.86% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.387762 * 2000, metric = 8.86% * 2000 797.882s (  2.5 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 15.11% * 2000;
0.4994995756372809
 Minibatch[   1- 100]: loss = 0.407841 * 100, metric = 9.63% * 100;
 Minibatch[ 101- 200]: loss = 0.392716 * 100, metric = 8.97% * 100;
 Minibatch[ 201- 300]: loss = 0.391078 * 100, metric = 8.73% * 100;
 Minibatch[ 301- 400]: loss = 0.398103 * 100, metric = 9.17% * 100;
 Minibatch[ 401- 500]: loss = 0.375001 * 100, metric = 8.36% * 100;
 Minibatch[ 501- 600]: loss = 0.386022 * 100, metric = 8.88% * 100;
 Minibatch[ 601- 700]: loss = 0.380905 * 100, metric = 8.69% * 100;
 Minibatch[ 701- 800]: loss = 0.377141 * 100, metric = 8.42% * 100;
 Minibatch[ 801- 900]: loss = 0.375089 * 100, metric = 8.49% * 100;
 Minibatch[ 901-1000]: loss = 0.383601 * 100, metric = 8.83% * 100;
 Minibatch[1001-1100]: loss = 0.370190 * 100, metric = 8.35% * 100;
 Minibatch[1101-1200]: loss = 0.381248 * 100, metric = 8.76% * 100;
 Minibatch[1201-1300]: loss = 0.369281 * 100, metric = 8.38% * 100;
 Minibatch[1301-1400]: loss = 0.379261 * 100, metric = 8.61% * 100;
 Minibatch[1401-1500]: loss = 0.378666 * 100, metric = 8.79% * 100;
 Minibatch[1501-1600]: loss = 0.381538 * 100, metric = 8.73% * 100;
 Minibatch[1601-1700]: loss = 0.379935 * 100, metric = 8.67% * 100;
 Minibatch[1701-1800]: loss = 0.392285 * 100, metric = 8.93% * 100;
 Minibatch[1801-1900]: loss = 0.385554 * 100, metric = 8.95% * 100;
 Minibatch[1901-2000]: loss = 0.374444 * 100, metric = 8.46% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.382995 * 2000, metric = 8.74% * 2000 801.366s (  2.5 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 15.57% * 2000;
 Minibatch[   1- 100]: loss = 0.368041 * 100, metric = 8.44% * 100;
 Minibatch[ 101- 200]: loss = 0.391979 * 100, metric = 8.92% * 100;
 Minibatch[ 201- 300]: loss = 0.381711 * 100, metric = 8.74% * 100;
 Minibatch[ 301- 400]: loss = 0.378013 * 100, metric = 8.54% * 100;
 Minibatch[ 401- 500]: loss = 0.382674 * 100, metric = 8.62% * 100;
 Minibatch[ 501- 600]: loss = 0.375352 * 100, metric = 8.45% * 100;
 Minibatch[ 601- 700]: loss = 0.356017 * 100, metric = 7.82% * 100;
 Minibatch[ 701- 800]: loss = 0.375417 * 100, metric = 8.54% * 100;
 Minibatch[ 801- 900]: loss = 0.375515 * 100, metric = 8.58% * 100;
 Minibatch[ 901-1000]: loss = 0.368605 * 100, metric = 8.19% * 100;
 Minibatch[1001-1100]: loss = 0.367597 * 100, metric = 8.42% * 100;
 Minibatch[1101-1200]: loss = 0.389671 * 100, metric = 9.10% * 100;
 Minibatch[1201-1300]: loss = 0.383134 * 100, metric = 8.72% * 100;
 Minibatch[1301-1400]: loss = 0.362614 * 100, metric = 8.25% * 100;
 Minibatch[1401-1500]: loss = 0.378248 * 100, metric = 8.47% * 100;
 Minibatch[1501-1600]: loss = 0.373923 * 100, metric = 8.53% * 100;
 Minibatch[1601-1700]: loss = 0.372839 * 100, metric = 8.36% * 100;
 Minibatch[1701-1800]: loss = 0.357180 * 100, metric = 8.05% * 100;
 Minibatch[1801-1900]: loss = 0.388582 * 100, metric = 9.00% * 100;
 Minibatch[1901-2000]: loss = 0.389416 * 100, metric = 9.08% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.375826 * 2000, metric = 8.54% * 2000 798.624s (  2.5 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.80% * 2000;
0.49947239746153355
 Minibatch[   1- 100]: loss = 0.364760 * 100, metric = 8.24% * 100;
 Minibatch[ 101- 200]: loss = 0.379299 * 100, metric = 8.67% * 100;
 Minibatch[ 201- 300]: loss = 0.365498 * 100, metric = 8.32% * 100;
 Minibatch[ 301- 400]: loss = 0.373501 * 100, metric = 8.49% * 100;
 Minibatch[ 401- 500]: loss = 0.363011 * 100, metric = 8.13% * 100;
 Minibatch[ 501- 600]: loss = 0.369524 * 100, metric = 8.45% * 100;
 Minibatch[ 601- 700]: loss = 0.373850 * 100, metric = 8.55% * 100;
 Minibatch[ 701- 800]: loss = 0.361435 * 100, metric = 8.33% * 100;
 Minibatch[ 801- 900]: loss = 0.371227 * 100, metric = 8.43% * 100;
 Minibatch[ 901-1000]: loss = 0.372660 * 100, metric = 8.51% * 100;
 Minibatch[1001-1100]: loss = 0.387912 * 100, metric = 8.95% * 100;
 Minibatch[1101-1200]: loss = 0.377251 * 100, metric = 8.58% * 100;
 Minibatch[1201-1300]: loss = 0.381533 * 100, metric = 8.74% * 100;
 Minibatch[1301-1400]: loss = 0.377061 * 100, metric = 8.48% * 100;
 Minibatch[1401-1500]: loss = 0.356030 * 100, metric = 7.99% * 100;
 Minibatch[1501-1600]: loss = 0.366810 * 100, metric = 8.30% * 100;
 Minibatch[1601-1700]: loss = 0.348782 * 100, metric = 7.80% * 100;
 Minibatch[1701-1800]: loss = 0.364883 * 100, metric = 8.12% * 100;
 Minibatch[1801-1900]: loss = 0.350347 * 100, metric = 7.93% * 100;
 Minibatch[1901-2000]: loss = 0.355875 * 100, metric = 7.86% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.368062 * 2000, metric = 8.34% * 2000 791.147s (  2.5 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 16.00% * 2000;
 Minibatch[   1- 100]: loss = 0.373378 * 100, metric = 8.53% * 100;
 Minibatch[ 101- 200]: loss = 0.378271 * 100, metric = 8.49% * 100;
 Minibatch[ 201- 300]: loss = 0.358689 * 100, metric = 7.83% * 100;
 Minibatch[ 301- 400]: loss = 0.373321 * 100, metric = 8.31% * 100;
 Minibatch[ 401- 500]: loss = 0.363186 * 100, metric = 8.01% * 100;
 Minibatch[ 501- 600]: loss = 0.360507 * 100, metric = 7.81% * 100;
 Minibatch[ 601- 700]: loss = 0.368152 * 100, metric = 8.18% * 100;
 Minibatch[ 701- 800]: loss = 0.363964 * 100, metric = 8.30% * 100;
 Minibatch[ 801- 900]: loss = 0.383271 * 100, metric = 8.59% * 100;
 Minibatch[ 901-1000]: loss = 0.352630 * 100, metric = 7.66% * 100;
 Minibatch[1001-1100]: loss = 0.372048 * 100, metric = 8.37% * 100;
 Minibatch[1101-1200]: loss = 0.361570 * 100, metric = 8.23% * 100;
 Minibatch[1201-1300]: loss = 0.365675 * 100, metric = 8.30% * 100;
 Minibatch[1301-1400]: loss = 0.363324 * 100, metric = 8.34% * 100;
 Minibatch[1401-1500]: loss = 0.369110 * 100, metric = 8.39% * 100;
 Minibatch[1501-1600]: loss = 0.368569 * 100, metric = 8.39% * 100;
 Minibatch[1601-1700]: loss = 0.352433 * 100, metric = 7.90% * 100;
 Minibatch[1701-1800]: loss = 0.343826 * 100, metric = 7.64% * 100;
 Minibatch[1801-1900]: loss = 0.349169 * 100, metric = 7.64% * 100;
 Minibatch[1901-2000]: loss = 0.338312 * 100, metric = 7.34% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.362970 * 2000, metric = 8.11% * 2000 792.356s (  2.5 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 15.45% * 2000;
 Minibatch[   1- 100]: loss = 0.352213 * 100, metric = 7.58% * 100;
 Minibatch[ 101- 200]: loss = 0.349181 * 100, metric = 7.84% * 100;
 Minibatch[ 201- 300]: loss = 0.347622 * 100, metric = 7.65% * 100;
 Minibatch[ 301- 400]: loss = 0.366528 * 100, metric = 8.00% * 100;
 Minibatch[ 401- 500]: loss = 0.347837 * 100, metric = 7.74% * 100;
 Minibatch[ 501- 600]: loss = 0.362995 * 100, metric = 8.25% * 100;
 Minibatch[ 601- 700]: loss = 0.360557 * 100, metric = 8.25% * 100;
 Minibatch[ 701- 800]: loss = 0.356850 * 100, metric = 8.01% * 100;
 Minibatch[ 801- 900]: loss = 0.371821 * 100, metric = 8.37% * 100;
 Minibatch[ 901-1000]: loss = 0.368723 * 100, metric = 8.32% * 100;
 Minibatch[1001-1100]: loss = 0.341833 * 100, metric = 7.46% * 100;
 Minibatch[1101-1200]: loss = 0.346208 * 100, metric = 7.67% * 100;
 Minibatch[1201-1300]: loss = 0.360133 * 100, metric = 8.15% * 100;
 Minibatch[1301-1400]: loss = 0.359514 * 100, metric = 8.19% * 100;
 Minibatch[1401-1500]: loss = 0.347585 * 100, metric = 7.97% * 100;
 Minibatch[1501-1600]: loss = 0.370042 * 100, metric = 8.26% * 100;
 Minibatch[1601-1700]: loss = 0.353550 * 100, metric = 7.88% * 100;
 Minibatch[1701-1800]: loss = 0.363392 * 100, metric = 8.26% * 100;
 Minibatch[1801-1900]: loss = 0.352860 * 100, metric = 8.09% * 100;
 Minibatch[1901-2000]: loss = 0.348486 * 100, metric = 7.94% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.356396 * 2000, metric = 7.99% * 2000 786.752s (  2.5 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 16.33% * 2000;
 Minibatch[   1- 100]: loss = 0.353853 * 100, metric = 7.79% * 100;
 Minibatch[ 101- 200]: loss = 0.355087 * 100, metric = 8.04% * 100;
 Minibatch[ 201- 300]: loss = 0.349719 * 100, metric = 7.98% * 100;
 Minibatch[ 301- 400]: loss = 0.354676 * 100, metric = 8.11% * 100;
 Minibatch[ 401- 500]: loss = 0.344051 * 100, metric = 7.69% * 100;
 Minibatch[ 501- 600]: loss = 0.345806 * 100, metric = 7.72% * 100;
 Minibatch[ 601- 700]: loss = 0.344159 * 100, metric = 7.52% * 100;
 Minibatch[ 701- 800]: loss = 0.325549 * 100, metric = 7.34% * 100;
 Minibatch[ 801- 900]: loss = 0.351407 * 100, metric = 7.89% * 100;
 Minibatch[ 901-1000]: loss = 0.336021 * 100, metric = 7.45% * 100;
 Minibatch[1001-1100]: loss = 0.343166 * 100, metric = 7.79% * 100;
 Minibatch[1101-1200]: loss = 0.338235 * 100, metric = 7.49% * 100;
 Minibatch[1201-1300]: loss = 0.348340 * 100, metric = 7.65% * 100;
 Minibatch[1301-1400]: loss = 0.327449 * 100, metric = 7.28% * 100;
 Minibatch[1401-1500]: loss = 0.353866 * 100, metric = 8.08% * 100;
 Minibatch[1501-1600]: loss = 0.359424 * 100, metric = 8.34% * 100;
 Minibatch[1601-1700]: loss = 0.345828 * 100, metric = 7.78% * 100;
 Minibatch[1701-1800]: loss = 0.343105 * 100, metric = 7.69% * 100;
 Minibatch[1801-1900]: loss = 0.358619 * 100, metric = 7.92% * 100;
 Minibatch[1901-2000]: loss = 0.332851 * 100, metric = 7.32% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.345561 * 2000, metric = 7.74% * 2000 790.084s (  2.5 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 14.20% * 2000;
0.4938951689787209
 Minibatch[   1- 100]: loss = 0.353397 * 100, metric = 7.94% * 100;
 Minibatch[ 101- 200]: loss = 0.348131 * 100, metric = 7.91% * 100;
 Minibatch[ 201- 300]: loss = 0.349635 * 100, metric = 7.90% * 100;
 Minibatch[ 301- 400]: loss = 0.341523 * 100, metric = 7.76% * 100;
 Minibatch[ 401- 500]: loss = 0.333373 * 100, metric = 7.34% * 100;
 Minibatch[ 501- 600]: loss = 0.352301 * 100, metric = 7.87% * 100;
 Minibatch[ 601- 700]: loss = 0.338307 * 100, metric = 7.51% * 100;
 Minibatch[ 701- 800]: loss = 0.339845 * 100, metric = 7.51% * 100;
 Minibatch[ 801- 900]: loss = 0.348489 * 100, metric = 7.82% * 100;
 Minibatch[ 901-1000]: loss = 0.349209 * 100, metric = 7.88% * 100;
 Minibatch[1001-1100]: loss = 0.334262 * 100, metric = 7.44% * 100;
 Minibatch[1101-1200]: loss = 0.322836 * 100, metric = 7.15% * 100;
 Minibatch[1201-1300]: loss = 0.333984 * 100, metric = 7.44% * 100;
 Minibatch[1301-1400]: loss = 0.339149 * 100, metric = 7.76% * 100;
 Minibatch[1401-1500]: loss = 0.336486 * 100, metric = 7.58% * 100;
 Minibatch[1501-1600]: loss = 0.325945 * 100, metric = 7.32% * 100;
 Minibatch[1601-1700]: loss = 0.336118 * 100, metric = 7.58% * 100;
 Minibatch[1701-1800]: loss = 0.333182 * 100, metric = 7.42% * 100;
 Minibatch[1801-1900]: loss = 0.331995 * 100, metric = 7.48% * 100;
 Minibatch[1901-2000]: loss = 0.330231 * 100, metric = 7.06% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.338920 * 2000, metric = 7.58% * 2000 781.418s (  2.6 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 15.27% * 2000;
 Minibatch[   1- 100]: loss = 0.347215 * 100, metric = 7.62% * 100;
 Minibatch[ 101- 200]: loss = 0.347454 * 100, metric = 7.97% * 100;
 Minibatch[ 201- 300]: loss = 0.340828 * 100, metric = 7.48% * 100;
 Minibatch[ 301- 400]: loss = 0.344597 * 100, metric = 7.79% * 100;
 Minibatch[ 401- 500]: loss = 0.348100 * 100, metric = 7.99% * 100;
 Minibatch[ 501- 600]: loss = 0.340203 * 100, metric = 7.55% * 100;
 Minibatch[ 601- 700]: loss = 0.343965 * 100, metric = 7.59% * 100;
 Minibatch[ 701- 800]: loss = 0.325442 * 100, metric = 7.22% * 100;
 Minibatch[ 801- 900]: loss = 0.325010 * 100, metric = 7.17% * 100;
 Minibatch[ 901-1000]: loss = 0.345040 * 100, metric = 7.63% * 100;
 Minibatch[1001-1100]: loss = 0.330876 * 100, metric = 7.10% * 100;
 Minibatch[1101-1200]: loss = 0.337641 * 100, metric = 7.54% * 100;
 Minibatch[1201-1300]: loss = 0.340721 * 100, metric = 7.70% * 100;
 Minibatch[1301-1400]: loss = 0.343651 * 100, metric = 7.76% * 100;
 Minibatch[1401-1500]: loss = 0.331056 * 100, metric = 7.56% * 100;
 Minibatch[1501-1600]: loss = 0.330199 * 100, metric = 7.24% * 100;
 Minibatch[1601-1700]: loss = 0.329842 * 100, metric = 7.42% * 100;
 Minibatch[1701-1800]: loss = 0.339139 * 100, metric = 7.73% * 100;
 Minibatch[1801-1900]: loss = 0.340486 * 100, metric = 7.77% * 100;
 Minibatch[1901-2000]: loss = 0.339219 * 100, metric = 7.55% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.338534 * 2000, metric = 7.57% * 2000 782.828s (  2.6 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 14.85% * 2000;
 Minibatch[   1- 100]: loss = 0.320918 * 100, metric = 7.34% * 100;
 Minibatch[ 101- 200]: loss = 0.340833 * 100, metric = 7.95% * 100;
 Minibatch[ 201- 300]: loss = 0.327151 * 100, metric = 7.37% * 100;
 Minibatch[ 301- 400]: loss = 0.333821 * 100, metric = 7.59% * 100;
 Minibatch[ 401- 500]: loss = 0.329772 * 100, metric = 7.33% * 100;
 Minibatch[ 501- 600]: loss = 0.329229 * 100, metric = 7.53% * 100;
 Minibatch[ 601- 700]: loss = 0.338684 * 100, metric = 7.54% * 100;
 Minibatch[ 701- 800]: loss = 0.325901 * 100, metric = 7.34% * 100;
 Minibatch[ 801- 900]: loss = 0.348438 * 100, metric = 7.93% * 100;
 Minibatch[ 901-1000]: loss = 0.333906 * 100, metric = 7.61% * 100;
 Minibatch[1001-1100]: loss = 0.339580 * 100, metric = 7.83% * 100;
 Minibatch[1101-1200]: loss = 0.348756 * 100, metric = 8.06% * 100;
 Minibatch[1201-1300]: loss = 0.337573 * 100, metric = 7.49% * 100;
 Minibatch[1301-1400]: loss = 0.332338 * 100, metric = 7.29% * 100;
 Minibatch[1401-1500]: loss = 0.331404 * 100, metric = 7.44% * 100;
 Minibatch[1501-1600]: loss = 0.338748 * 100, metric = 7.65% * 100;
 Minibatch[1601-1700]: loss = 0.326243 * 100, metric = 7.26% * 100;
 Minibatch[1701-1800]: loss = 0.326923 * 100, metric = 7.39% * 100;
 Minibatch[1801-1900]: loss = 0.337927 * 100, metric = 7.63% * 100;
 Minibatch[1901-2000]: loss = 0.345903 * 100, metric = 7.95% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.334702 * 2000, metric = 7.58% * 2000 783.995s (  2.6 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.76% * 2000;
 Minibatch[   1- 100]: loss = 0.339403 * 100, metric = 7.50% * 100;
 Minibatch[ 101- 200]: loss = 0.341242 * 100, metric = 7.82% * 100;
 Minibatch[ 201- 300]: loss = 0.342968 * 100, metric = 7.77% * 100;
 Minibatch[ 301- 400]: loss = 0.335697 * 100, metric = 7.69% * 100;
 Minibatch[ 401- 500]: loss = 0.333475 * 100, metric = 7.53% * 100;
 Minibatch[ 501- 600]: loss = 0.330368 * 100, metric = 7.35% * 100;
 Minibatch[ 601- 700]: loss = 0.334238 * 100, metric = 7.53% * 100;
 Minibatch[ 701- 800]: loss = 0.320239 * 100, metric = 7.15% * 100;
 Minibatch[ 801- 900]: loss = 0.326229 * 100, metric = 7.33% * 100;
 Minibatch[ 901-1000]: loss = 0.327687 * 100, metric = 7.36% * 100;
 Minibatch[1001-1100]: loss = 0.338087 * 100, metric = 7.54% * 100;
 Minibatch[1101-1200]: loss = 0.333450 * 100, metric = 7.44% * 100;
 Minibatch[1201-1300]: loss = 0.345624 * 100, metric = 7.97% * 100;
 Minibatch[1301-1400]: loss = 0.335623 * 100, metric = 7.53% * 100;
 Minibatch[1401-1500]: loss = 0.325978 * 100, metric = 7.31% * 100;
 Minibatch[1501-1600]: loss = 0.342846 * 100, metric = 8.11% * 100;
 Minibatch[1601-1700]: loss = 0.330187 * 100, metric = 7.49% * 100;
 Minibatch[1701-1800]: loss = 0.332233 * 100, metric = 7.59% * 100;
 Minibatch[1801-1900]: loss = 0.324636 * 100, metric = 7.49% * 100;
 Minibatch[1901-2000]: loss = 0.313973 * 100, metric = 7.02% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.332709 * 2000, metric = 7.53% * 2000 781.456s (  2.6 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.15% * 2000;
 Minibatch[   1- 100]: loss = 0.331280 * 100, metric = 7.65% * 100;
 Minibatch[ 101- 200]: loss = 0.318058 * 100, metric = 7.23% * 100;
 Minibatch[ 201- 300]: loss = 0.337237 * 100, metric = 7.59% * 100;
 Minibatch[ 301- 400]: loss = 0.316181 * 100, metric = 7.00% * 100;
 Minibatch[ 401- 500]: loss = 0.328122 * 100, metric = 7.49% * 100;
 Minibatch[ 501- 600]: loss = 0.317820 * 100, metric = 6.95% * 100;
 Minibatch[ 601- 700]: loss = 0.344253 * 100, metric = 7.70% * 100;
 Minibatch[ 701- 800]: loss = 0.326678 * 100, metric = 7.59% * 100;
 Minibatch[ 801- 900]: loss = 0.313137 * 100, metric = 6.95% * 100;
 Minibatch[ 901-1000]: loss = 0.313828 * 100, metric = 7.00% * 100;
 Minibatch[1001-1100]: loss = 0.337330 * 100, metric = 7.81% * 100;
 Minibatch[1101-1200]: loss = 0.333112 * 100, metric = 7.58% * 100;
 Minibatch[1201-1300]: loss = 0.327576 * 100, metric = 7.37% * 100;
 Minibatch[1301-1400]: loss = 0.309745 * 100, metric = 6.78% * 100;
 Minibatch[1401-1500]: loss = 0.324791 * 100, metric = 7.33% * 100;
 Minibatch[1501-1600]: loss = 0.319765 * 100, metric = 6.95% * 100;
 Minibatch[1601-1700]: loss = 0.337524 * 100, metric = 7.63% * 100;
 Minibatch[1701-1800]: loss = 0.333121 * 100, metric = 7.47% * 100;
 Minibatch[1801-1900]: loss = 0.324785 * 100, metric = 7.23% * 100;
 Minibatch[1901-2000]: loss = 0.326439 * 100, metric = 7.31% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.326039 * 2000, metric = 7.33% * 2000 775.242s (  2.6 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.77% * 2000;
 Minibatch[   1- 100]: loss = 0.324018 * 100, metric = 7.13% * 100;
 Minibatch[ 101- 200]: loss = 0.331571 * 100, metric = 7.27% * 100;
 Minibatch[ 201- 300]: loss = 0.323832 * 100, metric = 7.23% * 100;
 Minibatch[ 301- 400]: loss = 0.320377 * 100, metric = 7.28% * 100;
 Minibatch[ 401- 500]: loss = 0.321863 * 100, metric = 7.39% * 100;
 Minibatch[ 501- 600]: loss = 0.325308 * 100, metric = 7.32% * 100;
 Minibatch[ 601- 700]: loss = 0.315275 * 100, metric = 7.00% * 100;
 Minibatch[ 701- 800]: loss = 0.325140 * 100, metric = 7.33% * 100;
 Minibatch[ 801- 900]: loss = 0.326093 * 100, metric = 7.12% * 100;
 Minibatch[ 901-1000]: loss = 0.322031 * 100, metric = 7.41% * 100;
 Minibatch[1001-1100]: loss = 0.316183 * 100, metric = 7.08% * 100;
 Minibatch[1101-1200]: loss = 0.334093 * 100, metric = 7.46% * 100;
 Minibatch[1201-1300]: loss = 0.323691 * 100, metric = 7.19% * 100;
 Minibatch[1301-1400]: loss = 0.328788 * 100, metric = 7.37% * 100;
 Minibatch[1401-1500]: loss = 0.316989 * 100, metric = 7.12% * 100;
 Minibatch[1501-1600]: loss = 0.321581 * 100, metric = 7.33% * 100;
 Minibatch[1601-1700]: loss = 0.303760 * 100, metric = 6.66% * 100;
 Minibatch[1701-1800]: loss = 0.307234 * 100, metric = 6.79% * 100;
 Minibatch[1801-1900]: loss = 0.323527 * 100, metric = 7.31% * 100;
 Minibatch[1901-2000]: loss = 0.320457 * 100, metric = 7.02% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.321591 * 2000, metric = 7.19% * 2000 787.564s (  2.5 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 14.05% * 2000;
0.4937504144012928
 Minibatch[   1- 100]: loss = 0.328223 * 100, metric = 7.53% * 100;
 Minibatch[ 101- 200]: loss = 0.313687 * 100, metric = 6.95% * 100;
 Minibatch[ 201- 300]: loss = 0.322392 * 100, metric = 7.06% * 100;
 Minibatch[ 301- 400]: loss = 0.319911 * 100, metric = 7.16% * 100;
 Minibatch[ 401- 500]: loss = 0.315506 * 100, metric = 6.99% * 100;
 Minibatch[ 501- 600]: loss = 0.336189 * 100, metric = 7.64% * 100;
 Minibatch[ 601- 700]: loss = 0.315613 * 100, metric = 6.85% * 100;
 Minibatch[ 701- 800]: loss = 0.307051 * 100, metric = 6.81% * 100;
 Minibatch[ 801- 900]: loss = 0.324640 * 100, metric = 7.28% * 100;
 Minibatch[ 901-1000]: loss = 0.325008 * 100, metric = 7.41% * 100;
 Minibatch[1001-1100]: loss = 0.321004 * 100, metric = 7.32% * 100;
 Minibatch[1101-1200]: loss = 0.307579 * 100, metric = 6.69% * 100;
 Minibatch[1201-1300]: loss = 0.318308 * 100, metric = 7.30% * 100;
 Minibatch[1301-1400]: loss = 0.315502 * 100, metric = 7.11% * 100;
 Minibatch[1401-1500]: loss = 0.319760 * 100, metric = 7.05% * 100;
 Minibatch[1501-1600]: loss = 0.312623 * 100, metric = 6.99% * 100;
 Minibatch[1601-1700]: loss = 0.311654 * 100, metric = 6.89% * 100;
 Minibatch[1701-1800]: loss = 0.307978 * 100, metric = 6.96% * 100;
 Minibatch[1801-1900]: loss = 0.313158 * 100, metric = 7.00% * 100;
 Minibatch[1901-2000]: loss = 0.315562 * 100, metric = 7.06% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.317567 * 2000, metric = 7.10% * 2000 809.811s (  2.5 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.56% * 2000;
0.4884845707193017
 Minibatch[   1- 100]: loss = 0.308233 * 100, metric = 6.73% * 100;
 Minibatch[ 101- 200]: loss = 0.314646 * 100, metric = 7.02% * 100;
 Minibatch[ 201- 300]: loss = 0.325459 * 100, metric = 7.36% * 100;
 Minibatch[ 301- 400]: loss = 0.331607 * 100, metric = 7.66% * 100;
 Minibatch[ 401- 500]: loss = 0.306040 * 100, metric = 6.81% * 100;
 Minibatch[ 501- 600]: loss = 0.315033 * 100, metric = 6.98% * 100;
 Minibatch[ 601- 700]: loss = 0.312625 * 100, metric = 6.99% * 100;
 Minibatch[ 701- 800]: loss = 0.317523 * 100, metric = 7.28% * 100;
 Minibatch[ 801- 900]: loss = 0.315891 * 100, metric = 7.12% * 100;
 Minibatch[ 901-1000]: loss = 0.317556 * 100, metric = 7.27% * 100;
 Minibatch[1001-1100]: loss = 0.315482 * 100, metric = 7.21% * 100;
 Minibatch[1101-1200]: loss = 0.303560 * 100, metric = 6.69% * 100;
 Minibatch[1201-1300]: loss = 0.325556 * 100, metric = 7.31% * 100;
 Minibatch[1301-1400]: loss = 0.305173 * 100, metric = 6.59% * 100;
 Minibatch[1401-1500]: loss = 0.325146 * 100, metric = 7.30% * 100;
 Minibatch[1501-1600]: loss = 0.302766 * 100, metric = 6.78% * 100;
 Minibatch[1601-1700]: loss = 0.322364 * 100, metric = 7.34% * 100;
 Minibatch[1701-1800]: loss = 0.305850 * 100, metric = 6.79% * 100;
 Minibatch[1801-1900]: loss = 0.320704 * 100, metric = 7.15% * 100;
 Minibatch[1901-2000]: loss = 0.315970 * 100, metric = 7.02% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.315359 * 2000, metric = 7.07% * 2000 827.837s (  2.4 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 14.92% * 2000;
 Minibatch[   1- 100]: loss = 0.331368 * 100, metric = 7.22% * 100;
 Minibatch[ 101- 200]: loss = 0.293095 * 100, metric = 6.31% * 100;
 Minibatch[ 201- 300]: loss = 0.308922 * 100, metric = 6.88% * 100;
 Minibatch[ 301- 400]: loss = 0.317797 * 100, metric = 7.08% * 100;
 Minibatch[ 401- 500]: loss = 0.313240 * 100, metric = 6.95% * 100;
 Minibatch[ 501- 600]: loss = 0.294168 * 100, metric = 6.37% * 100;
 Minibatch[ 601- 700]: loss = 0.317845 * 100, metric = 7.14% * 100;
 Minibatch[ 701- 800]: loss = 0.310961 * 100, metric = 6.76% * 100;
 Minibatch[ 801- 900]: loss = 0.322633 * 100, metric = 7.33% * 100;
 Minibatch[ 901-1000]: loss = 0.293766 * 100, metric = 6.48% * 100;
 Minibatch[1001-1100]: loss = 0.310636 * 100, metric = 6.90% * 100;
 Minibatch[1101-1200]: loss = 0.317987 * 100, metric = 7.05% * 100;
 Minibatch[1201-1300]: loss = 0.308069 * 100, metric = 6.71% * 100;
 Minibatch[1301-1400]: loss = 0.316717 * 100, metric = 7.07% * 100;
 Minibatch[1401-1500]: loss = 0.312312 * 100, metric = 6.94% * 100;
 Minibatch[1501-1600]: loss = 0.310865 * 100, metric = 7.06% * 100;
 Minibatch[1601-1700]: loss = 0.320833 * 100, metric = 7.12% * 100;
 Minibatch[1701-1800]: loss = 0.315051 * 100, metric = 7.09% * 100;
 Minibatch[1801-1900]: loss = 0.312628 * 100, metric = 6.99% * 100;
 Minibatch[1901-2000]: loss = 0.326727 * 100, metric = 7.43% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.312781 * 2000, metric = 6.94% * 2000 796.087s (  2.5 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.92% * 2000;
 Minibatch[   1- 100]: loss = 0.309295 * 100, metric = 6.76% * 100;
 Minibatch[ 101- 200]: loss = 0.319306 * 100, metric = 7.36% * 100;
 Minibatch[ 201- 300]: loss = 0.305005 * 100, metric = 6.74% * 100;
 Minibatch[ 301- 400]: loss = 0.314547 * 100, metric = 7.14% * 100;
 Minibatch[ 401- 500]: loss = 0.308867 * 100, metric = 6.72% * 100;
 Minibatch[ 501- 600]: loss = 0.308401 * 100, metric = 6.73% * 100;
 Minibatch[ 601- 700]: loss = 0.321982 * 100, metric = 7.19% * 100;
 Minibatch[ 701- 800]: loss = 0.318184 * 100, metric = 7.15% * 100;
 Minibatch[ 801- 900]: loss = 0.313463 * 100, metric = 6.86% * 100;
 Minibatch[ 901-1000]: loss = 0.302049 * 100, metric = 6.61% * 100;
 Minibatch[1001-1100]: loss = 0.297236 * 100, metric = 6.48% * 100;
 Minibatch[1101-1200]: loss = 0.302440 * 100, metric = 6.75% * 100;
 Minibatch[1201-1300]: loss = 0.303324 * 100, metric = 6.68% * 100;
 Minibatch[1301-1400]: loss = 0.310252 * 100, metric = 7.05% * 100;
 Minibatch[1401-1500]: loss = 0.315706 * 100, metric = 7.07% * 100;
 Minibatch[1501-1600]: loss = 0.294984 * 100, metric = 6.52% * 100;
 Minibatch[1601-1700]: loss = 0.305038 * 100, metric = 6.71% * 100;
 Minibatch[1701-1800]: loss = 0.304014 * 100, metric = 6.86% * 100;
 Minibatch[1801-1900]: loss = 0.306096 * 100, metric = 6.77% * 100;
 Minibatch[1901-2000]: loss = 0.303122 * 100, metric = 6.68% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.308166 * 2000, metric = 6.84% * 2000 769.087s (  2.6 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 14.18% * 2000;
 Minibatch[   1- 100]: loss = 0.299058 * 100, metric = 6.69% * 100;
 Minibatch[ 101- 200]: loss = 0.307282 * 100, metric = 6.91% * 100;
 Minibatch[ 201- 300]: loss = 0.312022 * 100, metric = 6.97% * 100;
 Minibatch[ 301- 400]: loss = 0.316102 * 100, metric = 6.87% * 100;
 Minibatch[ 401- 500]: loss = 0.313977 * 100, metric = 7.10% * 100;
 Minibatch[ 501- 600]: loss = 0.310855 * 100, metric = 6.97% * 100;
 Minibatch[ 601- 700]: loss = 0.299947 * 100, metric = 6.42% * 100;
 Minibatch[ 701- 800]: loss = 0.299226 * 100, metric = 6.54% * 100;
 Minibatch[ 801- 900]: loss = 0.306880 * 100, metric = 6.78% * 100;
 Minibatch[ 901-1000]: loss = 0.296596 * 100, metric = 6.48% * 100;
 Minibatch[1001-1100]: loss = 0.299750 * 100, metric = 6.45% * 100;
 Minibatch[1101-1200]: loss = 0.305301 * 100, metric = 6.79% * 100;
 Minibatch[1201-1300]: loss = 0.314749 * 100, metric = 7.21% * 100;
 Minibatch[1301-1400]: loss = 0.303559 * 100, metric = 6.75% * 100;
 Minibatch[1401-1500]: loss = 0.307699 * 100, metric = 7.00% * 100;
 Minibatch[1501-1600]: loss = 0.310021 * 100, metric = 7.04% * 100;
 Minibatch[1601-1700]: loss = 0.300423 * 100, metric = 6.74% * 100;
 Minibatch[1701-1800]: loss = 0.310992 * 100, metric = 7.03% * 100;
 Minibatch[1801-1900]: loss = 0.298392 * 100, metric = 6.62% * 100;
 Minibatch[1901-2000]: loss = 0.309398 * 100, metric = 7.06% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.306111 * 2000, metric = 6.82% * 2000 769.677s (  2.6 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.28% * 2000;
 Minibatch[   1- 100]: loss = 0.320243 * 100, metric = 7.20% * 100;
 Minibatch[ 101- 200]: loss = 0.308163 * 100, metric = 7.13% * 100;
 Minibatch[ 201- 300]: loss = 0.305013 * 100, metric = 6.96% * 100;
 Minibatch[ 301- 400]: loss = 0.305781 * 100, metric = 6.98% * 100;
 Minibatch[ 401- 500]: loss = 0.301625 * 100, metric = 6.81% * 100;
 Minibatch[ 501- 600]: loss = 0.303503 * 100, metric = 6.75% * 100;
 Minibatch[ 601- 700]: loss = 0.314631 * 100, metric = 7.12% * 100;
 Minibatch[ 701- 800]: loss = 0.313912 * 100, metric = 6.95% * 100;
 Minibatch[ 801- 900]: loss = 0.297420 * 100, metric = 6.55% * 100;
 Minibatch[ 901-1000]: loss = 0.292174 * 100, metric = 6.46% * 100;
 Minibatch[1001-1100]: loss = 0.299381 * 100, metric = 6.67% * 100;
 Minibatch[1101-1200]: loss = 0.290690 * 100, metric = 6.35% * 100;
 Minibatch[1201-1300]: loss = 0.307885 * 100, metric = 6.79% * 100;
 Minibatch[1301-1400]: loss = 0.293431 * 100, metric = 6.49% * 100;
 Minibatch[1401-1500]: loss = 0.316443 * 100, metric = 7.07% * 100;
 Minibatch[1501-1600]: loss = 0.311400 * 100, metric = 7.08% * 100;
 Minibatch[1601-1700]: loss = 0.300027 * 100, metric = 6.52% * 100;
 Minibatch[1701-1800]: loss = 0.299759 * 100, metric = 6.65% * 100;
 Minibatch[1801-1900]: loss = 0.293025 * 100, metric = 6.42% * 100;
 Minibatch[1901-2000]: loss = 0.312653 * 100, metric = 7.21% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.304358 * 2000, metric = 6.81% * 2000 763.921s (  2.6 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.80% * 2000;
 Minibatch[   1- 100]: loss = 0.297734 * 100, metric = 6.64% * 100;
 Minibatch[ 101- 200]: loss = 0.308213 * 100, metric = 7.00% * 100;
 Minibatch[ 201- 300]: loss = 0.305321 * 100, metric = 6.74% * 100;
 Minibatch[ 301- 400]: loss = 0.306659 * 100, metric = 6.88% * 100;
 Minibatch[ 401- 500]: loss = 0.299151 * 100, metric = 6.61% * 100;
 Minibatch[ 501- 600]: loss = 0.314274 * 100, metric = 6.89% * 100;
 Minibatch[ 601- 700]: loss = 0.307975 * 100, metric = 7.22% * 100;
 Minibatch[ 701- 800]: loss = 0.293001 * 100, metric = 6.57% * 100;
 Minibatch[ 801- 900]: loss = 0.289250 * 100, metric = 6.24% * 100;
 Minibatch[ 901-1000]: loss = 0.292020 * 100, metric = 6.64% * 100;
 Minibatch[1001-1100]: loss = 0.300399 * 100, metric = 6.88% * 100;
 Minibatch[1101-1200]: loss = 0.296975 * 100, metric = 6.72% * 100;
 Minibatch[1201-1300]: loss = 0.305974 * 100, metric = 7.00% * 100;
 Minibatch[1301-1400]: loss = 0.293166 * 100, metric = 6.50% * 100;
 Minibatch[1401-1500]: loss = 0.310069 * 100, metric = 7.09% * 100;
 Minibatch[1501-1600]: loss = 0.305747 * 100, metric = 6.82% * 100;
 Minibatch[1601-1700]: loss = 0.316046 * 100, metric = 7.15% * 100;
 Minibatch[1701-1800]: loss = 0.294894 * 100, metric = 6.54% * 100;
 Minibatch[1801-1900]: loss = 0.304965 * 100, metric = 6.97% * 100;
 Minibatch[1901-2000]: loss = 0.305829 * 100, metric = 6.80% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.302383 * 2000, metric = 6.80% * 2000 772.226s (  2.6 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.37% * 2000;
 Minibatch[   1- 100]: loss = 0.286207 * 100, metric = 6.25% * 100;
 Minibatch[ 101- 200]: loss = 0.300411 * 100, metric = 6.83% * 100;
 Minibatch[ 201- 300]: loss = 0.305246 * 100, metric = 6.80% * 100;
 Minibatch[ 301- 400]: loss = 0.286652 * 100, metric = 6.35% * 100;
 Minibatch[ 401- 500]: loss = 0.290943 * 100, metric = 6.29% * 100;
 Minibatch[ 501- 600]: loss = 0.282417 * 100, metric = 6.09% * 100;
 Minibatch[ 601- 700]: loss = 0.307320 * 100, metric = 7.07% * 100;
 Minibatch[ 701- 800]: loss = 0.283437 * 100, metric = 6.32% * 100;
 Minibatch[ 801- 900]: loss = 0.303391 * 100, metric = 6.74% * 100;
 Minibatch[ 901-1000]: loss = 0.285241 * 100, metric = 6.37% * 100;
 Minibatch[1001-1100]: loss = 0.303921 * 100, metric = 6.81% * 100;
 Minibatch[1101-1200]: loss = 0.297368 * 100, metric = 6.63% * 100;
 Minibatch[1201-1300]: loss = 0.298452 * 100, metric = 6.66% * 100;
 Minibatch[1301-1400]: loss = 0.300173 * 100, metric = 6.79% * 100;
 Minibatch[1401-1500]: loss = 0.292397 * 100, metric = 6.35% * 100;
 Minibatch[1501-1600]: loss = 0.298187 * 100, metric = 6.62% * 100;
 Minibatch[1601-1700]: loss = 0.298633 * 100, metric = 6.68% * 100;
 Minibatch[1701-1800]: loss = 0.289936 * 100, metric = 6.44% * 100;
 Minibatch[1801-1900]: loss = 0.299711 * 100, metric = 6.87% * 100;
 Minibatch[1901-2000]: loss = 0.290213 * 100, metric = 6.64% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.295013 * 2000, metric = 6.58% * 2000 765.945s (  2.6 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.76% * 2000;
 Minibatch[   1- 100]: loss = 0.293871 * 100, metric = 6.50% * 100;
 Minibatch[ 101- 200]: loss = 0.284554 * 100, metric = 6.25% * 100;
 Minibatch[ 201- 300]: loss = 0.305950 * 100, metric = 7.25% * 100;
 Minibatch[ 301- 400]: loss = 0.291432 * 100, metric = 6.51% * 100;
 Minibatch[ 401- 500]: loss = 0.287450 * 100, metric = 6.38% * 100;
 Minibatch[ 501- 600]: loss = 0.299388 * 100, metric = 6.66% * 100;
 Minibatch[ 601- 700]: loss = 0.298943 * 100, metric = 6.53% * 100;
 Minibatch[ 701- 800]: loss = 0.284011 * 100, metric = 6.30% * 100;
 Minibatch[ 801- 900]: loss = 0.282583 * 100, metric = 6.35% * 100;
 Minibatch[ 901-1000]: loss = 0.298787 * 100, metric = 6.76% * 100;
 Minibatch[1001-1100]: loss = 0.300820 * 100, metric = 6.91% * 100;
 Minibatch[1101-1200]: loss = 0.284776 * 100, metric = 6.35% * 100;
 Minibatch[1201-1300]: loss = 0.295561 * 100, metric = 6.72% * 100;
 Minibatch[1301-1400]: loss = 0.275887 * 100, metric = 6.06% * 100;
 Minibatch[1401-1500]: loss = 0.288222 * 100, metric = 6.31% * 100;
 Minibatch[1501-1600]: loss = 0.287628 * 100, metric = 6.54% * 100;
 Minibatch[1601-1700]: loss = 0.296563 * 100, metric = 6.64% * 100;
 Minibatch[1701-1800]: loss = 0.292432 * 100, metric = 6.66% * 100;
 Minibatch[1801-1900]: loss = 0.287974 * 100, metric = 6.37% * 100;
 Minibatch[1901-2000]: loss = 0.284299 * 100, metric = 6.26% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.291056 * 2000, metric = 6.52% * 2000 761.287s (  2.6 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.58% * 2000;
 Minibatch[   1- 100]: loss = 0.288350 * 100, metric = 6.34% * 100;
 Minibatch[ 101- 200]: loss = 0.294542 * 100, metric = 6.69% * 100;
 Minibatch[ 201- 300]: loss = 0.286348 * 100, metric = 6.48% * 100;
 Minibatch[ 301- 400]: loss = 0.289695 * 100, metric = 6.56% * 100;
 Minibatch[ 401- 500]: loss = 0.286043 * 100, metric = 6.48% * 100;
 Minibatch[ 501- 600]: loss = 0.278687 * 100, metric = 6.44% * 100;
 Minibatch[ 601- 700]: loss = 0.284682 * 100, metric = 6.53% * 100;
 Minibatch[ 701- 800]: loss = 0.302441 * 100, metric = 6.82% * 100;
 Minibatch[ 801- 900]: loss = 0.287597 * 100, metric = 6.55% * 100;
 Minibatch[ 901-1000]: loss = 0.281564 * 100, metric = 6.15% * 100;
 Minibatch[1001-1100]: loss = 0.285659 * 100, metric = 6.50% * 100;
 Minibatch[1101-1200]: loss = 0.303637 * 100, metric = 7.21% * 100;
 Minibatch[1201-1300]: loss = 0.308514 * 100, metric = 7.01% * 100;
 Minibatch[1301-1400]: loss = 0.292672 * 100, metric = 6.30% * 100;
 Minibatch[1401-1500]: loss = 0.297495 * 100, metric = 6.63% * 100;
 Minibatch[1501-1600]: loss = 0.286934 * 100, metric = 6.26% * 100;
 Minibatch[1601-1700]: loss = 0.296348 * 100, metric = 6.90% * 100;
 Minibatch[1701-1800]: loss = 0.282802 * 100, metric = 6.16% * 100;
 Minibatch[1801-1900]: loss = 0.293643 * 100, metric = 6.73% * 100;
 Minibatch[1901-2000]: loss = 0.287786 * 100, metric = 6.54% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.290772 * 2000, metric = 6.56% * 2000 764.510s (  2.6 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.49% * 2000;
 Minibatch[   1- 100]: loss = 0.296291 * 100, metric = 6.68% * 100;
 Minibatch[ 101- 200]: loss = 0.292471 * 100, metric = 6.58% * 100;
 Minibatch[ 201- 300]: loss = 0.274995 * 100, metric = 6.00% * 100;
 Minibatch[ 301- 400]: loss = 0.278904 * 100, metric = 6.28% * 100;
 Minibatch[ 401- 500]: loss = 0.290438 * 100, metric = 6.46% * 100;
 Minibatch[ 501- 600]: loss = 0.283876 * 100, metric = 6.25% * 100;
 Minibatch[ 601- 700]: loss = 0.297386 * 100, metric = 6.79% * 100;
 Minibatch[ 701- 800]: loss = 0.283768 * 100, metric = 6.28% * 100;
 Minibatch[ 801- 900]: loss = 0.293482 * 100, metric = 6.70% * 100;
 Minibatch[ 901-1000]: loss = 0.285872 * 100, metric = 6.44% * 100;
 Minibatch[1001-1100]: loss = 0.294746 * 100, metric = 6.72% * 100;
 Minibatch[1101-1200]: loss = 0.281798 * 100, metric = 6.19% * 100;
 Minibatch[1201-1300]: loss = 0.285553 * 100, metric = 6.46% * 100;
 Minibatch[1301-1400]: loss = 0.296920 * 100, metric = 6.49% * 100;
 Minibatch[1401-1500]: loss = 0.289342 * 100, metric = 6.57% * 100;
 Minibatch[1501-1600]: loss = 0.293097 * 100, metric = 6.59% * 100;
 Minibatch[1601-1700]: loss = 0.276895 * 100, metric = 6.04% * 100;
 Minibatch[1701-1800]: loss = 0.285169 * 100, metric = 6.50% * 100;
 Minibatch[1801-1900]: loss = 0.286718 * 100, metric = 6.40% * 100;
 Minibatch[1901-2000]: loss = 0.285186 * 100, metric = 6.21% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.287645 * 2000, metric = 6.43% * 2000 762.942s (  2.6 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 13.02% * 2000;
 Minibatch[   1- 100]: loss = 0.276488 * 100, metric = 6.24% * 100;
 Minibatch[ 101- 200]: loss = 0.290465 * 100, metric = 6.51% * 100;
 Minibatch[ 201- 300]: loss = 0.285815 * 100, metric = 6.29% * 100;
 Minibatch[ 301- 400]: loss = 0.282368 * 100, metric = 6.26% * 100;
 Minibatch[ 401- 500]: loss = 0.276849 * 100, metric = 6.21% * 100;
 Minibatch[ 501- 600]: loss = 0.284992 * 100, metric = 6.41% * 100;
 Minibatch[ 601- 700]: loss = 0.293627 * 100, metric = 6.52% * 100;
 Minibatch[ 701- 800]: loss = 0.287677 * 100, metric = 6.45% * 100;
 Minibatch[ 801- 900]: loss = 0.271193 * 100, metric = 6.09% * 100;
 Minibatch[ 901-1000]: loss = 0.271417 * 100, metric = 5.89% * 100;
 Minibatch[1001-1100]: loss = 0.289527 * 100, metric = 6.53% * 100;
 Minibatch[1101-1200]: loss = 0.288111 * 100, metric = 6.43% * 100;
 Minibatch[1201-1300]: loss = 0.286610 * 100, metric = 6.31% * 100;
 Minibatch[1301-1400]: loss = 0.289755 * 100, metric = 6.42% * 100;
 Minibatch[1401-1500]: loss = 0.289898 * 100, metric = 6.65% * 100;
 Minibatch[1501-1600]: loss = 0.284717 * 100, metric = 6.26% * 100;
 Minibatch[1601-1700]: loss = 0.273891 * 100, metric = 6.12% * 100;
 Minibatch[1701-1800]: loss = 0.292419 * 100, metric = 6.61% * 100;
 Minibatch[1801-1900]: loss = 0.284785 * 100, metric = 6.39% * 100;
 Minibatch[1901-2000]: loss = 0.284939 * 100, metric = 6.21% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.284277 * 2000, metric = 6.34% * 2000 756.954s (  2.6 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.33% * 2000;
 Minibatch[   1- 100]: loss = 0.282117 * 100, metric = 6.20% * 100;
 Minibatch[ 101- 200]: loss = 0.272952 * 100, metric = 6.04% * 100;
 Minibatch[ 201- 300]: loss = 0.285882 * 100, metric = 6.33% * 100;
 Minibatch[ 301- 400]: loss = 0.283805 * 100, metric = 6.36% * 100;
 Minibatch[ 401- 500]: loss = 0.276801 * 100, metric = 6.21% * 100;
 Minibatch[ 501- 600]: loss = 0.275927 * 100, metric = 5.98% * 100;
 Minibatch[ 601- 700]: loss = 0.292393 * 100, metric = 6.39% * 100;
 Minibatch[ 701- 800]: loss = 0.280218 * 100, metric = 6.10% * 100;
 Minibatch[ 801- 900]: loss = 0.281582 * 100, metric = 6.42% * 100;
 Minibatch[ 901-1000]: loss = 0.279090 * 100, metric = 6.21% * 100;
 Minibatch[1001-1100]: loss = 0.291128 * 100, metric = 6.48% * 100;
 Minibatch[1101-1200]: loss = 0.287512 * 100, metric = 6.41% * 100;
 Minibatch[1201-1300]: loss = 0.287665 * 100, metric = 6.36% * 100;
 Minibatch[1301-1400]: loss = 0.288779 * 100, metric = 6.32% * 100;
 Minibatch[1401-1500]: loss = 0.277401 * 100, metric = 5.98% * 100;
 Minibatch[1501-1600]: loss = 0.292276 * 100, metric = 6.60% * 100;
 Minibatch[1601-1700]: loss = 0.282451 * 100, metric = 6.25% * 100;
 Minibatch[1701-1800]: loss = 0.268991 * 100, metric = 5.95% * 100;
 Minibatch[1801-1900]: loss = 0.266369 * 100, metric = 5.81% * 100;
 Minibatch[1901-2000]: loss = 0.282501 * 100, metric = 6.49% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.281792 * 2000, metric = 6.24% * 2000 756.989s (  2.6 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 13.71% * 2000;
 Minibatch[   1- 100]: loss = 0.273307 * 100, metric = 6.15% * 100;
 Minibatch[ 101- 200]: loss = 0.275732 * 100, metric = 6.13% * 100;
 Minibatch[ 201- 300]: loss = 0.284136 * 100, metric = 6.31% * 100;
 Minibatch[ 301- 400]: loss = 0.286403 * 100, metric = 6.40% * 100;
 Minibatch[ 401- 500]: loss = 0.278799 * 100, metric = 6.21% * 100;
 Minibatch[ 501- 600]: loss = 0.274159 * 100, metric = 6.01% * 100;
 Minibatch[ 601- 700]: loss = 0.277625 * 100, metric = 6.29% * 100;
 Minibatch[ 701- 800]: loss = 0.275076 * 100, metric = 6.14% * 100;
 Minibatch[ 801- 900]: loss = 0.277736 * 100, metric = 6.19% * 100;
 Minibatch[ 901-1000]: loss = 0.275707 * 100, metric = 6.34% * 100;
 Minibatch[1001-1100]: loss = 0.276733 * 100, metric = 6.07% * 100;
 Minibatch[1101-1200]: loss = 0.286439 * 100, metric = 6.45% * 100;
 Minibatch[1201-1300]: loss = 0.286210 * 100, metric = 6.44% * 100;
 Minibatch[1301-1400]: loss = 0.264536 * 100, metric = 5.88% * 100;
 Minibatch[1401-1500]: loss = 0.275581 * 100, metric = 6.16% * 100;
 Minibatch[1501-1600]: loss = 0.275164 * 100, metric = 6.06% * 100;
 Minibatch[1601-1700]: loss = 0.276021 * 100, metric = 6.10% * 100;
 Minibatch[1701-1800]: loss = 0.286082 * 100, metric = 6.48% * 100;
 Minibatch[1801-1900]: loss = 0.280164 * 100, metric = 6.24% * 100;
 Minibatch[1901-2000]: loss = 0.275007 * 100, metric = 6.05% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.278031 * 2000, metric = 6.21% * 2000 778.181s (  2.6 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 14.04% * 2000;
 Minibatch[   1- 100]: loss = 0.275766 * 100, metric = 6.12% * 100;
 Minibatch[ 101- 200]: loss = 0.273553 * 100, metric = 6.20% * 100;
 Minibatch[ 201- 300]: loss = 0.271932 * 100, metric = 6.00% * 100;
 Minibatch[ 301- 400]: loss = 0.268968 * 100, metric = 6.01% * 100;
 Minibatch[ 401- 500]: loss = 0.275553 * 100, metric = 5.98% * 100;
 Minibatch[ 501- 600]: loss = 0.274703 * 100, metric = 6.25% * 100;
 Minibatch[ 601- 700]: loss = 0.276403 * 100, metric = 6.07% * 100;
 Minibatch[ 701- 800]: loss = 0.269064 * 100, metric = 5.98% * 100;
 Minibatch[ 801- 900]: loss = 0.271276 * 100, metric = 6.13% * 100;
 Minibatch[ 901-1000]: loss = 0.288089 * 100, metric = 6.51% * 100;
 Minibatch[1001-1100]: loss = 0.279959 * 100, metric = 6.42% * 100;
 Minibatch[1101-1200]: loss = 0.267683 * 100, metric = 5.94% * 100;
 Minibatch[1201-1300]: loss = 0.272070 * 100, metric = 6.05% * 100;
 Minibatch[1301-1400]: loss = 0.272883 * 100, metric = 6.11% * 100;
 Minibatch[1401-1500]: loss = 0.271024 * 100, metric = 6.11% * 100;
 Minibatch[1501-1600]: loss = 0.269251 * 100, metric = 5.93% * 100;
 Minibatch[1601-1700]: loss = 0.286333 * 100, metric = 6.31% * 100;
 Minibatch[1701-1800]: loss = 0.280938 * 100, metric = 6.24% * 100;
 Minibatch[1801-1900]: loss = 0.277213 * 100, metric = 6.20% * 100;
 Minibatch[1901-2000]: loss = 0.274630 * 100, metric = 6.03% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.274865 * 2000, metric = 6.13% * 2000 754.477s (  2.7 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 12.59% * 2000;
 Minibatch[   1- 100]: loss = 0.289220 * 100, metric = 6.59% * 100;
 Minibatch[ 101- 200]: loss = 0.261433 * 100, metric = 5.72% * 100;
 Minibatch[ 201- 300]: loss = 0.279403 * 100, metric = 6.16% * 100;
 Minibatch[ 301- 400]: loss = 0.277545 * 100, metric = 6.16% * 100;
 Minibatch[ 401- 500]: loss = 0.268033 * 100, metric = 5.88% * 100;
 Minibatch[ 501- 600]: loss = 0.271220 * 100, metric = 6.09% * 100;
 Minibatch[ 601- 700]: loss = 0.278018 * 100, metric = 6.20% * 100;
 Minibatch[ 701- 800]: loss = 0.267125 * 100, metric = 5.96% * 100;
 Minibatch[ 801- 900]: loss = 0.276612 * 100, metric = 6.43% * 100;
 Minibatch[ 901-1000]: loss = 0.274985 * 100, metric = 6.25% * 100;
 Minibatch[1001-1100]: loss = 0.281526 * 100, metric = 6.45% * 100;
 Minibatch[1101-1200]: loss = 0.276571 * 100, metric = 6.29% * 100;
 Minibatch[1201-1300]: loss = 0.285136 * 100, metric = 6.62% * 100;
 Minibatch[1301-1400]: loss = 0.274921 * 100, metric = 6.40% * 100;
 Minibatch[1401-1500]: loss = 0.266892 * 100, metric = 6.01% * 100;
 Minibatch[1501-1600]: loss = 0.283898 * 100, metric = 6.31% * 100;
 Minibatch[1601-1700]: loss = 0.271216 * 100, metric = 6.17% * 100;
 Minibatch[1701-1800]: loss = 0.271350 * 100, metric = 6.12% * 100;
 Minibatch[1801-1900]: loss = 0.287354 * 100, metric = 6.57% * 100;
 Minibatch[1901-2000]: loss = 0.274280 * 100, metric = 6.06% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.275837 * 2000, metric = 6.22% * 2000 745.865s (  2.7 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 13.57% * 2000;
 Minibatch[   1- 100]: loss = 0.261418 * 100, metric = 5.83% * 100;
 Minibatch[ 101- 200]: loss = 0.265998 * 100, metric = 6.12% * 100;
 Minibatch[ 201- 300]: loss = 0.269170 * 100, metric = 5.96% * 100;
 Minibatch[ 301- 400]: loss = 0.279555 * 100, metric = 6.28% * 100;
 Minibatch[ 401- 500]: loss = 0.274181 * 100, metric = 6.04% * 100;
 Minibatch[ 501- 600]: loss = 0.269833 * 100, metric = 6.09% * 100;
 Minibatch[ 601- 700]: loss = 0.282937 * 100, metric = 6.40% * 100;
 Minibatch[ 701- 800]: loss = 0.252565 * 100, metric = 5.55% * 100;
 Minibatch[ 801- 900]: loss = 0.266871 * 100, metric = 5.79% * 100;
 Minibatch[ 901-1000]: loss = 0.264612 * 100, metric = 5.85% * 100;
 Minibatch[1001-1100]: loss = 0.264623 * 100, metric = 5.65% * 100;
 Minibatch[1101-1200]: loss = 0.249290 * 100, metric = 5.42% * 100;
 Minibatch[1201-1300]: loss = 0.265483 * 100, metric = 5.91% * 100;
 Minibatch[1301-1400]: loss = 0.269602 * 100, metric = 5.91% * 100;
 Minibatch[1401-1500]: loss = 0.257229 * 100, metric = 5.64% * 100;
 Minibatch[1501-1600]: loss = 0.252160 * 100, metric = 5.53% * 100;
 Minibatch[1601-1700]: loss = 0.259003 * 100, metric = 5.59% * 100;
 Minibatch[1701-1800]: loss = 0.280760 * 100, metric = 6.42% * 100;
 Minibatch[1801-1900]: loss = 0.265084 * 100, metric = 5.77% * 100;
 Minibatch[1901-2000]: loss = 0.267412 * 100, metric = 5.85% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.265889 * 2000, metric = 5.88% * 2000 741.095s (  2.7 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 14.30% * 2000;
 Minibatch[   1- 100]: loss = 0.266695 * 100, metric = 5.82% * 100;
 Minibatch[ 101- 200]: loss = 0.265908 * 100, metric = 5.82% * 100;
 Minibatch[ 201- 300]: loss = 0.266741 * 100, metric = 5.88% * 100;
 Minibatch[ 301- 400]: loss = 0.273374 * 100, metric = 6.08% * 100;
 Minibatch[ 401- 500]: loss = 0.264782 * 100, metric = 5.91% * 100;
 Minibatch[ 501- 600]: loss = 0.264104 * 100, metric = 5.75% * 100;
 Minibatch[ 601- 700]: loss = 0.258347 * 100, metric = 5.62% * 100;
 Minibatch[ 701- 800]: loss = 0.257644 * 100, metric = 5.78% * 100;
 Minibatch[ 801- 900]: loss = 0.279475 * 100, metric = 6.27% * 100;
 Minibatch[ 901-1000]: loss = 0.260676 * 100, metric = 5.79% * 100;
 Minibatch[1001-1100]: loss = 0.254967 * 100, metric = 5.46% * 100;
 Minibatch[1101-1200]: loss = 0.279094 * 100, metric = 6.21% * 100;
 Minibatch[1201-1300]: loss = 0.269891 * 100, metric = 6.02% * 100;
 Minibatch[1301-1400]: loss = 0.264474 * 100, metric = 5.82% * 100;
 Minibatch[1401-1500]: loss = 0.271542 * 100, metric = 6.18% * 100;
 Minibatch[1501-1600]: loss = 0.264933 * 100, metric = 5.88% * 100;
 Minibatch[1601-1700]: loss = 0.261168 * 100, metric = 5.93% * 100;
 Minibatch[1701-1800]: loss = 0.279933 * 100, metric = 6.19% * 100;
 Minibatch[1801-1900]: loss = 0.269990 * 100, metric = 6.24% * 100;
 Minibatch[1901-2000]: loss = 0.262767 * 100, metric = 5.68% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.266825 * 2000, metric = 5.92% * 2000 739.161s (  2.7 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 13.61% * 2000;
 Minibatch[   1- 100]: loss = 0.258849 * 100, metric = 5.84% * 100;
 Minibatch[ 101- 200]: loss = 0.279344 * 100, metric = 6.35% * 100;
 Minibatch[ 201- 300]: loss = 0.263231 * 100, metric = 5.73% * 100;
 Minibatch[ 301- 400]: loss = 0.278440 * 100, metric = 6.12% * 100;
 Minibatch[ 401- 500]: loss = 0.263404 * 100, metric = 5.59% * 100;
 Minibatch[ 501- 600]: loss = 0.261656 * 100, metric = 5.82% * 100;
 Minibatch[ 601- 700]: loss = 0.250620 * 100, metric = 5.49% * 100;
 Minibatch[ 701- 800]: loss = 0.252352 * 100, metric = 5.48% * 100;
 Minibatch[ 801- 900]: loss = 0.259406 * 100, metric = 5.75% * 100;
 Minibatch[ 901-1000]: loss = 0.258901 * 100, metric = 5.75% * 100;
 Minibatch[1001-1100]: loss = 0.260367 * 100, metric = 5.75% * 100;
 Minibatch[1101-1200]: loss = 0.263803 * 100, metric = 5.76% * 100;
 Minibatch[1201-1300]: loss = 0.266167 * 100, metric = 5.83% * 100;
 Minibatch[1301-1400]: loss = 0.271530 * 100, metric = 6.11% * 100;
 Minibatch[1401-1500]: loss = 0.254333 * 100, metric = 5.65% * 100;
 Minibatch[1501-1600]: loss = 0.258350 * 100, metric = 5.67% * 100;
 Minibatch[1601-1700]: loss = 0.255724 * 100, metric = 5.48% * 100;
 Minibatch[1701-1800]: loss = 0.275570 * 100, metric = 6.05% * 100;
 Minibatch[1801-1900]: loss = 0.254484 * 100, metric = 5.43% * 100;
 Minibatch[1901-2000]: loss = 0.265776 * 100, metric = 5.79% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.262615 * 2000, metric = 5.77% * 2000 741.270s (  2.7 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 12.91% * 2000;
 Minibatch[   1- 100]: loss = 0.266997 * 100, metric = 5.72% * 100;
 Minibatch[ 101- 200]: loss = 0.257234 * 100, metric = 5.65% * 100;
 Minibatch[ 201- 300]: loss = 0.253032 * 100, metric = 5.57% * 100;
 Minibatch[ 301- 400]: loss = 0.248288 * 100, metric = 5.22% * 100;
 Minibatch[ 401- 500]: loss = 0.260058 * 100, metric = 5.70% * 100;
 Minibatch[ 501- 600]: loss = 0.259199 * 100, metric = 5.53% * 100;
 Minibatch[ 601- 700]: loss = 0.266369 * 100, metric = 5.83% * 100;
 Minibatch[ 701- 800]: loss = 0.268533 * 100, metric = 6.08% * 100;
 Minibatch[ 801- 900]: loss = 0.255799 * 100, metric = 5.49% * 100;
 Minibatch[ 901-1000]: loss = 0.263519 * 100, metric = 5.58% * 100;
 Minibatch[1001-1100]: loss = 0.276479 * 100, metric = 6.24% * 100;
 Minibatch[1101-1200]: loss = 0.260719 * 100, metric = 5.70% * 100;
 Minibatch[1201-1300]: loss = 0.243762 * 100, metric = 5.39% * 100;
 Minibatch[1301-1400]: loss = 0.251235 * 100, metric = 5.55% * 100;
 Minibatch[1401-1500]: loss = 0.265972 * 100, metric = 5.96% * 100;
 Minibatch[1501-1600]: loss = 0.269681 * 100, metric = 5.79% * 100;
 Minibatch[1601-1700]: loss = 0.258041 * 100, metric = 5.52% * 100;
 Minibatch[1701-1800]: loss = 0.267154 * 100, metric = 5.95% * 100;
 Minibatch[1801-1900]: loss = 0.264918 * 100, metric = 5.89% * 100;
 Minibatch[1901-2000]: loss = 0.270405 * 100, metric = 6.01% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.261370 * 2000, metric = 5.72% * 2000 738.437s (  2.7 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 12.30% * 2000;
 Minibatch[   1- 100]: loss = 0.261956 * 100, metric = 5.94% * 100;
 Minibatch[ 101- 200]: loss = 0.262546 * 100, metric = 5.76% * 100;
 Minibatch[ 201- 300]: loss = 0.253437 * 100, metric = 5.71% * 100;
 Minibatch[ 301- 400]: loss = 0.259484 * 100, metric = 5.89% * 100;
 Minibatch[ 401- 500]: loss = 0.267879 * 100, metric = 6.00% * 100;
 Minibatch[ 501- 600]: loss = 0.270787 * 100, metric = 6.13% * 100;
 Minibatch[ 601- 700]: loss = 0.272564 * 100, metric = 6.02% * 100;
 Minibatch[ 701- 800]: loss = 0.254163 * 100, metric = 5.53% * 100;
 Minibatch[ 801- 900]: loss = 0.244741 * 100, metric = 5.35% * 100;
 Minibatch[ 901-1000]: loss = 0.265631 * 100, metric = 5.89% * 100;
 Minibatch[1001-1100]: loss = 0.259108 * 100, metric = 5.62% * 100;
 Minibatch[1101-1200]: loss = 0.259638 * 100, metric = 5.65% * 100;
 Minibatch[1201-1300]: loss = 0.258860 * 100, metric = 5.70% * 100;
 Minibatch[1301-1400]: loss = 0.262616 * 100, metric = 5.84% * 100;
 Minibatch[1401-1500]: loss = 0.261123 * 100, metric = 6.02% * 100;
 Minibatch[1501-1600]: loss = 0.251914 * 100, metric = 5.63% * 100;
 Minibatch[1601-1700]: loss = 0.252818 * 100, metric = 5.57% * 100;
 Minibatch[1701-1800]: loss = 0.259666 * 100, metric = 5.65% * 100;
 Minibatch[1801-1900]: loss = 0.271922 * 100, metric = 5.86% * 100;
 Minibatch[1901-2000]: loss = 0.254055 * 100, metric = 5.51% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.260245 * 2000, metric = 5.76% * 2000 764.459s (  2.6 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 13.56% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
