Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.369849 * 100, metric = 25.87% * 100;
 Minibatch[ 101- 200]: loss = 1.147455 * 100, metric = 23.44% * 100;
 Minibatch[ 201- 300]: loss = 1.040874 * 100, metric = 21.38% * 100;
 Minibatch[ 301- 400]: loss = 1.040435 * 100, metric = 20.82% * 100;
 Minibatch[ 401- 500]: loss = 0.979925 * 100, metric = 19.77% * 100;
 Minibatch[ 501- 600]: loss = 0.963796 * 100, metric = 18.67% * 100;
 Minibatch[ 601- 700]: loss = 0.926259 * 100, metric = 18.10% * 100;
 Minibatch[ 701- 800]: loss = 0.889586 * 100, metric = 17.21% * 100;
 Minibatch[ 801- 900]: loss = 0.902009 * 100, metric = 17.27% * 100;
 Minibatch[ 901-1000]: loss = 0.921269 * 100, metric = 17.92% * 100;
 Minibatch[1001-1100]: loss = 0.897967 * 100, metric = 17.44% * 100;
 Minibatch[1101-1200]: loss = 0.879729 * 100, metric = 16.59% * 100;
 Minibatch[1201-1300]: loss = 0.872449 * 100, metric = 16.77% * 100;
 Minibatch[1301-1400]: loss = 0.858134 * 100, metric = 15.99% * 100;
 Minibatch[1401-1500]: loss = 0.880010 * 100, metric = 16.28% * 100;
 Minibatch[1501-1600]: loss = 0.849233 * 100, metric = 16.19% * 100;
 Minibatch[1601-1700]: loss = 0.828340 * 100, metric = 15.69% * 100;
 Minibatch[1701-1800]: loss = 0.864902 * 100, metric = 16.30% * 100;
 Minibatch[1801-1900]: loss = 0.843949 * 100, metric = 16.01% * 100;
 Minibatch[1901-2000]: loss = 0.830087 * 100, metric = 15.39% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.939313 * 2000, metric = 18.15% * 2000 999.091s (  2.0 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 23.02% * 2000;
0.8520098164230585
 Minibatch[   1- 100]: loss = 0.831987 * 100, metric = 15.40% * 100;
 Minibatch[ 101- 200]: loss = 0.848164 * 100, metric = 16.20% * 100;
 Minibatch[ 201- 300]: loss = 0.832579 * 100, metric = 14.96% * 100;
 Minibatch[ 301- 400]: loss = 0.839738 * 100, metric = 15.55% * 100;
 Minibatch[ 401- 500]: loss = 0.830337 * 100, metric = 15.40% * 100;
 Minibatch[ 501- 600]: loss = 0.831647 * 100, metric = 15.23% * 100;
 Minibatch[ 601- 700]: loss = 0.790567 * 100, metric = 14.44% * 100;
 Minibatch[ 701- 800]: loss = 0.830259 * 100, metric = 15.49% * 100;
 Minibatch[ 801- 900]: loss = 0.809538 * 100, metric = 14.94% * 100;
 Minibatch[ 901-1000]: loss = 0.803110 * 100, metric = 14.50% * 100;
 Minibatch[1001-1100]: loss = 0.810134 * 100, metric = 15.06% * 100;
 Minibatch[1101-1200]: loss = 0.811866 * 100, metric = 14.58% * 100;
 Minibatch[1201-1300]: loss = 0.800321 * 100, metric = 14.49% * 100;
 Minibatch[1301-1400]: loss = 0.813209 * 100, metric = 14.89% * 100;
 Minibatch[1401-1500]: loss = 0.779291 * 100, metric = 13.97% * 100;
 Minibatch[1501-1600]: loss = 0.780220 * 100, metric = 14.05% * 100;
 Minibatch[1601-1700]: loss = 0.787164 * 100, metric = 14.20% * 100;
 Minibatch[1701-1800]: loss = 0.795309 * 100, metric = 14.80% * 100;
 Minibatch[1801-1900]: loss = 0.799871 * 100, metric = 14.46% * 100;
 Minibatch[1901-2000]: loss = 0.757831 * 100, metric = 14.01% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.809157 * 2000, metric = 14.83% * 2000 960.128s (  2.1 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 20.71% * 2000;
0.7793767591714859
 Minibatch[   1- 100]: loss = 0.781879 * 100, metric = 14.21% * 100;
 Minibatch[ 101- 200]: loss = 0.793576 * 100, metric = 14.59% * 100;
 Minibatch[ 201- 300]: loss = 0.773670 * 100, metric = 13.83% * 100;
 Minibatch[ 301- 400]: loss = 0.796796 * 100, metric = 14.86% * 100;
 Minibatch[ 401- 500]: loss = 0.802186 * 100, metric = 15.02% * 100;
 Minibatch[ 501- 600]: loss = 0.793128 * 100, metric = 14.52% * 100;
 Minibatch[ 601- 700]: loss = 0.799976 * 100, metric = 14.36% * 100;
 Minibatch[ 701- 800]: loss = 0.763748 * 100, metric = 13.49% * 100;
 Minibatch[ 801- 900]: loss = 0.781915 * 100, metric = 14.35% * 100;
 Minibatch[ 901-1000]: loss = 0.753091 * 100, metric = 14.13% * 100;
 Minibatch[1001-1100]: loss = 0.776176 * 100, metric = 14.50% * 100;
 Minibatch[1101-1200]: loss = 0.764655 * 100, metric = 13.86% * 100;
 Minibatch[1201-1300]: loss = 0.760850 * 100, metric = 13.70% * 100;
 Minibatch[1301-1400]: loss = 0.777574 * 100, metric = 14.04% * 100;
 Minibatch[1401-1500]: loss = 0.773790 * 100, metric = 14.31% * 100;
 Minibatch[1501-1600]: loss = 0.759204 * 100, metric = 13.63% * 100;
 Minibatch[1601-1700]: loss = 0.743201 * 100, metric = 13.05% * 100;
 Minibatch[1701-1800]: loss = 0.772694 * 100, metric = 13.93% * 100;
 Minibatch[1801-1900]: loss = 0.751370 * 100, metric = 13.20% * 100;
 Minibatch[1901-2000]: loss = 0.753248 * 100, metric = 13.65% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.773636 * 2000, metric = 14.06% * 2000 961.636s (  2.1 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 20.11% * 2000;
0.7680843667164445
 Minibatch[   1- 100]: loss = 0.784448 * 100, metric = 13.75% * 100;
 Minibatch[ 101- 200]: loss = 0.743097 * 100, metric = 13.09% * 100;
 Minibatch[ 201- 300]: loss = 0.761939 * 100, metric = 13.74% * 100;
 Minibatch[ 301- 400]: loss = 0.725473 * 100, metric = 13.10% * 100;
 Minibatch[ 401- 500]: loss = 0.751946 * 100, metric = 13.51% * 100;
 Minibatch[ 501- 600]: loss = 0.728757 * 100, metric = 12.87% * 100;
 Minibatch[ 601- 700]: loss = 0.730625 * 100, metric = 12.86% * 100;
 Minibatch[ 701- 800]: loss = 0.753471 * 100, metric = 13.20% * 100;
 Minibatch[ 801- 900]: loss = 0.745785 * 100, metric = 13.39% * 100;
 Minibatch[ 901-1000]: loss = 0.745459 * 100, metric = 13.61% * 100;
 Minibatch[1001-1100]: loss = 0.754353 * 100, metric = 13.95% * 100;
 Minibatch[1101-1200]: loss = 0.726915 * 100, metric = 13.14% * 100;
 Minibatch[1201-1300]: loss = 0.737231 * 100, metric = 13.32% * 100;
 Minibatch[1301-1400]: loss = 0.760427 * 100, metric = 13.49% * 100;
 Minibatch[1401-1500]: loss = 0.756906 * 100, metric = 13.81% * 100;
 Minibatch[1501-1600]: loss = 0.724238 * 100, metric = 12.87% * 100;
 Minibatch[1601-1700]: loss = 0.744897 * 100, metric = 13.62% * 100;
 Minibatch[1701-1800]: loss = 0.737559 * 100, metric = 13.50% * 100;
 Minibatch[1801-1900]: loss = 0.718478 * 100, metric = 12.79% * 100;
 Minibatch[1901-2000]: loss = 0.724666 * 100, metric = 13.00% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.742834 * 2000, metric = 13.33% * 2000 978.425s (  2.0 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 20.23% * 2000;
0.7642560428306461
 Minibatch[   1- 100]: loss = 0.747699 * 100, metric = 13.49% * 100;
 Minibatch[ 101- 200]: loss = 0.731107 * 100, metric = 12.90% * 100;
 Minibatch[ 201- 300]: loss = 0.722023 * 100, metric = 13.01% * 100;
 Minibatch[ 301- 400]: loss = 0.755768 * 100, metric = 14.05% * 100;
 Minibatch[ 401- 500]: loss = 0.727809 * 100, metric = 12.80% * 100;
 Minibatch[ 501- 600]: loss = 0.714107 * 100, metric = 12.41% * 100;
 Minibatch[ 601- 700]: loss = 0.730321 * 100, metric = 12.66% * 100;
 Minibatch[ 701- 800]: loss = 0.736201 * 100, metric = 13.12% * 100;
 Minibatch[ 801- 900]: loss = 0.720969 * 100, metric = 12.64% * 100;
 Minibatch[ 901-1000]: loss = 0.710729 * 100, metric = 12.60% * 100;
 Minibatch[1001-1100]: loss = 0.731285 * 100, metric = 12.98% * 100;
 Minibatch[1101-1200]: loss = 0.709576 * 100, metric = 12.41% * 100;
 Minibatch[1201-1300]: loss = 0.719997 * 100, metric = 12.61% * 100;
 Minibatch[1301-1400]: loss = 0.735192 * 100, metric = 13.12% * 100;
 Minibatch[1401-1500]: loss = 0.710173 * 100, metric = 12.55% * 100;
 Minibatch[1501-1600]: loss = 0.715468 * 100, metric = 12.68% * 100;
 Minibatch[1601-1700]: loss = 0.723226 * 100, metric = 13.19% * 100;
 Minibatch[1701-1800]: loss = 0.725673 * 100, metric = 13.13% * 100;
 Minibatch[1801-1900]: loss = 0.725613 * 100, metric = 13.05% * 100;
 Minibatch[1901-2000]: loss = 0.708931 * 100, metric = 12.73% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.725093 * 2000, metric = 12.91% * 2000 959.097s (  2.1 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 19.63% * 2000;
0.7413199188560248
 Minibatch[   1- 100]: loss = 0.710804 * 100, metric = 12.68% * 100;
 Minibatch[ 101- 200]: loss = 0.709393 * 100, metric = 12.66% * 100;
 Minibatch[ 201- 300]: loss = 0.718440 * 100, metric = 12.74% * 100;
 Minibatch[ 301- 400]: loss = 0.717610 * 100, metric = 12.43% * 100;
 Minibatch[ 401- 500]: loss = 0.685656 * 100, metric = 12.01% * 100;
 Minibatch[ 501- 600]: loss = 0.702788 * 100, metric = 12.64% * 100;
 Minibatch[ 601- 700]: loss = 0.702482 * 100, metric = 12.35% * 100;
 Minibatch[ 701- 800]: loss = 0.700432 * 100, metric = 12.44% * 100;
 Minibatch[ 801- 900]: loss = 0.707723 * 100, metric = 12.71% * 100;
 Minibatch[ 901-1000]: loss = 0.703035 * 100, metric = 12.39% * 100;
 Minibatch[1001-1100]: loss = 0.705751 * 100, metric = 12.23% * 100;
 Minibatch[1101-1200]: loss = 0.711476 * 100, metric = 12.35% * 100;
 Minibatch[1201-1300]: loss = 0.712813 * 100, metric = 12.82% * 100;
 Minibatch[1301-1400]: loss = 0.698573 * 100, metric = 12.37% * 100;
 Minibatch[1401-1500]: loss = 0.701045 * 100, metric = 12.61% * 100;
 Minibatch[1501-1600]: loss = 0.685863 * 100, metric = 11.91% * 100;
 Minibatch[1601-1700]: loss = 0.687891 * 100, metric = 11.86% * 100;
 Minibatch[1701-1800]: loss = 0.685239 * 100, metric = 12.19% * 100;
 Minibatch[1801-1900]: loss = 0.697428 * 100, metric = 12.03% * 100;
 Minibatch[1901-2000]: loss = 0.688519 * 100, metric = 12.17% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.701648 * 2000, metric = 12.38% * 2000 950.895s (  2.1 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.09% * 2000;
 Minibatch[   1- 100]: loss = 0.685891 * 100, metric = 11.95% * 100;
 Minibatch[ 101- 200]: loss = 0.700206 * 100, metric = 12.16% * 100;
 Minibatch[ 201- 300]: loss = 0.695249 * 100, metric = 12.44% * 100;
 Minibatch[ 301- 400]: loss = 0.689753 * 100, metric = 12.16% * 100;
 Minibatch[ 401- 500]: loss = 0.694005 * 100, metric = 12.06% * 100;
 Minibatch[ 501- 600]: loss = 0.675478 * 100, metric = 11.64% * 100;
 Minibatch[ 601- 700]: loss = 0.689543 * 100, metric = 11.79% * 100;
 Minibatch[ 701- 800]: loss = 0.697408 * 100, metric = 11.83% * 100;
 Minibatch[ 801- 900]: loss = 0.694614 * 100, metric = 12.36% * 100;
 Minibatch[ 901-1000]: loss = 0.687259 * 100, metric = 11.93% * 100;
 Minibatch[1001-1100]: loss = 0.699200 * 100, metric = 12.51% * 100;
 Minibatch[1101-1200]: loss = 0.678055 * 100, metric = 11.80% * 100;
 Minibatch[1201-1300]: loss = 0.691676 * 100, metric = 12.40% * 100;
 Minibatch[1301-1400]: loss = 0.669481 * 100, metric = 11.63% * 100;
 Minibatch[1401-1500]: loss = 0.668773 * 100, metric = 11.38% * 100;
 Minibatch[1501-1600]: loss = 0.681488 * 100, metric = 11.79% * 100;
 Minibatch[1601-1700]: loss = 0.686725 * 100, metric = 12.17% * 100;
 Minibatch[1701-1800]: loss = 0.668241 * 100, metric = 11.60% * 100;
 Minibatch[1801-1900]: loss = 0.672030 * 100, metric = 11.51% * 100;
 Minibatch[1901-2000]: loss = 0.676254 * 100, metric = 11.85% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.685066 * 2000, metric = 11.95% * 2000 950.398s (  2.1 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.24% * 2000;
0.704919885315001
 Minibatch[   1- 100]: loss = 0.684269 * 100, metric = 11.97% * 100;
 Minibatch[ 101- 200]: loss = 0.667706 * 100, metric = 11.89% * 100;
 Minibatch[ 201- 300]: loss = 0.658788 * 100, metric = 11.45% * 100;
 Minibatch[ 301- 400]: loss = 0.660411 * 100, metric = 11.36% * 100;
 Minibatch[ 401- 500]: loss = 0.665812 * 100, metric = 11.80% * 100;
 Minibatch[ 501- 600]: loss = 0.684619 * 100, metric = 12.17% * 100;
 Minibatch[ 601- 700]: loss = 0.645950 * 100, metric = 11.06% * 100;
 Minibatch[ 701- 800]: loss = 0.671834 * 100, metric = 11.43% * 100;
 Minibatch[ 801- 900]: loss = 0.644213 * 100, metric = 10.71% * 100;
 Minibatch[ 901-1000]: loss = 0.629767 * 100, metric = 10.37% * 100;
 Minibatch[1001-1100]: loss = 0.639617 * 100, metric = 10.73% * 100;
 Minibatch[1101-1200]: loss = 0.646535 * 100, metric = 10.96% * 100;
 Minibatch[1201-1300]: loss = 0.662980 * 100, metric = 11.56% * 100;
 Minibatch[1301-1400]: loss = 0.664882 * 100, metric = 11.57% * 100;
 Minibatch[1401-1500]: loss = 0.661171 * 100, metric = 11.20% * 100;
 Minibatch[1501-1600]: loss = 0.660609 * 100, metric = 11.53% * 100;
 Minibatch[1601-1700]: loss = 0.653770 * 100, metric = 11.10% * 100;
 Minibatch[1701-1800]: loss = 0.653510 * 100, metric = 10.97% * 100;
 Minibatch[1801-1900]: loss = 0.652214 * 100, metric = 11.00% * 100;
 Minibatch[1901-2000]: loss = 0.655684 * 100, metric = 11.01% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.658217 * 2000, metric = 11.29% * 2000 955.190s (  2.1 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 16.96% * 2000;
0.667754394158721
 Minibatch[   1- 100]: loss = 0.630668 * 100, metric = 10.30% * 100;
 Minibatch[ 101- 200]: loss = 0.664733 * 100, metric = 11.31% * 100;
 Minibatch[ 201- 300]: loss = 0.649652 * 100, metric = 10.75% * 100;
 Minibatch[ 301- 400]: loss = 0.661865 * 100, metric = 11.32% * 100;
 Minibatch[ 401- 500]: loss = 0.646938 * 100, metric = 10.78% * 100;
 Minibatch[ 501- 600]: loss = 0.643959 * 100, metric = 10.93% * 100;
 Minibatch[ 601- 700]: loss = 0.637409 * 100, metric = 10.93% * 100;
 Minibatch[ 701- 800]: loss = 0.637485 * 100, metric = 10.62% * 100;
 Minibatch[ 801- 900]: loss = 0.631692 * 100, metric = 10.73% * 100;
 Minibatch[ 901-1000]: loss = 0.647213 * 100, metric = 11.10% * 100;
 Minibatch[1001-1100]: loss = 0.631390 * 100, metric = 10.39% * 100;
 Minibatch[1101-1200]: loss = 0.651318 * 100, metric = 10.92% * 100;
 Minibatch[1201-1300]: loss = 0.633183 * 100, metric = 10.62% * 100;
 Minibatch[1301-1400]: loss = 0.632930 * 100, metric = 10.23% * 100;
 Minibatch[1401-1500]: loss = 0.654164 * 100, metric = 11.07% * 100;
 Minibatch[1501-1600]: loss = 0.647536 * 100, metric = 10.83% * 100;
 Minibatch[1601-1700]: loss = 0.642004 * 100, metric = 10.94% * 100;
 Minibatch[1701-1800]: loss = 0.627000 * 100, metric = 10.24% * 100;
 Minibatch[1801-1900]: loss = 0.636080 * 100, metric = 10.80% * 100;
 Minibatch[1901-2000]: loss = 0.648162 * 100, metric = 11.03% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.642769 * 2000, metric = 10.79% * 2000 952.582s (  2.1 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 15.99% * 2000;
0.6597801938951016
 Minibatch[   1- 100]: loss = 0.657990 * 100, metric = 11.50% * 100;
 Minibatch[ 101- 200]: loss = 0.630175 * 100, metric = 10.86% * 100;
 Minibatch[ 201- 300]: loss = 0.643091 * 100, metric = 10.93% * 100;
 Minibatch[ 301- 400]: loss = 0.625205 * 100, metric = 10.31% * 100;
 Minibatch[ 401- 500]: loss = 0.649971 * 100, metric = 11.12% * 100;
 Minibatch[ 501- 600]: loss = 0.627630 * 100, metric = 10.56% * 100;
 Minibatch[ 601- 700]: loss = 0.619957 * 100, metric = 10.14% * 100;
 Minibatch[ 701- 800]: loss = 0.609679 * 100, metric = 9.73% * 100;
 Minibatch[ 801- 900]: loss = 0.629949 * 100, metric = 10.29% * 100;
 Minibatch[ 901-1000]: loss = 0.628895 * 100, metric = 10.58% * 100;
 Minibatch[1001-1100]: loss = 0.627816 * 100, metric = 10.44% * 100;
 Minibatch[1101-1200]: loss = 0.636222 * 100, metric = 10.61% * 100;
 Minibatch[1201-1300]: loss = 0.639169 * 100, metric = 10.86% * 100;
 Minibatch[1301-1400]: loss = 0.635596 * 100, metric = 10.84% * 100;
 Minibatch[1401-1500]: loss = 0.622050 * 100, metric = 10.32% * 100;
 Minibatch[1501-1600]: loss = 0.624561 * 100, metric = 10.56% * 100;
 Minibatch[1601-1700]: loss = 0.624105 * 100, metric = 10.05% * 100;
 Minibatch[1701-1800]: loss = 0.631183 * 100, metric = 10.28% * 100;
 Minibatch[1801-1900]: loss = 0.641951 * 100, metric = 10.72% * 100;
 Minibatch[1901-2000]: loss = 0.614635 * 100, metric = 10.50% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.630992 * 2000, metric = 10.56% * 2000 952.831s (  2.1 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 16.06% * 2000;
0.6553685166761279
 Minibatch[   1- 100]: loss = 0.609481 * 100, metric = 10.06% * 100;
 Minibatch[ 101- 200]: loss = 0.623333 * 100, metric = 10.29% * 100;
 Minibatch[ 201- 300]: loss = 0.626603 * 100, metric = 10.61% * 100;
 Minibatch[ 301- 400]: loss = 0.622076 * 100, metric = 10.19% * 100;
 Minibatch[ 401- 500]: loss = 0.616577 * 100, metric = 10.42% * 100;
 Minibatch[ 501- 600]: loss = 0.624921 * 100, metric = 10.48% * 100;
 Minibatch[ 601- 700]: loss = 0.610407 * 100, metric = 9.89% * 100;
 Minibatch[ 701- 800]: loss = 0.624810 * 100, metric = 10.45% * 100;
 Minibatch[ 801- 900]: loss = 0.624854 * 100, metric = 10.25% * 100;
 Minibatch[ 901-1000]: loss = 0.623335 * 100, metric = 10.31% * 100;
 Minibatch[1001-1100]: loss = 0.603821 * 100, metric = 10.03% * 100;
 Minibatch[1101-1200]: loss = 0.624493 * 100, metric = 10.46% * 100;
 Minibatch[1201-1300]: loss = 0.605540 * 100, metric = 10.02% * 100;
 Minibatch[1301-1400]: loss = 0.597032 * 100, metric = 9.84% * 100;
 Minibatch[1401-1500]: loss = 0.621210 * 100, metric = 10.46% * 100;
 Minibatch[1501-1600]: loss = 0.612230 * 100, metric = 10.15% * 100;
 Minibatch[1601-1700]: loss = 0.618684 * 100, metric = 10.07% * 100;
 Minibatch[1701-1800]: loss = 0.620054 * 100, metric = 10.27% * 100;
 Minibatch[1801-1900]: loss = 0.604799 * 100, metric = 10.09% * 100;
 Minibatch[1901-2000]: loss = 0.606309 * 100, metric = 10.27% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.616028 * 2000, metric = 10.23% * 2000 951.205s (  2.1 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 16.24% * 2000;
 Minibatch[   1- 100]: loss = 0.594034 * 100, metric = 9.59% * 100;
 Minibatch[ 101- 200]: loss = 0.614361 * 100, metric = 9.83% * 100;
 Minibatch[ 201- 300]: loss = 0.607244 * 100, metric = 10.13% * 100;
 Minibatch[ 301- 400]: loss = 0.635278 * 100, metric = 10.84% * 100;
 Minibatch[ 401- 500]: loss = 0.606063 * 100, metric = 9.85% * 100;
 Minibatch[ 501- 600]: loss = 0.588384 * 100, metric = 9.24% * 100;
 Minibatch[ 601- 700]: loss = 0.599025 * 100, metric = 9.74% * 100;
 Minibatch[ 701- 800]: loss = 0.607831 * 100, metric = 10.01% * 100;
 Minibatch[ 801- 900]: loss = 0.602307 * 100, metric = 9.54% * 100;
 Minibatch[ 901-1000]: loss = 0.608004 * 100, metric = 10.02% * 100;
 Minibatch[1001-1100]: loss = 0.602865 * 100, metric = 10.13% * 100;
 Minibatch[1101-1200]: loss = 0.609042 * 100, metric = 9.93% * 100;
 Minibatch[1201-1300]: loss = 0.614920 * 100, metric = 10.40% * 100;
 Minibatch[1301-1400]: loss = 0.591274 * 100, metric = 9.62% * 100;
 Minibatch[1401-1500]: loss = 0.604920 * 100, metric = 9.97% * 100;
 Minibatch[1501-1600]: loss = 0.575074 * 100, metric = 9.41% * 100;
 Minibatch[1601-1700]: loss = 0.605359 * 100, metric = 10.12% * 100;
 Minibatch[1701-1800]: loss = 0.586118 * 100, metric = 9.49% * 100;
 Minibatch[1801-1900]: loss = 0.587781 * 100, metric = 9.46% * 100;
 Minibatch[1901-2000]: loss = 0.602129 * 100, metric = 9.84% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.602101 * 2000, metric = 9.86% * 2000 948.785s (  2.1 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 17.59% * 2000;
 Minibatch[   1- 100]: loss = 0.600626 * 100, metric = 9.97% * 100;
 Minibatch[ 101- 200]: loss = 0.601380 * 100, metric = 9.96% * 100;
 Minibatch[ 201- 300]: loss = 0.593821 * 100, metric = 9.64% * 100;
 Minibatch[ 301- 400]: loss = 0.605426 * 100, metric = 10.08% * 100;
 Minibatch[ 401- 500]: loss = 0.602453 * 100, metric = 10.59% * 100;
 Minibatch[ 501- 600]: loss = 0.608724 * 100, metric = 10.29% * 100;
 Minibatch[ 601- 700]: loss = 0.581202 * 100, metric = 9.24% * 100;
 Minibatch[ 701- 800]: loss = 0.579467 * 100, metric = 9.54% * 100;
 Minibatch[ 801- 900]: loss = 0.588574 * 100, metric = 9.38% * 100;
 Minibatch[ 901-1000]: loss = 0.609930 * 100, metric = 10.16% * 100;
 Minibatch[1001-1100]: loss = 0.605734 * 100, metric = 10.07% * 100;
 Minibatch[1101-1200]: loss = 0.595264 * 100, metric = 9.77% * 100;
 Minibatch[1201-1300]: loss = 0.595316 * 100, metric = 9.80% * 100;
 Minibatch[1301-1400]: loss = 0.585862 * 100, metric = 9.34% * 100;
 Minibatch[1401-1500]: loss = 0.591312 * 100, metric = 9.64% * 100;
 Minibatch[1501-1600]: loss = 0.580393 * 100, metric = 9.12% * 100;
 Minibatch[1601-1700]: loss = 0.568564 * 100, metric = 9.02% * 100;
 Minibatch[1701-1800]: loss = 0.581915 * 100, metric = 9.34% * 100;
 Minibatch[1801-1900]: loss = 0.580974 * 100, metric = 9.27% * 100;
 Minibatch[1901-2000]: loss = 0.597428 * 100, metric = 9.87% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.592718 * 2000, metric = 9.70% * 2000 890.296s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 17.41% * 2000;
 Minibatch[   1- 100]: loss = 0.585020 * 100, metric = 9.48% * 100;
 Minibatch[ 101- 200]: loss = 0.582798 * 100, metric = 9.50% * 100;
 Minibatch[ 201- 300]: loss = 0.590921 * 100, metric = 9.81% * 100;
 Minibatch[ 301- 400]: loss = 0.590970 * 100, metric = 9.79% * 100;
 Minibatch[ 401- 500]: loss = 0.585592 * 100, metric = 9.67% * 100;
 Minibatch[ 501- 600]: loss = 0.589452 * 100, metric = 9.64% * 100;
 Minibatch[ 601- 700]: loss = 0.586456 * 100, metric = 9.53% * 100;
 Minibatch[ 701- 800]: loss = 0.597438 * 100, metric = 9.83% * 100;
 Minibatch[ 801- 900]: loss = 0.598606 * 100, metric = 9.89% * 100;
 Minibatch[ 901-1000]: loss = 0.590244 * 100, metric = 9.81% * 100;
 Minibatch[1001-1100]: loss = 0.585045 * 100, metric = 9.82% * 100;
 Minibatch[1101-1200]: loss = 0.576634 * 100, metric = 9.52% * 100;
 Minibatch[1201-1300]: loss = 0.561688 * 100, metric = 8.91% * 100;
 Minibatch[1301-1400]: loss = 0.580757 * 100, metric = 9.92% * 100;
 Minibatch[1401-1500]: loss = 0.579420 * 100, metric = 9.43% * 100;
 Minibatch[1501-1600]: loss = 0.566937 * 100, metric = 9.34% * 100;
 Minibatch[1601-1700]: loss = 0.588843 * 100, metric = 9.55% * 100;
 Minibatch[1701-1800]: loss = 0.585150 * 100, metric = 9.34% * 100;
 Minibatch[1801-1900]: loss = 0.581986 * 100, metric = 9.30% * 100;
 Minibatch[1901-2000]: loss = 0.583044 * 100, metric = 9.39% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.584350 * 2000, metric = 9.57% * 2000 891.258s (  2.2 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 17.03% * 2000;
 Minibatch[   1- 100]: loss = 0.567543 * 100, metric = 9.01% * 100;
 Minibatch[ 101- 200]: loss = 0.586278 * 100, metric = 9.57% * 100;
 Minibatch[ 201- 300]: loss = 0.589528 * 100, metric = 9.59% * 100;
 Minibatch[ 301- 400]: loss = 0.562678 * 100, metric = 8.97% * 100;
 Minibatch[ 401- 500]: loss = 0.564435 * 100, metric = 9.09% * 100;
 Minibatch[ 501- 600]: loss = 0.561778 * 100, metric = 8.82% * 100;
 Minibatch[ 601- 700]: loss = 0.549326 * 100, metric = 8.91% * 100;
 Minibatch[ 701- 800]: loss = 0.579606 * 100, metric = 9.39% * 100;
 Minibatch[ 801- 900]: loss = 0.587108 * 100, metric = 9.81% * 100;
 Minibatch[ 901-1000]: loss = 0.577220 * 100, metric = 9.35% * 100;
 Minibatch[1001-1100]: loss = 0.573010 * 100, metric = 9.22% * 100;
 Minibatch[1101-1200]: loss = 0.567057 * 100, metric = 9.16% * 100;
 Minibatch[1201-1300]: loss = 0.558969 * 100, metric = 8.58% * 100;
 Minibatch[1301-1400]: loss = 0.584789 * 100, metric = 9.76% * 100;
 Minibatch[1401-1500]: loss = 0.550002 * 100, metric = 8.88% * 100;
 Minibatch[1501-1600]: loss = 0.555880 * 100, metric = 8.88% * 100;
 Minibatch[1601-1700]: loss = 0.564819 * 100, metric = 9.19% * 100;
 Minibatch[1701-1800]: loss = 0.547061 * 100, metric = 8.66% * 100;
 Minibatch[1801-1900]: loss = 0.559833 * 100, metric = 9.10% * 100;
 Minibatch[1901-2000]: loss = 0.564441 * 100, metric = 9.20% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.567568 * 2000, metric = 9.16% * 2000 880.232s (  2.3 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 15.08% * 2000;
0.6431255276724697
 Minibatch[   1- 100]: loss = 0.579487 * 100, metric = 9.75% * 100;
 Minibatch[ 101- 200]: loss = 0.566996 * 100, metric = 8.96% * 100;
 Minibatch[ 201- 300]: loss = 0.568947 * 100, metric = 9.19% * 100;
 Minibatch[ 301- 400]: loss = 0.565855 * 100, metric = 9.23% * 100;
 Minibatch[ 401- 500]: loss = 0.546743 * 100, metric = 8.69% * 100;
 Minibatch[ 501- 600]: loss = 0.556010 * 100, metric = 8.85% * 100;
 Minibatch[ 601- 700]: loss = 0.558795 * 100, metric = 8.97% * 100;
 Minibatch[ 701- 800]: loss = 0.555295 * 100, metric = 8.68% * 100;
 Minibatch[ 801- 900]: loss = 0.546222 * 100, metric = 8.58% * 100;
 Minibatch[ 901-1000]: loss = 0.556776 * 100, metric = 9.11% * 100;
 Minibatch[1001-1100]: loss = 0.537927 * 100, metric = 8.62% * 100;
 Minibatch[1101-1200]: loss = 0.547823 * 100, metric = 8.71% * 100;
 Minibatch[1201-1300]: loss = 0.538578 * 100, metric = 8.31% * 100;
 Minibatch[1301-1400]: loss = 0.546563 * 100, metric = 8.69% * 100;
 Minibatch[1401-1500]: loss = 0.544488 * 100, metric = 8.78% * 100;
 Minibatch[1501-1600]: loss = 0.551392 * 100, metric = 8.99% * 100;
 Minibatch[1601-1700]: loss = 0.545775 * 100, metric = 8.77% * 100;
 Minibatch[1701-1800]: loss = 0.562405 * 100, metric = 8.93% * 100;
 Minibatch[1801-1900]: loss = 0.557504 * 100, metric = 9.28% * 100;
 Minibatch[1901-2000]: loss = 0.536458 * 100, metric = 8.62% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.553502 * 2000, metric = 8.89% * 2000 886.504s (  2.3 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 14.89% * 2000;
0.6269231587797404
 Minibatch[   1- 100]: loss = 0.535625 * 100, metric = 8.45% * 100;
 Minibatch[ 101- 200]: loss = 0.556153 * 100, metric = 8.90% * 100;
 Minibatch[ 201- 300]: loss = 0.555885 * 100, metric = 9.10% * 100;
 Minibatch[ 301- 400]: loss = 0.547700 * 100, metric = 8.75% * 100;
 Minibatch[ 401- 500]: loss = 0.556707 * 100, metric = 8.89% * 100;
 Minibatch[ 501- 600]: loss = 0.539408 * 100, metric = 8.66% * 100;
 Minibatch[ 601- 700]: loss = 0.536909 * 100, metric = 8.51% * 100;
 Minibatch[ 701- 800]: loss = 0.549429 * 100, metric = 8.71% * 100;
 Minibatch[ 801- 900]: loss = 0.548926 * 100, metric = 8.86% * 100;
 Minibatch[ 901-1000]: loss = 0.545529 * 100, metric = 8.53% * 100;
 Minibatch[1001-1100]: loss = 0.532397 * 100, metric = 8.31% * 100;
 Minibatch[1101-1200]: loss = 0.564313 * 100, metric = 9.08% * 100;
 Minibatch[1201-1300]: loss = 0.559438 * 100, metric = 8.70% * 100;
 Minibatch[1301-1400]: loss = 0.534357 * 100, metric = 8.44% * 100;
 Minibatch[1401-1500]: loss = 0.543489 * 100, metric = 8.74% * 100;
 Minibatch[1501-1600]: loss = 0.546202 * 100, metric = 8.67% * 100;
 Minibatch[1601-1700]: loss = 0.558007 * 100, metric = 8.83% * 100;
 Minibatch[1701-1800]: loss = 0.540089 * 100, metric = 8.66% * 100;
 Minibatch[1801-1900]: loss = 0.560747 * 100, metric = 9.11% * 100;
 Minibatch[1901-2000]: loss = 0.561816 * 100, metric = 9.11% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.548656 * 2000, metric = 8.75% * 2000 881.369s (  2.3 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.74% * 2000;
 Minibatch[   1- 100]: loss = 0.531631 * 100, metric = 8.17% * 100;
 Minibatch[ 101- 200]: loss = 0.557042 * 100, metric = 8.86% * 100;
 Minibatch[ 201- 300]: loss = 0.527141 * 100, metric = 8.21% * 100;
 Minibatch[ 301- 400]: loss = 0.542357 * 100, metric = 8.55% * 100;
 Minibatch[ 401- 500]: loss = 0.524750 * 100, metric = 8.33% * 100;
 Minibatch[ 501- 600]: loss = 0.538177 * 100, metric = 8.38% * 100;
 Minibatch[ 601- 700]: loss = 0.538412 * 100, metric = 8.51% * 100;
 Minibatch[ 701- 800]: loss = 0.531742 * 100, metric = 8.44% * 100;
 Minibatch[ 801- 900]: loss = 0.548870 * 100, metric = 8.58% * 100;
 Minibatch[ 901-1000]: loss = 0.550252 * 100, metric = 8.81% * 100;
 Minibatch[1001-1100]: loss = 0.546019 * 100, metric = 8.71% * 100;
 Minibatch[1101-1200]: loss = 0.546270 * 100, metric = 8.76% * 100;
 Minibatch[1201-1300]: loss = 0.552039 * 100, metric = 9.14% * 100;
 Minibatch[1301-1400]: loss = 0.555640 * 100, metric = 9.06% * 100;
 Minibatch[1401-1500]: loss = 0.522946 * 100, metric = 7.86% * 100;
 Minibatch[1501-1600]: loss = 0.536078 * 100, metric = 8.55% * 100;
 Minibatch[1601-1700]: loss = 0.516126 * 100, metric = 8.03% * 100;
 Minibatch[1701-1800]: loss = 0.532690 * 100, metric = 8.30% * 100;
 Minibatch[1801-1900]: loss = 0.519905 * 100, metric = 8.30% * 100;
 Minibatch[1901-2000]: loss = 0.513392 * 100, metric = 7.94% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.536574 * 2000, metric = 8.47% * 2000 896.256s (  2.2 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 14.91% * 2000;
0.624182898811996
 Minibatch[   1- 100]: loss = 0.537216 * 100, metric = 8.64% * 100;
 Minibatch[ 101- 200]: loss = 0.541441 * 100, metric = 8.72% * 100;
 Minibatch[ 201- 300]: loss = 0.513325 * 100, metric = 7.92% * 100;
 Minibatch[ 301- 400]: loss = 0.537563 * 100, metric = 8.46% * 100;
 Minibatch[ 401- 500]: loss = 0.534007 * 100, metric = 8.37% * 100;
 Minibatch[ 501- 600]: loss = 0.528802 * 100, metric = 8.13% * 100;
 Minibatch[ 601- 700]: loss = 0.533535 * 100, metric = 8.36% * 100;
 Minibatch[ 701- 800]: loss = 0.520689 * 100, metric = 8.06% * 100;
 Minibatch[ 801- 900]: loss = 0.554839 * 100, metric = 9.02% * 100;
 Minibatch[ 901-1000]: loss = 0.529499 * 100, metric = 8.26% * 100;
 Minibatch[1001-1100]: loss = 0.538311 * 100, metric = 8.29% * 100;
 Minibatch[1101-1200]: loss = 0.530693 * 100, metric = 8.43% * 100;
 Minibatch[1201-1300]: loss = 0.529193 * 100, metric = 8.35% * 100;
 Minibatch[1301-1400]: loss = 0.522430 * 100, metric = 8.20% * 100;
 Minibatch[1401-1500]: loss = 0.541082 * 100, metric = 8.54% * 100;
 Minibatch[1501-1600]: loss = 0.540371 * 100, metric = 8.60% * 100;
 Minibatch[1601-1700]: loss = 0.523170 * 100, metric = 8.17% * 100;
 Minibatch[1701-1800]: loss = 0.504048 * 100, metric = 7.90% * 100;
 Minibatch[1801-1900]: loss = 0.516106 * 100, metric = 8.02% * 100;
 Minibatch[1901-2000]: loss = 0.512523 * 100, metric = 7.96% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.529442 * 2000, metric = 8.32% * 2000 913.805s (  2.2 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 15.11% * 2000;
 Minibatch[   1- 100]: loss = 0.518381 * 100, metric = 8.05% * 100;
 Minibatch[ 101- 200]: loss = 0.526451 * 100, metric = 8.08% * 100;
 Minibatch[ 201- 300]: loss = 0.528352 * 100, metric = 8.23% * 100;
 Minibatch[ 301- 400]: loss = 0.537127 * 100, metric = 8.32% * 100;
 Minibatch[ 401- 500]: loss = 0.523901 * 100, metric = 8.23% * 100;
 Minibatch[ 501- 600]: loss = 0.526328 * 100, metric = 8.27% * 100;
 Minibatch[ 601- 700]: loss = 0.534975 * 100, metric = 8.58% * 100;
 Minibatch[ 701- 800]: loss = 0.525136 * 100, metric = 8.20% * 100;
 Minibatch[ 801- 900]: loss = 0.537621 * 100, metric = 8.67% * 100;
 Minibatch[ 901-1000]: loss = 0.544737 * 100, metric = 8.55% * 100;
 Minibatch[1001-1100]: loss = 0.510034 * 100, metric = 7.94% * 100;
 Minibatch[1101-1200]: loss = 0.518142 * 100, metric = 7.91% * 100;
 Minibatch[1201-1300]: loss = 0.525665 * 100, metric = 8.20% * 100;
 Minibatch[1301-1400]: loss = 0.516373 * 100, metric = 8.12% * 100;
 Minibatch[1401-1500]: loss = 0.510004 * 100, metric = 8.15% * 100;
 Minibatch[1501-1600]: loss = 0.534150 * 100, metric = 8.45% * 100;
 Minibatch[1601-1700]: loss = 0.526129 * 100, metric = 8.21% * 100;
 Minibatch[1701-1800]: loss = 0.528644 * 100, metric = 8.46% * 100;
 Minibatch[1801-1900]: loss = 0.521923 * 100, metric = 8.20% * 100;
 Minibatch[1901-2000]: loss = 0.519491 * 100, metric = 8.10% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.525678 * 2000, metric = 8.25% * 2000 919.210s (  2.2 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 15.76% * 2000;
 Minibatch[   1- 100]: loss = 0.526757 * 100, metric = 8.25% * 100;
 Minibatch[ 101- 200]: loss = 0.523722 * 100, metric = 8.21% * 100;
 Minibatch[ 201- 300]: loss = 0.521502 * 100, metric = 8.10% * 100;
 Minibatch[ 301- 400]: loss = 0.526315 * 100, metric = 8.35% * 100;
 Minibatch[ 401- 500]: loss = 0.511591 * 100, metric = 8.01% * 100;
 Minibatch[ 501- 600]: loss = 0.509249 * 100, metric = 7.79% * 100;
 Minibatch[ 601- 700]: loss = 0.506420 * 100, metric = 7.90% * 100;
 Minibatch[ 701- 800]: loss = 0.482206 * 100, metric = 7.35% * 100;
 Minibatch[ 801- 900]: loss = 0.519732 * 100, metric = 8.09% * 100;
 Minibatch[ 901-1000]: loss = 0.497378 * 100, metric = 7.68% * 100;
 Minibatch[1001-1100]: loss = 0.508966 * 100, metric = 7.81% * 100;
 Minibatch[1101-1200]: loss = 0.501066 * 100, metric = 7.56% * 100;
 Minibatch[1201-1300]: loss = 0.512291 * 100, metric = 7.80% * 100;
 Minibatch[1301-1400]: loss = 0.500676 * 100, metric = 7.58% * 100;
 Minibatch[1401-1500]: loss = 0.519235 * 100, metric = 7.86% * 100;
 Minibatch[1501-1600]: loss = 0.528049 * 100, metric = 8.45% * 100;
 Minibatch[1601-1700]: loss = 0.503436 * 100, metric = 7.78% * 100;
 Minibatch[1701-1800]: loss = 0.505264 * 100, metric = 7.82% * 100;
 Minibatch[1801-1900]: loss = 0.524326 * 100, metric = 8.27% * 100;
 Minibatch[1901-2000]: loss = 0.487244 * 100, metric = 7.49% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.510771 * 2000, metric = 7.91% * 2000 916.346s (  2.2 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 13.85% * 2000;
0.6075217029303313
 Minibatch[   1- 100]: loss = 0.519862 * 100, metric = 8.15% * 100;
 Minibatch[ 101- 200]: loss = 0.518301 * 100, metric = 8.01% * 100;
 Minibatch[ 201- 300]: loss = 0.525539 * 100, metric = 8.19% * 100;
 Minibatch[ 301- 400]: loss = 0.516707 * 100, metric = 8.33% * 100;
 Minibatch[ 401- 500]: loss = 0.498881 * 100, metric = 7.76% * 100;
 Minibatch[ 501- 600]: loss = 0.520417 * 100, metric = 8.02% * 100;
 Minibatch[ 601- 700]: loss = 0.505450 * 100, metric = 7.61% * 100;
 Minibatch[ 701- 800]: loss = 0.505359 * 100, metric = 7.98% * 100;
 Minibatch[ 801- 900]: loss = 0.521078 * 100, metric = 8.25% * 100;
 Minibatch[ 901-1000]: loss = 0.516849 * 100, metric = 7.98% * 100;
 Minibatch[1001-1100]: loss = 0.490674 * 100, metric = 7.54% * 100;
 Minibatch[1101-1200]: loss = 0.483240 * 100, metric = 7.33% * 100;
 Minibatch[1201-1300]: loss = 0.501027 * 100, metric = 7.73% * 100;
 Minibatch[1301-1400]: loss = 0.507953 * 100, metric = 7.86% * 100;
 Minibatch[1401-1500]: loss = 0.494302 * 100, metric = 7.70% * 100;
 Minibatch[1501-1600]: loss = 0.489382 * 100, metric = 7.50% * 100;
 Minibatch[1601-1700]: loss = 0.492885 * 100, metric = 7.58% * 100;
 Minibatch[1701-1800]: loss = 0.495855 * 100, metric = 7.35% * 100;
 Minibatch[1801-1900]: loss = 0.498967 * 100, metric = 7.78% * 100;
 Minibatch[1901-2000]: loss = 0.495796 * 100, metric = 7.40% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.504926 * 2000, metric = 7.80% * 2000 911.254s (  2.2 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 14.98% * 2000;
 Minibatch[   1- 100]: loss = 0.518130 * 100, metric = 8.00% * 100;
 Minibatch[ 101- 200]: loss = 0.521632 * 100, metric = 8.03% * 100;
 Minibatch[ 201- 300]: loss = 0.507361 * 100, metric = 7.75% * 100;
 Minibatch[ 301- 400]: loss = 0.517615 * 100, metric = 8.10% * 100;
 Minibatch[ 401- 500]: loss = 0.520307 * 100, metric = 8.25% * 100;
 Minibatch[ 501- 600]: loss = 0.513011 * 100, metric = 7.93% * 100;
 Minibatch[ 601- 700]: loss = 0.505024 * 100, metric = 7.85% * 100;
 Minibatch[ 701- 800]: loss = 0.495564 * 100, metric = 7.43% * 100;
 Minibatch[ 801- 900]: loss = 0.485370 * 100, metric = 7.43% * 100;
 Minibatch[ 901-1000]: loss = 0.509930 * 100, metric = 7.84% * 100;
 Minibatch[1001-1100]: loss = 0.489183 * 100, metric = 7.41% * 100;
 Minibatch[1101-1200]: loss = 0.505499 * 100, metric = 7.86% * 100;
 Minibatch[1201-1300]: loss = 0.507696 * 100, metric = 7.89% * 100;
 Minibatch[1301-1400]: loss = 0.511394 * 100, metric = 7.98% * 100;
 Minibatch[1401-1500]: loss = 0.493702 * 100, metric = 7.72% * 100;
 Minibatch[1501-1600]: loss = 0.499507 * 100, metric = 7.67% * 100;
 Minibatch[1601-1700]: loss = 0.499808 * 100, metric = 7.75% * 100;
 Minibatch[1701-1800]: loss = 0.502205 * 100, metric = 7.76% * 100;
 Minibatch[1801-1900]: loss = 0.497409 * 100, metric = 8.08% * 100;
 Minibatch[1901-2000]: loss = 0.514161 * 100, metric = 7.93% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.505725 * 2000, metric = 7.83% * 2000 896.860s (  2.2 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 14.87% * 2000;
 Minibatch[   1- 100]: loss = 0.476891 * 100, metric = 7.37% * 100;
 Minibatch[ 101- 200]: loss = 0.509182 * 100, metric = 7.94% * 100;
 Minibatch[ 201- 300]: loss = 0.489884 * 100, metric = 7.39% * 100;
 Minibatch[ 301- 400]: loss = 0.502854 * 100, metric = 7.81% * 100;
 Minibatch[ 401- 500]: loss = 0.498848 * 100, metric = 7.57% * 100;
 Minibatch[ 501- 600]: loss = 0.489314 * 100, metric = 7.48% * 100;
 Minibatch[ 601- 700]: loss = 0.502413 * 100, metric = 7.54% * 100;
 Minibatch[ 701- 800]: loss = 0.485798 * 100, metric = 7.51% * 100;
 Minibatch[ 801- 900]: loss = 0.512950 * 100, metric = 8.02% * 100;
 Minibatch[ 901-1000]: loss = 0.505240 * 100, metric = 7.91% * 100;
 Minibatch[1001-1100]: loss = 0.505520 * 100, metric = 7.76% * 100;
 Minibatch[1101-1200]: loss = 0.517540 * 100, metric = 8.08% * 100;
 Minibatch[1201-1300]: loss = 0.511805 * 100, metric = 7.89% * 100;
 Minibatch[1301-1400]: loss = 0.501041 * 100, metric = 7.62% * 100;
 Minibatch[1401-1500]: loss = 0.499363 * 100, metric = 7.63% * 100;
 Minibatch[1501-1600]: loss = 0.516196 * 100, metric = 8.08% * 100;
 Minibatch[1601-1700]: loss = 0.494408 * 100, metric = 7.44% * 100;
 Minibatch[1701-1800]: loss = 0.484996 * 100, metric = 7.29% * 100;
 Minibatch[1801-1900]: loss = 0.505690 * 100, metric = 7.84% * 100;
 Minibatch[1901-2000]: loss = 0.508361 * 100, metric = 7.90% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.500915 * 2000, metric = 7.70% * 2000 903.927s (  2.2 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.54% * 2000;
 Minibatch[   1- 100]: loss = 0.502258 * 100, metric = 7.73% * 100;
 Minibatch[ 101- 200]: loss = 0.491506 * 100, metric = 7.69% * 100;
 Minibatch[ 201- 300]: loss = 0.502579 * 100, metric = 7.97% * 100;
 Minibatch[ 301- 400]: loss = 0.501909 * 100, metric = 7.73% * 100;
 Minibatch[ 401- 500]: loss = 0.499423 * 100, metric = 7.72% * 100;
 Minibatch[ 501- 600]: loss = 0.499555 * 100, metric = 7.63% * 100;
 Minibatch[ 601- 700]: loss = 0.498767 * 100, metric = 7.57% * 100;
 Minibatch[ 701- 800]: loss = 0.480716 * 100, metric = 7.16% * 100;
 Minibatch[ 801- 900]: loss = 0.480759 * 100, metric = 7.38% * 100;
 Minibatch[ 901-1000]: loss = 0.491108 * 100, metric = 7.66% * 100;
 Minibatch[1001-1100]: loss = 0.505209 * 100, metric = 7.97% * 100;
 Minibatch[1101-1200]: loss = 0.503265 * 100, metric = 7.86% * 100;
 Minibatch[1201-1300]: loss = 0.515482 * 100, metric = 8.18% * 100;
 Minibatch[1301-1400]: loss = 0.496193 * 100, metric = 7.59% * 100;
 Minibatch[1401-1500]: loss = 0.486336 * 100, metric = 7.27% * 100;
 Minibatch[1501-1600]: loss = 0.508452 * 100, metric = 7.89% * 100;
 Minibatch[1601-1700]: loss = 0.495424 * 100, metric = 7.80% * 100;
 Minibatch[1701-1800]: loss = 0.492176 * 100, metric = 7.59% * 100;
 Minibatch[1801-1900]: loss = 0.476672 * 100, metric = 6.96% * 100;
 Minibatch[1901-2000]: loss = 0.480153 * 100, metric = 7.27% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.495397 * 2000, metric = 7.63% * 2000 896.082s (  2.2 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.97% * 2000;
 Minibatch[   1- 100]: loss = 0.485652 * 100, metric = 7.46% * 100;
 Minibatch[ 101- 200]: loss = 0.474189 * 100, metric = 7.03% * 100;
 Minibatch[ 201- 300]: loss = 0.490474 * 100, metric = 7.47% * 100;
 Minibatch[ 301- 400]: loss = 0.477650 * 100, metric = 7.07% * 100;
 Minibatch[ 401- 500]: loss = 0.481744 * 100, metric = 7.42% * 100;
 Minibatch[ 501- 600]: loss = 0.483646 * 100, metric = 7.25% * 100;
 Minibatch[ 601- 700]: loss = 0.492351 * 100, metric = 7.58% * 100;
 Minibatch[ 701- 800]: loss = 0.473712 * 100, metric = 7.43% * 100;
 Minibatch[ 801- 900]: loss = 0.468112 * 100, metric = 6.95% * 100;
 Minibatch[ 901-1000]: loss = 0.479435 * 100, metric = 7.32% * 100;
 Minibatch[1001-1100]: loss = 0.490289 * 100, metric = 7.65% * 100;
 Minibatch[1101-1200]: loss = 0.499268 * 100, metric = 7.80% * 100;
 Minibatch[1201-1300]: loss = 0.479709 * 100, metric = 7.34% * 100;
 Minibatch[1301-1400]: loss = 0.471978 * 100, metric = 6.98% * 100;
 Minibatch[1401-1500]: loss = 0.489694 * 100, metric = 7.45% * 100;
 Minibatch[1501-1600]: loss = 0.483148 * 100, metric = 7.09% * 100;
 Minibatch[1601-1700]: loss = 0.500244 * 100, metric = 7.69% * 100;
 Minibatch[1701-1800]: loss = 0.496983 * 100, metric = 7.80% * 100;
 Minibatch[1801-1900]: loss = 0.477073 * 100, metric = 7.15% * 100;
 Minibatch[1901-2000]: loss = 0.480889 * 100, metric = 7.04% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.483812 * 2000, metric = 7.35% * 2000 888.012s (  2.3 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.37% * 2000;
 Minibatch[   1- 100]: loss = 0.471078 * 100, metric = 7.07% * 100;
 Minibatch[ 101- 200]: loss = 0.495827 * 100, metric = 7.61% * 100;
 Minibatch[ 201- 300]: loss = 0.471040 * 100, metric = 7.06% * 100;
 Minibatch[ 301- 400]: loss = 0.467741 * 100, metric = 6.98% * 100;
 Minibatch[ 401- 500]: loss = 0.476729 * 100, metric = 7.21% * 100;
 Minibatch[ 501- 600]: loss = 0.468976 * 100, metric = 7.20% * 100;
 Minibatch[ 601- 700]: loss = 0.475706 * 100, metric = 7.11% * 100;
 Minibatch[ 701- 800]: loss = 0.468836 * 100, metric = 7.19% * 100;
 Minibatch[ 801- 900]: loss = 0.483762 * 100, metric = 7.11% * 100;
 Minibatch[ 901-1000]: loss = 0.489872 * 100, metric = 7.60% * 100;
 Minibatch[1001-1100]: loss = 0.472800 * 100, metric = 7.07% * 100;
 Minibatch[1101-1200]: loss = 0.486465 * 100, metric = 7.46% * 100;
 Minibatch[1201-1300]: loss = 0.484936 * 100, metric = 7.24% * 100;
 Minibatch[1301-1400]: loss = 0.489694 * 100, metric = 7.71% * 100;
 Minibatch[1401-1500]: loss = 0.468471 * 100, metric = 7.08% * 100;
 Minibatch[1501-1600]: loss = 0.473397 * 100, metric = 7.04% * 100;
 Minibatch[1601-1700]: loss = 0.459670 * 100, metric = 6.85% * 100;
 Minibatch[1701-1800]: loss = 0.473505 * 100, metric = 6.96% * 100;
 Minibatch[1801-1900]: loss = 0.471791 * 100, metric = 7.08% * 100;
 Minibatch[1901-2000]: loss = 0.476152 * 100, metric = 7.12% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.476322 * 2000, metric = 7.19% * 2000 898.140s (  2.2 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.47% * 2000;
 Minibatch[   1- 100]: loss = 0.487681 * 100, metric = 7.59% * 100;
 Minibatch[ 101- 200]: loss = 0.466125 * 100, metric = 7.10% * 100;
 Minibatch[ 201- 300]: loss = 0.490259 * 100, metric = 7.53% * 100;
 Minibatch[ 301- 400]: loss = 0.483421 * 100, metric = 7.34% * 100;
 Minibatch[ 401- 500]: loss = 0.488701 * 100, metric = 7.53% * 100;
 Minibatch[ 501- 600]: loss = 0.495280 * 100, metric = 7.91% * 100;
 Minibatch[ 601- 700]: loss = 0.472994 * 100, metric = 7.12% * 100;
 Minibatch[ 701- 800]: loss = 0.453767 * 100, metric = 6.71% * 100;
 Minibatch[ 801- 900]: loss = 0.484550 * 100, metric = 7.43% * 100;
 Minibatch[ 901-1000]: loss = 0.487350 * 100, metric = 7.75% * 100;
 Minibatch[1001-1100]: loss = 0.483368 * 100, metric = 7.42% * 100;
 Minibatch[1101-1200]: loss = 0.475026 * 100, metric = 7.12% * 100;
 Minibatch[1201-1300]: loss = 0.473905 * 100, metric = 7.33% * 100;
 Minibatch[1301-1400]: loss = 0.475483 * 100, metric = 7.29% * 100;
 Minibatch[1401-1500]: loss = 0.489111 * 100, metric = 7.40% * 100;
 Minibatch[1501-1600]: loss = 0.473763 * 100, metric = 7.12% * 100;
 Minibatch[1601-1700]: loss = 0.475611 * 100, metric = 7.04% * 100;
 Minibatch[1701-1800]: loss = 0.471385 * 100, metric = 7.16% * 100;
 Minibatch[1801-1900]: loss = 0.475479 * 100, metric = 7.25% * 100;
 Minibatch[1901-2000]: loss = 0.472667 * 100, metric = 7.18% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.478796 * 2000, metric = 7.32% * 2000 893.532s (  2.2 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.42% * 2000;
 Minibatch[   1- 100]: loss = 0.461841 * 100, metric = 6.95% * 100;
 Minibatch[ 101- 200]: loss = 0.465768 * 100, metric = 7.00% * 100;
 Minibatch[ 201- 300]: loss = 0.485060 * 100, metric = 7.29% * 100;
 Minibatch[ 301- 400]: loss = 0.500379 * 100, metric = 7.55% * 100;
 Minibatch[ 401- 500]: loss = 0.471053 * 100, metric = 6.89% * 100;
 Minibatch[ 501- 600]: loss = 0.476658 * 100, metric = 7.31% * 100;
 Minibatch[ 601- 700]: loss = 0.470857 * 100, metric = 7.33% * 100;
 Minibatch[ 701- 800]: loss = 0.482760 * 100, metric = 7.51% * 100;
 Minibatch[ 801- 900]: loss = 0.471679 * 100, metric = 7.17% * 100;
 Minibatch[ 901-1000]: loss = 0.476789 * 100, metric = 7.41% * 100;
 Minibatch[1001-1100]: loss = 0.467591 * 100, metric = 7.18% * 100;
 Minibatch[1101-1200]: loss = 0.460687 * 100, metric = 6.90% * 100;
 Minibatch[1201-1300]: loss = 0.480054 * 100, metric = 7.40% * 100;
 Minibatch[1301-1400]: loss = 0.464806 * 100, metric = 7.12% * 100;
 Minibatch[1401-1500]: loss = 0.487534 * 100, metric = 7.53% * 100;
 Minibatch[1501-1600]: loss = 0.457420 * 100, metric = 6.84% * 100;
 Minibatch[1601-1700]: loss = 0.484964 * 100, metric = 7.51% * 100;
 Minibatch[1701-1800]: loss = 0.471917 * 100, metric = 7.08% * 100;
 Minibatch[1801-1900]: loss = 0.492714 * 100, metric = 7.62% * 100;
 Minibatch[1901-2000]: loss = 0.475039 * 100, metric = 7.27% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.475278 * 2000, metric = 7.24% * 2000 890.475s (  2.2 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 14.79% * 2000;
 Minibatch[   1- 100]: loss = 0.497999 * 100, metric = 7.77% * 100;
 Minibatch[ 101- 200]: loss = 0.451414 * 100, metric = 6.50% * 100;
 Minibatch[ 201- 300]: loss = 0.466429 * 100, metric = 7.00% * 100;
 Minibatch[ 301- 400]: loss = 0.472838 * 100, metric = 7.19% * 100;
 Minibatch[ 401- 500]: loss = 0.474943 * 100, metric = 7.15% * 100;
 Minibatch[ 501- 600]: loss = 0.450297 * 100, metric = 6.48% * 100;
 Minibatch[ 601- 700]: loss = 0.466628 * 100, metric = 7.24% * 100;
 Minibatch[ 701- 800]: loss = 0.463530 * 100, metric = 6.91% * 100;
 Minibatch[ 801- 900]: loss = 0.479752 * 100, metric = 7.05% * 100;
 Minibatch[ 901-1000]: loss = 0.449197 * 100, metric = 6.66% * 100;
 Minibatch[1001-1100]: loss = 0.468659 * 100, metric = 6.93% * 100;
 Minibatch[1101-1200]: loss = 0.483564 * 100, metric = 7.39% * 100;
 Minibatch[1201-1300]: loss = 0.462161 * 100, metric = 6.85% * 100;
 Minibatch[1301-1400]: loss = 0.467572 * 100, metric = 7.08% * 100;
 Minibatch[1401-1500]: loss = 0.463496 * 100, metric = 7.03% * 100;
 Minibatch[1501-1600]: loss = 0.480312 * 100, metric = 7.19% * 100;
 Minibatch[1601-1700]: loss = 0.471198 * 100, metric = 7.05% * 100;
 Minibatch[1701-1800]: loss = 0.476197 * 100, metric = 7.15% * 100;
 Minibatch[1801-1900]: loss = 0.465217 * 100, metric = 7.05% * 100;
 Minibatch[1901-2000]: loss = 0.493177 * 100, metric = 7.63% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.470229 * 2000, metric = 7.07% * 2000 891.663s (  2.2 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 15.14% * 2000;
 Minibatch[   1- 100]: loss = 0.469882 * 100, metric = 6.97% * 100;
 Minibatch[ 101- 200]: loss = 0.473695 * 100, metric = 7.36% * 100;
 Minibatch[ 201- 300]: loss = 0.461742 * 100, metric = 6.83% * 100;
 Minibatch[ 301- 400]: loss = 0.464990 * 100, metric = 7.05% * 100;
 Minibatch[ 401- 500]: loss = 0.461807 * 100, metric = 6.90% * 100;
 Minibatch[ 501- 600]: loss = 0.458292 * 100, metric = 7.09% * 100;
 Minibatch[ 601- 700]: loss = 0.480905 * 100, metric = 7.29% * 100;
 Minibatch[ 701- 800]: loss = 0.476864 * 100, metric = 7.30% * 100;
 Minibatch[ 801- 900]: loss = 0.472864 * 100, metric = 7.31% * 100;
 Minibatch[ 901-1000]: loss = 0.460167 * 100, metric = 6.91% * 100;
 Minibatch[1001-1100]: loss = 0.463624 * 100, metric = 6.96% * 100;
 Minibatch[1101-1200]: loss = 0.463141 * 100, metric = 7.13% * 100;
 Minibatch[1201-1300]: loss = 0.456754 * 100, metric = 6.91% * 100;
 Minibatch[1301-1400]: loss = 0.464207 * 100, metric = 7.06% * 100;
 Minibatch[1401-1500]: loss = 0.468124 * 100, metric = 7.16% * 100;
 Minibatch[1501-1600]: loss = 0.449525 * 100, metric = 6.75% * 100;
 Minibatch[1601-1700]: loss = 0.465536 * 100, metric = 6.81% * 100;
 Minibatch[1701-1800]: loss = 0.455038 * 100, metric = 6.83% * 100;
 Minibatch[1801-1900]: loss = 0.468131 * 100, metric = 7.09% * 100;
 Minibatch[1901-2000]: loss = 0.461858 * 100, metric = 7.10% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.464857 * 2000, metric = 7.04% * 2000 879.006s (  2.3 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 13.97% * 2000;
 Minibatch[   1- 100]: loss = 0.463129 * 100, metric = 6.90% * 100;
 Minibatch[ 101- 200]: loss = 0.467838 * 100, metric = 6.86% * 100;
 Minibatch[ 201- 300]: loss = 0.480674 * 100, metric = 7.18% * 100;
 Minibatch[ 301- 400]: loss = 0.477276 * 100, metric = 7.07% * 100;
 Minibatch[ 401- 500]: loss = 0.468882 * 100, metric = 6.99% * 100;
 Minibatch[ 501- 600]: loss = 0.477585 * 100, metric = 7.29% * 100;
 Minibatch[ 601- 700]: loss = 0.455580 * 100, metric = 6.63% * 100;
 Minibatch[ 701- 800]: loss = 0.454910 * 100, metric = 6.75% * 100;
 Minibatch[ 801- 900]: loss = 0.458581 * 100, metric = 7.02% * 100;
 Minibatch[ 901-1000]: loss = 0.449348 * 100, metric = 6.46% * 100;
 Minibatch[1001-1100]: loss = 0.448505 * 100, metric = 6.60% * 100;
 Minibatch[1101-1200]: loss = 0.468278 * 100, metric = 7.07% * 100;
 Minibatch[1201-1300]: loss = 0.463600 * 100, metric = 7.04% * 100;
 Minibatch[1301-1400]: loss = 0.468603 * 100, metric = 7.17% * 100;
 Minibatch[1401-1500]: loss = 0.466993 * 100, metric = 7.24% * 100;
 Minibatch[1501-1600]: loss = 0.468829 * 100, metric = 7.15% * 100;
 Minibatch[1601-1700]: loss = 0.450242 * 100, metric = 6.71% * 100;
 Minibatch[1701-1800]: loss = 0.476160 * 100, metric = 7.23% * 100;
 Minibatch[1801-1900]: loss = 0.458204 * 100, metric = 6.74% * 100;
 Minibatch[1901-2000]: loss = 0.473433 * 100, metric = 7.43% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.464832 * 2000, metric = 6.98% * 2000 872.486s (  2.3 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 14.30% * 2000;
 Minibatch[   1- 100]: loss = 0.475237 * 100, metric = 7.36% * 100;
 Minibatch[ 101- 200]: loss = 0.460413 * 100, metric = 6.94% * 100;
 Minibatch[ 201- 300]: loss = 0.452719 * 100, metric = 6.77% * 100;
 Minibatch[ 301- 400]: loss = 0.457345 * 100, metric = 7.00% * 100;
 Minibatch[ 401- 500]: loss = 0.451150 * 100, metric = 6.89% * 100;
 Minibatch[ 501- 600]: loss = 0.456279 * 100, metric = 6.94% * 100;
 Minibatch[ 601- 700]: loss = 0.463548 * 100, metric = 6.96% * 100;
 Minibatch[ 701- 800]: loss = 0.464379 * 100, metric = 7.09% * 100;
 Minibatch[ 801- 900]: loss = 0.460912 * 100, metric = 6.82% * 100;
 Minibatch[ 901-1000]: loss = 0.445983 * 100, metric = 6.61% * 100;
 Minibatch[1001-1100]: loss = 0.455434 * 100, metric = 6.98% * 100;
 Minibatch[1101-1200]: loss = 0.443784 * 100, metric = 6.62% * 100;
 Minibatch[1201-1300]: loss = 0.467744 * 100, metric = 7.01% * 100;
 Minibatch[1301-1400]: loss = 0.444734 * 100, metric = 6.60% * 100;
 Minibatch[1401-1500]: loss = 0.472951 * 100, metric = 7.25% * 100;
 Minibatch[1501-1600]: loss = 0.471797 * 100, metric = 7.12% * 100;
 Minibatch[1601-1700]: loss = 0.464281 * 100, metric = 6.74% * 100;
 Minibatch[1701-1800]: loss = 0.458267 * 100, metric = 6.88% * 100;
 Minibatch[1801-1900]: loss = 0.465226 * 100, metric = 6.92% * 100;
 Minibatch[1901-2000]: loss = 0.470189 * 100, metric = 7.21% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.460119 * 2000, metric = 6.94% * 2000 873.043s (  2.3 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.51% * 2000;
 Minibatch[   1- 100]: loss = 0.454431 * 100, metric = 6.80% * 100;
 Minibatch[ 101- 200]: loss = 0.458607 * 100, metric = 6.83% * 100;
 Minibatch[ 201- 300]: loss = 0.452370 * 100, metric = 6.78% * 100;
 Minibatch[ 301- 400]: loss = 0.465061 * 100, metric = 6.95% * 100;
 Minibatch[ 401- 500]: loss = 0.446962 * 100, metric = 6.62% * 100;
 Minibatch[ 501- 600]: loss = 0.459286 * 100, metric = 6.87% * 100;
 Minibatch[ 601- 700]: loss = 0.466322 * 100, metric = 7.11% * 100;
 Minibatch[ 701- 800]: loss = 0.457666 * 100, metric = 6.80% * 100;
 Minibatch[ 801- 900]: loss = 0.446096 * 100, metric = 6.38% * 100;
 Minibatch[ 901-1000]: loss = 0.451917 * 100, metric = 6.92% * 100;
 Minibatch[1001-1100]: loss = 0.457341 * 100, metric = 6.97% * 100;
 Minibatch[1101-1200]: loss = 0.454319 * 100, metric = 7.03% * 100;
 Minibatch[1201-1300]: loss = 0.453129 * 100, metric = 6.78% * 100;
 Minibatch[1301-1400]: loss = 0.453452 * 100, metric = 6.79% * 100;
 Minibatch[1401-1500]: loss = 0.466129 * 100, metric = 7.18% * 100;
 Minibatch[1501-1600]: loss = 0.463909 * 100, metric = 6.86% * 100;
 Minibatch[1601-1700]: loss = 0.471769 * 100, metric = 7.37% * 100;
 Minibatch[1701-1800]: loss = 0.455562 * 100, metric = 6.94% * 100;
 Minibatch[1801-1900]: loss = 0.454867 * 100, metric = 6.80% * 100;
 Minibatch[1901-2000]: loss = 0.469013 * 100, metric = 6.74% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.457910 * 2000, metric = 6.88% * 2000 875.483s (  2.3 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.59% * 2000;
 Minibatch[   1- 100]: loss = 0.431111 * 100, metric = 6.48% * 100;
 Minibatch[ 101- 200]: loss = 0.444262 * 100, metric = 6.85% * 100;
 Minibatch[ 201- 300]: loss = 0.456980 * 100, metric = 6.74% * 100;
 Minibatch[ 301- 400]: loss = 0.444429 * 100, metric = 6.70% * 100;
 Minibatch[ 401- 500]: loss = 0.452793 * 100, metric = 6.78% * 100;
 Minibatch[ 501- 600]: loss = 0.431622 * 100, metric = 6.26% * 100;
 Minibatch[ 601- 700]: loss = 0.466143 * 100, metric = 7.00% * 100;
 Minibatch[ 701- 800]: loss = 0.439547 * 100, metric = 6.53% * 100;
 Minibatch[ 801- 900]: loss = 0.455269 * 100, metric = 6.89% * 100;
 Minibatch[ 901-1000]: loss = 0.436552 * 100, metric = 6.50% * 100;
 Minibatch[1001-1100]: loss = 0.461015 * 100, metric = 7.21% * 100;
 Minibatch[1101-1200]: loss = 0.448435 * 100, metric = 6.60% * 100;
 Minibatch[1201-1300]: loss = 0.451942 * 100, metric = 6.74% * 100;
 Minibatch[1301-1400]: loss = 0.451780 * 100, metric = 6.81% * 100;
 Minibatch[1401-1500]: loss = 0.442526 * 100, metric = 6.54% * 100;
 Minibatch[1501-1600]: loss = 0.455464 * 100, metric = 6.88% * 100;
 Minibatch[1601-1700]: loss = 0.449468 * 100, metric = 6.68% * 100;
 Minibatch[1701-1800]: loss = 0.436002 * 100, metric = 6.41% * 100;
 Minibatch[1801-1900]: loss = 0.453420 * 100, metric = 6.74% * 100;
 Minibatch[1901-2000]: loss = 0.438140 * 100, metric = 6.55% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.447345 * 2000, metric = 6.69% * 2000 873.503s (  2.3 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.33% * 2000;
 Minibatch[   1- 100]: loss = 0.441877 * 100, metric = 6.30% * 100;
 Minibatch[ 101- 200]: loss = 0.429310 * 100, metric = 6.28% * 100;
 Minibatch[ 201- 300]: loss = 0.462641 * 100, metric = 7.16% * 100;
 Minibatch[ 301- 400]: loss = 0.436633 * 100, metric = 6.51% * 100;
 Minibatch[ 401- 500]: loss = 0.437107 * 100, metric = 6.61% * 100;
 Minibatch[ 501- 600]: loss = 0.445442 * 100, metric = 6.60% * 100;
 Minibatch[ 601- 700]: loss = 0.443948 * 100, metric = 6.55% * 100;
 Minibatch[ 701- 800]: loss = 0.431153 * 100, metric = 6.37% * 100;
 Minibatch[ 801- 900]: loss = 0.434926 * 100, metric = 6.38% * 100;
 Minibatch[ 901-1000]: loss = 0.460863 * 100, metric = 6.88% * 100;
 Minibatch[1001-1100]: loss = 0.459900 * 100, metric = 7.11% * 100;
 Minibatch[1101-1200]: loss = 0.442917 * 100, metric = 6.66% * 100;
 Minibatch[1201-1300]: loss = 0.451014 * 100, metric = 6.75% * 100;
 Minibatch[1301-1400]: loss = 0.425527 * 100, metric = 6.15% * 100;
 Minibatch[1401-1500]: loss = 0.437946 * 100, metric = 6.47% * 100;
 Minibatch[1501-1600]: loss = 0.443629 * 100, metric = 6.58% * 100;
 Minibatch[1601-1700]: loss = 0.447482 * 100, metric = 6.88% * 100;
 Minibatch[1701-1800]: loss = 0.454471 * 100, metric = 6.83% * 100;
 Minibatch[1801-1900]: loss = 0.440027 * 100, metric = 6.44% * 100;
 Minibatch[1901-2000]: loss = 0.443438 * 100, metric = 6.73% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.443513 * 2000, metric = 6.61% * 2000 870.402s (  2.3 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.24% * 2000;
 Minibatch[   1- 100]: loss = 0.445876 * 100, metric = 6.82% * 100;
 Minibatch[ 101- 200]: loss = 0.445620 * 100, metric = 6.85% * 100;
 Minibatch[ 201- 300]: loss = 0.444154 * 100, metric = 6.76% * 100;
 Minibatch[ 301- 400]: loss = 0.445931 * 100, metric = 6.60% * 100;
 Minibatch[ 401- 500]: loss = 0.441656 * 100, metric = 6.67% * 100;
 Minibatch[ 501- 600]: loss = 0.432045 * 100, metric = 6.59% * 100;
 Minibatch[ 601- 700]: loss = 0.446780 * 100, metric = 6.66% * 100;
 Minibatch[ 701- 800]: loss = 0.455074 * 100, metric = 7.00% * 100;
 Minibatch[ 801- 900]: loss = 0.447031 * 100, metric = 6.74% * 100;
 Minibatch[ 901-1000]: loss = 0.432361 * 100, metric = 6.15% * 100;
 Minibatch[1001-1100]: loss = 0.436935 * 100, metric = 6.56% * 100;
 Minibatch[1101-1200]: loss = 0.452514 * 100, metric = 6.95% * 100;
 Minibatch[1201-1300]: loss = 0.452285 * 100, metric = 6.78% * 100;
 Minibatch[1301-1400]: loss = 0.442991 * 100, metric = 6.46% * 100;
 Minibatch[1401-1500]: loss = 0.454374 * 100, metric = 6.83% * 100;
 Minibatch[1501-1600]: loss = 0.440812 * 100, metric = 6.54% * 100;
 Minibatch[1601-1700]: loss = 0.440085 * 100, metric = 6.81% * 100;
 Minibatch[1701-1800]: loss = 0.438179 * 100, metric = 6.48% * 100;
 Minibatch[1801-1900]: loss = 0.449260 * 100, metric = 6.94% * 100;
 Minibatch[1901-2000]: loss = 0.452604 * 100, metric = 6.92% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.444828 * 2000, metric = 6.70% * 2000 857.850s (  2.3 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.55% * 2000;
 Minibatch[   1- 100]: loss = 0.451250 * 100, metric = 6.93% * 100;
 Minibatch[ 101- 200]: loss = 0.449473 * 100, metric = 6.77% * 100;
 Minibatch[ 201- 300]: loss = 0.427529 * 100, metric = 6.13% * 100;
 Minibatch[ 301- 400]: loss = 0.429659 * 100, metric = 6.18% * 100;
 Minibatch[ 401- 500]: loss = 0.441779 * 100, metric = 6.64% * 100;
 Minibatch[ 501- 600]: loss = 0.432528 * 100, metric = 6.28% * 100;
 Minibatch[ 601- 700]: loss = 0.445344 * 100, metric = 6.72% * 100;
 Minibatch[ 701- 800]: loss = 0.443105 * 100, metric = 6.67% * 100;
 Minibatch[ 801- 900]: loss = 0.448434 * 100, metric = 6.76% * 100;
 Minibatch[ 901-1000]: loss = 0.442577 * 100, metric = 6.51% * 100;
 Minibatch[1001-1100]: loss = 0.449384 * 100, metric = 6.68% * 100;
 Minibatch[1101-1200]: loss = 0.433077 * 100, metric = 6.30% * 100;
 Minibatch[1201-1300]: loss = 0.433576 * 100, metric = 6.53% * 100;
 Minibatch[1301-1400]: loss = 0.455112 * 100, metric = 6.69% * 100;
 Minibatch[1401-1500]: loss = 0.445501 * 100, metric = 6.71% * 100;
 Minibatch[1501-1600]: loss = 0.453541 * 100, metric = 6.76% * 100;
 Minibatch[1601-1700]: loss = 0.432479 * 100, metric = 6.35% * 100;
 Minibatch[1701-1800]: loss = 0.436538 * 100, metric = 6.60% * 100;
 Minibatch[1801-1900]: loss = 0.441116 * 100, metric = 6.56% * 100;
 Minibatch[1901-2000]: loss = 0.439363 * 100, metric = 6.64% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.441568 * 2000, metric = 6.57% * 2000 865.738s (  2.3 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 13.64% * 2000;
 Minibatch[   1- 100]: loss = 0.427350 * 100, metric = 6.46% * 100;
 Minibatch[ 101- 200]: loss = 0.449457 * 100, metric = 6.63% * 100;
 Minibatch[ 201- 300]: loss = 0.433976 * 100, metric = 6.13% * 100;
 Minibatch[ 301- 400]: loss = 0.431130 * 100, metric = 6.28% * 100;
 Minibatch[ 401- 500]: loss = 0.437379 * 100, metric = 6.57% * 100;
 Minibatch[ 501- 600]: loss = 0.440348 * 100, metric = 6.54% * 100;
 Minibatch[ 601- 700]: loss = 0.441197 * 100, metric = 6.57% * 100;
 Minibatch[ 701- 800]: loss = 0.451124 * 100, metric = 6.71% * 100;
 Minibatch[ 801- 900]: loss = 0.424163 * 100, metric = 6.17% * 100;
 Minibatch[ 901-1000]: loss = 0.427768 * 100, metric = 6.31% * 100;
 Minibatch[1001-1100]: loss = 0.437313 * 100, metric = 6.74% * 100;
 Minibatch[1101-1200]: loss = 0.439450 * 100, metric = 6.86% * 100;
 Minibatch[1201-1300]: loss = 0.438794 * 100, metric = 6.39% * 100;
 Minibatch[1301-1400]: loss = 0.442487 * 100, metric = 6.51% * 100;
 Minibatch[1401-1500]: loss = 0.441910 * 100, metric = 6.60% * 100;
 Minibatch[1501-1600]: loss = 0.428120 * 100, metric = 6.35% * 100;
 Minibatch[1601-1700]: loss = 0.439471 * 100, metric = 6.50% * 100;
 Minibatch[1701-1800]: loss = 0.439510 * 100, metric = 6.63% * 100;
 Minibatch[1801-1900]: loss = 0.429800 * 100, metric = 6.44% * 100;
 Minibatch[1901-2000]: loss = 0.428767 * 100, metric = 6.39% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.436476 * 2000, metric = 6.49% * 2000 865.615s (  2.3 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.84% * 2000;
 Minibatch[   1- 100]: loss = 0.428325 * 100, metric = 6.57% * 100;
 Minibatch[ 101- 200]: loss = 0.417436 * 100, metric = 6.16% * 100;
 Minibatch[ 201- 300]: loss = 0.439225 * 100, metric = 6.33% * 100;
 Minibatch[ 301- 400]: loss = 0.434696 * 100, metric = 6.72% * 100;
 Minibatch[ 401- 500]: loss = 0.440438 * 100, metric = 6.54% * 100;
 Minibatch[ 501- 600]: loss = 0.429259 * 100, metric = 6.54% * 100;
 Minibatch[ 601- 700]: loss = 0.451679 * 100, metric = 6.77% * 100;
 Minibatch[ 701- 800]: loss = 0.432065 * 100, metric = 6.24% * 100;
 Minibatch[ 801- 900]: loss = 0.427756 * 100, metric = 6.22% * 100;
 Minibatch[ 901-1000]: loss = 0.436373 * 100, metric = 6.48% * 100;
 Minibatch[1001-1100]: loss = 0.446460 * 100, metric = 6.84% * 100;
 Minibatch[1101-1200]: loss = 0.441491 * 100, metric = 6.74% * 100;
 Minibatch[1201-1300]: loss = 0.432700 * 100, metric = 6.46% * 100;
 Minibatch[1301-1400]: loss = 0.437493 * 100, metric = 6.53% * 100;
 Minibatch[1401-1500]: loss = 0.430287 * 100, metric = 6.19% * 100;
 Minibatch[1501-1600]: loss = 0.445153 * 100, metric = 6.61% * 100;
 Minibatch[1601-1700]: loss = 0.438609 * 100, metric = 6.61% * 100;
 Minibatch[1701-1800]: loss = 0.425256 * 100, metric = 6.49% * 100;
 Minibatch[1801-1900]: loss = 0.430277 * 100, metric = 6.19% * 100;
 Minibatch[1901-2000]: loss = 0.438459 * 100, metric = 6.69% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.435172 * 2000, metric = 6.50% * 2000 858.743s (  2.3 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 13.92% * 2000;
 Minibatch[   1- 100]: loss = 0.429318 * 100, metric = 6.56% * 100;
 Minibatch[ 101- 200]: loss = 0.439011 * 100, metric = 6.40% * 100;
 Minibatch[ 201- 300]: loss = 0.443129 * 100, metric = 6.74% * 100;
 Minibatch[ 301- 400]: loss = 0.448087 * 100, metric = 6.76% * 100;
 Minibatch[ 401- 500]: loss = 0.442793 * 100, metric = 6.52% * 100;
 Minibatch[ 501- 600]: loss = 0.437778 * 100, metric = 6.31% * 100;
 Minibatch[ 601- 700]: loss = 0.442255 * 100, metric = 6.51% * 100;
 Minibatch[ 701- 800]: loss = 0.434891 * 100, metric = 6.58% * 100;
 Minibatch[ 801- 900]: loss = 0.434655 * 100, metric = 6.56% * 100;
 Minibatch[ 901-1000]: loss = 0.434948 * 100, metric = 6.62% * 100;
 Minibatch[1001-1100]: loss = 0.441855 * 100, metric = 6.39% * 100;
 Minibatch[1101-1200]: loss = 0.456206 * 100, metric = 6.87% * 100;
 Minibatch[1201-1300]: loss = 0.437876 * 100, metric = 6.55% * 100;
 Minibatch[1301-1400]: loss = 0.426298 * 100, metric = 6.41% * 100;
 Minibatch[1401-1500]: loss = 0.423278 * 100, metric = 6.17% * 100;
 Minibatch[1501-1600]: loss = 0.437911 * 100, metric = 6.49% * 100;
 Minibatch[1601-1700]: loss = 0.438171 * 100, metric = 6.46% * 100;
 Minibatch[1701-1800]: loss = 0.431674 * 100, metric = 6.71% * 100;
 Minibatch[1801-1900]: loss = 0.438090 * 100, metric = 6.50% * 100;
 Minibatch[1901-2000]: loss = 0.429855 * 100, metric = 6.34% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.437404 * 2000, metric = 6.52% * 2000 864.253s (  2.3 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 14.35% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
