Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.361551 * 100, metric = 25.11% * 100;
 Minibatch[ 101- 200]: loss = 1.173551 * 100, metric = 23.54% * 100;
 Minibatch[ 201- 300]: loss = 1.074894 * 100, metric = 22.88% * 100;
 Minibatch[ 301- 400]: loss = 1.067780 * 100, metric = 21.86% * 100;
 Minibatch[ 401- 500]: loss = 1.005528 * 100, metric = 20.74% * 100;
 Minibatch[ 501- 600]: loss = 0.970959 * 100, metric = 19.46% * 100;
 Minibatch[ 601- 700]: loss = 0.950359 * 100, metric = 18.92% * 100;
 Minibatch[ 701- 800]: loss = 0.920316 * 100, metric = 17.87% * 100;
 Minibatch[ 801- 900]: loss = 0.924069 * 100, metric = 18.14% * 100;
 Minibatch[ 901-1000]: loss = 0.938247 * 100, metric = 18.51% * 100;
 Minibatch[1001-1100]: loss = 0.918276 * 100, metric = 17.97% * 100;
 Minibatch[1101-1200]: loss = 0.912013 * 100, metric = 17.21% * 100;
 Minibatch[1201-1300]: loss = 0.907073 * 100, metric = 17.78% * 100;
 Minibatch[1301-1400]: loss = 0.875999 * 100, metric = 16.67% * 100;
 Minibatch[1401-1500]: loss = 0.904575 * 100, metric = 17.32% * 100;
 Minibatch[1501-1600]: loss = 0.862169 * 100, metric = 16.29% * 100;
 Minibatch[1601-1700]: loss = 0.851752 * 100, metric = 16.39% * 100;
 Minibatch[1701-1800]: loss = 0.863208 * 100, metric = 16.29% * 100;
 Minibatch[1801-1900]: loss = 0.863833 * 100, metric = 16.58% * 100;
 Minibatch[1901-2000]: loss = 0.847546 * 100, metric = 15.58% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.959685 * 2000, metric = 18.75% * 2000 963.783s (  2.1 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 24.08% * 2000;
0.8622284389063716
 Minibatch[   1- 100]: loss = 0.851869 * 100, metric = 15.61% * 100;
 Minibatch[ 101- 200]: loss = 0.850386 * 100, metric = 16.04% * 100;
 Minibatch[ 201- 300]: loss = 0.840761 * 100, metric = 15.22% * 100;
 Minibatch[ 301- 400]: loss = 0.850830 * 100, metric = 15.43% * 100;
 Minibatch[ 401- 500]: loss = 0.838450 * 100, metric = 15.51% * 100;
 Minibatch[ 501- 600]: loss = 0.852375 * 100, metric = 15.25% * 100;
 Minibatch[ 601- 700]: loss = 0.805404 * 100, metric = 14.55% * 100;
 Minibatch[ 701- 800]: loss = 0.838452 * 100, metric = 15.67% * 100;
 Minibatch[ 801- 900]: loss = 0.823332 * 100, metric = 15.35% * 100;
 Minibatch[ 901-1000]: loss = 0.797363 * 100, metric = 14.40% * 100;
 Minibatch[1001-1100]: loss = 0.813820 * 100, metric = 14.72% * 100;
 Minibatch[1101-1200]: loss = 0.812263 * 100, metric = 14.55% * 100;
 Minibatch[1201-1300]: loss = 0.811005 * 100, metric = 15.02% * 100;
 Minibatch[1301-1400]: loss = 0.818151 * 100, metric = 14.85% * 100;
 Minibatch[1401-1500]: loss = 0.791823 * 100, metric = 14.37% * 100;
 Minibatch[1501-1600]: loss = 0.786663 * 100, metric = 14.07% * 100;
 Minibatch[1601-1700]: loss = 0.807096 * 100, metric = 14.85% * 100;
 Minibatch[1701-1800]: loss = 0.797765 * 100, metric = 14.67% * 100;
 Minibatch[1801-1900]: loss = 0.813512 * 100, metric = 14.82% * 100;
 Minibatch[1901-2000]: loss = 0.763298 * 100, metric = 13.86% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.818231 * 2000, metric = 14.94% * 2000 915.861s (  2.2 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 22.14% * 2000;
0.811329777829349
 Minibatch[   1- 100]: loss = 0.793347 * 100, metric = 14.31% * 100;
 Minibatch[ 101- 200]: loss = 0.796746 * 100, metric = 14.73% * 100;
 Minibatch[ 201- 300]: loss = 0.776174 * 100, metric = 13.99% * 100;
 Minibatch[ 301- 400]: loss = 0.800559 * 100, metric = 14.71% * 100;
 Minibatch[ 401- 500]: loss = 0.803602 * 100, metric = 14.97% * 100;
 Minibatch[ 501- 600]: loss = 0.795421 * 100, metric = 14.36% * 100;
 Minibatch[ 601- 700]: loss = 0.799327 * 100, metric = 14.31% * 100;
 Minibatch[ 701- 800]: loss = 0.769601 * 100, metric = 13.22% * 100;
 Minibatch[ 801- 900]: loss = 0.791468 * 100, metric = 14.28% * 100;
 Minibatch[ 901-1000]: loss = 0.762516 * 100, metric = 13.93% * 100;
 Minibatch[1001-1100]: loss = 0.785983 * 100, metric = 14.41% * 100;
 Minibatch[1101-1200]: loss = 0.771615 * 100, metric = 13.67% * 100;
 Minibatch[1201-1300]: loss = 0.761402 * 100, metric = 13.89% * 100;
 Minibatch[1301-1400]: loss = 0.780723 * 100, metric = 14.18% * 100;
 Minibatch[1401-1500]: loss = 0.779065 * 100, metric = 14.08% * 100;
 Minibatch[1501-1600]: loss = 0.757217 * 100, metric = 13.46% * 100;
 Minibatch[1601-1700]: loss = 0.735392 * 100, metric = 13.18% * 100;
 Minibatch[1701-1800]: loss = 0.766108 * 100, metric = 13.88% * 100;
 Minibatch[1801-1900]: loss = 0.761102 * 100, metric = 13.37% * 100;
 Minibatch[1901-2000]: loss = 0.748325 * 100, metric = 13.50% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.776785 * 2000, metric = 14.02% * 2000 913.869s (  2.2 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 20.45% * 2000;
0.786140770226717
 Minibatch[   1- 100]: loss = 0.785703 * 100, metric = 13.65% * 100;
 Minibatch[ 101- 200]: loss = 0.739110 * 100, metric = 13.24% * 100;
 Minibatch[ 201- 300]: loss = 0.761698 * 100, metric = 13.49% * 100;
 Minibatch[ 301- 400]: loss = 0.726897 * 100, metric = 12.84% * 100;
 Minibatch[ 401- 500]: loss = 0.755562 * 100, metric = 13.38% * 100;
 Minibatch[ 501- 600]: loss = 0.734108 * 100, metric = 12.92% * 100;
 Minibatch[ 601- 700]: loss = 0.746130 * 100, metric = 13.35% * 100;
 Minibatch[ 701- 800]: loss = 0.753720 * 100, metric = 13.27% * 100;
 Minibatch[ 801- 900]: loss = 0.754740 * 100, metric = 13.96% * 100;
 Minibatch[ 901-1000]: loss = 0.745822 * 100, metric = 13.30% * 100;
 Minibatch[1001-1100]: loss = 0.750192 * 100, metric = 13.32% * 100;
 Minibatch[1101-1200]: loss = 0.726594 * 100, metric = 12.81% * 100;
 Minibatch[1201-1300]: loss = 0.730228 * 100, metric = 13.00% * 100;
 Minibatch[1301-1400]: loss = 0.757264 * 100, metric = 13.60% * 100;
 Minibatch[1401-1500]: loss = 0.751444 * 100, metric = 13.52% * 100;
 Minibatch[1501-1600]: loss = 0.717645 * 100, metric = 12.74% * 100;
 Minibatch[1601-1700]: loss = 0.751763 * 100, metric = 13.51% * 100;
 Minibatch[1701-1800]: loss = 0.741827 * 100, metric = 13.27% * 100;
 Minibatch[1801-1900]: loss = 0.729327 * 100, metric = 12.84% * 100;
 Minibatch[1901-2000]: loss = 0.714023 * 100, metric = 12.55% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.743690 * 2000, metric = 13.23% * 2000 915.410s (  2.2 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 22.33% * 2000;
 Minibatch[   1- 100]: loss = 0.750167 * 100, metric = 13.37% * 100;
 Minibatch[ 101- 200]: loss = 0.729276 * 100, metric = 12.72% * 100;
 Minibatch[ 201- 300]: loss = 0.714025 * 100, metric = 12.56% * 100;
 Minibatch[ 301- 400]: loss = 0.756808 * 100, metric = 13.98% * 100;
 Minibatch[ 401- 500]: loss = 0.710226 * 100, metric = 12.48% * 100;
 Minibatch[ 501- 600]: loss = 0.706948 * 100, metric = 11.97% * 100;
 Minibatch[ 601- 700]: loss = 0.717071 * 100, metric = 12.13% * 100;
 Minibatch[ 701- 800]: loss = 0.729746 * 100, metric = 12.87% * 100;
 Minibatch[ 801- 900]: loss = 0.712028 * 100, metric = 12.14% * 100;
 Minibatch[ 901-1000]: loss = 0.713811 * 100, metric = 12.75% * 100;
 Minibatch[1001-1100]: loss = 0.724160 * 100, metric = 12.58% * 100;
 Minibatch[1101-1200]: loss = 0.704641 * 100, metric = 12.08% * 100;
 Minibatch[1201-1300]: loss = 0.724060 * 100, metric = 12.63% * 100;
 Minibatch[1301-1400]: loss = 0.741867 * 100, metric = 13.34% * 100;
 Minibatch[1401-1500]: loss = 0.714899 * 100, metric = 12.76% * 100;
 Minibatch[1501-1600]: loss = 0.725328 * 100, metric = 12.84% * 100;
 Minibatch[1601-1700]: loss = 0.726467 * 100, metric = 13.26% * 100;
 Minibatch[1701-1800]: loss = 0.728588 * 100, metric = 13.01% * 100;
 Minibatch[1801-1900]: loss = 0.729081 * 100, metric = 12.85% * 100;
 Minibatch[1901-2000]: loss = 0.706864 * 100, metric = 12.08% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.723303 * 2000, metric = 12.72% * 2000 918.051s (  2.2 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 19.63% * 2000;
0.7520069382339716
 Minibatch[   1- 100]: loss = 0.716407 * 100, metric = 12.77% * 100;
 Minibatch[ 101- 200]: loss = 0.703237 * 100, metric = 12.54% * 100;
 Minibatch[ 201- 300]: loss = 0.712665 * 100, metric = 12.29% * 100;
 Minibatch[ 301- 400]: loss = 0.713018 * 100, metric = 12.02% * 100;
 Minibatch[ 401- 500]: loss = 0.691882 * 100, metric = 11.82% * 100;
 Minibatch[ 501- 600]: loss = 0.713796 * 100, metric = 12.51% * 100;
 Minibatch[ 601- 700]: loss = 0.705022 * 100, metric = 12.54% * 100;
 Minibatch[ 701- 800]: loss = 0.713374 * 100, metric = 12.48% * 100;
 Minibatch[ 801- 900]: loss = 0.709736 * 100, metric = 12.53% * 100;
 Minibatch[ 901-1000]: loss = 0.694113 * 100, metric = 12.46% * 100;
 Minibatch[1001-1100]: loss = 0.701749 * 100, metric = 11.85% * 100;
 Minibatch[1101-1200]: loss = 0.711775 * 100, metric = 12.42% * 100;
 Minibatch[1201-1300]: loss = 0.726920 * 100, metric = 12.95% * 100;
 Minibatch[1301-1400]: loss = 0.694091 * 100, metric = 12.09% * 100;
 Minibatch[1401-1500]: loss = 0.700733 * 100, metric = 12.42% * 100;
 Minibatch[1501-1600]: loss = 0.688193 * 100, metric = 11.86% * 100;
 Minibatch[1601-1700]: loss = 0.693044 * 100, metric = 11.86% * 100;
 Minibatch[1701-1800]: loss = 0.678944 * 100, metric = 11.85% * 100;
 Minibatch[1801-1900]: loss = 0.701495 * 100, metric = 12.40% * 100;
 Minibatch[1901-2000]: loss = 0.688557 * 100, metric = 11.87% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.702938 * 2000, metric = 12.28% * 2000 917.934s (  2.2 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.16% * 2000;
 Minibatch[   1- 100]: loss = 0.680073 * 100, metric = 11.53% * 100;
 Minibatch[ 101- 200]: loss = 0.699917 * 100, metric = 11.96% * 100;
 Minibatch[ 201- 300]: loss = 0.699872 * 100, metric = 12.25% * 100;
 Minibatch[ 301- 400]: loss = 0.686066 * 100, metric = 11.85% * 100;
 Minibatch[ 401- 500]: loss = 0.697578 * 100, metric = 11.89% * 100;
 Minibatch[ 501- 600]: loss = 0.675238 * 100, metric = 11.60% * 100;
 Minibatch[ 601- 700]: loss = 0.690933 * 100, metric = 11.60% * 100;
 Minibatch[ 701- 800]: loss = 0.700121 * 100, metric = 11.91% * 100;
 Minibatch[ 801- 900]: loss = 0.702402 * 100, metric = 12.37% * 100;
 Minibatch[ 901-1000]: loss = 0.692186 * 100, metric = 11.85% * 100;
 Minibatch[1001-1100]: loss = 0.692797 * 100, metric = 12.05% * 100;
 Minibatch[1101-1200]: loss = 0.682842 * 100, metric = 11.72% * 100;
 Minibatch[1201-1300]: loss = 0.689095 * 100, metric = 11.92% * 100;
 Minibatch[1301-1400]: loss = 0.676208 * 100, metric = 11.48% * 100;
 Minibatch[1401-1500]: loss = 0.678810 * 100, metric = 11.58% * 100;
 Minibatch[1501-1600]: loss = 0.688948 * 100, metric = 11.93% * 100;
 Minibatch[1601-1700]: loss = 0.689453 * 100, metric = 11.94% * 100;
 Minibatch[1701-1800]: loss = 0.680044 * 100, metric = 11.72% * 100;
 Minibatch[1801-1900]: loss = 0.681641 * 100, metric = 11.80% * 100;
 Minibatch[1901-2000]: loss = 0.690808 * 100, metric = 11.96% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.688752 * 2000, metric = 11.85% * 2000 911.851s (  2.2 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 17.98% * 2000;
0.7074986397475004
 Minibatch[   1- 100]: loss = 0.689005 * 100, metric = 11.73% * 100;
 Minibatch[ 101- 200]: loss = 0.667767 * 100, metric = 11.42% * 100;
 Minibatch[ 201- 300]: loss = 0.661650 * 100, metric = 11.42% * 100;
 Minibatch[ 301- 400]: loss = 0.672014 * 100, metric = 11.71% * 100;
 Minibatch[ 401- 500]: loss = 0.682472 * 100, metric = 12.04% * 100;
 Minibatch[ 501- 600]: loss = 0.698971 * 100, metric = 12.39% * 100;
 Minibatch[ 601- 700]: loss = 0.662430 * 100, metric = 11.41% * 100;
 Minibatch[ 701- 800]: loss = 0.688718 * 100, metric = 11.80% * 100;
 Minibatch[ 801- 900]: loss = 0.669606 * 100, metric = 11.18% * 100;
 Minibatch[ 901-1000]: loss = 0.650466 * 100, metric = 10.93% * 100;
 Minibatch[1001-1100]: loss = 0.670156 * 100, metric = 11.63% * 100;
 Minibatch[1101-1200]: loss = 0.666777 * 100, metric = 11.13% * 100;
 Minibatch[1201-1300]: loss = 0.677495 * 100, metric = 11.88% * 100;
 Minibatch[1301-1400]: loss = 0.682802 * 100, metric = 11.89% * 100;
 Minibatch[1401-1500]: loss = 0.667747 * 100, metric = 11.57% * 100;
 Minibatch[1501-1600]: loss = 0.681705 * 100, metric = 11.85% * 100;
 Minibatch[1601-1700]: loss = 0.661987 * 100, metric = 11.30% * 100;
 Minibatch[1701-1800]: loss = 0.662762 * 100, metric = 10.99% * 100;
 Minibatch[1801-1900]: loss = 0.673507 * 100, metric = 11.36% * 100;
 Minibatch[1901-2000]: loss = 0.666561 * 100, metric = 11.24% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.672730 * 2000, metric = 11.54% * 2000 908.719s (  2.2 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 17.87% * 2000;
0.6963376965001226
 Minibatch[   1- 100]: loss = 0.646508 * 100, metric = 10.87% * 100;
 Minibatch[ 101- 200]: loss = 0.686399 * 100, metric = 12.10% * 100;
 Minibatch[ 201- 300]: loss = 0.664386 * 100, metric = 11.20% * 100;
 Minibatch[ 301- 400]: loss = 0.685944 * 100, metric = 11.93% * 100;
 Minibatch[ 401- 500]: loss = 0.670063 * 100, metric = 11.34% * 100;
 Minibatch[ 501- 600]: loss = 0.655903 * 100, metric = 11.16% * 100;
 Minibatch[ 601- 700]: loss = 0.657639 * 100, metric = 11.30% * 100;
 Minibatch[ 701- 800]: loss = 0.645248 * 100, metric = 10.73% * 100;
 Minibatch[ 801- 900]: loss = 0.645445 * 100, metric = 11.29% * 100;
 Minibatch[ 901-1000]: loss = 0.666483 * 100, metric = 11.64% * 100;
 Minibatch[1001-1100]: loss = 0.634620 * 100, metric = 10.76% * 100;
 Minibatch[1101-1200]: loss = 0.667866 * 100, metric = 11.55% * 100;
 Minibatch[1201-1300]: loss = 0.649246 * 100, metric = 11.12% * 100;
 Minibatch[1301-1400]: loss = 0.639312 * 100, metric = 10.40% * 100;
 Minibatch[1401-1500]: loss = 0.656935 * 100, metric = 11.25% * 100;
 Minibatch[1501-1600]: loss = 0.662783 * 100, metric = 11.29% * 100;
 Minibatch[1601-1700]: loss = 0.659941 * 100, metric = 11.40% * 100;
 Minibatch[1701-1800]: loss = 0.644025 * 100, metric = 10.74% * 100;
 Minibatch[1801-1900]: loss = 0.649373 * 100, metric = 11.14% * 100;
 Minibatch[1901-2000]: loss = 0.661372 * 100, metric = 11.29% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.657475 * 2000, metric = 11.23% * 2000 899.703s (  2.2 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 16.51% * 2000;
0.677937321215868
 Minibatch[   1- 100]: loss = 0.667464 * 100, metric = 11.73% * 100;
 Minibatch[ 101- 200]: loss = 0.646703 * 100, metric = 10.92% * 100;
 Minibatch[ 201- 300]: loss = 0.653081 * 100, metric = 11.36% * 100;
 Minibatch[ 301- 400]: loss = 0.641747 * 100, metric = 10.62% * 100;
 Minibatch[ 401- 500]: loss = 0.663979 * 100, metric = 11.32% * 100;
 Minibatch[ 501- 600]: loss = 0.635967 * 100, metric = 10.58% * 100;
 Minibatch[ 601- 700]: loss = 0.629408 * 100, metric = 10.45% * 100;
 Minibatch[ 701- 800]: loss = 0.622982 * 100, metric = 10.13% * 100;
 Minibatch[ 801- 900]: loss = 0.639969 * 100, metric = 10.62% * 100;
 Minibatch[ 901-1000]: loss = 0.645683 * 100, metric = 10.73% * 100;
 Minibatch[1001-1100]: loss = 0.646690 * 100, metric = 10.97% * 100;
 Minibatch[1101-1200]: loss = 0.635294 * 100, metric = 10.54% * 100;
 Minibatch[1201-1300]: loss = 0.646462 * 100, metric = 10.96% * 100;
 Minibatch[1301-1400]: loss = 0.641179 * 100, metric = 10.81% * 100;
 Minibatch[1401-1500]: loss = 0.639366 * 100, metric = 10.65% * 100;
 Minibatch[1501-1600]: loss = 0.639119 * 100, metric = 10.74% * 100;
 Minibatch[1601-1700]: loss = 0.643125 * 100, metric = 10.79% * 100;
 Minibatch[1701-1800]: loss = 0.646392 * 100, metric = 10.78% * 100;
 Minibatch[1801-1900]: loss = 0.650750 * 100, metric = 11.16% * 100;
 Minibatch[1901-2000]: loss = 0.631934 * 100, metric = 10.86% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.643365 * 2000, metric = 10.84% * 2000 926.237s (  2.2 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 15.81% * 2000;
0.6621320561319589
 Minibatch[   1- 100]: loss = 0.616429 * 100, metric = 10.04% * 100;
 Minibatch[ 101- 200]: loss = 0.630059 * 100, metric = 10.35% * 100;
 Minibatch[ 201- 300]: loss = 0.641983 * 100, metric = 10.87% * 100;
 Minibatch[ 301- 400]: loss = 0.634794 * 100, metric = 10.73% * 100;
 Minibatch[ 401- 500]: loss = 0.631801 * 100, metric = 10.71% * 100;
 Minibatch[ 501- 600]: loss = 0.637382 * 100, metric = 10.69% * 100;
 Minibatch[ 601- 700]: loss = 0.622463 * 100, metric = 10.58% * 100;
 Minibatch[ 701- 800]: loss = 0.630760 * 100, metric = 10.76% * 100;
 Minibatch[ 801- 900]: loss = 0.638675 * 100, metric = 10.61% * 100;
 Minibatch[ 901-1000]: loss = 0.643030 * 100, metric = 10.80% * 100;
 Minibatch[1001-1100]: loss = 0.631169 * 100, metric = 10.61% * 100;
 Minibatch[1101-1200]: loss = 0.638148 * 100, metric = 10.81% * 100;
 Minibatch[1201-1300]: loss = 0.621068 * 100, metric = 10.40% * 100;
 Minibatch[1301-1400]: loss = 0.609802 * 100, metric = 9.91% * 100;
 Minibatch[1401-1500]: loss = 0.640474 * 100, metric = 10.97% * 100;
 Minibatch[1501-1600]: loss = 0.626994 * 100, metric = 10.63% * 100;
 Minibatch[1601-1700]: loss = 0.625151 * 100, metric = 10.16% * 100;
 Minibatch[1701-1800]: loss = 0.642235 * 100, metric = 10.74% * 100;
 Minibatch[1801-1900]: loss = 0.619357 * 100, metric = 10.37% * 100;
 Minibatch[1901-2000]: loss = 0.623313 * 100, metric = 10.57% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.630254 * 2000, metric = 10.57% * 2000 1003.120s (  2.0 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 16.88% * 2000;
 Minibatch[   1- 100]: loss = 0.602664 * 100, metric = 9.84% * 100;
 Minibatch[ 101- 200]: loss = 0.610790 * 100, metric = 9.73% * 100;
 Minibatch[ 201- 300]: loss = 0.612268 * 100, metric = 10.04% * 100;
 Minibatch[ 301- 400]: loss = 0.643306 * 100, metric = 11.20% * 100;
 Minibatch[ 401- 500]: loss = 0.615833 * 100, metric = 9.99% * 100;
 Minibatch[ 501- 600]: loss = 0.598472 * 100, metric = 9.48% * 100;
 Minibatch[ 601- 700]: loss = 0.614314 * 100, metric = 9.94% * 100;
 Minibatch[ 701- 800]: loss = 0.620169 * 100, metric = 10.16% * 100;
 Minibatch[ 801- 900]: loss = 0.617399 * 100, metric = 10.02% * 100;
 Minibatch[ 901-1000]: loss = 0.618883 * 100, metric = 9.98% * 100;
 Minibatch[1001-1100]: loss = 0.620151 * 100, metric = 10.41% * 100;
 Minibatch[1101-1200]: loss = 0.620486 * 100, metric = 10.15% * 100;
 Minibatch[1201-1300]: loss = 0.629105 * 100, metric = 10.75% * 100;
 Minibatch[1301-1400]: loss = 0.608115 * 100, metric = 9.95% * 100;
 Minibatch[1401-1500]: loss = 0.627500 * 100, metric = 10.52% * 100;
 Minibatch[1501-1600]: loss = 0.585560 * 100, metric = 9.56% * 100;
 Minibatch[1601-1700]: loss = 0.612892 * 100, metric = 10.29% * 100;
 Minibatch[1701-1800]: loss = 0.595571 * 100, metric = 9.73% * 100;
 Minibatch[1801-1900]: loss = 0.606345 * 100, metric = 9.97% * 100;
 Minibatch[1901-2000]: loss = 0.623743 * 100, metric = 10.62% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.614178 * 2000, metric = 10.12% * 2000 986.931s (  2.0 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 17.15% * 2000;
 Minibatch[   1- 100]: loss = 0.616886 * 100, metric = 10.41% * 100;
 Minibatch[ 101- 200]: loss = 0.626453 * 100, metric = 10.79% * 100;
 Minibatch[ 201- 300]: loss = 0.613553 * 100, metric = 10.10% * 100;
 Minibatch[ 301- 400]: loss = 0.619135 * 100, metric = 10.13% * 100;
 Minibatch[ 401- 500]: loss = 0.621239 * 100, metric = 10.90% * 100;
 Minibatch[ 501- 600]: loss = 0.621128 * 100, metric = 10.63% * 100;
 Minibatch[ 601- 700]: loss = 0.593526 * 100, metric = 9.54% * 100;
 Minibatch[ 701- 800]: loss = 0.599942 * 100, metric = 9.69% * 100;
 Minibatch[ 801- 900]: loss = 0.603672 * 100, metric = 9.86% * 100;
 Minibatch[ 901-1000]: loss = 0.613133 * 100, metric = 10.30% * 100;
 Minibatch[1001-1100]: loss = 0.614032 * 100, metric = 10.32% * 100;
 Minibatch[1101-1200]: loss = 0.599614 * 100, metric = 9.56% * 100;
 Minibatch[1201-1300]: loss = 0.604220 * 100, metric = 10.12% * 100;
 Minibatch[1301-1400]: loss = 0.602072 * 100, metric = 9.89% * 100;
 Minibatch[1401-1500]: loss = 0.602136 * 100, metric = 9.93% * 100;
 Minibatch[1501-1600]: loss = 0.591685 * 100, metric = 9.41% * 100;
 Minibatch[1601-1700]: loss = 0.585800 * 100, metric = 9.42% * 100;
 Minibatch[1701-1800]: loss = 0.599252 * 100, metric = 9.61% * 100;
 Minibatch[1801-1900]: loss = 0.597000 * 100, metric = 9.73% * 100;
 Minibatch[1901-2000]: loss = 0.612781 * 100, metric = 10.09% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.606863 * 2000, metric = 10.02% * 2000 961.836s (  2.1 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 18.01% * 2000;
 Minibatch[   1- 100]: loss = 0.595747 * 100, metric = 9.71% * 100;
 Minibatch[ 101- 200]: loss = 0.592062 * 100, metric = 9.77% * 100;
 Minibatch[ 201- 300]: loss = 0.610759 * 100, metric = 10.19% * 100;
 Minibatch[ 301- 400]: loss = 0.601077 * 100, metric = 9.83% * 100;
 Minibatch[ 401- 500]: loss = 0.589205 * 100, metric = 9.72% * 100;
 Minibatch[ 501- 600]: loss = 0.593041 * 100, metric = 9.63% * 100;
 Minibatch[ 601- 700]: loss = 0.599856 * 100, metric = 10.10% * 100;
 Minibatch[ 701- 800]: loss = 0.618475 * 100, metric = 10.37% * 100;
 Minibatch[ 801- 900]: loss = 0.608069 * 100, metric = 10.34% * 100;
 Minibatch[ 901-1000]: loss = 0.604306 * 100, metric = 10.04% * 100;
 Minibatch[1001-1100]: loss = 0.601068 * 100, metric = 9.97% * 100;
 Minibatch[1101-1200]: loss = 0.587849 * 100, metric = 9.55% * 100;
 Minibatch[1201-1300]: loss = 0.575583 * 100, metric = 9.07% * 100;
 Minibatch[1301-1400]: loss = 0.588204 * 100, metric = 9.83% * 100;
 Minibatch[1401-1500]: loss = 0.593236 * 100, metric = 9.79% * 100;
 Minibatch[1501-1600]: loss = 0.576432 * 100, metric = 9.20% * 100;
 Minibatch[1601-1700]: loss = 0.592471 * 100, metric = 9.63% * 100;
 Minibatch[1701-1800]: loss = 0.585190 * 100, metric = 9.28% * 100;
 Minibatch[1801-1900]: loss = 0.589977 * 100, metric = 9.51% * 100;
 Minibatch[1901-2000]: loss = 0.595909 * 100, metric = 9.52% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.594926 * 2000, metric = 9.75% * 2000 938.800s (  2.1 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 17.82% * 2000;
 Minibatch[   1- 100]: loss = 0.585771 * 100, metric = 9.62% * 100;
 Minibatch[ 101- 200]: loss = 0.589442 * 100, metric = 9.55% * 100;
 Minibatch[ 201- 300]: loss = 0.591071 * 100, metric = 9.62% * 100;
 Minibatch[ 301- 400]: loss = 0.571121 * 100, metric = 9.05% * 100;
 Minibatch[ 401- 500]: loss = 0.580823 * 100, metric = 9.65% * 100;
 Minibatch[ 501- 600]: loss = 0.578114 * 100, metric = 9.14% * 100;
 Minibatch[ 601- 700]: loss = 0.561667 * 100, metric = 9.15% * 100;
 Minibatch[ 701- 800]: loss = 0.588585 * 100, metric = 9.74% * 100;
 Minibatch[ 801- 900]: loss = 0.605610 * 100, metric = 10.37% * 100;
 Minibatch[ 901-1000]: loss = 0.589873 * 100, metric = 9.74% * 100;
 Minibatch[1001-1100]: loss = 0.595338 * 100, metric = 9.69% * 100;
 Minibatch[1101-1200]: loss = 0.581279 * 100, metric = 9.39% * 100;
 Minibatch[1201-1300]: loss = 0.575297 * 100, metric = 9.24% * 100;
 Minibatch[1301-1400]: loss = 0.601349 * 100, metric = 10.03% * 100;
 Minibatch[1401-1500]: loss = 0.560889 * 100, metric = 8.90% * 100;
 Minibatch[1501-1600]: loss = 0.576826 * 100, metric = 9.44% * 100;
 Minibatch[1601-1700]: loss = 0.589493 * 100, metric = 9.48% * 100;
 Minibatch[1701-1800]: loss = 0.570231 * 100, metric = 8.83% * 100;
 Minibatch[1801-1900]: loss = 0.573608 * 100, metric = 9.27% * 100;
 Minibatch[1901-2000]: loss = 0.574384 * 100, metric = 9.39% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.582039 * 2000, metric = 9.46% * 2000 791.712s (  2.5 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 15.33% * 2000;
0.6505386835485697
 Minibatch[   1- 100]: loss = 0.602752 * 100, metric = 10.32% * 100;
 Minibatch[ 101- 200]: loss = 0.591649 * 100, metric = 9.58% * 100;
 Minibatch[ 201- 300]: loss = 0.576808 * 100, metric = 9.26% * 100;
 Minibatch[ 301- 400]: loss = 0.585109 * 100, metric = 9.52% * 100;
 Minibatch[ 401- 500]: loss = 0.559524 * 100, metric = 8.75% * 100;
 Minibatch[ 501- 600]: loss = 0.573390 * 100, metric = 9.38% * 100;
 Minibatch[ 601- 700]: loss = 0.576683 * 100, metric = 9.36% * 100;
 Minibatch[ 701- 800]: loss = 0.570912 * 100, metric = 9.10% * 100;
 Minibatch[ 801- 900]: loss = 0.564363 * 100, metric = 9.01% * 100;
 Minibatch[ 901-1000]: loss = 0.578055 * 100, metric = 9.32% * 100;
 Minibatch[1001-1100]: loss = 0.558013 * 100, metric = 9.01% * 100;
 Minibatch[1101-1200]: loss = 0.565446 * 100, metric = 9.25% * 100;
 Minibatch[1201-1300]: loss = 0.568496 * 100, metric = 8.76% * 100;
 Minibatch[1301-1400]: loss = 0.570908 * 100, metric = 9.23% * 100;
 Minibatch[1401-1500]: loss = 0.571039 * 100, metric = 9.34% * 100;
 Minibatch[1501-1600]: loss = 0.572018 * 100, metric = 9.29% * 100;
 Minibatch[1601-1700]: loss = 0.567307 * 100, metric = 9.32% * 100;
 Minibatch[1701-1800]: loss = 0.583766 * 100, metric = 9.24% * 100;
 Minibatch[1801-1900]: loss = 0.576039 * 100, metric = 9.25% * 100;
 Minibatch[1901-2000]: loss = 0.560487 * 100, metric = 9.10% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.573638 * 2000, metric = 9.27% * 2000 876.537s (  2.3 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 15.24% * 2000;
 Minibatch[   1- 100]: loss = 0.560978 * 100, metric = 8.99% * 100;
 Minibatch[ 101- 200]: loss = 0.585709 * 100, metric = 9.67% * 100;
 Minibatch[ 201- 300]: loss = 0.584206 * 100, metric = 9.55% * 100;
 Minibatch[ 301- 400]: loss = 0.575661 * 100, metric = 9.31% * 100;
 Minibatch[ 401- 500]: loss = 0.582806 * 100, metric = 9.36% * 100;
 Minibatch[ 501- 600]: loss = 0.555886 * 100, metric = 8.73% * 100;
 Minibatch[ 601- 700]: loss = 0.543186 * 100, metric = 8.47% * 100;
 Minibatch[ 701- 800]: loss = 0.560155 * 100, metric = 8.87% * 100;
 Minibatch[ 801- 900]: loss = 0.573301 * 100, metric = 9.21% * 100;
 Minibatch[ 901-1000]: loss = 0.556499 * 100, metric = 8.79% * 100;
 Minibatch[1001-1100]: loss = 0.551274 * 100, metric = 8.78% * 100;
 Minibatch[1101-1200]: loss = 0.578174 * 100, metric = 9.32% * 100;
 Minibatch[1201-1300]: loss = 0.572148 * 100, metric = 9.35% * 100;
 Minibatch[1301-1400]: loss = 0.544031 * 100, metric = 8.63% * 100;
 Minibatch[1401-1500]: loss = 0.568190 * 100, metric = 9.41% * 100;
 Minibatch[1501-1600]: loss = 0.562388 * 100, metric = 8.93% * 100;
 Minibatch[1601-1700]: loss = 0.568688 * 100, metric = 9.10% * 100;
 Minibatch[1701-1800]: loss = 0.545343 * 100, metric = 8.72% * 100;
 Minibatch[1801-1900]: loss = 0.575399 * 100, metric = 9.46% * 100;
 Minibatch[1901-2000]: loss = 0.582720 * 100, metric = 9.56% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.566337 * 2000, metric = 9.11% * 2000 897.765s (  2.2 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 15.04% * 2000;
0.6395338991060853
 Minibatch[   1- 100]: loss = 0.552053 * 100, metric = 8.58% * 100;
 Minibatch[ 101- 200]: loss = 0.573004 * 100, metric = 9.23% * 100;
 Minibatch[ 201- 300]: loss = 0.550501 * 100, metric = 8.90% * 100;
 Minibatch[ 301- 400]: loss = 0.570898 * 100, metric = 9.10% * 100;
 Minibatch[ 401- 500]: loss = 0.546364 * 100, metric = 8.57% * 100;
 Minibatch[ 501- 600]: loss = 0.559531 * 100, metric = 8.98% * 100;
 Minibatch[ 601- 700]: loss = 0.568119 * 100, metric = 9.09% * 100;
 Minibatch[ 701- 800]: loss = 0.550912 * 100, metric = 8.81% * 100;
 Minibatch[ 801- 900]: loss = 0.569508 * 100, metric = 8.93% * 100;
 Minibatch[ 901-1000]: loss = 0.569981 * 100, metric = 9.31% * 100;
 Minibatch[1001-1100]: loss = 0.574990 * 100, metric = 9.62% * 100;
 Minibatch[1101-1200]: loss = 0.563873 * 100, metric = 9.00% * 100;
 Minibatch[1201-1300]: loss = 0.567367 * 100, metric = 9.40% * 100;
 Minibatch[1301-1400]: loss = 0.575738 * 100, metric = 9.29% * 100;
 Minibatch[1401-1500]: loss = 0.545433 * 100, metric = 8.40% * 100;
 Minibatch[1501-1600]: loss = 0.567086 * 100, metric = 9.06% * 100;
 Minibatch[1601-1700]: loss = 0.538808 * 100, metric = 8.47% * 100;
 Minibatch[1701-1800]: loss = 0.559462 * 100, metric = 8.86% * 100;
 Minibatch[1801-1900]: loss = 0.538867 * 100, metric = 8.45% * 100;
 Minibatch[1901-2000]: loss = 0.543221 * 100, metric = 8.47% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.559286 * 2000, metric = 8.93% * 2000 889.791s (  2.2 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.67% * 2000;
 Minibatch[   1- 100]: loss = 0.563164 * 100, metric = 8.92% * 100;
 Minibatch[ 101- 200]: loss = 0.570902 * 100, metric = 9.25% * 100;
 Minibatch[ 201- 300]: loss = 0.540252 * 100, metric = 8.36% * 100;
 Minibatch[ 301- 400]: loss = 0.565368 * 100, metric = 9.07% * 100;
 Minibatch[ 401- 500]: loss = 0.553425 * 100, metric = 8.47% * 100;
 Minibatch[ 501- 600]: loss = 0.542554 * 100, metric = 8.20% * 100;
 Minibatch[ 601- 700]: loss = 0.569082 * 100, metric = 9.07% * 100;
 Minibatch[ 701- 800]: loss = 0.536602 * 100, metric = 8.55% * 100;
 Minibatch[ 801- 900]: loss = 0.575366 * 100, metric = 9.38% * 100;
 Minibatch[ 901-1000]: loss = 0.544240 * 100, metric = 8.41% * 100;
 Minibatch[1001-1100]: loss = 0.567578 * 100, metric = 8.99% * 100;
 Minibatch[1101-1200]: loss = 0.557125 * 100, metric = 8.87% * 100;
 Minibatch[1201-1300]: loss = 0.550142 * 100, metric = 8.78% * 100;
 Minibatch[1301-1400]: loss = 0.543834 * 100, metric = 8.52% * 100;
 Minibatch[1401-1500]: loss = 0.564404 * 100, metric = 9.24% * 100;
 Minibatch[1501-1600]: loss = 0.572642 * 100, metric = 9.13% * 100;
 Minibatch[1601-1700]: loss = 0.546907 * 100, metric = 8.73% * 100;
 Minibatch[1701-1800]: loss = 0.528247 * 100, metric = 8.03% * 100;
 Minibatch[1801-1900]: loss = 0.541267 * 100, metric = 8.50% * 100;
 Minibatch[1901-2000]: loss = 0.533810 * 100, metric = 8.31% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.553346 * 2000, metric = 8.74% * 2000 879.889s (  2.3 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 15.16% * 2000;
 Minibatch[   1- 100]: loss = 0.531444 * 100, metric = 8.04% * 100;
 Minibatch[ 101- 200]: loss = 0.542692 * 100, metric = 8.51% * 100;
 Minibatch[ 201- 300]: loss = 0.536385 * 100, metric = 8.17% * 100;
 Minibatch[ 301- 400]: loss = 0.561617 * 100, metric = 8.57% * 100;
 Minibatch[ 401- 500]: loss = 0.542802 * 100, metric = 8.64% * 100;
 Minibatch[ 501- 600]: loss = 0.551454 * 100, metric = 8.95% * 100;
 Minibatch[ 601- 700]: loss = 0.553604 * 100, metric = 8.92% * 100;
 Minibatch[ 701- 800]: loss = 0.549689 * 100, metric = 8.87% * 100;
 Minibatch[ 801- 900]: loss = 0.560031 * 100, metric = 8.88% * 100;
 Minibatch[ 901-1000]: loss = 0.562576 * 100, metric = 8.82% * 100;
 Minibatch[1001-1100]: loss = 0.537205 * 100, metric = 8.36% * 100;
 Minibatch[1101-1200]: loss = 0.550998 * 100, metric = 8.62% * 100;
 Minibatch[1201-1300]: loss = 0.549337 * 100, metric = 8.75% * 100;
 Minibatch[1301-1400]: loss = 0.553799 * 100, metric = 8.98% * 100;
 Minibatch[1401-1500]: loss = 0.535787 * 100, metric = 8.57% * 100;
 Minibatch[1501-1600]: loss = 0.551592 * 100, metric = 8.56% * 100;
 Minibatch[1601-1700]: loss = 0.542720 * 100, metric = 8.51% * 100;
 Minibatch[1701-1800]: loss = 0.552420 * 100, metric = 8.70% * 100;
 Minibatch[1801-1900]: loss = 0.546642 * 100, metric = 8.55% * 100;
 Minibatch[1901-2000]: loss = 0.540856 * 100, metric = 8.54% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.547683 * 2000, metric = 8.63% * 2000 877.257s (  2.3 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 15.74% * 2000;
 Minibatch[   1- 100]: loss = 0.546371 * 100, metric = 8.46% * 100;
 Minibatch[ 101- 200]: loss = 0.543485 * 100, metric = 8.59% * 100;
 Minibatch[ 201- 300]: loss = 0.541927 * 100, metric = 8.54% * 100;
 Minibatch[ 301- 400]: loss = 0.551331 * 100, metric = 8.78% * 100;
 Minibatch[ 401- 500]: loss = 0.531828 * 100, metric = 8.30% * 100;
 Minibatch[ 501- 600]: loss = 0.538233 * 100, metric = 8.27% * 100;
 Minibatch[ 601- 700]: loss = 0.538210 * 100, metric = 8.60% * 100;
 Minibatch[ 701- 800]: loss = 0.505417 * 100, metric = 7.55% * 100;
 Minibatch[ 801- 900]: loss = 0.543293 * 100, metric = 8.43% * 100;
 Minibatch[ 901-1000]: loss = 0.530392 * 100, metric = 8.31% * 100;
 Minibatch[1001-1100]: loss = 0.528280 * 100, metric = 8.03% * 100;
 Minibatch[1101-1200]: loss = 0.530409 * 100, metric = 8.23% * 100;
 Minibatch[1201-1300]: loss = 0.530322 * 100, metric = 8.08% * 100;
 Minibatch[1301-1400]: loss = 0.519982 * 100, metric = 8.09% * 100;
 Minibatch[1401-1500]: loss = 0.536870 * 100, metric = 8.42% * 100;
 Minibatch[1501-1600]: loss = 0.542584 * 100, metric = 8.94% * 100;
 Minibatch[1601-1700]: loss = 0.528046 * 100, metric = 8.36% * 100;
 Minibatch[1701-1800]: loss = 0.520626 * 100, metric = 7.90% * 100;
 Minibatch[1801-1900]: loss = 0.545204 * 100, metric = 8.69% * 100;
 Minibatch[1901-2000]: loss = 0.510832 * 100, metric = 8.05% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.533182 * 2000, metric = 8.33% * 2000 872.974s (  2.3 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 14.41% * 2000;
0.6279831550046802
 Minibatch[   1- 100]: loss = 0.538930 * 100, metric = 8.51% * 100;
 Minibatch[ 101- 200]: loss = 0.534698 * 100, metric = 8.45% * 100;
 Minibatch[ 201- 300]: loss = 0.542208 * 100, metric = 8.90% * 100;
 Minibatch[ 301- 400]: loss = 0.528265 * 100, metric = 8.35% * 100;
 Minibatch[ 401- 500]: loss = 0.526154 * 100, metric = 8.04% * 100;
 Minibatch[ 501- 600]: loss = 0.538272 * 100, metric = 8.29% * 100;
 Minibatch[ 601- 700]: loss = 0.524518 * 100, metric = 7.88% * 100;
 Minibatch[ 701- 800]: loss = 0.524393 * 100, metric = 8.20% * 100;
 Minibatch[ 801- 900]: loss = 0.540584 * 100, metric = 8.46% * 100;
 Minibatch[ 901-1000]: loss = 0.542709 * 100, metric = 8.42% * 100;
 Minibatch[1001-1100]: loss = 0.513539 * 100, metric = 7.96% * 100;
 Minibatch[1101-1200]: loss = 0.505173 * 100, metric = 7.52% * 100;
 Minibatch[1201-1300]: loss = 0.528043 * 100, metric = 8.26% * 100;
 Minibatch[1301-1400]: loss = 0.529609 * 100, metric = 8.40% * 100;
 Minibatch[1401-1500]: loss = 0.519907 * 100, metric = 8.07% * 100;
 Minibatch[1501-1600]: loss = 0.509761 * 100, metric = 7.77% * 100;
 Minibatch[1601-1700]: loss = 0.519434 * 100, metric = 8.08% * 100;
 Minibatch[1701-1800]: loss = 0.522494 * 100, metric = 7.91% * 100;
 Minibatch[1801-1900]: loss = 0.520729 * 100, metric = 8.04% * 100;
 Minibatch[1901-2000]: loss = 0.526144 * 100, metric = 8.03% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.526778 * 2000, metric = 8.18% * 2000 879.683s (  2.3 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 14.62% * 2000;
 Minibatch[   1- 100]: loss = 0.531437 * 100, metric = 8.43% * 100;
 Minibatch[ 101- 200]: loss = 0.541212 * 100, metric = 8.68% * 100;
 Minibatch[ 201- 300]: loss = 0.528350 * 100, metric = 8.13% * 100;
 Minibatch[ 301- 400]: loss = 0.538382 * 100, metric = 8.42% * 100;
 Minibatch[ 401- 500]: loss = 0.531491 * 100, metric = 8.21% * 100;
 Minibatch[ 501- 600]: loss = 0.529765 * 100, metric = 8.07% * 100;
 Minibatch[ 601- 700]: loss = 0.527838 * 100, metric = 8.12% * 100;
 Minibatch[ 701- 800]: loss = 0.514588 * 100, metric = 7.74% * 100;
 Minibatch[ 801- 900]: loss = 0.502657 * 100, metric = 7.84% * 100;
 Minibatch[ 901-1000]: loss = 0.539445 * 100, metric = 8.42% * 100;
 Minibatch[1001-1100]: loss = 0.513022 * 100, metric = 7.84% * 100;
 Minibatch[1101-1200]: loss = 0.528161 * 100, metric = 8.47% * 100;
 Minibatch[1201-1300]: loss = 0.524779 * 100, metric = 8.20% * 100;
 Minibatch[1301-1400]: loss = 0.538988 * 100, metric = 8.59% * 100;
 Minibatch[1401-1500]: loss = 0.510328 * 100, metric = 7.87% * 100;
 Minibatch[1501-1600]: loss = 0.519736 * 100, metric = 7.90% * 100;
 Minibatch[1601-1700]: loss = 0.516392 * 100, metric = 8.13% * 100;
 Minibatch[1701-1800]: loss = 0.517203 * 100, metric = 8.20% * 100;
 Minibatch[1801-1900]: loss = 0.530794 * 100, metric = 8.50% * 100;
 Minibatch[1901-2000]: loss = 0.531741 * 100, metric = 8.25% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.525815 * 2000, metric = 8.20% * 2000 873.315s (  2.3 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 14.91% * 2000;
 Minibatch[   1- 100]: loss = 0.502747 * 100, metric = 7.82% * 100;
 Minibatch[ 101- 200]: loss = 0.516122 * 100, metric = 7.88% * 100;
 Minibatch[ 201- 300]: loss = 0.516034 * 100, metric = 7.93% * 100;
 Minibatch[ 301- 400]: loss = 0.517876 * 100, metric = 7.92% * 100;
 Minibatch[ 401- 500]: loss = 0.523178 * 100, metric = 8.03% * 100;
 Minibatch[ 501- 600]: loss = 0.511644 * 100, metric = 7.77% * 100;
 Minibatch[ 601- 700]: loss = 0.511612 * 100, metric = 7.67% * 100;
 Minibatch[ 701- 800]: loss = 0.508010 * 100, metric = 7.73% * 100;
 Minibatch[ 801- 900]: loss = 0.528296 * 100, metric = 8.17% * 100;
 Minibatch[ 901-1000]: loss = 0.517236 * 100, metric = 8.16% * 100;
 Minibatch[1001-1100]: loss = 0.517564 * 100, metric = 7.94% * 100;
 Minibatch[1101-1200]: loss = 0.528404 * 100, metric = 8.25% * 100;
 Minibatch[1201-1300]: loss = 0.520083 * 100, metric = 8.18% * 100;
 Minibatch[1301-1400]: loss = 0.511150 * 100, metric = 7.71% * 100;
 Minibatch[1401-1500]: loss = 0.506063 * 100, metric = 7.83% * 100;
 Minibatch[1501-1600]: loss = 0.519163 * 100, metric = 8.10% * 100;
 Minibatch[1601-1700]: loss = 0.502833 * 100, metric = 7.65% * 100;
 Minibatch[1701-1800]: loss = 0.500112 * 100, metric = 7.74% * 100;
 Minibatch[1801-1900]: loss = 0.516803 * 100, metric = 8.10% * 100;
 Minibatch[1901-2000]: loss = 0.512872 * 100, metric = 8.06% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.514390 * 2000, metric = 7.93% * 2000 857.767s (  2.3 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.33% * 2000;
 Minibatch[   1- 100]: loss = 0.507904 * 100, metric = 7.73% * 100;
 Minibatch[ 101- 200]: loss = 0.511771 * 100, metric = 8.01% * 100;
 Minibatch[ 201- 300]: loss = 0.513469 * 100, metric = 8.19% * 100;
 Minibatch[ 301- 400]: loss = 0.514762 * 100, metric = 7.99% * 100;
 Minibatch[ 401- 500]: loss = 0.514412 * 100, metric = 8.01% * 100;
 Minibatch[ 501- 600]: loss = 0.510743 * 100, metric = 7.81% * 100;
 Minibatch[ 601- 700]: loss = 0.512176 * 100, metric = 7.95% * 100;
 Minibatch[ 701- 800]: loss = 0.500302 * 100, metric = 7.56% * 100;
 Minibatch[ 801- 900]: loss = 0.504828 * 100, metric = 7.81% * 100;
 Minibatch[ 901-1000]: loss = 0.507439 * 100, metric = 7.84% * 100;
 Minibatch[1001-1100]: loss = 0.510522 * 100, metric = 7.75% * 100;
 Minibatch[1101-1200]: loss = 0.515294 * 100, metric = 8.01% * 100;
 Minibatch[1201-1300]: loss = 0.528688 * 100, metric = 8.36% * 100;
 Minibatch[1301-1400]: loss = 0.510285 * 100, metric = 7.84% * 100;
 Minibatch[1401-1500]: loss = 0.497854 * 100, metric = 7.38% * 100;
 Minibatch[1501-1600]: loss = 0.515226 * 100, metric = 8.03% * 100;
 Minibatch[1601-1700]: loss = 0.507534 * 100, metric = 7.95% * 100;
 Minibatch[1701-1800]: loss = 0.512529 * 100, metric = 7.94% * 100;
 Minibatch[1801-1900]: loss = 0.495820 * 100, metric = 7.47% * 100;
 Minibatch[1901-2000]: loss = 0.487141 * 100, metric = 7.16% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.508935 * 2000, metric = 7.84% * 2000 840.506s (  2.4 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.98% * 2000;
 Minibatch[   1- 100]: loss = 0.505532 * 100, metric = 7.71% * 100;
 Minibatch[ 101- 200]: loss = 0.486972 * 100, metric = 7.36% * 100;
 Minibatch[ 201- 300]: loss = 0.504841 * 100, metric = 7.89% * 100;
 Minibatch[ 301- 400]: loss = 0.497804 * 100, metric = 7.28% * 100;
 Minibatch[ 401- 500]: loss = 0.502351 * 100, metric = 7.54% * 100;
 Minibatch[ 501- 600]: loss = 0.498647 * 100, metric = 7.59% * 100;
 Minibatch[ 601- 700]: loss = 0.514626 * 100, metric = 7.94% * 100;
 Minibatch[ 701- 800]: loss = 0.497549 * 100, metric = 7.70% * 100;
 Minibatch[ 801- 900]: loss = 0.489256 * 100, metric = 7.36% * 100;
 Minibatch[ 901-1000]: loss = 0.492331 * 100, metric = 7.38% * 100;
 Minibatch[1001-1100]: loss = 0.514374 * 100, metric = 8.34% * 100;
 Minibatch[1101-1200]: loss = 0.520148 * 100, metric = 8.03% * 100;
 Minibatch[1201-1300]: loss = 0.499958 * 100, metric = 7.58% * 100;
 Minibatch[1301-1400]: loss = 0.491724 * 100, metric = 7.52% * 100;
 Minibatch[1401-1500]: loss = 0.499440 * 100, metric = 7.71% * 100;
 Minibatch[1501-1600]: loss = 0.493414 * 100, metric = 7.37% * 100;
 Minibatch[1601-1700]: loss = 0.519890 * 100, metric = 8.17% * 100;
 Minibatch[1701-1800]: loss = 0.502993 * 100, metric = 7.76% * 100;
 Minibatch[1801-1900]: loss = 0.508460 * 100, metric = 7.69% * 100;
 Minibatch[1901-2000]: loss = 0.509916 * 100, metric = 7.79% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.502511 * 2000, metric = 7.68% * 2000 847.470s (  2.4 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.41% * 2000;
 Minibatch[   1- 100]: loss = 0.500673 * 100, metric = 7.59% * 100;
 Minibatch[ 101- 200]: loss = 0.518849 * 100, metric = 7.93% * 100;
 Minibatch[ 201- 300]: loss = 0.502786 * 100, metric = 7.73% * 100;
 Minibatch[ 301- 400]: loss = 0.490882 * 100, metric = 7.40% * 100;
 Minibatch[ 401- 500]: loss = 0.507133 * 100, metric = 7.78% * 100;
 Minibatch[ 501- 600]: loss = 0.492273 * 100, metric = 7.64% * 100;
 Minibatch[ 601- 700]: loss = 0.497643 * 100, metric = 7.57% * 100;
 Minibatch[ 701- 800]: loss = 0.500222 * 100, metric = 7.55% * 100;
 Minibatch[ 801- 900]: loss = 0.511195 * 100, metric = 7.85% * 100;
 Minibatch[ 901-1000]: loss = 0.504508 * 100, metric = 8.06% * 100;
 Minibatch[1001-1100]: loss = 0.492828 * 100, metric = 7.28% * 100;
 Minibatch[1101-1200]: loss = 0.511390 * 100, metric = 7.94% * 100;
 Minibatch[1201-1300]: loss = 0.496258 * 100, metric = 7.48% * 100;
 Minibatch[1301-1400]: loss = 0.510062 * 100, metric = 7.92% * 100;
 Minibatch[1401-1500]: loss = 0.491622 * 100, metric = 7.82% * 100;
 Minibatch[1501-1600]: loss = 0.504911 * 100, metric = 7.64% * 100;
 Minibatch[1601-1700]: loss = 0.482072 * 100, metric = 7.32% * 100;
 Minibatch[1701-1800]: loss = 0.497664 * 100, metric = 7.31% * 100;
 Minibatch[1801-1900]: loss = 0.494258 * 100, metric = 7.67% * 100;
 Minibatch[1901-2000]: loss = 0.502972 * 100, metric = 7.55% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.500510 * 2000, metric = 7.65% * 2000 852.372s (  2.3 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.76% * 2000;
 Minibatch[   1- 100]: loss = 0.506831 * 100, metric = 7.89% * 100;
 Minibatch[ 101- 200]: loss = 0.486479 * 100, metric = 7.25% * 100;
 Minibatch[ 201- 300]: loss = 0.497039 * 100, metric = 7.78% * 100;
 Minibatch[ 301- 400]: loss = 0.495701 * 100, metric = 7.35% * 100;
 Minibatch[ 401- 500]: loss = 0.497733 * 100, metric = 7.70% * 100;
 Minibatch[ 501- 600]: loss = 0.507851 * 100, metric = 8.17% * 100;
 Minibatch[ 601- 700]: loss = 0.489711 * 100, metric = 7.38% * 100;
 Minibatch[ 701- 800]: loss = 0.480071 * 100, metric = 7.32% * 100;
 Minibatch[ 801- 900]: loss = 0.497609 * 100, metric = 7.65% * 100;
 Minibatch[ 901-1000]: loss = 0.500653 * 100, metric = 7.94% * 100;
 Minibatch[1001-1100]: loss = 0.495140 * 100, metric = 7.68% * 100;
 Minibatch[1101-1200]: loss = 0.491273 * 100, metric = 7.46% * 100;
 Minibatch[1201-1300]: loss = 0.491842 * 100, metric = 7.57% * 100;
 Minibatch[1301-1400]: loss = 0.481091 * 100, metric = 7.32% * 100;
 Minibatch[1401-1500]: loss = 0.501791 * 100, metric = 7.73% * 100;
 Minibatch[1501-1600]: loss = 0.479992 * 100, metric = 7.26% * 100;
 Minibatch[1601-1700]: loss = 0.489886 * 100, metric = 7.38% * 100;
 Minibatch[1701-1800]: loss = 0.487653 * 100, metric = 7.36% * 100;
 Minibatch[1801-1900]: loss = 0.496145 * 100, metric = 7.59% * 100;
 Minibatch[1901-2000]: loss = 0.490302 * 100, metric = 7.41% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.493240 * 2000, metric = 7.56% * 2000 848.375s (  2.4 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.63% * 2000;
0.6239631895646452
 Minibatch[   1- 100]: loss = 0.484854 * 100, metric = 7.45% * 100;
 Minibatch[ 101- 200]: loss = 0.484908 * 100, metric = 7.29% * 100;
 Minibatch[ 201- 300]: loss = 0.488417 * 100, metric = 7.60% * 100;
 Minibatch[ 301- 400]: loss = 0.512406 * 100, metric = 7.90% * 100;
 Minibatch[ 401- 500]: loss = 0.482268 * 100, metric = 7.25% * 100;
 Minibatch[ 501- 600]: loss = 0.490000 * 100, metric = 7.50% * 100;
 Minibatch[ 601- 700]: loss = 0.487985 * 100, metric = 7.65% * 100;
 Minibatch[ 701- 800]: loss = 0.490637 * 100, metric = 7.40% * 100;
 Minibatch[ 801- 900]: loss = 0.485656 * 100, metric = 7.37% * 100;
 Minibatch[ 901-1000]: loss = 0.499522 * 100, metric = 7.62% * 100;
 Minibatch[1001-1100]: loss = 0.491030 * 100, metric = 7.74% * 100;
 Minibatch[1101-1200]: loss = 0.483762 * 100, metric = 7.17% * 100;
 Minibatch[1201-1300]: loss = 0.499310 * 100, metric = 7.81% * 100;
 Minibatch[1301-1400]: loss = 0.480607 * 100, metric = 7.31% * 100;
 Minibatch[1401-1500]: loss = 0.501889 * 100, metric = 7.69% * 100;
 Minibatch[1501-1600]: loss = 0.469998 * 100, metric = 7.04% * 100;
 Minibatch[1601-1700]: loss = 0.495156 * 100, metric = 7.71% * 100;
 Minibatch[1701-1800]: loss = 0.474011 * 100, metric = 7.11% * 100;
 Minibatch[1801-1900]: loss = 0.500319 * 100, metric = 7.41% * 100;
 Minibatch[1901-2000]: loss = 0.486773 * 100, metric = 7.40% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.489475 * 2000, metric = 7.47% * 2000 850.776s (  2.4 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 14.48% * 2000;
 Minibatch[   1- 100]: loss = 0.515850 * 100, metric = 8.12% * 100;
 Minibatch[ 101- 200]: loss = 0.469543 * 100, metric = 6.78% * 100;
 Minibatch[ 201- 300]: loss = 0.477934 * 100, metric = 7.40% * 100;
 Minibatch[ 301- 400]: loss = 0.495399 * 100, metric = 7.60% * 100;
 Minibatch[ 401- 500]: loss = 0.488504 * 100, metric = 7.36% * 100;
 Minibatch[ 501- 600]: loss = 0.462416 * 100, metric = 6.72% * 100;
 Minibatch[ 601- 700]: loss = 0.484808 * 100, metric = 7.48% * 100;
 Minibatch[ 701- 800]: loss = 0.479250 * 100, metric = 7.00% * 100;
 Minibatch[ 801- 900]: loss = 0.488513 * 100, metric = 7.47% * 100;
 Minibatch[ 901-1000]: loss = 0.469034 * 100, metric = 7.03% * 100;
 Minibatch[1001-1100]: loss = 0.484448 * 100, metric = 7.09% * 100;
 Minibatch[1101-1200]: loss = 0.502296 * 100, metric = 7.59% * 100;
 Minibatch[1201-1300]: loss = 0.481419 * 100, metric = 7.28% * 100;
 Minibatch[1301-1400]: loss = 0.493401 * 100, metric = 7.53% * 100;
 Minibatch[1401-1500]: loss = 0.476407 * 100, metric = 7.30% * 100;
 Minibatch[1501-1600]: loss = 0.490810 * 100, metric = 7.47% * 100;
 Minibatch[1601-1700]: loss = 0.489182 * 100, metric = 7.39% * 100;
 Minibatch[1701-1800]: loss = 0.493244 * 100, metric = 7.46% * 100;
 Minibatch[1801-1900]: loss = 0.482549 * 100, metric = 7.49% * 100;
 Minibatch[1901-2000]: loss = 0.498052 * 100, metric = 7.80% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.486153 * 2000, metric = 7.37% * 2000 851.335s (  2.3 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.92% * 2000;
 Minibatch[   1- 100]: loss = 0.491616 * 100, metric = 7.37% * 100;
 Minibatch[ 101- 200]: loss = 0.497770 * 100, metric = 7.85% * 100;
 Minibatch[ 201- 300]: loss = 0.486948 * 100, metric = 7.45% * 100;
 Minibatch[ 301- 400]: loss = 0.479569 * 100, metric = 7.21% * 100;
 Minibatch[ 401- 500]: loss = 0.481923 * 100, metric = 7.26% * 100;
 Minibatch[ 501- 600]: loss = 0.476590 * 100, metric = 7.12% * 100;
 Minibatch[ 601- 700]: loss = 0.497693 * 100, metric = 7.92% * 100;
 Minibatch[ 701- 800]: loss = 0.492016 * 100, metric = 7.54% * 100;
 Minibatch[ 801- 900]: loss = 0.487281 * 100, metric = 7.19% * 100;
 Minibatch[ 901-1000]: loss = 0.467403 * 100, metric = 6.90% * 100;
 Minibatch[1001-1100]: loss = 0.476237 * 100, metric = 7.05% * 100;
 Minibatch[1101-1200]: loss = 0.495443 * 100, metric = 7.59% * 100;
 Minibatch[1201-1300]: loss = 0.481351 * 100, metric = 7.31% * 100;
 Minibatch[1301-1400]: loss = 0.479690 * 100, metric = 7.25% * 100;
 Minibatch[1401-1500]: loss = 0.489549 * 100, metric = 7.39% * 100;
 Minibatch[1501-1600]: loss = 0.466303 * 100, metric = 7.00% * 100;
 Minibatch[1601-1700]: loss = 0.481816 * 100, metric = 7.40% * 100;
 Minibatch[1701-1800]: loss = 0.475439 * 100, metric = 7.22% * 100;
 Minibatch[1801-1900]: loss = 0.479227 * 100, metric = 7.12% * 100;
 Minibatch[1901-2000]: loss = 0.476315 * 100, metric = 7.13% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.483009 * 2000, metric = 7.31% * 2000 846.642s (  2.4 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 14.24% * 2000;
 Minibatch[   1- 100]: loss = 0.483812 * 100, metric = 7.45% * 100;
 Minibatch[ 101- 200]: loss = 0.483706 * 100, metric = 7.39% * 100;
 Minibatch[ 201- 300]: loss = 0.495947 * 100, metric = 7.60% * 100;
 Minibatch[ 301- 400]: loss = 0.495846 * 100, metric = 7.57% * 100;
 Minibatch[ 401- 500]: loss = 0.481838 * 100, metric = 7.38% * 100;
 Minibatch[ 501- 600]: loss = 0.487813 * 100, metric = 7.56% * 100;
 Minibatch[ 601- 700]: loss = 0.475778 * 100, metric = 7.21% * 100;
 Minibatch[ 701- 800]: loss = 0.473246 * 100, metric = 7.12% * 100;
 Minibatch[ 801- 900]: loss = 0.476795 * 100, metric = 7.36% * 100;
 Minibatch[ 901-1000]: loss = 0.472099 * 100, metric = 7.06% * 100;
 Minibatch[1001-1100]: loss = 0.479279 * 100, metric = 7.15% * 100;
 Minibatch[1101-1200]: loss = 0.492364 * 100, metric = 7.61% * 100;
 Minibatch[1201-1300]: loss = 0.493309 * 100, metric = 7.62% * 100;
 Minibatch[1301-1400]: loss = 0.486729 * 100, metric = 7.39% * 100;
 Minibatch[1401-1500]: loss = 0.487055 * 100, metric = 7.50% * 100;
 Minibatch[1501-1600]: loss = 0.485950 * 100, metric = 7.35% * 100;
 Minibatch[1601-1700]: loss = 0.477701 * 100, metric = 7.29% * 100;
 Minibatch[1701-1800]: loss = 0.503773 * 100, metric = 7.78% * 100;
 Minibatch[1801-1900]: loss = 0.483437 * 100, metric = 7.31% * 100;
 Minibatch[1901-2000]: loss = 0.495623 * 100, metric = 7.78% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.485605 * 2000, metric = 7.42% * 2000 859.696s (  2.3 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.62% * 2000;
 Minibatch[   1- 100]: loss = 0.498692 * 100, metric = 7.82% * 100;
 Minibatch[ 101- 200]: loss = 0.484771 * 100, metric = 7.57% * 100;
 Minibatch[ 201- 300]: loss = 0.475409 * 100, metric = 7.23% * 100;
 Minibatch[ 301- 400]: loss = 0.479935 * 100, metric = 7.42% * 100;
 Minibatch[ 401- 500]: loss = 0.484934 * 100, metric = 7.43% * 100;
 Minibatch[ 501- 600]: loss = 0.479868 * 100, metric = 7.20% * 100;
 Minibatch[ 601- 700]: loss = 0.501314 * 100, metric = 7.61% * 100;
 Minibatch[ 701- 800]: loss = 0.489786 * 100, metric = 7.23% * 100;
 Minibatch[ 801- 900]: loss = 0.478202 * 100, metric = 7.21% * 100;
 Minibatch[ 901-1000]: loss = 0.470278 * 100, metric = 7.00% * 100;
 Minibatch[1001-1100]: loss = 0.483480 * 100, metric = 7.62% * 100;
 Minibatch[1101-1200]: loss = 0.465467 * 100, metric = 6.87% * 100;
 Minibatch[1201-1300]: loss = 0.491209 * 100, metric = 7.34% * 100;
 Minibatch[1301-1400]: loss = 0.475862 * 100, metric = 7.17% * 100;
 Minibatch[1401-1500]: loss = 0.488766 * 100, metric = 7.58% * 100;
 Minibatch[1501-1600]: loss = 0.495345 * 100, metric = 7.52% * 100;
 Minibatch[1601-1700]: loss = 0.482769 * 100, metric = 7.05% * 100;
 Minibatch[1701-1800]: loss = 0.479755 * 100, metric = 7.34% * 100;
 Minibatch[1801-1900]: loss = 0.483906 * 100, metric = 7.17% * 100;
 Minibatch[1901-2000]: loss = 0.494911 * 100, metric = 7.78% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.484233 * 2000, metric = 7.36% * 2000 878.902s (  2.3 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 14.35% * 2000;
 Minibatch[   1- 100]: loss = 0.478619 * 100, metric = 7.40% * 100;
 Minibatch[ 101- 200]: loss = 0.487895 * 100, metric = 7.56% * 100;
 Minibatch[ 201- 300]: loss = 0.471196 * 100, metric = 7.15% * 100;
 Minibatch[ 301- 400]: loss = 0.482308 * 100, metric = 7.37% * 100;
 Minibatch[ 401- 500]: loss = 0.464640 * 100, metric = 7.06% * 100;
 Minibatch[ 501- 600]: loss = 0.478811 * 100, metric = 7.20% * 100;
 Minibatch[ 601- 700]: loss = 0.483795 * 100, metric = 7.34% * 100;
 Minibatch[ 701- 800]: loss = 0.478533 * 100, metric = 7.21% * 100;
 Minibatch[ 801- 900]: loss = 0.468990 * 100, metric = 6.98% * 100;
 Minibatch[ 901-1000]: loss = 0.463682 * 100, metric = 7.07% * 100;
 Minibatch[1001-1100]: loss = 0.475987 * 100, metric = 7.33% * 100;
 Minibatch[1101-1200]: loss = 0.467650 * 100, metric = 7.16% * 100;
 Minibatch[1201-1300]: loss = 0.473923 * 100, metric = 7.29% * 100;
 Minibatch[1301-1400]: loss = 0.469855 * 100, metric = 7.10% * 100;
 Minibatch[1401-1500]: loss = 0.488954 * 100, metric = 7.50% * 100;
 Minibatch[1501-1600]: loss = 0.485515 * 100, metric = 6.99% * 100;
 Minibatch[1601-1700]: loss = 0.492485 * 100, metric = 7.54% * 100;
 Minibatch[1701-1800]: loss = 0.474033 * 100, metric = 7.21% * 100;
 Minibatch[1801-1900]: loss = 0.475452 * 100, metric = 7.10% * 100;
 Minibatch[1901-2000]: loss = 0.480444 * 100, metric = 7.17% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.477138 * 2000, metric = 7.24% * 2000 876.974s (  2.3 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.60% * 2000;
 Minibatch[   1- 100]: loss = 0.451518 * 100, metric = 6.61% * 100;
 Minibatch[ 101- 200]: loss = 0.468577 * 100, metric = 7.32% * 100;
 Minibatch[ 201- 300]: loss = 0.475773 * 100, metric = 7.23% * 100;
 Minibatch[ 301- 400]: loss = 0.464506 * 100, metric = 6.91% * 100;
 Minibatch[ 401- 500]: loss = 0.471472 * 100, metric = 6.92% * 100;
 Minibatch[ 501- 600]: loss = 0.449826 * 100, metric = 6.38% * 100;
 Minibatch[ 601- 700]: loss = 0.487422 * 100, metric = 7.48% * 100;
 Minibatch[ 701- 800]: loss = 0.451860 * 100, metric = 6.70% * 100;
 Minibatch[ 801- 900]: loss = 0.466579 * 100, metric = 7.13% * 100;
 Minibatch[ 901-1000]: loss = 0.450002 * 100, metric = 6.97% * 100;
 Minibatch[1001-1100]: loss = 0.485932 * 100, metric = 7.69% * 100;
 Minibatch[1101-1200]: loss = 0.467006 * 100, metric = 7.02% * 100;
 Minibatch[1201-1300]: loss = 0.463726 * 100, metric = 6.88% * 100;
 Minibatch[1301-1400]: loss = 0.475787 * 100, metric = 7.37% * 100;
 Minibatch[1401-1500]: loss = 0.466338 * 100, metric = 6.75% * 100;
 Minibatch[1501-1600]: loss = 0.472101 * 100, metric = 7.10% * 100;
 Minibatch[1601-1700]: loss = 0.471323 * 100, metric = 7.24% * 100;
 Minibatch[1701-1800]: loss = 0.466143 * 100, metric = 6.99% * 100;
 Minibatch[1801-1900]: loss = 0.477151 * 100, metric = 7.33% * 100;
 Minibatch[1901-2000]: loss = 0.459445 * 100, metric = 6.78% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.467124 * 2000, metric = 7.04% * 2000 877.057s (  2.3 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.04% * 2000;
 Minibatch[   1- 100]: loss = 0.463827 * 100, metric = 6.79% * 100;
 Minibatch[ 101- 200]: loss = 0.451105 * 100, metric = 6.66% * 100;
 Minibatch[ 201- 300]: loss = 0.480728 * 100, metric = 7.53% * 100;
 Minibatch[ 301- 400]: loss = 0.466072 * 100, metric = 6.90% * 100;
 Minibatch[ 401- 500]: loss = 0.462279 * 100, metric = 6.86% * 100;
 Minibatch[ 501- 600]: loss = 0.474109 * 100, metric = 7.16% * 100;
 Minibatch[ 601- 700]: loss = 0.468857 * 100, metric = 6.87% * 100;
 Minibatch[ 701- 800]: loss = 0.447306 * 100, metric = 6.70% * 100;
 Minibatch[ 801- 900]: loss = 0.452444 * 100, metric = 6.77% * 100;
 Minibatch[ 901-1000]: loss = 0.474110 * 100, metric = 7.09% * 100;
 Minibatch[1001-1100]: loss = 0.477069 * 100, metric = 7.31% * 100;
 Minibatch[1101-1200]: loss = 0.465193 * 100, metric = 6.87% * 100;
 Minibatch[1201-1300]: loss = 0.472004 * 100, metric = 7.24% * 100;
 Minibatch[1301-1400]: loss = 0.454072 * 100, metric = 6.81% * 100;
 Minibatch[1401-1500]: loss = 0.460619 * 100, metric = 6.72% * 100;
 Minibatch[1501-1600]: loss = 0.460452 * 100, metric = 6.82% * 100;
 Minibatch[1601-1700]: loss = 0.481044 * 100, metric = 7.50% * 100;
 Minibatch[1701-1800]: loss = 0.473892 * 100, metric = 7.12% * 100;
 Minibatch[1801-1900]: loss = 0.461663 * 100, metric = 6.98% * 100;
 Minibatch[1901-2000]: loss = 0.468778 * 100, metric = 7.01% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.465781 * 2000, metric = 6.98% * 2000 870.554s (  2.3 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.73% * 2000;
 Minibatch[   1- 100]: loss = 0.466341 * 100, metric = 7.08% * 100;
 Minibatch[ 101- 200]: loss = 0.469064 * 100, metric = 7.25% * 100;
 Minibatch[ 201- 300]: loss = 0.465057 * 100, metric = 7.07% * 100;
 Minibatch[ 301- 400]: loss = 0.469792 * 100, metric = 7.09% * 100;
 Minibatch[ 401- 500]: loss = 0.466562 * 100, metric = 7.29% * 100;
 Minibatch[ 501- 600]: loss = 0.454023 * 100, metric = 6.98% * 100;
 Minibatch[ 601- 700]: loss = 0.469622 * 100, metric = 7.14% * 100;
 Minibatch[ 701- 800]: loss = 0.474383 * 100, metric = 7.41% * 100;
 Minibatch[ 801- 900]: loss = 0.470854 * 100, metric = 7.04% * 100;
 Minibatch[ 901-1000]: loss = 0.448824 * 100, metric = 6.62% * 100;
 Minibatch[1001-1100]: loss = 0.459890 * 100, metric = 6.95% * 100;
 Minibatch[1101-1200]: loss = 0.486907 * 100, metric = 7.78% * 100;
 Minibatch[1201-1300]: loss = 0.478696 * 100, metric = 7.36% * 100;
 Minibatch[1301-1400]: loss = 0.470861 * 100, metric = 7.01% * 100;
 Minibatch[1401-1500]: loss = 0.464538 * 100, metric = 7.01% * 100;
 Minibatch[1501-1600]: loss = 0.449311 * 100, metric = 6.48% * 100;
 Minibatch[1601-1700]: loss = 0.463993 * 100, metric = 7.06% * 100;
 Minibatch[1701-1800]: loss = 0.464366 * 100, metric = 6.89% * 100;
 Minibatch[1801-1900]: loss = 0.467575 * 100, metric = 7.13% * 100;
 Minibatch[1901-2000]: loss = 0.464146 * 100, metric = 7.12% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.466240 * 2000, metric = 7.09% * 2000 863.863s (  2.3 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.44% * 2000;
 Minibatch[   1- 100]: loss = 0.470992 * 100, metric = 7.30% * 100;
 Minibatch[ 101- 200]: loss = 0.460762 * 100, metric = 7.26% * 100;
 Minibatch[ 201- 300]: loss = 0.456945 * 100, metric = 6.90% * 100;
 Minibatch[ 301- 400]: loss = 0.444138 * 100, metric = 6.57% * 100;
 Minibatch[ 401- 500]: loss = 0.465143 * 100, metric = 6.93% * 100;
 Minibatch[ 501- 600]: loss = 0.462834 * 100, metric = 7.00% * 100;
 Minibatch[ 601- 700]: loss = 0.462710 * 100, metric = 7.17% * 100;
 Minibatch[ 701- 800]: loss = 0.461572 * 100, metric = 7.03% * 100;
 Minibatch[ 801- 900]: loss = 0.471415 * 100, metric = 7.21% * 100;
 Minibatch[ 901-1000]: loss = 0.467200 * 100, metric = 6.96% * 100;
 Minibatch[1001-1100]: loss = 0.470267 * 100, metric = 7.15% * 100;
 Minibatch[1101-1200]: loss = 0.447865 * 100, metric = 6.79% * 100;
 Minibatch[1201-1300]: loss = 0.465457 * 100, metric = 6.98% * 100;
 Minibatch[1301-1400]: loss = 0.478123 * 100, metric = 7.35% * 100;
 Minibatch[1401-1500]: loss = 0.465735 * 100, metric = 7.05% * 100;
 Minibatch[1501-1600]: loss = 0.464114 * 100, metric = 7.07% * 100;
 Minibatch[1601-1700]: loss = 0.447036 * 100, metric = 6.61% * 100;
 Minibatch[1701-1800]: loss = 0.456224 * 100, metric = 6.99% * 100;
 Minibatch[1801-1900]: loss = 0.464174 * 100, metric = 6.90% * 100;
 Minibatch[1901-2000]: loss = 0.466200 * 100, metric = 7.09% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.462445 * 2000, metric = 7.02% * 2000 863.818s (  2.3 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 13.39% * 2000;
 Minibatch[   1- 100]: loss = 0.451898 * 100, metric = 6.70% * 100;
 Minibatch[ 101- 200]: loss = 0.466148 * 100, metric = 6.79% * 100;
 Minibatch[ 201- 300]: loss = 0.447605 * 100, metric = 6.53% * 100;
 Minibatch[ 301- 400]: loss = 0.452566 * 100, metric = 6.67% * 100;
 Minibatch[ 401- 500]: loss = 0.452450 * 100, metric = 6.97% * 100;
 Minibatch[ 501- 600]: loss = 0.470393 * 100, metric = 7.04% * 100;
 Minibatch[ 601- 700]: loss = 0.456964 * 100, metric = 6.92% * 100;
 Minibatch[ 701- 800]: loss = 0.465641 * 100, metric = 7.04% * 100;
 Minibatch[ 801- 900]: loss = 0.450132 * 100, metric = 6.72% * 100;
 Minibatch[ 901-1000]: loss = 0.442939 * 100, metric = 6.42% * 100;
 Minibatch[1001-1100]: loss = 0.463491 * 100, metric = 7.14% * 100;
 Minibatch[1101-1200]: loss = 0.458796 * 100, metric = 6.86% * 100;
 Minibatch[1201-1300]: loss = 0.453105 * 100, metric = 6.62% * 100;
 Minibatch[1301-1400]: loss = 0.464789 * 100, metric = 6.97% * 100;
 Minibatch[1401-1500]: loss = 0.469733 * 100, metric = 7.16% * 100;
 Minibatch[1501-1600]: loss = 0.455964 * 100, metric = 6.96% * 100;
 Minibatch[1601-1700]: loss = 0.451875 * 100, metric = 6.72% * 100;
 Minibatch[1701-1800]: loss = 0.468375 * 100, metric = 7.00% * 100;
 Minibatch[1801-1900]: loss = 0.456241 * 100, metric = 6.92% * 100;
 Minibatch[1901-2000]: loss = 0.458062 * 100, metric = 6.89% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.457858 * 2000, metric = 6.85% * 2000 858.652s (  2.3 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.46% * 2000;
 Minibatch[   1- 100]: loss = 0.446351 * 100, metric = 6.66% * 100;
 Minibatch[ 101- 200]: loss = 0.448451 * 100, metric = 6.66% * 100;
 Minibatch[ 201- 300]: loss = 0.462806 * 100, metric = 6.65% * 100;
 Minibatch[ 301- 400]: loss = 0.453874 * 100, metric = 6.97% * 100;
 Minibatch[ 401- 500]: loss = 0.455569 * 100, metric = 6.66% * 100;
 Minibatch[ 501- 600]: loss = 0.439282 * 100, metric = 6.68% * 100;
 Minibatch[ 601- 700]: loss = 0.465639 * 100, metric = 6.87% * 100;
 Minibatch[ 701- 800]: loss = 0.450222 * 100, metric = 6.59% * 100;
 Minibatch[ 801- 900]: loss = 0.457269 * 100, metric = 6.68% * 100;
 Minibatch[ 901-1000]: loss = 0.446396 * 100, metric = 6.62% * 100;
 Minibatch[1001-1100]: loss = 0.473149 * 100, metric = 7.25% * 100;
 Minibatch[1101-1200]: loss = 0.448547 * 100, metric = 6.68% * 100;
 Minibatch[1201-1300]: loss = 0.454825 * 100, metric = 6.70% * 100;
 Minibatch[1301-1400]: loss = 0.464203 * 100, metric = 7.01% * 100;
 Minibatch[1401-1500]: loss = 0.449857 * 100, metric = 6.67% * 100;
 Minibatch[1501-1600]: loss = 0.455535 * 100, metric = 6.86% * 100;
 Minibatch[1601-1700]: loss = 0.452990 * 100, metric = 6.87% * 100;
 Minibatch[1701-1800]: loss = 0.429620 * 100, metric = 6.28% * 100;
 Minibatch[1801-1900]: loss = 0.436204 * 100, metric = 6.19% * 100;
 Minibatch[1901-2000]: loss = 0.446450 * 100, metric = 6.80% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.451862 * 2000, metric = 6.72% * 2000 860.242s (  2.3 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 13.75% * 2000;
 Minibatch[   1- 100]: loss = 0.443729 * 100, metric = 6.86% * 100;
 Minibatch[ 101- 200]: loss = 0.448288 * 100, metric = 6.69% * 100;
 Minibatch[ 201- 300]: loss = 0.462773 * 100, metric = 7.08% * 100;
 Minibatch[ 301- 400]: loss = 0.458288 * 100, metric = 6.95% * 100;
 Minibatch[ 401- 500]: loss = 0.456618 * 100, metric = 6.83% * 100;
 Minibatch[ 501- 600]: loss = 0.454165 * 100, metric = 6.54% * 100;
 Minibatch[ 601- 700]: loss = 0.450148 * 100, metric = 6.64% * 100;
 Minibatch[ 701- 800]: loss = 0.445341 * 100, metric = 6.67% * 100;
 Minibatch[ 801- 900]: loss = 0.444413 * 100, metric = 6.56% * 100;
 Minibatch[ 901-1000]: loss = 0.446797 * 100, metric = 6.78% * 100;
 Minibatch[1001-1100]: loss = 0.451046 * 100, metric = 6.63% * 100;
 Minibatch[1101-1200]: loss = 0.467134 * 100, metric = 7.02% * 100;
 Minibatch[1201-1300]: loss = 0.452995 * 100, metric = 6.90% * 100;
 Minibatch[1301-1400]: loss = 0.437514 * 100, metric = 6.56% * 100;
 Minibatch[1401-1500]: loss = 0.437932 * 100, metric = 6.38% * 100;
 Minibatch[1501-1600]: loss = 0.448460 * 100, metric = 6.75% * 100;
 Minibatch[1601-1700]: loss = 0.445864 * 100, metric = 6.56% * 100;
 Minibatch[1701-1800]: loss = 0.448961 * 100, metric = 6.77% * 100;
 Minibatch[1801-1900]: loss = 0.449362 * 100, metric = 6.75% * 100;
 Minibatch[1901-2000]: loss = 0.445549 * 100, metric = 6.60% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.449769 * 2000, metric = 6.73% * 2000 862.572s (  2.3 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 14.37% * 2000;
 Minibatch[   1- 100]: loss = 0.433414 * 100, metric = 6.29% * 100;
 Minibatch[ 101- 200]: loss = 0.444858 * 100, metric = 6.68% * 100;
 Minibatch[ 201- 300]: loss = 0.440572 * 100, metric = 6.63% * 100;
 Minibatch[ 301- 400]: loss = 0.433156 * 100, metric = 6.27% * 100;
 Minibatch[ 401- 500]: loss = 0.436135 * 100, metric = 6.35% * 100;
 Minibatch[ 501- 600]: loss = 0.447768 * 100, metric = 6.71% * 100;
 Minibatch[ 601- 700]: loss = 0.446618 * 100, metric = 6.74% * 100;
 Minibatch[ 701- 800]: loss = 0.435685 * 100, metric = 6.63% * 100;
 Minibatch[ 801- 900]: loss = 0.439116 * 100, metric = 6.59% * 100;
 Minibatch[ 901-1000]: loss = 0.453815 * 100, metric = 6.83% * 100;
 Minibatch[1001-1100]: loss = 0.444323 * 100, metric = 6.67% * 100;
 Minibatch[1101-1200]: loss = 0.439456 * 100, metric = 6.45% * 100;
 Minibatch[1201-1300]: loss = 0.450272 * 100, metric = 6.60% * 100;
 Minibatch[1301-1400]: loss = 0.453737 * 100, metric = 6.84% * 100;
 Minibatch[1401-1500]: loss = 0.440315 * 100, metric = 6.56% * 100;
 Minibatch[1501-1600]: loss = 0.447217 * 100, metric = 6.70% * 100;
 Minibatch[1601-1700]: loss = 0.446714 * 100, metric = 6.65% * 100;
 Minibatch[1701-1800]: loss = 0.453074 * 100, metric = 6.72% * 100;
 Minibatch[1801-1900]: loss = 0.444156 * 100, metric = 6.43% * 100;
 Minibatch[1901-2000]: loss = 0.439215 * 100, metric = 6.27% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.443481 * 2000, metric = 6.58% * 2000 849.801s (  2.4 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 13.02% * 2000;
 Minibatch[   1- 100]: loss = 0.457486 * 100, metric = 7.02% * 100;
 Minibatch[ 101- 200]: loss = 0.425412 * 100, metric = 6.10% * 100;
 Minibatch[ 201- 300]: loss = 0.449305 * 100, metric = 6.64% * 100;
 Minibatch[ 301- 400]: loss = 0.448009 * 100, metric = 6.70% * 100;
 Minibatch[ 401- 500]: loss = 0.448646 * 100, metric = 6.67% * 100;
 Minibatch[ 501- 600]: loss = 0.426835 * 100, metric = 6.31% * 100;
 Minibatch[ 601- 700]: loss = 0.453694 * 100, metric = 6.72% * 100;
 Minibatch[ 701- 800]: loss = 0.427119 * 100, metric = 6.44% * 100;
 Minibatch[ 801- 900]: loss = 0.427213 * 100, metric = 6.27% * 100;
 Minibatch[ 901-1000]: loss = 0.438230 * 100, metric = 6.39% * 100;
 Minibatch[1001-1100]: loss = 0.439286 * 100, metric = 6.46% * 100;
 Minibatch[1101-1200]: loss = 0.436667 * 100, metric = 6.58% * 100;
 Minibatch[1201-1300]: loss = 0.454820 * 100, metric = 6.89% * 100;
 Minibatch[1301-1400]: loss = 0.445802 * 100, metric = 6.81% * 100;
 Minibatch[1401-1500]: loss = 0.427892 * 100, metric = 6.21% * 100;
 Minibatch[1501-1600]: loss = 0.453962 * 100, metric = 6.90% * 100;
 Minibatch[1601-1700]: loss = 0.434117 * 100, metric = 6.58% * 100;
 Minibatch[1701-1800]: loss = 0.436265 * 100, metric = 6.59% * 100;
 Minibatch[1801-1900]: loss = 0.447368 * 100, metric = 6.91% * 100;
 Minibatch[1901-2000]: loss = 0.438306 * 100, metric = 6.38% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.440822 * 2000, metric = 6.58% * 2000 835.545s (  2.4 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 13.89% * 2000;
 Minibatch[   1- 100]: loss = 0.431467 * 100, metric = 6.35% * 100;
 Minibatch[ 101- 200]: loss = 0.439855 * 100, metric = 6.73% * 100;
 Minibatch[ 201- 300]: loss = 0.438908 * 100, metric = 6.51% * 100;
 Minibatch[ 301- 400]: loss = 0.443431 * 100, metric = 6.38% * 100;
 Minibatch[ 401- 500]: loss = 0.444333 * 100, metric = 6.36% * 100;
 Minibatch[ 501- 600]: loss = 0.431987 * 100, metric = 6.44% * 100;
 Minibatch[ 601- 700]: loss = 0.447602 * 100, metric = 6.81% * 100;
 Minibatch[ 701- 800]: loss = 0.412685 * 100, metric = 5.71% * 100;
 Minibatch[ 801- 900]: loss = 0.430253 * 100, metric = 6.11% * 100;
 Minibatch[ 901-1000]: loss = 0.428800 * 100, metric = 6.13% * 100;
 Minibatch[1001-1100]: loss = 0.418215 * 100, metric = 5.91% * 100;
 Minibatch[1101-1200]: loss = 0.420233 * 100, metric = 6.16% * 100;
 Minibatch[1201-1300]: loss = 0.428916 * 100, metric = 6.22% * 100;
 Minibatch[1301-1400]: loss = 0.421411 * 100, metric = 6.22% * 100;
 Minibatch[1401-1500]: loss = 0.417114 * 100, metric = 6.06% * 100;
 Minibatch[1501-1600]: loss = 0.410336 * 100, metric = 5.74% * 100;
 Minibatch[1601-1700]: loss = 0.424984 * 100, metric = 6.04% * 100;
 Minibatch[1701-1800]: loss = 0.443449 * 100, metric = 6.73% * 100;
 Minibatch[1801-1900]: loss = 0.444384 * 100, metric = 6.50% * 100;
 Minibatch[1901-2000]: loss = 0.431839 * 100, metric = 6.26% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.430510 * 2000, metric = 6.27% * 2000 865.355s (  2.3 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 13.32% * 2000;
 Minibatch[   1- 100]: loss = 0.439413 * 100, metric = 6.26% * 100;
 Minibatch[ 101- 200]: loss = 0.425734 * 100, metric = 6.04% * 100;
 Minibatch[ 201- 300]: loss = 0.431219 * 100, metric = 6.27% * 100;
 Minibatch[ 301- 400]: loss = 0.446420 * 100, metric = 6.70% * 100;
 Minibatch[ 401- 500]: loss = 0.423813 * 100, metric = 6.09% * 100;
 Minibatch[ 501- 600]: loss = 0.420300 * 100, metric = 5.96% * 100;
 Minibatch[ 601- 700]: loss = 0.420007 * 100, metric = 5.89% * 100;
 Minibatch[ 701- 800]: loss = 0.411096 * 100, metric = 6.13% * 100;
 Minibatch[ 801- 900]: loss = 0.448898 * 100, metric = 6.82% * 100;
 Minibatch[ 901-1000]: loss = 0.425791 * 100, metric = 5.88% * 100;
 Minibatch[1001-1100]: loss = 0.411216 * 100, metric = 5.79% * 100;
 Minibatch[1101-1200]: loss = 0.445145 * 100, metric = 6.35% * 100;
 Minibatch[1201-1300]: loss = 0.425302 * 100, metric = 6.34% * 100;
 Minibatch[1301-1400]: loss = 0.422333 * 100, metric = 6.03% * 100;
 Minibatch[1401-1500]: loss = 0.437280 * 100, metric = 6.48% * 100;
 Minibatch[1501-1600]: loss = 0.426525 * 100, metric = 6.21% * 100;
 Minibatch[1601-1700]: loss = 0.418163 * 100, metric = 6.22% * 100;
 Minibatch[1701-1800]: loss = 0.428752 * 100, metric = 6.36% * 100;
 Minibatch[1801-1900]: loss = 0.425927 * 100, metric = 6.58% * 100;
 Minibatch[1901-2000]: loss = 0.433861 * 100, metric = 6.25% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.428360 * 2000, metric = 6.23% * 2000 862.986s (  2.3 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 14.05% * 2000;
 Minibatch[   1- 100]: loss = 0.416249 * 100, metric = 5.96% * 100;
 Minibatch[ 101- 200]: loss = 0.436185 * 100, metric = 6.62% * 100;
 Minibatch[ 201- 300]: loss = 0.421956 * 100, metric = 6.16% * 100;
 Minibatch[ 301- 400]: loss = 0.445944 * 100, metric = 6.66% * 100;
 Minibatch[ 401- 500]: loss = 0.430415 * 100, metric = 6.33% * 100;
 Minibatch[ 501- 600]: loss = 0.420422 * 100, metric = 6.19% * 100;
 Minibatch[ 601- 700]: loss = 0.412240 * 100, metric = 5.94% * 100;
 Minibatch[ 701- 800]: loss = 0.411914 * 100, metric = 5.98% * 100;
 Minibatch[ 801- 900]: loss = 0.422109 * 100, metric = 6.14% * 100;
 Minibatch[ 901-1000]: loss = 0.430879 * 100, metric = 6.20% * 100;
 Minibatch[1001-1100]: loss = 0.425176 * 100, metric = 6.32% * 100;
 Minibatch[1101-1200]: loss = 0.431819 * 100, metric = 6.20% * 100;
 Minibatch[1201-1300]: loss = 0.431882 * 100, metric = 6.34% * 100;
 Minibatch[1301-1400]: loss = 0.435574 * 100, metric = 6.38% * 100;
 Minibatch[1401-1500]: loss = 0.423515 * 100, metric = 6.08% * 100;
 Minibatch[1501-1600]: loss = 0.438210 * 100, metric = 6.28% * 100;
 Minibatch[1601-1700]: loss = 0.422408 * 100, metric = 6.16% * 100;
 Minibatch[1701-1800]: loss = 0.439252 * 100, metric = 6.42% * 100;
 Minibatch[1801-1900]: loss = 0.416513 * 100, metric = 5.95% * 100;
 Minibatch[1901-2000]: loss = 0.421312 * 100, metric = 5.95% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.426699 * 2000, metric = 6.21% * 2000 869.286s (  2.3 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 13.23% * 2000;
 Minibatch[   1- 100]: loss = 0.433704 * 100, metric = 6.37% * 100;
 Minibatch[ 101- 200]: loss = 0.420452 * 100, metric = 6.26% * 100;
 Minibatch[ 201- 300]: loss = 0.431008 * 100, metric = 6.27% * 100;
 Minibatch[ 301- 400]: loss = 0.428074 * 100, metric = 6.00% * 100;
 Minibatch[ 401- 500]: loss = 0.420175 * 100, metric = 6.24% * 100;
 Minibatch[ 501- 600]: loss = 0.416172 * 100, metric = 6.17% * 100;
 Minibatch[ 601- 700]: loss = 0.444394 * 100, metric = 6.42% * 100;
 Minibatch[ 701- 800]: loss = 0.438621 * 100, metric = 6.56% * 100;
 Minibatch[ 801- 900]: loss = 0.417961 * 100, metric = 5.80% * 100;
 Minibatch[ 901-1000]: loss = 0.429747 * 100, metric = 6.14% * 100;
 Minibatch[1001-1100]: loss = 0.433694 * 100, metric = 6.36% * 100;
 Minibatch[1101-1200]: loss = 0.428506 * 100, metric = 6.13% * 100;
 Minibatch[1201-1300]: loss = 0.405223 * 100, metric = 5.82% * 100;
 Minibatch[1301-1400]: loss = 0.415707 * 100, metric = 5.95% * 100;
 Minibatch[1401-1500]: loss = 0.431647 * 100, metric = 6.41% * 100;
 Minibatch[1501-1600]: loss = 0.429379 * 100, metric = 6.11% * 100;
 Minibatch[1601-1700]: loss = 0.422545 * 100, metric = 6.10% * 100;
 Minibatch[1701-1800]: loss = 0.435670 * 100, metric = 6.39% * 100;
 Minibatch[1801-1900]: loss = 0.412299 * 100, metric = 6.05% * 100;
 Minibatch[1901-2000]: loss = 0.429585 * 100, metric = 6.30% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.426228 * 2000, metric = 6.19% * 2000 869.935s (  2.3 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 13.01% * 2000;
 Minibatch[   1- 100]: loss = 0.425863 * 100, metric = 6.15% * 100;
 Minibatch[ 101- 200]: loss = 0.428899 * 100, metric = 6.18% * 100;
 Minibatch[ 201- 300]: loss = 0.417780 * 100, metric = 6.20% * 100;
 Minibatch[ 301- 400]: loss = 0.404918 * 100, metric = 5.91% * 100;
 Minibatch[ 401- 500]: loss = 0.423222 * 100, metric = 6.25% * 100;
 Minibatch[ 501- 600]: loss = 0.426328 * 100, metric = 6.33% * 100;
 Minibatch[ 601- 700]: loss = 0.435960 * 100, metric = 6.17% * 100;
 Minibatch[ 701- 800]: loss = 0.412210 * 100, metric = 5.95% * 100;
 Minibatch[ 801- 900]: loss = 0.416637 * 100, metric = 5.94% * 100;
 Minibatch[ 901-1000]: loss = 0.427280 * 100, metric = 6.30% * 100;
 Minibatch[1001-1100]: loss = 0.413771 * 100, metric = 6.17% * 100;
 Minibatch[1101-1200]: loss = 0.422457 * 100, metric = 6.11% * 100;
 Minibatch[1201-1300]: loss = 0.411402 * 100, metric = 5.99% * 100;
 Minibatch[1301-1400]: loss = 0.407286 * 100, metric = 6.07% * 100;
 Minibatch[1401-1500]: loss = 0.418976 * 100, metric = 6.10% * 100;
 Minibatch[1501-1600]: loss = 0.417072 * 100, metric = 6.26% * 100;
 Minibatch[1601-1700]: loss = 0.413396 * 100, metric = 6.02% * 100;
 Minibatch[1701-1800]: loss = 0.422643 * 100, metric = 6.34% * 100;
 Minibatch[1801-1900]: loss = 0.422181 * 100, metric = 6.03% * 100;
 Minibatch[1901-2000]: loss = 0.404188 * 100, metric = 5.68% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.418623 * 2000, metric = 6.11% * 2000 869.578s (  2.3 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 12.91% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
