Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.395398 * 100, metric = 26.11% * 100;
 Minibatch[ 101- 200]: loss = 1.139979 * 100, metric = 23.72% * 100;
 Minibatch[ 201- 300]: loss = 1.035932 * 100, metric = 22.58% * 100;
 Minibatch[ 301- 400]: loss = 1.022935 * 100, metric = 21.55% * 100;
 Minibatch[ 401- 500]: loss = 0.962420 * 100, metric = 20.35% * 100;
 Minibatch[ 501- 600]: loss = 0.934974 * 100, metric = 18.91% * 100;
 Minibatch[ 601- 700]: loss = 0.915090 * 100, metric = 18.49% * 100;
 Minibatch[ 701- 800]: loss = 0.872457 * 100, metric = 17.56% * 100;
 Minibatch[ 801- 900]: loss = 0.890880 * 100, metric = 17.54% * 100;
 Minibatch[ 901-1000]: loss = 0.912050 * 100, metric = 18.34% * 100;
 Minibatch[1001-1100]: loss = 0.892061 * 100, metric = 17.71% * 100;
 Minibatch[1101-1200]: loss = 0.878754 * 100, metric = 16.96% * 100;
 Minibatch[1201-1300]: loss = 0.875055 * 100, metric = 17.19% * 100;
 Minibatch[1301-1400]: loss = 0.844076 * 100, metric = 16.35% * 100;
 Minibatch[1401-1500]: loss = 0.864835 * 100, metric = 16.59% * 100;
 Minibatch[1501-1600]: loss = 0.834014 * 100, metric = 16.16% * 100;
 Minibatch[1601-1700]: loss = 0.831097 * 100, metric = 16.02% * 100;
 Minibatch[1701-1800]: loss = 0.847080 * 100, metric = 16.00% * 100;
 Minibatch[1801-1900]: loss = 0.840189 * 100, metric = 16.12% * 100;
 Minibatch[1901-2000]: loss = 0.812139 * 100, metric = 15.34% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.930071 * 2000, metric = 18.48% * 2000 995.657s (  2.0 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 24.57% * 2000;
0.8582279002591967
 Minibatch[   1- 100]: loss = 0.820493 * 100, metric = 15.44% * 100;
 Minibatch[ 101- 200]: loss = 0.825645 * 100, metric = 16.00% * 100;
 Minibatch[ 201- 300]: loss = 0.821197 * 100, metric = 15.26% * 100;
 Minibatch[ 301- 400]: loss = 0.821878 * 100, metric = 15.14% * 100;
 Minibatch[ 401- 500]: loss = 0.813164 * 100, metric = 15.21% * 100;
 Minibatch[ 501- 600]: loss = 0.830561 * 100, metric = 14.70% * 100;
 Minibatch[ 601- 700]: loss = 0.787851 * 100, metric = 14.61% * 100;
 Minibatch[ 701- 800]: loss = 0.808611 * 100, metric = 15.21% * 100;
 Minibatch[ 801- 900]: loss = 0.791923 * 100, metric = 14.77% * 100;
 Minibatch[ 901-1000]: loss = 0.775940 * 100, metric = 14.28% * 100;
 Minibatch[1001-1100]: loss = 0.793956 * 100, metric = 14.67% * 100;
 Minibatch[1101-1200]: loss = 0.790460 * 100, metric = 14.24% * 100;
 Minibatch[1201-1300]: loss = 0.778764 * 100, metric = 14.50% * 100;
 Minibatch[1301-1400]: loss = 0.783568 * 100, metric = 14.25% * 100;
 Minibatch[1401-1500]: loss = 0.767101 * 100, metric = 13.89% * 100;
 Minibatch[1501-1600]: loss = 0.754403 * 100, metric = 13.82% * 100;
 Minibatch[1601-1700]: loss = 0.774216 * 100, metric = 13.96% * 100;
 Minibatch[1701-1800]: loss = 0.773313 * 100, metric = 14.34% * 100;
 Minibatch[1801-1900]: loss = 0.781560 * 100, metric = 14.59% * 100;
 Minibatch[1901-2000]: loss = 0.745306 * 100, metric = 13.93% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.791996 * 2000, metric = 14.64% * 2000 964.261s (  2.1 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 22.66% * 2000;
0.7963243489414453
 Minibatch[   1- 100]: loss = 0.772808 * 100, metric = 14.24% * 100;
 Minibatch[ 101- 200]: loss = 0.770709 * 100, metric = 14.27% * 100;
 Minibatch[ 201- 300]: loss = 0.751785 * 100, metric = 13.76% * 100;
 Minibatch[ 301- 400]: loss = 0.772064 * 100, metric = 14.44% * 100;
 Minibatch[ 401- 500]: loss = 0.774336 * 100, metric = 14.60% * 100;
 Minibatch[ 501- 600]: loss = 0.756186 * 100, metric = 14.00% * 100;
 Minibatch[ 601- 700]: loss = 0.765659 * 100, metric = 13.87% * 100;
 Minibatch[ 701- 800]: loss = 0.739938 * 100, metric = 13.00% * 100;
 Minibatch[ 801- 900]: loss = 0.758990 * 100, metric = 14.02% * 100;
 Minibatch[ 901-1000]: loss = 0.737392 * 100, metric = 14.03% * 100;
 Minibatch[1001-1100]: loss = 0.747782 * 100, metric = 13.93% * 100;
 Minibatch[1101-1200]: loss = 0.740154 * 100, metric = 13.38% * 100;
 Minibatch[1201-1300]: loss = 0.738072 * 100, metric = 13.23% * 100;
 Minibatch[1301-1400]: loss = 0.752416 * 100, metric = 13.67% * 100;
 Minibatch[1401-1500]: loss = 0.749878 * 100, metric = 13.73% * 100;
 Minibatch[1501-1600]: loss = 0.738718 * 100, metric = 13.42% * 100;
 Minibatch[1601-1700]: loss = 0.726669 * 100, metric = 13.14% * 100;
 Minibatch[1701-1800]: loss = 0.741541 * 100, metric = 13.69% * 100;
 Minibatch[1801-1900]: loss = 0.728344 * 100, metric = 13.01% * 100;
 Minibatch[1901-2000]: loss = 0.725720 * 100, metric = 13.15% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.749458 * 2000, metric = 13.73% * 2000 962.591s (  2.1 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 20.67% * 2000;
0.7656742017567157
 Minibatch[   1- 100]: loss = 0.749539 * 100, metric = 13.29% * 100;
 Minibatch[ 101- 200]: loss = 0.712789 * 100, metric = 12.62% * 100;
 Minibatch[ 201- 300]: loss = 0.732676 * 100, metric = 13.21% * 100;
 Minibatch[ 301- 400]: loss = 0.689090 * 100, metric = 12.23% * 100;
 Minibatch[ 401- 500]: loss = 0.728555 * 100, metric = 13.06% * 100;
 Minibatch[ 501- 600]: loss = 0.705087 * 100, metric = 12.32% * 100;
 Minibatch[ 601- 700]: loss = 0.714499 * 100, metric = 12.99% * 100;
 Minibatch[ 701- 800]: loss = 0.713324 * 100, metric = 12.56% * 100;
 Minibatch[ 801- 900]: loss = 0.709867 * 100, metric = 12.93% * 100;
 Minibatch[ 901-1000]: loss = 0.715666 * 100, metric = 13.18% * 100;
 Minibatch[1001-1100]: loss = 0.715970 * 100, metric = 12.89% * 100;
 Minibatch[1101-1200]: loss = 0.689255 * 100, metric = 12.44% * 100;
 Minibatch[1201-1300]: loss = 0.691553 * 100, metric = 12.42% * 100;
 Minibatch[1301-1400]: loss = 0.716890 * 100, metric = 12.77% * 100;
 Minibatch[1401-1500]: loss = 0.722665 * 100, metric = 13.24% * 100;
 Minibatch[1501-1600]: loss = 0.686414 * 100, metric = 12.30% * 100;
 Minibatch[1601-1700]: loss = 0.717722 * 100, metric = 12.85% * 100;
 Minibatch[1701-1800]: loss = 0.721218 * 100, metric = 13.21% * 100;
 Minibatch[1801-1900]: loss = 0.700632 * 100, metric = 12.24% * 100;
 Minibatch[1901-2000]: loss = 0.689547 * 100, metric = 12.22% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.711148 * 2000, metric = 12.75% * 2000 985.751s (  2.0 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 21.52% * 2000;
 Minibatch[   1- 100]: loss = 0.719788 * 100, metric = 12.91% * 100;
 Minibatch[ 101- 200]: loss = 0.703342 * 100, metric = 12.49% * 100;
 Minibatch[ 201- 300]: loss = 0.690990 * 100, metric = 12.40% * 100;
 Minibatch[ 301- 400]: loss = 0.723101 * 100, metric = 13.09% * 100;
 Minibatch[ 401- 500]: loss = 0.685077 * 100, metric = 11.96% * 100;
 Minibatch[ 501- 600]: loss = 0.680137 * 100, metric = 11.83% * 100;
 Minibatch[ 601- 700]: loss = 0.688494 * 100, metric = 11.94% * 100;
 Minibatch[ 701- 800]: loss = 0.692032 * 100, metric = 12.30% * 100;
 Minibatch[ 801- 900]: loss = 0.669611 * 100, metric = 11.68% * 100;
 Minibatch[ 901-1000]: loss = 0.663142 * 100, metric = 11.72% * 100;
 Minibatch[1001-1100]: loss = 0.686564 * 100, metric = 12.19% * 100;
 Minibatch[1101-1200]: loss = 0.668393 * 100, metric = 11.88% * 100;
 Minibatch[1201-1300]: loss = 0.681442 * 100, metric = 12.07% * 100;
 Minibatch[1301-1400]: loss = 0.694270 * 100, metric = 12.26% * 100;
 Minibatch[1401-1500]: loss = 0.676655 * 100, metric = 12.19% * 100;
 Minibatch[1501-1600]: loss = 0.683777 * 100, metric = 12.17% * 100;
 Minibatch[1601-1700]: loss = 0.688870 * 100, metric = 12.43% * 100;
 Minibatch[1701-1800]: loss = 0.694607 * 100, metric = 12.61% * 100;
 Minibatch[1801-1900]: loss = 0.693651 * 100, metric = 12.36% * 100;
 Minibatch[1901-2000]: loss = 0.661362 * 100, metric = 11.44% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.687265 * 2000, metric = 12.20% * 2000 958.474s (  2.1 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.24% * 2000;
0.7491914171725511
 Minibatch[   1- 100]: loss = 0.669760 * 100, metric = 11.88% * 100;
 Minibatch[ 101- 200]: loss = 0.661543 * 100, metric = 11.83% * 100;
 Minibatch[ 201- 300]: loss = 0.676637 * 100, metric = 12.01% * 100;
 Minibatch[ 301- 400]: loss = 0.667961 * 100, metric = 11.62% * 100;
 Minibatch[ 401- 500]: loss = 0.643493 * 100, metric = 11.13% * 100;
 Minibatch[ 501- 600]: loss = 0.665654 * 100, metric = 11.76% * 100;
 Minibatch[ 601- 700]: loss = 0.645151 * 100, metric = 11.42% * 100;
 Minibatch[ 701- 800]: loss = 0.666696 * 100, metric = 11.83% * 100;
 Minibatch[ 801- 900]: loss = 0.663936 * 100, metric = 11.63% * 100;
 Minibatch[ 901-1000]: loss = 0.652150 * 100, metric = 11.58% * 100;
 Minibatch[1001-1100]: loss = 0.656257 * 100, metric = 11.22% * 100;
 Minibatch[1101-1200]: loss = 0.667531 * 100, metric = 11.69% * 100;
 Minibatch[1201-1300]: loss = 0.677840 * 100, metric = 11.93% * 100;
 Minibatch[1301-1400]: loss = 0.647759 * 100, metric = 11.23% * 100;
 Minibatch[1401-1500]: loss = 0.666723 * 100, metric = 11.98% * 100;
 Minibatch[1501-1600]: loss = 0.647917 * 100, metric = 11.14% * 100;
 Minibatch[1601-1700]: loss = 0.651350 * 100, metric = 11.37% * 100;
 Minibatch[1701-1800]: loss = 0.634779 * 100, metric = 10.87% * 100;
 Minibatch[1801-1900]: loss = 0.650092 * 100, metric = 11.52% * 100;
 Minibatch[1901-2000]: loss = 0.636898 * 100, metric = 10.92% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.657506 * 2000, metric = 11.53% * 2000 957.078s (  2.1 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 21.27% * 2000;
 Minibatch[   1- 100]: loss = 0.639532 * 100, metric = 11.14% * 100;
 Minibatch[ 101- 200]: loss = 0.646991 * 100, metric = 10.90% * 100;
 Minibatch[ 201- 300]: loss = 0.656467 * 100, metric = 11.52% * 100;
 Minibatch[ 301- 400]: loss = 0.642631 * 100, metric = 11.03% * 100;
 Minibatch[ 401- 500]: loss = 0.656278 * 100, metric = 11.22% * 100;
 Minibatch[ 501- 600]: loss = 0.632325 * 100, metric = 10.75% * 100;
 Minibatch[ 601- 700]: loss = 0.650414 * 100, metric = 10.92% * 100;
 Minibatch[ 701- 800]: loss = 0.653199 * 100, metric = 11.28% * 100;
 Minibatch[ 801- 900]: loss = 0.656215 * 100, metric = 11.43% * 100;
 Minibatch[ 901-1000]: loss = 0.648293 * 100, metric = 11.34% * 100;
 Minibatch[1001-1100]: loss = 0.650559 * 100, metric = 11.64% * 100;
 Minibatch[1101-1200]: loss = 0.624988 * 100, metric = 10.77% * 100;
 Minibatch[1201-1300]: loss = 0.646799 * 100, metric = 11.40% * 100;
 Minibatch[1301-1400]: loss = 0.630358 * 100, metric = 10.75% * 100;
 Minibatch[1401-1500]: loss = 0.627308 * 100, metric = 10.58% * 100;
 Minibatch[1501-1600]: loss = 0.636387 * 100, metric = 10.91% * 100;
 Minibatch[1601-1700]: loss = 0.640563 * 100, metric = 11.11% * 100;
 Minibatch[1701-1800]: loss = 0.629304 * 100, metric = 10.94% * 100;
 Minibatch[1801-1900]: loss = 0.637256 * 100, metric = 11.26% * 100;
 Minibatch[1901-2000]: loss = 0.639554 * 100, metric = 11.28% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.642271 * 2000, metric = 11.11% * 2000 958.945s (  2.1 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.53% * 2000;
0.7031129597947001
 Minibatch[   1- 100]: loss = 0.647624 * 100, metric = 11.36% * 100;
 Minibatch[ 101- 200]: loss = 0.636461 * 100, metric = 11.16% * 100;
 Minibatch[ 201- 300]: loss = 0.618638 * 100, metric = 10.92% * 100;
 Minibatch[ 301- 400]: loss = 0.624083 * 100, metric = 10.71% * 100;
 Minibatch[ 401- 500]: loss = 0.636457 * 100, metric = 11.34% * 100;
 Minibatch[ 501- 600]: loss = 0.653389 * 100, metric = 11.79% * 100;
 Minibatch[ 601- 700]: loss = 0.614845 * 100, metric = 10.59% * 100;
 Minibatch[ 701- 800]: loss = 0.636926 * 100, metric = 10.86% * 100;
 Minibatch[ 801- 900]: loss = 0.614422 * 100, metric = 10.29% * 100;
 Minibatch[ 901-1000]: loss = 0.600630 * 100, metric = 10.04% * 100;
 Minibatch[1001-1100]: loss = 0.604085 * 100, metric = 10.46% * 100;
 Minibatch[1101-1200]: loss = 0.604819 * 100, metric = 10.13% * 100;
 Minibatch[1201-1300]: loss = 0.622268 * 100, metric = 11.03% * 100;
 Minibatch[1301-1400]: loss = 0.641622 * 100, metric = 11.05% * 100;
 Minibatch[1401-1500]: loss = 0.621536 * 100, metric = 10.68% * 100;
 Minibatch[1501-1600]: loss = 0.625341 * 100, metric = 10.71% * 100;
 Minibatch[1601-1700]: loss = 0.613187 * 100, metric = 10.48% * 100;
 Minibatch[1701-1800]: loss = 0.616892 * 100, metric = 10.46% * 100;
 Minibatch[1801-1900]: loss = 0.622219 * 100, metric = 10.55% * 100;
 Minibatch[1901-2000]: loss = 0.622009 * 100, metric = 10.58% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.623873 * 2000, metric = 10.76% * 2000 959.252s (  2.1 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 18.25% * 2000;
0.6838339817598462
 Minibatch[   1- 100]: loss = 0.590654 * 100, metric = 9.87% * 100;
 Minibatch[ 101- 200]: loss = 0.634637 * 100, metric = 11.06% * 100;
 Minibatch[ 201- 300]: loss = 0.621282 * 100, metric = 10.61% * 100;
 Minibatch[ 301- 400]: loss = 0.635526 * 100, metric = 11.02% * 100;
 Minibatch[ 401- 500]: loss = 0.614738 * 100, metric = 10.53% * 100;
 Minibatch[ 501- 600]: loss = 0.610323 * 100, metric = 10.47% * 100;
 Minibatch[ 601- 700]: loss = 0.613543 * 100, metric = 10.49% * 100;
 Minibatch[ 701- 800]: loss = 0.598949 * 100, metric = 10.39% * 100;
 Minibatch[ 801- 900]: loss = 0.599349 * 100, metric = 10.19% * 100;
 Minibatch[ 901-1000]: loss = 0.612615 * 100, metric = 10.65% * 100;
 Minibatch[1001-1100]: loss = 0.580886 * 100, metric = 9.52% * 100;
 Minibatch[1101-1200]: loss = 0.603613 * 100, metric = 10.21% * 100;
 Minibatch[1201-1300]: loss = 0.608712 * 100, metric = 10.21% * 100;
 Minibatch[1301-1400]: loss = 0.599627 * 100, metric = 10.00% * 100;
 Minibatch[1401-1500]: loss = 0.611865 * 100, metric = 10.57% * 100;
 Minibatch[1501-1600]: loss = 0.616689 * 100, metric = 10.60% * 100;
 Minibatch[1601-1700]: loss = 0.606591 * 100, metric = 10.15% * 100;
 Minibatch[1701-1800]: loss = 0.590814 * 100, metric = 9.83% * 100;
 Minibatch[1801-1900]: loss = 0.589452 * 100, metric = 9.98% * 100;
 Minibatch[1901-2000]: loss = 0.608870 * 100, metric = 10.27% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.607437 * 2000, metric = 10.33% * 2000 954.124s (  2.1 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 16.92% * 2000;
0.6695359651967883
 Minibatch[   1- 100]: loss = 0.617188 * 100, metric = 10.86% * 100;
 Minibatch[ 101- 200]: loss = 0.590776 * 100, metric = 10.05% * 100;
 Minibatch[ 201- 300]: loss = 0.599673 * 100, metric = 10.23% * 100;
 Minibatch[ 301- 400]: loss = 0.590642 * 100, metric = 9.99% * 100;
 Minibatch[ 401- 500]: loss = 0.608848 * 100, metric = 10.24% * 100;
 Minibatch[ 501- 600]: loss = 0.586520 * 100, metric = 9.72% * 100;
 Minibatch[ 601- 700]: loss = 0.576917 * 100, metric = 9.55% * 100;
 Minibatch[ 701- 800]: loss = 0.568798 * 100, metric = 9.16% * 100;
 Minibatch[ 801- 900]: loss = 0.587852 * 100, metric = 9.84% * 100;
 Minibatch[ 901-1000]: loss = 0.598353 * 100, metric = 10.04% * 100;
 Minibatch[1001-1100]: loss = 0.589725 * 100, metric = 10.10% * 100;
 Minibatch[1101-1200]: loss = 0.594117 * 100, metric = 9.98% * 100;
 Minibatch[1201-1300]: loss = 0.585933 * 100, metric = 9.96% * 100;
 Minibatch[1301-1400]: loss = 0.592988 * 100, metric = 9.85% * 100;
 Minibatch[1401-1500]: loss = 0.570376 * 100, metric = 9.26% * 100;
 Minibatch[1501-1600]: loss = 0.582614 * 100, metric = 9.77% * 100;
 Minibatch[1601-1700]: loss = 0.582280 * 100, metric = 9.49% * 100;
 Minibatch[1701-1800]: loss = 0.594268 * 100, metric = 9.86% * 100;
 Minibatch[1801-1900]: loss = 0.596494 * 100, metric = 10.07% * 100;
 Minibatch[1901-2000]: loss = 0.578035 * 100, metric = 9.90% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.589620 * 2000, metric = 9.90% * 2000 953.668s (  2.1 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 16.06% * 2000;
0.6479842723608017
 Minibatch[   1- 100]: loss = 0.568915 * 100, metric = 9.28% * 100;
 Minibatch[ 101- 200]: loss = 0.580705 * 100, metric = 9.43% * 100;
 Minibatch[ 201- 300]: loss = 0.592877 * 100, metric = 10.02% * 100;
 Minibatch[ 301- 400]: loss = 0.580840 * 100, metric = 9.77% * 100;
 Minibatch[ 401- 500]: loss = 0.573376 * 100, metric = 9.61% * 100;
 Minibatch[ 501- 600]: loss = 0.587985 * 100, metric = 10.01% * 100;
 Minibatch[ 601- 700]: loss = 0.570540 * 100, metric = 9.30% * 100;
 Minibatch[ 701- 800]: loss = 0.585307 * 100, metric = 9.98% * 100;
 Minibatch[ 801- 900]: loss = 0.584235 * 100, metric = 9.53% * 100;
 Minibatch[ 901-1000]: loss = 0.583553 * 100, metric = 9.59% * 100;
 Minibatch[1001-1100]: loss = 0.572857 * 100, metric = 9.47% * 100;
 Minibatch[1101-1200]: loss = 0.581664 * 100, metric = 9.77% * 100;
 Minibatch[1201-1300]: loss = 0.571937 * 100, metric = 9.59% * 100;
 Minibatch[1301-1400]: loss = 0.555151 * 100, metric = 9.35% * 100;
 Minibatch[1401-1500]: loss = 0.584667 * 100, metric = 10.06% * 100;
 Minibatch[1501-1600]: loss = 0.568220 * 100, metric = 9.48% * 100;
 Minibatch[1601-1700]: loss = 0.576082 * 100, metric = 9.38% * 100;
 Minibatch[1701-1800]: loss = 0.590007 * 100, metric = 9.95% * 100;
 Minibatch[1801-1900]: loss = 0.572676 * 100, metric = 9.69% * 100;
 Minibatch[1901-2000]: loss = 0.571255 * 100, metric = 9.68% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.577642 * 2000, metric = 9.65% * 2000 957.659s (  2.1 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 17.53% * 2000;
 Minibatch[   1- 100]: loss = 0.556274 * 100, metric = 9.21% * 100;
 Minibatch[ 101- 200]: loss = 0.565958 * 100, metric = 9.17% * 100;
 Minibatch[ 201- 300]: loss = 0.564897 * 100, metric = 9.59% * 100;
 Minibatch[ 301- 400]: loss = 0.600736 * 100, metric = 10.20% * 100;
 Minibatch[ 401- 500]: loss = 0.567197 * 100, metric = 9.36% * 100;
 Minibatch[ 501- 600]: loss = 0.556478 * 100, metric = 8.99% * 100;
 Minibatch[ 601- 700]: loss = 0.558099 * 100, metric = 9.24% * 100;
 Minibatch[ 701- 800]: loss = 0.568946 * 100, metric = 9.39% * 100;
 Minibatch[ 801- 900]: loss = 0.560547 * 100, metric = 8.90% * 100;
 Minibatch[ 901-1000]: loss = 0.575728 * 100, metric = 9.55% * 100;
 Minibatch[1001-1100]: loss = 0.571121 * 100, metric = 9.60% * 100;
 Minibatch[1101-1200]: loss = 0.573972 * 100, metric = 9.67% * 100;
 Minibatch[1201-1300]: loss = 0.579274 * 100, metric = 9.53% * 100;
 Minibatch[1301-1400]: loss = 0.562297 * 100, metric = 9.08% * 100;
 Minibatch[1401-1500]: loss = 0.577394 * 100, metric = 9.84% * 100;
 Minibatch[1501-1600]: loss = 0.536018 * 100, metric = 8.73% * 100;
 Minibatch[1601-1700]: loss = 0.571544 * 100, metric = 9.64% * 100;
 Minibatch[1701-1800]: loss = 0.551481 * 100, metric = 8.90% * 100;
 Minibatch[1801-1900]: loss = 0.561869 * 100, metric = 9.40% * 100;
 Minibatch[1901-2000]: loss = 0.572455 * 100, metric = 9.45% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.566614 * 2000, metric = 9.37% * 2000 939.068s (  2.1 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 17.25% * 2000;
 Minibatch[   1- 100]: loss = 0.563517 * 100, metric = 9.06% * 100;
 Minibatch[ 101- 200]: loss = 0.559717 * 100, metric = 9.31% * 100;
 Minibatch[ 201- 300]: loss = 0.557400 * 100, metric = 9.31% * 100;
 Minibatch[ 301- 400]: loss = 0.568018 * 100, metric = 9.28% * 100;
 Minibatch[ 401- 500]: loss = 0.566453 * 100, metric = 9.76% * 100;
 Minibatch[ 501- 600]: loss = 0.580331 * 100, metric = 9.72% * 100;
 Minibatch[ 601- 700]: loss = 0.543271 * 100, metric = 8.68% * 100;
 Minibatch[ 701- 800]: loss = 0.551618 * 100, metric = 8.92% * 100;
 Minibatch[ 801- 900]: loss = 0.551534 * 100, metric = 8.95% * 100;
 Minibatch[ 901-1000]: loss = 0.567784 * 100, metric = 9.42% * 100;
 Minibatch[1001-1100]: loss = 0.572830 * 100, metric = 9.31% * 100;
 Minibatch[1101-1200]: loss = 0.561932 * 100, metric = 9.22% * 100;
 Minibatch[1201-1300]: loss = 0.564561 * 100, metric = 9.27% * 100;
 Minibatch[1301-1400]: loss = 0.551432 * 100, metric = 8.80% * 100;
 Minibatch[1401-1500]: loss = 0.543317 * 100, metric = 8.83% * 100;
 Minibatch[1501-1600]: loss = 0.542045 * 100, metric = 8.75% * 100;
 Minibatch[1601-1700]: loss = 0.537529 * 100, metric = 8.95% * 100;
 Minibatch[1701-1800]: loss = 0.547836 * 100, metric = 8.77% * 100;
 Minibatch[1801-1900]: loss = 0.538577 * 100, metric = 8.74% * 100;
 Minibatch[1901-2000]: loss = 0.555284 * 100, metric = 9.16% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.556249 * 2000, metric = 9.11% * 2000 892.210s (  2.2 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 18.76% * 2000;
 Minibatch[   1- 100]: loss = 0.543228 * 100, metric = 8.61% * 100;
 Minibatch[ 101- 200]: loss = 0.541016 * 100, metric = 8.61% * 100;
 Minibatch[ 201- 300]: loss = 0.560435 * 100, metric = 9.22% * 100;
 Minibatch[ 301- 400]: loss = 0.551416 * 100, metric = 9.02% * 100;
 Minibatch[ 401- 500]: loss = 0.544615 * 100, metric = 8.86% * 100;
 Minibatch[ 501- 600]: loss = 0.548714 * 100, metric = 8.84% * 100;
 Minibatch[ 601- 700]: loss = 0.543053 * 100, metric = 8.96% * 100;
 Minibatch[ 701- 800]: loss = 0.560596 * 100, metric = 9.22% * 100;
 Minibatch[ 801- 900]: loss = 0.561658 * 100, metric = 9.46% * 100;
 Minibatch[ 901-1000]: loss = 0.557756 * 100, metric = 9.29% * 100;
 Minibatch[1001-1100]: loss = 0.558990 * 100, metric = 9.26% * 100;
 Minibatch[1101-1200]: loss = 0.545562 * 100, metric = 9.06% * 100;
 Minibatch[1201-1300]: loss = 0.523073 * 100, metric = 8.32% * 100;
 Minibatch[1301-1400]: loss = 0.555120 * 100, metric = 9.57% * 100;
 Minibatch[1401-1500]: loss = 0.553230 * 100, metric = 9.25% * 100;
 Minibatch[1501-1600]: loss = 0.540663 * 100, metric = 8.82% * 100;
 Minibatch[1601-1700]: loss = 0.550204 * 100, metric = 9.04% * 100;
 Minibatch[1701-1800]: loss = 0.548906 * 100, metric = 8.53% * 100;
 Minibatch[1801-1900]: loss = 0.547904 * 100, metric = 8.80% * 100;
 Minibatch[1901-2000]: loss = 0.554780 * 100, metric = 8.97% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.549546 * 2000, metric = 8.99% * 2000 894.462s (  2.2 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 18.26% * 2000;
 Minibatch[   1- 100]: loss = 0.537980 * 100, metric = 8.59% * 100;
 Minibatch[ 101- 200]: loss = 0.554724 * 100, metric = 9.36% * 100;
 Minibatch[ 201- 300]: loss = 0.545921 * 100, metric = 8.68% * 100;
 Minibatch[ 301- 400]: loss = 0.537241 * 100, metric = 8.57% * 100;
 Minibatch[ 401- 500]: loss = 0.532568 * 100, metric = 8.61% * 100;
 Minibatch[ 501- 600]: loss = 0.530186 * 100, metric = 8.44% * 100;
 Minibatch[ 601- 700]: loss = 0.518586 * 100, metric = 8.45% * 100;
 Minibatch[ 701- 800]: loss = 0.547752 * 100, metric = 9.00% * 100;
 Minibatch[ 801- 900]: loss = 0.554936 * 100, metric = 9.55% * 100;
 Minibatch[ 901-1000]: loss = 0.547669 * 100, metric = 9.02% * 100;
 Minibatch[1001-1100]: loss = 0.546141 * 100, metric = 8.70% * 100;
 Minibatch[1101-1200]: loss = 0.528315 * 100, metric = 8.55% * 100;
 Minibatch[1201-1300]: loss = 0.526896 * 100, metric = 8.19% * 100;
 Minibatch[1301-1400]: loss = 0.542360 * 100, metric = 8.88% * 100;
 Minibatch[1401-1500]: loss = 0.509144 * 100, metric = 7.97% * 100;
 Minibatch[1501-1600]: loss = 0.529515 * 100, metric = 8.61% * 100;
 Minibatch[1601-1700]: loss = 0.541445 * 100, metric = 8.72% * 100;
 Minibatch[1701-1800]: loss = 0.519728 * 100, metric = 8.07% * 100;
 Minibatch[1801-1900]: loss = 0.531524 * 100, metric = 8.51% * 100;
 Minibatch[1901-2000]: loss = 0.532800 * 100, metric = 8.87% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.535772 * 2000, metric = 8.67% * 2000 877.369s (  2.3 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 15.78% * 2000;
 Minibatch[   1- 100]: loss = 0.550694 * 100, metric = 9.40% * 100;
 Minibatch[ 101- 200]: loss = 0.542768 * 100, metric = 8.84% * 100;
 Minibatch[ 201- 300]: loss = 0.543331 * 100, metric = 9.12% * 100;
 Minibatch[ 301- 400]: loss = 0.543012 * 100, metric = 8.83% * 100;
 Minibatch[ 401- 500]: loss = 0.520942 * 100, metric = 8.41% * 100;
 Minibatch[ 501- 600]: loss = 0.531184 * 100, metric = 8.67% * 100;
 Minibatch[ 601- 700]: loss = 0.527494 * 100, metric = 8.62% * 100;
 Minibatch[ 701- 800]: loss = 0.524750 * 100, metric = 8.52% * 100;
 Minibatch[ 801- 900]: loss = 0.512599 * 100, metric = 8.23% * 100;
 Minibatch[ 901-1000]: loss = 0.539480 * 100, metric = 8.80% * 100;
 Minibatch[1001-1100]: loss = 0.515453 * 100, metric = 8.38% * 100;
 Minibatch[1101-1200]: loss = 0.525120 * 100, metric = 8.44% * 100;
 Minibatch[1201-1300]: loss = 0.518688 * 100, metric = 8.16% * 100;
 Minibatch[1301-1400]: loss = 0.520868 * 100, metric = 8.41% * 100;
 Minibatch[1401-1500]: loss = 0.517115 * 100, metric = 8.65% * 100;
 Minibatch[1501-1600]: loss = 0.520687 * 100, metric = 8.46% * 100;
 Minibatch[1601-1700]: loss = 0.534761 * 100, metric = 8.78% * 100;
 Minibatch[1701-1800]: loss = 0.546009 * 100, metric = 8.94% * 100;
 Minibatch[1801-1900]: loss = 0.537494 * 100, metric = 8.86% * 100;
 Minibatch[1901-2000]: loss = 0.515311 * 100, metric = 8.31% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.529388 * 2000, metric = 8.64% * 2000 879.767s (  2.3 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 15.81% * 2000;
0.6452774926945567
 Minibatch[   1- 100]: loss = 0.506773 * 100, metric = 8.08% * 100;
 Minibatch[ 101- 200]: loss = 0.537803 * 100, metric = 8.71% * 100;
 Minibatch[ 201- 300]: loss = 0.533622 * 100, metric = 8.62% * 100;
 Minibatch[ 301- 400]: loss = 0.530772 * 100, metric = 8.55% * 100;
 Minibatch[ 401- 500]: loss = 0.538040 * 100, metric = 8.56% * 100;
 Minibatch[ 501- 600]: loss = 0.521453 * 100, metric = 8.30% * 100;
 Minibatch[ 601- 700]: loss = 0.500671 * 100, metric = 7.87% * 100;
 Minibatch[ 701- 800]: loss = 0.523035 * 100, metric = 8.44% * 100;
 Minibatch[ 801- 900]: loss = 0.521448 * 100, metric = 8.38% * 100;
 Minibatch[ 901-1000]: loss = 0.511762 * 100, metric = 8.10% * 100;
 Minibatch[1001-1100]: loss = 0.512073 * 100, metric = 8.18% * 100;
 Minibatch[1101-1200]: loss = 0.533709 * 100, metric = 8.53% * 100;
 Minibatch[1201-1300]: loss = 0.534592 * 100, metric = 8.56% * 100;
 Minibatch[1301-1400]: loss = 0.502973 * 100, metric = 7.97% * 100;
 Minibatch[1401-1500]: loss = 0.522676 * 100, metric = 8.47% * 100;
 Minibatch[1501-1600]: loss = 0.518795 * 100, metric = 8.24% * 100;
 Minibatch[1601-1700]: loss = 0.520983 * 100, metric = 8.24% * 100;
 Minibatch[1701-1800]: loss = 0.508038 * 100, metric = 8.04% * 100;
 Minibatch[1801-1900]: loss = 0.531647 * 100, metric = 8.61% * 100;
 Minibatch[1901-2000]: loss = 0.533862 * 100, metric = 8.49% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.522236 * 2000, metric = 8.35% * 2000 880.217s (  2.3 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 14.98% * 2000;
0.6323853398263455
 Minibatch[   1- 100]: loss = 0.505151 * 100, metric = 7.98% * 100;
 Minibatch[ 101- 200]: loss = 0.530485 * 100, metric = 8.63% * 100;
 Minibatch[ 201- 300]: loss = 0.503147 * 100, metric = 8.04% * 100;
 Minibatch[ 301- 400]: loss = 0.520075 * 100, metric = 8.25% * 100;
 Minibatch[ 401- 500]: loss = 0.495539 * 100, metric = 7.75% * 100;
 Minibatch[ 501- 600]: loss = 0.504448 * 100, metric = 8.18% * 100;
 Minibatch[ 601- 700]: loss = 0.520343 * 100, metric = 8.21% * 100;
 Minibatch[ 701- 800]: loss = 0.507115 * 100, metric = 8.10% * 100;
 Minibatch[ 801- 900]: loss = 0.513984 * 100, metric = 8.31% * 100;
 Minibatch[ 901-1000]: loss = 0.522389 * 100, metric = 8.26% * 100;
 Minibatch[1001-1100]: loss = 0.525848 * 100, metric = 8.50% * 100;
 Minibatch[1101-1200]: loss = 0.523094 * 100, metric = 8.36% * 100;
 Minibatch[1201-1300]: loss = 0.525522 * 100, metric = 8.67% * 100;
 Minibatch[1301-1400]: loss = 0.527098 * 100, metric = 8.57% * 100;
 Minibatch[1401-1500]: loss = 0.498827 * 100, metric = 7.91% * 100;
 Minibatch[1501-1600]: loss = 0.516039 * 100, metric = 8.11% * 100;
 Minibatch[1601-1700]: loss = 0.492442 * 100, metric = 7.54% * 100;
 Minibatch[1701-1800]: loss = 0.500740 * 100, metric = 7.82% * 100;
 Minibatch[1801-1900]: loss = 0.496996 * 100, metric = 8.00% * 100;
 Minibatch[1901-2000]: loss = 0.500653 * 100, metric = 7.93% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.511497 * 2000, metric = 8.16% * 2000 896.067s (  2.2 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.09% * 2000;
0.6256315444931387
 Minibatch[   1- 100]: loss = 0.515977 * 100, metric = 8.52% * 100;
 Minibatch[ 101- 200]: loss = 0.528338 * 100, metric = 8.49% * 100;
 Minibatch[ 201- 300]: loss = 0.491398 * 100, metric = 7.66% * 100;
 Minibatch[ 301- 400]: loss = 0.507279 * 100, metric = 7.98% * 100;
 Minibatch[ 401- 500]: loss = 0.509718 * 100, metric = 7.98% * 100;
 Minibatch[ 501- 600]: loss = 0.495705 * 100, metric = 7.51% * 100;
 Minibatch[ 601- 700]: loss = 0.512738 * 100, metric = 8.18% * 100;
 Minibatch[ 701- 800]: loss = 0.484870 * 100, metric = 7.56% * 100;
 Minibatch[ 801- 900]: loss = 0.533267 * 100, metric = 8.87% * 100;
 Minibatch[ 901-1000]: loss = 0.494674 * 100, metric = 7.62% * 100;
 Minibatch[1001-1100]: loss = 0.516691 * 100, metric = 8.33% * 100;
 Minibatch[1101-1200]: loss = 0.504535 * 100, metric = 8.21% * 100;
 Minibatch[1201-1300]: loss = 0.500963 * 100, metric = 7.88% * 100;
 Minibatch[1301-1400]: loss = 0.488786 * 100, metric = 7.80% * 100;
 Minibatch[1401-1500]: loss = 0.506963 * 100, metric = 8.19% * 100;
 Minibatch[1501-1600]: loss = 0.510668 * 100, metric = 8.05% * 100;
 Minibatch[1601-1700]: loss = 0.498120 * 100, metric = 7.93% * 100;
 Minibatch[1701-1800]: loss = 0.475139 * 100, metric = 7.36% * 100;
 Minibatch[1801-1900]: loss = 0.502020 * 100, metric = 8.08% * 100;
 Minibatch[1901-2000]: loss = 0.485074 * 100, metric = 7.52% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.503146 * 2000, metric = 7.99% * 2000 896.432s (  2.2 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 15.89% * 2000;
 Minibatch[   1- 100]: loss = 0.493255 * 100, metric = 7.52% * 100;
 Minibatch[ 101- 200]: loss = 0.502828 * 100, metric = 7.62% * 100;
 Minibatch[ 201- 300]: loss = 0.488473 * 100, metric = 7.31% * 100;
 Minibatch[ 301- 400]: loss = 0.510249 * 100, metric = 7.67% * 100;
 Minibatch[ 401- 500]: loss = 0.492044 * 100, metric = 7.81% * 100;
 Minibatch[ 501- 600]: loss = 0.496942 * 100, metric = 7.92% * 100;
 Minibatch[ 601- 700]: loss = 0.496277 * 100, metric = 7.95% * 100;
 Minibatch[ 701- 800]: loss = 0.500757 * 100, metric = 8.06% * 100;
 Minibatch[ 801- 900]: loss = 0.504143 * 100, metric = 8.06% * 100;
 Minibatch[ 901-1000]: loss = 0.513663 * 100, metric = 8.22% * 100;
 Minibatch[1001-1100]: loss = 0.472007 * 100, metric = 7.44% * 100;
 Minibatch[1101-1200]: loss = 0.489761 * 100, metric = 7.50% * 100;
 Minibatch[1201-1300]: loss = 0.493354 * 100, metric = 7.70% * 100;
 Minibatch[1301-1400]: loss = 0.497759 * 100, metric = 7.93% * 100;
 Minibatch[1401-1500]: loss = 0.484548 * 100, metric = 7.75% * 100;
 Minibatch[1501-1600]: loss = 0.500192 * 100, metric = 7.86% * 100;
 Minibatch[1601-1700]: loss = 0.488237 * 100, metric = 7.55% * 100;
 Minibatch[1701-1800]: loss = 0.505219 * 100, metric = 8.20% * 100;
 Minibatch[1801-1900]: loss = 0.492705 * 100, metric = 7.70% * 100;
 Minibatch[1901-2000]: loss = 0.489582 * 100, metric = 7.77% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.495600 * 2000, metric = 7.78% * 2000 912.071s (  2.2 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 15.57% * 2000;
 Minibatch[   1- 100]: loss = 0.497069 * 100, metric = 7.90% * 100;
 Minibatch[ 101- 200]: loss = 0.496687 * 100, metric = 7.76% * 100;
 Minibatch[ 201- 300]: loss = 0.487649 * 100, metric = 7.70% * 100;
 Minibatch[ 301- 400]: loss = 0.494878 * 100, metric = 8.13% * 100;
 Minibatch[ 401- 500]: loss = 0.475383 * 100, metric = 7.32% * 100;
 Minibatch[ 501- 600]: loss = 0.484190 * 100, metric = 7.45% * 100;
 Minibatch[ 601- 700]: loss = 0.482107 * 100, metric = 7.65% * 100;
 Minibatch[ 701- 800]: loss = 0.453792 * 100, metric = 7.10% * 100;
 Minibatch[ 801- 900]: loss = 0.488242 * 100, metric = 7.53% * 100;
 Minibatch[ 901-1000]: loss = 0.471638 * 100, metric = 7.34% * 100;
 Minibatch[1001-1100]: loss = 0.477662 * 100, metric = 7.54% * 100;
 Minibatch[1101-1200]: loss = 0.476411 * 100, metric = 7.33% * 100;
 Minibatch[1201-1300]: loss = 0.485779 * 100, metric = 7.59% * 100;
 Minibatch[1301-1400]: loss = 0.467012 * 100, metric = 7.24% * 100;
 Minibatch[1401-1500]: loss = 0.482667 * 100, metric = 7.56% * 100;
 Minibatch[1501-1600]: loss = 0.492330 * 100, metric = 8.06% * 100;
 Minibatch[1601-1700]: loss = 0.467542 * 100, metric = 7.27% * 100;
 Minibatch[1701-1800]: loss = 0.471880 * 100, metric = 7.14% * 100;
 Minibatch[1801-1900]: loss = 0.497405 * 100, metric = 7.98% * 100;
 Minibatch[1901-2000]: loss = 0.463647 * 100, metric = 7.07% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.480698 * 2000, metric = 7.53% * 2000 910.837s (  2.2 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 14.26% * 2000;
0.6150249475911259
 Minibatch[   1- 100]: loss = 0.480273 * 100, metric = 7.63% * 100;
 Minibatch[ 101- 200]: loss = 0.479189 * 100, metric = 7.46% * 100;
 Minibatch[ 201- 300]: loss = 0.489103 * 100, metric = 7.71% * 100;
 Minibatch[ 301- 400]: loss = 0.471407 * 100, metric = 7.44% * 100;
 Minibatch[ 401- 500]: loss = 0.465457 * 100, metric = 7.45% * 100;
 Minibatch[ 501- 600]: loss = 0.484447 * 100, metric = 7.49% * 100;
 Minibatch[ 601- 700]: loss = 0.471006 * 100, metric = 7.28% * 100;
 Minibatch[ 701- 800]: loss = 0.471529 * 100, metric = 7.33% * 100;
 Minibatch[ 801- 900]: loss = 0.488324 * 100, metric = 7.71% * 100;
 Minibatch[ 901-1000]: loss = 0.488830 * 100, metric = 7.52% * 100;
 Minibatch[1001-1100]: loss = 0.459841 * 100, metric = 7.26% * 100;
 Minibatch[1101-1200]: loss = 0.453926 * 100, metric = 6.93% * 100;
 Minibatch[1201-1300]: loss = 0.471723 * 100, metric = 7.39% * 100;
 Minibatch[1301-1400]: loss = 0.480198 * 100, metric = 7.52% * 100;
 Minibatch[1401-1500]: loss = 0.469852 * 100, metric = 7.17% * 100;
 Minibatch[1501-1600]: loss = 0.468398 * 100, metric = 7.28% * 100;
 Minibatch[1601-1700]: loss = 0.473092 * 100, metric = 7.30% * 100;
 Minibatch[1701-1800]: loss = 0.469820 * 100, metric = 7.17% * 100;
 Minibatch[1801-1900]: loss = 0.468742 * 100, metric = 7.42% * 100;
 Minibatch[1901-2000]: loss = 0.470914 * 100, metric = 7.14% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.473803 * 2000, metric = 7.38% * 2000 892.253s (  2.2 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 15.12% * 2000;
 Minibatch[   1- 100]: loss = 0.478234 * 100, metric = 7.36% * 100;
 Minibatch[ 101- 200]: loss = 0.487332 * 100, metric = 7.73% * 100;
 Minibatch[ 201- 300]: loss = 0.472840 * 100, metric = 7.42% * 100;
 Minibatch[ 301- 400]: loss = 0.488439 * 100, metric = 7.80% * 100;
 Minibatch[ 401- 500]: loss = 0.482173 * 100, metric = 7.46% * 100;
 Minibatch[ 501- 600]: loss = 0.469161 * 100, metric = 7.28% * 100;
 Minibatch[ 601- 700]: loss = 0.476291 * 100, metric = 7.20% * 100;
 Minibatch[ 701- 800]: loss = 0.461102 * 100, metric = 6.94% * 100;
 Minibatch[ 801- 900]: loss = 0.458694 * 100, metric = 7.31% * 100;
 Minibatch[ 901-1000]: loss = 0.484624 * 100, metric = 7.54% * 100;
 Minibatch[1001-1100]: loss = 0.459697 * 100, metric = 6.94% * 100;
 Minibatch[1101-1200]: loss = 0.472843 * 100, metric = 7.43% * 100;
 Minibatch[1201-1300]: loss = 0.479307 * 100, metric = 7.54% * 100;
 Minibatch[1301-1400]: loss = 0.472422 * 100, metric = 7.52% * 100;
 Minibatch[1401-1500]: loss = 0.464424 * 100, metric = 7.31% * 100;
 Minibatch[1501-1600]: loss = 0.465781 * 100, metric = 7.21% * 100;
 Minibatch[1601-1700]: loss = 0.470173 * 100, metric = 7.50% * 100;
 Minibatch[1701-1800]: loss = 0.477509 * 100, metric = 7.59% * 100;
 Minibatch[1801-1900]: loss = 0.479704 * 100, metric = 7.82% * 100;
 Minibatch[1901-2000]: loss = 0.478376 * 100, metric = 7.46% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.473956 * 2000, metric = 7.42% * 2000 882.006s (  2.3 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 15.17% * 2000;
 Minibatch[   1- 100]: loss = 0.453569 * 100, metric = 7.07% * 100;
 Minibatch[ 101- 200]: loss = 0.476052 * 100, metric = 7.53% * 100;
 Minibatch[ 201- 300]: loss = 0.463238 * 100, metric = 7.42% * 100;
 Minibatch[ 301- 400]: loss = 0.467363 * 100, metric = 7.21% * 100;
 Minibatch[ 401- 500]: loss = 0.465884 * 100, metric = 7.35% * 100;
 Minibatch[ 501- 600]: loss = 0.457085 * 100, metric = 7.06% * 100;
 Minibatch[ 601- 700]: loss = 0.468103 * 100, metric = 7.15% * 100;
 Minibatch[ 701- 800]: loss = 0.461209 * 100, metric = 7.10% * 100;
 Minibatch[ 801- 900]: loss = 0.475625 * 100, metric = 7.56% * 100;
 Minibatch[ 901-1000]: loss = 0.466416 * 100, metric = 7.19% * 100;
 Minibatch[1001-1100]: loss = 0.471298 * 100, metric = 7.25% * 100;
 Minibatch[1101-1200]: loss = 0.482342 * 100, metric = 7.59% * 100;
 Minibatch[1201-1300]: loss = 0.475749 * 100, metric = 7.36% * 100;
 Minibatch[1301-1400]: loss = 0.467929 * 100, metric = 6.94% * 100;
 Minibatch[1401-1500]: loss = 0.464910 * 100, metric = 7.07% * 100;
 Minibatch[1501-1600]: loss = 0.475150 * 100, metric = 7.42% * 100;
 Minibatch[1601-1700]: loss = 0.450947 * 100, metric = 6.79% * 100;
 Minibatch[1701-1800]: loss = 0.458148 * 100, metric = 6.97% * 100;
 Minibatch[1801-1900]: loss = 0.468792 * 100, metric = 7.29% * 100;
 Minibatch[1901-2000]: loss = 0.468619 * 100, metric = 7.38% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.466921 * 2000, metric = 7.23% * 2000 890.815s (  2.2 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.65% * 2000;
 Minibatch[   1- 100]: loss = 0.463667 * 100, metric = 7.16% * 100;
 Minibatch[ 101- 200]: loss = 0.458017 * 100, metric = 7.36% * 100;
 Minibatch[ 201- 300]: loss = 0.477077 * 100, metric = 7.74% * 100;
 Minibatch[ 301- 400]: loss = 0.472076 * 100, metric = 7.21% * 100;
 Minibatch[ 401- 500]: loss = 0.461804 * 100, metric = 7.29% * 100;
 Minibatch[ 501- 600]: loss = 0.469227 * 100, metric = 7.24% * 100;
 Minibatch[ 601- 700]: loss = 0.466889 * 100, metric = 7.23% * 100;
 Minibatch[ 701- 800]: loss = 0.452439 * 100, metric = 6.86% * 100;
 Minibatch[ 801- 900]: loss = 0.460976 * 100, metric = 7.10% * 100;
 Minibatch[ 901-1000]: loss = 0.459647 * 100, metric = 6.96% * 100;
 Minibatch[1001-1100]: loss = 0.459318 * 100, metric = 6.98% * 100;
 Minibatch[1101-1200]: loss = 0.470677 * 100, metric = 7.28% * 100;
 Minibatch[1201-1300]: loss = 0.481398 * 100, metric = 7.53% * 100;
 Minibatch[1301-1400]: loss = 0.455887 * 100, metric = 6.81% * 100;
 Minibatch[1401-1500]: loss = 0.454454 * 100, metric = 6.91% * 100;
 Minibatch[1501-1600]: loss = 0.472887 * 100, metric = 7.57% * 100;
 Minibatch[1601-1700]: loss = 0.457943 * 100, metric = 7.04% * 100;
 Minibatch[1701-1800]: loss = 0.465654 * 100, metric = 7.25% * 100;
 Minibatch[1801-1900]: loss = 0.456604 * 100, metric = 7.00% * 100;
 Minibatch[1901-2000]: loss = 0.446967 * 100, metric = 6.88% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.463180 * 2000, metric = 7.17% * 2000 881.045s (  2.3 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.69% * 2000;
 Minibatch[   1- 100]: loss = 0.460968 * 100, metric = 7.23% * 100;
 Minibatch[ 101- 200]: loss = 0.443046 * 100, metric = 6.75% * 100;
 Minibatch[ 201- 300]: loss = 0.465085 * 100, metric = 7.13% * 100;
 Minibatch[ 301- 400]: loss = 0.450094 * 100, metric = 6.66% * 100;
 Minibatch[ 401- 500]: loss = 0.458547 * 100, metric = 7.12% * 100;
 Minibatch[ 501- 600]: loss = 0.457528 * 100, metric = 6.98% * 100;
 Minibatch[ 601- 700]: loss = 0.465466 * 100, metric = 7.28% * 100;
 Minibatch[ 701- 800]: loss = 0.454839 * 100, metric = 7.22% * 100;
 Minibatch[ 801- 900]: loss = 0.441774 * 100, metric = 6.76% * 100;
 Minibatch[ 901-1000]: loss = 0.448354 * 100, metric = 6.79% * 100;
 Minibatch[1001-1100]: loss = 0.465743 * 100, metric = 7.43% * 100;
 Minibatch[1101-1200]: loss = 0.470229 * 100, metric = 7.44% * 100;
 Minibatch[1201-1300]: loss = 0.451062 * 100, metric = 6.85% * 100;
 Minibatch[1301-1400]: loss = 0.445076 * 100, metric = 6.62% * 100;
 Minibatch[1401-1500]: loss = 0.455635 * 100, metric = 7.08% * 100;
 Minibatch[1501-1600]: loss = 0.447631 * 100, metric = 6.64% * 100;
 Minibatch[1601-1700]: loss = 0.474551 * 100, metric = 7.37% * 100;
 Minibatch[1701-1800]: loss = 0.463614 * 100, metric = 7.10% * 100;
 Minibatch[1801-1900]: loss = 0.460301 * 100, metric = 7.19% * 100;
 Minibatch[1901-2000]: loss = 0.457101 * 100, metric = 6.98% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.456832 * 2000, metric = 7.03% * 2000 876.129s (  2.3 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.66% * 2000;
 Minibatch[   1- 100]: loss = 0.463203 * 100, metric = 7.07% * 100;
 Minibatch[ 101- 200]: loss = 0.471403 * 100, metric = 7.13% * 100;
 Minibatch[ 201- 300]: loss = 0.457441 * 100, metric = 7.00% * 100;
 Minibatch[ 301- 400]: loss = 0.452488 * 100, metric = 7.12% * 100;
 Minibatch[ 401- 500]: loss = 0.456291 * 100, metric = 6.92% * 100;
 Minibatch[ 501- 600]: loss = 0.444765 * 100, metric = 6.76% * 100;
 Minibatch[ 601- 700]: loss = 0.449295 * 100, metric = 6.84% * 100;
 Minibatch[ 701- 800]: loss = 0.456650 * 100, metric = 6.97% * 100;
 Minibatch[ 801- 900]: loss = 0.469926 * 100, metric = 7.32% * 100;
 Minibatch[ 901-1000]: loss = 0.462332 * 100, metric = 7.34% * 100;
 Minibatch[1001-1100]: loss = 0.448019 * 100, metric = 6.68% * 100;
 Minibatch[1101-1200]: loss = 0.467411 * 100, metric = 7.31% * 100;
 Minibatch[1201-1300]: loss = 0.458813 * 100, metric = 7.13% * 100;
 Minibatch[1301-1400]: loss = 0.469357 * 100, metric = 7.62% * 100;
 Minibatch[1401-1500]: loss = 0.443113 * 100, metric = 6.93% * 100;
 Minibatch[1501-1600]: loss = 0.450271 * 100, metric = 7.07% * 100;
 Minibatch[1601-1700]: loss = 0.431349 * 100, metric = 6.57% * 100;
 Minibatch[1701-1800]: loss = 0.451038 * 100, metric = 6.76% * 100;
 Minibatch[1801-1900]: loss = 0.448141 * 100, metric = 6.84% * 100;
 Minibatch[1901-2000]: loss = 0.457353 * 100, metric = 6.88% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.455433 * 2000, metric = 7.01% * 2000 873.937s (  2.3 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 14.04% * 2000;
0.6049575599953532
 Minibatch[   1- 100]: loss = 0.457310 * 100, metric = 7.14% * 100;
 Minibatch[ 101- 200]: loss = 0.442631 * 100, metric = 6.70% * 100;
 Minibatch[ 201- 300]: loss = 0.460773 * 100, metric = 7.18% * 100;
 Minibatch[ 301- 400]: loss = 0.448789 * 100, metric = 6.84% * 100;
 Minibatch[ 401- 500]: loss = 0.443044 * 100, metric = 6.82% * 100;
 Minibatch[ 501- 600]: loss = 0.464699 * 100, metric = 7.43% * 100;
 Minibatch[ 601- 700]: loss = 0.440565 * 100, metric = 6.67% * 100;
 Minibatch[ 701- 800]: loss = 0.432296 * 100, metric = 6.45% * 100;
 Minibatch[ 801- 900]: loss = 0.457927 * 100, metric = 7.12% * 100;
 Minibatch[ 901-1000]: loss = 0.463474 * 100, metric = 7.32% * 100;
 Minibatch[1001-1100]: loss = 0.450348 * 100, metric = 6.88% * 100;
 Minibatch[1101-1200]: loss = 0.451513 * 100, metric = 6.76% * 100;
 Minibatch[1201-1300]: loss = 0.453990 * 100, metric = 7.08% * 100;
 Minibatch[1301-1400]: loss = 0.442205 * 100, metric = 6.82% * 100;
 Minibatch[1401-1500]: loss = 0.454617 * 100, metric = 7.02% * 100;
 Minibatch[1501-1600]: loss = 0.436597 * 100, metric = 6.56% * 100;
 Minibatch[1601-1700]: loss = 0.451398 * 100, metric = 6.61% * 100;
 Minibatch[1701-1800]: loss = 0.440457 * 100, metric = 6.64% * 100;
 Minibatch[1801-1900]: loss = 0.449172 * 100, metric = 7.02% * 100;
 Minibatch[1901-2000]: loss = 0.444041 * 100, metric = 6.64% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.449292 * 2000, metric = 6.88% * 2000 871.123s (  2.3 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 14.25% * 2000;
 Minibatch[   1- 100]: loss = 0.428223 * 100, metric = 6.59% * 100;
 Minibatch[ 101- 200]: loss = 0.437894 * 100, metric = 6.86% * 100;
 Minibatch[ 201- 300]: loss = 0.438222 * 100, metric = 6.84% * 100;
 Minibatch[ 301- 400]: loss = 0.463726 * 100, metric = 7.26% * 100;
 Minibatch[ 401- 500]: loss = 0.435378 * 100, metric = 6.54% * 100;
 Minibatch[ 501- 600]: loss = 0.445121 * 100, metric = 6.77% * 100;
 Minibatch[ 601- 700]: loss = 0.434882 * 100, metric = 6.82% * 100;
 Minibatch[ 701- 800]: loss = 0.448474 * 100, metric = 6.96% * 100;
 Minibatch[ 801- 900]: loss = 0.439475 * 100, metric = 6.83% * 100;
 Minibatch[ 901-1000]: loss = 0.452914 * 100, metric = 7.04% * 100;
 Minibatch[1001-1100]: loss = 0.443756 * 100, metric = 6.93% * 100;
 Minibatch[1101-1200]: loss = 0.428925 * 100, metric = 6.50% * 100;
 Minibatch[1201-1300]: loss = 0.445000 * 100, metric = 6.81% * 100;
 Minibatch[1301-1400]: loss = 0.428398 * 100, metric = 6.58% * 100;
 Minibatch[1401-1500]: loss = 0.456777 * 100, metric = 7.14% * 100;
 Minibatch[1501-1600]: loss = 0.429467 * 100, metric = 6.57% * 100;
 Minibatch[1601-1700]: loss = 0.449036 * 100, metric = 7.17% * 100;
 Minibatch[1701-1800]: loss = 0.440197 * 100, metric = 6.66% * 100;
 Minibatch[1801-1900]: loss = 0.452979 * 100, metric = 6.88% * 100;
 Minibatch[1901-2000]: loss = 0.438339 * 100, metric = 6.71% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.441859 * 2000, metric = 6.82% * 2000 881.563s (  2.3 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 14.62% * 2000;
 Minibatch[   1- 100]: loss = 0.455210 * 100, metric = 6.98% * 100;
 Minibatch[ 101- 200]: loss = 0.426371 * 100, metric = 6.38% * 100;
 Minibatch[ 201- 300]: loss = 0.436412 * 100, metric = 6.72% * 100;
 Minibatch[ 301- 400]: loss = 0.447218 * 100, metric = 6.99% * 100;
 Minibatch[ 401- 500]: loss = 0.442349 * 100, metric = 6.85% * 100;
 Minibatch[ 501- 600]: loss = 0.417636 * 100, metric = 6.19% * 100;
 Minibatch[ 601- 700]: loss = 0.442807 * 100, metric = 6.85% * 100;
 Minibatch[ 701- 800]: loss = 0.430500 * 100, metric = 6.44% * 100;
 Minibatch[ 801- 900]: loss = 0.449126 * 100, metric = 6.71% * 100;
 Minibatch[ 901-1000]: loss = 0.414510 * 100, metric = 6.32% * 100;
 Minibatch[1001-1100]: loss = 0.442613 * 100, metric = 6.78% * 100;
 Minibatch[1101-1200]: loss = 0.449395 * 100, metric = 6.89% * 100;
 Minibatch[1201-1300]: loss = 0.430162 * 100, metric = 6.62% * 100;
 Minibatch[1301-1400]: loss = 0.439857 * 100, metric = 6.61% * 100;
 Minibatch[1401-1500]: loss = 0.432781 * 100, metric = 6.69% * 100;
 Minibatch[1501-1600]: loss = 0.446479 * 100, metric = 6.86% * 100;
 Minibatch[1601-1700]: loss = 0.440499 * 100, metric = 6.66% * 100;
 Minibatch[1701-1800]: loss = 0.443754 * 100, metric = 6.76% * 100;
 Minibatch[1801-1900]: loss = 0.443275 * 100, metric = 7.08% * 100;
 Minibatch[1901-2000]: loss = 0.463047 * 100, metric = 7.18% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.439700 * 2000, metric = 6.73% * 2000 878.347s (  2.3 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 13.85% * 2000;
 Minibatch[   1- 100]: loss = 0.445657 * 100, metric = 6.75% * 100;
 Minibatch[ 101- 200]: loss = 0.457694 * 100, metric = 7.28% * 100;
 Minibatch[ 201- 300]: loss = 0.445305 * 100, metric = 6.84% * 100;
 Minibatch[ 301- 400]: loss = 0.434831 * 100, metric = 6.72% * 100;
 Minibatch[ 401- 500]: loss = 0.438130 * 100, metric = 6.68% * 100;
 Minibatch[ 501- 600]: loss = 0.427517 * 100, metric = 6.49% * 100;
 Minibatch[ 601- 700]: loss = 0.447504 * 100, metric = 6.85% * 100;
 Minibatch[ 701- 800]: loss = 0.445290 * 100, metric = 6.77% * 100;
 Minibatch[ 801- 900]: loss = 0.443031 * 100, metric = 6.75% * 100;
 Minibatch[ 901-1000]: loss = 0.426309 * 100, metric = 6.52% * 100;
 Minibatch[1001-1100]: loss = 0.430179 * 100, metric = 6.52% * 100;
 Minibatch[1101-1200]: loss = 0.443165 * 100, metric = 6.58% * 100;
 Minibatch[1201-1300]: loss = 0.430630 * 100, metric = 6.49% * 100;
 Minibatch[1301-1400]: loss = 0.434850 * 100, metric = 6.72% * 100;
 Minibatch[1401-1500]: loss = 0.440686 * 100, metric = 6.91% * 100;
 Minibatch[1501-1600]: loss = 0.424689 * 100, metric = 6.60% * 100;
 Minibatch[1601-1700]: loss = 0.443967 * 100, metric = 6.79% * 100;
 Minibatch[1701-1800]: loss = 0.429227 * 100, metric = 6.66% * 100;
 Minibatch[1801-1900]: loss = 0.443716 * 100, metric = 6.85% * 100;
 Minibatch[1901-2000]: loss = 0.435929 * 100, metric = 6.57% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.438415 * 2000, metric = 6.72% * 2000 859.777s (  2.3 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 14.15% * 2000;
 Minibatch[   1- 100]: loss = 0.444323 * 100, metric = 6.77% * 100;
 Minibatch[ 101- 200]: loss = 0.439429 * 100, metric = 6.51% * 100;
 Minibatch[ 201- 300]: loss = 0.446311 * 100, metric = 6.90% * 100;
 Minibatch[ 301- 400]: loss = 0.442900 * 100, metric = 6.67% * 100;
 Minibatch[ 401- 500]: loss = 0.448376 * 100, metric = 7.16% * 100;
 Minibatch[ 501- 600]: loss = 0.445623 * 100, metric = 7.03% * 100;
 Minibatch[ 601- 700]: loss = 0.428819 * 100, metric = 6.38% * 100;
 Minibatch[ 701- 800]: loss = 0.433206 * 100, metric = 6.61% * 100;
 Minibatch[ 801- 900]: loss = 0.430299 * 100, metric = 6.74% * 100;
 Minibatch[ 901-1000]: loss = 0.425627 * 100, metric = 6.20% * 100;
 Minibatch[1001-1100]: loss = 0.424290 * 100, metric = 6.24% * 100;
 Minibatch[1101-1200]: loss = 0.440355 * 100, metric = 6.85% * 100;
 Minibatch[1201-1300]: loss = 0.443636 * 100, metric = 7.00% * 100;
 Minibatch[1301-1400]: loss = 0.430470 * 100, metric = 6.55% * 100;
 Minibatch[1401-1500]: loss = 0.426782 * 100, metric = 6.62% * 100;
 Minibatch[1501-1600]: loss = 0.444552 * 100, metric = 6.71% * 100;
 Minibatch[1601-1700]: loss = 0.422175 * 100, metric = 6.27% * 100;
 Minibatch[1701-1800]: loss = 0.447287 * 100, metric = 6.79% * 100;
 Minibatch[1801-1900]: loss = 0.427261 * 100, metric = 6.28% * 100;
 Minibatch[1901-2000]: loss = 0.437888 * 100, metric = 7.00% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.436480 * 2000, metric = 6.67% * 2000 859.104s (  2.3 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 14.18% * 2000;
 Minibatch[   1- 100]: loss = 0.444392 * 100, metric = 7.13% * 100;
 Minibatch[ 101- 200]: loss = 0.431036 * 100, metric = 6.70% * 100;
 Minibatch[ 201- 300]: loss = 0.423015 * 100, metric = 6.54% * 100;
 Minibatch[ 301- 400]: loss = 0.434665 * 100, metric = 6.71% * 100;
 Minibatch[ 401- 500]: loss = 0.435567 * 100, metric = 6.73% * 100;
 Minibatch[ 501- 600]: loss = 0.441778 * 100, metric = 6.73% * 100;
 Minibatch[ 601- 700]: loss = 0.447484 * 100, metric = 7.03% * 100;
 Minibatch[ 701- 800]: loss = 0.430910 * 100, metric = 6.52% * 100;
 Minibatch[ 801- 900]: loss = 0.429119 * 100, metric = 6.41% * 100;
 Minibatch[ 901-1000]: loss = 0.415410 * 100, metric = 6.15% * 100;
 Minibatch[1001-1100]: loss = 0.424755 * 100, metric = 6.57% * 100;
 Minibatch[1101-1200]: loss = 0.417492 * 100, metric = 6.36% * 100;
 Minibatch[1201-1300]: loss = 0.447103 * 100, metric = 6.68% * 100;
 Minibatch[1301-1400]: loss = 0.420638 * 100, metric = 6.05% * 100;
 Minibatch[1401-1500]: loss = 0.438199 * 100, metric = 6.73% * 100;
 Minibatch[1501-1600]: loss = 0.442906 * 100, metric = 6.83% * 100;
 Minibatch[1601-1700]: loss = 0.429600 * 100, metric = 6.31% * 100;
 Minibatch[1701-1800]: loss = 0.422679 * 100, metric = 6.35% * 100;
 Minibatch[1801-1900]: loss = 0.421635 * 100, metric = 6.41% * 100;
 Minibatch[1901-2000]: loss = 0.444077 * 100, metric = 7.03% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.432123 * 2000, metric = 6.60% * 2000 852.874s (  2.3 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.44% * 2000;
 Minibatch[   1- 100]: loss = 0.415926 * 100, metric = 6.11% * 100;
 Minibatch[ 101- 200]: loss = 0.435399 * 100, metric = 6.61% * 100;
 Minibatch[ 201- 300]: loss = 0.414813 * 100, metric = 6.15% * 100;
 Minibatch[ 301- 400]: loss = 0.430329 * 100, metric = 6.56% * 100;
 Minibatch[ 401- 500]: loss = 0.418922 * 100, metric = 6.38% * 100;
 Minibatch[ 501- 600]: loss = 0.426397 * 100, metric = 6.47% * 100;
 Minibatch[ 601- 700]: loss = 0.424176 * 100, metric = 6.45% * 100;
 Minibatch[ 701- 800]: loss = 0.414811 * 100, metric = 6.21% * 100;
 Minibatch[ 801- 900]: loss = 0.406431 * 100, metric = 5.86% * 100;
 Minibatch[ 901-1000]: loss = 0.417156 * 100, metric = 6.51% * 100;
 Minibatch[1001-1100]: loss = 0.428710 * 100, metric = 6.69% * 100;
 Minibatch[1101-1200]: loss = 0.422065 * 100, metric = 6.53% * 100;
 Minibatch[1201-1300]: loss = 0.422521 * 100, metric = 6.44% * 100;
 Minibatch[1301-1400]: loss = 0.418166 * 100, metric = 6.33% * 100;
 Minibatch[1401-1500]: loss = 0.423047 * 100, metric = 6.46% * 100;
 Minibatch[1501-1600]: loss = 0.434143 * 100, metric = 6.55% * 100;
 Minibatch[1601-1700]: loss = 0.436722 * 100, metric = 6.71% * 100;
 Minibatch[1701-1800]: loss = 0.428069 * 100, metric = 6.48% * 100;
 Minibatch[1801-1900]: loss = 0.431491 * 100, metric = 6.63% * 100;
 Minibatch[1901-2000]: loss = 0.433012 * 100, metric = 6.53% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.424115 * 2000, metric = 6.43% * 2000 853.966s (  2.3 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.44% * 2000;
 Minibatch[   1- 100]: loss = 0.406779 * 100, metric = 6.07% * 100;
 Minibatch[ 101- 200]: loss = 0.421264 * 100, metric = 6.41% * 100;
 Minibatch[ 201- 300]: loss = 0.426020 * 100, metric = 6.40% * 100;
 Minibatch[ 301- 400]: loss = 0.401329 * 100, metric = 5.94% * 100;
 Minibatch[ 401- 500]: loss = 0.417671 * 100, metric = 6.15% * 100;
 Minibatch[ 501- 600]: loss = 0.397600 * 100, metric = 5.65% * 100;
 Minibatch[ 601- 700]: loss = 0.440553 * 100, metric = 6.59% * 100;
 Minibatch[ 701- 800]: loss = 0.406311 * 100, metric = 5.97% * 100;
 Minibatch[ 801- 900]: loss = 0.421538 * 100, metric = 6.24% * 100;
 Minibatch[ 901-1000]: loss = 0.404777 * 100, metric = 5.87% * 100;
 Minibatch[1001-1100]: loss = 0.422122 * 100, metric = 6.33% * 100;
 Minibatch[1101-1200]: loss = 0.417231 * 100, metric = 6.24% * 100;
 Minibatch[1201-1300]: loss = 0.422984 * 100, metric = 6.47% * 100;
 Minibatch[1301-1400]: loss = 0.427254 * 100, metric = 6.52% * 100;
 Minibatch[1401-1500]: loss = 0.413738 * 100, metric = 6.11% * 100;
 Minibatch[1501-1600]: loss = 0.417387 * 100, metric = 6.49% * 100;
 Minibatch[1601-1700]: loss = 0.416448 * 100, metric = 6.12% * 100;
 Minibatch[1701-1800]: loss = 0.407449 * 100, metric = 5.90% * 100;
 Minibatch[1801-1900]: loss = 0.422436 * 100, metric = 6.51% * 100;
 Minibatch[1901-2000]: loss = 0.411122 * 100, metric = 6.22% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.416101 * 2000, metric = 6.21% * 2000 851.631s (  2.3 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.51% * 2000;
 Minibatch[   1- 100]: loss = 0.412618 * 100, metric = 6.25% * 100;
 Minibatch[ 101- 200]: loss = 0.400677 * 100, metric = 5.85% * 100;
 Minibatch[ 201- 300]: loss = 0.422440 * 100, metric = 6.37% * 100;
 Minibatch[ 301- 400]: loss = 0.409473 * 100, metric = 6.03% * 100;
 Minibatch[ 401- 500]: loss = 0.413003 * 100, metric = 6.22% * 100;
 Minibatch[ 501- 600]: loss = 0.413505 * 100, metric = 6.12% * 100;
 Minibatch[ 601- 700]: loss = 0.434388 * 100, metric = 6.48% * 100;
 Minibatch[ 701- 800]: loss = 0.392268 * 100, metric = 5.85% * 100;
 Minibatch[ 801- 900]: loss = 0.397731 * 100, metric = 5.92% * 100;
 Minibatch[ 901-1000]: loss = 0.418690 * 100, metric = 6.29% * 100;
 Minibatch[1001-1100]: loss = 0.423065 * 100, metric = 6.41% * 100;
 Minibatch[1101-1200]: loss = 0.416988 * 100, metric = 6.29% * 100;
 Minibatch[1201-1300]: loss = 0.419189 * 100, metric = 6.24% * 100;
 Minibatch[1301-1400]: loss = 0.390557 * 100, metric = 5.61% * 100;
 Minibatch[1401-1500]: loss = 0.404095 * 100, metric = 5.91% * 100;
 Minibatch[1501-1600]: loss = 0.409112 * 100, metric = 6.15% * 100;
 Minibatch[1601-1700]: loss = 0.425737 * 100, metric = 6.53% * 100;
 Minibatch[1701-1800]: loss = 0.421988 * 100, metric = 6.45% * 100;
 Minibatch[1801-1900]: loss = 0.419556 * 100, metric = 6.25% * 100;
 Minibatch[1901-2000]: loss = 0.410784 * 100, metric = 6.02% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.412793 * 2000, metric = 6.16% * 2000 847.526s (  2.4 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.19% * 2000;
 Minibatch[   1- 100]: loss = 0.411691 * 100, metric = 6.23% * 100;
 Minibatch[ 101- 200]: loss = 0.416826 * 100, metric = 6.49% * 100;
 Minibatch[ 201- 300]: loss = 0.413016 * 100, metric = 6.27% * 100;
 Minibatch[ 301- 400]: loss = 0.410044 * 100, metric = 5.92% * 100;
 Minibatch[ 401- 500]: loss = 0.411265 * 100, metric = 6.39% * 100;
 Minibatch[ 501- 600]: loss = 0.403358 * 100, metric = 6.21% * 100;
 Minibatch[ 601- 700]: loss = 0.413660 * 100, metric = 6.34% * 100;
 Minibatch[ 701- 800]: loss = 0.423269 * 100, metric = 6.47% * 100;
 Minibatch[ 801- 900]: loss = 0.417462 * 100, metric = 6.09% * 100;
 Minibatch[ 901-1000]: loss = 0.398245 * 100, metric = 5.60% * 100;
 Minibatch[1001-1100]: loss = 0.405381 * 100, metric = 6.10% * 100;
 Minibatch[1101-1200]: loss = 0.427827 * 100, metric = 6.55% * 100;
 Minibatch[1201-1300]: loss = 0.423220 * 100, metric = 6.38% * 100;
 Minibatch[1301-1400]: loss = 0.416768 * 100, metric = 6.08% * 100;
 Minibatch[1401-1500]: loss = 0.419908 * 100, metric = 6.46% * 100;
 Minibatch[1501-1600]: loss = 0.406008 * 100, metric = 6.04% * 100;
 Minibatch[1601-1700]: loss = 0.412903 * 100, metric = 6.42% * 100;
 Minibatch[1701-1800]: loss = 0.415098 * 100, metric = 6.16% * 100;
 Minibatch[1801-1900]: loss = 0.413168 * 100, metric = 6.31% * 100;
 Minibatch[1901-2000]: loss = 0.410255 * 100, metric = 6.28% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.413469 * 2000, metric = 6.24% * 2000 843.004s (  2.4 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 12.86% * 2000;
 Minibatch[   1- 100]: loss = 0.423599 * 100, metric = 6.54% * 100;
 Minibatch[ 101- 200]: loss = 0.415051 * 100, metric = 6.24% * 100;
 Minibatch[ 201- 300]: loss = 0.395675 * 100, metric = 5.85% * 100;
 Minibatch[ 301- 400]: loss = 0.401373 * 100, metric = 6.01% * 100;
 Minibatch[ 401- 500]: loss = 0.408675 * 100, metric = 6.15% * 100;
 Minibatch[ 501- 600]: loss = 0.407813 * 100, metric = 6.00% * 100;
 Minibatch[ 601- 700]: loss = 0.418699 * 100, metric = 6.45% * 100;
 Minibatch[ 701- 800]: loss = 0.401909 * 100, metric = 5.90% * 100;
 Minibatch[ 801- 900]: loss = 0.407824 * 100, metric = 6.12% * 100;
 Minibatch[ 901-1000]: loss = 0.404407 * 100, metric = 5.98% * 100;
 Minibatch[1001-1100]: loss = 0.413437 * 100, metric = 6.25% * 100;
 Minibatch[1101-1200]: loss = 0.394953 * 100, metric = 5.80% * 100;
 Minibatch[1201-1300]: loss = 0.396775 * 100, metric = 5.96% * 100;
 Minibatch[1301-1400]: loss = 0.413603 * 100, metric = 6.05% * 100;
 Minibatch[1401-1500]: loss = 0.406390 * 100, metric = 6.17% * 100;
 Minibatch[1501-1600]: loss = 0.410237 * 100, metric = 6.30% * 100;
 Minibatch[1601-1700]: loss = 0.390649 * 100, metric = 5.75% * 100;
 Minibatch[1701-1800]: loss = 0.401491 * 100, metric = 6.05% * 100;
 Minibatch[1801-1900]: loss = 0.414182 * 100, metric = 6.16% * 100;
 Minibatch[1901-2000]: loss = 0.409568 * 100, metric = 6.06% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.406816 * 2000, metric = 6.09% * 2000 847.044s (  2.4 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 12.69% * 2000;
 Minibatch[   1- 100]: loss = 0.395375 * 100, metric = 5.76% * 100;
 Minibatch[ 101- 200]: loss = 0.415399 * 100, metric = 6.25% * 100;
 Minibatch[ 201- 300]: loss = 0.399778 * 100, metric = 5.90% * 100;
 Minibatch[ 301- 400]: loss = 0.392050 * 100, metric = 5.73% * 100;
 Minibatch[ 401- 500]: loss = 0.390692 * 100, metric = 5.94% * 100;
 Minibatch[ 501- 600]: loss = 0.412840 * 100, metric = 6.33% * 100;
 Minibatch[ 601- 700]: loss = 0.403083 * 100, metric = 6.09% * 100;
 Minibatch[ 701- 800]: loss = 0.408392 * 100, metric = 6.00% * 100;
 Minibatch[ 801- 900]: loss = 0.387525 * 100, metric = 5.64% * 100;
 Minibatch[ 901-1000]: loss = 0.399229 * 100, metric = 5.85% * 100;
 Minibatch[1001-1100]: loss = 0.414619 * 100, metric = 6.34% * 100;
 Minibatch[1101-1200]: loss = 0.392682 * 100, metric = 5.84% * 100;
 Minibatch[1201-1300]: loss = 0.407722 * 100, metric = 5.85% * 100;
 Minibatch[1301-1400]: loss = 0.416340 * 100, metric = 6.20% * 100;
 Minibatch[1401-1500]: loss = 0.404373 * 100, metric = 5.96% * 100;
 Minibatch[1501-1600]: loss = 0.409841 * 100, metric = 6.16% * 100;
 Minibatch[1601-1700]: loss = 0.399615 * 100, metric = 5.83% * 100;
 Minibatch[1701-1800]: loss = 0.413019 * 100, metric = 6.12% * 100;
 Minibatch[1801-1900]: loss = 0.402753 * 100, metric = 5.97% * 100;
 Minibatch[1901-2000]: loss = 0.400687 * 100, metric = 5.94% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.403301 * 2000, metric = 5.99% * 2000 838.965s (  2.4 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.46% * 2000;
 Minibatch[   1- 100]: loss = 0.394357 * 100, metric = 5.98% * 100;
 Minibatch[ 101- 200]: loss = 0.391547 * 100, metric = 5.96% * 100;
 Minibatch[ 201- 300]: loss = 0.410131 * 100, metric = 6.07% * 100;
 Minibatch[ 301- 400]: loss = 0.403846 * 100, metric = 6.06% * 100;
 Minibatch[ 401- 500]: loss = 0.398936 * 100, metric = 5.96% * 100;
 Minibatch[ 501- 600]: loss = 0.397802 * 100, metric = 5.96% * 100;
 Minibatch[ 601- 700]: loss = 0.420769 * 100, metric = 6.40% * 100;
 Minibatch[ 701- 800]: loss = 0.405915 * 100, metric = 5.94% * 100;
 Minibatch[ 801- 900]: loss = 0.405379 * 100, metric = 6.04% * 100;
 Minibatch[ 901-1000]: loss = 0.395008 * 100, metric = 5.88% * 100;
 Minibatch[1001-1100]: loss = 0.411893 * 100, metric = 6.27% * 100;
 Minibatch[1101-1200]: loss = 0.408142 * 100, metric = 6.15% * 100;
 Minibatch[1201-1300]: loss = 0.402480 * 100, metric = 5.90% * 100;
 Minibatch[1301-1400]: loss = 0.409709 * 100, metric = 6.26% * 100;
 Minibatch[1401-1500]: loss = 0.397401 * 100, metric = 5.82% * 100;
 Minibatch[1501-1600]: loss = 0.419802 * 100, metric = 6.30% * 100;
 Minibatch[1601-1700]: loss = 0.401495 * 100, metric = 5.90% * 100;
 Minibatch[1701-1800]: loss = 0.392577 * 100, metric = 5.89% * 100;
 Minibatch[1801-1900]: loss = 0.397469 * 100, metric = 5.85% * 100;
 Minibatch[1901-2000]: loss = 0.398698 * 100, metric = 5.91% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.403168 * 2000, metric = 6.03% * 2000 837.282s (  2.4 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 13.54% * 2000;
 Minibatch[   1- 100]: loss = 0.400894 * 100, metric = 5.86% * 100;
 Minibatch[ 101- 200]: loss = 0.392986 * 100, metric = 5.90% * 100;
 Minibatch[ 201- 300]: loss = 0.404906 * 100, metric = 6.09% * 100;
 Minibatch[ 301- 400]: loss = 0.408056 * 100, metric = 6.17% * 100;
 Minibatch[ 401- 500]: loss = 0.404577 * 100, metric = 6.08% * 100;
 Minibatch[ 501- 600]: loss = 0.399363 * 100, metric = 5.86% * 100;
 Minibatch[ 601- 700]: loss = 0.401227 * 100, metric = 6.10% * 100;
 Minibatch[ 701- 800]: loss = 0.395942 * 100, metric = 5.92% * 100;
 Minibatch[ 801- 900]: loss = 0.388577 * 100, metric = 5.78% * 100;
 Minibatch[ 901-1000]: loss = 0.398107 * 100, metric = 5.96% * 100;
 Minibatch[1001-1100]: loss = 0.407231 * 100, metric = 5.91% * 100;
 Minibatch[1101-1200]: loss = 0.411208 * 100, metric = 6.07% * 100;
 Minibatch[1201-1300]: loss = 0.406571 * 100, metric = 6.03% * 100;
 Minibatch[1301-1400]: loss = 0.379114 * 100, metric = 5.51% * 100;
 Minibatch[1401-1500]: loss = 0.390831 * 100, metric = 5.80% * 100;
 Minibatch[1501-1600]: loss = 0.400367 * 100, metric = 5.87% * 100;
 Minibatch[1601-1700]: loss = 0.400320 * 100, metric = 5.95% * 100;
 Minibatch[1701-1800]: loss = 0.395742 * 100, metric = 5.93% * 100;
 Minibatch[1801-1900]: loss = 0.398085 * 100, metric = 5.95% * 100;
 Minibatch[1901-2000]: loss = 0.397557 * 100, metric = 5.72% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.399083 * 2000, metric = 5.92% * 2000 843.572s (  2.4 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 14.11% * 2000;
 Minibatch[   1- 100]: loss = 0.394148 * 100, metric = 5.84% * 100;
 Minibatch[ 101- 200]: loss = 0.394699 * 100, metric = 6.01% * 100;
 Minibatch[ 201- 300]: loss = 0.393375 * 100, metric = 5.71% * 100;
 Minibatch[ 301- 400]: loss = 0.381834 * 100, metric = 5.43% * 100;
 Minibatch[ 401- 500]: loss = 0.390818 * 100, metric = 5.51% * 100;
 Minibatch[ 501- 600]: loss = 0.396508 * 100, metric = 5.84% * 100;
 Minibatch[ 601- 700]: loss = 0.395206 * 100, metric = 5.85% * 100;
 Minibatch[ 701- 800]: loss = 0.389254 * 100, metric = 5.76% * 100;
 Minibatch[ 801- 900]: loss = 0.382194 * 100, metric = 5.65% * 100;
 Minibatch[ 901-1000]: loss = 0.402234 * 100, metric = 5.95% * 100;
 Minibatch[1001-1100]: loss = 0.393240 * 100, metric = 5.83% * 100;
 Minibatch[1101-1200]: loss = 0.389163 * 100, metric = 5.68% * 100;
 Minibatch[1201-1300]: loss = 0.391896 * 100, metric = 5.78% * 100;
 Minibatch[1301-1400]: loss = 0.398581 * 100, metric = 5.86% * 100;
 Minibatch[1401-1500]: loss = 0.386810 * 100, metric = 5.59% * 100;
 Minibatch[1501-1600]: loss = 0.393143 * 100, metric = 5.71% * 100;
 Minibatch[1601-1700]: loss = 0.389879 * 100, metric = 5.73% * 100;
 Minibatch[1701-1800]: loss = 0.400170 * 100, metric = 5.90% * 100;
 Minibatch[1801-1900]: loss = 0.387525 * 100, metric = 5.75% * 100;
 Minibatch[1901-2000]: loss = 0.392604 * 100, metric = 5.69% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.392164 * 2000, metric = 5.75% * 2000 831.683s (  2.4 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 13.04% * 2000;
 Minibatch[   1- 100]: loss = 0.406659 * 100, metric = 6.21% * 100;
 Minibatch[ 101- 200]: loss = 0.383979 * 100, metric = 5.58% * 100;
 Minibatch[ 201- 300]: loss = 0.395271 * 100, metric = 5.84% * 100;
 Minibatch[ 301- 400]: loss = 0.395283 * 100, metric = 5.92% * 100;
 Minibatch[ 401- 500]: loss = 0.389433 * 100, metric = 5.54% * 100;
 Minibatch[ 501- 600]: loss = 0.384181 * 100, metric = 5.81% * 100;
 Minibatch[ 601- 700]: loss = 0.401647 * 100, metric = 5.97% * 100;
 Minibatch[ 701- 800]: loss = 0.383703 * 100, metric = 5.81% * 100;
 Minibatch[ 801- 900]: loss = 0.388788 * 100, metric = 5.89% * 100;
 Minibatch[ 901-1000]: loss = 0.391666 * 100, metric = 5.70% * 100;
 Minibatch[1001-1100]: loss = 0.394023 * 100, metric = 5.99% * 100;
 Minibatch[1101-1200]: loss = 0.385335 * 100, metric = 5.82% * 100;
 Minibatch[1201-1300]: loss = 0.396744 * 100, metric = 6.17% * 100;
 Minibatch[1301-1400]: loss = 0.397852 * 100, metric = 6.14% * 100;
 Minibatch[1401-1500]: loss = 0.374709 * 100, metric = 5.45% * 100;
 Minibatch[1501-1600]: loss = 0.394503 * 100, metric = 5.70% * 100;
 Minibatch[1601-1700]: loss = 0.392668 * 100, metric = 5.91% * 100;
 Minibatch[1701-1800]: loss = 0.386779 * 100, metric = 5.93% * 100;
 Minibatch[1801-1900]: loss = 0.394021 * 100, metric = 6.00% * 100;
 Minibatch[1901-2000]: loss = 0.384431 * 100, metric = 5.71% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.391084 * 2000, metric = 5.85% * 2000 830.988s (  2.4 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 12.95% * 2000;
 Minibatch[   1- 100]: loss = 0.382306 * 100, metric = 5.67% * 100;
 Minibatch[ 101- 200]: loss = 0.381383 * 100, metric = 5.63% * 100;
 Minibatch[ 201- 300]: loss = 0.384215 * 100, metric = 5.48% * 100;
 Minibatch[ 301- 400]: loss = 0.393642 * 100, metric = 5.68% * 100;
 Minibatch[ 401- 500]: loss = 0.386135 * 100, metric = 5.52% * 100;
 Minibatch[ 501- 600]: loss = 0.377550 * 100, metric = 5.59% * 100;
 Minibatch[ 601- 700]: loss = 0.396938 * 100, metric = 6.02% * 100;
 Minibatch[ 701- 800]: loss = 0.359704 * 100, metric = 4.99% * 100;
 Minibatch[ 801- 900]: loss = 0.377838 * 100, metric = 5.30% * 100;
 Minibatch[ 901-1000]: loss = 0.372936 * 100, metric = 5.25% * 100;
 Minibatch[1001-1100]: loss = 0.375015 * 100, metric = 5.49% * 100;
 Minibatch[1101-1200]: loss = 0.368123 * 100, metric = 5.37% * 100;
 Minibatch[1201-1300]: loss = 0.375145 * 100, metric = 5.36% * 100;
 Minibatch[1301-1400]: loss = 0.382747 * 100, metric = 5.66% * 100;
 Minibatch[1401-1500]: loss = 0.372473 * 100, metric = 5.23% * 100;
 Minibatch[1501-1600]: loss = 0.370263 * 100, metric = 5.31% * 100;
 Minibatch[1601-1700]: loss = 0.380182 * 100, metric = 5.59% * 100;
 Minibatch[1701-1800]: loss = 0.398772 * 100, metric = 6.22% * 100;
 Minibatch[1801-1900]: loss = 0.390692 * 100, metric = 5.61% * 100;
 Minibatch[1901-2000]: loss = 0.373239 * 100, metric = 5.48% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.379965 * 2000, metric = 5.52% * 2000 826.043s (  2.4 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 13.86% * 2000;
 Minibatch[   1- 100]: loss = 0.383694 * 100, metric = 5.50% * 100;
 Minibatch[ 101- 200]: loss = 0.377685 * 100, metric = 5.21% * 100;
 Minibatch[ 201- 300]: loss = 0.375825 * 100, metric = 5.23% * 100;
 Minibatch[ 301- 400]: loss = 0.389950 * 100, metric = 5.74% * 100;
 Minibatch[ 401- 500]: loss = 0.385862 * 100, metric = 5.67% * 100;
 Minibatch[ 501- 600]: loss = 0.362638 * 100, metric = 5.14% * 100;
 Minibatch[ 601- 700]: loss = 0.371064 * 100, metric = 5.37% * 100;
 Minibatch[ 701- 800]: loss = 0.368014 * 100, metric = 5.52% * 100;
 Minibatch[ 801- 900]: loss = 0.399034 * 100, metric = 6.04% * 100;
 Minibatch[ 901-1000]: loss = 0.374614 * 100, metric = 5.44% * 100;
 Minibatch[1001-1100]: loss = 0.370060 * 100, metric = 5.31% * 100;
 Minibatch[1101-1200]: loss = 0.388453 * 100, metric = 5.60% * 100;
 Minibatch[1201-1300]: loss = 0.381609 * 100, metric = 5.69% * 100;
 Minibatch[1301-1400]: loss = 0.370506 * 100, metric = 5.42% * 100;
 Minibatch[1401-1500]: loss = 0.379696 * 100, metric = 5.47% * 100;
 Minibatch[1501-1600]: loss = 0.380612 * 100, metric = 5.48% * 100;
 Minibatch[1601-1700]: loss = 0.365943 * 100, metric = 5.42% * 100;
 Minibatch[1701-1800]: loss = 0.385500 * 100, metric = 5.67% * 100;
 Minibatch[1801-1900]: loss = 0.378140 * 100, metric = 5.66% * 100;
 Minibatch[1901-2000]: loss = 0.379336 * 100, metric = 5.38% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.378412 * 2000, metric = 5.50% * 2000 832.482s (  2.4 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 12.90% * 2000;
 Minibatch[   1- 100]: loss = 0.368833 * 100, metric = 5.37% * 100;
 Minibatch[ 101- 200]: loss = 0.395882 * 100, metric = 5.86% * 100;
 Minibatch[ 201- 300]: loss = 0.379721 * 100, metric = 5.47% * 100;
 Minibatch[ 301- 400]: loss = 0.394418 * 100, metric = 6.02% * 100;
 Minibatch[ 401- 500]: loss = 0.376631 * 100, metric = 5.40% * 100;
 Minibatch[ 501- 600]: loss = 0.372114 * 100, metric = 5.30% * 100;
 Minibatch[ 601- 700]: loss = 0.363238 * 100, metric = 5.26% * 100;
 Minibatch[ 701- 800]: loss = 0.365650 * 100, metric = 5.30% * 100;
 Minibatch[ 801- 900]: loss = 0.370738 * 100, metric = 5.34% * 100;
 Minibatch[ 901-1000]: loss = 0.379254 * 100, metric = 5.55% * 100;
 Minibatch[1001-1100]: loss = 0.375044 * 100, metric = 5.50% * 100;
 Minibatch[1101-1200]: loss = 0.392027 * 100, metric = 5.90% * 100;
 Minibatch[1201-1300]: loss = 0.391813 * 100, metric = 5.67% * 100;
 Minibatch[1301-1400]: loss = 0.380511 * 100, metric = 5.54% * 100;
 Minibatch[1401-1500]: loss = 0.378625 * 100, metric = 5.58% * 100;
 Minibatch[1501-1600]: loss = 0.381254 * 100, metric = 5.56% * 100;
 Minibatch[1601-1700]: loss = 0.373512 * 100, metric = 5.35% * 100;
 Minibatch[1701-1800]: loss = 0.383138 * 100, metric = 5.60% * 100;
 Minibatch[1801-1900]: loss = 0.369127 * 100, metric = 5.25% * 100;
 Minibatch[1901-2000]: loss = 0.380244 * 100, metric = 5.54% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.378589 * 2000, metric = 5.52% * 2000 826.904s (  2.4 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 12.70% * 2000;
 Minibatch[   1- 100]: loss = 0.382566 * 100, metric = 5.51% * 100;
 Minibatch[ 101- 200]: loss = 0.369034 * 100, metric = 5.50% * 100;
 Minibatch[ 201- 300]: loss = 0.376295 * 100, metric = 5.54% * 100;
 Minibatch[ 301- 400]: loss = 0.365900 * 100, metric = 5.26% * 100;
 Minibatch[ 401- 500]: loss = 0.374231 * 100, metric = 5.44% * 100;
 Minibatch[ 501- 600]: loss = 0.372884 * 100, metric = 5.49% * 100;
 Minibatch[ 601- 700]: loss = 0.389998 * 100, metric = 5.71% * 100;
 Minibatch[ 701- 800]: loss = 0.389813 * 100, metric = 5.88% * 100;
 Minibatch[ 801- 900]: loss = 0.374511 * 100, metric = 5.33% * 100;
 Minibatch[ 901-1000]: loss = 0.376448 * 100, metric = 5.38% * 100;
 Minibatch[1001-1100]: loss = 0.390636 * 100, metric = 5.75% * 100;
 Minibatch[1101-1200]: loss = 0.385071 * 100, metric = 5.64% * 100;
 Minibatch[1201-1300]: loss = 0.359539 * 100, metric = 5.16% * 100;
 Minibatch[1301-1400]: loss = 0.374962 * 100, metric = 5.49% * 100;
 Minibatch[1401-1500]: loss = 0.383563 * 100, metric = 5.62% * 100;
 Minibatch[1501-1600]: loss = 0.384849 * 100, metric = 5.55% * 100;
 Minibatch[1601-1700]: loss = 0.376963 * 100, metric = 5.39% * 100;
 Minibatch[1701-1800]: loss = 0.387733 * 100, metric = 5.77% * 100;
 Minibatch[1801-1900]: loss = 0.379008 * 100, metric = 5.43% * 100;
 Minibatch[1901-2000]: loss = 0.388249 * 100, metric = 5.70% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.379113 * 2000, metric = 5.53% * 2000 823.086s (  2.4 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 12.00% * 2000;
0.5930982725024223
 Minibatch[   1- 100]: loss = 0.379519 * 100, metric = 5.56% * 100;
 Minibatch[ 101- 200]: loss = 0.383193 * 100, metric = 5.49% * 100;
 Minibatch[ 201- 300]: loss = 0.372131 * 100, metric = 5.48% * 100;
 Minibatch[ 301- 400]: loss = 0.376505 * 100, metric = 5.54% * 100;
 Minibatch[ 401- 500]: loss = 0.384404 * 100, metric = 5.74% * 100;
 Minibatch[ 501- 600]: loss = 0.391431 * 100, metric = 5.87% * 100;
 Minibatch[ 601- 700]: loss = 0.393576 * 100, metric = 5.79% * 100;
 Minibatch[ 701- 800]: loss = 0.382617 * 100, metric = 5.53% * 100;
 Minibatch[ 801- 900]: loss = 0.372502 * 100, metric = 5.28% * 100;
 Minibatch[ 901-1000]: loss = 0.386251 * 100, metric = 5.75% * 100;
 Minibatch[1001-1100]: loss = 0.372770 * 100, metric = 5.52% * 100;
 Minibatch[1101-1200]: loss = 0.376753 * 100, metric = 5.38% * 100;
 Minibatch[1201-1300]: loss = 0.377195 * 100, metric = 5.57% * 100;
 Minibatch[1301-1400]: loss = 0.369117 * 100, metric = 5.63% * 100;
 Minibatch[1401-1500]: loss = 0.374640 * 100, metric = 5.57% * 100;
 Minibatch[1501-1600]: loss = 0.369059 * 100, metric = 5.40% * 100;
 Minibatch[1601-1700]: loss = 0.374890 * 100, metric = 5.60% * 100;
 Minibatch[1701-1800]: loss = 0.370988 * 100, metric = 5.30% * 100;
 Minibatch[1801-1900]: loss = 0.382009 * 100, metric = 5.46% * 100;
 Minibatch[1901-2000]: loss = 0.365696 * 100, metric = 5.06% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.377762 * 2000, metric = 5.53% * 2000 823.579s (  2.4 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 13.32% * 2000;
 Minibatch[   1- 100]: loss = 0.385350 * 100, metric = 5.73% * 100;
 Minibatch[ 101- 200]: loss = 0.365047 * 100, metric = 5.37% * 100;
 Minibatch[ 201- 300]: loss = 0.382776 * 100, metric = 5.73% * 100;
 Minibatch[ 301- 400]: loss = 0.372245 * 100, metric = 5.39% * 100;
 Minibatch[ 401- 500]: loss = 0.385971 * 100, metric = 5.63% * 100;
 Minibatch[ 501- 600]: loss = 0.371322 * 100, metric = 5.52% * 100;
 Minibatch[ 601- 700]: loss = 0.370371 * 100, metric = 5.35% * 100;
 Minibatch[ 701- 800]: loss = 0.368027 * 100, metric = 5.24% * 100;
 Minibatch[ 801- 900]: loss = 0.366296 * 100, metric = 5.22% * 100;
 Minibatch[ 901-1000]: loss = 0.377650 * 100, metric = 5.71% * 100;
 Minibatch[1001-1100]: loss = 0.382359 * 100, metric = 5.62% * 100;
 Minibatch[1101-1200]: loss = 0.376069 * 100, metric = 5.53% * 100;
 Minibatch[1201-1300]: loss = 0.354973 * 100, metric = 5.07% * 100;
 Minibatch[1301-1400]: loss = 0.372324 * 100, metric = 5.23% * 100;
 Minibatch[1401-1500]: loss = 0.362556 * 100, metric = 5.26% * 100;
 Minibatch[1501-1600]: loss = 0.347402 * 100, metric = 4.77% * 100;
 Minibatch[1601-1700]: loss = 0.373875 * 100, metric = 5.65% * 100;
 Minibatch[1701-1800]: loss = 0.362006 * 100, metric = 5.32% * 100;
 Minibatch[1801-1900]: loss = 0.369800 * 100, metric = 5.34% * 100;
 Minibatch[1901-2000]: loss = 0.369165 * 100, metric = 5.23% * 100;
Finished Epoch[49 of 200]: [Training] loss = 0.370779 * 2000, metric = 5.40% * 2000 836.352s (  2.4 samples/s);
Finished Evaluation [49]: Minibatch[1-2000]: metric = 12.38% * 2000;
 Minibatch[   1- 100]: loss = 0.371890 * 100, metric = 5.21% * 100;
 Minibatch[ 101- 200]: loss = 0.361246 * 100, metric = 5.12% * 100;
 Minibatch[ 201- 300]: loss = 0.351805 * 100, metric = 4.79% * 100;
 Minibatch[ 301- 400]: loss = 0.363996 * 100, metric = 4.98% * 100;
 Minibatch[ 401- 500]: loss = 0.374112 * 100, metric = 5.68% * 100;
 Minibatch[ 501- 600]: loss = 0.384688 * 100, metric = 5.67% * 100;
 Minibatch[ 601- 700]: loss = 0.359605 * 100, metric = 5.10% * 100;
 Minibatch[ 701- 800]: loss = 0.362249 * 100, metric = 5.11% * 100;
 Minibatch[ 801- 900]: loss = 0.370535 * 100, metric = 5.30% * 100;
 Minibatch[ 901-1000]: loss = 0.364559 * 100, metric = 5.05% * 100;
 Minibatch[1001-1100]: loss = 0.361857 * 100, metric = 5.22% * 100;
 Minibatch[1101-1200]: loss = 0.365038 * 100, metric = 5.35% * 100;
 Minibatch[1201-1300]: loss = 0.371228 * 100, metric = 5.50% * 100;
 Minibatch[1301-1400]: loss = 0.356273 * 100, metric = 5.23% * 100;
 Minibatch[1401-1500]: loss = 0.366027 * 100, metric = 5.34% * 100;
 Minibatch[1501-1600]: loss = 0.356052 * 100, metric = 5.00% * 100;
 Minibatch[1601-1700]: loss = 0.361107 * 100, metric = 5.25% * 100;
 Minibatch[1701-1800]: loss = 0.373531 * 100, metric = 5.56% * 100;
 Minibatch[1801-1900]: loss = 0.369286 * 100, metric = 5.20% * 100;
 Minibatch[1901-2000]: loss = 0.367246 * 100, metric = 5.37% * 100;
Finished Epoch[50 of 200]: [Training] loss = 0.365616 * 2000, metric = 5.25% * 2000 825.110s (  2.4 samples/s);
Finished Evaluation [50]: Minibatch[1-2000]: metric = 13.16% * 2000;
 Minibatch[   1- 100]: loss = 0.352723 * 100, metric = 5.07% * 100;
 Minibatch[ 101- 200]: loss = 0.373967 * 100, metric = 5.60% * 100;
 Minibatch[ 201- 300]: loss = 0.372608 * 100, metric = 5.30% * 100;
 Minibatch[ 301- 400]: loss = 0.362524 * 100, metric = 5.24% * 100;
 Minibatch[ 401- 500]: loss = 0.360490 * 100, metric = 5.11% * 100;
 Minibatch[ 501- 600]: loss = 0.373437 * 100, metric = 5.64% * 100;
 Minibatch[ 601- 700]: loss = 0.346252 * 100, metric = 4.95% * 100;
 Minibatch[ 701- 800]: loss = 0.364145 * 100, metric = 5.20% * 100;
 Minibatch[ 801- 900]: loss = 0.361241 * 100, metric = 5.18% * 100;
 Minibatch[ 901-1000]: loss = 0.361878 * 100, metric = 5.08% * 100;
 Minibatch[1001-1100]: loss = 0.367581 * 100, metric = 5.43% * 100;
 Minibatch[1101-1200]: loss = 0.369990 * 100, metric = 5.34% * 100;
 Minibatch[1201-1300]: loss = 0.383800 * 100, metric = 5.51% * 100;
 Minibatch[1301-1400]: loss = 0.383712 * 100, metric = 5.50% * 100;
 Minibatch[1401-1500]: loss = 0.356747 * 100, metric = 5.18% * 100;
 Minibatch[1501-1600]: loss = 0.374365 * 100, metric = 5.39% * 100;
 Minibatch[1601-1700]: loss = 0.358323 * 100, metric = 5.24% * 100;
 Minibatch[1701-1800]: loss = 0.363879 * 100, metric = 5.39% * 100;
 Minibatch[1801-1900]: loss = 0.352434 * 100, metric = 5.10% * 100;
 Minibatch[1901-2000]: loss = 0.371498 * 100, metric = 5.45% * 100;
Finished Epoch[51 of 200]: [Training] loss = 0.365580 * 2000, metric = 5.29% * 2000 822.902s (  2.4 samples/s);
Finished Evaluation [51]: Minibatch[1-2000]: metric = 12.29% * 2000;
 Minibatch[   1- 100]: loss = 0.353380 * 100, metric = 5.24% * 100;
 Minibatch[ 101- 200]: loss = 0.363935 * 100, metric = 5.26% * 100;
 Minibatch[ 201- 300]: loss = 0.369238 * 100, metric = 5.63% * 100;
 Minibatch[ 301- 400]: loss = 0.357215 * 100, metric = 5.36% * 100;
 Minibatch[ 401- 500]: loss = 0.366893 * 100, metric = 5.19% * 100;
 Minibatch[ 501- 600]: loss = 0.369029 * 100, metric = 5.57% * 100;
 Minibatch[ 601- 700]: loss = 0.353682 * 100, metric = 5.10% * 100;
 Minibatch[ 701- 800]: loss = 0.382203 * 100, metric = 5.76% * 100;
 Minibatch[ 801- 900]: loss = 0.381604 * 100, metric = 5.68% * 100;
 Minibatch[ 901-1000]: loss = 0.377827 * 100, metric = 5.51% * 100;
 Minibatch[1001-1100]: loss = 0.366655 * 100, metric = 5.38% * 100;
 Minibatch[1101-1200]: loss = 0.363238 * 100, metric = 5.15% * 100;
 Minibatch[1201-1300]: loss = 0.360639 * 100, metric = 5.13% * 100;
 Minibatch[1301-1400]: loss = 0.366516 * 100, metric = 5.09% * 100;
 Minibatch[1401-1500]: loss = 0.346899 * 100, metric = 4.86% * 100;
 Minibatch[1501-1600]: loss = 0.347822 * 100, metric = 4.93% * 100;
 Minibatch[1601-1700]: loss = 0.362635 * 100, metric = 5.12% * 100;
 Minibatch[1701-1800]: loss = 0.357643 * 100, metric = 5.25% * 100;
 Minibatch[1801-1900]: loss = 0.357340 * 100, metric = 5.07% * 100;
 Minibatch[1901-2000]: loss = 0.363452 * 100, metric = 5.28% * 100;
Finished Epoch[52 of 200]: [Training] loss = 0.363392 * 2000, metric = 5.28% * 2000 847.835s (  2.4 samples/s);
Finished Evaluation [52]: Minibatch[1-2000]: metric = 12.67% * 2000;
 Minibatch[   1- 100]: loss = 0.370531 * 100, metric = 5.45% * 100;
 Minibatch[ 101- 200]: loss = 0.352291 * 100, metric = 4.90% * 100;
 Minibatch[ 201- 300]: loss = 0.358108 * 100, metric = 5.28% * 100;
 Minibatch[ 301- 400]: loss = 0.371212 * 100, metric = 5.33% * 100;
 Minibatch[ 401- 500]: loss = 0.362595 * 100, metric = 5.30% * 100;
 Minibatch[ 501- 600]: loss = 0.366176 * 100, metric = 5.47% * 100;
 Minibatch[ 601- 700]: loss = 0.363871 * 100, metric = 5.05% * 100;
 Minibatch[ 701- 800]: loss = 0.366285 * 100, metric = 5.19% * 100;
 Minibatch[ 801- 900]: loss = 0.363388 * 100, metric = 5.33% * 100;
 Minibatch[ 901-1000]: loss = 0.357960 * 100, metric = 5.17% * 100;
 Minibatch[1001-1100]: loss = 0.365989 * 100, metric = 5.24% * 100;
 Minibatch[1101-1200]: loss = 0.348246 * 100, metric = 5.06% * 100;
 Minibatch[1201-1300]: loss = 0.348674 * 100, metric = 5.02% * 100;
 Minibatch[1301-1400]: loss = 0.370141 * 100, metric = 5.31% * 100;
 Minibatch[1401-1500]: loss = 0.360738 * 100, metric = 5.28% * 100;
 Minibatch[1501-1600]: loss = 0.375891 * 100, metric = 5.53% * 100;
 Minibatch[1601-1700]: loss = 0.365974 * 100, metric = 5.20% * 100;
 Minibatch[1701-1800]: loss = 0.375632 * 100, metric = 5.51% * 100;
 Minibatch[1801-1900]: loss = 0.385897 * 100, metric = 5.77% * 100;
 Minibatch[1901-2000]: loss = 0.346422 * 100, metric = 4.92% * 100;
Finished Epoch[53 of 200]: [Training] loss = 0.363801 * 2000, metric = 5.27% * 2000 828.379s (  2.4 samples/s);
Finished Evaluation [53]: Minibatch[1-2000]: metric = 12.35% * 2000;
 Minibatch[   1- 100]: loss = 0.360117 * 100, metric = 5.23% * 100;
 Minibatch[ 101- 200]: loss = 0.367625 * 100, metric = 5.33% * 100;
 Minibatch[ 201- 300]: loss = 0.348125 * 100, metric = 5.00% * 100;
 Minibatch[ 301- 400]: loss = 0.355940 * 100, metric = 4.88% * 100;
 Minibatch[ 401- 500]: loss = 0.359233 * 100, metric = 5.11% * 100;
 Minibatch[ 501- 600]: loss = 0.354173 * 100, metric = 4.85% * 100;
 Minibatch[ 601- 700]: loss = 0.369526 * 100, metric = 5.39% * 100;
 Minibatch[ 701- 800]: loss = 0.358639 * 100, metric = 5.14% * 100;
 Minibatch[ 801- 900]: loss = 0.341827 * 100, metric = 4.76% * 100;
 Minibatch[ 901-1000]: loss = 0.364812 * 100, metric = 5.28% * 100;
 Minibatch[1001-1100]: loss = 0.352800 * 100, metric = 5.11% * 100;
 Minibatch[1101-1200]: loss = 0.354140 * 100, metric = 5.16% * 100;
 Minibatch[1201-1300]: loss = 0.356284 * 100, metric = 5.11% * 100;
 Minibatch[1301-1400]: loss = 0.348822 * 100, metric = 5.05% * 100;
 Minibatch[1401-1500]: loss = 0.363244 * 100, metric = 5.10% * 100;
 Minibatch[1501-1600]: loss = 0.359904 * 100, metric = 5.22% * 100;
 Minibatch[1601-1700]: loss = 0.348245 * 100, metric = 4.97% * 100;
 Minibatch[1701-1800]: loss = 0.354029 * 100, metric = 5.02% * 100;
 Minibatch[1801-1900]: loss = 0.366476 * 100, metric = 5.26% * 100;
 Minibatch[1901-2000]: loss = 0.354542 * 100, metric = 4.99% * 100;
Finished Epoch[54 of 200]: [Training] loss = 0.356925 * 2000, metric = 5.10% * 2000 818.361s (  2.4 samples/s);
Finished Evaluation [54]: Minibatch[1-2000]: metric = 11.89% * 2000;
0.591910751964897
 Minibatch[   1- 100]: loss = 0.362294 * 100, metric = 5.00% * 100;
 Minibatch[ 101- 200]: loss = 0.359971 * 100, metric = 5.15% * 100;
 Minibatch[ 201- 300]: loss = 0.363817 * 100, metric = 5.22% * 100;
 Minibatch[ 301- 400]: loss = 0.346648 * 100, metric = 4.97% * 100;
 Minibatch[ 401- 500]: loss = 0.350946 * 100, metric = 4.91% * 100;
 Minibatch[ 501- 600]: loss = 0.357637 * 100, metric = 4.89% * 100;
 Minibatch[ 601- 700]: loss = 0.358887 * 100, metric = 5.20% * 100;
 Minibatch[ 701- 800]: loss = 0.362912 * 100, metric = 5.17% * 100;
 Minibatch[ 801- 900]: loss = 0.353823 * 100, metric = 5.25% * 100;
 Minibatch[ 901-1000]: loss = 0.347014 * 100, metric = 4.80% * 100;
 Minibatch[1001-1100]: loss = 0.364386 * 100, metric = 5.21% * 100;
 Minibatch[1101-1200]: loss = 0.352006 * 100, metric = 4.90% * 100;
 Minibatch[1201-1300]: loss = 0.355035 * 100, metric = 4.96% * 100;
 Minibatch[1301-1400]: loss = 0.346565 * 100, metric = 4.85% * 100;
 Minibatch[1401-1500]: loss = 0.353055 * 100, metric = 4.97% * 100;
 Minibatch[1501-1600]: loss = 0.361439 * 100, metric = 5.07% * 100;
 Minibatch[1601-1700]: loss = 0.349130 * 100, metric = 5.04% * 100;
 Minibatch[1701-1800]: loss = 0.358802 * 100, metric = 5.00% * 100;
 Minibatch[1801-1900]: loss = 0.334576 * 100, metric = 4.67% * 100;
 Minibatch[1901-2000]: loss = 0.347639 * 100, metric = 4.78% * 100;
Finished Epoch[55 of 200]: [Training] loss = 0.354329 * 2000, metric = 5.00% * 2000 812.582s (  2.5 samples/s);
Finished Evaluation [55]: Minibatch[1-2000]: metric = 12.38% * 2000;
 Minibatch[   1- 100]: loss = 0.347892 * 100, metric = 4.92% * 100;
 Minibatch[ 101- 200]: loss = 0.346850 * 100, metric = 4.86% * 100;
 Minibatch[ 201- 300]: loss = 0.365053 * 100, metric = 5.26% * 100;
 Minibatch[ 301- 400]: loss = 0.359025 * 100, metric = 5.11% * 100;
 Minibatch[ 401- 500]: loss = 0.363203 * 100, metric = 5.27% * 100;
 Minibatch[ 501- 600]: loss = 0.367699 * 100, metric = 5.29% * 100;
 Minibatch[ 601- 700]: loss = 0.359828 * 100, metric = 5.10% * 100;
 Minibatch[ 701- 800]: loss = 0.355056 * 100, metric = 4.89% * 100;
 Minibatch[ 801- 900]: loss = 0.353044 * 100, metric = 4.90% * 100;
 Minibatch[ 901-1000]: loss = 0.358720 * 100, metric = 5.21% * 100;
 Minibatch[1001-1100]: loss = 0.357349 * 100, metric = 5.05% * 100;
 Minibatch[1101-1200]: loss = 0.352877 * 100, metric = 5.03% * 100;
 Minibatch[1201-1300]: loss = 0.349263 * 100, metric = 4.77% * 100;
 Minibatch[1301-1400]: loss = 0.342333 * 100, metric = 4.58% * 100;
 Minibatch[1401-1500]: loss = 0.358600 * 100, metric = 5.05% * 100;
 Minibatch[1501-1600]: loss = 0.358387 * 100, metric = 5.05% * 100;
 Minibatch[1601-1700]: loss = 0.348456 * 100, metric = 4.85% * 100;
 Minibatch[1701-1800]: loss = 0.343064 * 100, metric = 4.79% * 100;
 Minibatch[1801-1900]: loss = 0.340309 * 100, metric = 4.70% * 100;
 Minibatch[1901-2000]: loss = 0.357282 * 100, metric = 5.07% * 100;
Finished Epoch[56 of 200]: [Training] loss = 0.354215 * 2000, metric = 4.99% * 2000 818.388s (  2.4 samples/s);
Finished Evaluation [56]: Minibatch[1-2000]: metric = 12.07% * 2000;
 Minibatch[   1- 100]: loss = 0.357852 * 100, metric = 5.07% * 100;
 Minibatch[ 101- 200]: loss = 0.341620 * 100, metric = 4.88% * 100;
 Minibatch[ 201- 300]: loss = 0.349156 * 100, metric = 4.83% * 100;
 Minibatch[ 301- 400]: loss = 0.347175 * 100, metric = 4.74% * 100;
 Minibatch[ 401- 500]: loss = 0.345760 * 100, metric = 4.94% * 100;
 Minibatch[ 501- 600]: loss = 0.342634 * 100, metric = 4.75% * 100;
 Minibatch[ 601- 700]: loss = 0.349162 * 100, metric = 4.81% * 100;
 Minibatch[ 701- 800]: loss = 0.343374 * 100, metric = 4.90% * 100;
 Minibatch[ 801- 900]: loss = 0.352718 * 100, metric = 4.91% * 100;
 Minibatch[ 901-1000]: loss = 0.343872 * 100, metric = 4.76% * 100;
 Minibatch[1001-1100]: loss = 0.356913 * 100, metric = 5.05% * 100;
 Minibatch[1101-1200]: loss = 0.338783 * 100, metric = 4.70% * 100;
 Minibatch[1201-1300]: loss = 0.354163 * 100, metric = 5.00% * 100;
 Minibatch[1301-1400]: loss = 0.342588 * 100, metric = 4.91% * 100;
 Minibatch[1401-1500]: loss = 0.355439 * 100, metric = 5.00% * 100;
 Minibatch[1501-1600]: loss = 0.346650 * 100, metric = 4.74% * 100;
 Minibatch[1601-1700]: loss = 0.345615 * 100, metric = 4.76% * 100;
 Minibatch[1701-1800]: loss = 0.350186 * 100, metric = 5.09% * 100;
 Minibatch[1801-1900]: loss = 0.357908 * 100, metric = 4.97% * 100;
 Minibatch[1901-2000]: loss = 0.358664 * 100, metric = 5.11% * 100;
Finished Epoch[57 of 200]: [Training] loss = 0.349012 * 2000, metric = 4.90% * 2000 821.146s (  2.4 samples/s);
Finished Evaluation [57]: Minibatch[1-2000]: metric = 11.87% * 2000;
 Minibatch[   1- 100]: loss = 0.346791 * 100, metric = 4.72% * 100;
 Minibatch[ 101- 200]: loss = 0.344292 * 100, metric = 4.76% * 100;
 Minibatch[ 201- 300]: loss = 0.339064 * 100, metric = 4.92% * 100;
 Minibatch[ 301- 400]: loss = 0.346806 * 100, metric = 4.78% * 100;
 Minibatch[ 401- 500]: loss = 0.362642 * 100, metric = 5.14% * 100;
 Minibatch[ 501- 600]: loss = 0.344531 * 100, metric = 4.64% * 100;
 Minibatch[ 601- 700]: loss = 0.343689 * 100, metric = 4.76% * 100;
 Minibatch[ 701- 800]: loss = 0.354643 * 100, metric = 4.99% * 100;
 Minibatch[ 801- 900]: loss = 0.348559 * 100, metric = 4.88% * 100;
 Minibatch[ 901-1000]: loss = 0.336414 * 100, metric = 4.69% * 100;
 Minibatch[1001-1100]: loss = 0.337617 * 100, metric = 4.70% * 100;
 Minibatch[1101-1200]: loss = 0.362849 * 100, metric = 5.11% * 100;
 Minibatch[1201-1300]: loss = 0.350629 * 100, metric = 4.94% * 100;
 Minibatch[1301-1400]: loss = 0.352488 * 100, metric = 4.99% * 100;
 Minibatch[1401-1500]: loss = 0.342251 * 100, metric = 4.56% * 100;
 Minibatch[1501-1600]: loss = 0.339296 * 100, metric = 4.68% * 100;
 Minibatch[1601-1700]: loss = 0.352444 * 100, metric = 4.76% * 100;
 Minibatch[1701-1800]: loss = 0.336974 * 100, metric = 4.72% * 100;
 Minibatch[1801-1900]: loss = 0.343244 * 100, metric = 4.77% * 100;
 Minibatch[1901-2000]: loss = 0.331667 * 100, metric = 4.38% * 100;
Finished Epoch[58 of 200]: [Training] loss = 0.345845 * 2000, metric = 4.79% * 2000 819.944s (  2.4 samples/s);
Finished Evaluation [58]: Minibatch[1-2000]: metric = 11.67% * 2000;
 Minibatch[   1- 100]: loss = 0.347026 * 100, metric = 5.06% * 100;
 Minibatch[ 101- 200]: loss = 0.352761 * 100, metric = 4.98% * 100;
 Minibatch[ 201- 300]: loss = 0.328812 * 100, metric = 4.62% * 100;
 Minibatch[ 301- 400]: loss = 0.336771 * 100, metric = 4.52% * 100;
 Minibatch[ 401- 500]: loss = 0.338959 * 100, metric = 4.64% * 100;
 Minibatch[ 501- 600]: loss = 0.336741 * 100, metric = 4.63% * 100;
 Minibatch[ 601- 700]: loss = 0.339001 * 100, metric = 4.59% * 100;
 Minibatch[ 701- 800]: loss = 0.345715 * 100, metric = 4.61% * 100;
 Minibatch[ 801- 900]: loss = 0.333717 * 100, metric = 4.76% * 100;
 Minibatch[ 901-1000]: loss = 0.345591 * 100, metric = 5.00% * 100;
 Minibatch[1001-1100]: loss = 0.337226 * 100, metric = 4.80% * 100;
 Minibatch[1101-1200]: loss = 0.352793 * 100, metric = 5.08% * 100;
 Minibatch[1201-1300]: loss = 0.343590 * 100, metric = 4.65% * 100;
 Minibatch[1301-1400]: loss = 0.336043 * 100, metric = 4.61% * 100;
 Minibatch[1401-1500]: loss = 0.341986 * 100, metric = 4.87% * 100;
 Minibatch[1501-1600]: loss = 0.350468 * 100, metric = 4.88% * 100;
 Minibatch[1601-1700]: loss = 0.338231 * 100, metric = 4.90% * 100;
 Minibatch[1701-1800]: loss = 0.349512 * 100, metric = 4.74% * 100;
 Minibatch[1801-1900]: loss = 0.345623 * 100, metric = 4.72% * 100;
 Minibatch[1901-2000]: loss = 0.345317 * 100, metric = 4.71% * 100;
Finished Epoch[59 of 200]: [Training] loss = 0.342294 * 2000, metric = 4.77% * 2000 821.476s (  2.4 samples/s);
Finished Evaluation [59]: Minibatch[1-2000]: metric = 12.57% * 2000;
 Minibatch[   1- 100]: loss = 0.336989 * 100, metric = 4.62% * 100;
 Minibatch[ 101- 200]: loss = 0.326854 * 100, metric = 4.46% * 100;
 Minibatch[ 201- 300]: loss = 0.317265 * 100, metric = 4.20% * 100;
 Minibatch[ 301- 400]: loss = 0.343447 * 100, metric = 4.54% * 100;
 Minibatch[ 401- 500]: loss = 0.343787 * 100, metric = 4.91% * 100;
 Minibatch[ 501- 600]: loss = 0.342699 * 100, metric = 4.87% * 100;
 Minibatch[ 601- 700]: loss = 0.331527 * 100, metric = 4.46% * 100;
 Minibatch[ 701- 800]: loss = 0.342370 * 100, metric = 4.58% * 100;
 Minibatch[ 801- 900]: loss = 0.339017 * 100, metric = 4.72% * 100;
 Minibatch[ 901-1000]: loss = 0.346042 * 100, metric = 4.86% * 100;
 Minibatch[1001-1100]: loss = 0.351779 * 100, metric = 5.09% * 100;
 Minibatch[1101-1200]: loss = 0.342982 * 100, metric = 4.67% * 100;
 Minibatch[1201-1300]: loss = 0.341475 * 100, metric = 4.88% * 100;
 Minibatch[1301-1400]: loss = 0.340873 * 100, metric = 4.86% * 100;
 Minibatch[1401-1500]: loss = 0.332044 * 100, metric = 4.45% * 100;
 Minibatch[1501-1600]: loss = 0.336960 * 100, metric = 4.52% * 100;
 Minibatch[1601-1700]: loss = 0.337902 * 100, metric = 4.79% * 100;
 Minibatch[1701-1800]: loss = 0.353805 * 100, metric = 4.72% * 100;
 Minibatch[1801-1900]: loss = 0.344368 * 100, metric = 4.73% * 100;
 Minibatch[1901-2000]: loss = 0.328156 * 100, metric = 4.57% * 100;
Finished Epoch[60 of 200]: [Training] loss = 0.339017 * 2000, metric = 4.68% * 2000 813.728s (  2.5 samples/s);
Finished Evaluation [60]: Minibatch[1-2000]: metric = 12.80% * 2000;
 Minibatch[   1- 100]: loss = 0.346957 * 100, metric = 4.92% * 100;
 Minibatch[ 101- 200]: loss = 0.328928 * 100, metric = 4.38% * 100;
 Minibatch[ 201- 300]: loss = 0.330874 * 100, metric = 4.65% * 100;
 Minibatch[ 301- 400]: loss = 0.348360 * 100, metric = 4.88% * 100;
 Minibatch[ 401- 500]: loss = 0.332741 * 100, metric = 4.61% * 100;
 Minibatch[ 501- 600]: loss = 0.315445 * 100, metric = 4.13% * 100;
 Minibatch[ 601- 700]: loss = 0.343674 * 100, metric = 4.62% * 100;
 Minibatch[ 701- 800]: loss = 0.341829 * 100, metric = 4.77% * 100;
 Minibatch[ 801- 900]: loss = 0.331672 * 100, metric = 4.46% * 100;
 Minibatch[ 901-1000]: loss = 0.330253 * 100, metric = 4.68% * 100;
 Minibatch[1001-1100]: loss = 0.330131 * 100, metric = 4.54% * 100;
 Minibatch[1101-1200]: loss = 0.344272 * 100, metric = 4.63% * 100;
 Minibatch[1201-1300]: loss = 0.325235 * 100, metric = 4.41% * 100;
 Minibatch[1301-1400]: loss = 0.318647 * 100, metric = 3.93% * 100;
 Minibatch[1401-1500]: loss = 0.339694 * 100, metric = 4.58% * 100;
 Minibatch[1501-1600]: loss = 0.341247 * 100, metric = 4.74% * 100;
 Minibatch[1601-1700]: loss = 0.346271 * 100, metric = 4.77% * 100;
 Minibatch[1701-1800]: loss = 0.333612 * 100, metric = 4.52% * 100;
 Minibatch[1801-1900]: loss = 0.328915 * 100, metric = 4.60% * 100;
 Minibatch[1901-2000]: loss = 0.334481 * 100, metric = 4.44% * 100;
Finished Epoch[61 of 200]: [Training] loss = 0.334662 * 2000, metric = 4.56% * 2000 817.896s (  2.4 samples/s);
Finished Evaluation [61]: Minibatch[1-2000]: metric = 12.15% * 2000;
 Minibatch[   1- 100]: loss = 0.329687 * 100, metric = 4.52% * 100;
 Minibatch[ 101- 200]: loss = 0.335229 * 100, metric = 4.61% * 100;
 Minibatch[ 201- 300]: loss = 0.339469 * 100, metric = 4.78% * 100;
 Minibatch[ 301- 400]: loss = 0.342428 * 100, metric = 4.75% * 100;
 Minibatch[ 401- 500]: loss = 0.338730 * 100, metric = 4.46% * 100;
 Minibatch[ 501- 600]: loss = 0.330386 * 100, metric = 4.55% * 100;
 Minibatch[ 601- 700]: loss = 0.342838 * 100, metric = 4.81% * 100;
 Minibatch[ 701- 800]: loss = 0.329207 * 100, metric = 4.43% * 100;
 Minibatch[ 801- 900]: loss = 0.330811 * 100, metric = 4.60% * 100;
 Minibatch[ 901-1000]: loss = 0.345433 * 100, metric = 4.84% * 100;
 Minibatch[1001-1100]: loss = 0.317486 * 100, metric = 4.37% * 100;
 Minibatch[1101-1200]: loss = 0.355703 * 100, metric = 4.95% * 100;
 Minibatch[1201-1300]: loss = 0.337070 * 100, metric = 4.63% * 100;
 Minibatch[1301-1400]: loss = 0.346642 * 100, metric = 4.67% * 100;
 Minibatch[1401-1500]: loss = 0.325072 * 100, metric = 4.32% * 100;
 Minibatch[1501-1600]: loss = 0.333342 * 100, metric = 4.46% * 100;
 Minibatch[1601-1700]: loss = 0.332372 * 100, metric = 4.46% * 100;
 Minibatch[1701-1800]: loss = 0.339706 * 100, metric = 4.61% * 100;
 Minibatch[1801-1900]: loss = 0.346907 * 100, metric = 4.83% * 100;
 Minibatch[1901-2000]: loss = 0.345445 * 100, metric = 4.74% * 100;
Finished Epoch[62 of 200]: [Training] loss = 0.337198 * 2000, metric = 4.62% * 2000 802.598s (  2.5 samples/s);
Finished Evaluation [62]: Minibatch[1-2000]: metric = 12.17% * 2000;
 Minibatch[   1- 100]: loss = 0.344759 * 100, metric = 4.65% * 100;
 Minibatch[ 101- 200]: loss = 0.326996 * 100, metric = 4.32% * 100;
 Minibatch[ 201- 300]: loss = 0.345481 * 100, metric = 4.82% * 100;
 Minibatch[ 301- 400]: loss = 0.327199 * 100, metric = 4.47% * 100;
 Minibatch[ 401- 500]: loss = 0.318835 * 100, metric = 4.29% * 100;
 Minibatch[ 501- 600]: loss = 0.320668 * 100, metric = 4.39% * 100;
 Minibatch[ 601- 700]: loss = 0.328403 * 100, metric = 4.63% * 100;
 Minibatch[ 701- 800]: loss = 0.337865 * 100, metric = 4.82% * 100;
 Minibatch[ 801- 900]: loss = 0.333732 * 100, metric = 4.62% * 100;
 Minibatch[ 901-1000]: loss = 0.323997 * 100, metric = 4.37% * 100;
 Minibatch[1001-1100]: loss = 0.339880 * 100, metric = 4.70% * 100;
 Minibatch[1101-1200]: loss = 0.331989 * 100, metric = 4.47% * 100;
 Minibatch[1201-1300]: loss = 0.334834 * 100, metric = 4.30% * 100;
 Minibatch[1301-1400]: loss = 0.338618 * 100, metric = 4.44% * 100;
 Minibatch[1401-1500]: loss = 0.322047 * 100, metric = 4.33% * 100;
 Minibatch[1501-1600]: loss = 0.329569 * 100, metric = 4.60% * 100;
 Minibatch[1601-1700]: loss = 0.333768 * 100, metric = 4.50% * 100;
 Minibatch[1701-1800]: loss = 0.319688 * 100, metric = 4.38% * 100;
 Minibatch[1801-1900]: loss = 0.330303 * 100, metric = 4.32% * 100;
 Minibatch[1901-2000]: loss = 0.332575 * 100, metric = 4.45% * 100;
Finished Epoch[63 of 200]: [Training] loss = 0.331060 * 2000, metric = 4.49% * 2000 783.642s (  2.6 samples/s);
Finished Evaluation [63]: Minibatch[1-2000]: metric = 12.69% * 2000;
 Minibatch[   1- 100]: loss = 0.328013 * 100, metric = 4.46% * 100;
 Minibatch[ 101- 200]: loss = 0.334569 * 100, metric = 4.46% * 100;
 Minibatch[ 201- 300]: loss = 0.328540 * 100, metric = 4.44% * 100;
 Minibatch[ 301- 400]: loss = 0.331264 * 100, metric = 4.43% * 100;
 Minibatch[ 401- 500]: loss = 0.326972 * 100, metric = 4.31% * 100;
 Minibatch[ 501- 600]: loss = 0.327495 * 100, metric = 4.27% * 100;
 Minibatch[ 601- 700]: loss = 0.326409 * 100, metric = 4.30% * 100;
 Minibatch[ 701- 800]: loss = 0.339671 * 100, metric = 4.56% * 100;
 Minibatch[ 801- 900]: loss = 0.337234 * 100, metric = 4.49% * 100;
 Minibatch[ 901-1000]: loss = 0.326806 * 100, metric = 4.39% * 100;
 Minibatch[1001-1100]: loss = 0.328111 * 100, metric = 4.36% * 100;
 Minibatch[1101-1200]: loss = 0.328065 * 100, metric = 4.44% * 100;
 Minibatch[1201-1300]: loss = 0.334849 * 100, metric = 4.46% * 100;
 Minibatch[1301-1400]: loss = 0.341486 * 100, metric = 4.71% * 100;
 Minibatch[1401-1500]: loss = 0.341259 * 100, metric = 4.82% * 100;
 Minibatch[1501-1600]: loss = 0.338868 * 100, metric = 4.60% * 100;
 Minibatch[1601-1700]: loss = 0.326545 * 100, metric = 4.17% * 100;
 Minibatch[1701-1800]: loss = 0.321782 * 100, metric = 4.17% * 100;
 Minibatch[1801-1900]: loss = 0.338582 * 100, metric = 4.67% * 100;
 Minibatch[1901-2000]: loss = 0.322284 * 100, metric = 4.38% * 100;
Finished Epoch[64 of 200]: [Training] loss = 0.331440 * 2000, metric = 4.44% * 2000 792.729s (  2.5 samples/s);
Finished Evaluation [64]: Minibatch[1-2000]: metric = 14.64% * 2000;
 Minibatch[   1- 100]: loss = 0.319428 * 100, metric = 4.38% * 100;
 Minibatch[ 101- 200]: loss = 0.324957 * 100, metric = 4.34% * 100;
 Minibatch[ 201- 300]: loss = 0.328345 * 100, metric = 4.30% * 100;
 Minibatch[ 301- 400]: loss = 0.333346 * 100, metric = 4.57% * 100;
 Minibatch[ 401- 500]: loss = 0.334646 * 100, metric = 4.42% * 100;
 Minibatch[ 501- 600]: loss = 0.334447 * 100, metric = 4.52% * 100;
 Minibatch[ 601- 700]: loss = 0.329290 * 100, metric = 4.52% * 100;
 Minibatch[ 701- 800]: loss = 0.353375 * 100, metric = 5.03% * 100;
 Minibatch[ 801- 900]: loss = 0.336875 * 100, metric = 4.51% * 100;
 Minibatch[ 901-1000]: loss = 0.325366 * 100, metric = 4.35% * 100;
 Minibatch[1001-1100]: loss = 0.324854 * 100, metric = 4.48% * 100;
 Minibatch[1101-1200]: loss = 0.334850 * 100, metric = 4.53% * 100;
 Minibatch[1201-1300]: loss = 0.333061 * 100, metric = 4.47% * 100;
 Minibatch[1301-1400]: loss = 0.319774 * 100, metric = 4.30% * 100;
 Minibatch[1401-1500]: loss = 0.325220 * 100, metric = 4.40% * 100;
 Minibatch[1501-1600]: loss = 0.324822 * 100, metric = 4.49% * 100;
 Minibatch[1601-1700]: loss = 0.337193 * 100, metric = 4.57% * 100;
 Minibatch[1701-1800]: loss = 0.340696 * 100, metric = 4.80% * 100;
 Minibatch[1801-1900]: loss = 0.341648 * 100, metric = 4.67% * 100;
 Minibatch[1901-2000]: loss = 0.335829 * 100, metric = 4.51% * 100;
Finished Epoch[65 of 200]: [Training] loss = 0.331901 * 2000, metric = 4.51% * 2000 813.035s (  2.5 samples/s);
Finished Evaluation [65]: Minibatch[1-2000]: metric = 11.77% * 2000;
 Minibatch[   1- 100]: loss = 0.331513 * 100, metric = 4.60% * 100;
 Minibatch[ 101- 200]: loss = 0.332168 * 100, metric = 4.65% * 100;
 Minibatch[ 201- 300]: loss = 0.335242 * 100, metric = 4.48% * 100;
 Minibatch[ 301- 400]: loss = 0.323427 * 100, metric = 4.40% * 100;
 Minibatch[ 401- 500]: loss = 0.336954 * 100, metric = 4.64% * 100;
 Minibatch[ 501- 600]: loss = 0.333992 * 100, metric = 4.44% * 100;
 Minibatch[ 601- 700]: loss = 0.329827 * 100, metric = 4.42% * 100;
 Minibatch[ 701- 800]: loss = 0.327202 * 100, metric = 4.62% * 100;
 Minibatch[ 801- 900]: loss = 0.318453 * 100, metric = 4.10% * 100;
 Minibatch[ 901-1000]: loss = 0.314997 * 100, metric = 4.09% * 100;
 Minibatch[1001-1100]: loss = 0.330884 * 100, metric = 4.57% * 100;
 Minibatch[1101-1200]: loss = 0.324173 * 100, metric = 4.53% * 100;
 Minibatch[1201-1300]: loss = 0.337332 * 100, metric = 4.72% * 100;
 Minibatch[1301-1400]: loss = 0.320356 * 100, metric = 4.26% * 100;
 Minibatch[1401-1500]: loss = 0.321713 * 100, metric = 4.21% * 100;
 Minibatch[1501-1600]: loss = 0.328235 * 100, metric = 4.59% * 100;
 Minibatch[1601-1700]: loss = 0.337128 * 100, metric = 4.33% * 100;
 Minibatch[1701-1800]: loss = 0.331702 * 100, metric = 4.54% * 100;
 Minibatch[1801-1900]: loss = 0.335659 * 100, metric = 4.64% * 100;
 Minibatch[1901-2000]: loss = 0.330023 * 100, metric = 4.69% * 100;
Finished Epoch[66 of 200]: [Training] loss = 0.329049 * 2000, metric = 4.48% * 2000 807.364s (  2.5 samples/s);
Finished Evaluation [66]: Minibatch[1-2000]: metric = 12.14% * 2000;
 Minibatch[   1- 100]: loss = 0.332835 * 100, metric = 4.48% * 100;
 Minibatch[ 101- 200]: loss = 0.330592 * 100, metric = 4.43% * 100;
 Minibatch[ 201- 300]: loss = 0.327668 * 100, metric = 4.37% * 100;
 Minibatch[ 301- 400]: loss = 0.350778 * 100, metric = 4.72% * 100;
 Minibatch[ 401- 500]: loss = 0.330108 * 100, metric = 4.59% * 100;
 Minibatch[ 501- 600]: loss = 0.334576 * 100, metric = 4.46% * 100;
 Minibatch[ 601- 700]: loss = 0.327909 * 100, metric = 4.40% * 100;
 Minibatch[ 701- 800]: loss = 0.330684 * 100, metric = 4.38% * 100;
 Minibatch[ 801- 900]: loss = 0.328819 * 100, metric = 4.36% * 100;
 Minibatch[ 901-1000]: loss = 0.345610 * 100, metric = 4.58% * 100;
 Minibatch[1001-1100]: loss = 0.335181 * 100, metric = 4.53% * 100;
 Minibatch[1101-1200]: loss = 0.331985 * 100, metric = 4.46% * 100;
 Minibatch[1201-1300]: loss = 0.334892 * 100, metric = 4.57% * 100;
 Minibatch[1301-1400]: loss = 0.336397 * 100, metric = 4.52% * 100;
 Minibatch[1401-1500]: loss = 0.315707 * 100, metric = 4.33% * 100;
 Minibatch[1501-1600]: loss = 0.326887 * 100, metric = 4.45% * 100;
 Minibatch[1601-1700]: loss = 0.326445 * 100, metric = 4.42% * 100;
 Minibatch[1701-1800]: loss = 0.337925 * 100, metric = 4.82% * 100;
 Minibatch[1801-1900]: loss = 0.320049 * 100, metric = 4.26% * 100;
 Minibatch[1901-2000]: loss = 0.335752 * 100, metric = 4.63% * 100;
Finished Epoch[67 of 200]: [Training] loss = 0.332040 * 2000, metric = 4.49% * 2000 810.338s (  2.5 samples/s);
Finished Evaluation [67]: Minibatch[1-2000]: metric = 11.53% * 2000;
 Minibatch[   1- 100]: loss = 0.322543 * 100, metric = 4.45% * 100;
 Minibatch[ 101- 200]: loss = 0.334315 * 100, metric = 4.43% * 100;
 Minibatch[ 201- 300]: loss = 0.336456 * 100, metric = 4.65% * 100;
 Minibatch[ 301- 400]: loss = 0.331576 * 100, metric = 4.42% * 100;
 Minibatch[ 401- 500]: loss = 0.339190 * 100, metric = 4.37% * 100;
 Minibatch[ 501- 600]: loss = 0.322491 * 100, metric = 4.47% * 100;
 Minibatch[ 601- 700]: loss = 0.322443 * 100, metric = 4.31% * 100;
 Minibatch[ 701- 800]: loss = 0.331718 * 100, metric = 4.44% * 100;
 Minibatch[ 801- 900]: loss = 0.309990 * 100, metric = 3.97% * 100;
 Minibatch[ 901-1000]: loss = 0.322385 * 100, metric = 4.17% * 100;
 Minibatch[1001-1100]: loss = 0.330819 * 100, metric = 4.37% * 100;
 Minibatch[1101-1200]: loss = 0.332839 * 100, metric = 4.48% * 100;
 Minibatch[1201-1300]: loss = 0.321598 * 100, metric = 4.20% * 100;
 Minibatch[1301-1400]: loss = 0.312222 * 100, metric = 4.14% * 100;
 Minibatch[1401-1500]: loss = 0.325038 * 100, metric = 4.39% * 100;
 Minibatch[1501-1600]: loss = 0.313916 * 100, metric = 4.07% * 100;
 Minibatch[1601-1700]: loss = 0.316490 * 100, metric = 3.94% * 100;
 Minibatch[1701-1800]: loss = 0.330291 * 100, metric = 4.26% * 100;
 Minibatch[1801-1900]: loss = 0.329128 * 100, metric = 4.37% * 100;
 Minibatch[1901-2000]: loss = 0.306848 * 100, metric = 3.97% * 100;
Finished Epoch[68 of 200]: [Training] loss = 0.324615 * 2000, metric = 4.29% * 2000 805.671s (  2.5 samples/s);
Finished Evaluation [68]: Minibatch[1-2000]: metric = 11.66% * 2000;
 Minibatch[   1- 100]: loss = 0.310018 * 100, metric = 4.06% * 100;
 Minibatch[ 101- 200]: loss = 0.325727 * 100, metric = 4.36% * 100;
 Minibatch[ 201- 300]: loss = 0.319502 * 100, metric = 3.95% * 100;
 Minibatch[ 301- 400]: loss = 0.332273 * 100, metric = 4.32% * 100;
 Minibatch[ 401- 500]: loss = 0.327975 * 100, metric = 4.28% * 100;
 Minibatch[ 501- 600]: loss = 0.324201 * 100, metric = 4.38% * 100;
 Minibatch[ 601- 700]: loss = 0.321659 * 100, metric = 4.10% * 100;
 Minibatch[ 701- 800]: loss = 0.331273 * 100, metric = 4.53% * 100;
 Minibatch[ 801- 900]: loss = 0.324453 * 100, metric = 4.27% * 100;
 Minibatch[ 901-1000]: loss = 0.319719 * 100, metric = 4.06% * 100;
 Minibatch[1001-1100]: loss = 0.329718 * 100, metric = 4.42% * 100;
 Minibatch[1101-1200]: loss = 0.316014 * 100, metric = 3.84% * 100;
 Minibatch[1201-1300]: loss = 0.327405 * 100, metric = 4.30% * 100;
 Minibatch[1301-1400]: loss = 0.316804 * 100, metric = 3.99% * 100;
 Minibatch[1401-1500]: loss = 0.322119 * 100, metric = 4.12% * 100;
 Minibatch[1501-1600]: loss = 0.313028 * 100, metric = 4.08% * 100;
 Minibatch[1601-1700]: loss = 0.332325 * 100, metric = 4.31% * 100;
 Minibatch[1701-1800]: loss = 0.324582 * 100, metric = 4.41% * 100;
 Minibatch[1801-1900]: loss = 0.312759 * 100, metric = 3.95% * 100;
 Minibatch[1901-2000]: loss = 0.325030 * 100, metric = 4.28% * 100;
Finished Epoch[69 of 200]: [Training] loss = 0.322829 * 2000, metric = 4.20% * 2000 807.376s (  2.5 samples/s);
Finished Evaluation [69]: Minibatch[1-2000]: metric = 11.43% * 2000;
 Minibatch[   1- 100]: loss = 0.319093 * 100, metric = 4.08% * 100;
 Minibatch[ 101- 200]: loss = 0.307678 * 100, metric = 3.91% * 100;
 Minibatch[ 201- 300]: loss = 0.322035 * 100, metric = 4.20% * 100;
 Minibatch[ 301- 400]: loss = 0.310283 * 100, metric = 4.00% * 100;
 Minibatch[ 401- 500]: loss = 0.319815 * 100, metric = 4.06% * 100;
 Minibatch[ 501- 600]: loss = 0.315541 * 100, metric = 4.26% * 100;
 Minibatch[ 601- 700]: loss = 0.323196 * 100, metric = 4.03% * 100;
 Minibatch[ 701- 800]: loss = 0.313477 * 100, metric = 4.17% * 100;
 Minibatch[ 801- 900]: loss = 0.307370 * 100, metric = 3.75% * 100;
 Minibatch[ 901-1000]: loss = 0.321086 * 100, metric = 4.22% * 100;
 Minibatch[1001-1100]: loss = 0.307404 * 100, metric = 3.88% * 100;
 Minibatch[1101-1200]: loss = 0.297144 * 100, metric = 3.91% * 100;
 Minibatch[1201-1300]: loss = 0.310262 * 100, metric = 3.99% * 100;
 Minibatch[1301-1400]: loss = 0.318015 * 100, metric = 4.32% * 100;
 Minibatch[1401-1500]: loss = 0.312362 * 100, metric = 3.93% * 100;
 Minibatch[1501-1600]: loss = 0.311899 * 100, metric = 4.10% * 100;
 Minibatch[1601-1700]: loss = 0.320640 * 100, metric = 4.18% * 100;
 Minibatch[1701-1800]: loss = 0.323241 * 100, metric = 4.29% * 100;
 Minibatch[1801-1900]: loss = 0.308091 * 100, metric = 3.86% * 100;
 Minibatch[1901-2000]: loss = 0.316506 * 100, metric = 4.19% * 100;
Finished Epoch[70 of 200]: [Training] loss = 0.314257 * 2000, metric = 4.07% * 2000 805.525s (  2.5 samples/s);
Finished Evaluation [70]: Minibatch[1-2000]: metric = 11.86% * 2000;
 Minibatch[   1- 100]: loss = 0.327638 * 100, metric = 4.52% * 100;
 Minibatch[ 101- 200]: loss = 0.310185 * 100, metric = 3.81% * 100;
 Minibatch[ 201- 300]: loss = 0.324878 * 100, metric = 4.22% * 100;
 Minibatch[ 301- 400]: loss = 0.308430 * 100, metric = 3.84% * 100;
 Minibatch[ 401- 500]: loss = 0.304721 * 100, metric = 3.94% * 100;
 Minibatch[ 501- 600]: loss = 0.311071 * 100, metric = 4.16% * 100;
 Minibatch[ 601- 700]: loss = 0.306646 * 100, metric = 3.97% * 100;
 Minibatch[ 701- 800]: loss = 0.312832 * 100, metric = 4.13% * 100;
 Minibatch[ 801- 900]: loss = 0.325647 * 100, metric = 4.21% * 100;
 Minibatch[ 901-1000]: loss = 0.310278 * 100, metric = 3.84% * 100;
 Minibatch[1001-1100]: loss = 0.317726 * 100, metric = 4.08% * 100;
 Minibatch[1101-1200]: loss = 0.305233 * 100, metric = 3.97% * 100;
 Minibatch[1201-1300]: loss = 0.296444 * 100, metric = 3.68% * 100;
 Minibatch[1301-1400]: loss = 0.306899 * 100, metric = 3.93% * 100;
 Minibatch[1401-1500]: loss = 0.314766 * 100, metric = 3.92% * 100;
 Minibatch[1501-1600]: loss = 0.321260 * 100, metric = 4.13% * 100;
 Minibatch[1601-1700]: loss = 0.316202 * 100, metric = 3.95% * 100;
 Minibatch[1701-1800]: loss = 0.324700 * 100, metric = 4.09% * 100;
 Minibatch[1801-1900]: loss = 0.314511 * 100, metric = 3.98% * 100;
 Minibatch[1901-2000]: loss = 0.320043 * 100, metric = 4.28% * 100;
Finished Epoch[71 of 200]: [Training] loss = 0.314006 * 2000, metric = 4.03% * 2000 804.537s (  2.5 samples/s);
Finished Evaluation [71]: Minibatch[1-2000]: metric = 11.93% * 2000;
 Minibatch[   1- 100]: loss = 0.326168 * 100, metric = 4.23% * 100;
 Minibatch[ 101- 200]: loss = 0.309151 * 100, metric = 4.07% * 100;
 Minibatch[ 201- 300]: loss = 0.303275 * 100, metric = 3.90% * 100;
 Minibatch[ 301- 400]: loss = 0.304765 * 100, metric = 3.91% * 100;
 Minibatch[ 401- 500]: loss = 0.307891 * 100, metric = 4.02% * 100;
 Minibatch[ 501- 600]: loss = 0.304099 * 100, metric = 3.82% * 100;
 Minibatch[ 601- 700]: loss = 0.310106 * 100, metric = 4.10% * 100;
 Minibatch[ 701- 800]: loss = 0.309293 * 100, metric = 4.09% * 100;
 Minibatch[ 801- 900]: loss = 0.295179 * 100, metric = 3.70% * 100;
 Minibatch[ 901-1000]: loss = 0.298299 * 100, metric = 3.86% * 100;
 Minibatch[1001-1100]: loss = 0.311835 * 100, metric = 3.94% * 100;
 Minibatch[1101-1200]: loss = 0.306461 * 100, metric = 3.88% * 100;
 Minibatch[1201-1300]: loss = 0.306078 * 100, metric = 3.94% * 100;
 Minibatch[1301-1400]: loss = 0.314296 * 100, metric = 3.99% * 100;
 Minibatch[1401-1500]: loss = 0.309655 * 100, metric = 3.83% * 100;
 Minibatch[1501-1600]: loss = 0.313230 * 100, metric = 4.04% * 100;
 Minibatch[1601-1700]: loss = 0.323709 * 100, metric = 4.02% * 100;
 Minibatch[1701-1800]: loss = 0.322246 * 100, metric = 4.32% * 100;
 Minibatch[1801-1900]: loss = 0.322749 * 100, metric = 4.25% * 100;
 Minibatch[1901-2000]: loss = 0.310332 * 100, metric = 4.13% * 100;
Finished Epoch[72 of 200]: [Training] loss = 0.310441 * 2000, metric = 4.00% * 2000 812.756s (  2.5 samples/s);
Finished Evaluation [72]: Minibatch[1-2000]: metric = 12.16% * 2000;
 Minibatch[   1- 100]: loss = 0.310547 * 100, metric = 3.92% * 100;
 Minibatch[ 101- 200]: loss = 0.314806 * 100, metric = 4.11% * 100;
 Minibatch[ 201- 300]: loss = 0.308333 * 100, metric = 4.13% * 100;
 Minibatch[ 301- 400]: loss = 0.315522 * 100, metric = 4.18% * 100;
 Minibatch[ 401- 500]: loss = 0.311807 * 100, metric = 4.05% * 100;
 Minibatch[ 501- 600]: loss = 0.308889 * 100, metric = 3.94% * 100;
 Minibatch[ 601- 700]: loss = 0.305994 * 100, metric = 3.81% * 100;
 Minibatch[ 701- 800]: loss = 0.307803 * 100, metric = 4.05% * 100;
 Minibatch[ 801- 900]: loss = 0.313467 * 100, metric = 3.94% * 100;
 Minibatch[ 901-1000]: loss = 0.314207 * 100, metric = 4.01% * 100;
 Minibatch[1001-1100]: loss = 0.312879 * 100, metric = 4.03% * 100;
 Minibatch[1101-1200]: loss = 0.292972 * 100, metric = 3.77% * 100;
 Minibatch[1201-1300]: loss = 0.314318 * 100, metric = 4.11% * 100;
 Minibatch[1301-1400]: loss = 0.309908 * 100, metric = 3.95% * 100;
 Minibatch[1401-1500]: loss = 0.307157 * 100, metric = 3.93% * 100;
 Minibatch[1501-1600]: loss = 0.311971 * 100, metric = 4.23% * 100;
 Minibatch[1601-1700]: loss = 0.315710 * 100, metric = 3.96% * 100;
 Minibatch[1701-1800]: loss = 0.304782 * 100, metric = 3.96% * 100;
 Minibatch[1801-1900]: loss = 0.305517 * 100, metric = 4.01% * 100;
 Minibatch[1901-2000]: loss = 0.306783 * 100, metric = 3.96% * 100;
Finished Epoch[73 of 200]: [Training] loss = 0.309669 * 2000, metric = 4.00% * 2000 806.376s (  2.5 samples/s);
Finished Evaluation [73]: Minibatch[1-2000]: metric = 11.50% * 2000;
 Minibatch[   1- 100]: loss = 0.298027 * 100, metric = 3.96% * 100;
 Minibatch[ 101- 200]: loss = 0.313006 * 100, metric = 3.97% * 100;
 Minibatch[ 201- 300]: loss = 0.299598 * 100, metric = 3.82% * 100;
 Minibatch[ 301- 400]: loss = 0.303908 * 100, metric = 3.90% * 100;
 Minibatch[ 401- 500]: loss = 0.308472 * 100, metric = 3.93% * 100;
 Minibatch[ 501- 600]: loss = 0.319855 * 100, metric = 4.22% * 100;
 Minibatch[ 601- 700]: loss = 0.309087 * 100, metric = 3.65% * 100;
 Minibatch[ 701- 800]: loss = 0.302793 * 100, metric = 3.97% * 100;
 Minibatch[ 801- 900]: loss = 0.315240 * 100, metric = 3.99% * 100;
 Minibatch[ 901-1000]: loss = 0.314057 * 100, metric = 3.96% * 100;
 Minibatch[1001-1100]: loss = 0.308703 * 100, metric = 3.91% * 100;
 Minibatch[1101-1200]: loss = 0.328273 * 100, metric = 4.35% * 100;
 Minibatch[1201-1300]: loss = 0.298861 * 100, metric = 3.80% * 100;
 Minibatch[1301-1400]: loss = 0.309648 * 100, metric = 3.89% * 100;
 Minibatch[1401-1500]: loss = 0.297957 * 100, metric = 3.66% * 100;
 Minibatch[1501-1600]: loss = 0.310542 * 100, metric = 3.95% * 100;
 Minibatch[1601-1700]: loss = 0.290444 * 100, metric = 3.72% * 100;
 Minibatch[1701-1800]: loss = 0.307166 * 100, metric = 3.75% * 100;
 Minibatch[1801-1900]: loss = 0.300654 * 100, metric = 3.81% * 100;
 Minibatch[1901-2000]: loss = 0.311508 * 100, metric = 4.09% * 100;
Finished Epoch[74 of 200]: [Training] loss = 0.307390 * 2000, metric = 3.92% * 2000 800.751s (  2.5 samples/s);
Finished Evaluation [74]: Minibatch[1-2000]: metric = 11.41% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
