Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.251609 * 100, metric = 25.04% * 100;
 Minibatch[ 101- 200]: loss = 1.069363 * 100, metric = 23.54% * 100;
 Minibatch[ 201- 300]: loss = 0.950606 * 100, metric = 22.13% * 100;
 Minibatch[ 301- 400]: loss = 0.928677 * 100, metric = 20.77% * 100;
 Minibatch[ 401- 500]: loss = 0.870564 * 100, metric = 19.38% * 100;
 Minibatch[ 501- 600]: loss = 0.841056 * 100, metric = 18.05% * 100;
 Minibatch[ 601- 700]: loss = 0.829612 * 100, metric = 18.01% * 100;
 Minibatch[ 701- 800]: loss = 0.779313 * 100, metric = 16.77% * 100;
 Minibatch[ 801- 900]: loss = 0.793835 * 100, metric = 17.01% * 100;
 Minibatch[ 901-1000]: loss = 0.817905 * 100, metric = 18.06% * 100;
 Minibatch[1001-1100]: loss = 0.793008 * 100, metric = 17.26% * 100;
 Minibatch[1101-1200]: loss = 0.776332 * 100, metric = 16.50% * 100;
 Minibatch[1201-1300]: loss = 0.770422 * 100, metric = 16.40% * 100;
 Minibatch[1301-1400]: loss = 0.752953 * 100, metric = 16.42% * 100;
 Minibatch[1401-1500]: loss = 0.769531 * 100, metric = 16.71% * 100;
 Minibatch[1501-1600]: loss = 0.738767 * 100, metric = 15.96% * 100;
 Minibatch[1601-1700]: loss = 0.735499 * 100, metric = 15.72% * 100;
 Minibatch[1701-1800]: loss = 0.744386 * 100, metric = 15.83% * 100;
 Minibatch[1801-1900]: loss = 0.743771 * 100, metric = 15.99% * 100;
 Minibatch[1901-2000]: loss = 0.727000 * 100, metric = 15.19% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.834211 * 2000, metric = 18.04% * 2000 890.556s (  2.2 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 24.84% * 2000;
0.7866419179737568
 Minibatch[   1- 100]: loss = 0.730161 * 100, metric = 15.56% * 100;
 Minibatch[ 101- 200]: loss = 0.726951 * 100, metric = 15.66% * 100;
 Minibatch[ 201- 300]: loss = 0.718200 * 100, metric = 14.85% * 100;
 Minibatch[ 301- 400]: loss = 0.719261 * 100, metric = 15.06% * 100;
 Minibatch[ 401- 500]: loss = 0.715561 * 100, metric = 15.17% * 100;
 Minibatch[ 501- 600]: loss = 0.728294 * 100, metric = 14.97% * 100;
 Minibatch[ 601- 700]: loss = 0.690024 * 100, metric = 14.70% * 100;
 Minibatch[ 701- 800]: loss = 0.708168 * 100, metric = 15.29% * 100;
 Minibatch[ 801- 900]: loss = 0.694375 * 100, metric = 14.82% * 100;
 Minibatch[ 901-1000]: loss = 0.673789 * 100, metric = 13.93% * 100;
 Minibatch[1001-1100]: loss = 0.693470 * 100, metric = 14.81% * 100;
 Minibatch[1101-1200]: loss = 0.697870 * 100, metric = 14.64% * 100;
 Minibatch[1201-1300]: loss = 0.673322 * 100, metric = 14.21% * 100;
 Minibatch[1301-1400]: loss = 0.690126 * 100, metric = 14.63% * 100;
 Minibatch[1401-1500]: loss = 0.674167 * 100, metric = 14.05% * 100;
 Minibatch[1501-1600]: loss = 0.663651 * 100, metric = 13.90% * 100;
 Minibatch[1601-1700]: loss = 0.677073 * 100, metric = 13.98% * 100;
 Minibatch[1701-1800]: loss = 0.670864 * 100, metric = 14.15% * 100;
 Minibatch[1801-1900]: loss = 0.670159 * 100, metric = 14.07% * 100;
 Minibatch[1901-2000]: loss = 0.643206 * 100, metric = 13.58% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.692935 * 2000, metric = 14.60% * 2000 834.351s (  2.4 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 22.36% * 2000;
0.7089102476388216
 Minibatch[   1- 100]: loss = 0.661959 * 100, metric = 14.18% * 100;
 Minibatch[ 101- 200]: loss = 0.663665 * 100, metric = 13.86% * 100;
 Minibatch[ 201- 300]: loss = 0.652430 * 100, metric = 13.65% * 100;
 Minibatch[ 301- 400]: loss = 0.669733 * 100, metric = 14.28% * 100;
 Minibatch[ 401- 500]: loss = 0.668595 * 100, metric = 14.14% * 100;
 Minibatch[ 501- 600]: loss = 0.661788 * 100, metric = 14.05% * 100;
 Minibatch[ 601- 700]: loss = 0.668515 * 100, metric = 13.90% * 100;
 Minibatch[ 701- 800]: loss = 0.636902 * 100, metric = 12.93% * 100;
 Minibatch[ 801- 900]: loss = 0.661565 * 100, metric = 14.16% * 100;
 Minibatch[ 901-1000]: loss = 0.628597 * 100, metric = 13.58% * 100;
 Minibatch[1001-1100]: loss = 0.659449 * 100, metric = 14.08% * 100;
 Minibatch[1101-1200]: loss = 0.637958 * 100, metric = 13.22% * 100;
 Minibatch[1201-1300]: loss = 0.644050 * 100, metric = 13.69% * 100;
 Minibatch[1301-1400]: loss = 0.651696 * 100, metric = 13.64% * 100;
 Minibatch[1401-1500]: loss = 0.651157 * 100, metric = 13.74% * 100;
 Minibatch[1501-1600]: loss = 0.631766 * 100, metric = 13.17% * 100;
 Minibatch[1601-1700]: loss = 0.617589 * 100, metric = 12.54% * 100;
 Minibatch[1701-1800]: loss = 0.651094 * 100, metric = 14.03% * 100;
 Minibatch[1801-1900]: loss = 0.628826 * 100, metric = 13.08% * 100;
 Minibatch[1901-2000]: loss = 0.623265 * 100, metric = 12.79% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.648530 * 2000, metric = 13.64% * 2000 834.107s (  2.4 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 21.15% * 2000;
0.6882464200258255
 Minibatch[   1- 100]: loss = 0.649107 * 100, metric = 13.05% * 100;
 Minibatch[ 101- 200]: loss = 0.619557 * 100, metric = 12.95% * 100;
 Minibatch[ 201- 300]: loss = 0.632327 * 100, metric = 13.25% * 100;
 Minibatch[ 301- 400]: loss = 0.593796 * 100, metric = 12.21% * 100;
 Minibatch[ 401- 500]: loss = 0.624134 * 100, metric = 12.82% * 100;
 Minibatch[ 501- 600]: loss = 0.606132 * 100, metric = 12.24% * 100;
 Minibatch[ 601- 700]: loss = 0.613022 * 100, metric = 12.83% * 100;
 Minibatch[ 701- 800]: loss = 0.614615 * 100, metric = 12.76% * 100;
 Minibatch[ 801- 900]: loss = 0.611898 * 100, metric = 12.68% * 100;
 Minibatch[ 901-1000]: loss = 0.618650 * 100, metric = 13.14% * 100;
 Minibatch[1001-1100]: loss = 0.627042 * 100, metric = 13.24% * 100;
 Minibatch[1101-1200]: loss = 0.606404 * 100, metric = 12.63% * 100;
 Minibatch[1201-1300]: loss = 0.604207 * 100, metric = 12.37% * 100;
 Minibatch[1301-1400]: loss = 0.628052 * 100, metric = 13.19% * 100;
 Minibatch[1401-1500]: loss = 0.628195 * 100, metric = 13.28% * 100;
 Minibatch[1501-1600]: loss = 0.589785 * 100, metric = 12.08% * 100;
 Minibatch[1601-1700]: loss = 0.620567 * 100, metric = 12.93% * 100;
 Minibatch[1701-1800]: loss = 0.618318 * 100, metric = 13.03% * 100;
 Minibatch[1801-1900]: loss = 0.603101 * 100, metric = 12.42% * 100;
 Minibatch[1901-2000]: loss = 0.596494 * 100, metric = 12.22% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.615270 * 2000, metric = 12.77% * 2000 836.326s (  2.4 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 21.75% * 2000;
 Minibatch[   1- 100]: loss = 0.624444 * 100, metric = 12.98% * 100;
 Minibatch[ 101- 200]: loss = 0.601013 * 100, metric = 12.51% * 100;
 Minibatch[ 201- 300]: loss = 0.589074 * 100, metric = 12.12% * 100;
 Minibatch[ 301- 400]: loss = 0.626716 * 100, metric = 13.28% * 100;
 Minibatch[ 401- 500]: loss = 0.587296 * 100, metric = 11.85% * 100;
 Minibatch[ 501- 600]: loss = 0.589515 * 100, metric = 11.79% * 100;
 Minibatch[ 601- 700]: loss = 0.598232 * 100, metric = 11.97% * 100;
 Minibatch[ 701- 800]: loss = 0.603447 * 100, metric = 12.13% * 100;
 Minibatch[ 801- 900]: loss = 0.590172 * 100, metric = 11.85% * 100;
 Minibatch[ 901-1000]: loss = 0.583856 * 100, metric = 11.84% * 100;
 Minibatch[1001-1100]: loss = 0.592513 * 100, metric = 12.29% * 100;
 Minibatch[1101-1200]: loss = 0.578881 * 100, metric = 11.96% * 100;
 Minibatch[1201-1300]: loss = 0.598117 * 100, metric = 12.27% * 100;
 Minibatch[1301-1400]: loss = 0.609456 * 100, metric = 12.58% * 100;
 Minibatch[1401-1500]: loss = 0.589887 * 100, metric = 12.35% * 100;
 Minibatch[1501-1600]: loss = 0.590593 * 100, metric = 12.05% * 100;
 Minibatch[1601-1700]: loss = 0.607727 * 100, metric = 13.10% * 100;
 Minibatch[1701-1800]: loss = 0.605702 * 100, metric = 12.70% * 100;
 Minibatch[1801-1900]: loss = 0.603489 * 100, metric = 12.64% * 100;
 Minibatch[1901-2000]: loss = 0.581475 * 100, metric = 11.83% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.597580 * 2000, metric = 12.30% * 2000 833.973s (  2.4 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.26% * 2000;
0.6537661777958274
 Minibatch[   1- 100]: loss = 0.581794 * 100, metric = 12.17% * 100;
 Minibatch[ 101- 200]: loss = 0.575953 * 100, metric = 12.05% * 100;
 Minibatch[ 201- 300]: loss = 0.583553 * 100, metric = 11.93% * 100;
 Minibatch[ 301- 400]: loss = 0.588497 * 100, metric = 12.18% * 100;
 Minibatch[ 401- 500]: loss = 0.560521 * 100, metric = 11.24% * 100;
 Minibatch[ 501- 600]: loss = 0.578321 * 100, metric = 12.29% * 100;
 Minibatch[ 601- 700]: loss = 0.572176 * 100, metric = 11.73% * 100;
 Minibatch[ 701- 800]: loss = 0.583462 * 100, metric = 11.95% * 100;
 Minibatch[ 801- 900]: loss = 0.584061 * 100, metric = 12.06% * 100;
 Minibatch[ 901-1000]: loss = 0.571038 * 100, metric = 11.73% * 100;
 Minibatch[1001-1100]: loss = 0.574955 * 100, metric = 11.57% * 100;
 Minibatch[1101-1200]: loss = 0.575973 * 100, metric = 11.84% * 100;
 Minibatch[1201-1300]: loss = 0.593826 * 100, metric = 11.99% * 100;
 Minibatch[1301-1400]: loss = 0.574300 * 100, metric = 11.95% * 100;
 Minibatch[1401-1500]: loss = 0.582938 * 100, metric = 12.16% * 100;
 Minibatch[1501-1600]: loss = 0.564216 * 100, metric = 11.41% * 100;
 Minibatch[1601-1700]: loss = 0.558999 * 100, metric = 11.26% * 100;
 Minibatch[1701-1800]: loss = 0.554136 * 100, metric = 11.19% * 100;
 Minibatch[1801-1900]: loss = 0.580187 * 100, metric = 11.98% * 100;
 Minibatch[1901-2000]: loss = 0.563503 * 100, metric = 11.39% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.575120 * 2000, metric = 11.80% * 2000 830.293s (  2.4 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 21.43% * 2000;
 Minibatch[   1- 100]: loss = 0.566329 * 100, metric = 11.54% * 100;
 Minibatch[ 101- 200]: loss = 0.576460 * 100, metric = 11.54% * 100;
 Minibatch[ 201- 300]: loss = 0.579691 * 100, metric = 11.94% * 100;
 Minibatch[ 301- 400]: loss = 0.561926 * 100, metric = 11.40% * 100;
 Minibatch[ 401- 500]: loss = 0.579107 * 100, metric = 11.88% * 100;
 Minibatch[ 501- 600]: loss = 0.554088 * 100, metric = 11.36% * 100;
 Minibatch[ 601- 700]: loss = 0.570021 * 100, metric = 11.46% * 100;
 Minibatch[ 701- 800]: loss = 0.575420 * 100, metric = 11.80% * 100;
 Minibatch[ 801- 900]: loss = 0.573761 * 100, metric = 11.85% * 100;
 Minibatch[ 901-1000]: loss = 0.561903 * 100, metric = 11.65% * 100;
 Minibatch[1001-1100]: loss = 0.573789 * 100, metric = 11.88% * 100;
 Minibatch[1101-1200]: loss = 0.550892 * 100, metric = 10.97% * 100;
 Minibatch[1201-1300]: loss = 0.569473 * 100, metric = 11.89% * 100;
 Minibatch[1301-1400]: loss = 0.551393 * 100, metric = 11.20% * 100;
 Minibatch[1401-1500]: loss = 0.542247 * 100, metric = 10.99% * 100;
 Minibatch[1501-1600]: loss = 0.557548 * 100, metric = 11.28% * 100;
 Minibatch[1601-1700]: loss = 0.559478 * 100, metric = 11.56% * 100;
 Minibatch[1701-1800]: loss = 0.546580 * 100, metric = 11.24% * 100;
 Minibatch[1801-1900]: loss = 0.552481 * 100, metric = 11.46% * 100;
 Minibatch[1901-2000]: loss = 0.560500 * 100, metric = 11.51% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.563154 * 2000, metric = 11.52% * 2000 832.889s (  2.4 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.05% * 2000;
0.6109667016863823
 Minibatch[   1- 100]: loss = 0.561959 * 100, metric = 11.50% * 100;
 Minibatch[ 101- 200]: loss = 0.554050 * 100, metric = 11.39% * 100;
 Minibatch[ 201- 300]: loss = 0.540377 * 100, metric = 11.09% * 100;
 Minibatch[ 301- 400]: loss = 0.547057 * 100, metric = 11.19% * 100;
 Minibatch[ 401- 500]: loss = 0.558199 * 100, metric = 11.68% * 100;
 Minibatch[ 501- 600]: loss = 0.569005 * 100, metric = 12.01% * 100;
 Minibatch[ 601- 700]: loss = 0.537022 * 100, metric = 10.98% * 100;
 Minibatch[ 701- 800]: loss = 0.555854 * 100, metric = 11.44% * 100;
 Minibatch[ 801- 900]: loss = 0.533551 * 100, metric = 10.63% * 100;
 Minibatch[ 901-1000]: loss = 0.528014 * 100, metric = 10.59% * 100;
 Minibatch[1001-1100]: loss = 0.530263 * 100, metric = 10.90% * 100;
 Minibatch[1101-1200]: loss = 0.539398 * 100, metric = 10.90% * 100;
 Minibatch[1201-1300]: loss = 0.550963 * 100, metric = 11.25% * 100;
 Minibatch[1301-1400]: loss = 0.557982 * 100, metric = 11.58% * 100;
 Minibatch[1401-1500]: loss = 0.544592 * 100, metric = 10.83% * 100;
 Minibatch[1501-1600]: loss = 0.546434 * 100, metric = 11.28% * 100;
 Minibatch[1601-1700]: loss = 0.528750 * 100, metric = 10.60% * 100;
 Minibatch[1701-1800]: loss = 0.531497 * 100, metric = 10.48% * 100;
 Minibatch[1801-1900]: loss = 0.528998 * 100, metric = 10.64% * 100;
 Minibatch[1901-2000]: loss = 0.536473 * 100, metric = 10.90% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.544022 * 2000, metric = 11.09% * 2000 828.601s (  2.4 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 18.04% * 2000;
0.5972563289478421
 Minibatch[   1- 100]: loss = 0.519304 * 100, metric = 10.26% * 100;
 Minibatch[ 101- 200]: loss = 0.540947 * 100, metric = 11.03% * 100;
 Minibatch[ 201- 300]: loss = 0.534355 * 100, metric = 10.96% * 100;
 Minibatch[ 301- 400]: loss = 0.548153 * 100, metric = 11.30% * 100;
 Minibatch[ 401- 500]: loss = 0.532825 * 100, metric = 10.65% * 100;
 Minibatch[ 501- 600]: loss = 0.525919 * 100, metric = 10.65% * 100;
 Minibatch[ 601- 700]: loss = 0.525977 * 100, metric = 10.68% * 100;
 Minibatch[ 701- 800]: loss = 0.514682 * 100, metric = 10.16% * 100;
 Minibatch[ 801- 900]: loss = 0.511462 * 100, metric = 10.36% * 100;
 Minibatch[ 901-1000]: loss = 0.527836 * 100, metric = 10.77% * 100;
 Minibatch[1001-1100]: loss = 0.503953 * 100, metric = 9.75% * 100;
 Minibatch[1101-1200]: loss = 0.527272 * 100, metric = 10.40% * 100;
 Minibatch[1201-1300]: loss = 0.515234 * 100, metric = 10.37% * 100;
 Minibatch[1301-1400]: loss = 0.515475 * 100, metric = 10.15% * 100;
 Minibatch[1401-1500]: loss = 0.535206 * 100, metric = 10.95% * 100;
 Minibatch[1501-1600]: loss = 0.525645 * 100, metric = 10.45% * 100;
 Minibatch[1601-1700]: loss = 0.524579 * 100, metric = 10.72% * 100;
 Minibatch[1701-1800]: loss = 0.520640 * 100, metric = 10.31% * 100;
 Minibatch[1801-1900]: loss = 0.516082 * 100, metric = 10.34% * 100;
 Minibatch[1901-2000]: loss = 0.530842 * 100, metric = 10.61% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.524819 * 2000, metric = 10.54% * 2000 829.074s (  2.4 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 16.56% * 2000;
0.5866338351294398
 Minibatch[   1- 100]: loss = 0.542759 * 100, metric = 11.33% * 100;
 Minibatch[ 101- 200]: loss = 0.510691 * 100, metric = 10.29% * 100;
 Minibatch[ 201- 300]: loss = 0.519574 * 100, metric = 10.23% * 100;
 Minibatch[ 301- 400]: loss = 0.507994 * 100, metric = 10.34% * 100;
 Minibatch[ 401- 500]: loss = 0.519508 * 100, metric = 10.60% * 100;
 Minibatch[ 501- 600]: loss = 0.500490 * 100, metric = 9.88% * 100;
 Minibatch[ 601- 700]: loss = 0.500641 * 100, metric = 10.12% * 100;
 Minibatch[ 701- 800]: loss = 0.492139 * 100, metric = 9.46% * 100;
 Minibatch[ 801- 900]: loss = 0.511018 * 100, metric = 10.11% * 100;
 Minibatch[ 901-1000]: loss = 0.512444 * 100, metric = 10.17% * 100;
 Minibatch[1001-1100]: loss = 0.513961 * 100, metric = 10.33% * 100;
 Minibatch[1101-1200]: loss = 0.511954 * 100, metric = 10.09% * 100;
 Minibatch[1201-1300]: loss = 0.508565 * 100, metric = 10.43% * 100;
 Minibatch[1301-1400]: loss = 0.512255 * 100, metric = 10.45% * 100;
 Minibatch[1401-1500]: loss = 0.493672 * 100, metric = 9.68% * 100;
 Minibatch[1501-1600]: loss = 0.505170 * 100, metric = 10.17% * 100;
 Minibatch[1601-1700]: loss = 0.501528 * 100, metric = 9.73% * 100;
 Minibatch[1701-1800]: loss = 0.507512 * 100, metric = 10.07% * 100;
 Minibatch[1801-1900]: loss = 0.513353 * 100, metric = 10.22% * 100;
 Minibatch[1901-2000]: loss = 0.491194 * 100, metric = 9.84% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.508821 * 2000, metric = 10.18% * 2000 824.713s (  2.4 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 16.63% * 2000;
0.5715338914319873
 Minibatch[   1- 100]: loss = 0.483036 * 100, metric = 9.40% * 100;
 Minibatch[ 101- 200]: loss = 0.498898 * 100, metric = 9.94% * 100;
 Minibatch[ 201- 300]: loss = 0.502733 * 100, metric = 10.15% * 100;
 Minibatch[ 301- 400]: loss = 0.498997 * 100, metric = 9.80% * 100;
 Minibatch[ 401- 500]: loss = 0.496206 * 100, metric = 9.81% * 100;
 Minibatch[ 501- 600]: loss = 0.497139 * 100, metric = 9.83% * 100;
 Minibatch[ 601- 700]: loss = 0.493636 * 100, metric = 9.88% * 100;
 Minibatch[ 701- 800]: loss = 0.502181 * 100, metric = 10.06% * 100;
 Minibatch[ 801- 900]: loss = 0.493174 * 100, metric = 9.76% * 100;
 Minibatch[ 901-1000]: loss = 0.503289 * 100, metric = 10.17% * 100;
 Minibatch[1001-1100]: loss = 0.492423 * 100, metric = 9.80% * 100;
 Minibatch[1101-1200]: loss = 0.498974 * 100, metric = 10.00% * 100;
 Minibatch[1201-1300]: loss = 0.491540 * 100, metric = 9.91% * 100;
 Minibatch[1301-1400]: loss = 0.481261 * 100, metric = 9.77% * 100;
 Minibatch[1401-1500]: loss = 0.499106 * 100, metric = 9.96% * 100;
 Minibatch[1501-1600]: loss = 0.485179 * 100, metric = 9.59% * 100;
 Minibatch[1601-1700]: loss = 0.492390 * 100, metric = 9.88% * 100;
 Minibatch[1701-1800]: loss = 0.500587 * 100, metric = 9.99% * 100;
 Minibatch[1801-1900]: loss = 0.498955 * 100, metric = 10.17% * 100;
 Minibatch[1901-2000]: loss = 0.489957 * 100, metric = 9.86% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.494983 * 2000, metric = 9.89% * 2000 827.278s (  2.4 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 16.83% * 2000;
 Minibatch[   1- 100]: loss = 0.476281 * 100, metric = 9.17% * 100;
 Minibatch[ 101- 200]: loss = 0.478509 * 100, metric = 9.29% * 100;
 Minibatch[ 201- 300]: loss = 0.484368 * 100, metric = 9.76% * 100;
 Minibatch[ 301- 400]: loss = 0.522734 * 100, metric = 10.78% * 100;
 Minibatch[ 401- 500]: loss = 0.485544 * 100, metric = 9.52% * 100;
 Minibatch[ 501- 600]: loss = 0.472913 * 100, metric = 9.23% * 100;
 Minibatch[ 601- 700]: loss = 0.474865 * 100, metric = 9.31% * 100;
 Minibatch[ 701- 800]: loss = 0.479634 * 100, metric = 9.35% * 100;
 Minibatch[ 801- 900]: loss = 0.473438 * 100, metric = 9.23% * 100;
 Minibatch[ 901-1000]: loss = 0.492356 * 100, metric = 10.04% * 100;
 Minibatch[1001-1100]: loss = 0.485782 * 100, metric = 9.76% * 100;
 Minibatch[1101-1200]: loss = 0.493716 * 100, metric = 9.60% * 100;
 Minibatch[1201-1300]: loss = 0.493279 * 100, metric = 10.04% * 100;
 Minibatch[1301-1400]: loss = 0.470443 * 100, metric = 9.30% * 100;
 Minibatch[1401-1500]: loss = 0.496092 * 100, metric = 10.06% * 100;
 Minibatch[1501-1600]: loss = 0.459981 * 100, metric = 8.90% * 100;
 Minibatch[1601-1700]: loss = 0.486382 * 100, metric = 9.62% * 100;
 Minibatch[1701-1800]: loss = 0.468653 * 100, metric = 9.16% * 100;
 Minibatch[1801-1900]: loss = 0.474301 * 100, metric = 9.27% * 100;
 Minibatch[1901-2000]: loss = 0.489219 * 100, metric = 9.84% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.482925 * 2000, metric = 9.56% * 2000 822.839s (  2.4 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 17.15% * 2000;
 Minibatch[   1- 100]: loss = 0.486353 * 100, metric = 9.67% * 100;
 Minibatch[ 101- 200]: loss = 0.477652 * 100, metric = 9.63% * 100;
 Minibatch[ 201- 300]: loss = 0.473850 * 100, metric = 9.31% * 100;
 Minibatch[ 301- 400]: loss = 0.489388 * 100, metric = 9.66% * 100;
 Minibatch[ 401- 500]: loss = 0.483567 * 100, metric = 9.95% * 100;
 Minibatch[ 501- 600]: loss = 0.497267 * 100, metric = 10.03% * 100;
 Minibatch[ 601- 700]: loss = 0.474958 * 100, metric = 9.05% * 100;
 Minibatch[ 701- 800]: loss = 0.469370 * 100, metric = 9.03% * 100;
 Minibatch[ 801- 900]: loss = 0.479604 * 100, metric = 9.54% * 100;
 Minibatch[ 901-1000]: loss = 0.490845 * 100, metric = 9.84% * 100;
 Minibatch[1001-1100]: loss = 0.485329 * 100, metric = 9.62% * 100;
 Minibatch[1101-1200]: loss = 0.469279 * 100, metric = 9.15% * 100;
 Minibatch[1201-1300]: loss = 0.476398 * 100, metric = 9.52% * 100;
 Minibatch[1301-1400]: loss = 0.468640 * 100, metric = 9.22% * 100;
 Minibatch[1401-1500]: loss = 0.465550 * 100, metric = 9.12% * 100;
 Minibatch[1501-1600]: loss = 0.457122 * 100, metric = 8.94% * 100;
 Minibatch[1601-1700]: loss = 0.454067 * 100, metric = 9.06% * 100;
 Minibatch[1701-1800]: loss = 0.473830 * 100, metric = 9.09% * 100;
 Minibatch[1801-1900]: loss = 0.459465 * 100, metric = 9.22% * 100;
 Minibatch[1901-2000]: loss = 0.476119 * 100, metric = 9.31% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.475433 * 2000, metric = 9.40% * 2000 812.733s (  2.5 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 18.52% * 2000;
 Minibatch[   1- 100]: loss = 0.473230 * 100, metric = 9.16% * 100;
 Minibatch[ 101- 200]: loss = 0.459234 * 100, metric = 8.96% * 100;
 Minibatch[ 201- 300]: loss = 0.483272 * 100, metric = 9.60% * 100;
 Minibatch[ 301- 400]: loss = 0.466094 * 100, metric = 9.22% * 100;
 Minibatch[ 401- 500]: loss = 0.473682 * 100, metric = 9.59% * 100;
 Minibatch[ 501- 600]: loss = 0.468098 * 100, metric = 9.20% * 100;
 Minibatch[ 601- 700]: loss = 0.471559 * 100, metric = 9.37% * 100;
 Minibatch[ 701- 800]: loss = 0.489942 * 100, metric = 9.80% * 100;
 Minibatch[ 801- 900]: loss = 0.483586 * 100, metric = 9.88% * 100;
 Minibatch[ 901-1000]: loss = 0.475342 * 100, metric = 9.47% * 100;
 Minibatch[1001-1100]: loss = 0.474222 * 100, metric = 9.50% * 100;
 Minibatch[1101-1200]: loss = 0.461518 * 100, metric = 9.04% * 100;
 Minibatch[1201-1300]: loss = 0.447078 * 100, metric = 8.65% * 100;
 Minibatch[1301-1400]: loss = 0.466621 * 100, metric = 9.59% * 100;
 Minibatch[1401-1500]: loss = 0.470873 * 100, metric = 9.52% * 100;
 Minibatch[1501-1600]: loss = 0.449152 * 100, metric = 8.88% * 100;
 Minibatch[1601-1700]: loss = 0.460161 * 100, metric = 8.95% * 100;
 Minibatch[1701-1800]: loss = 0.452905 * 100, metric = 8.63% * 100;
 Minibatch[1801-1900]: loss = 0.459519 * 100, metric = 8.99% * 100;
 Minibatch[1901-2000]: loss = 0.463422 * 100, metric = 8.95% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.467475 * 2000, metric = 9.25% * 2000 810.595s (  2.5 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 17.50% * 2000;
 Minibatch[   1- 100]: loss = 0.450933 * 100, metric = 8.85% * 100;
 Minibatch[ 101- 200]: loss = 0.455528 * 100, metric = 8.89% * 100;
 Minibatch[ 201- 300]: loss = 0.456645 * 100, metric = 9.01% * 100;
 Minibatch[ 301- 400]: loss = 0.443518 * 100, metric = 8.58% * 100;
 Minibatch[ 401- 500]: loss = 0.457582 * 100, metric = 9.04% * 100;
 Minibatch[ 501- 600]: loss = 0.445731 * 100, metric = 8.60% * 100;
 Minibatch[ 601- 700]: loss = 0.441816 * 100, metric = 8.64% * 100;
 Minibatch[ 701- 800]: loss = 0.463903 * 100, metric = 9.24% * 100;
 Minibatch[ 801- 900]: loss = 0.479423 * 100, metric = 9.88% * 100;
 Minibatch[ 901-1000]: loss = 0.453436 * 100, metric = 8.78% * 100;
 Minibatch[1001-1100]: loss = 0.459766 * 100, metric = 9.02% * 100;
 Minibatch[1101-1200]: loss = 0.450356 * 100, metric = 8.92% * 100;
 Minibatch[1201-1300]: loss = 0.444883 * 100, metric = 8.69% * 100;
 Minibatch[1301-1400]: loss = 0.467982 * 100, metric = 9.48% * 100;
 Minibatch[1401-1500]: loss = 0.430101 * 100, metric = 8.42% * 100;
 Minibatch[1501-1600]: loss = 0.449548 * 100, metric = 8.88% * 100;
 Minibatch[1601-1700]: loss = 0.454564 * 100, metric = 8.88% * 100;
 Minibatch[1701-1800]: loss = 0.440584 * 100, metric = 8.39% * 100;
 Minibatch[1801-1900]: loss = 0.446830 * 100, metric = 8.78% * 100;
 Minibatch[1901-2000]: loss = 0.445762 * 100, metric = 8.86% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.451944 * 2000, metric = 8.89% * 2000 806.211s (  2.5 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 16.10% * 2000;
0.5708291431218385
 Minibatch[   1- 100]: loss = 0.465199 * 100, metric = 9.47% * 100;
 Minibatch[ 101- 200]: loss = 0.460765 * 100, metric = 9.04% * 100;
 Minibatch[ 201- 300]: loss = 0.453872 * 100, metric = 9.04% * 100;
 Minibatch[ 301- 400]: loss = 0.459937 * 100, metric = 8.79% * 100;
 Minibatch[ 401- 500]: loss = 0.427941 * 100, metric = 8.12% * 100;
 Minibatch[ 501- 600]: loss = 0.438015 * 100, metric = 8.55% * 100;
 Minibatch[ 601- 700]: loss = 0.446878 * 100, metric = 8.86% * 100;
 Minibatch[ 701- 800]: loss = 0.437223 * 100, metric = 8.50% * 100;
 Minibatch[ 801- 900]: loss = 0.430588 * 100, metric = 8.37% * 100;
 Minibatch[ 901-1000]: loss = 0.449037 * 100, metric = 9.21% * 100;
 Minibatch[1001-1100]: loss = 0.426437 * 100, metric = 8.36% * 100;
 Minibatch[1101-1200]: loss = 0.434610 * 100, metric = 8.43% * 100;
 Minibatch[1201-1300]: loss = 0.428443 * 100, metric = 8.21% * 100;
 Minibatch[1301-1400]: loss = 0.433629 * 100, metric = 8.47% * 100;
 Minibatch[1401-1500]: loss = 0.441351 * 100, metric = 8.83% * 100;
 Minibatch[1501-1600]: loss = 0.439083 * 100, metric = 8.95% * 100;
 Minibatch[1601-1700]: loss = 0.439390 * 100, metric = 8.45% * 100;
 Minibatch[1701-1800]: loss = 0.452332 * 100, metric = 8.82% * 100;
 Minibatch[1801-1900]: loss = 0.443752 * 100, metric = 8.77% * 100;
 Minibatch[1901-2000]: loss = 0.426685 * 100, metric = 8.48% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.441758 * 2000, metric = 8.69% * 2000 813.070s (  2.5 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 15.17% * 2000;
0.5579301440417767
 Minibatch[   1- 100]: loss = 0.425261 * 100, metric = 8.20% * 100;
 Minibatch[ 101- 200]: loss = 0.445647 * 100, metric = 8.82% * 100;
 Minibatch[ 201- 300]: loss = 0.441298 * 100, metric = 8.78% * 100;
 Minibatch[ 301- 400]: loss = 0.436949 * 100, metric = 8.53% * 100;
 Minibatch[ 401- 500]: loss = 0.442717 * 100, metric = 8.63% * 100;
 Minibatch[ 501- 600]: loss = 0.425309 * 100, metric = 8.26% * 100;
 Minibatch[ 601- 700]: loss = 0.419682 * 100, metric = 8.05% * 100;
 Minibatch[ 701- 800]: loss = 0.431871 * 100, metric = 8.15% * 100;
 Minibatch[ 801- 900]: loss = 0.436801 * 100, metric = 8.47% * 100;
 Minibatch[ 901-1000]: loss = 0.420896 * 100, metric = 8.06% * 100;
 Minibatch[1001-1100]: loss = 0.423213 * 100, metric = 8.36% * 100;
 Minibatch[1101-1200]: loss = 0.443689 * 100, metric = 8.61% * 100;
 Minibatch[1201-1300]: loss = 0.440812 * 100, metric = 8.54% * 100;
 Minibatch[1301-1400]: loss = 0.413237 * 100, metric = 7.95% * 100;
 Minibatch[1401-1500]: loss = 0.430595 * 100, metric = 8.49% * 100;
 Minibatch[1501-1600]: loss = 0.431028 * 100, metric = 8.31% * 100;
 Minibatch[1601-1700]: loss = 0.425306 * 100, metric = 8.14% * 100;
 Minibatch[1701-1800]: loss = 0.422826 * 100, metric = 8.31% * 100;
 Minibatch[1801-1900]: loss = 0.443027 * 100, metric = 8.94% * 100;
 Minibatch[1901-2000]: loss = 0.446484 * 100, metric = 8.89% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.432332 * 2000, metric = 8.43% * 2000 807.687s (  2.5 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 15.30% * 2000;
0.5560488748624921
 Minibatch[   1- 100]: loss = 0.421492 * 100, metric = 8.22% * 100;
 Minibatch[ 101- 200]: loss = 0.440165 * 100, metric = 8.62% * 100;
 Minibatch[ 201- 300]: loss = 0.418301 * 100, metric = 8.09% * 100;
 Minibatch[ 301- 400]: loss = 0.430739 * 100, metric = 8.39% * 100;
 Minibatch[ 401- 500]: loss = 0.415212 * 100, metric = 8.12% * 100;
 Minibatch[ 501- 600]: loss = 0.428299 * 100, metric = 8.25% * 100;
 Minibatch[ 601- 700]: loss = 0.427797 * 100, metric = 8.40% * 100;
 Minibatch[ 701- 800]: loss = 0.416433 * 100, metric = 8.10% * 100;
 Minibatch[ 801- 900]: loss = 0.428304 * 100, metric = 8.20% * 100;
 Minibatch[ 901-1000]: loss = 0.435357 * 100, metric = 8.46% * 100;
 Minibatch[1001-1100]: loss = 0.434645 * 100, metric = 8.46% * 100;
 Minibatch[1101-1200]: loss = 0.426731 * 100, metric = 8.34% * 100;
 Minibatch[1201-1300]: loss = 0.433618 * 100, metric = 8.64% * 100;
 Minibatch[1301-1400]: loss = 0.436717 * 100, metric = 8.81% * 100;
 Minibatch[1401-1500]: loss = 0.410778 * 100, metric = 7.88% * 100;
 Minibatch[1501-1600]: loss = 0.425822 * 100, metric = 8.25% * 100;
 Minibatch[1601-1700]: loss = 0.405908 * 100, metric = 7.71% * 100;
 Minibatch[1701-1800]: loss = 0.413528 * 100, metric = 8.08% * 100;
 Minibatch[1801-1900]: loss = 0.406990 * 100, metric = 8.00% * 100;
 Minibatch[1901-2000]: loss = 0.409821 * 100, metric = 7.74% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.423333 * 2000, metric = 8.24% * 2000 802.294s (  2.5 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.82% * 2000;
 Minibatch[   1- 100]: loss = 0.422596 * 100, metric = 8.28% * 100;
 Minibatch[ 101- 200]: loss = 0.437417 * 100, metric = 8.52% * 100;
 Minibatch[ 201- 300]: loss = 0.402227 * 100, metric = 7.63% * 100;
 Minibatch[ 301- 400]: loss = 0.421958 * 100, metric = 8.12% * 100;
 Minibatch[ 401- 500]: loss = 0.412613 * 100, metric = 7.84% * 100;
 Minibatch[ 501- 600]: loss = 0.406391 * 100, metric = 7.72% * 100;
 Minibatch[ 601- 700]: loss = 0.418544 * 100, metric = 8.14% * 100;
 Minibatch[ 701- 800]: loss = 0.405500 * 100, metric = 7.78% * 100;
 Minibatch[ 801- 900]: loss = 0.445310 * 100, metric = 8.67% * 100;
 Minibatch[ 901-1000]: loss = 0.410720 * 100, metric = 7.79% * 100;
 Minibatch[1001-1100]: loss = 0.429316 * 100, metric = 8.45% * 100;
 Minibatch[1101-1200]: loss = 0.418658 * 100, metric = 8.26% * 100;
 Minibatch[1201-1300]: loss = 0.409979 * 100, metric = 7.98% * 100;
 Minibatch[1301-1400]: loss = 0.400554 * 100, metric = 7.81% * 100;
 Minibatch[1401-1500]: loss = 0.421576 * 100, metric = 8.15% * 100;
 Minibatch[1501-1600]: loss = 0.423668 * 100, metric = 8.30% * 100;
 Minibatch[1601-1700]: loss = 0.406251 * 100, metric = 7.82% * 100;
 Minibatch[1701-1800]: loss = 0.395131 * 100, metric = 7.49% * 100;
 Minibatch[1801-1900]: loss = 0.403008 * 100, metric = 7.79% * 100;
 Minibatch[1901-2000]: loss = 0.390475 * 100, metric = 7.50% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.414095 * 2000, metric = 8.00% * 2000 799.496s (  2.5 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 15.38% * 2000;
 Minibatch[   1- 100]: loss = 0.406744 * 100, metric = 7.63% * 100;
 Minibatch[ 101- 200]: loss = 0.406699 * 100, metric = 7.90% * 100;
 Minibatch[ 201- 300]: loss = 0.398963 * 100, metric = 7.60% * 100;
 Minibatch[ 301- 400]: loss = 0.424208 * 100, metric = 7.83% * 100;
 Minibatch[ 401- 500]: loss = 0.411049 * 100, metric = 7.94% * 100;
 Minibatch[ 501- 600]: loss = 0.416380 * 100, metric = 8.25% * 100;
 Minibatch[ 601- 700]: loss = 0.419827 * 100, metric = 8.32% * 100;
 Minibatch[ 701- 800]: loss = 0.413459 * 100, metric = 8.11% * 100;
 Minibatch[ 801- 900]: loss = 0.423031 * 100, metric = 8.12% * 100;
 Minibatch[ 901-1000]: loss = 0.415958 * 100, metric = 8.11% * 100;
 Minibatch[1001-1100]: loss = 0.395873 * 100, metric = 7.64% * 100;
 Minibatch[1101-1200]: loss = 0.410088 * 100, metric = 7.90% * 100;
 Minibatch[1201-1300]: loss = 0.410421 * 100, metric = 7.96% * 100;
 Minibatch[1301-1400]: loss = 0.413441 * 100, metric = 8.03% * 100;
 Minibatch[1401-1500]: loss = 0.407566 * 100, metric = 8.01% * 100;
 Minibatch[1501-1600]: loss = 0.421366 * 100, metric = 8.24% * 100;
 Minibatch[1601-1700]: loss = 0.406515 * 100, metric = 7.75% * 100;
 Minibatch[1701-1800]: loss = 0.415422 * 100, metric = 8.20% * 100;
 Minibatch[1801-1900]: loss = 0.397344 * 100, metric = 7.58% * 100;
 Minibatch[1901-2000]: loss = 0.405466 * 100, metric = 7.87% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.410991 * 2000, metric = 7.95% * 2000 801.115s (  2.5 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 15.31% * 2000;
 Minibatch[   1- 100]: loss = 0.415578 * 100, metric = 8.21% * 100;
 Minibatch[ 101- 200]: loss = 0.411730 * 100, metric = 7.93% * 100;
 Minibatch[ 201- 300]: loss = 0.403713 * 100, metric = 8.12% * 100;
 Minibatch[ 301- 400]: loss = 0.415508 * 100, metric = 8.22% * 100;
 Minibatch[ 401- 500]: loss = 0.399872 * 100, metric = 7.57% * 100;
 Minibatch[ 501- 600]: loss = 0.403348 * 100, metric = 7.67% * 100;
 Minibatch[ 601- 700]: loss = 0.398310 * 100, metric = 7.73% * 100;
 Minibatch[ 701- 800]: loss = 0.380690 * 100, metric = 7.24% * 100;
 Minibatch[ 801- 900]: loss = 0.409805 * 100, metric = 7.91% * 100;
 Minibatch[ 901-1000]: loss = 0.389175 * 100, metric = 7.51% * 100;
 Minibatch[1001-1100]: loss = 0.395503 * 100, metric = 7.63% * 100;
 Minibatch[1101-1200]: loss = 0.392598 * 100, metric = 7.56% * 100;
 Minibatch[1201-1300]: loss = 0.401161 * 100, metric = 7.56% * 100;
 Minibatch[1301-1400]: loss = 0.386422 * 100, metric = 7.32% * 100;
 Minibatch[1401-1500]: loss = 0.401559 * 100, metric = 7.78% * 100;
 Minibatch[1501-1600]: loss = 0.418303 * 100, metric = 8.29% * 100;
 Minibatch[1601-1700]: loss = 0.390953 * 100, metric = 7.77% * 100;
 Minibatch[1701-1800]: loss = 0.391688 * 100, metric = 7.24% * 100;
 Minibatch[1801-1900]: loss = 0.411740 * 100, metric = 8.25% * 100;
 Minibatch[1901-2000]: loss = 0.385134 * 100, metric = 7.47% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.400139 * 2000, metric = 7.75% * 2000 796.016s (  2.5 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 14.55% * 2000;
0.5365867951512336
 Minibatch[   1- 100]: loss = 0.407669 * 100, metric = 8.02% * 100;
 Minibatch[ 101- 200]: loss = 0.393438 * 100, metric = 7.46% * 100;
 Minibatch[ 201- 300]: loss = 0.402514 * 100, metric = 7.90% * 100;
 Minibatch[ 301- 400]: loss = 0.390683 * 100, metric = 7.63% * 100;
 Minibatch[ 401- 500]: loss = 0.389795 * 100, metric = 7.48% * 100;
 Minibatch[ 501- 600]: loss = 0.402163 * 100, metric = 7.70% * 100;
 Minibatch[ 601- 700]: loss = 0.392256 * 100, metric = 7.53% * 100;
 Minibatch[ 701- 800]: loss = 0.392189 * 100, metric = 7.88% * 100;
 Minibatch[ 801- 900]: loss = 0.400577 * 100, metric = 7.74% * 100;
 Minibatch[ 901-1000]: loss = 0.405743 * 100, metric = 7.78% * 100;
 Minibatch[1001-1100]: loss = 0.377501 * 100, metric = 7.20% * 100;
 Minibatch[1101-1200]: loss = 0.371565 * 100, metric = 7.01% * 100;
 Minibatch[1201-1300]: loss = 0.389070 * 100, metric = 7.51% * 100;
 Minibatch[1301-1400]: loss = 0.394041 * 100, metric = 7.48% * 100;
 Minibatch[1401-1500]: loss = 0.385405 * 100, metric = 7.52% * 100;
 Minibatch[1501-1600]: loss = 0.381213 * 100, metric = 7.31% * 100;
 Minibatch[1601-1700]: loss = 0.386602 * 100, metric = 7.46% * 100;
 Minibatch[1701-1800]: loss = 0.382709 * 100, metric = 7.12% * 100;
 Minibatch[1801-1900]: loss = 0.381895 * 100, metric = 7.18% * 100;
 Minibatch[1901-2000]: loss = 0.389003 * 100, metric = 7.38% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.390802 * 2000, metric = 7.51% * 2000 789.913s (  2.5 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 15.00% * 2000;
 Minibatch[   1- 100]: loss = 0.399342 * 100, metric = 7.57% * 100;
 Minibatch[ 101- 200]: loss = 0.397638 * 100, metric = 7.71% * 100;
 Minibatch[ 201- 300]: loss = 0.386590 * 100, metric = 7.35% * 100;
 Minibatch[ 301- 400]: loss = 0.399288 * 100, metric = 7.60% * 100;
 Minibatch[ 401- 500]: loss = 0.399495 * 100, metric = 7.75% * 100;
 Minibatch[ 501- 600]: loss = 0.394213 * 100, metric = 7.66% * 100;
 Minibatch[ 601- 700]: loss = 0.390309 * 100, metric = 7.27% * 100;
 Minibatch[ 701- 800]: loss = 0.374294 * 100, metric = 7.07% * 100;
 Minibatch[ 801- 900]: loss = 0.373026 * 100, metric = 7.26% * 100;
 Minibatch[ 901-1000]: loss = 0.393979 * 100, metric = 7.52% * 100;
 Minibatch[1001-1100]: loss = 0.384705 * 100, metric = 7.29% * 100;
 Minibatch[1101-1200]: loss = 0.388793 * 100, metric = 7.52% * 100;
 Minibatch[1201-1300]: loss = 0.391907 * 100, metric = 7.54% * 100;
 Minibatch[1301-1400]: loss = 0.395168 * 100, metric = 7.69% * 100;
 Minibatch[1401-1500]: loss = 0.379384 * 100, metric = 7.37% * 100;
 Minibatch[1501-1600]: loss = 0.385941 * 100, metric = 7.26% * 100;
 Minibatch[1601-1700]: loss = 0.382665 * 100, metric = 7.25% * 100;
 Minibatch[1701-1800]: loss = 0.392862 * 100, metric = 7.62% * 100;
 Minibatch[1801-1900]: loss = 0.394672 * 100, metric = 7.90% * 100;
 Minibatch[1901-2000]: loss = 0.390455 * 100, metric = 7.51% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.389736 * 2000, metric = 7.49% * 2000 785.483s (  2.5 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 16.11% * 2000;
 Minibatch[   1- 100]: loss = 0.376606 * 100, metric = 7.31% * 100;
 Minibatch[ 101- 200]: loss = 0.389347 * 100, metric = 7.60% * 100;
 Minibatch[ 201- 300]: loss = 0.386666 * 100, metric = 7.43% * 100;
 Minibatch[ 301- 400]: loss = 0.389072 * 100, metric = 7.35% * 100;
 Minibatch[ 401- 500]: loss = 0.384457 * 100, metric = 7.42% * 100;
 Minibatch[ 501- 600]: loss = 0.377263 * 100, metric = 7.37% * 100;
 Minibatch[ 601- 700]: loss = 0.393355 * 100, metric = 7.54% * 100;
 Minibatch[ 701- 800]: loss = 0.384485 * 100, metric = 7.53% * 100;
 Minibatch[ 801- 900]: loss = 0.388297 * 100, metric = 7.52% * 100;
 Minibatch[ 901-1000]: loss = 0.388252 * 100, metric = 7.53% * 100;
 Minibatch[1001-1100]: loss = 0.386441 * 100, metric = 7.33% * 100;
 Minibatch[1101-1200]: loss = 0.404834 * 100, metric = 7.79% * 100;
 Minibatch[1201-1300]: loss = 0.391550 * 100, metric = 7.54% * 100;
 Minibatch[1301-1400]: loss = 0.379096 * 100, metric = 7.34% * 100;
 Minibatch[1401-1500]: loss = 0.382142 * 100, metric = 7.40% * 100;
 Minibatch[1501-1600]: loss = 0.396728 * 100, metric = 7.76% * 100;
 Minibatch[1601-1700]: loss = 0.374791 * 100, metric = 7.14% * 100;
 Minibatch[1701-1800]: loss = 0.372913 * 100, metric = 7.05% * 100;
 Minibatch[1801-1900]: loss = 0.389374 * 100, metric = 7.62% * 100;
 Minibatch[1901-2000]: loss = 0.389728 * 100, metric = 7.75% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.386270 * 2000, metric = 7.47% * 2000 793.487s (  2.5 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.60% * 2000;
 Minibatch[   1- 100]: loss = 0.386608 * 100, metric = 7.39% * 100;
 Minibatch[ 101- 200]: loss = 0.384052 * 100, metric = 7.62% * 100;
 Minibatch[ 201- 300]: loss = 0.384911 * 100, metric = 7.50% * 100;
 Minibatch[ 301- 400]: loss = 0.389226 * 100, metric = 7.41% * 100;
 Minibatch[ 401- 500]: loss = 0.376605 * 100, metric = 7.34% * 100;
 Minibatch[ 501- 600]: loss = 0.379706 * 100, metric = 7.31% * 100;
 Minibatch[ 601- 700]: loss = 0.378845 * 100, metric = 7.19% * 100;
 Minibatch[ 701- 800]: loss = 0.366168 * 100, metric = 6.99% * 100;
 Minibatch[ 801- 900]: loss = 0.369122 * 100, metric = 7.04% * 100;
 Minibatch[ 901-1000]: loss = 0.367835 * 100, metric = 7.06% * 100;
 Minibatch[1001-1100]: loss = 0.373179 * 100, metric = 7.05% * 100;
 Minibatch[1101-1200]: loss = 0.387671 * 100, metric = 7.53% * 100;
 Minibatch[1201-1300]: loss = 0.396571 * 100, metric = 7.68% * 100;
 Minibatch[1301-1400]: loss = 0.376043 * 100, metric = 7.30% * 100;
 Minibatch[1401-1500]: loss = 0.369642 * 100, metric = 6.81% * 100;
 Minibatch[1501-1600]: loss = 0.386129 * 100, metric = 7.39% * 100;
 Minibatch[1601-1700]: loss = 0.377740 * 100, metric = 7.36% * 100;
 Minibatch[1701-1800]: loss = 0.377250 * 100, metric = 7.38% * 100;
 Minibatch[1801-1900]: loss = 0.365647 * 100, metric = 6.84% * 100;
 Minibatch[1901-2000]: loss = 0.355485 * 100, metric = 6.70% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.377422 * 2000, metric = 7.24% * 2000 789.516s (  2.5 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.05% * 2000;
 Minibatch[   1- 100]: loss = 0.372240 * 100, metric = 7.30% * 100;
 Minibatch[ 101- 200]: loss = 0.360295 * 100, metric = 6.88% * 100;
 Minibatch[ 201- 300]: loss = 0.375934 * 100, metric = 7.26% * 100;
 Minibatch[ 301- 400]: loss = 0.365896 * 100, metric = 6.94% * 100;
 Minibatch[ 401- 500]: loss = 0.374250 * 100, metric = 7.32% * 100;
 Minibatch[ 501- 600]: loss = 0.366966 * 100, metric = 7.11% * 100;
 Minibatch[ 601- 700]: loss = 0.388576 * 100, metric = 7.50% * 100;
 Minibatch[ 701- 800]: loss = 0.372824 * 100, metric = 7.32% * 100;
 Minibatch[ 801- 900]: loss = 0.359991 * 100, metric = 6.93% * 100;
 Minibatch[ 901-1000]: loss = 0.358479 * 100, metric = 6.83% * 100;
 Minibatch[1001-1100]: loss = 0.383342 * 100, metric = 7.60% * 100;
 Minibatch[1101-1200]: loss = 0.386304 * 100, metric = 7.45% * 100;
 Minibatch[1201-1300]: loss = 0.368272 * 100, metric = 7.17% * 100;
 Minibatch[1301-1400]: loss = 0.358592 * 100, metric = 6.71% * 100;
 Minibatch[1401-1500]: loss = 0.369523 * 100, metric = 7.15% * 100;
 Minibatch[1501-1600]: loss = 0.370349 * 100, metric = 7.03% * 100;
 Minibatch[1601-1700]: loss = 0.392594 * 100, metric = 7.75% * 100;
 Minibatch[1701-1800]: loss = 0.386755 * 100, metric = 7.51% * 100;
 Minibatch[1801-1900]: loss = 0.370682 * 100, metric = 7.11% * 100;
 Minibatch[1901-2000]: loss = 0.371050 * 100, metric = 7.28% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.372646 * 2000, metric = 7.21% * 2000 784.470s (  2.5 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.62% * 2000;
 Minibatch[   1- 100]: loss = 0.368878 * 100, metric = 6.99% * 100;
 Minibatch[ 101- 200]: loss = 0.381393 * 100, metric = 7.38% * 100;
 Minibatch[ 201- 300]: loss = 0.373166 * 100, metric = 7.07% * 100;
 Minibatch[ 301- 400]: loss = 0.368372 * 100, metric = 6.95% * 100;
 Minibatch[ 401- 500]: loss = 0.372508 * 100, metric = 7.04% * 100;
 Minibatch[ 501- 600]: loss = 0.363608 * 100, metric = 6.90% * 100;
 Minibatch[ 601- 700]: loss = 0.364252 * 100, metric = 6.93% * 100;
 Minibatch[ 701- 800]: loss = 0.366343 * 100, metric = 7.06% * 100;
 Minibatch[ 801- 900]: loss = 0.381144 * 100, metric = 7.24% * 100;
 Minibatch[ 901-1000]: loss = 0.370934 * 100, metric = 7.22% * 100;
 Minibatch[1001-1100]: loss = 0.368888 * 100, metric = 6.97% * 100;
 Minibatch[1101-1200]: loss = 0.381953 * 100, metric = 7.39% * 100;
 Minibatch[1201-1300]: loss = 0.373558 * 100, metric = 7.27% * 100;
 Minibatch[1301-1400]: loss = 0.380382 * 100, metric = 7.48% * 100;
 Minibatch[1401-1500]: loss = 0.371810 * 100, metric = 7.01% * 100;
 Minibatch[1501-1600]: loss = 0.371150 * 100, metric = 7.09% * 100;
 Minibatch[1601-1700]: loss = 0.352794 * 100, metric = 6.66% * 100;
 Minibatch[1701-1800]: loss = 0.361174 * 100, metric = 6.77% * 100;
 Minibatch[1801-1900]: loss = 0.364294 * 100, metric = 6.98% * 100;
 Minibatch[1901-2000]: loss = 0.378321 * 100, metric = 7.15% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.370746 * 2000, metric = 7.08% * 2000 823.357s (  2.4 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.81% * 2000;
 Minibatch[   1- 100]: loss = 0.372496 * 100, metric = 7.31% * 100;
 Minibatch[ 101- 200]: loss = 0.358917 * 100, metric = 6.80% * 100;
 Minibatch[ 201- 300]: loss = 0.371267 * 100, metric = 7.18% * 100;
 Minibatch[ 301- 400]: loss = 0.368416 * 100, metric = 6.88% * 100;
 Minibatch[ 401- 500]: loss = 0.363715 * 100, metric = 7.11% * 100;
 Minibatch[ 501- 600]: loss = 0.380073 * 100, metric = 7.55% * 100;
 Minibatch[ 601- 700]: loss = 0.361791 * 100, metric = 6.95% * 100;
 Minibatch[ 701- 800]: loss = 0.350864 * 100, metric = 6.65% * 100;
 Minibatch[ 801- 900]: loss = 0.363651 * 100, metric = 6.97% * 100;
 Minibatch[ 901-1000]: loss = 0.365529 * 100, metric = 7.25% * 100;
 Minibatch[1001-1100]: loss = 0.367990 * 100, metric = 7.03% * 100;
 Minibatch[1101-1200]: loss = 0.356441 * 100, metric = 6.72% * 100;
 Minibatch[1201-1300]: loss = 0.365567 * 100, metric = 7.18% * 100;
 Minibatch[1301-1400]: loss = 0.353548 * 100, metric = 6.84% * 100;
 Minibatch[1401-1500]: loss = 0.370304 * 100, metric = 7.13% * 100;
 Minibatch[1501-1600]: loss = 0.364762 * 100, metric = 6.98% * 100;
 Minibatch[1601-1700]: loss = 0.363573 * 100, metric = 6.68% * 100;
 Minibatch[1701-1800]: loss = 0.358503 * 100, metric = 6.62% * 100;
 Minibatch[1801-1900]: loss = 0.356990 * 100, metric = 6.90% * 100;
 Minibatch[1901-2000]: loss = 0.363476 * 100, metric = 6.90% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.363894 * 2000, metric = 6.98% * 2000 832.250s (  2.4 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 14.08% * 2000;
 Minibatch[   1- 100]: loss = 0.351540 * 100, metric = 6.58% * 100;
 Minibatch[ 101- 200]: loss = 0.356553 * 100, metric = 6.92% * 100;
 Minibatch[ 201- 300]: loss = 0.361371 * 100, metric = 7.01% * 100;
 Minibatch[ 301- 400]: loss = 0.383371 * 100, metric = 7.42% * 100;
 Minibatch[ 401- 500]: loss = 0.351073 * 100, metric = 6.66% * 100;
 Minibatch[ 501- 600]: loss = 0.357574 * 100, metric = 6.65% * 100;
 Minibatch[ 601- 700]: loss = 0.352408 * 100, metric = 6.78% * 100;
 Minibatch[ 701- 800]: loss = 0.364622 * 100, metric = 6.92% * 100;
 Minibatch[ 801- 900]: loss = 0.355905 * 100, metric = 6.92% * 100;
 Minibatch[ 901-1000]: loss = 0.360113 * 100, metric = 7.05% * 100;
 Minibatch[1001-1100]: loss = 0.359287 * 100, metric = 7.07% * 100;
 Minibatch[1101-1200]: loss = 0.347533 * 100, metric = 6.60% * 100;
 Minibatch[1201-1300]: loss = 0.355520 * 100, metric = 6.83% * 100;
 Minibatch[1301-1400]: loss = 0.347186 * 100, metric = 6.70% * 100;
 Minibatch[1401-1500]: loss = 0.366855 * 100, metric = 7.07% * 100;
 Minibatch[1501-1600]: loss = 0.343786 * 100, metric = 6.54% * 100;
 Minibatch[1601-1700]: loss = 0.362573 * 100, metric = 6.95% * 100;
 Minibatch[1701-1800]: loss = 0.342947 * 100, metric = 6.66% * 100;
 Minibatch[1801-1900]: loss = 0.368361 * 100, metric = 7.18% * 100;
 Minibatch[1901-2000]: loss = 0.360060 * 100, metric = 6.84% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.357432 * 2000, metric = 6.87% * 2000 829.574s (  2.4 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 14.80% * 2000;
 Minibatch[   1- 100]: loss = 0.372835 * 100, metric = 7.08% * 100;
 Minibatch[ 101- 200]: loss = 0.335438 * 100, metric = 6.25% * 100;
 Minibatch[ 201- 300]: loss = 0.348182 * 100, metric = 6.67% * 100;
 Minibatch[ 301- 400]: loss = 0.362884 * 100, metric = 6.97% * 100;
 Minibatch[ 401- 500]: loss = 0.351763 * 100, metric = 6.54% * 100;
 Minibatch[ 501- 600]: loss = 0.334077 * 100, metric = 6.28% * 100;
 Minibatch[ 601- 700]: loss = 0.356999 * 100, metric = 6.99% * 100;
 Minibatch[ 701- 800]: loss = 0.347818 * 100, metric = 6.69% * 100;
 Minibatch[ 801- 900]: loss = 0.355678 * 100, metric = 6.65% * 100;
 Minibatch[ 901-1000]: loss = 0.333205 * 100, metric = 6.37% * 100;
 Minibatch[1001-1100]: loss = 0.343739 * 100, metric = 6.45% * 100;
 Minibatch[1101-1200]: loss = 0.361275 * 100, metric = 6.90% * 100;
 Minibatch[1201-1300]: loss = 0.352901 * 100, metric = 6.83% * 100;
 Minibatch[1301-1400]: loss = 0.344565 * 100, metric = 6.54% * 100;
 Minibatch[1401-1500]: loss = 0.350809 * 100, metric = 6.72% * 100;
 Minibatch[1501-1600]: loss = 0.358557 * 100, metric = 6.76% * 100;
 Minibatch[1601-1700]: loss = 0.361216 * 100, metric = 6.95% * 100;
 Minibatch[1701-1800]: loss = 0.362095 * 100, metric = 6.79% * 100;
 Minibatch[1801-1900]: loss = 0.351132 * 100, metric = 6.76% * 100;
 Minibatch[1901-2000]: loss = 0.373161 * 100, metric = 7.30% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.352917 * 2000, metric = 6.72% * 2000 783.672s (  2.6 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.30% * 2000;
 Minibatch[   1- 100]: loss = 0.357785 * 100, metric = 6.69% * 100;
 Minibatch[ 101- 200]: loss = 0.365352 * 100, metric = 7.10% * 100;
 Minibatch[ 201- 300]: loss = 0.354462 * 100, metric = 6.79% * 100;
 Minibatch[ 301- 400]: loss = 0.349378 * 100, metric = 6.61% * 100;
 Minibatch[ 401- 500]: loss = 0.355552 * 100, metric = 6.72% * 100;
 Minibatch[ 501- 600]: loss = 0.345148 * 100, metric = 6.54% * 100;
 Minibatch[ 601- 700]: loss = 0.360265 * 100, metric = 7.11% * 100;
 Minibatch[ 701- 800]: loss = 0.359844 * 100, metric = 7.06% * 100;
 Minibatch[ 801- 900]: loss = 0.357832 * 100, metric = 6.78% * 100;
 Minibatch[ 901-1000]: loss = 0.342550 * 100, metric = 6.45% * 100;
 Minibatch[1001-1100]: loss = 0.344755 * 100, metric = 6.60% * 100;
 Minibatch[1101-1200]: loss = 0.352363 * 100, metric = 6.92% * 100;
 Minibatch[1201-1300]: loss = 0.345569 * 100, metric = 6.54% * 100;
 Minibatch[1301-1400]: loss = 0.353459 * 100, metric = 6.94% * 100;
 Minibatch[1401-1500]: loss = 0.365718 * 100, metric = 7.01% * 100;
 Minibatch[1501-1600]: loss = 0.340591 * 100, metric = 6.68% * 100;
 Minibatch[1601-1700]: loss = 0.344725 * 100, metric = 6.60% * 100;
 Minibatch[1701-1800]: loss = 0.350008 * 100, metric = 6.72% * 100;
 Minibatch[1801-1900]: loss = 0.362575 * 100, metric = 6.99% * 100;
 Minibatch[1901-2000]: loss = 0.357315 * 100, metric = 6.88% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.353262 * 2000, metric = 6.79% * 2000 780.663s (  2.6 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 14.02% * 2000;
 Minibatch[   1- 100]: loss = 0.352489 * 100, metric = 6.94% * 100;
 Minibatch[ 101- 200]: loss = 0.354289 * 100, metric = 6.63% * 100;
 Minibatch[ 201- 300]: loss = 0.358636 * 100, metric = 7.05% * 100;
 Minibatch[ 301- 400]: loss = 0.364771 * 100, metric = 6.99% * 100;
 Minibatch[ 401- 500]: loss = 0.355645 * 100, metric = 6.90% * 100;
 Minibatch[ 501- 600]: loss = 0.345385 * 100, metric = 6.76% * 100;
 Minibatch[ 601- 700]: loss = 0.338238 * 100, metric = 6.46% * 100;
 Minibatch[ 701- 800]: loss = 0.337319 * 100, metric = 6.53% * 100;
 Minibatch[ 801- 900]: loss = 0.343976 * 100, metric = 6.64% * 100;
 Minibatch[ 901-1000]: loss = 0.339240 * 100, metric = 6.54% * 100;
 Minibatch[1001-1100]: loss = 0.342881 * 100, metric = 6.45% * 100;
 Minibatch[1101-1200]: loss = 0.355670 * 100, metric = 7.01% * 100;
 Minibatch[1201-1300]: loss = 0.353510 * 100, metric = 6.81% * 100;
 Minibatch[1301-1400]: loss = 0.347999 * 100, metric = 6.81% * 100;
 Minibatch[1401-1500]: loss = 0.343957 * 100, metric = 6.70% * 100;
 Minibatch[1501-1600]: loss = 0.347130 * 100, metric = 6.53% * 100;
 Minibatch[1601-1700]: loss = 0.340674 * 100, metric = 6.42% * 100;
 Minibatch[1701-1800]: loss = 0.356173 * 100, metric = 6.93% * 100;
 Minibatch[1801-1900]: loss = 0.343998 * 100, metric = 6.52% * 100;
 Minibatch[1901-2000]: loss = 0.347054 * 100, metric = 6.80% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.348452 * 2000, metric = 6.72% * 2000 781.832s (  2.6 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.54% * 2000;
 Minibatch[   1- 100]: loss = 0.357917 * 100, metric = 6.86% * 100;
 Minibatch[ 101- 200]: loss = 0.345791 * 100, metric = 6.64% * 100;
 Minibatch[ 201- 300]: loss = 0.339872 * 100, metric = 6.62% * 100;
 Minibatch[ 301- 400]: loss = 0.349141 * 100, metric = 6.81% * 100;
 Minibatch[ 401- 500]: loss = 0.340165 * 100, metric = 6.38% * 100;
 Minibatch[ 501- 600]: loss = 0.348152 * 100, metric = 6.55% * 100;
 Minibatch[ 601- 700]: loss = 0.358411 * 100, metric = 6.79% * 100;
 Minibatch[ 701- 800]: loss = 0.341556 * 100, metric = 6.60% * 100;
 Minibatch[ 801- 900]: loss = 0.339106 * 100, metric = 6.27% * 100;
 Minibatch[ 901-1000]: loss = 0.326346 * 100, metric = 6.13% * 100;
 Minibatch[1001-1100]: loss = 0.343753 * 100, metric = 6.50% * 100;
 Minibatch[1101-1200]: loss = 0.330311 * 100, metric = 6.21% * 100;
 Minibatch[1201-1300]: loss = 0.353204 * 100, metric = 6.64% * 100;
 Minibatch[1301-1400]: loss = 0.335608 * 100, metric = 6.23% * 100;
 Minibatch[1401-1500]: loss = 0.355652 * 100, metric = 6.81% * 100;
 Minibatch[1501-1600]: loss = 0.353882 * 100, metric = 6.78% * 100;
 Minibatch[1601-1700]: loss = 0.334728 * 100, metric = 6.18% * 100;
 Minibatch[1701-1800]: loss = 0.340037 * 100, metric = 6.36% * 100;
 Minibatch[1801-1900]: loss = 0.334863 * 100, metric = 6.29% * 100;
 Minibatch[1901-2000]: loss = 0.350739 * 100, metric = 6.82% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.343962 * 2000, metric = 6.52% * 2000 782.418s (  2.6 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.72% * 2000;
 Minibatch[   1- 100]: loss = 0.338638 * 100, metric = 6.41% * 100;
 Minibatch[ 101- 200]: loss = 0.351741 * 100, metric = 6.70% * 100;
 Minibatch[ 201- 300]: loss = 0.331683 * 100, metric = 6.26% * 100;
 Minibatch[ 301- 400]: loss = 0.344388 * 100, metric = 6.51% * 100;
 Minibatch[ 401- 500]: loss = 0.339528 * 100, metric = 6.46% * 100;
 Minibatch[ 501- 600]: loss = 0.345800 * 100, metric = 6.61% * 100;
 Minibatch[ 601- 700]: loss = 0.350648 * 100, metric = 6.72% * 100;
 Minibatch[ 701- 800]: loss = 0.335719 * 100, metric = 6.53% * 100;
 Minibatch[ 801- 900]: loss = 0.322092 * 100, metric = 6.03% * 100;
 Minibatch[ 901-1000]: loss = 0.336078 * 100, metric = 6.53% * 100;
 Minibatch[1001-1100]: loss = 0.347131 * 100, metric = 6.74% * 100;
 Minibatch[1101-1200]: loss = 0.334245 * 100, metric = 6.43% * 100;
 Minibatch[1201-1300]: loss = 0.347609 * 100, metric = 6.65% * 100;
 Minibatch[1301-1400]: loss = 0.342534 * 100, metric = 6.59% * 100;
 Minibatch[1401-1500]: loss = 0.349133 * 100, metric = 6.88% * 100;
 Minibatch[1501-1600]: loss = 0.348303 * 100, metric = 6.69% * 100;
 Minibatch[1601-1700]: loss = 0.352239 * 100, metric = 6.81% * 100;
 Minibatch[1701-1800]: loss = 0.343525 * 100, metric = 6.64% * 100;
 Minibatch[1801-1900]: loss = 0.340889 * 100, metric = 6.53% * 100;
 Minibatch[1901-2000]: loss = 0.343143 * 100, metric = 6.41% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.342253 * 2000, metric = 6.56% * 2000 776.267s (  2.6 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.42% * 2000;
 Minibatch[   1- 100]: loss = 0.316514 * 100, metric = 5.90% * 100;
 Minibatch[ 101- 200]: loss = 0.331581 * 100, metric = 6.47% * 100;
 Minibatch[ 201- 300]: loss = 0.337453 * 100, metric = 6.46% * 100;
 Minibatch[ 301- 400]: loss = 0.325277 * 100, metric = 6.07% * 100;
 Minibatch[ 401- 500]: loss = 0.340393 * 100, metric = 6.53% * 100;
 Minibatch[ 501- 600]: loss = 0.318673 * 100, metric = 5.96% * 100;
 Minibatch[ 601- 700]: loss = 0.343808 * 100, metric = 6.58% * 100;
 Minibatch[ 701- 800]: loss = 0.315324 * 100, metric = 5.87% * 100;
 Minibatch[ 801- 900]: loss = 0.340156 * 100, metric = 6.44% * 100;
 Minibatch[ 901-1000]: loss = 0.323552 * 100, metric = 6.25% * 100;
 Minibatch[1001-1100]: loss = 0.345088 * 100, metric = 6.65% * 100;
 Minibatch[1101-1200]: loss = 0.330497 * 100, metric = 6.17% * 100;
 Minibatch[1201-1300]: loss = 0.332703 * 100, metric = 6.43% * 100;
 Minibatch[1301-1400]: loss = 0.340589 * 100, metric = 6.43% * 100;
 Minibatch[1401-1500]: loss = 0.329541 * 100, metric = 6.13% * 100;
 Minibatch[1501-1600]: loss = 0.334342 * 100, metric = 6.39% * 100;
 Minibatch[1601-1700]: loss = 0.335175 * 100, metric = 6.34% * 100;
 Minibatch[1701-1800]: loss = 0.320735 * 100, metric = 6.12% * 100;
 Minibatch[1801-1900]: loss = 0.339279 * 100, metric = 6.52% * 100;
 Minibatch[1901-2000]: loss = 0.329250 * 100, metric = 6.23% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.331496 * 2000, metric = 6.30% * 2000 776.336s (  2.6 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.36% * 2000;
 Minibatch[   1- 100]: loss = 0.331085 * 100, metric = 6.30% * 100;
 Minibatch[ 101- 200]: loss = 0.318153 * 100, metric = 6.03% * 100;
 Minibatch[ 201- 300]: loss = 0.341940 * 100, metric = 6.54% * 100;
 Minibatch[ 301- 400]: loss = 0.322335 * 100, metric = 6.24% * 100;
 Minibatch[ 401- 500]: loss = 0.323093 * 100, metric = 6.03% * 100;
 Minibatch[ 501- 600]: loss = 0.333016 * 100, metric = 6.29% * 100;
 Minibatch[ 601- 700]: loss = 0.337188 * 100, metric = 6.18% * 100;
 Minibatch[ 701- 800]: loss = 0.314069 * 100, metric = 6.04% * 100;
 Minibatch[ 801- 900]: loss = 0.323086 * 100, metric = 6.11% * 100;
 Minibatch[ 901-1000]: loss = 0.329380 * 100, metric = 6.36% * 100;
 Minibatch[1001-1100]: loss = 0.340836 * 100, metric = 6.57% * 100;
 Minibatch[1101-1200]: loss = 0.332676 * 100, metric = 6.46% * 100;
 Minibatch[1201-1300]: loss = 0.334597 * 100, metric = 6.48% * 100;
 Minibatch[1301-1400]: loss = 0.312295 * 100, metric = 5.91% * 100;
 Minibatch[1401-1500]: loss = 0.322617 * 100, metric = 6.00% * 100;
 Minibatch[1501-1600]: loss = 0.324763 * 100, metric = 6.09% * 100;
 Minibatch[1601-1700]: loss = 0.340214 * 100, metric = 6.64% * 100;
 Minibatch[1701-1800]: loss = 0.328392 * 100, metric = 6.26% * 100;
 Minibatch[1801-1900]: loss = 0.325455 * 100, metric = 6.13% * 100;
 Minibatch[1901-2000]: loss = 0.321583 * 100, metric = 6.02% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.327839 * 2000, metric = 6.23% * 2000 775.872s (  2.6 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 12.94% * 2000;
 Minibatch[   1- 100]: loss = 0.323310 * 100, metric = 6.08% * 100;
 Minibatch[ 101- 200]: loss = 0.333484 * 100, metric = 6.33% * 100;
 Minibatch[ 201- 300]: loss = 0.328982 * 100, metric = 6.35% * 100;
 Minibatch[ 301- 400]: loss = 0.324600 * 100, metric = 6.01% * 100;
 Minibatch[ 401- 500]: loss = 0.331306 * 100, metric = 6.39% * 100;
 Minibatch[ 501- 600]: loss = 0.313296 * 100, metric = 5.86% * 100;
 Minibatch[ 601- 700]: loss = 0.331098 * 100, metric = 6.51% * 100;
 Minibatch[ 701- 800]: loss = 0.341429 * 100, metric = 6.77% * 100;
 Minibatch[ 801- 900]: loss = 0.327428 * 100, metric = 6.30% * 100;
 Minibatch[ 901-1000]: loss = 0.309292 * 100, metric = 5.70% * 100;
 Minibatch[1001-1100]: loss = 0.325012 * 100, metric = 6.11% * 100;
 Minibatch[1101-1200]: loss = 0.342047 * 100, metric = 6.64% * 100;
 Minibatch[1201-1300]: loss = 0.341217 * 100, metric = 6.67% * 100;
 Minibatch[1301-1400]: loss = 0.323493 * 100, metric = 6.05% * 100;
 Minibatch[1401-1500]: loss = 0.330947 * 100, metric = 6.60% * 100;
 Minibatch[1501-1600]: loss = 0.321309 * 100, metric = 6.01% * 100;
 Minibatch[1601-1700]: loss = 0.327520 * 100, metric = 6.36% * 100;
 Minibatch[1701-1800]: loss = 0.326710 * 100, metric = 6.11% * 100;
 Minibatch[1801-1900]: loss = 0.335812 * 100, metric = 6.36% * 100;
 Minibatch[1901-2000]: loss = 0.325771 * 100, metric = 6.09% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.328203 * 2000, metric = 6.26% * 2000 769.217s (  2.6 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.51% * 2000;
 Minibatch[   1- 100]: loss = 0.339252 * 100, metric = 6.54% * 100;
 Minibatch[ 101- 200]: loss = 0.336813 * 100, metric = 6.54% * 100;
 Minibatch[ 201- 300]: loss = 0.312555 * 100, metric = 5.79% * 100;
 Minibatch[ 301- 400]: loss = 0.320300 * 100, metric = 6.17% * 100;
 Minibatch[ 401- 500]: loss = 0.330081 * 100, metric = 6.26% * 100;
 Minibatch[ 501- 600]: loss = 0.334748 * 100, metric = 6.38% * 100;
 Minibatch[ 601- 700]: loss = 0.332458 * 100, metric = 6.54% * 100;
 Minibatch[ 701- 800]: loss = 0.328786 * 100, metric = 6.31% * 100;
 Minibatch[ 801- 900]: loss = 0.331339 * 100, metric = 6.20% * 100;
 Minibatch[ 901-1000]: loss = 0.326755 * 100, metric = 6.12% * 100;
 Minibatch[1001-1100]: loss = 0.332358 * 100, metric = 6.42% * 100;
 Minibatch[1101-1200]: loss = 0.322278 * 100, metric = 6.06% * 100;
 Minibatch[1201-1300]: loss = 0.327700 * 100, metric = 6.44% * 100;
 Minibatch[1301-1400]: loss = 0.335986 * 100, metric = 6.30% * 100;
 Minibatch[1401-1500]: loss = 0.329301 * 100, metric = 6.37% * 100;
 Minibatch[1501-1600]: loss = 0.337983 * 100, metric = 6.43% * 100;
 Minibatch[1601-1700]: loss = 0.315463 * 100, metric = 5.89% * 100;
 Minibatch[1701-1800]: loss = 0.322803 * 100, metric = 6.12% * 100;
 Minibatch[1801-1900]: loss = 0.325847 * 100, metric = 6.35% * 100;
 Minibatch[1901-2000]: loss = 0.331055 * 100, metric = 6.34% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.328693 * 2000, metric = 6.28% * 2000 772.596s (  2.6 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 12.93% * 2000;
0.533926594208926
 Minibatch[   1- 100]: loss = 0.325012 * 100, metric = 6.40% * 100;
 Minibatch[ 101- 200]: loss = 0.325872 * 100, metric = 6.20% * 100;
 Minibatch[ 201- 300]: loss = 0.327203 * 100, metric = 6.17% * 100;
 Minibatch[ 301- 400]: loss = 0.317232 * 100, metric = 6.12% * 100;
 Minibatch[ 401- 500]: loss = 0.326342 * 100, metric = 6.23% * 100;
 Minibatch[ 501- 600]: loss = 0.332441 * 100, metric = 6.43% * 100;
 Minibatch[ 601- 700]: loss = 0.325427 * 100, metric = 6.32% * 100;
 Minibatch[ 701- 800]: loss = 0.328397 * 100, metric = 6.23% * 100;
 Minibatch[ 801- 900]: loss = 0.308906 * 100, metric = 5.95% * 100;
 Minibatch[ 901-1000]: loss = 0.319651 * 100, metric = 6.11% * 100;
 Minibatch[1001-1100]: loss = 0.330545 * 100, metric = 6.52% * 100;
 Minibatch[1101-1200]: loss = 0.325769 * 100, metric = 6.43% * 100;
 Minibatch[1201-1300]: loss = 0.328926 * 100, metric = 6.04% * 100;
 Minibatch[1301-1400]: loss = 0.331268 * 100, metric = 6.27% * 100;
 Minibatch[1401-1500]: loss = 0.325117 * 100, metric = 6.23% * 100;
 Minibatch[1501-1600]: loss = 0.326321 * 100, metric = 6.12% * 100;
 Minibatch[1601-1700]: loss = 0.319086 * 100, metric = 5.99% * 100;
 Minibatch[1701-1800]: loss = 0.329606 * 100, metric = 6.36% * 100;
 Minibatch[1801-1900]: loss = 0.322967 * 100, metric = 6.25% * 100;
 Minibatch[1901-2000]: loss = 0.324410 * 100, metric = 6.23% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.325025 * 2000, metric = 6.23% * 2000 766.783s (  2.6 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.25% * 2000;
 Minibatch[   1- 100]: loss = 0.315653 * 100, metric = 6.22% * 100;
 Minibatch[ 101- 200]: loss = 0.316930 * 100, metric = 6.08% * 100;
 Minibatch[ 201- 300]: loss = 0.336110 * 100, metric = 6.59% * 100;
 Minibatch[ 301- 400]: loss = 0.328692 * 100, metric = 6.28% * 100;
 Minibatch[ 401- 500]: loss = 0.327213 * 100, metric = 6.15% * 100;
 Minibatch[ 501- 600]: loss = 0.317457 * 100, metric = 6.11% * 100;
 Minibatch[ 601- 700]: loss = 0.334554 * 100, metric = 6.44% * 100;
 Minibatch[ 701- 800]: loss = 0.319430 * 100, metric = 6.06% * 100;
 Minibatch[ 801- 900]: loss = 0.323095 * 100, metric = 6.12% * 100;
 Minibatch[ 901-1000]: loss = 0.328526 * 100, metric = 6.34% * 100;
 Minibatch[1001-1100]: loss = 0.332666 * 100, metric = 6.56% * 100;
 Minibatch[1101-1200]: loss = 0.324168 * 100, metric = 6.13% * 100;
 Minibatch[1201-1300]: loss = 0.324749 * 100, metric = 6.11% * 100;
 Minibatch[1301-1400]: loss = 0.326556 * 100, metric = 6.47% * 100;
 Minibatch[1401-1500]: loss = 0.323324 * 100, metric = 6.23% * 100;
 Minibatch[1501-1600]: loss = 0.334007 * 100, metric = 6.34% * 100;
 Minibatch[1601-1700]: loss = 0.326044 * 100, metric = 6.28% * 100;
 Minibatch[1701-1800]: loss = 0.320752 * 100, metric = 6.09% * 100;
 Minibatch[1801-1900]: loss = 0.320166 * 100, metric = 6.07% * 100;
 Minibatch[1901-2000]: loss = 0.330394 * 100, metric = 6.18% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.325524 * 2000, metric = 6.24% * 2000 770.763s (  2.6 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 13.23% * 2000;
 Minibatch[   1- 100]: loss = 0.325250 * 100, metric = 6.21% * 100;
 Minibatch[ 101- 200]: loss = 0.320442 * 100, metric = 6.18% * 100;
 Minibatch[ 201- 300]: loss = 0.325079 * 100, metric = 6.16% * 100;
 Minibatch[ 301- 400]: loss = 0.327284 * 100, metric = 6.45% * 100;
 Minibatch[ 401- 500]: loss = 0.325490 * 100, metric = 6.26% * 100;
 Minibatch[ 501- 600]: loss = 0.314905 * 100, metric = 6.00% * 100;
 Minibatch[ 601- 700]: loss = 0.326381 * 100, metric = 6.30% * 100;
 Minibatch[ 701- 800]: loss = 0.322741 * 100, metric = 6.23% * 100;
 Minibatch[ 801- 900]: loss = 0.317190 * 100, metric = 5.95% * 100;
 Minibatch[ 901-1000]: loss = 0.327078 * 100, metric = 6.51% * 100;
 Minibatch[1001-1100]: loss = 0.322702 * 100, metric = 6.05% * 100;
 Minibatch[1101-1200]: loss = 0.323745 * 100, metric = 6.19% * 100;
 Minibatch[1201-1300]: loss = 0.323420 * 100, metric = 6.14% * 100;
 Minibatch[1301-1400]: loss = 0.306812 * 100, metric = 5.69% * 100;
 Minibatch[1401-1500]: loss = 0.317948 * 100, metric = 6.11% * 100;
 Minibatch[1501-1600]: loss = 0.320694 * 100, metric = 5.93% * 100;
 Minibatch[1601-1700]: loss = 0.320477 * 100, metric = 6.09% * 100;
 Minibatch[1701-1800]: loss = 0.323930 * 100, metric = 6.41% * 100;
 Minibatch[1801-1900]: loss = 0.321341 * 100, metric = 6.20% * 100;
 Minibatch[1901-2000]: loss = 0.318951 * 100, metric = 5.96% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.321593 * 2000, metric = 6.15% * 2000 780.608s (  2.6 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 13.62% * 2000;
 Minibatch[   1- 100]: loss = 0.314879 * 100, metric = 5.98% * 100;
 Minibatch[ 101- 200]: loss = 0.313537 * 100, metric = 6.21% * 100;
 Minibatch[ 201- 300]: loss = 0.316123 * 100, metric = 6.04% * 100;
 Minibatch[ 301- 400]: loss = 0.309076 * 100, metric = 5.72% * 100;
 Minibatch[ 401- 500]: loss = 0.310948 * 100, metric = 5.87% * 100;
 Minibatch[ 501- 600]: loss = 0.317688 * 100, metric = 6.12% * 100;
 Minibatch[ 601- 700]: loss = 0.318775 * 100, metric = 6.13% * 100;
 Minibatch[ 701- 800]: loss = 0.307459 * 100, metric = 5.91% * 100;
 Minibatch[ 801- 900]: loss = 0.315971 * 100, metric = 6.15% * 100;
 Minibatch[ 901-1000]: loss = 0.322112 * 100, metric = 6.39% * 100;
 Minibatch[1001-1100]: loss = 0.318874 * 100, metric = 6.15% * 100;
 Minibatch[1101-1200]: loss = 0.314415 * 100, metric = 6.09% * 100;
 Minibatch[1201-1300]: loss = 0.311957 * 100, metric = 5.89% * 100;
 Minibatch[1301-1400]: loss = 0.315240 * 100, metric = 5.99% * 100;
 Minibatch[1401-1500]: loss = 0.311536 * 100, metric = 5.95% * 100;
 Minibatch[1501-1600]: loss = 0.312517 * 100, metric = 5.97% * 100;
 Minibatch[1601-1700]: loss = 0.318013 * 100, metric = 5.88% * 100;
 Minibatch[1701-1800]: loss = 0.313372 * 100, metric = 6.04% * 100;
 Minibatch[1801-1900]: loss = 0.314201 * 100, metric = 6.06% * 100;
 Minibatch[1901-2000]: loss = 0.313275 * 100, metric = 5.93% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.314498 * 2000, metric = 6.02% * 2000 758.905s (  2.6 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 12.68% * 2000;
 Minibatch[   1- 100]: loss = 0.326863 * 100, metric = 6.30% * 100;
 Minibatch[ 101- 200]: loss = 0.299805 * 100, metric = 5.54% * 100;
 Minibatch[ 201- 300]: loss = 0.316143 * 100, metric = 6.02% * 100;
 Minibatch[ 301- 400]: loss = 0.310531 * 100, metric = 6.02% * 100;
 Minibatch[ 401- 500]: loss = 0.307236 * 100, metric = 5.74% * 100;
 Minibatch[ 501- 600]: loss = 0.304603 * 100, metric = 5.80% * 100;
 Minibatch[ 601- 700]: loss = 0.319971 * 100, metric = 6.35% * 100;
 Minibatch[ 701- 800]: loss = 0.303500 * 100, metric = 5.97% * 100;
 Minibatch[ 801- 900]: loss = 0.306826 * 100, metric = 5.85% * 100;
 Minibatch[ 901-1000]: loss = 0.309561 * 100, metric = 5.90% * 100;
 Minibatch[1001-1100]: loss = 0.305185 * 100, metric = 5.76% * 100;
 Minibatch[1101-1200]: loss = 0.303046 * 100, metric = 5.85% * 100;
 Minibatch[1201-1300]: loss = 0.314591 * 100, metric = 6.22% * 100;
 Minibatch[1301-1400]: loss = 0.310891 * 100, metric = 5.95% * 100;
 Minibatch[1401-1500]: loss = 0.298415 * 100, metric = 5.72% * 100;
 Minibatch[1501-1600]: loss = 0.314241 * 100, metric = 5.98% * 100;
 Minibatch[1601-1700]: loss = 0.308629 * 100, metric = 5.88% * 100;
 Minibatch[1701-1800]: loss = 0.303982 * 100, metric = 5.89% * 100;
 Minibatch[1801-1900]: loss = 0.312706 * 100, metric = 6.10% * 100;
 Minibatch[1901-2000]: loss = 0.304532 * 100, metric = 5.74% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.309063 * 2000, metric = 5.93% * 2000 754.904s (  2.6 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 13.68% * 2000;
 Minibatch[   1- 100]: loss = 0.302163 * 100, metric = 5.58% * 100;
 Minibatch[ 101- 200]: loss = 0.312523 * 100, metric = 6.10% * 100;
 Minibatch[ 201- 300]: loss = 0.310402 * 100, metric = 5.92% * 100;
 Minibatch[ 301- 400]: loss = 0.317641 * 100, metric = 6.07% * 100;
 Minibatch[ 401- 500]: loss = 0.304739 * 100, metric = 5.67% * 100;
 Minibatch[ 501- 600]: loss = 0.305488 * 100, metric = 5.86% * 100;
 Minibatch[ 601- 700]: loss = 0.321807 * 100, metric = 6.30% * 100;
 Minibatch[ 701- 800]: loss = 0.286762 * 100, metric = 5.27% * 100;
 Minibatch[ 801- 900]: loss = 0.297772 * 100, metric = 5.56% * 100;
 Minibatch[ 901-1000]: loss = 0.298056 * 100, metric = 5.55% * 100;
 Minibatch[1001-1100]: loss = 0.302665 * 100, metric = 5.56% * 100;
 Minibatch[1101-1200]: loss = 0.297851 * 100, metric = 5.64% * 100;
 Minibatch[1201-1300]: loss = 0.305593 * 100, metric = 5.88% * 100;
 Minibatch[1301-1400]: loss = 0.296789 * 100, metric = 5.57% * 100;
 Minibatch[1401-1500]: loss = 0.295503 * 100, metric = 5.40% * 100;
 Minibatch[1501-1600]: loss = 0.290267 * 100, metric = 5.38% * 100;
 Minibatch[1601-1700]: loss = 0.305242 * 100, metric = 5.65% * 100;
 Minibatch[1701-1800]: loss = 0.315147 * 100, metric = 6.23% * 100;
 Minibatch[1801-1900]: loss = 0.305601 * 100, metric = 5.69% * 100;
 Minibatch[1901-2000]: loss = 0.299696 * 100, metric = 5.62% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.303585 * 2000, metric = 5.73% * 2000 752.285s (  2.7 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 13.33% * 2000;
 Minibatch[   1- 100]: loss = 0.309249 * 100, metric = 5.62% * 100;
 Minibatch[ 101- 200]: loss = 0.299193 * 100, metric = 5.53% * 100;
 Minibatch[ 201- 300]: loss = 0.298427 * 100, metric = 5.65% * 100;
 Minibatch[ 301- 400]: loss = 0.308568 * 100, metric = 5.90% * 100;
 Minibatch[ 401- 500]: loss = 0.293742 * 100, metric = 5.40% * 100;
 Minibatch[ 501- 600]: loss = 0.289060 * 100, metric = 5.26% * 100;
 Minibatch[ 601- 700]: loss = 0.287777 * 100, metric = 5.42% * 100;
 Minibatch[ 701- 800]: loss = 0.289707 * 100, metric = 5.59% * 100;
 Minibatch[ 801- 900]: loss = 0.314000 * 100, metric = 5.99% * 100;
 Minibatch[ 901-1000]: loss = 0.294558 * 100, metric = 5.50% * 100;
 Minibatch[1001-1100]: loss = 0.288217 * 100, metric = 5.30% * 100;
 Minibatch[1101-1200]: loss = 0.308962 * 100, metric = 5.63% * 100;
 Minibatch[1201-1300]: loss = 0.305733 * 100, metric = 5.86% * 100;
 Minibatch[1301-1400]: loss = 0.292062 * 100, metric = 5.40% * 100;
 Minibatch[1401-1500]: loss = 0.304618 * 100, metric = 5.68% * 100;
 Minibatch[1501-1600]: loss = 0.296208 * 100, metric = 5.63% * 100;
 Minibatch[1601-1700]: loss = 0.296851 * 100, metric = 5.58% * 100;
 Minibatch[1701-1800]: loss = 0.301604 * 100, metric = 5.59% * 100;
 Minibatch[1801-1900]: loss = 0.304526 * 100, metric = 5.86% * 100;
 Minibatch[1901-2000]: loss = 0.300161 * 100, metric = 5.49% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.299161 * 2000, metric = 5.59% * 2000 756.748s (  2.6 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 13.13% * 2000;
 Minibatch[   1- 100]: loss = 0.295954 * 100, metric = 5.58% * 100;
 Minibatch[ 101- 200]: loss = 0.303619 * 100, metric = 5.69% * 100;
 Minibatch[ 201- 300]: loss = 0.299065 * 100, metric = 5.43% * 100;
 Minibatch[ 301- 400]: loss = 0.312437 * 100, metric = 5.97% * 100;
 Minibatch[ 401- 500]: loss = 0.301669 * 100, metric = 5.63% * 100;
 Minibatch[ 501- 600]: loss = 0.301166 * 100, metric = 5.69% * 100;
 Minibatch[ 601- 700]: loss = 0.288546 * 100, metric = 5.52% * 100;
 Minibatch[ 701- 800]: loss = 0.289286 * 100, metric = 5.46% * 100;
 Minibatch[ 801- 900]: loss = 0.295817 * 100, metric = 5.49% * 100;
 Minibatch[ 901-1000]: loss = 0.293717 * 100, metric = 5.39% * 100;
 Minibatch[1001-1100]: loss = 0.295211 * 100, metric = 5.47% * 100;
 Minibatch[1101-1200]: loss = 0.301717 * 100, metric = 5.66% * 100;
 Minibatch[1201-1300]: loss = 0.298508 * 100, metric = 5.61% * 100;
 Minibatch[1301-1400]: loss = 0.308785 * 100, metric = 5.90% * 100;
 Minibatch[1401-1500]: loss = 0.299360 * 100, metric = 5.70% * 100;
 Minibatch[1501-1600]: loss = 0.306680 * 100, metric = 5.76% * 100;
 Minibatch[1601-1700]: loss = 0.296254 * 100, metric = 5.50% * 100;
 Minibatch[1701-1800]: loss = 0.312774 * 100, metric = 5.93% * 100;
 Minibatch[1801-1900]: loss = 0.295773 * 100, metric = 5.40% * 100;
 Minibatch[1901-2000]: loss = 0.296012 * 100, metric = 5.30% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.299617 * 2000, metric = 5.60% * 2000 753.765s (  2.7 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 12.94% * 2000;
 Minibatch[   1- 100]: loss = 0.299305 * 100, metric = 5.54% * 100;
 Minibatch[ 101- 200]: loss = 0.294782 * 100, metric = 5.50% * 100;
 Minibatch[ 201- 300]: loss = 0.306939 * 100, metric = 5.73% * 100;
 Minibatch[ 301- 400]: loss = 0.291899 * 100, metric = 5.16% * 100;
 Minibatch[ 401- 500]: loss = 0.292932 * 100, metric = 5.50% * 100;
 Minibatch[ 501- 600]: loss = 0.288264 * 100, metric = 5.53% * 100;
 Minibatch[ 601- 700]: loss = 0.299989 * 100, metric = 5.62% * 100;
 Minibatch[ 701- 800]: loss = 0.307696 * 100, metric = 6.04% * 100;
 Minibatch[ 801- 900]: loss = 0.293849 * 100, metric = 5.44% * 100;
 Minibatch[ 901-1000]: loss = 0.299893 * 100, metric = 5.65% * 100;
 Minibatch[1001-1100]: loss = 0.310563 * 100, metric = 6.09% * 100;
 Minibatch[1101-1200]: loss = 0.294928 * 100, metric = 5.57% * 100;
 Minibatch[1201-1300]: loss = 0.279641 * 100, metric = 5.04% * 100;
 Minibatch[1301-1400]: loss = 0.282934 * 100, metric = 5.42% * 100;
 Minibatch[1401-1500]: loss = 0.297620 * 100, metric = 5.70% * 100;
 Minibatch[1501-1600]: loss = 0.303805 * 100, metric = 5.74% * 100;
 Minibatch[1601-1700]: loss = 0.293319 * 100, metric = 5.61% * 100;
 Minibatch[1701-1800]: loss = 0.300571 * 100, metric = 5.75% * 100;
 Minibatch[1801-1900]: loss = 0.304484 * 100, metric = 5.84% * 100;
 Minibatch[1901-2000]: loss = 0.307133 * 100, metric = 6.03% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.297527 * 2000, metric = 5.62% * 2000 762.286s (  2.6 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 12.39% * 2000;
 Minibatch[   1- 100]: loss = 0.298925 * 100, metric = 5.76% * 100;
 Minibatch[ 101- 200]: loss = 0.298453 * 100, metric = 5.72% * 100;
 Minibatch[ 201- 300]: loss = 0.296896 * 100, metric = 5.90% * 100;
 Minibatch[ 301- 400]: loss = 0.287596 * 100, metric = 5.39% * 100;
 Minibatch[ 401- 500]: loss = 0.307257 * 100, metric = 5.84% * 100;
 Minibatch[ 501- 600]: loss = 0.308560 * 100, metric = 5.89% * 100;
 Minibatch[ 601- 700]: loss = 0.310553 * 100, metric = 5.94% * 100;
 Minibatch[ 701- 800]: loss = 0.292477 * 100, metric = 5.54% * 100;
 Minibatch[ 801- 900]: loss = 0.283961 * 100, metric = 5.28% * 100;
 Minibatch[ 901-1000]: loss = 0.300376 * 100, metric = 5.87% * 100;
 Minibatch[1001-1100]: loss = 0.291467 * 100, metric = 5.49% * 100;
 Minibatch[1101-1200]: loss = 0.294952 * 100, metric = 5.64% * 100;
 Minibatch[1201-1300]: loss = 0.295634 * 100, metric = 5.64% * 100;
 Minibatch[1301-1400]: loss = 0.288087 * 100, metric = 5.64% * 100;
 Minibatch[1401-1500]: loss = 0.289579 * 100, metric = 5.65% * 100;
 Minibatch[1501-1600]: loss = 0.289308 * 100, metric = 5.64% * 100;
 Minibatch[1601-1700]: loss = 0.282772 * 100, metric = 5.35% * 100;
 Minibatch[1701-1800]: loss = 0.291268 * 100, metric = 5.25% * 100;
 Minibatch[1801-1900]: loss = 0.298551 * 100, metric = 5.67% * 100;
 Minibatch[1901-2000]: loss = 0.284608 * 100, metric = 5.24% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.294564 * 2000, metric = 5.62% * 2000 774.330s (  2.6 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 13.05% * 2000;
 Minibatch[   1- 100]: loss = 0.302629 * 100, metric = 5.68% * 100;
 Minibatch[ 101- 200]: loss = 0.286483 * 100, metric = 5.35% * 100;
 Minibatch[ 201- 300]: loss = 0.299759 * 100, metric = 5.53% * 100;
 Minibatch[ 301- 400]: loss = 0.293412 * 100, metric = 5.65% * 100;
 Minibatch[ 401- 500]: loss = 0.301932 * 100, metric = 5.84% * 100;
 Minibatch[ 501- 600]: loss = 0.291651 * 100, metric = 5.47% * 100;
 Minibatch[ 601- 700]: loss = 0.284732 * 100, metric = 5.45% * 100;
 Minibatch[ 701- 800]: loss = 0.295540 * 100, metric = 5.60% * 100;
 Minibatch[ 801- 900]: loss = 0.283108 * 100, metric = 5.41% * 100;
 Minibatch[ 901-1000]: loss = 0.312127 * 100, metric = 6.06% * 100;
 Minibatch[1001-1100]: loss = 0.305930 * 100, metric = 5.88% * 100;
 Minibatch[1101-1200]: loss = 0.300430 * 100, metric = 5.86% * 100;
 Minibatch[1201-1300]: loss = 0.289861 * 100, metric = 5.49% * 100;
 Minibatch[1301-1400]: loss = 0.301246 * 100, metric = 5.73% * 100;
 Minibatch[1401-1500]: loss = 0.291449 * 100, metric = 5.65% * 100;
 Minibatch[1501-1600]: loss = 0.275698 * 100, metric = 5.12% * 100;
 Minibatch[1601-1700]: loss = 0.302690 * 100, metric = 6.06% * 100;
 Minibatch[1701-1800]: loss = 0.295380 * 100, metric = 5.65% * 100;
 Minibatch[1801-1900]: loss = 0.295471 * 100, metric = 5.57% * 100;
 Minibatch[1901-2000]: loss = 0.286226 * 100, metric = 5.51% * 100;
Finished Epoch[49 of 200]: [Training] loss = 0.294788 * 2000, metric = 5.63% * 2000 779.126s (  2.6 samples/s);
Finished Evaluation [49]: Minibatch[1-2000]: metric = 12.97% * 2000;
 Minibatch[   1- 100]: loss = 0.297400 * 100, metric = 5.69% * 100;
 Minibatch[ 101- 200]: loss = 0.283087 * 100, metric = 5.26% * 100;
 Minibatch[ 201- 300]: loss = 0.283771 * 100, metric = 5.24% * 100;
 Minibatch[ 301- 400]: loss = 0.289610 * 100, metric = 5.43% * 100;
 Minibatch[ 401- 500]: loss = 0.292549 * 100, metric = 5.61% * 100;
 Minibatch[ 501- 600]: loss = 0.297101 * 100, metric = 5.84% * 100;
 Minibatch[ 601- 700]: loss = 0.287386 * 100, metric = 5.44% * 100;
 Minibatch[ 701- 800]: loss = 0.279684 * 100, metric = 5.45% * 100;
 Minibatch[ 801- 900]: loss = 0.291865 * 100, metric = 5.42% * 100;
 Minibatch[ 901-1000]: loss = 0.284785 * 100, metric = 5.04% * 100;
 Minibatch[1001-1100]: loss = 0.283077 * 100, metric = 5.49% * 100;
 Minibatch[1101-1200]: loss = 0.284927 * 100, metric = 5.37% * 100;
 Minibatch[1201-1300]: loss = 0.288961 * 100, metric = 5.49% * 100;
 Minibatch[1301-1400]: loss = 0.275845 * 100, metric = 5.35% * 100;
 Minibatch[1401-1500]: loss = 0.285526 * 100, metric = 5.56% * 100;
 Minibatch[1501-1600]: loss = 0.277626 * 100, metric = 5.13% * 100;
 Minibatch[1601-1700]: loss = 0.277842 * 100, metric = 5.07% * 100;
 Minibatch[1701-1800]: loss = 0.286284 * 100, metric = 5.57% * 100;
 Minibatch[1801-1900]: loss = 0.290021 * 100, metric = 5.35% * 100;
 Minibatch[1901-2000]: loss = 0.285525 * 100, metric = 5.46% * 100;
Finished Epoch[50 of 200]: [Training] loss = 0.286144 * 2000, metric = 5.41% * 2000 787.622s (  2.5 samples/s);
Finished Evaluation [50]: Minibatch[1-2000]: metric = 12.90% * 2000;
 Minibatch[   1- 100]: loss = 0.279732 * 100, metric = 5.41% * 100;
 Minibatch[ 101- 200]: loss = 0.293993 * 100, metric = 5.51% * 100;
 Minibatch[ 201- 300]: loss = 0.286513 * 100, metric = 5.34% * 100;
 Minibatch[ 301- 400]: loss = 0.286851 * 100, metric = 5.37% * 100;
 Minibatch[ 401- 500]: loss = 0.281462 * 100, metric = 5.26% * 100;
 Minibatch[ 501- 600]: loss = 0.291216 * 100, metric = 5.58% * 100;
 Minibatch[ 601- 700]: loss = 0.276629 * 100, metric = 5.27% * 100;
 Minibatch[ 701- 800]: loss = 0.285267 * 100, metric = 5.37% * 100;
 Minibatch[ 801- 900]: loss = 0.285376 * 100, metric = 5.54% * 100;
 Minibatch[ 901-1000]: loss = 0.281450 * 100, metric = 5.18% * 100;
 Minibatch[1001-1100]: loss = 0.291865 * 100, metric = 5.65% * 100;
 Minibatch[1101-1200]: loss = 0.290494 * 100, metric = 5.51% * 100;
 Minibatch[1201-1300]: loss = 0.302604 * 100, metric = 5.66% * 100;
 Minibatch[1301-1400]: loss = 0.284734 * 100, metric = 5.39% * 100;
 Minibatch[1401-1500]: loss = 0.277435 * 100, metric = 5.02% * 100;
 Minibatch[1501-1600]: loss = 0.290436 * 100, metric = 5.39% * 100;
 Minibatch[1601-1700]: loss = 0.277661 * 100, metric = 5.29% * 100;
 Minibatch[1701-1800]: loss = 0.285330 * 100, metric = 5.42% * 100;
 Minibatch[1801-1900]: loss = 0.265763 * 100, metric = 4.99% * 100;
 Minibatch[1901-2000]: loss = 0.285089 * 100, metric = 5.33% * 100;
Finished Epoch[51 of 200]: [Training] loss = 0.284995 * 2000, metric = 5.37% * 2000 789.998s (  2.5 samples/s);
Finished Evaluation [51]: Minibatch[1-2000]: metric = 12.38% * 2000;
 Minibatch[   1- 100]: loss = 0.273144 * 100, metric = 5.11% * 100;
 Minibatch[ 101- 200]: loss = 0.284046 * 100, metric = 5.23% * 100;
 Minibatch[ 201- 300]: loss = 0.293239 * 100, metric = 5.70% * 100;
 Minibatch[ 301- 400]: loss = 0.272444 * 100, metric = 5.12% * 100;
 Minibatch[ 401- 500]: loss = 0.287246 * 100, metric = 5.30% * 100;
 Minibatch[ 501- 600]: loss = 0.285771 * 100, metric = 5.31% * 100;
 Minibatch[ 601- 700]: loss = 0.278771 * 100, metric = 5.13% * 100;
 Minibatch[ 701- 800]: loss = 0.288019 * 100, metric = 5.61% * 100;
 Minibatch[ 801- 900]: loss = 0.288360 * 100, metric = 5.39% * 100;
 Minibatch[ 901-1000]: loss = 0.292950 * 100, metric = 5.59% * 100;
 Minibatch[1001-1100]: loss = 0.279107 * 100, metric = 5.41% * 100;
 Minibatch[1101-1200]: loss = 0.272338 * 100, metric = 4.96% * 100;
 Minibatch[1201-1300]: loss = 0.275279 * 100, metric = 5.11% * 100;
 Minibatch[1301-1400]: loss = 0.276513 * 100, metric = 5.05% * 100;
 Minibatch[1401-1500]: loss = 0.270383 * 100, metric = 4.84% * 100;
 Minibatch[1501-1600]: loss = 0.270603 * 100, metric = 4.96% * 100;
 Minibatch[1601-1700]: loss = 0.287289 * 100, metric = 5.41% * 100;
 Minibatch[1701-1800]: loss = 0.273517 * 100, metric = 5.14% * 100;
 Minibatch[1801-1900]: loss = 0.273037 * 100, metric = 4.93% * 100;
 Minibatch[1901-2000]: loss = 0.284067 * 100, metric = 5.45% * 100;
Finished Epoch[52 of 200]: [Training] loss = 0.280306 * 2000, metric = 5.24% * 2000 778.847s (  2.6 samples/s);
Finished Evaluation [52]: Minibatch[1-2000]: metric = 13.07% * 2000;
 Minibatch[   1- 100]: loss = 0.282631 * 100, metric = 5.29% * 100;
 Minibatch[ 101- 200]: loss = 0.265213 * 100, metric = 4.79% * 100;
 Minibatch[ 201- 300]: loss = 0.273281 * 100, metric = 5.08% * 100;
 Minibatch[ 301- 400]: loss = 0.279479 * 100, metric = 5.29% * 100;
 Minibatch[ 401- 500]: loss = 0.281841 * 100, metric = 5.31% * 100;
 Minibatch[ 501- 600]: loss = 0.280094 * 100, metric = 5.20% * 100;
 Minibatch[ 601- 700]: loss = 0.277206 * 100, metric = 5.12% * 100;
 Minibatch[ 701- 800]: loss = 0.277473 * 100, metric = 5.01% * 100;
 Minibatch[ 801- 900]: loss = 0.281196 * 100, metric = 5.43% * 100;
 Minibatch[ 901-1000]: loss = 0.276579 * 100, metric = 5.11% * 100;
 Minibatch[1001-1100]: loss = 0.278375 * 100, metric = 5.22% * 100;
 Minibatch[1101-1200]: loss = 0.273816 * 100, metric = 5.26% * 100;
 Minibatch[1201-1300]: loss = 0.271411 * 100, metric = 5.04% * 100;
 Minibatch[1301-1400]: loss = 0.275735 * 100, metric = 4.96% * 100;
 Minibatch[1401-1500]: loss = 0.276175 * 100, metric = 5.23% * 100;
 Minibatch[1501-1600]: loss = 0.282159 * 100, metric = 5.37% * 100;
 Minibatch[1601-1700]: loss = 0.274581 * 100, metric = 5.16% * 100;
 Minibatch[1701-1800]: loss = 0.281728 * 100, metric = 5.02% * 100;
 Minibatch[1801-1900]: loss = 0.294619 * 100, metric = 5.58% * 100;
 Minibatch[1901-2000]: loss = 0.265042 * 100, metric = 4.94% * 100;
Finished Epoch[53 of 200]: [Training] loss = 0.277432 * 2000, metric = 5.17% * 2000 789.106s (  2.5 samples/s);
Finished Evaluation [53]: Minibatch[1-2000]: metric = 12.41% * 2000;
 Minibatch[   1- 100]: loss = 0.275947 * 100, metric = 5.04% * 100;
 Minibatch[ 101- 200]: loss = 0.274688 * 100, metric = 5.19% * 100;
 Minibatch[ 201- 300]: loss = 0.276882 * 100, metric = 5.21% * 100;
 Minibatch[ 301- 400]: loss = 0.268792 * 100, metric = 4.96% * 100;
 Minibatch[ 401- 500]: loss = 0.282351 * 100, metric = 5.24% * 100;
 Minibatch[ 501- 600]: loss = 0.267487 * 100, metric = 4.90% * 100;
 Minibatch[ 601- 700]: loss = 0.273837 * 100, metric = 5.14% * 100;
 Minibatch[ 701- 800]: loss = 0.281269 * 100, metric = 5.23% * 100;
 Minibatch[ 801- 900]: loss = 0.263101 * 100, metric = 4.88% * 100;
 Minibatch[ 901-1000]: loss = 0.279676 * 100, metric = 5.20% * 100;
 Minibatch[1001-1100]: loss = 0.268619 * 100, metric = 4.87% * 100;
 Minibatch[1101-1200]: loss = 0.270026 * 100, metric = 5.00% * 100;
 Minibatch[1201-1300]: loss = 0.273426 * 100, metric = 5.12% * 100;
 Minibatch[1301-1400]: loss = 0.276310 * 100, metric = 5.12% * 100;
 Minibatch[1401-1500]: loss = 0.288079 * 100, metric = 5.39% * 100;
 Minibatch[1501-1600]: loss = 0.287689 * 100, metric = 5.36% * 100;
 Minibatch[1601-1700]: loss = 0.277369 * 100, metric = 5.37% * 100;
 Minibatch[1701-1800]: loss = 0.284040 * 100, metric = 5.40% * 100;
 Minibatch[1801-1900]: loss = 0.283873 * 100, metric = 5.33% * 100;
 Minibatch[1901-2000]: loss = 0.278463 * 100, metric = 5.22% * 100;
Finished Epoch[54 of 200]: [Training] loss = 0.276596 * 2000, metric = 5.16% * 2000 779.068s (  2.6 samples/s);
Finished Evaluation [54]: Minibatch[1-2000]: metric = 12.48% * 2000;
 Minibatch[   1- 100]: loss = 0.287860 * 100, metric = 5.31% * 100;
 Minibatch[ 101- 200]: loss = 0.279146 * 100, metric = 5.18% * 100;
 Minibatch[ 201- 300]: loss = 0.282931 * 100, metric = 5.32% * 100;
 Minibatch[ 301- 400]: loss = 0.268936 * 100, metric = 4.95% * 100;
 Minibatch[ 401- 500]: loss = 0.279587 * 100, metric = 5.33% * 100;
 Minibatch[ 501- 600]: loss = 0.290030 * 100, metric = 5.44% * 100;
 Minibatch[ 601- 700]: loss = 0.284299 * 100, metric = 5.46% * 100;
 Minibatch[ 701- 800]: loss = 0.291838 * 100, metric = 5.59% * 100;
 Minibatch[ 801- 900]: loss = 0.279945 * 100, metric = 5.42% * 100;
 Minibatch[ 901-1000]: loss = 0.272049 * 100, metric = 5.11% * 100;
 Minibatch[1001-1100]: loss = 0.279851 * 100, metric = 5.13% * 100;
 Minibatch[1101-1200]: loss = 0.280501 * 100, metric = 5.27% * 100;
 Minibatch[1201-1300]: loss = 0.273170 * 100, metric = 5.08% * 100;
 Minibatch[1301-1400]: loss = 0.265344 * 100, metric = 4.90% * 100;
 Minibatch[1401-1500]: loss = 0.275805 * 100, metric = 5.20% * 100;
 Minibatch[1501-1600]: loss = 0.273209 * 100, metric = 5.07% * 100;
 Minibatch[1601-1700]: loss = 0.274839 * 100, metric = 5.38% * 100;
 Minibatch[1701-1800]: loss = 0.283482 * 100, metric = 5.22% * 100;
 Minibatch[1801-1900]: loss = 0.268161 * 100, metric = 4.94% * 100;
 Minibatch[1901-2000]: loss = 0.278081 * 100, metric = 5.16% * 100;
Finished Epoch[55 of 200]: [Training] loss = 0.278453 * 2000, metric = 5.22% * 2000 788.833s (  2.5 samples/s);
Finished Evaluation [55]: Minibatch[1-2000]: metric = 12.68% * 2000;
 Minibatch[   1- 100]: loss = 0.281961 * 100, metric = 5.44% * 100;
 Minibatch[ 101- 200]: loss = 0.277987 * 100, metric = 5.04% * 100;
 Minibatch[ 201- 300]: loss = 0.286277 * 100, metric = 5.46% * 100;
 Minibatch[ 301- 400]: loss = 0.279397 * 100, metric = 5.34% * 100;
 Minibatch[ 401- 500]: loss = 0.288961 * 100, metric = 5.54% * 100;
 Minibatch[ 501- 600]: loss = 0.288399 * 100, metric = 5.33% * 100;
 Minibatch[ 601- 700]: loss = 0.282248 * 100, metric = 5.23% * 100;
 Minibatch[ 701- 800]: loss = 0.269323 * 100, metric = 4.99% * 100;
 Minibatch[ 801- 900]: loss = 0.275011 * 100, metric = 5.05% * 100;
 Minibatch[ 901-1000]: loss = 0.279846 * 100, metric = 5.42% * 100;
 Minibatch[1001-1100]: loss = 0.287017 * 100, metric = 5.44% * 100;
 Minibatch[1101-1200]: loss = 0.277671 * 100, metric = 5.17% * 100;
 Minibatch[1201-1300]: loss = 0.271559 * 100, metric = 5.01% * 100;
 Minibatch[1301-1400]: loss = 0.268366 * 100, metric = 4.88% * 100;
 Minibatch[1401-1500]: loss = 0.276745 * 100, metric = 5.15% * 100;
 Minibatch[1501-1600]: loss = 0.268432 * 100, metric = 4.93% * 100;
 Minibatch[1601-1700]: loss = 0.271484 * 100, metric = 4.94% * 100;
 Minibatch[1701-1800]: loss = 0.267481 * 100, metric = 4.97% * 100;
 Minibatch[1801-1900]: loss = 0.274599 * 100, metric = 4.99% * 100;
 Minibatch[1901-2000]: loss = 0.281980 * 100, metric = 5.32% * 100;
Finished Epoch[56 of 200]: [Training] loss = 0.277737 * 2000, metric = 5.18% * 2000 827.778s (  2.4 samples/s);
Finished Evaluation [56]: Minibatch[1-2000]: metric = 11.95% * 2000;
 Minibatch[   1- 100]: loss = 0.273947 * 100, metric = 4.96% * 100;
 Minibatch[ 101- 200]: loss = 0.262432 * 100, metric = 4.86% * 100;
 Minibatch[ 201- 300]: loss = 0.265457 * 100, metric = 4.83% * 100;
 Minibatch[ 301- 400]: loss = 0.274150 * 100, metric = 4.91% * 100;
 Minibatch[ 401- 500]: loss = 0.270074 * 100, metric = 4.93% * 100;
 Minibatch[ 501- 600]: loss = 0.265059 * 100, metric = 4.72% * 100;
 Minibatch[ 601- 700]: loss = 0.275843 * 100, metric = 5.02% * 100;
 Minibatch[ 701- 800]: loss = 0.267755 * 100, metric = 5.01% * 100;
 Minibatch[ 801- 900]: loss = 0.269507 * 100, metric = 4.96% * 100;
 Minibatch[ 901-1000]: loss = 0.271474 * 100, metric = 5.09% * 100;
 Minibatch[1001-1100]: loss = 0.286230 * 100, metric = 5.41% * 100;
 Minibatch[1101-1200]: loss = 0.267279 * 100, metric = 4.91% * 100;
 Minibatch[1201-1300]: loss = 0.269684 * 100, metric = 5.01% * 100;
 Minibatch[1301-1400]: loss = 0.266018 * 100, metric = 4.94% * 100;
 Minibatch[1401-1500]: loss = 0.278748 * 100, metric = 5.14% * 100;
 Minibatch[1501-1600]: loss = 0.268531 * 100, metric = 5.03% * 100;
 Minibatch[1601-1700]: loss = 0.271056 * 100, metric = 5.09% * 100;
 Minibatch[1701-1800]: loss = 0.265951 * 100, metric = 5.06% * 100;
 Minibatch[1801-1900]: loss = 0.280613 * 100, metric = 5.24% * 100;
 Minibatch[1901-2000]: loss = 0.275750 * 100, metric = 5.10% * 100;
Finished Epoch[57 of 200]: [Training] loss = 0.271278 * 2000, metric = 5.01% * 2000 790.808s (  2.5 samples/s);
Finished Evaluation [57]: Minibatch[1-2000]: metric = 12.86% * 2000;
 Minibatch[   1- 100]: loss = 0.270778 * 100, metric = 4.95% * 100;
 Minibatch[ 101- 200]: loss = 0.269415 * 100, metric = 4.96% * 100;
 Minibatch[ 201- 300]: loss = 0.262528 * 100, metric = 4.92% * 100;
 Minibatch[ 301- 400]: loss = 0.273651 * 100, metric = 5.14% * 100;
 Minibatch[ 401- 500]: loss = 0.280357 * 100, metric = 5.37% * 100;
 Minibatch[ 501- 600]: loss = 0.269340 * 100, metric = 5.05% * 100;
 Minibatch[ 601- 700]: loss = 0.267520 * 100, metric = 4.96% * 100;
 Minibatch[ 701- 800]: loss = 0.278381 * 100, metric = 5.14% * 100;
 Minibatch[ 801- 900]: loss = 0.274553 * 100, metric = 5.09% * 100;
 Minibatch[ 901-1000]: loss = 0.271582 * 100, metric = 5.16% * 100;
 Minibatch[1001-1100]: loss = 0.270568 * 100, metric = 5.00% * 100;
 Minibatch[1101-1200]: loss = 0.277352 * 100, metric = 5.19% * 100;
 Minibatch[1201-1300]: loss = 0.262547 * 100, metric = 4.72% * 100;
 Minibatch[1301-1400]: loss = 0.273732 * 100, metric = 5.14% * 100;
 Minibatch[1401-1500]: loss = 0.260048 * 100, metric = 4.79% * 100;
 Minibatch[1501-1600]: loss = 0.276967 * 100, metric = 5.20% * 100;
 Minibatch[1601-1700]: loss = 0.272178 * 100, metric = 5.00% * 100;
 Minibatch[1701-1800]: loss = 0.272453 * 100, metric = 5.11% * 100;
 Minibatch[1801-1900]: loss = 0.269507 * 100, metric = 5.16% * 100;
 Minibatch[1901-2000]: loss = 0.261771 * 100, metric = 4.55% * 100;
Finished Epoch[58 of 200]: [Training] loss = 0.270761 * 2000, metric = 5.03% * 2000 805.095s (  2.5 samples/s);
Finished Evaluation [58]: Minibatch[1-2000]: metric = 12.41% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
