Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 0.889819 * 100, metric = 24.53% * 100;
 Minibatch[ 101- 200]: loss = 0.710502 * 100, metric = 23.71% * 100;
 Minibatch[ 201- 300]: loss = 0.596816 * 100, metric = 22.09% * 100;
 Minibatch[ 301- 400]: loss = 0.562554 * 100, metric = 20.58% * 100;
 Minibatch[ 401- 500]: loss = 0.504560 * 100, metric = 19.35% * 100;
 Minibatch[ 501- 600]: loss = 0.485676 * 100, metric = 17.91% * 100;
 Minibatch[ 601- 700]: loss = 0.455913 * 100, metric = 17.54% * 100;
 Minibatch[ 701- 800]: loss = 0.425043 * 100, metric = 16.20% * 100;
 Minibatch[ 801- 900]: loss = 0.430658 * 100, metric = 16.62% * 100;
 Minibatch[ 901-1000]: loss = 0.444780 * 100, metric = 17.28% * 100;
 Minibatch[1001-1100]: loss = 0.437170 * 100, metric = 16.93% * 100;
 Minibatch[1101-1200]: loss = 0.416255 * 100, metric = 16.09% * 100;
 Minibatch[1201-1300]: loss = 0.426553 * 100, metric = 16.90% * 100;
 Minibatch[1301-1400]: loss = 0.405219 * 100, metric = 15.77% * 100;
 Minibatch[1401-1500]: loss = 0.418028 * 100, metric = 16.21% * 100;
 Minibatch[1501-1600]: loss = 0.390752 * 100, metric = 15.44% * 100;
 Minibatch[1601-1700]: loss = 0.401100 * 100, metric = 15.56% * 100;
 Minibatch[1701-1800]: loss = 0.403940 * 100, metric = 15.71% * 100;
 Minibatch[1801-1900]: loss = 0.406924 * 100, metric = 15.83% * 100;
 Minibatch[1901-2000]: loss = 0.399882 * 100, metric = 15.38% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.480607 * 2000, metric = 17.78% * 2000 929.180s (  2.2 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 24.20% * 2000;
0.5400589170530439
 Minibatch[   1- 100]: loss = 0.389300 * 100, metric = 15.04% * 100;
 Minibatch[ 101- 200]: loss = 0.400610 * 100, metric = 15.82% * 100;
 Minibatch[ 201- 300]: loss = 0.394363 * 100, metric = 14.94% * 100;
 Minibatch[ 301- 400]: loss = 0.393755 * 100, metric = 15.13% * 100;
 Minibatch[ 401- 500]: loss = 0.385382 * 100, metric = 15.03% * 100;
 Minibatch[ 501- 600]: loss = 0.399524 * 100, metric = 14.76% * 100;
 Minibatch[ 601- 700]: loss = 0.373261 * 100, metric = 14.45% * 100;
 Minibatch[ 701- 800]: loss = 0.389521 * 100, metric = 15.38% * 100;
 Minibatch[ 801- 900]: loss = 0.372855 * 100, metric = 14.67% * 100;
 Minibatch[ 901-1000]: loss = 0.362234 * 100, metric = 13.85% * 100;
 Minibatch[1001-1100]: loss = 0.373852 * 100, metric = 14.53% * 100;
 Minibatch[1101-1200]: loss = 0.374775 * 100, metric = 14.46% * 100;
 Minibatch[1201-1300]: loss = 0.366845 * 100, metric = 14.33% * 100;
 Minibatch[1301-1400]: loss = 0.380898 * 100, metric = 14.70% * 100;
 Minibatch[1401-1500]: loss = 0.361757 * 100, metric = 13.88% * 100;
 Minibatch[1501-1600]: loss = 0.356292 * 100, metric = 13.79% * 100;
 Minibatch[1601-1700]: loss = 0.371851 * 100, metric = 14.41% * 100;
 Minibatch[1701-1800]: loss = 0.377237 * 100, metric = 14.49% * 100;
 Minibatch[1801-1900]: loss = 0.363982 * 100, metric = 13.95% * 100;
 Minibatch[1901-2000]: loss = 0.351472 * 100, metric = 13.63% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.376988 * 2000, metric = 14.56% * 2000 866.889s (  2.3 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 21.75% * 2000;
0.47979524471610785
 Minibatch[   1- 100]: loss = 0.358052 * 100, metric = 14.03% * 100;
 Minibatch[ 101- 200]: loss = 0.366721 * 100, metric = 14.13% * 100;
 Minibatch[ 201- 300]: loss = 0.354185 * 100, metric = 13.88% * 100;
 Minibatch[ 301- 400]: loss = 0.361225 * 100, metric = 13.93% * 100;
 Minibatch[ 401- 500]: loss = 0.370424 * 100, metric = 14.53% * 100;
 Minibatch[ 501- 600]: loss = 0.367958 * 100, metric = 14.37% * 100;
 Minibatch[ 601- 700]: loss = 0.374146 * 100, metric = 14.33% * 100;
 Minibatch[ 701- 800]: loss = 0.343854 * 100, metric = 13.23% * 100;
 Minibatch[ 801- 900]: loss = 0.365641 * 100, metric = 13.90% * 100;
 Minibatch[ 901-1000]: loss = 0.345837 * 100, metric = 13.47% * 100;
 Minibatch[1001-1100]: loss = 0.360635 * 100, metric = 14.19% * 100;
 Minibatch[1101-1200]: loss = 0.345620 * 100, metric = 13.61% * 100;
 Minibatch[1201-1300]: loss = 0.344913 * 100, metric = 13.32% * 100;
 Minibatch[1301-1400]: loss = 0.355211 * 100, metric = 13.95% * 100;
 Minibatch[1401-1500]: loss = 0.358232 * 100, metric = 13.97% * 100;
 Minibatch[1501-1600]: loss = 0.344061 * 100, metric = 13.50% * 100;
 Minibatch[1601-1700]: loss = 0.343078 * 100, metric = 13.02% * 100;
 Minibatch[1701-1800]: loss = 0.357223 * 100, metric = 13.78% * 100;
 Minibatch[1801-1900]: loss = 0.341019 * 100, metric = 13.25% * 100;
 Minibatch[1901-2000]: loss = 0.341695 * 100, metric = 13.35% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.354987 * 2000, metric = 13.79% * 2000 859.318s (  2.3 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 20.71% * 2000;
0.47554354506731034
 Minibatch[   1- 100]: loss = 0.360425 * 100, metric = 13.39% * 100;
 Minibatch[ 101- 200]: loss = 0.341080 * 100, metric = 13.25% * 100;
 Minibatch[ 201- 300]: loss = 0.346897 * 100, metric = 13.46% * 100;
 Minibatch[ 301- 400]: loss = 0.324668 * 100, metric = 12.63% * 100;
 Minibatch[ 401- 500]: loss = 0.351461 * 100, metric = 13.51% * 100;
 Minibatch[ 501- 600]: loss = 0.328461 * 100, metric = 12.70% * 100;
 Minibatch[ 601- 700]: loss = 0.332378 * 100, metric = 12.99% * 100;
 Minibatch[ 701- 800]: loss = 0.340490 * 100, metric = 13.28% * 100;
 Minibatch[ 801- 900]: loss = 0.342514 * 100, metric = 13.05% * 100;
 Minibatch[ 901-1000]: loss = 0.345194 * 100, metric = 13.54% * 100;
 Minibatch[1001-1100]: loss = 0.344060 * 100, metric = 13.42% * 100;
 Minibatch[1101-1200]: loss = 0.327367 * 100, metric = 12.80% * 100;
 Minibatch[1201-1300]: loss = 0.325397 * 100, metric = 12.59% * 100;
 Minibatch[1301-1400]: loss = 0.345351 * 100, metric = 13.27% * 100;
 Minibatch[1401-1500]: loss = 0.346584 * 100, metric = 13.41% * 100;
 Minibatch[1501-1600]: loss = 0.320706 * 100, metric = 12.37% * 100;
 Minibatch[1601-1700]: loss = 0.333840 * 100, metric = 13.13% * 100;
 Minibatch[1701-1800]: loss = 0.339923 * 100, metric = 13.30% * 100;
 Minibatch[1801-1900]: loss = 0.337825 * 100, metric = 12.96% * 100;
 Minibatch[1901-2000]: loss = 0.327116 * 100, metric = 12.54% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.338087 * 2000, metric = 13.08% * 2000 850.178s (  2.4 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 21.78% * 2000;
 Minibatch[   1- 100]: loss = 0.341332 * 100, metric = 13.11% * 100;
 Minibatch[ 101- 200]: loss = 0.327616 * 100, metric = 12.86% * 100;
 Minibatch[ 201- 300]: loss = 0.325746 * 100, metric = 12.62% * 100;
 Minibatch[ 301- 400]: loss = 0.343635 * 100, metric = 13.51% * 100;
 Minibatch[ 401- 500]: loss = 0.313513 * 100, metric = 11.92% * 100;
 Minibatch[ 501- 600]: loss = 0.319169 * 100, metric = 12.01% * 100;
 Minibatch[ 601- 700]: loss = 0.319839 * 100, metric = 12.00% * 100;
 Minibatch[ 701- 800]: loss = 0.333744 * 100, metric = 12.60% * 100;
 Minibatch[ 801- 900]: loss = 0.313602 * 100, metric = 11.85% * 100;
 Minibatch[ 901-1000]: loss = 0.322446 * 100, metric = 12.45% * 100;
 Minibatch[1001-1100]: loss = 0.329473 * 100, metric = 12.63% * 100;
 Minibatch[1101-1200]: loss = 0.319559 * 100, metric = 12.33% * 100;
 Minibatch[1201-1300]: loss = 0.324236 * 100, metric = 12.47% * 100;
 Minibatch[1301-1400]: loss = 0.337182 * 100, metric = 13.02% * 100;
 Minibatch[1401-1500]: loss = 0.321346 * 100, metric = 12.28% * 100;
 Minibatch[1501-1600]: loss = 0.328361 * 100, metric = 12.64% * 100;
 Minibatch[1601-1700]: loss = 0.335259 * 100, metric = 12.81% * 100;
 Minibatch[1701-1800]: loss = 0.336908 * 100, metric = 12.92% * 100;
 Minibatch[1801-1900]: loss = 0.333734 * 100, metric = 12.75% * 100;
 Minibatch[1901-2000]: loss = 0.319538 * 100, metric = 12.08% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.327312 * 2000, metric = 12.54% * 2000 845.387s (  2.4 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 19.85% * 2000;
0.46279379992187025
 Minibatch[   1- 100]: loss = 0.317793 * 100, metric = 12.44% * 100;
 Minibatch[ 101- 200]: loss = 0.318720 * 100, metric = 12.41% * 100;
 Minibatch[ 201- 300]: loss = 0.324570 * 100, metric = 12.51% * 100;
 Minibatch[ 301- 400]: loss = 0.323440 * 100, metric = 11.99% * 100;
 Minibatch[ 401- 500]: loss = 0.308413 * 100, metric = 11.85% * 100;
 Minibatch[ 501- 600]: loss = 0.321620 * 100, metric = 12.38% * 100;
 Minibatch[ 601- 700]: loss = 0.311591 * 100, metric = 12.16% * 100;
 Minibatch[ 701- 800]: loss = 0.320541 * 100, metric = 12.36% * 100;
 Minibatch[ 801- 900]: loss = 0.322366 * 100, metric = 12.47% * 100;
 Minibatch[ 901-1000]: loss = 0.318547 * 100, metric = 12.12% * 100;
 Minibatch[1001-1100]: loss = 0.313476 * 100, metric = 11.62% * 100;
 Minibatch[1101-1200]: loss = 0.327058 * 100, metric = 12.43% * 100;
 Minibatch[1201-1300]: loss = 0.330350 * 100, metric = 12.43% * 100;
 Minibatch[1301-1400]: loss = 0.320065 * 100, metric = 12.12% * 100;
 Minibatch[1401-1500]: loss = 0.313435 * 100, metric = 12.16% * 100;
 Minibatch[1501-1600]: loss = 0.307655 * 100, metric = 11.73% * 100;
 Minibatch[1601-1700]: loss = 0.310242 * 100, metric = 11.89% * 100;
 Minibatch[1701-1800]: loss = 0.308600 * 100, metric = 11.94% * 100;
 Minibatch[1801-1900]: loss = 0.316437 * 100, metric = 12.36% * 100;
 Minibatch[1901-2000]: loss = 0.306274 * 100, metric = 11.77% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.317060 * 2000, metric = 12.16% * 2000 843.824s (  2.4 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 21.93% * 2000;
 Minibatch[   1- 100]: loss = 0.308466 * 100, metric = 12.09% * 100;
 Minibatch[ 101- 200]: loss = 0.313683 * 100, metric = 11.70% * 100;
 Minibatch[ 201- 300]: loss = 0.322528 * 100, metric = 12.00% * 100;
 Minibatch[ 301- 400]: loss = 0.307937 * 100, metric = 11.71% * 100;
 Minibatch[ 401- 500]: loss = 0.318742 * 100, metric = 12.07% * 100;
 Minibatch[ 501- 600]: loss = 0.295197 * 100, metric = 11.28% * 100;
 Minibatch[ 601- 700]: loss = 0.307926 * 100, metric = 11.55% * 100;
 Minibatch[ 701- 800]: loss = 0.306601 * 100, metric = 11.62% * 100;
 Minibatch[ 801- 900]: loss = 0.315536 * 100, metric = 12.12% * 100;
 Minibatch[ 901-1000]: loss = 0.306112 * 100, metric = 11.50% * 100;
 Minibatch[1001-1100]: loss = 0.317704 * 100, metric = 11.96% * 100;
 Minibatch[1101-1200]: loss = 0.302495 * 100, metric = 11.53% * 100;
 Minibatch[1201-1300]: loss = 0.308557 * 100, metric = 11.71% * 100;
 Minibatch[1301-1400]: loss = 0.301656 * 100, metric = 11.55% * 100;
 Minibatch[1401-1500]: loss = 0.298493 * 100, metric = 11.19% * 100;
 Minibatch[1501-1600]: loss = 0.307046 * 100, metric = 11.68% * 100;
 Minibatch[1601-1700]: loss = 0.309810 * 100, metric = 11.91% * 100;
 Minibatch[1701-1800]: loss = 0.301675 * 100, metric = 11.30% * 100;
 Minibatch[1801-1900]: loss = 0.309794 * 100, metric = 11.56% * 100;
 Minibatch[1901-2000]: loss = 0.314036 * 100, metric = 12.01% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.308700 * 2000, metric = 11.70% * 2000 836.134s (  2.4 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.78% * 2000;
0.4357514567412436
 Minibatch[   1- 100]: loss = 0.308090 * 100, metric = 11.71% * 100;
 Minibatch[ 101- 200]: loss = 0.304776 * 100, metric = 11.54% * 100;
 Minibatch[ 201- 300]: loss = 0.292710 * 100, metric = 11.30% * 100;
 Minibatch[ 301- 400]: loss = 0.295047 * 100, metric = 11.38% * 100;
 Minibatch[ 401- 500]: loss = 0.311128 * 100, metric = 11.99% * 100;
 Minibatch[ 501- 600]: loss = 0.323104 * 100, metric = 12.35% * 100;
 Minibatch[ 601- 700]: loss = 0.291654 * 100, metric = 11.35% * 100;
 Minibatch[ 701- 800]: loss = 0.304799 * 100, metric = 11.36% * 100;
 Minibatch[ 801- 900]: loss = 0.291267 * 100, metric = 10.83% * 100;
 Minibatch[ 901-1000]: loss = 0.284102 * 100, metric = 10.91% * 100;
 Minibatch[1001-1100]: loss = 0.296728 * 100, metric = 11.40% * 100;
 Minibatch[1101-1200]: loss = 0.291323 * 100, metric = 10.81% * 100;
 Minibatch[1201-1300]: loss = 0.303345 * 100, metric = 11.45% * 100;
 Minibatch[1301-1400]: loss = 0.303167 * 100, metric = 11.72% * 100;
 Minibatch[1401-1500]: loss = 0.301440 * 100, metric = 11.43% * 100;
 Minibatch[1501-1600]: loss = 0.306141 * 100, metric = 11.67% * 100;
 Minibatch[1601-1700]: loss = 0.299531 * 100, metric = 11.49% * 100;
 Minibatch[1701-1800]: loss = 0.297778 * 100, metric = 11.21% * 100;
 Minibatch[1801-1900]: loss = 0.297714 * 100, metric = 11.45% * 100;
 Minibatch[1901-2000]: loss = 0.290219 * 100, metric = 11.08% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.299703 * 2000, metric = 11.42% * 2000 832.023s (  2.4 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 17.60% * 2000;
0.4154764946997166
 Minibatch[   1- 100]: loss = 0.279944 * 100, metric = 10.56% * 100;
 Minibatch[ 101- 200]: loss = 0.305972 * 100, metric = 11.49% * 100;
 Minibatch[ 201- 300]: loss = 0.288075 * 100, metric = 10.90% * 100;
 Minibatch[ 301- 400]: loss = 0.305277 * 100, metric = 11.54% * 100;
 Minibatch[ 401- 500]: loss = 0.293434 * 100, metric = 11.05% * 100;
 Minibatch[ 501- 600]: loss = 0.291749 * 100, metric = 11.04% * 100;
 Minibatch[ 601- 700]: loss = 0.290914 * 100, metric = 11.03% * 100;
 Minibatch[ 701- 800]: loss = 0.277256 * 100, metric = 10.67% * 100;
 Minibatch[ 801- 900]: loss = 0.280482 * 100, metric = 10.75% * 100;
 Minibatch[ 901-1000]: loss = 0.294968 * 100, metric = 11.26% * 100;
 Minibatch[1001-1100]: loss = 0.270114 * 100, metric = 10.40% * 100;
 Minibatch[1101-1200]: loss = 0.290658 * 100, metric = 11.12% * 100;
 Minibatch[1201-1300]: loss = 0.285500 * 100, metric = 10.66% * 100;
 Minibatch[1301-1400]: loss = 0.280226 * 100, metric = 10.29% * 100;
 Minibatch[1401-1500]: loss = 0.298294 * 100, metric = 11.30% * 100;
 Minibatch[1501-1600]: loss = 0.285651 * 100, metric = 10.89% * 100;
 Minibatch[1601-1700]: loss = 0.292930 * 100, metric = 11.20% * 100;
 Minibatch[1701-1800]: loss = 0.282505 * 100, metric = 10.57% * 100;
 Minibatch[1801-1900]: loss = 0.284228 * 100, metric = 10.76% * 100;
 Minibatch[1901-2000]: loss = 0.289672 * 100, metric = 11.01% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.288393 * 2000, metric = 10.92% * 2000 841.510s (  2.4 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 16.82% * 2000;
0.4034046505019069
 Minibatch[   1- 100]: loss = 0.304224 * 100, metric = 11.92% * 100;
 Minibatch[ 101- 200]: loss = 0.280715 * 100, metric = 10.66% * 100;
 Minibatch[ 201- 300]: loss = 0.282887 * 100, metric = 10.72% * 100;
 Minibatch[ 301- 400]: loss = 0.274141 * 100, metric = 10.29% * 100;
 Minibatch[ 401- 500]: loss = 0.288178 * 100, metric = 10.87% * 100;
 Minibatch[ 501- 600]: loss = 0.269460 * 100, metric = 10.11% * 100;
 Minibatch[ 601- 700]: loss = 0.265372 * 100, metric = 9.75% * 100;
 Minibatch[ 701- 800]: loss = 0.264650 * 100, metric = 9.82% * 100;
 Minibatch[ 801- 900]: loss = 0.275981 * 100, metric = 10.50% * 100;
 Minibatch[ 901-1000]: loss = 0.285793 * 100, metric = 10.70% * 100;
 Minibatch[1001-1100]: loss = 0.283913 * 100, metric = 10.73% * 100;
 Minibatch[1101-1200]: loss = 0.277300 * 100, metric = 10.36% * 100;
 Minibatch[1201-1300]: loss = 0.277472 * 100, metric = 10.32% * 100;
 Minibatch[1301-1400]: loss = 0.278717 * 100, metric = 10.38% * 100;
 Minibatch[1401-1500]: loss = 0.267409 * 100, metric = 10.03% * 100;
 Minibatch[1501-1600]: loss = 0.277308 * 100, metric = 10.43% * 100;
 Minibatch[1601-1700]: loss = 0.274772 * 100, metric = 10.26% * 100;
 Minibatch[1701-1800]: loss = 0.278441 * 100, metric = 10.24% * 100;
 Minibatch[1801-1900]: loss = 0.277863 * 100, metric = 10.28% * 100;
 Minibatch[1901-2000]: loss = 0.265932 * 100, metric = 9.79% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.277526 * 2000, metric = 10.41% * 2000 837.936s (  2.4 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 16.79% * 2000;
 Minibatch[   1- 100]: loss = 0.258956 * 100, metric = 9.69% * 100;
 Minibatch[ 101- 200]: loss = 0.268944 * 100, metric = 10.08% * 100;
 Minibatch[ 201- 300]: loss = 0.277345 * 100, metric = 10.60% * 100;
 Minibatch[ 301- 400]: loss = 0.273057 * 100, metric = 10.35% * 100;
 Minibatch[ 401- 500]: loss = 0.269967 * 100, metric = 10.09% * 100;
 Minibatch[ 501- 600]: loss = 0.272335 * 100, metric = 10.18% * 100;
 Minibatch[ 601- 700]: loss = 0.269723 * 100, metric = 10.12% * 100;
 Minibatch[ 701- 800]: loss = 0.276918 * 100, metric = 10.36% * 100;
 Minibatch[ 801- 900]: loss = 0.270112 * 100, metric = 9.87% * 100;
 Minibatch[ 901-1000]: loss = 0.276849 * 100, metric = 10.29% * 100;
 Minibatch[1001-1100]: loss = 0.274592 * 100, metric = 10.08% * 100;
 Minibatch[1101-1200]: loss = 0.276201 * 100, metric = 10.20% * 100;
 Minibatch[1201-1300]: loss = 0.265839 * 100, metric = 9.81% * 100;
 Minibatch[1301-1400]: loss = 0.259532 * 100, metric = 9.85% * 100;
 Minibatch[1401-1500]: loss = 0.274784 * 100, metric = 10.27% * 100;
 Minibatch[1501-1600]: loss = 0.262698 * 100, metric = 9.86% * 100;
 Minibatch[1601-1700]: loss = 0.262662 * 100, metric = 9.82% * 100;
 Minibatch[1701-1800]: loss = 0.277003 * 100, metric = 10.33% * 100;
 Minibatch[1801-1900]: loss = 0.268112 * 100, metric = 9.75% * 100;
 Minibatch[1901-2000]: loss = 0.268795 * 100, metric = 10.05% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.270221 * 2000, metric = 10.08% * 2000 829.070s (  2.4 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 17.54% * 2000;
 Minibatch[   1- 100]: loss = 0.259426 * 100, metric = 9.81% * 100;
 Minibatch[ 101- 200]: loss = 0.256837 * 100, metric = 9.58% * 100;
 Minibatch[ 201- 300]: loss = 0.261923 * 100, metric = 9.89% * 100;
 Minibatch[ 301- 400]: loss = 0.284604 * 100, metric = 10.66% * 100;
 Minibatch[ 401- 500]: loss = 0.257561 * 100, metric = 9.56% * 100;
 Minibatch[ 501- 600]: loss = 0.257330 * 100, metric = 9.54% * 100;
 Minibatch[ 601- 700]: loss = 0.253834 * 100, metric = 9.38% * 100;
 Minibatch[ 701- 800]: loss = 0.261280 * 100, metric = 9.64% * 100;
 Minibatch[ 801- 900]: loss = 0.257823 * 100, metric = 9.33% * 100;
 Minibatch[ 901-1000]: loss = 0.265605 * 100, metric = 9.92% * 100;
 Minibatch[1001-1100]: loss = 0.267067 * 100, metric = 9.91% * 100;
 Minibatch[1101-1200]: loss = 0.269193 * 100, metric = 10.03% * 100;
 Minibatch[1201-1300]: loss = 0.273077 * 100, metric = 10.18% * 100;
 Minibatch[1301-1400]: loss = 0.258277 * 100, metric = 9.55% * 100;
 Minibatch[1401-1500]: loss = 0.265979 * 100, metric = 10.04% * 100;
 Minibatch[1501-1600]: loss = 0.251637 * 100, metric = 9.55% * 100;
 Minibatch[1601-1700]: loss = 0.269578 * 100, metric = 10.31% * 100;
 Minibatch[1701-1800]: loss = 0.255667 * 100, metric = 9.57% * 100;
 Minibatch[1801-1900]: loss = 0.259167 * 100, metric = 9.76% * 100;
 Minibatch[1901-2000]: loss = 0.263969 * 100, metric = 9.77% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.262492 * 2000, metric = 9.80% * 2000 843.429s (  2.4 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 17.21% * 2000;
 Minibatch[   1- 100]: loss = 0.266378 * 100, metric = 9.92% * 100;
 Minibatch[ 101- 200]: loss = 0.264390 * 100, metric = 9.96% * 100;
 Minibatch[ 201- 300]: loss = 0.261835 * 100, metric = 9.68% * 100;
 Minibatch[ 301- 400]: loss = 0.263322 * 100, metric = 9.69% * 100;
 Minibatch[ 401- 500]: loss = 0.274394 * 100, metric = 10.48% * 100;
 Minibatch[ 501- 600]: loss = 0.271802 * 100, metric = 10.28% * 100;
 Minibatch[ 601- 700]: loss = 0.257989 * 100, metric = 9.37% * 100;
 Minibatch[ 701- 800]: loss = 0.249901 * 100, metric = 9.39% * 100;
 Minibatch[ 801- 900]: loss = 0.258549 * 100, metric = 9.67% * 100;
 Minibatch[ 901-1000]: loss = 0.266227 * 100, metric = 10.03% * 100;
 Minibatch[1001-1100]: loss = 0.267878 * 100, metric = 10.18% * 100;
 Minibatch[1101-1200]: loss = 0.251045 * 100, metric = 9.43% * 100;
 Minibatch[1201-1300]: loss = 0.257260 * 100, metric = 9.67% * 100;
 Minibatch[1301-1400]: loss = 0.256084 * 100, metric = 9.61% * 100;
 Minibatch[1401-1500]: loss = 0.252379 * 100, metric = 9.42% * 100;
 Minibatch[1501-1600]: loss = 0.248026 * 100, metric = 9.15% * 100;
 Minibatch[1601-1700]: loss = 0.248723 * 100, metric = 9.38% * 100;
 Minibatch[1701-1800]: loss = 0.255978 * 100, metric = 9.57% * 100;
 Minibatch[1801-1900]: loss = 0.245166 * 100, metric = 9.05% * 100;
 Minibatch[1901-2000]: loss = 0.254811 * 100, metric = 9.52% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.258607 * 2000, metric = 9.67% * 2000 1141.231s (  1.8 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 18.76% * 2000;
 Minibatch[   1- 100]: loss = 0.251988 * 100, metric = 9.16% * 100;
 Minibatch[ 101- 200]: loss = 0.245523 * 100, metric = 9.22% * 100;
 Minibatch[ 201- 300]: loss = 0.260301 * 100, metric = 9.71% * 100;
 Minibatch[ 301- 400]: loss = 0.254015 * 100, metric = 9.68% * 100;
 Minibatch[ 401- 500]: loss = 0.253794 * 100, metric = 9.45% * 100;
 Minibatch[ 501- 600]: loss = 0.253419 * 100, metric = 9.71% * 100;
 Minibatch[ 601- 700]: loss = 0.251974 * 100, metric = 9.34% * 100;
 Minibatch[ 701- 800]: loss = 0.265000 * 100, metric = 9.97% * 100;
 Minibatch[ 801- 900]: loss = 0.269021 * 100, metric = 10.09% * 100;
 Minibatch[ 901-1000]: loss = 0.252152 * 100, metric = 9.46% * 100;
 Minibatch[1001-1100]: loss = 0.260657 * 100, metric = 9.65% * 100;
 Minibatch[1101-1200]: loss = 0.250332 * 100, metric = 9.46% * 100;
 Minibatch[1201-1300]: loss = 0.240917 * 100, metric = 8.88% * 100;
 Minibatch[1301-1400]: loss = 0.258035 * 100, metric = 9.85% * 100;
 Minibatch[1401-1500]: loss = 0.250868 * 100, metric = 9.39% * 100;
 Minibatch[1501-1600]: loss = 0.245699 * 100, metric = 9.41% * 100;
 Minibatch[1601-1700]: loss = 0.248105 * 100, metric = 9.08% * 100;
 Minibatch[1701-1800]: loss = 0.241552 * 100, metric = 9.06% * 100;
 Minibatch[1801-1900]: loss = 0.246208 * 100, metric = 9.42% * 100;
 Minibatch[1901-2000]: loss = 0.249134 * 100, metric = 9.19% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.252435 * 2000, metric = 9.46% * 2000 1085.508s (  1.8 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 17.88% * 2000;
 Minibatch[   1- 100]: loss = 0.244621 * 100, metric = 9.04% * 100;
 Minibatch[ 101- 200]: loss = 0.250983 * 100, metric = 9.46% * 100;
 Minibatch[ 201- 300]: loss = 0.251024 * 100, metric = 9.39% * 100;
 Minibatch[ 301- 400]: loss = 0.242300 * 100, metric = 9.04% * 100;
 Minibatch[ 401- 500]: loss = 0.243993 * 100, metric = 9.10% * 100;
 Minibatch[ 501- 600]: loss = 0.240296 * 100, metric = 8.99% * 100;
 Minibatch[ 601- 700]: loss = 0.232811 * 100, metric = 8.68% * 100;
 Minibatch[ 701- 800]: loss = 0.253604 * 100, metric = 9.46% * 100;
 Minibatch[ 801- 900]: loss = 0.264890 * 100, metric = 9.80% * 100;
 Minibatch[ 901-1000]: loss = 0.241427 * 100, metric = 9.19% * 100;
 Minibatch[1001-1100]: loss = 0.253647 * 100, metric = 9.48% * 100;
 Minibatch[1101-1200]: loss = 0.250247 * 100, metric = 9.28% * 100;
 Minibatch[1201-1300]: loss = 0.240256 * 100, metric = 8.96% * 100;
 Minibatch[1301-1400]: loss = 0.261916 * 100, metric = 9.79% * 100;
 Minibatch[1401-1500]: loss = 0.233244 * 100, metric = 8.61% * 100;
 Minibatch[1501-1600]: loss = 0.242039 * 100, metric = 9.17% * 100;
 Minibatch[1601-1700]: loss = 0.246127 * 100, metric = 9.07% * 100;
 Minibatch[1701-1800]: loss = 0.232918 * 100, metric = 8.50% * 100;
 Minibatch[1801-1900]: loss = 0.244103 * 100, metric = 9.05% * 100;
 Minibatch[1901-2000]: loss = 0.242851 * 100, metric = 9.15% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.245665 * 2000, metric = 9.16% * 2000 906.895s (  2.2 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 15.47% * 2000;
0.4017110998779535
 Minibatch[   1- 100]: loss = 0.253479 * 100, metric = 9.70% * 100;
 Minibatch[ 101- 200]: loss = 0.246481 * 100, metric = 9.16% * 100;
 Minibatch[ 201- 300]: loss = 0.242680 * 100, metric = 8.96% * 100;
 Minibatch[ 301- 400]: loss = 0.245108 * 100, metric = 9.06% * 100;
 Minibatch[ 401- 500]: loss = 0.228894 * 100, metric = 8.33% * 100;
 Minibatch[ 501- 600]: loss = 0.241646 * 100, metric = 8.65% * 100;
 Minibatch[ 601- 700]: loss = 0.242077 * 100, metric = 9.07% * 100;
 Minibatch[ 701- 800]: loss = 0.235827 * 100, metric = 8.70% * 100;
 Minibatch[ 801- 900]: loss = 0.233905 * 100, metric = 8.78% * 100;
 Minibatch[ 901-1000]: loss = 0.245499 * 100, metric = 9.39% * 100;
 Minibatch[1001-1100]: loss = 0.229483 * 100, metric = 8.53% * 100;
 Minibatch[1101-1200]: loss = 0.234851 * 100, metric = 8.81% * 100;
 Minibatch[1201-1300]: loss = 0.227585 * 100, metric = 8.51% * 100;
 Minibatch[1301-1400]: loss = 0.239546 * 100, metric = 9.03% * 100;
 Minibatch[1401-1500]: loss = 0.233327 * 100, metric = 8.79% * 100;
 Minibatch[1501-1600]: loss = 0.234651 * 100, metric = 8.91% * 100;
 Minibatch[1601-1700]: loss = 0.239608 * 100, metric = 9.16% * 100;
 Minibatch[1701-1800]: loss = 0.247747 * 100, metric = 9.37% * 100;
 Minibatch[1801-1900]: loss = 0.245278 * 100, metric = 9.20% * 100;
 Minibatch[1901-2000]: loss = 0.234145 * 100, metric = 9.01% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.239091 * 2000, metric = 8.96% * 2000 843.789s (  2.4 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 15.36% * 2000;
0.3972008674442768
 Minibatch[   1- 100]: loss = 0.228172 * 100, metric = 8.63% * 100;
 Minibatch[ 101- 200]: loss = 0.241147 * 100, metric = 9.04% * 100;
 Minibatch[ 201- 300]: loss = 0.243383 * 100, metric = 9.00% * 100;
 Minibatch[ 301- 400]: loss = 0.229216 * 100, metric = 8.55% * 100;
 Minibatch[ 401- 500]: loss = 0.239113 * 100, metric = 8.97% * 100;
 Minibatch[ 501- 600]: loss = 0.228769 * 100, metric = 8.46% * 100;
 Minibatch[ 601- 700]: loss = 0.220734 * 100, metric = 8.12% * 100;
 Minibatch[ 701- 800]: loss = 0.234105 * 100, metric = 8.61% * 100;
 Minibatch[ 801- 900]: loss = 0.244000 * 100, metric = 9.21% * 100;
 Minibatch[ 901-1000]: loss = 0.227209 * 100, metric = 8.37% * 100;
 Minibatch[1001-1100]: loss = 0.230468 * 100, metric = 8.37% * 100;
 Minibatch[1101-1200]: loss = 0.246186 * 100, metric = 9.19% * 100;
 Minibatch[1201-1300]: loss = 0.239654 * 100, metric = 9.07% * 100;
 Minibatch[1301-1400]: loss = 0.226898 * 100, metric = 8.65% * 100;
 Minibatch[1401-1500]: loss = 0.235114 * 100, metric = 8.83% * 100;
 Minibatch[1501-1600]: loss = 0.233132 * 100, metric = 8.74% * 100;
 Minibatch[1601-1700]: loss = 0.235902 * 100, metric = 8.82% * 100;
 Minibatch[1701-1800]: loss = 0.226552 * 100, metric = 8.47% * 100;
 Minibatch[1801-1900]: loss = 0.241483 * 100, metric = 9.25% * 100;
 Minibatch[1901-2000]: loss = 0.247179 * 100, metric = 9.19% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.234921 * 2000, metric = 8.78% * 2000 792.067s (  2.5 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 15.10% * 2000;
0.3919892558194697
 Minibatch[   1- 100]: loss = 0.221119 * 100, metric = 8.37% * 100;
 Minibatch[ 101- 200]: loss = 0.235899 * 100, metric = 8.99% * 100;
 Minibatch[ 201- 300]: loss = 0.224779 * 100, metric = 8.57% * 100;
 Minibatch[ 301- 400]: loss = 0.231626 * 100, metric = 8.64% * 100;
 Minibatch[ 401- 500]: loss = 0.218559 * 100, metric = 8.23% * 100;
 Minibatch[ 501- 600]: loss = 0.222743 * 100, metric = 8.17% * 100;
 Minibatch[ 601- 700]: loss = 0.232831 * 100, metric = 8.76% * 100;
 Minibatch[ 701- 800]: loss = 0.219871 * 100, metric = 8.30% * 100;
 Minibatch[ 801- 900]: loss = 0.232264 * 100, metric = 8.50% * 100;
 Minibatch[ 901-1000]: loss = 0.228604 * 100, metric = 8.60% * 100;
 Minibatch[1001-1100]: loss = 0.240224 * 100, metric = 9.02% * 100;
 Minibatch[1101-1200]: loss = 0.234327 * 100, metric = 8.86% * 100;
 Minibatch[1201-1300]: loss = 0.240737 * 100, metric = 9.12% * 100;
 Minibatch[1301-1400]: loss = 0.243132 * 100, metric = 9.08% * 100;
 Minibatch[1401-1500]: loss = 0.218230 * 100, metric = 8.09% * 100;
 Minibatch[1501-1600]: loss = 0.233035 * 100, metric = 8.77% * 100;
 Minibatch[1601-1700]: loss = 0.216055 * 100, metric = 7.84% * 100;
 Minibatch[1701-1800]: loss = 0.216456 * 100, metric = 8.12% * 100;
 Minibatch[1801-1900]: loss = 0.215250 * 100, metric = 8.11% * 100;
 Minibatch[1901-2000]: loss = 0.218705 * 100, metric = 8.14% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.227222 * 2000, metric = 8.51% * 2000 780.675s (  2.6 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 15.89% * 2000;
 Minibatch[   1- 100]: loss = 0.232414 * 100, metric = 8.80% * 100;
 Minibatch[ 101- 200]: loss = 0.238608 * 100, metric = 8.84% * 100;
 Minibatch[ 201- 300]: loss = 0.220462 * 100, metric = 8.13% * 100;
 Minibatch[ 301- 400]: loss = 0.230334 * 100, metric = 8.60% * 100;
 Minibatch[ 401- 500]: loss = 0.228452 * 100, metric = 8.40% * 100;
 Minibatch[ 501- 600]: loss = 0.215138 * 100, metric = 7.98% * 100;
 Minibatch[ 601- 700]: loss = 0.224097 * 100, metric = 8.29% * 100;
 Minibatch[ 701- 800]: loss = 0.218109 * 100, metric = 7.95% * 100;
 Minibatch[ 801- 900]: loss = 0.243346 * 100, metric = 9.16% * 100;
 Minibatch[ 901-1000]: loss = 0.215570 * 100, metric = 8.11% * 100;
 Minibatch[1001-1100]: loss = 0.229781 * 100, metric = 8.62% * 100;
 Minibatch[1101-1200]: loss = 0.226061 * 100, metric = 8.54% * 100;
 Minibatch[1201-1300]: loss = 0.223734 * 100, metric = 8.55% * 100;
 Minibatch[1301-1400]: loss = 0.220962 * 100, metric = 8.26% * 100;
 Minibatch[1401-1500]: loss = 0.229212 * 100, metric = 8.81% * 100;
 Minibatch[1501-1600]: loss = 0.232481 * 100, metric = 8.70% * 100;
 Minibatch[1601-1700]: loss = 0.224226 * 100, metric = 8.53% * 100;
 Minibatch[1701-1800]: loss = 0.215968 * 100, metric = 8.13% * 100;
 Minibatch[1801-1900]: loss = 0.217237 * 100, metric = 8.13% * 100;
 Minibatch[1901-2000]: loss = 0.216091 * 100, metric = 7.94% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.225114 * 2000, metric = 8.42% * 2000 779.870s (  2.6 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 15.84% * 2000;
 Minibatch[   1- 100]: loss = 0.219741 * 100, metric = 8.08% * 100;
 Minibatch[ 101- 200]: loss = 0.217617 * 100, metric = 8.16% * 100;
 Minibatch[ 201- 300]: loss = 0.216031 * 100, metric = 8.10% * 100;
 Minibatch[ 301- 400]: loss = 0.230843 * 100, metric = 8.36% * 100;
 Minibatch[ 401- 500]: loss = 0.221998 * 100, metric = 8.40% * 100;
 Minibatch[ 501- 600]: loss = 0.226767 * 100, metric = 8.53% * 100;
 Minibatch[ 601- 700]: loss = 0.228799 * 100, metric = 8.63% * 100;
 Minibatch[ 701- 800]: loss = 0.220973 * 100, metric = 8.29% * 100;
 Minibatch[ 801- 900]: loss = 0.225695 * 100, metric = 8.37% * 100;
 Minibatch[ 901-1000]: loss = 0.228891 * 100, metric = 8.51% * 100;
 Minibatch[1001-1100]: loss = 0.211480 * 100, metric = 7.97% * 100;
 Minibatch[1101-1200]: loss = 0.222919 * 100, metric = 8.39% * 100;
 Minibatch[1201-1300]: loss = 0.228932 * 100, metric = 8.43% * 100;
 Minibatch[1301-1400]: loss = 0.227791 * 100, metric = 8.47% * 100;
 Minibatch[1401-1500]: loss = 0.222595 * 100, metric = 8.49% * 100;
 Minibatch[1501-1600]: loss = 0.233463 * 100, metric = 8.54% * 100;
 Minibatch[1601-1700]: loss = 0.220101 * 100, metric = 8.22% * 100;
 Minibatch[1701-1800]: loss = 0.229456 * 100, metric = 8.70% * 100;
 Minibatch[1801-1900]: loss = 0.221276 * 100, metric = 8.38% * 100;
 Minibatch[1901-2000]: loss = 0.218955 * 100, metric = 8.28% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.223716 * 2000, metric = 8.36% * 2000 976.020s (  2.0 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 15.90% * 2000;
 Minibatch[   1- 100]: loss = 0.221645 * 100, metric = 8.30% * 100;
 Minibatch[ 101- 200]: loss = 0.219953 * 100, metric = 8.34% * 100;
 Minibatch[ 201- 300]: loss = 0.221213 * 100, metric = 8.30% * 100;
 Minibatch[ 301- 400]: loss = 0.225309 * 100, metric = 8.48% * 100;
 Minibatch[ 401- 500]: loss = 0.215476 * 100, metric = 8.29% * 100;
 Minibatch[ 501- 600]: loss = 0.214390 * 100, metric = 8.15% * 100;
 Minibatch[ 601- 700]: loss = 0.217976 * 100, metric = 8.09% * 100;
 Minibatch[ 701- 800]: loss = 0.199588 * 100, metric = 7.46% * 100;
 Minibatch[ 801- 900]: loss = 0.222223 * 100, metric = 8.32% * 100;
 Minibatch[ 901-1000]: loss = 0.211500 * 100, metric = 8.04% * 100;
 Minibatch[1001-1100]: loss = 0.215004 * 100, metric = 8.03% * 100;
 Minibatch[1101-1200]: loss = 0.211810 * 100, metric = 7.63% * 100;
 Minibatch[1201-1300]: loss = 0.215802 * 100, metric = 8.00% * 100;
 Minibatch[1301-1400]: loss = 0.203662 * 100, metric = 7.52% * 100;
 Minibatch[1401-1500]: loss = 0.218165 * 100, metric = 8.06% * 100;
 Minibatch[1501-1600]: loss = 0.221291 * 100, metric = 8.27% * 100;
 Minibatch[1601-1700]: loss = 0.216459 * 100, metric = 8.11% * 100;
 Minibatch[1701-1800]: loss = 0.209822 * 100, metric = 7.73% * 100;
 Minibatch[1801-1900]: loss = 0.227872 * 100, metric = 8.54% * 100;
 Minibatch[1901-2000]: loss = 0.210940 * 100, metric = 7.77% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.216005 * 2000, metric = 8.07% * 2000 773.700s (  2.6 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 14.49% * 2000;
 Minibatch[   1- 100]: loss = 0.221698 * 100, metric = 8.25% * 100;
 Minibatch[ 101- 200]: loss = 0.212516 * 100, metric = 7.72% * 100;
 Minibatch[ 201- 300]: loss = 0.221400 * 100, metric = 8.37% * 100;
 Minibatch[ 301- 400]: loss = 0.213108 * 100, metric = 8.00% * 100;
 Minibatch[ 401- 500]: loss = 0.214385 * 100, metric = 7.96% * 100;
 Minibatch[ 501- 600]: loss = 0.220416 * 100, metric = 8.36% * 100;
 Minibatch[ 601- 700]: loss = 0.205435 * 100, metric = 7.57% * 100;
 Minibatch[ 701- 800]: loss = 0.212495 * 100, metric = 8.09% * 100;
 Minibatch[ 801- 900]: loss = 0.214586 * 100, metric = 7.88% * 100;
 Minibatch[ 901-1000]: loss = 0.220452 * 100, metric = 8.27% * 100;
 Minibatch[1001-1100]: loss = 0.204677 * 100, metric = 7.44% * 100;
 Minibatch[1101-1200]: loss = 0.193606 * 100, metric = 7.23% * 100;
 Minibatch[1201-1300]: loss = 0.215456 * 100, metric = 8.19% * 100;
 Minibatch[1301-1400]: loss = 0.218418 * 100, metric = 8.18% * 100;
 Minibatch[1401-1500]: loss = 0.206324 * 100, metric = 7.60% * 100;
 Minibatch[1501-1600]: loss = 0.203941 * 100, metric = 7.51% * 100;
 Minibatch[1601-1700]: loss = 0.209163 * 100, metric = 7.86% * 100;
 Minibatch[1701-1800]: loss = 0.207272 * 100, metric = 7.71% * 100;
 Minibatch[1801-1900]: loss = 0.210197 * 100, metric = 7.82% * 100;
 Minibatch[1901-2000]: loss = 0.206064 * 100, metric = 7.56% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.211580 * 2000, metric = 7.88% * 2000 780.236s (  2.6 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 15.45% * 2000;
 Minibatch[   1- 100]: loss = 0.213908 * 100, metric = 7.92% * 100;
 Minibatch[ 101- 200]: loss = 0.212463 * 100, metric = 7.81% * 100;
 Minibatch[ 201- 300]: loss = 0.203944 * 100, metric = 7.67% * 100;
 Minibatch[ 301- 400]: loss = 0.211169 * 100, metric = 7.92% * 100;
 Minibatch[ 401- 500]: loss = 0.218602 * 100, metric = 8.09% * 100;
 Minibatch[ 501- 600]: loss = 0.203359 * 100, metric = 7.62% * 100;
 Minibatch[ 601- 700]: loss = 0.208254 * 100, metric = 7.51% * 100;
 Minibatch[ 701- 800]: loss = 0.198742 * 100, metric = 7.43% * 100;
 Minibatch[ 801- 900]: loss = 0.202450 * 100, metric = 7.68% * 100;
 Minibatch[ 901-1000]: loss = 0.210092 * 100, metric = 7.83% * 100;
 Minibatch[1001-1100]: loss = 0.200888 * 100, metric = 7.38% * 100;
 Minibatch[1101-1200]: loss = 0.213353 * 100, metric = 8.01% * 100;
 Minibatch[1201-1300]: loss = 0.203493 * 100, metric = 7.72% * 100;
 Minibatch[1301-1400]: loss = 0.209962 * 100, metric = 7.91% * 100;
 Minibatch[1401-1500]: loss = 0.195312 * 100, metric = 7.13% * 100;
 Minibatch[1501-1600]: loss = 0.204420 * 100, metric = 7.68% * 100;
 Minibatch[1601-1700]: loss = 0.198658 * 100, metric = 7.39% * 100;
 Minibatch[1701-1800]: loss = 0.207845 * 100, metric = 7.65% * 100;
 Minibatch[1801-1900]: loss = 0.211887 * 100, metric = 7.93% * 100;
 Minibatch[1901-2000]: loss = 0.207408 * 100, metric = 7.72% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.206810 * 2000, metric = 7.70% * 2000 776.580s (  2.6 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 15.29% * 2000;
 Minibatch[   1- 100]: loss = 0.198887 * 100, metric = 7.48% * 100;
 Minibatch[ 101- 200]: loss = 0.208040 * 100, metric = 7.84% * 100;
 Minibatch[ 201- 300]: loss = 0.198693 * 100, metric = 7.49% * 100;
 Minibatch[ 301- 400]: loss = 0.199649 * 100, metric = 7.58% * 100;
 Minibatch[ 401- 500]: loss = 0.206243 * 100, metric = 7.69% * 100;
 Minibatch[ 501- 600]: loss = 0.200569 * 100, metric = 7.59% * 100;
 Minibatch[ 601- 700]: loss = 0.204435 * 100, metric = 7.43% * 100;
 Minibatch[ 701- 800]: loss = 0.200839 * 100, metric = 7.52% * 100;
 Minibatch[ 801- 900]: loss = 0.206405 * 100, metric = 7.65% * 100;
 Minibatch[ 901-1000]: loss = 0.202430 * 100, metric = 7.55% * 100;
 Minibatch[1001-1100]: loss = 0.203995 * 100, metric = 7.63% * 100;
 Minibatch[1101-1200]: loss = 0.215390 * 100, metric = 7.99% * 100;
 Minibatch[1201-1300]: loss = 0.204252 * 100, metric = 7.48% * 100;
 Minibatch[1301-1400]: loss = 0.196055 * 100, metric = 7.12% * 100;
 Minibatch[1401-1500]: loss = 0.198861 * 100, metric = 7.45% * 100;
 Minibatch[1501-1600]: loss = 0.204961 * 100, metric = 7.65% * 100;
 Minibatch[1601-1700]: loss = 0.196830 * 100, metric = 7.30% * 100;
 Minibatch[1701-1800]: loss = 0.200744 * 100, metric = 7.36% * 100;
 Minibatch[1801-1900]: loss = 0.212457 * 100, metric = 7.92% * 100;
 Minibatch[1901-2000]: loss = 0.206478 * 100, metric = 7.68% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.203311 * 2000, metric = 7.57% * 2000 767.699s (  2.6 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 14.32% * 2000;
 Minibatch[   1- 100]: loss = 0.207198 * 100, metric = 7.68% * 100;
 Minibatch[ 101- 200]: loss = 0.200467 * 100, metric = 7.31% * 100;
 Minibatch[ 201- 300]: loss = 0.202165 * 100, metric = 7.47% * 100;
 Minibatch[ 301- 400]: loss = 0.195501 * 100, metric = 7.10% * 100;
 Minibatch[ 401- 500]: loss = 0.201160 * 100, metric = 7.46% * 100;
 Minibatch[ 501- 600]: loss = 0.199058 * 100, metric = 7.30% * 100;
 Minibatch[ 601- 700]: loss = 0.205768 * 100, metric = 7.63% * 100;
 Minibatch[ 701- 800]: loss = 0.192824 * 100, metric = 7.09% * 100;
 Minibatch[ 801- 900]: loss = 0.200238 * 100, metric = 7.58% * 100;
 Minibatch[ 901-1000]: loss = 0.206133 * 100, metric = 7.74% * 100;
 Minibatch[1001-1100]: loss = 0.199002 * 100, metric = 7.42% * 100;
 Minibatch[1101-1200]: loss = 0.205307 * 100, metric = 7.51% * 100;
 Minibatch[1201-1300]: loss = 0.214012 * 100, metric = 7.92% * 100;
 Minibatch[1301-1400]: loss = 0.193874 * 100, metric = 7.20% * 100;
 Minibatch[1401-1500]: loss = 0.185228 * 100, metric = 6.76% * 100;
 Minibatch[1501-1600]: loss = 0.204828 * 100, metric = 7.54% * 100;
 Minibatch[1601-1700]: loss = 0.195044 * 100, metric = 7.24% * 100;
 Minibatch[1701-1800]: loss = 0.202253 * 100, metric = 7.51% * 100;
 Minibatch[1801-1900]: loss = 0.193646 * 100, metric = 7.16% * 100;
 Minibatch[1901-2000]: loss = 0.188565 * 100, metric = 6.93% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.199613 * 2000, metric = 7.38% * 2000 764.072s (  2.6 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.21% * 2000;
 Minibatch[   1- 100]: loss = 0.199634 * 100, metric = 7.32% * 100;
 Minibatch[ 101- 200]: loss = 0.183792 * 100, metric = 6.66% * 100;
 Minibatch[ 201- 300]: loss = 0.197096 * 100, metric = 7.29% * 100;
 Minibatch[ 301- 400]: loss = 0.189524 * 100, metric = 7.07% * 100;
 Minibatch[ 401- 500]: loss = 0.194181 * 100, metric = 7.04% * 100;
 Minibatch[ 501- 600]: loss = 0.189184 * 100, metric = 6.79% * 100;
 Minibatch[ 601- 700]: loss = 0.201211 * 100, metric = 7.23% * 100;
 Minibatch[ 701- 800]: loss = 0.194153 * 100, metric = 7.27% * 100;
 Minibatch[ 801- 900]: loss = 0.189130 * 100, metric = 7.06% * 100;
 Minibatch[ 901-1000]: loss = 0.188489 * 100, metric = 6.87% * 100;
 Minibatch[1001-1100]: loss = 0.201928 * 100, metric = 7.48% * 100;
 Minibatch[1101-1200]: loss = 0.201307 * 100, metric = 7.32% * 100;
 Minibatch[1201-1300]: loss = 0.190516 * 100, metric = 6.94% * 100;
 Minibatch[1301-1400]: loss = 0.185011 * 100, metric = 6.63% * 100;
 Minibatch[1401-1500]: loss = 0.193040 * 100, metric = 7.03% * 100;
 Minibatch[1501-1600]: loss = 0.181739 * 100, metric = 6.55% * 100;
 Minibatch[1601-1700]: loss = 0.206729 * 100, metric = 7.69% * 100;
 Minibatch[1701-1800]: loss = 0.198553 * 100, metric = 7.25% * 100;
 Minibatch[1801-1900]: loss = 0.188047 * 100, metric = 6.88% * 100;
 Minibatch[1901-2000]: loss = 0.191584 * 100, metric = 7.06% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.193242 * 2000, metric = 7.07% * 2000 762.026s (  2.6 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 15.62% * 2000;
 Minibatch[   1- 100]: loss = 0.187429 * 100, metric = 6.64% * 100;
 Minibatch[ 101- 200]: loss = 0.199777 * 100, metric = 7.19% * 100;
 Minibatch[ 201- 300]: loss = 0.190298 * 100, metric = 7.06% * 100;
 Minibatch[ 301- 400]: loss = 0.189819 * 100, metric = 6.92% * 100;
 Minibatch[ 401- 500]: loss = 0.192828 * 100, metric = 7.00% * 100;
 Minibatch[ 501- 600]: loss = 0.188911 * 100, metric = 6.90% * 100;
 Minibatch[ 601- 700]: loss = 0.182823 * 100, metric = 6.67% * 100;
 Minibatch[ 701- 800]: loss = 0.190375 * 100, metric = 6.99% * 100;
 Minibatch[ 801- 900]: loss = 0.198976 * 100, metric = 7.13% * 100;
 Minibatch[ 901-1000]: loss = 0.195202 * 100, metric = 7.25% * 100;
 Minibatch[1001-1100]: loss = 0.183393 * 100, metric = 6.62% * 100;
 Minibatch[1101-1200]: loss = 0.192595 * 100, metric = 7.05% * 100;
 Minibatch[1201-1300]: loss = 0.192401 * 100, metric = 6.99% * 100;
 Minibatch[1301-1400]: loss = 0.199052 * 100, metric = 7.33% * 100;
 Minibatch[1401-1500]: loss = 0.188103 * 100, metric = 6.96% * 100;
 Minibatch[1501-1600]: loss = 0.187413 * 100, metric = 6.72% * 100;
 Minibatch[1601-1700]: loss = 0.179663 * 100, metric = 6.45% * 100;
 Minibatch[1701-1800]: loss = 0.179783 * 100, metric = 6.33% * 100;
 Minibatch[1801-1900]: loss = 0.187454 * 100, metric = 6.72% * 100;
 Minibatch[1901-2000]: loss = 0.190102 * 100, metric = 6.79% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.189820 * 2000, metric = 6.88% * 2000 757.238s (  2.6 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 13.57% * 2000;
 Minibatch[   1- 100]: loss = 0.191880 * 100, metric = 6.99% * 100;
 Minibatch[ 101- 200]: loss = 0.179892 * 100, metric = 6.51% * 100;
 Minibatch[ 201- 300]: loss = 0.191577 * 100, metric = 6.96% * 100;
 Minibatch[ 301- 400]: loss = 0.190951 * 100, metric = 6.77% * 100;
 Minibatch[ 401- 500]: loss = 0.195662 * 100, metric = 7.35% * 100;
 Minibatch[ 501- 600]: loss = 0.201594 * 100, metric = 7.61% * 100;
 Minibatch[ 601- 700]: loss = 0.180730 * 100, metric = 6.84% * 100;
 Minibatch[ 701- 800]: loss = 0.180219 * 100, metric = 6.56% * 100;
 Minibatch[ 801- 900]: loss = 0.193123 * 100, metric = 7.10% * 100;
 Minibatch[ 901-1000]: loss = 0.198769 * 100, metric = 7.23% * 100;
 Minibatch[1001-1100]: loss = 0.188802 * 100, metric = 7.03% * 100;
 Minibatch[1101-1200]: loss = 0.181521 * 100, metric = 6.64% * 100;
 Minibatch[1201-1300]: loss = 0.193219 * 100, metric = 7.11% * 100;
 Minibatch[1301-1400]: loss = 0.182400 * 100, metric = 6.72% * 100;
 Minibatch[1401-1500]: loss = 0.195441 * 100, metric = 7.27% * 100;
 Minibatch[1501-1600]: loss = 0.181798 * 100, metric = 6.58% * 100;
 Minibatch[1601-1700]: loss = 0.180537 * 100, metric = 6.46% * 100;
 Minibatch[1701-1800]: loss = 0.179639 * 100, metric = 6.59% * 100;
 Minibatch[1801-1900]: loss = 0.185014 * 100, metric = 6.74% * 100;
 Minibatch[1901-2000]: loss = 0.185293 * 100, metric = 6.67% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.187903 * 2000, metric = 6.89% * 2000 760.450s (  2.6 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 13.35% * 2000;
 Minibatch[   1- 100]: loss = 0.180136 * 100, metric = 6.55% * 100;
 Minibatch[ 101- 200]: loss = 0.184336 * 100, metric = 6.55% * 100;
 Minibatch[ 201- 300]: loss = 0.184516 * 100, metric = 6.77% * 100;
 Minibatch[ 301- 400]: loss = 0.198335 * 100, metric = 7.40% * 100;
 Minibatch[ 401- 500]: loss = 0.174004 * 100, metric = 6.29% * 100;
 Minibatch[ 501- 600]: loss = 0.184047 * 100, metric = 6.75% * 100;
 Minibatch[ 601- 700]: loss = 0.184709 * 100, metric = 6.81% * 100;
 Minibatch[ 701- 800]: loss = 0.194067 * 100, metric = 7.12% * 100;
 Minibatch[ 801- 900]: loss = 0.187660 * 100, metric = 6.90% * 100;
 Minibatch[ 901-1000]: loss = 0.192946 * 100, metric = 7.16% * 100;
 Minibatch[1001-1100]: loss = 0.191260 * 100, metric = 7.00% * 100;
 Minibatch[1101-1200]: loss = 0.181525 * 100, metric = 6.71% * 100;
 Minibatch[1201-1300]: loss = 0.181589 * 100, metric = 6.71% * 100;
 Minibatch[1301-1400]: loss = 0.181757 * 100, metric = 6.80% * 100;
 Minibatch[1401-1500]: loss = 0.192182 * 100, metric = 6.98% * 100;
 Minibatch[1501-1600]: loss = 0.180734 * 100, metric = 6.59% * 100;
 Minibatch[1601-1700]: loss = 0.191822 * 100, metric = 7.09% * 100;
 Minibatch[1701-1800]: loss = 0.176610 * 100, metric = 6.51% * 100;
 Minibatch[1801-1900]: loss = 0.194755 * 100, metric = 7.25% * 100;
 Minibatch[1901-2000]: loss = 0.185618 * 100, metric = 6.84% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.186130 * 2000, metric = 6.84% * 2000 759.058s (  2.6 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 15.51% * 2000;
 Minibatch[   1- 100]: loss = 0.192197 * 100, metric = 7.11% * 100;
 Minibatch[ 101- 200]: loss = 0.171551 * 100, metric = 6.30% * 100;
 Minibatch[ 201- 300]: loss = 0.183793 * 100, metric = 6.84% * 100;
 Minibatch[ 301- 400]: loss = 0.187831 * 100, metric = 7.10% * 100;
 Minibatch[ 401- 500]: loss = 0.183891 * 100, metric = 6.70% * 100;
 Minibatch[ 501- 600]: loss = 0.167046 * 100, metric = 6.11% * 100;
 Minibatch[ 601- 700]: loss = 0.185145 * 100, metric = 6.85% * 100;
 Minibatch[ 701- 800]: loss = 0.178916 * 100, metric = 6.64% * 100;
 Minibatch[ 801- 900]: loss = 0.184947 * 100, metric = 6.63% * 100;
 Minibatch[ 901-1000]: loss = 0.175761 * 100, metric = 6.50% * 100;
 Minibatch[1001-1100]: loss = 0.178024 * 100, metric = 6.27% * 100;
 Minibatch[1101-1200]: loss = 0.187574 * 100, metric = 6.84% * 100;
 Minibatch[1201-1300]: loss = 0.182630 * 100, metric = 6.73% * 100;
 Minibatch[1301-1400]: loss = 0.181096 * 100, metric = 6.74% * 100;
 Minibatch[1401-1500]: loss = 0.182932 * 100, metric = 6.77% * 100;
 Minibatch[1501-1600]: loss = 0.190316 * 100, metric = 7.11% * 100;
 Minibatch[1601-1700]: loss = 0.182701 * 100, metric = 6.73% * 100;
 Minibatch[1701-1800]: loss = 0.181296 * 100, metric = 6.71% * 100;
 Minibatch[1801-1900]: loss = 0.180810 * 100, metric = 6.70% * 100;
 Minibatch[1901-2000]: loss = 0.190104 * 100, metric = 7.01% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.182428 * 2000, metric = 6.72% * 2000 755.001s (  2.6 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 14.18% * 2000;
 Minibatch[   1- 100]: loss = 0.171412 * 100, metric = 6.23% * 100;
 Minibatch[ 101- 200]: loss = 0.190577 * 100, metric = 7.04% * 100;
 Minibatch[ 201- 300]: loss = 0.180273 * 100, metric = 6.61% * 100;
 Minibatch[ 301- 400]: loss = 0.176310 * 100, metric = 6.56% * 100;
 Minibatch[ 401- 500]: loss = 0.180075 * 100, metric = 6.47% * 100;
 Minibatch[ 501- 600]: loss = 0.178601 * 100, metric = 6.54% * 100;
 Minibatch[ 601- 700]: loss = 0.192832 * 100, metric = 7.21% * 100;
 Minibatch[ 701- 800]: loss = 0.189417 * 100, metric = 6.98% * 100;
 Minibatch[ 801- 900]: loss = 0.176870 * 100, metric = 6.28% * 100;
 Minibatch[ 901-1000]: loss = 0.172966 * 100, metric = 6.31% * 100;
 Minibatch[1001-1100]: loss = 0.171254 * 100, metric = 6.32% * 100;
 Minibatch[1101-1200]: loss = 0.186443 * 100, metric = 7.11% * 100;
 Minibatch[1201-1300]: loss = 0.180686 * 100, metric = 6.70% * 100;
 Minibatch[1301-1400]: loss = 0.178624 * 100, metric = 6.46% * 100;
 Minibatch[1401-1500]: loss = 0.179743 * 100, metric = 6.38% * 100;
 Minibatch[1501-1600]: loss = 0.173059 * 100, metric = 6.39% * 100;
 Minibatch[1601-1700]: loss = 0.177727 * 100, metric = 6.41% * 100;
 Minibatch[1701-1800]: loss = 0.173734 * 100, metric = 6.27% * 100;
 Minibatch[1801-1900]: loss = 0.176924 * 100, metric = 6.43% * 100;
 Minibatch[1901-2000]: loss = 0.174284 * 100, metric = 6.29% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.179090 * 2000, metric = 6.55% * 2000 758.924s (  2.6 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 13.46% * 2000;
 Minibatch[   1- 100]: loss = 0.176176 * 100, metric = 6.46% * 100;
 Minibatch[ 101- 200]: loss = 0.176189 * 100, metric = 6.40% * 100;
 Minibatch[ 201- 300]: loss = 0.190017 * 100, metric = 6.80% * 100;
 Minibatch[ 301- 400]: loss = 0.182046 * 100, metric = 6.67% * 100;
 Minibatch[ 401- 500]: loss = 0.182196 * 100, metric = 6.63% * 100;
 Minibatch[ 501- 600]: loss = 0.178227 * 100, metric = 6.60% * 100;
 Minibatch[ 601- 700]: loss = 0.174679 * 100, metric = 6.41% * 100;
 Minibatch[ 701- 800]: loss = 0.175125 * 100, metric = 6.48% * 100;
 Minibatch[ 801- 900]: loss = 0.176009 * 100, metric = 6.34% * 100;
 Minibatch[ 901-1000]: loss = 0.166595 * 100, metric = 6.17% * 100;
 Minibatch[1001-1100]: loss = 0.170126 * 100, metric = 6.30% * 100;
 Minibatch[1101-1200]: loss = 0.185650 * 100, metric = 6.95% * 100;
 Minibatch[1201-1300]: loss = 0.184030 * 100, metric = 6.75% * 100;
 Minibatch[1301-1400]: loss = 0.177718 * 100, metric = 6.46% * 100;
 Minibatch[1401-1500]: loss = 0.182854 * 100, metric = 6.80% * 100;
 Minibatch[1501-1600]: loss = 0.180394 * 100, metric = 6.57% * 100;
 Minibatch[1601-1700]: loss = 0.169351 * 100, metric = 6.02% * 100;
 Minibatch[1701-1800]: loss = 0.179058 * 100, metric = 6.72% * 100;
 Minibatch[1801-1900]: loss = 0.172543 * 100, metric = 6.21% * 100;
 Minibatch[1901-2000]: loss = 0.181338 * 100, metric = 6.76% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.178016 * 2000, metric = 6.53% * 2000 753.164s (  2.7 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 13.55% * 2000;
 Minibatch[   1- 100]: loss = 0.188412 * 100, metric = 6.78% * 100;
 Minibatch[ 101- 200]: loss = 0.177483 * 100, metric = 6.62% * 100;
 Minibatch[ 201- 300]: loss = 0.178857 * 100, metric = 6.60% * 100;
 Minibatch[ 301- 400]: loss = 0.181114 * 100, metric = 6.56% * 100;
 Minibatch[ 401- 500]: loss = 0.167773 * 100, metric = 6.08% * 100;
 Minibatch[ 501- 600]: loss = 0.172242 * 100, metric = 6.17% * 100;
 Minibatch[ 601- 700]: loss = 0.177940 * 100, metric = 6.55% * 100;
 Minibatch[ 701- 800]: loss = 0.174247 * 100, metric = 6.36% * 100;
 Minibatch[ 801- 900]: loss = 0.173500 * 100, metric = 6.26% * 100;
 Minibatch[ 901-1000]: loss = 0.162760 * 100, metric = 5.93% * 100;
 Minibatch[1001-1100]: loss = 0.170262 * 100, metric = 6.23% * 100;
 Minibatch[1101-1200]: loss = 0.164801 * 100, metric = 6.12% * 100;
 Minibatch[1201-1300]: loss = 0.182858 * 100, metric = 6.51% * 100;
 Minibatch[1301-1400]: loss = 0.160859 * 100, metric = 5.86% * 100;
 Minibatch[1401-1500]: loss = 0.181426 * 100, metric = 6.44% * 100;
 Minibatch[1501-1600]: loss = 0.179236 * 100, metric = 6.53% * 100;
 Minibatch[1601-1700]: loss = 0.170500 * 100, metric = 5.98% * 100;
 Minibatch[1701-1800]: loss = 0.166435 * 100, metric = 6.02% * 100;
 Minibatch[1801-1900]: loss = 0.164253 * 100, metric = 5.96% * 100;
 Minibatch[1901-2000]: loss = 0.181555 * 100, metric = 6.67% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.173826 * 2000, metric = 6.31% * 2000 754.385s (  2.7 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.49% * 2000;
 Minibatch[   1- 100]: loss = 0.171254 * 100, metric = 6.38% * 100;
 Minibatch[ 101- 200]: loss = 0.177429 * 100, metric = 6.51% * 100;
 Minibatch[ 201- 300]: loss = 0.167698 * 100, metric = 6.27% * 100;
 Minibatch[ 301- 400]: loss = 0.184110 * 100, metric = 6.69% * 100;
 Minibatch[ 401- 500]: loss = 0.173335 * 100, metric = 6.25% * 100;
 Minibatch[ 501- 600]: loss = 0.178573 * 100, metric = 6.43% * 100;
 Minibatch[ 601- 700]: loss = 0.174731 * 100, metric = 6.56% * 100;
 Minibatch[ 701- 800]: loss = 0.172923 * 100, metric = 6.54% * 100;
 Minibatch[ 801- 900]: loss = 0.164181 * 100, metric = 5.84% * 100;
 Minibatch[ 901-1000]: loss = 0.171127 * 100, metric = 6.31% * 100;
 Minibatch[1001-1100]: loss = 0.177693 * 100, metric = 6.57% * 100;
 Minibatch[1101-1200]: loss = 0.171877 * 100, metric = 6.30% * 100;
 Minibatch[1201-1300]: loss = 0.172012 * 100, metric = 6.16% * 100;
 Minibatch[1301-1400]: loss = 0.167876 * 100, metric = 6.07% * 100;
 Minibatch[1401-1500]: loss = 0.176390 * 100, metric = 6.45% * 100;
 Minibatch[1501-1600]: loss = 0.167747 * 100, metric = 6.04% * 100;
 Minibatch[1601-1700]: loss = 0.181279 * 100, metric = 6.59% * 100;
 Minibatch[1701-1800]: loss = 0.168546 * 100, metric = 6.20% * 100;
 Minibatch[1801-1900]: loss = 0.166555 * 100, metric = 6.07% * 100;
 Minibatch[1901-2000]: loss = 0.166484 * 100, metric = 6.18% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.172591 * 2000, metric = 6.32% * 2000 750.234s (  2.7 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 14.17% * 2000;
 Minibatch[   1- 100]: loss = 0.157292 * 100, metric = 5.58% * 100;
 Minibatch[ 101- 200]: loss = 0.172523 * 100, metric = 6.37% * 100;
 Minibatch[ 201- 300]: loss = 0.172404 * 100, metric = 6.24% * 100;
 Minibatch[ 301- 400]: loss = 0.160455 * 100, metric = 5.94% * 100;
 Minibatch[ 401- 500]: loss = 0.166733 * 100, metric = 6.14% * 100;
 Minibatch[ 501- 600]: loss = 0.156913 * 100, metric = 5.56% * 100;
 Minibatch[ 601- 700]: loss = 0.173002 * 100, metric = 6.25% * 100;
 Minibatch[ 701- 800]: loss = 0.166089 * 100, metric = 6.08% * 100;
 Minibatch[ 801- 900]: loss = 0.172485 * 100, metric = 6.34% * 100;
 Minibatch[ 901-1000]: loss = 0.162637 * 100, metric = 5.97% * 100;
 Minibatch[1001-1100]: loss = 0.178545 * 100, metric = 6.62% * 100;
 Minibatch[1101-1200]: loss = 0.165343 * 100, metric = 5.95% * 100;
 Minibatch[1201-1300]: loss = 0.172666 * 100, metric = 6.36% * 100;
 Minibatch[1301-1400]: loss = 0.172590 * 100, metric = 6.32% * 100;
 Minibatch[1401-1500]: loss = 0.167854 * 100, metric = 6.17% * 100;
 Minibatch[1501-1600]: loss = 0.173148 * 100, metric = 6.34% * 100;
 Minibatch[1601-1700]: loss = 0.168742 * 100, metric = 6.29% * 100;
 Minibatch[1701-1800]: loss = 0.164135 * 100, metric = 5.88% * 100;
 Minibatch[1801-1900]: loss = 0.175257 * 100, metric = 6.39% * 100;
 Minibatch[1901-2000]: loss = 0.162720 * 100, metric = 5.85% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.168077 * 2000, metric = 6.13% * 2000 751.538s (  2.7 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.12% * 2000;
 Minibatch[   1- 100]: loss = 0.168439 * 100, metric = 6.20% * 100;
 Minibatch[ 101- 200]: loss = 0.154521 * 100, metric = 5.66% * 100;
 Minibatch[ 201- 300]: loss = 0.182036 * 100, metric = 6.88% * 100;
 Minibatch[ 301- 400]: loss = 0.166056 * 100, metric = 5.97% * 100;
 Minibatch[ 401- 500]: loss = 0.161909 * 100, metric = 5.92% * 100;
 Minibatch[ 501- 600]: loss = 0.164528 * 100, metric = 6.04% * 100;
 Minibatch[ 601- 700]: loss = 0.165116 * 100, metric = 5.90% * 100;
 Minibatch[ 701- 800]: loss = 0.158755 * 100, metric = 5.80% * 100;
 Minibatch[ 801- 900]: loss = 0.159652 * 100, metric = 5.72% * 100;
 Minibatch[ 901-1000]: loss = 0.169733 * 100, metric = 6.20% * 100;
 Minibatch[1001-1100]: loss = 0.176646 * 100, metric = 6.45% * 100;
 Minibatch[1101-1200]: loss = 0.162048 * 100, metric = 5.79% * 100;
 Minibatch[1201-1300]: loss = 0.168941 * 100, metric = 6.21% * 100;
 Minibatch[1301-1400]: loss = 0.151248 * 100, metric = 5.60% * 100;
 Minibatch[1401-1500]: loss = 0.158259 * 100, metric = 5.59% * 100;
 Minibatch[1501-1600]: loss = 0.160150 * 100, metric = 5.78% * 100;
 Minibatch[1601-1700]: loss = 0.172751 * 100, metric = 6.29% * 100;
 Minibatch[1701-1800]: loss = 0.164141 * 100, metric = 6.00% * 100;
 Minibatch[1801-1900]: loss = 0.159738 * 100, metric = 5.78% * 100;
 Minibatch[1901-2000]: loss = 0.156399 * 100, metric = 5.55% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.164053 * 2000, metric = 5.97% * 2000 749.248s (  2.7 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 13.85% * 2000;
 Minibatch[   1- 100]: loss = 0.161149 * 100, metric = 5.80% * 100;
 Minibatch[ 101- 200]: loss = 0.166563 * 100, metric = 6.02% * 100;
 Minibatch[ 201- 300]: loss = 0.165268 * 100, metric = 5.94% * 100;
 Minibatch[ 301- 400]: loss = 0.158476 * 100, metric = 5.77% * 100;
 Minibatch[ 401- 500]: loss = 0.162845 * 100, metric = 5.92% * 100;
 Minibatch[ 501- 600]: loss = 0.159605 * 100, metric = 5.89% * 100;
 Minibatch[ 601- 700]: loss = 0.159004 * 100, metric = 5.75% * 100;
 Minibatch[ 701- 800]: loss = 0.171092 * 100, metric = 6.23% * 100;
 Minibatch[ 801- 900]: loss = 0.161544 * 100, metric = 5.87% * 100;
 Minibatch[ 901-1000]: loss = 0.148265 * 100, metric = 5.24% * 100;
 Minibatch[1001-1100]: loss = 0.157169 * 100, metric = 5.74% * 100;
 Minibatch[1101-1200]: loss = 0.175495 * 100, metric = 6.49% * 100;
 Minibatch[1201-1300]: loss = 0.169881 * 100, metric = 6.13% * 100;
 Minibatch[1301-1400]: loss = 0.157761 * 100, metric = 5.71% * 100;
 Minibatch[1401-1500]: loss = 0.169942 * 100, metric = 6.26% * 100;
 Minibatch[1501-1600]: loss = 0.162401 * 100, metric = 5.90% * 100;
 Minibatch[1601-1700]: loss = 0.162799 * 100, metric = 6.01% * 100;
 Minibatch[1701-1800]: loss = 0.159300 * 100, metric = 5.76% * 100;
 Minibatch[1801-1900]: loss = 0.164337 * 100, metric = 6.17% * 100;
 Minibatch[1901-2000]: loss = 0.158879 * 100, metric = 5.72% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.162589 * 2000, metric = 5.92% * 2000 747.619s (  2.7 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 13.30% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
