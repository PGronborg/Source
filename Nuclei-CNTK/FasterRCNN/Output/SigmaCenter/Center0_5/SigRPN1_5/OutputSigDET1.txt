Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.076244 * 100, metric = 26.33% * 100;
 Minibatch[ 101- 200]: loss = 0.858530 * 100, metric = 23.59% * 100;
 Minibatch[ 201- 300]: loss = 0.770599 * 100, metric = 22.87% * 100;
 Minibatch[ 301- 400]: loss = 0.740050 * 100, metric = 22.11% * 100;
 Minibatch[ 401- 500]: loss = 0.687740 * 100, metric = 21.07% * 100;
 Minibatch[ 501- 600]: loss = 0.668189 * 100, metric = 20.34% * 100;
 Minibatch[ 601- 700]: loss = 0.650085 * 100, metric = 19.79% * 100;
 Minibatch[ 701- 800]: loss = 0.598947 * 100, metric = 18.56% * 100;
 Minibatch[ 801- 900]: loss = 0.602451 * 100, metric = 17.82% * 100;
 Minibatch[ 901-1000]: loss = 0.628503 * 100, metric = 19.44% * 100;
 Minibatch[1001-1100]: loss = 0.599899 * 100, metric = 18.75% * 100;
 Minibatch[1101-1200]: loss = 0.581104 * 100, metric = 17.88% * 100;
 Minibatch[1201-1300]: loss = 0.578123 * 100, metric = 18.12% * 100;
 Minibatch[1301-1400]: loss = 0.547833 * 100, metric = 16.75% * 100;
 Minibatch[1401-1500]: loss = 0.565099 * 100, metric = 17.27% * 100;
 Minibatch[1501-1600]: loss = 0.539967 * 100, metric = 16.97% * 100;
 Minibatch[1601-1700]: loss = 0.539335 * 100, metric = 16.88% * 100;
 Minibatch[1701-1800]: loss = 0.546404 * 100, metric = 17.18% * 100;
 Minibatch[1801-1900]: loss = 0.539858 * 100, metric = 16.64% * 100;
 Minibatch[1901-2000]: loss = 0.530153 * 100, metric = 16.03% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.642456 * 2000, metric = 19.22% * 2000 1045.985s (  1.9 samples/s);
Finished Evaluation [1]: Minibatch[1-2000]: metric = 26.19% * 2000;
0.6725509244799613
 Minibatch[   1- 100]: loss = 0.522950 * 100, metric = 16.15% * 100;
 Minibatch[ 101- 200]: loss = 0.530526 * 100, metric = 16.49% * 100;
 Minibatch[ 201- 300]: loss = 0.519607 * 100, metric = 15.48% * 100;
 Minibatch[ 301- 400]: loss = 0.527514 * 100, metric = 16.24% * 100;
 Minibatch[ 401- 500]: loss = 0.518427 * 100, metric = 15.95% * 100;
 Minibatch[ 501- 600]: loss = 0.525958 * 100, metric = 16.03% * 100;
 Minibatch[ 601- 700]: loss = 0.501128 * 100, metric = 15.63% * 100;
 Minibatch[ 701- 800]: loss = 0.512314 * 100, metric = 15.96% * 100;
 Minibatch[ 801- 900]: loss = 0.494276 * 100, metric = 15.79% * 100;
 Minibatch[ 901-1000]: loss = 0.485181 * 100, metric = 15.01% * 100;
 Minibatch[1001-1100]: loss = 0.497847 * 100, metric = 15.69% * 100;
 Minibatch[1101-1200]: loss = 0.491630 * 100, metric = 15.39% * 100;
 Minibatch[1201-1300]: loss = 0.480767 * 100, metric = 15.13% * 100;
 Minibatch[1301-1400]: loss = 0.490768 * 100, metric = 15.15% * 100;
 Minibatch[1401-1500]: loss = 0.474764 * 100, metric = 14.53% * 100;
 Minibatch[1501-1600]: loss = 0.465961 * 100, metric = 14.63% * 100;
 Minibatch[1601-1700]: loss = 0.483004 * 100, metric = 14.71% * 100;
 Minibatch[1701-1800]: loss = 0.484686 * 100, metric = 15.17% * 100;
 Minibatch[1801-1900]: loss = 0.478970 * 100, metric = 15.10% * 100;
 Minibatch[1901-2000]: loss = 0.454946 * 100, metric = 14.27% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.497061 * 2000, metric = 15.42% * 2000 969.648s (  2.1 samples/s);
Finished Evaluation [2]: Minibatch[1-2000]: metric = 21.00% * 2000;
0.5340373673960567
 Minibatch[   1- 100]: loss = 0.470849 * 100, metric = 14.85% * 100;
 Minibatch[ 101- 200]: loss = 0.475348 * 100, metric = 14.78% * 100;
 Minibatch[ 201- 300]: loss = 0.457819 * 100, metric = 14.31% * 100;
 Minibatch[ 301- 400]: loss = 0.471549 * 100, metric = 15.12% * 100;
 Minibatch[ 401- 500]: loss = 0.480057 * 100, metric = 15.13% * 100;
 Minibatch[ 501- 600]: loss = 0.468730 * 100, metric = 14.87% * 100;
 Minibatch[ 601- 700]: loss = 0.481687 * 100, metric = 14.82% * 100;
 Minibatch[ 701- 800]: loss = 0.447697 * 100, metric = 14.21% * 100;
 Minibatch[ 801- 900]: loss = 0.467956 * 100, metric = 14.94% * 100;
 Minibatch[ 901-1000]: loss = 0.450278 * 100, metric = 14.18% * 100;
 Minibatch[1001-1100]: loss = 0.457968 * 100, metric = 14.55% * 100;
 Minibatch[1101-1200]: loss = 0.446723 * 100, metric = 14.33% * 100;
 Minibatch[1201-1300]: loss = 0.438489 * 100, metric = 13.40% * 100;
 Minibatch[1301-1400]: loss = 0.448641 * 100, metric = 14.12% * 100;
 Minibatch[1401-1500]: loss = 0.448542 * 100, metric = 14.08% * 100;
 Minibatch[1501-1600]: loss = 0.435910 * 100, metric = 13.93% * 100;
 Minibatch[1601-1700]: loss = 0.430347 * 100, metric = 13.39% * 100;
 Minibatch[1701-1800]: loss = 0.453868 * 100, metric = 14.47% * 100;
 Minibatch[1801-1900]: loss = 0.429832 * 100, metric = 13.48% * 100;
 Minibatch[1901-2000]: loss = 0.432175 * 100, metric = 13.70% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.454723 * 2000, metric = 14.33% * 2000 976.624s (  2.0 samples/s);
Finished Evaluation [3]: Minibatch[1-2000]: metric = 20.86% * 2000;
 Minibatch[   1- 100]: loss = 0.455785 * 100, metric = 14.23% * 100;
 Minibatch[ 101- 200]: loss = 0.424543 * 100, metric = 13.34% * 100;
 Minibatch[ 201- 300]: loss = 0.441710 * 100, metric = 13.95% * 100;
 Minibatch[ 301- 400]: loss = 0.404580 * 100, metric = 12.98% * 100;
 Minibatch[ 401- 500]: loss = 0.439814 * 100, metric = 13.41% * 100;
 Minibatch[ 501- 600]: loss = 0.418502 * 100, metric = 13.22% * 100;
 Minibatch[ 601- 700]: loss = 0.419286 * 100, metric = 13.22% * 100;
 Minibatch[ 701- 800]: loss = 0.424824 * 100, metric = 13.48% * 100;
 Minibatch[ 801- 900]: loss = 0.428295 * 100, metric = 13.35% * 100;
 Minibatch[ 901-1000]: loss = 0.423864 * 100, metric = 13.46% * 100;
 Minibatch[1001-1100]: loss = 0.429926 * 100, metric = 13.66% * 100;
 Minibatch[1101-1200]: loss = 0.412504 * 100, metric = 12.82% * 100;
 Minibatch[1201-1300]: loss = 0.419913 * 100, metric = 13.19% * 100;
 Minibatch[1301-1400]: loss = 0.434257 * 100, metric = 13.62% * 100;
 Minibatch[1401-1500]: loss = 0.428656 * 100, metric = 13.41% * 100;
 Minibatch[1501-1600]: loss = 0.407678 * 100, metric = 12.88% * 100;
 Minibatch[1601-1700]: loss = 0.421589 * 100, metric = 13.48% * 100;
 Minibatch[1701-1800]: loss = 0.431263 * 100, metric = 13.94% * 100;
 Minibatch[1801-1900]: loss = 0.418660 * 100, metric = 13.34% * 100;
 Minibatch[1901-2000]: loss = 0.414156 * 100, metric = 12.88% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.424990 * 2000, metric = 13.39% * 2000 979.450s (  2.0 samples/s);
Finished Evaluation [4]: Minibatch[1-2000]: metric = 23.71% * 2000;
 Minibatch[   1- 100]: loss = 0.425266 * 100, metric = 13.33% * 100;
 Minibatch[ 101- 200]: loss = 0.411927 * 100, metric = 13.11% * 100;
 Minibatch[ 201- 300]: loss = 0.409081 * 100, metric = 13.02% * 100;
 Minibatch[ 301- 400]: loss = 0.433347 * 100, metric = 13.82% * 100;
 Minibatch[ 401- 500]: loss = 0.400661 * 100, metric = 12.73% * 100;
 Minibatch[ 501- 600]: loss = 0.403226 * 100, metric = 12.49% * 100;
 Minibatch[ 601- 700]: loss = 0.409170 * 100, metric = 12.62% * 100;
 Minibatch[ 701- 800]: loss = 0.415934 * 100, metric = 13.08% * 100;
 Minibatch[ 801- 900]: loss = 0.394915 * 100, metric = 12.41% * 100;
 Minibatch[ 901-1000]: loss = 0.397538 * 100, metric = 12.40% * 100;
 Minibatch[1001-1100]: loss = 0.405801 * 100, metric = 12.72% * 100;
 Minibatch[1101-1200]: loss = 0.390576 * 100, metric = 12.27% * 100;
 Minibatch[1201-1300]: loss = 0.409679 * 100, metric = 12.77% * 100;
 Minibatch[1301-1400]: loss = 0.417917 * 100, metric = 13.29% * 100;
 Minibatch[1401-1500]: loss = 0.398953 * 100, metric = 12.63% * 100;
 Minibatch[1501-1600]: loss = 0.401524 * 100, metric = 12.48% * 100;
 Minibatch[1601-1700]: loss = 0.414007 * 100, metric = 13.29% * 100;
 Minibatch[1701-1800]: loss = 0.413748 * 100, metric = 13.28% * 100;
 Minibatch[1801-1900]: loss = 0.410095 * 100, metric = 13.05% * 100;
 Minibatch[1901-2000]: loss = 0.399966 * 100, metric = 12.47% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.408167 * 2000, metric = 12.86% * 2000 984.479s (  2.0 samples/s);
Finished Evaluation [5]: Minibatch[1-2000]: metric = 20.73% * 2000;
0.5255096426680684
 Minibatch[   1- 100]: loss = 0.398145 * 100, metric = 12.78% * 100;
 Minibatch[ 101- 200]: loss = 0.394566 * 100, metric = 12.74% * 100;
 Minibatch[ 201- 300]: loss = 0.402318 * 100, metric = 12.57% * 100;
 Minibatch[ 301- 400]: loss = 0.401515 * 100, metric = 12.54% * 100;
 Minibatch[ 401- 500]: loss = 0.381794 * 100, metric = 12.09% * 100;
 Minibatch[ 501- 600]: loss = 0.395305 * 100, metric = 12.63% * 100;
 Minibatch[ 601- 700]: loss = 0.398549 * 100, metric = 12.82% * 100;
 Minibatch[ 701- 800]: loss = 0.394397 * 100, metric = 12.62% * 100;
 Minibatch[ 801- 900]: loss = 0.396386 * 100, metric = 12.56% * 100;
 Minibatch[ 901-1000]: loss = 0.396308 * 100, metric = 12.47% * 100;
 Minibatch[1001-1100]: loss = 0.389706 * 100, metric = 11.90% * 100;
 Minibatch[1101-1200]: loss = 0.400251 * 100, metric = 12.64% * 100;
 Minibatch[1201-1300]: loss = 0.405445 * 100, metric = 12.78% * 100;
 Minibatch[1301-1400]: loss = 0.394606 * 100, metric = 12.43% * 100;
 Minibatch[1401-1500]: loss = 0.397869 * 100, metric = 12.83% * 100;
 Minibatch[1501-1600]: loss = 0.379932 * 100, metric = 11.71% * 100;
 Minibatch[1601-1700]: loss = 0.386049 * 100, metric = 12.42% * 100;
 Minibatch[1701-1800]: loss = 0.382943 * 100, metric = 12.01% * 100;
 Minibatch[1801-1900]: loss = 0.392170 * 100, metric = 12.67% * 100;
 Minibatch[1901-2000]: loss = 0.382018 * 100, metric = 12.04% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.393514 * 2000, metric = 12.46% * 2000 982.030s (  2.0 samples/s);
Finished Evaluation [6]: Minibatch[1-2000]: metric = 20.82% * 2000;
0.523556093275547
 Minibatch[   1- 100]: loss = 0.387172 * 100, metric = 12.27% * 100;
 Minibatch[ 101- 200]: loss = 0.395933 * 100, metric = 12.34% * 100;
 Minibatch[ 201- 300]: loss = 0.395563 * 100, metric = 12.39% * 100;
 Minibatch[ 301- 400]: loss = 0.377719 * 100, metric = 11.78% * 100;
 Minibatch[ 401- 500]: loss = 0.389139 * 100, metric = 12.09% * 100;
 Minibatch[ 501- 600]: loss = 0.370524 * 100, metric = 11.56% * 100;
 Minibatch[ 601- 700]: loss = 0.381471 * 100, metric = 11.90% * 100;
 Minibatch[ 701- 800]: loss = 0.379747 * 100, metric = 12.23% * 100;
 Minibatch[ 801- 900]: loss = 0.384020 * 100, metric = 12.20% * 100;
 Minibatch[ 901-1000]: loss = 0.375891 * 100, metric = 11.97% * 100;
 Minibatch[1001-1100]: loss = 0.388305 * 100, metric = 12.28% * 100;
 Minibatch[1101-1200]: loss = 0.372873 * 100, metric = 11.62% * 100;
 Minibatch[1201-1300]: loss = 0.385529 * 100, metric = 12.51% * 100;
 Minibatch[1301-1400]: loss = 0.371008 * 100, metric = 11.82% * 100;
 Minibatch[1401-1500]: loss = 0.370946 * 100, metric = 11.74% * 100;
 Minibatch[1501-1600]: loss = 0.381747 * 100, metric = 12.34% * 100;
 Minibatch[1601-1700]: loss = 0.380085 * 100, metric = 12.01% * 100;
 Minibatch[1701-1800]: loss = 0.376860 * 100, metric = 11.75% * 100;
 Minibatch[1801-1900]: loss = 0.383653 * 100, metric = 12.10% * 100;
 Minibatch[1901-2000]: loss = 0.387089 * 100, metric = 12.29% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.381764 * 2000, metric = 12.06% * 2000 985.753s (  2.0 samples/s);
Finished Evaluation [7]: Minibatch[1-2000]: metric = 18.58% * 2000;
0.4781014306917787
 Minibatch[   1- 100]: loss = 0.387572 * 100, metric = 12.41% * 100;
 Minibatch[ 101- 200]: loss = 0.372296 * 100, metric = 11.61% * 100;
 Minibatch[ 201- 300]: loss = 0.364598 * 100, metric = 11.68% * 100;
 Minibatch[ 301- 400]: loss = 0.366892 * 100, metric = 11.72% * 100;
 Minibatch[ 401- 500]: loss = 0.377044 * 100, metric = 12.04% * 100;
 Minibatch[ 501- 600]: loss = 0.387673 * 100, metric = 12.45% * 100;
 Minibatch[ 601- 700]: loss = 0.361761 * 100, metric = 11.64% * 100;
 Minibatch[ 701- 800]: loss = 0.379301 * 100, metric = 11.80% * 100;
 Minibatch[ 801- 900]: loss = 0.362431 * 100, metric = 11.15% * 100;
 Minibatch[ 901-1000]: loss = 0.349120 * 100, metric = 10.94% * 100;
 Minibatch[1001-1100]: loss = 0.358109 * 100, metric = 11.38% * 100;
 Minibatch[1101-1200]: loss = 0.358941 * 100, metric = 11.18% * 100;
 Minibatch[1201-1300]: loss = 0.373159 * 100, metric = 11.64% * 100;
 Minibatch[1301-1400]: loss = 0.375861 * 100, metric = 11.82% * 100;
 Minibatch[1401-1500]: loss = 0.370452 * 100, metric = 11.56% * 100;
 Minibatch[1501-1600]: loss = 0.369424 * 100, metric = 11.82% * 100;
 Minibatch[1601-1700]: loss = 0.364670 * 100, metric = 11.34% * 100;
 Minibatch[1701-1800]: loss = 0.362664 * 100, metric = 11.22% * 100;
 Minibatch[1801-1900]: loss = 0.366145 * 100, metric = 11.61% * 100;
 Minibatch[1901-2000]: loss = 0.356171 * 100, metric = 11.26% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.368214 * 2000, metric = 11.61% * 2000 974.630s (  2.1 samples/s);
Finished Evaluation [8]: Minibatch[1-2000]: metric = 18.53% * 2000;
0.4726651784852147
 Minibatch[   1- 100]: loss = 0.342613 * 100, metric = 10.71% * 100;
 Minibatch[ 101- 200]: loss = 0.365688 * 100, metric = 11.50% * 100;
 Minibatch[ 201- 300]: loss = 0.352587 * 100, metric = 11.21% * 100;
 Minibatch[ 301- 400]: loss = 0.373808 * 100, metric = 11.69% * 100;
 Minibatch[ 401- 500]: loss = 0.358770 * 100, metric = 11.13% * 100;
 Minibatch[ 501- 600]: loss = 0.358693 * 100, metric = 11.46% * 100;
 Minibatch[ 601- 700]: loss = 0.356006 * 100, metric = 11.00% * 100;
 Minibatch[ 701- 800]: loss = 0.343062 * 100, metric = 10.82% * 100;
 Minibatch[ 801- 900]: loss = 0.349626 * 100, metric = 11.21% * 100;
 Minibatch[ 901-1000]: loss = 0.356035 * 100, metric = 11.20% * 100;
 Minibatch[1001-1100]: loss = 0.327096 * 100, metric = 10.21% * 100;
 Minibatch[1101-1200]: loss = 0.350480 * 100, metric = 11.11% * 100;
 Minibatch[1201-1300]: loss = 0.346567 * 100, metric = 10.97% * 100;
 Minibatch[1301-1400]: loss = 0.345445 * 100, metric = 10.76% * 100;
 Minibatch[1401-1500]: loss = 0.359527 * 100, metric = 11.37% * 100;
 Minibatch[1501-1600]: loss = 0.354772 * 100, metric = 11.37% * 100;
 Minibatch[1601-1700]: loss = 0.354904 * 100, metric = 11.31% * 100;
 Minibatch[1701-1800]: loss = 0.341860 * 100, metric = 10.66% * 100;
 Minibatch[1801-1900]: loss = 0.344286 * 100, metric = 10.94% * 100;
 Minibatch[1901-2000]: loss = 0.352043 * 100, metric = 11.22% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.351693 * 2000, metric = 11.09% * 2000 972.770s (  2.1 samples/s);
Finished Evaluation [9]: Minibatch[1-2000]: metric = 16.90% * 2000;
0.4498287879489362
 Minibatch[   1- 100]: loss = 0.366712 * 100, metric = 11.62% * 100;
 Minibatch[ 101- 200]: loss = 0.345805 * 100, metric = 10.96% * 100;
 Minibatch[ 201- 300]: loss = 0.351150 * 100, metric = 11.24% * 100;
 Minibatch[ 301- 400]: loss = 0.339800 * 100, metric = 10.85% * 100;
 Minibatch[ 401- 500]: loss = 0.345248 * 100, metric = 10.80% * 100;
 Minibatch[ 501- 600]: loss = 0.337570 * 100, metric = 10.57% * 100;
 Minibatch[ 601- 700]: loss = 0.329235 * 100, metric = 10.18% * 100;
 Minibatch[ 701- 800]: loss = 0.326403 * 100, metric = 10.09% * 100;
 Minibatch[ 801- 900]: loss = 0.335900 * 100, metric = 10.46% * 100;
 Minibatch[ 901-1000]: loss = 0.340845 * 100, metric = 10.61% * 100;
 Minibatch[1001-1100]: loss = 0.344443 * 100, metric = 10.89% * 100;
 Minibatch[1101-1200]: loss = 0.343762 * 100, metric = 10.72% * 100;
 Minibatch[1201-1300]: loss = 0.348244 * 100, metric = 10.88% * 100;
 Minibatch[1301-1400]: loss = 0.344406 * 100, metric = 10.62% * 100;
 Minibatch[1401-1500]: loss = 0.330966 * 100, metric = 10.23% * 100;
 Minibatch[1501-1600]: loss = 0.334339 * 100, metric = 10.44% * 100;
 Minibatch[1601-1700]: loss = 0.333279 * 100, metric = 10.34% * 100;
 Minibatch[1701-1800]: loss = 0.342645 * 100, metric = 10.75% * 100;
 Minibatch[1801-1900]: loss = 0.343603 * 100, metric = 10.90% * 100;
 Minibatch[1901-2000]: loss = 0.328703 * 100, metric = 10.37% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.340653 * 2000, metric = 10.68% * 2000 967.125s (  2.1 samples/s);
Finished Evaluation [10]: Minibatch[1-2000]: metric = 16.84% * 2000;
 Minibatch[   1- 100]: loss = 0.321284 * 100, metric = 10.03% * 100;
 Minibatch[ 101- 200]: loss = 0.329857 * 100, metric = 10.36% * 100;
 Minibatch[ 201- 300]: loss = 0.339400 * 100, metric = 10.73% * 100;
 Minibatch[ 301- 400]: loss = 0.327952 * 100, metric = 10.30% * 100;
 Minibatch[ 401- 500]: loss = 0.333648 * 100, metric = 10.51% * 100;
 Minibatch[ 501- 600]: loss = 0.331893 * 100, metric = 10.45% * 100;
 Minibatch[ 601- 700]: loss = 0.326072 * 100, metric = 10.08% * 100;
 Minibatch[ 701- 800]: loss = 0.337201 * 100, metric = 10.66% * 100;
 Minibatch[ 801- 900]: loss = 0.329678 * 100, metric = 10.08% * 100;
 Minibatch[ 901-1000]: loss = 0.338936 * 100, metric = 10.62% * 100;
 Minibatch[1001-1100]: loss = 0.329196 * 100, metric = 10.12% * 100;
 Minibatch[1101-1200]: loss = 0.331348 * 100, metric = 10.50% * 100;
 Minibatch[1201-1300]: loss = 0.318830 * 100, metric = 10.03% * 100;
 Minibatch[1301-1400]: loss = 0.315759 * 100, metric = 9.95% * 100;
 Minibatch[1401-1500]: loss = 0.333598 * 100, metric = 10.64% * 100;
 Minibatch[1501-1600]: loss = 0.317489 * 100, metric = 9.98% * 100;
 Minibatch[1601-1700]: loss = 0.323717 * 100, metric = 10.24% * 100;
 Minibatch[1701-1800]: loss = 0.324705 * 100, metric = 10.18% * 100;
 Minibatch[1801-1900]: loss = 0.330948 * 100, metric = 10.39% * 100;
 Minibatch[1901-2000]: loss = 0.322777 * 100, metric = 10.19% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.328214 * 2000, metric = 10.30% * 2000 1051.436s (  1.9 samples/s);
Finished Evaluation [11]: Minibatch[1-2000]: metric = 17.33% * 2000;
 Minibatch[   1- 100]: loss = 0.311153 * 100, metric = 9.66% * 100;
 Minibatch[ 101- 200]: loss = 0.309906 * 100, metric = 9.62% * 100;
 Minibatch[ 201- 300]: loss = 0.316231 * 100, metric = 10.07% * 100;
 Minibatch[ 301- 400]: loss = 0.340848 * 100, metric = 10.80% * 100;
 Minibatch[ 401- 500]: loss = 0.315437 * 100, metric = 9.95% * 100;
 Minibatch[ 501- 600]: loss = 0.305511 * 100, metric = 9.41% * 100;
 Minibatch[ 601- 700]: loss = 0.309489 * 100, metric = 9.79% * 100;
 Minibatch[ 701- 800]: loss = 0.315858 * 100, metric = 9.90% * 100;
 Minibatch[ 801- 900]: loss = 0.314587 * 100, metric = 9.77% * 100;
 Minibatch[ 901-1000]: loss = 0.322985 * 100, metric = 9.99% * 100;
 Minibatch[1001-1100]: loss = 0.323714 * 100, metric = 10.24% * 100;
 Minibatch[1101-1200]: loss = 0.325718 * 100, metric = 10.11% * 100;
 Minibatch[1201-1300]: loss = 0.325558 * 100, metric = 10.26% * 100;
 Minibatch[1301-1400]: loss = 0.313329 * 100, metric = 10.02% * 100;
 Minibatch[1401-1500]: loss = 0.322625 * 100, metric = 10.19% * 100;
 Minibatch[1501-1600]: loss = 0.302372 * 100, metric = 9.53% * 100;
 Minibatch[1601-1700]: loss = 0.321913 * 100, metric = 10.23% * 100;
 Minibatch[1701-1800]: loss = 0.304036 * 100, metric = 9.37% * 100;
 Minibatch[1801-1900]: loss = 0.318447 * 100, metric = 10.05% * 100;
 Minibatch[1901-2000]: loss = 0.326760 * 100, metric = 10.17% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.317324 * 2000, metric = 9.96% * 2000 1077.316s (  1.9 samples/s);
Finished Evaluation [12]: Minibatch[1-2000]: metric = 17.74% * 2000;
 Minibatch[   1- 100]: loss = 0.316561 * 100, metric = 10.02% * 100;
 Minibatch[ 101- 200]: loss = 0.320247 * 100, metric = 10.14% * 100;
 Minibatch[ 201- 300]: loss = 0.315738 * 100, metric = 10.04% * 100;
 Minibatch[ 301- 400]: loss = 0.321951 * 100, metric = 9.97% * 100;
 Minibatch[ 401- 500]: loss = 0.325514 * 100, metric = 10.63% * 100;
 Minibatch[ 501- 600]: loss = 0.326318 * 100, metric = 10.62% * 100;
 Minibatch[ 601- 700]: loss = 0.309416 * 100, metric = 9.28% * 100;
 Minibatch[ 701- 800]: loss = 0.300276 * 100, metric = 9.34% * 100;
 Minibatch[ 801- 900]: loss = 0.305569 * 100, metric = 9.63% * 100;
 Minibatch[ 901-1000]: loss = 0.320183 * 100, metric = 10.23% * 100;
 Minibatch[1001-1100]: loss = 0.320392 * 100, metric = 10.12% * 100;
 Minibatch[1101-1200]: loss = 0.312505 * 100, metric = 9.78% * 100;
 Minibatch[1201-1300]: loss = 0.315926 * 100, metric = 10.06% * 100;
 Minibatch[1301-1400]: loss = 0.308652 * 100, metric = 9.70% * 100;
 Minibatch[1401-1500]: loss = 0.308580 * 100, metric = 9.85% * 100;
 Minibatch[1501-1600]: loss = 0.302659 * 100, metric = 9.37% * 100;
 Minibatch[1601-1700]: loss = 0.299697 * 100, metric = 9.32% * 100;
 Minibatch[1701-1800]: loss = 0.311321 * 100, metric = 9.58% * 100;
 Minibatch[1801-1900]: loss = 0.297681 * 100, metric = 9.24% * 100;
 Minibatch[1901-2000]: loss = 0.312751 * 100, metric = 9.86% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.312597 * 2000, metric = 9.84% * 2000 994.091s (  2.0 samples/s);
Finished Evaluation [13]: Minibatch[1-2000]: metric = 19.01% * 2000;
 Minibatch[   1- 100]: loss = 0.301491 * 100, metric = 9.19% * 100;
 Minibatch[ 101- 200]: loss = 0.303293 * 100, metric = 9.38% * 100;
 Minibatch[ 201- 300]: loss = 0.310454 * 100, metric = 9.74% * 100;
 Minibatch[ 301- 400]: loss = 0.304852 * 100, metric = 9.41% * 100;
 Minibatch[ 401- 500]: loss = 0.305786 * 100, metric = 9.54% * 100;
 Minibatch[ 501- 600]: loss = 0.301683 * 100, metric = 9.41% * 100;
 Minibatch[ 601- 700]: loss = 0.308224 * 100, metric = 9.57% * 100;
 Minibatch[ 701- 800]: loss = 0.318227 * 100, metric = 10.11% * 100;
 Minibatch[ 801- 900]: loss = 0.318024 * 100, metric = 10.08% * 100;
 Minibatch[ 901-1000]: loss = 0.311771 * 100, metric = 9.92% * 100;
 Minibatch[1001-1100]: loss = 0.310456 * 100, metric = 9.77% * 100;
 Minibatch[1101-1200]: loss = 0.296871 * 100, metric = 9.18% * 100;
 Minibatch[1201-1300]: loss = 0.290257 * 100, metric = 9.01% * 100;
 Minibatch[1301-1400]: loss = 0.303032 * 100, metric = 9.68% * 100;
 Minibatch[1401-1500]: loss = 0.305334 * 100, metric = 9.72% * 100;
 Minibatch[1501-1600]: loss = 0.293881 * 100, metric = 9.25% * 100;
 Minibatch[1601-1700]: loss = 0.302740 * 100, metric = 9.49% * 100;
 Minibatch[1701-1800]: loss = 0.295338 * 100, metric = 9.24% * 100;
 Minibatch[1801-1900]: loss = 0.298148 * 100, metric = 9.29% * 100;
 Minibatch[1901-2000]: loss = 0.303293 * 100, metric = 9.58% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.304158 * 2000, metric = 9.53% * 2000 1082.325s (  1.8 samples/s);
Finished Evaluation [14]: Minibatch[1-2000]: metric = 18.29% * 2000;
 Minibatch[   1- 100]: loss = 0.293108 * 100, metric = 9.17% * 100;
 Minibatch[ 101- 200]: loss = 0.299650 * 100, metric = 9.50% * 100;
 Minibatch[ 201- 300]: loss = 0.299368 * 100, metric = 9.33% * 100;
 Minibatch[ 301- 400]: loss = 0.287784 * 100, metric = 8.94% * 100;
 Minibatch[ 401- 500]: loss = 0.293931 * 100, metric = 9.25% * 100;
 Minibatch[ 501- 600]: loss = 0.287096 * 100, metric = 8.83% * 100;
 Minibatch[ 601- 700]: loss = 0.286269 * 100, metric = 9.03% * 100;
 Minibatch[ 701- 800]: loss = 0.303045 * 100, metric = 9.54% * 100;
 Minibatch[ 801- 900]: loss = 0.313185 * 100, metric = 9.96% * 100;
 Minibatch[ 901-1000]: loss = 0.298464 * 100, metric = 9.39% * 100;
 Minibatch[1001-1100]: loss = 0.302903 * 100, metric = 9.62% * 100;
 Minibatch[1101-1200]: loss = 0.290214 * 100, metric = 8.96% * 100;
 Minibatch[1201-1300]: loss = 0.283986 * 100, metric = 8.79% * 100;
 Minibatch[1301-1400]: loss = 0.310826 * 100, metric = 9.86% * 100;
 Minibatch[1401-1500]: loss = 0.280337 * 100, metric = 8.61% * 100;
 Minibatch[1501-1600]: loss = 0.290272 * 100, metric = 9.10% * 100;
 Minibatch[1601-1700]: loss = 0.289716 * 100, metric = 9.15% * 100;
 Minibatch[1701-1800]: loss = 0.276732 * 100, metric = 8.44% * 100;
 Minibatch[1801-1900]: loss = 0.289207 * 100, metric = 9.06% * 100;
 Minibatch[1901-2000]: loss = 0.283837 * 100, metric = 8.86% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.292996 * 2000, metric = 9.17% * 2000 945.061s (  2.1 samples/s);
Finished Evaluation [15]: Minibatch[1-2000]: metric = 15.73% * 2000;
 Minibatch[   1- 100]: loss = 0.299449 * 100, metric = 9.53% * 100;
 Minibatch[ 101- 200]: loss = 0.295597 * 100, metric = 9.30% * 100;
 Minibatch[ 201- 300]: loss = 0.291635 * 100, metric = 9.17% * 100;
 Minibatch[ 301- 400]: loss = 0.293037 * 100, metric = 9.18% * 100;
 Minibatch[ 401- 500]: loss = 0.279626 * 100, metric = 8.61% * 100;
 Minibatch[ 501- 600]: loss = 0.285867 * 100, metric = 8.69% * 100;
 Minibatch[ 601- 700]: loss = 0.284080 * 100, metric = 9.02% * 100;
 Minibatch[ 701- 800]: loss = 0.281219 * 100, metric = 8.71% * 100;
 Minibatch[ 801- 900]: loss = 0.274063 * 100, metric = 8.61% * 100;
 Minibatch[ 901-1000]: loss = 0.284690 * 100, metric = 9.04% * 100;
 Minibatch[1001-1100]: loss = 0.272562 * 100, metric = 8.57% * 100;
 Minibatch[1101-1200]: loss = 0.280870 * 100, metric = 8.79% * 100;
 Minibatch[1201-1300]: loss = 0.276726 * 100, metric = 8.63% * 100;
 Minibatch[1301-1400]: loss = 0.283430 * 100, metric = 8.78% * 100;
 Minibatch[1401-1500]: loss = 0.272021 * 100, metric = 8.51% * 100;
 Minibatch[1501-1600]: loss = 0.276511 * 100, metric = 8.77% * 100;
 Minibatch[1601-1700]: loss = 0.284356 * 100, metric = 8.82% * 100;
 Minibatch[1701-1800]: loss = 0.290145 * 100, metric = 8.95% * 100;
 Minibatch[1801-1900]: loss = 0.290276 * 100, metric = 9.12% * 100;
 Minibatch[1901-2000]: loss = 0.275551 * 100, metric = 8.75% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.283586 * 2000, metric = 8.88% * 2000 943.269s (  2.1 samples/s);
Finished Evaluation [16]: Minibatch[1-2000]: metric = 15.53% * 2000;
 Minibatch[   1- 100]: loss = 0.265430 * 100, metric = 8.18% * 100;
 Minibatch[ 101- 200]: loss = 0.285921 * 100, metric = 9.04% * 100;
 Minibatch[ 201- 300]: loss = 0.289956 * 100, metric = 9.09% * 100;
 Minibatch[ 301- 400]: loss = 0.277012 * 100, metric = 8.71% * 100;
 Minibatch[ 401- 500]: loss = 0.281110 * 100, metric = 8.69% * 100;
 Minibatch[ 501- 600]: loss = 0.268416 * 100, metric = 8.43% * 100;
 Minibatch[ 601- 700]: loss = 0.263329 * 100, metric = 8.18% * 100;
 Minibatch[ 701- 800]: loss = 0.270610 * 100, metric = 8.32% * 100;
 Minibatch[ 801- 900]: loss = 0.276456 * 100, metric = 8.57% * 100;
 Minibatch[ 901-1000]: loss = 0.271170 * 100, metric = 8.57% * 100;
 Minibatch[1001-1100]: loss = 0.267596 * 100, metric = 8.32% * 100;
 Minibatch[1101-1200]: loss = 0.285265 * 100, metric = 8.88% * 100;
 Minibatch[1201-1300]: loss = 0.279148 * 100, metric = 8.77% * 100;
 Minibatch[1301-1400]: loss = 0.268363 * 100, metric = 8.54% * 100;
 Minibatch[1401-1500]: loss = 0.276261 * 100, metric = 8.74% * 100;
 Minibatch[1501-1600]: loss = 0.275836 * 100, metric = 8.76% * 100;
 Minibatch[1601-1700]: loss = 0.279205 * 100, metric = 8.58% * 100;
 Minibatch[1701-1800]: loss = 0.272792 * 100, metric = 8.52% * 100;
 Minibatch[1801-1900]: loss = 0.289406 * 100, metric = 9.15% * 100;
 Minibatch[1901-2000]: loss = 0.287298 * 100, metric = 8.99% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.276529 * 2000, metric = 8.65% * 2000 938.559s (  2.1 samples/s);
Finished Evaluation [17]: Minibatch[1-2000]: metric = 15.64% * 2000;
 Minibatch[   1- 100]: loss = 0.264423 * 100, metric = 8.24% * 100;
 Minibatch[ 101- 200]: loss = 0.283268 * 100, metric = 8.83% * 100;
 Minibatch[ 201- 300]: loss = 0.269761 * 100, metric = 8.57% * 100;
 Minibatch[ 301- 400]: loss = 0.274724 * 100, metric = 8.44% * 100;
 Minibatch[ 401- 500]: loss = 0.268305 * 100, metric = 8.48% * 100;
 Minibatch[ 501- 600]: loss = 0.272651 * 100, metric = 8.45% * 100;
 Minibatch[ 601- 700]: loss = 0.274455 * 100, metric = 8.65% * 100;
 Minibatch[ 701- 800]: loss = 0.262123 * 100, metric = 8.28% * 100;
 Minibatch[ 801- 900]: loss = 0.275726 * 100, metric = 8.51% * 100;
 Minibatch[ 901-1000]: loss = 0.277787 * 100, metric = 8.61% * 100;
 Minibatch[1001-1100]: loss = 0.282592 * 100, metric = 8.94% * 100;
 Minibatch[1101-1200]: loss = 0.273655 * 100, metric = 8.54% * 100;
 Minibatch[1201-1300]: loss = 0.283260 * 100, metric = 8.89% * 100;
 Minibatch[1301-1400]: loss = 0.281750 * 100, metric = 8.71% * 100;
 Minibatch[1401-1500]: loss = 0.258546 * 100, metric = 8.03% * 100;
 Minibatch[1501-1600]: loss = 0.264252 * 100, metric = 8.19% * 100;
 Minibatch[1601-1700]: loss = 0.259032 * 100, metric = 7.99% * 100;
 Minibatch[1701-1800]: loss = 0.262785 * 100, metric = 8.26% * 100;
 Minibatch[1801-1900]: loss = 0.258372 * 100, metric = 8.11% * 100;
 Minibatch[1901-2000]: loss = 0.259167 * 100, metric = 7.93% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.270332 * 2000, metric = 8.43% * 2000 981.722s (  2.0 samples/s);
Finished Evaluation [18]: Minibatch[1-2000]: metric = 16.17% * 2000;
 Minibatch[   1- 100]: loss = 0.273869 * 100, metric = 8.42% * 100;
 Minibatch[ 101- 200]: loss = 0.273306 * 100, metric = 8.55% * 100;
 Minibatch[ 201- 300]: loss = 0.254534 * 100, metric = 7.84% * 100;
 Minibatch[ 301- 400]: loss = 0.266572 * 100, metric = 8.14% * 100;
 Minibatch[ 401- 500]: loss = 0.262889 * 100, metric = 7.94% * 100;
 Minibatch[ 501- 600]: loss = 0.258639 * 100, metric = 7.89% * 100;
 Minibatch[ 601- 700]: loss = 0.264140 * 100, metric = 8.26% * 100;
 Minibatch[ 701- 800]: loss = 0.252732 * 100, metric = 7.82% * 100;
 Minibatch[ 801- 900]: loss = 0.282092 * 100, metric = 8.73% * 100;
 Minibatch[ 901-1000]: loss = 0.258371 * 100, metric = 8.15% * 100;
 Minibatch[1001-1100]: loss = 0.269886 * 100, metric = 8.51% * 100;
 Minibatch[1101-1200]: loss = 0.262506 * 100, metric = 8.32% * 100;
 Minibatch[1201-1300]: loss = 0.265770 * 100, metric = 8.27% * 100;
 Minibatch[1301-1400]: loss = 0.254260 * 100, metric = 7.88% * 100;
 Minibatch[1401-1500]: loss = 0.266836 * 100, metric = 8.40% * 100;
 Minibatch[1501-1600]: loss = 0.262522 * 100, metric = 8.28% * 100;
 Minibatch[1601-1700]: loss = 0.258565 * 100, metric = 8.36% * 100;
 Minibatch[1701-1800]: loss = 0.250421 * 100, metric = 7.85% * 100;
 Minibatch[1801-1900]: loss = 0.251939 * 100, metric = 7.82% * 100;
 Minibatch[1901-2000]: loss = 0.249017 * 100, metric = 7.67% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.261943 * 2000, metric = 8.16% * 2000 930.316s (  2.1 samples/s);
Finished Evaluation [19]: Minibatch[1-2000]: metric = 16.01% * 2000;
 Minibatch[   1- 100]: loss = 0.257361 * 100, metric = 7.92% * 100;
 Minibatch[ 101- 200]: loss = 0.259035 * 100, metric = 8.02% * 100;
 Minibatch[ 201- 300]: loss = 0.254338 * 100, metric = 7.85% * 100;
 Minibatch[ 301- 400]: loss = 0.267635 * 100, metric = 7.97% * 100;
 Minibatch[ 401- 500]: loss = 0.257342 * 100, metric = 8.05% * 100;
 Minibatch[ 501- 600]: loss = 0.263509 * 100, metric = 8.35% * 100;
 Minibatch[ 601- 700]: loss = 0.265432 * 100, metric = 8.18% * 100;
 Minibatch[ 701- 800]: loss = 0.259071 * 100, metric = 8.12% * 100;
 Minibatch[ 801- 900]: loss = 0.265071 * 100, metric = 8.12% * 100;
 Minibatch[ 901-1000]: loss = 0.263237 * 100, metric = 8.16% * 100;
 Minibatch[1001-1100]: loss = 0.247838 * 100, metric = 7.67% * 100;
 Minibatch[1101-1200]: loss = 0.260017 * 100, metric = 8.13% * 100;
 Minibatch[1201-1300]: loss = 0.269207 * 100, metric = 8.30% * 100;
 Minibatch[1301-1400]: loss = 0.260554 * 100, metric = 8.09% * 100;
 Minibatch[1401-1500]: loss = 0.253698 * 100, metric = 7.74% * 100;
 Minibatch[1501-1600]: loss = 0.268162 * 100, metric = 8.20% * 100;
 Minibatch[1601-1700]: loss = 0.259169 * 100, metric = 8.01% * 100;
 Minibatch[1701-1800]: loss = 0.266902 * 100, metric = 8.39% * 100;
 Minibatch[1801-1900]: loss = 0.261893 * 100, metric = 8.11% * 100;
 Minibatch[1901-2000]: loss = 0.255034 * 100, metric = 7.98% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.260725 * 2000, metric = 8.07% * 2000 923.214s (  2.2 samples/s);
Finished Evaluation [20]: Minibatch[1-2000]: metric = 15.87% * 2000;
 Minibatch[   1- 100]: loss = 0.264452 * 100, metric = 8.29% * 100;
 Minibatch[ 101- 200]: loss = 0.265450 * 100, metric = 8.45% * 100;
 Minibatch[ 201- 300]: loss = 0.259414 * 100, metric = 8.12% * 100;
 Minibatch[ 301- 400]: loss = 0.263041 * 100, metric = 8.31% * 100;
 Minibatch[ 401- 500]: loss = 0.253201 * 100, metric = 7.88% * 100;
 Minibatch[ 501- 600]: loss = 0.253943 * 100, metric = 8.00% * 100;
 Minibatch[ 601- 700]: loss = 0.254507 * 100, metric = 7.94% * 100;
 Minibatch[ 701- 800]: loss = 0.234567 * 100, metric = 7.46% * 100;
 Minibatch[ 801- 900]: loss = 0.257911 * 100, metric = 7.97% * 100;
 Minibatch[ 901-1000]: loss = 0.248422 * 100, metric = 7.76% * 100;
 Minibatch[1001-1100]: loss = 0.254370 * 100, metric = 7.86% * 100;
 Minibatch[1101-1200]: loss = 0.251523 * 100, metric = 7.50% * 100;
 Minibatch[1201-1300]: loss = 0.255481 * 100, metric = 7.84% * 100;
 Minibatch[1301-1400]: loss = 0.242469 * 100, metric = 7.47% * 100;
 Minibatch[1401-1500]: loss = 0.257887 * 100, metric = 8.00% * 100;
 Minibatch[1501-1600]: loss = 0.264632 * 100, metric = 8.55% * 100;
 Minibatch[1601-1700]: loss = 0.250434 * 100, metric = 7.81% * 100;
 Minibatch[1701-1800]: loss = 0.249756 * 100, metric = 7.81% * 100;
 Minibatch[1801-1900]: loss = 0.262184 * 100, metric = 8.18% * 100;
 Minibatch[1901-2000]: loss = 0.247464 * 100, metric = 7.46% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.254555 * 2000, metric = 7.93% * 2000 921.828s (  2.2 samples/s);
Finished Evaluation [21]: Minibatch[1-2000]: metric = 14.41% * 2000;
0.44450947919487954
 Minibatch[   1- 100]: loss = 0.260116 * 100, metric = 8.05% * 100;
 Minibatch[ 101- 200]: loss = 0.262072 * 100, metric = 8.03% * 100;
 Minibatch[ 201- 300]: loss = 0.254815 * 100, metric = 7.97% * 100;
 Minibatch[ 301- 400]: loss = 0.255127 * 100, metric = 8.02% * 100;
 Minibatch[ 401- 500]: loss = 0.251689 * 100, metric = 7.86% * 100;
 Minibatch[ 501- 600]: loss = 0.255274 * 100, metric = 7.97% * 100;
 Minibatch[ 601- 700]: loss = 0.246955 * 100, metric = 7.84% * 100;
 Minibatch[ 701- 800]: loss = 0.254565 * 100, metric = 7.99% * 100;
 Minibatch[ 801- 900]: loss = 0.254754 * 100, metric = 7.99% * 100;
 Minibatch[ 901-1000]: loss = 0.254544 * 100, metric = 7.98% * 100;
 Minibatch[1001-1100]: loss = 0.242253 * 100, metric = 7.51% * 100;
 Minibatch[1101-1200]: loss = 0.228224 * 100, metric = 7.05% * 100;
 Minibatch[1201-1300]: loss = 0.248284 * 100, metric = 7.80% * 100;
 Minibatch[1301-1400]: loss = 0.249585 * 100, metric = 7.66% * 100;
 Minibatch[1401-1500]: loss = 0.241340 * 100, metric = 7.49% * 100;
 Minibatch[1501-1600]: loss = 0.238336 * 100, metric = 7.34% * 100;
 Minibatch[1601-1700]: loss = 0.245129 * 100, metric = 7.69% * 100;
 Minibatch[1701-1800]: loss = 0.243990 * 100, metric = 7.63% * 100;
 Minibatch[1801-1900]: loss = 0.247437 * 100, metric = 7.79% * 100;
 Minibatch[1901-2000]: loss = 0.245528 * 100, metric = 7.48% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.249001 * 2000, metric = 7.76% * 2000 916.356s (  2.2 samples/s);
Finished Evaluation [22]: Minibatch[1-2000]: metric = 15.11% * 2000;
 Minibatch[   1- 100]: loss = 0.253350 * 100, metric = 7.74% * 100;
 Minibatch[ 101- 200]: loss = 0.253359 * 100, metric = 7.90% * 100;
 Minibatch[ 201- 300]: loss = 0.246678 * 100, metric = 7.84% * 100;
 Minibatch[ 301- 400]: loss = 0.255223 * 100, metric = 8.03% * 100;
 Minibatch[ 401- 500]: loss = 0.259552 * 100, metric = 8.25% * 100;
 Minibatch[ 501- 600]: loss = 0.248878 * 100, metric = 7.60% * 100;
 Minibatch[ 601- 700]: loss = 0.246876 * 100, metric = 7.79% * 100;
 Minibatch[ 701- 800]: loss = 0.231146 * 100, metric = 7.01% * 100;
 Minibatch[ 801- 900]: loss = 0.241295 * 100, metric = 7.60% * 100;
 Minibatch[ 901-1000]: loss = 0.250215 * 100, metric = 7.88% * 100;
 Minibatch[1001-1100]: loss = 0.244654 * 100, metric = 7.62% * 100;
 Minibatch[1101-1200]: loss = 0.244373 * 100, metric = 7.65% * 100;
 Minibatch[1201-1300]: loss = 0.242349 * 100, metric = 7.77% * 100;
 Minibatch[1301-1400]: loss = 0.249212 * 100, metric = 7.89% * 100;
 Minibatch[1401-1500]: loss = 0.236062 * 100, metric = 7.34% * 100;
 Minibatch[1501-1600]: loss = 0.241165 * 100, metric = 7.62% * 100;
 Minibatch[1601-1700]: loss = 0.238817 * 100, metric = 7.43% * 100;
 Minibatch[1701-1800]: loss = 0.249118 * 100, metric = 7.71% * 100;
 Minibatch[1801-1900]: loss = 0.250968 * 100, metric = 7.92% * 100;
 Minibatch[1901-2000]: loss = 0.245060 * 100, metric = 7.70% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.246417 * 2000, metric = 7.71% * 2000 915.988s (  2.2 samples/s);
Finished Evaluation [23]: Minibatch[1-2000]: metric = 15.00% * 2000;
 Minibatch[   1- 100]: loss = 0.231880 * 100, metric = 7.33% * 100;
 Minibatch[ 101- 200]: loss = 0.246474 * 100, metric = 7.88% * 100;
 Minibatch[ 201- 300]: loss = 0.233832 * 100, metric = 7.42% * 100;
 Minibatch[ 301- 400]: loss = 0.237756 * 100, metric = 7.51% * 100;
 Minibatch[ 401- 500]: loss = 0.248347 * 100, metric = 7.85% * 100;
 Minibatch[ 501- 600]: loss = 0.234045 * 100, metric = 7.33% * 100;
 Minibatch[ 601- 700]: loss = 0.244378 * 100, metric = 7.49% * 100;
 Minibatch[ 701- 800]: loss = 0.239809 * 100, metric = 7.49% * 100;
 Minibatch[ 801- 900]: loss = 0.257450 * 100, metric = 8.31% * 100;
 Minibatch[ 901-1000]: loss = 0.241700 * 100, metric = 7.76% * 100;
 Minibatch[1001-1100]: loss = 0.242731 * 100, metric = 7.68% * 100;
 Minibatch[1101-1200]: loss = 0.258486 * 100, metric = 8.03% * 100;
 Minibatch[1201-1300]: loss = 0.242450 * 100, metric = 7.68% * 100;
 Minibatch[1301-1400]: loss = 0.237319 * 100, metric = 7.34% * 100;
 Minibatch[1401-1500]: loss = 0.237586 * 100, metric = 7.49% * 100;
 Minibatch[1501-1600]: loss = 0.246795 * 100, metric = 7.68% * 100;
 Minibatch[1601-1700]: loss = 0.232462 * 100, metric = 7.21% * 100;
 Minibatch[1701-1800]: loss = 0.237204 * 100, metric = 7.29% * 100;
 Minibatch[1801-1900]: loss = 0.242717 * 100, metric = 7.64% * 100;
 Minibatch[1901-2000]: loss = 0.245206 * 100, metric = 7.77% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.241931 * 2000, metric = 7.61% * 2000 917.706s (  2.2 samples/s);
Finished Evaluation [24]: Minibatch[1-2000]: metric = 15.29% * 2000;
 Minibatch[   1- 100]: loss = 0.245394 * 100, metric = 7.46% * 100;
 Minibatch[ 101- 200]: loss = 0.244798 * 100, metric = 7.66% * 100;
 Minibatch[ 201- 300]: loss = 0.244088 * 100, metric = 7.81% * 100;
 Minibatch[ 301- 400]: loss = 0.239131 * 100, metric = 7.62% * 100;
 Minibatch[ 401- 500]: loss = 0.243087 * 100, metric = 7.43% * 100;
 Minibatch[ 501- 600]: loss = 0.236468 * 100, metric = 7.35% * 100;
 Minibatch[ 601- 700]: loss = 0.243364 * 100, metric = 7.69% * 100;
 Minibatch[ 701- 800]: loss = 0.233968 * 100, metric = 7.21% * 100;
 Minibatch[ 801- 900]: loss = 0.230037 * 100, metric = 7.16% * 100;
 Minibatch[ 901-1000]: loss = 0.234901 * 100, metric = 7.20% * 100;
 Minibatch[1001-1100]: loss = 0.235997 * 100, metric = 7.29% * 100;
 Minibatch[1101-1200]: loss = 0.244036 * 100, metric = 7.55% * 100;
 Minibatch[1201-1300]: loss = 0.256052 * 100, metric = 8.10% * 100;
 Minibatch[1301-1400]: loss = 0.240363 * 100, metric = 7.43% * 100;
 Minibatch[1401-1500]: loss = 0.226311 * 100, metric = 7.01% * 100;
 Minibatch[1501-1600]: loss = 0.245686 * 100, metric = 7.79% * 100;
 Minibatch[1601-1700]: loss = 0.234801 * 100, metric = 7.20% * 100;
 Minibatch[1701-1800]: loss = 0.232081 * 100, metric = 7.12% * 100;
 Minibatch[1801-1900]: loss = 0.227693 * 100, metric = 6.99% * 100;
 Minibatch[1901-2000]: loss = 0.217452 * 100, metric = 6.69% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.237785 * 2000, metric = 7.39% * 2000 915.277s (  2.2 samples/s);
Finished Evaluation [25]: Minibatch[1-2000]: metric = 14.91% * 2000;
 Minibatch[   1- 100]: loss = 0.233374 * 100, metric = 7.14% * 100;
 Minibatch[ 101- 200]: loss = 0.222287 * 100, metric = 6.93% * 100;
 Minibatch[ 201- 300]: loss = 0.232658 * 100, metric = 7.22% * 100;
 Minibatch[ 301- 400]: loss = 0.225919 * 100, metric = 6.99% * 100;
 Minibatch[ 401- 500]: loss = 0.237383 * 100, metric = 7.32% * 100;
 Minibatch[ 501- 600]: loss = 0.230941 * 100, metric = 7.20% * 100;
 Minibatch[ 601- 700]: loss = 0.241523 * 100, metric = 7.59% * 100;
 Minibatch[ 701- 800]: loss = 0.230797 * 100, metric = 7.27% * 100;
 Minibatch[ 801- 900]: loss = 0.218947 * 100, metric = 6.82% * 100;
 Minibatch[ 901-1000]: loss = 0.227769 * 100, metric = 6.91% * 100;
 Minibatch[1001-1100]: loss = 0.237279 * 100, metric = 7.63% * 100;
 Minibatch[1101-1200]: loss = 0.238751 * 100, metric = 7.45% * 100;
 Minibatch[1201-1300]: loss = 0.232069 * 100, metric = 7.19% * 100;
 Minibatch[1301-1400]: loss = 0.223298 * 100, metric = 6.88% * 100;
 Minibatch[1401-1500]: loss = 0.232943 * 100, metric = 7.27% * 100;
 Minibatch[1501-1600]: loss = 0.216879 * 100, metric = 6.66% * 100;
 Minibatch[1601-1700]: loss = 0.242827 * 100, metric = 7.40% * 100;
 Minibatch[1701-1800]: loss = 0.243533 * 100, metric = 7.53% * 100;
 Minibatch[1801-1900]: loss = 0.229641 * 100, metric = 7.10% * 100;
 Minibatch[1901-2000]: loss = 0.230713 * 100, metric = 7.24% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.231477 * 2000, metric = 7.19% * 2000 912.967s (  2.2 samples/s);
Finished Evaluation [26]: Minibatch[1-2000]: metric = 16.53% * 2000;
 Minibatch[   1- 100]: loss = 0.233024 * 100, metric = 7.22% * 100;
 Minibatch[ 101- 200]: loss = 0.235051 * 100, metric = 7.12% * 100;
 Minibatch[ 201- 300]: loss = 0.229674 * 100, metric = 7.23% * 100;
 Minibatch[ 301- 400]: loss = 0.226237 * 100, metric = 7.16% * 100;
 Minibatch[ 401- 500]: loss = 0.228847 * 100, metric = 7.16% * 100;
 Minibatch[ 501- 600]: loss = 0.224488 * 100, metric = 6.91% * 100;
 Minibatch[ 601- 700]: loss = 0.222601 * 100, metric = 6.78% * 100;
 Minibatch[ 701- 800]: loss = 0.224727 * 100, metric = 7.00% * 100;
 Minibatch[ 801- 900]: loss = 0.237227 * 100, metric = 7.23% * 100;
 Minibatch[ 901-1000]: loss = 0.235537 * 100, metric = 7.61% * 100;
 Minibatch[1001-1100]: loss = 0.223717 * 100, metric = 7.02% * 100;
 Minibatch[1101-1200]: loss = 0.234528 * 100, metric = 7.35% * 100;
 Minibatch[1201-1300]: loss = 0.229368 * 100, metric = 7.08% * 100;
 Minibatch[1301-1400]: loss = 0.236260 * 100, metric = 7.58% * 100;
 Minibatch[1401-1500]: loss = 0.229253 * 100, metric = 7.10% * 100;
 Minibatch[1501-1600]: loss = 0.226740 * 100, metric = 6.95% * 100;
 Minibatch[1601-1700]: loss = 0.212283 * 100, metric = 6.62% * 100;
 Minibatch[1701-1800]: loss = 0.222442 * 100, metric = 6.67% * 100;
 Minibatch[1801-1900]: loss = 0.219912 * 100, metric = 6.78% * 100;
 Minibatch[1901-2000]: loss = 0.228218 * 100, metric = 7.23% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.228007 * 2000, metric = 7.09% * 2000 913.428s (  2.2 samples/s);
Finished Evaluation [27]: Minibatch[1-2000]: metric = 14.16% * 2000;
 Minibatch[   1- 100]: loss = 0.231792 * 100, metric = 7.25% * 100;
 Minibatch[ 101- 200]: loss = 0.222564 * 100, metric = 6.81% * 100;
 Minibatch[ 201- 300]: loss = 0.231355 * 100, metric = 7.17% * 100;
 Minibatch[ 301- 400]: loss = 0.228207 * 100, metric = 6.90% * 100;
 Minibatch[ 401- 500]: loss = 0.232419 * 100, metric = 7.21% * 100;
 Minibatch[ 501- 600]: loss = 0.244540 * 100, metric = 7.57% * 100;
 Minibatch[ 601- 700]: loss = 0.223198 * 100, metric = 7.08% * 100;
 Minibatch[ 701- 800]: loss = 0.214432 * 100, metric = 6.73% * 100;
 Minibatch[ 801- 900]: loss = 0.226055 * 100, metric = 7.16% * 100;
 Minibatch[ 901-1000]: loss = 0.233543 * 100, metric = 7.24% * 100;
 Minibatch[1001-1100]: loss = 0.222010 * 100, metric = 6.87% * 100;
 Minibatch[1101-1200]: loss = 0.219714 * 100, metric = 6.84% * 100;
 Minibatch[1201-1300]: loss = 0.226721 * 100, metric = 6.96% * 100;
 Minibatch[1301-1400]: loss = 0.222350 * 100, metric = 7.02% * 100;
 Minibatch[1401-1500]: loss = 0.229387 * 100, metric = 7.18% * 100;
 Minibatch[1501-1600]: loss = 0.221104 * 100, metric = 6.94% * 100;
 Minibatch[1601-1700]: loss = 0.222647 * 100, metric = 6.78% * 100;
 Minibatch[1701-1800]: loss = 0.221275 * 100, metric = 6.95% * 100;
 Minibatch[1801-1900]: loss = 0.226295 * 100, metric = 7.04% * 100;
 Minibatch[1901-2000]: loss = 0.221891 * 100, metric = 6.90% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.226075 * 2000, metric = 7.03% * 2000 906.582s (  2.2 samples/s);
Finished Evaluation [28]: Minibatch[1-2000]: metric = 14.75% * 2000;
 Minibatch[   1- 100]: loss = 0.211136 * 100, metric = 6.60% * 100;
 Minibatch[ 101- 200]: loss = 0.222490 * 100, metric = 7.12% * 100;
 Minibatch[ 201- 300]: loss = 0.229212 * 100, metric = 7.27% * 100;
 Minibatch[ 301- 400]: loss = 0.236591 * 100, metric = 7.35% * 100;
 Minibatch[ 401- 500]: loss = 0.217840 * 100, metric = 6.76% * 100;
 Minibatch[ 501- 600]: loss = 0.224731 * 100, metric = 7.08% * 100;
 Minibatch[ 601- 700]: loss = 0.214794 * 100, metric = 6.84% * 100;
 Minibatch[ 701- 800]: loss = 0.230732 * 100, metric = 7.18% * 100;
 Minibatch[ 801- 900]: loss = 0.216610 * 100, metric = 6.85% * 100;
 Minibatch[ 901-1000]: loss = 0.226368 * 100, metric = 7.13% * 100;
 Minibatch[1001-1100]: loss = 0.222515 * 100, metric = 7.13% * 100;
 Minibatch[1101-1200]: loss = 0.214888 * 100, metric = 6.70% * 100;
 Minibatch[1201-1300]: loss = 0.220128 * 100, metric = 6.93% * 100;
 Minibatch[1301-1400]: loss = 0.213847 * 100, metric = 6.72% * 100;
 Minibatch[1401-1500]: loss = 0.230767 * 100, metric = 7.24% * 100;
 Minibatch[1501-1600]: loss = 0.212296 * 100, metric = 6.62% * 100;
 Minibatch[1601-1700]: loss = 0.228070 * 100, metric = 7.18% * 100;
 Minibatch[1701-1800]: loss = 0.215020 * 100, metric = 6.62% * 100;
 Minibatch[1801-1900]: loss = 0.231866 * 100, metric = 7.14% * 100;
 Minibatch[1901-2000]: loss = 0.221882 * 100, metric = 6.91% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.222089 * 2000, metric = 6.97% * 2000 909.898s (  2.2 samples/s);
Finished Evaluation [29]: Minibatch[1-2000]: metric = 16.48% * 2000;
 Minibatch[   1- 100]: loss = 0.230511 * 100, metric = 7.08% * 100;
 Minibatch[ 101- 200]: loss = 0.205151 * 100, metric = 6.29% * 100;
 Minibatch[ 201- 300]: loss = 0.218158 * 100, metric = 6.80% * 100;
 Minibatch[ 301- 400]: loss = 0.224830 * 100, metric = 7.07% * 100;
 Minibatch[ 401- 500]: loss = 0.218232 * 100, metric = 6.95% * 100;
 Minibatch[ 501- 600]: loss = 0.202094 * 100, metric = 6.38% * 100;
 Minibatch[ 601- 700]: loss = 0.224910 * 100, metric = 7.19% * 100;
 Minibatch[ 701- 800]: loss = 0.215196 * 100, metric = 6.76% * 100;
 Minibatch[ 801- 900]: loss = 0.226257 * 100, metric = 7.02% * 100;
 Minibatch[ 901-1000]: loss = 0.208390 * 100, metric = 6.51% * 100;
 Minibatch[1001-1100]: loss = 0.220825 * 100, metric = 6.89% * 100;
 Minibatch[1101-1200]: loss = 0.225554 * 100, metric = 6.99% * 100;
 Minibatch[1201-1300]: loss = 0.216432 * 100, metric = 6.67% * 100;
 Minibatch[1301-1400]: loss = 0.216358 * 100, metric = 6.75% * 100;
 Minibatch[1401-1500]: loss = 0.211023 * 100, metric = 6.55% * 100;
 Minibatch[1501-1600]: loss = 0.226911 * 100, metric = 7.17% * 100;
 Minibatch[1601-1700]: loss = 0.218599 * 100, metric = 6.85% * 100;
 Minibatch[1701-1800]: loss = 0.222278 * 100, metric = 7.09% * 100;
 Minibatch[1801-1900]: loss = 0.217222 * 100, metric = 6.98% * 100;
 Minibatch[1901-2000]: loss = 0.228436 * 100, metric = 7.30% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.218868 * 2000, metric = 6.87% * 2000 913.321s (  2.2 samples/s);
Finished Evaluation [30]: Minibatch[1-2000]: metric = 15.12% * 2000;
 Minibatch[   1- 100]: loss = 0.214391 * 100, metric = 6.67% * 100;
 Minibatch[ 101- 200]: loss = 0.224671 * 100, metric = 7.17% * 100;
 Minibatch[ 201- 300]: loss = 0.216213 * 100, metric = 6.71% * 100;
 Minibatch[ 301- 400]: loss = 0.216461 * 100, metric = 6.70% * 100;
 Minibatch[ 401- 500]: loss = 0.216454 * 100, metric = 6.70% * 100;
 Minibatch[ 501- 600]: loss = 0.216419 * 100, metric = 6.64% * 100;
 Minibatch[ 601- 700]: loss = 0.223546 * 100, metric = 7.06% * 100;
 Minibatch[ 701- 800]: loss = 0.221924 * 100, metric = 7.04% * 100;
 Minibatch[ 801- 900]: loss = 0.221334 * 100, metric = 7.02% * 100;
 Minibatch[ 901-1000]: loss = 0.209207 * 100, metric = 6.63% * 100;
 Minibatch[1001-1100]: loss = 0.208855 * 100, metric = 6.49% * 100;
 Minibatch[1101-1200]: loss = 0.223652 * 100, metric = 7.08% * 100;
 Minibatch[1201-1300]: loss = 0.223621 * 100, metric = 7.02% * 100;
 Minibatch[1301-1400]: loss = 0.215536 * 100, metric = 6.77% * 100;
 Minibatch[1401-1500]: loss = 0.225811 * 100, metric = 7.11% * 100;
 Minibatch[1501-1600]: loss = 0.209441 * 100, metric = 6.64% * 100;
 Minibatch[1601-1700]: loss = 0.215368 * 100, metric = 6.68% * 100;
 Minibatch[1701-1800]: loss = 0.213319 * 100, metric = 6.53% * 100;
 Minibatch[1801-1900]: loss = 0.216810 * 100, metric = 6.87% * 100;
 Minibatch[1901-2000]: loss = 0.213781 * 100, metric = 6.67% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.217341 * 2000, metric = 6.81% * 2000 900.404s (  2.2 samples/s);
Finished Evaluation [31]: Minibatch[1-2000]: metric = 15.01% * 2000;
 Minibatch[   1- 100]: loss = 0.214018 * 100, metric = 6.62% * 100;
 Minibatch[ 101- 200]: loss = 0.217768 * 100, metric = 6.69% * 100;
 Minibatch[ 201- 300]: loss = 0.226655 * 100, metric = 6.96% * 100;
 Minibatch[ 301- 400]: loss = 0.225065 * 100, metric = 6.91% * 100;
 Minibatch[ 401- 500]: loss = 0.218861 * 100, metric = 6.79% * 100;
 Minibatch[ 501- 600]: loss = 0.216931 * 100, metric = 6.89% * 100;
 Minibatch[ 601- 700]: loss = 0.212750 * 100, metric = 6.67% * 100;
 Minibatch[ 701- 800]: loss = 0.211694 * 100, metric = 6.47% * 100;
 Minibatch[ 801- 900]: loss = 0.212831 * 100, metric = 6.59% * 100;
 Minibatch[ 901-1000]: loss = 0.209457 * 100, metric = 6.58% * 100;
 Minibatch[1001-1100]: loss = 0.209250 * 100, metric = 6.44% * 100;
 Minibatch[1101-1200]: loss = 0.218584 * 100, metric = 6.91% * 100;
 Minibatch[1201-1300]: loss = 0.217263 * 100, metric = 6.85% * 100;
 Minibatch[1301-1400]: loss = 0.214059 * 100, metric = 6.78% * 100;
 Minibatch[1401-1500]: loss = 0.219668 * 100, metric = 6.92% * 100;
 Minibatch[1501-1600]: loss = 0.220821 * 100, metric = 6.75% * 100;
 Minibatch[1601-1700]: loss = 0.208235 * 100, metric = 6.46% * 100;
 Minibatch[1701-1800]: loss = 0.223999 * 100, metric = 7.05% * 100;
 Minibatch[1801-1900]: loss = 0.214213 * 100, metric = 6.69% * 100;
 Minibatch[1901-2000]: loss = 0.222529 * 100, metric = 7.20% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.216733 * 2000, metric = 6.76% * 2000 873.621s (  2.3 samples/s);
Finished Evaluation [32]: Minibatch[1-2000]: metric = 14.84% * 2000;
 Minibatch[   1- 100]: loss = 0.223920 * 100, metric = 6.95% * 100;
 Minibatch[ 101- 200]: loss = 0.215962 * 100, metric = 6.91% * 100;
 Minibatch[ 201- 300]: loss = 0.214479 * 100, metric = 6.73% * 100;
 Minibatch[ 301- 400]: loss = 0.222044 * 100, metric = 7.15% * 100;
 Minibatch[ 401- 500]: loss = 0.209816 * 100, metric = 6.54% * 100;
 Minibatch[ 501- 600]: loss = 0.219497 * 100, metric = 6.87% * 100;
 Minibatch[ 601- 700]: loss = 0.221556 * 100, metric = 7.23% * 100;
 Minibatch[ 701- 800]: loss = 0.213054 * 100, metric = 6.62% * 100;
 Minibatch[ 801- 900]: loss = 0.211777 * 100, metric = 6.61% * 100;
 Minibatch[ 901-1000]: loss = 0.206288 * 100, metric = 6.57% * 100;
 Minibatch[1001-1100]: loss = 0.210238 * 100, metric = 6.67% * 100;
 Minibatch[1101-1200]: loss = 0.202829 * 100, metric = 6.27% * 100;
 Minibatch[1201-1300]: loss = 0.221306 * 100, metric = 6.76% * 100;
 Minibatch[1301-1400]: loss = 0.204017 * 100, metric = 6.32% * 100;
 Minibatch[1401-1500]: loss = 0.223365 * 100, metric = 6.82% * 100;
 Minibatch[1501-1600]: loss = 0.220445 * 100, metric = 6.87% * 100;
 Minibatch[1601-1700]: loss = 0.211270 * 100, metric = 6.49% * 100;
 Minibatch[1701-1800]: loss = 0.203936 * 100, metric = 6.26% * 100;
 Minibatch[1801-1900]: loss = 0.207693 * 100, metric = 6.53% * 100;
 Minibatch[1901-2000]: loss = 0.220125 * 100, metric = 6.95% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.214181 * 2000, metric = 6.71% * 2000 804.647s (  2.5 samples/s);
Finished Evaluation [33]: Minibatch[1-2000]: metric = 13.88% * 2000;
 Minibatch[   1- 100]: loss = 0.210572 * 100, metric = 6.48% * 100;
 Minibatch[ 101- 200]: loss = 0.213529 * 100, metric = 6.61% * 100;
 Minibatch[ 201- 300]: loss = 0.204307 * 100, metric = 6.36% * 100;
 Minibatch[ 301- 400]: loss = 0.219524 * 100, metric = 6.70% * 100;
 Minibatch[ 401- 500]: loss = 0.211939 * 100, metric = 6.64% * 100;
 Minibatch[ 501- 600]: loss = 0.216011 * 100, metric = 6.81% * 100;
 Minibatch[ 601- 700]: loss = 0.217073 * 100, metric = 6.84% * 100;
 Minibatch[ 701- 800]: loss = 0.205139 * 100, metric = 6.28% * 100;
 Minibatch[ 801- 900]: loss = 0.201341 * 100, metric = 6.14% * 100;
 Minibatch[ 901-1000]: loss = 0.203065 * 100, metric = 6.35% * 100;
 Minibatch[1001-1100]: loss = 0.209966 * 100, metric = 6.56% * 100;
 Minibatch[1101-1200]: loss = 0.206432 * 100, metric = 6.60% * 100;
 Minibatch[1201-1300]: loss = 0.208056 * 100, metric = 6.46% * 100;
 Minibatch[1301-1400]: loss = 0.207435 * 100, metric = 6.41% * 100;
 Minibatch[1401-1500]: loss = 0.211926 * 100, metric = 6.68% * 100;
 Minibatch[1501-1600]: loss = 0.212463 * 100, metric = 6.54% * 100;
 Minibatch[1601-1700]: loss = 0.221578 * 100, metric = 7.11% * 100;
 Minibatch[1701-1800]: loss = 0.208389 * 100, metric = 6.53% * 100;
 Minibatch[1801-1900]: loss = 0.205839 * 100, metric = 6.39% * 100;
 Minibatch[1901-2000]: loss = 0.210085 * 100, metric = 6.60% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.210233 * 2000, metric = 6.56% * 2000 807.155s (  2.5 samples/s);
Finished Evaluation [34]: Minibatch[1-2000]: metric = 15.88% * 2000;
 Minibatch[   1- 100]: loss = 0.199541 * 100, metric = 6.21% * 100;
 Minibatch[ 101- 200]: loss = 0.208233 * 100, metric = 6.58% * 100;
 Minibatch[ 201- 300]: loss = 0.204930 * 100, metric = 6.38% * 100;
 Minibatch[ 301- 400]: loss = 0.195948 * 100, metric = 6.04% * 100;
 Minibatch[ 401- 500]: loss = 0.200180 * 100, metric = 6.19% * 100;
 Minibatch[ 501- 600]: loss = 0.193509 * 100, metric = 5.98% * 100;
 Minibatch[ 601- 700]: loss = 0.211893 * 100, metric = 6.63% * 100;
 Minibatch[ 701- 800]: loss = 0.199580 * 100, metric = 6.22% * 100;
 Minibatch[ 801- 900]: loss = 0.203148 * 100, metric = 6.37% * 100;
 Minibatch[ 901-1000]: loss = 0.204546 * 100, metric = 6.27% * 100;
 Minibatch[1001-1100]: loss = 0.215787 * 100, metric = 6.72% * 100;
 Minibatch[1101-1200]: loss = 0.202546 * 100, metric = 6.38% * 100;
 Minibatch[1201-1300]: loss = 0.204607 * 100, metric = 6.49% * 100;
 Minibatch[1301-1400]: loss = 0.212401 * 100, metric = 6.77% * 100;
 Minibatch[1401-1500]: loss = 0.197291 * 100, metric = 6.15% * 100;
 Minibatch[1501-1600]: loss = 0.207581 * 100, metric = 6.45% * 100;
 Minibatch[1601-1700]: loss = 0.207816 * 100, metric = 6.74% * 100;
 Minibatch[1701-1800]: loss = 0.198057 * 100, metric = 6.19% * 100;
 Minibatch[1801-1900]: loss = 0.205412 * 100, metric = 6.39% * 100;
 Minibatch[1901-2000]: loss = 0.198996 * 100, metric = 6.24% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.203600 * 2000, metric = 6.37% * 2000 801.955s (  2.5 samples/s);
Finished Evaluation [35]: Minibatch[1-2000]: metric = 13.48% * 2000;
 Minibatch[   1- 100]: loss = 0.195940 * 100, metric = 6.13% * 100;
 Minibatch[ 101- 200]: loss = 0.189924 * 100, metric = 5.92% * 100;
 Minibatch[ 201- 300]: loss = 0.211175 * 100, metric = 6.62% * 100;
 Minibatch[ 301- 400]: loss = 0.200989 * 100, metric = 6.23% * 100;
 Minibatch[ 401- 500]: loss = 0.200916 * 100, metric = 6.31% * 100;
 Minibatch[ 501- 600]: loss = 0.204091 * 100, metric = 6.35% * 100;
 Minibatch[ 601- 700]: loss = 0.202912 * 100, metric = 6.26% * 100;
 Minibatch[ 701- 800]: loss = 0.189160 * 100, metric = 5.94% * 100;
 Minibatch[ 801- 900]: loss = 0.199263 * 100, metric = 6.18% * 100;
 Minibatch[ 901-1000]: loss = 0.209078 * 100, metric = 6.67% * 100;
 Minibatch[1001-1100]: loss = 0.212739 * 100, metric = 6.61% * 100;
 Minibatch[1101-1200]: loss = 0.198573 * 100, metric = 6.15% * 100;
 Minibatch[1201-1300]: loss = 0.210786 * 100, metric = 6.56% * 100;
 Minibatch[1301-1400]: loss = 0.185157 * 100, metric = 5.77% * 100;
 Minibatch[1401-1500]: loss = 0.197873 * 100, metric = 6.11% * 100;
 Minibatch[1501-1600]: loss = 0.198375 * 100, metric = 6.01% * 100;
 Minibatch[1601-1700]: loss = 0.214045 * 100, metric = 6.74% * 100;
 Minibatch[1701-1800]: loss = 0.199384 * 100, metric = 6.16% * 100;
 Minibatch[1801-1900]: loss = 0.198767 * 100, metric = 6.32% * 100;
 Minibatch[1901-2000]: loss = 0.195688 * 100, metric = 6.02% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.200742 * 2000, metric = 6.25% * 2000 801.333s (  2.5 samples/s);
Finished Evaluation [36]: Minibatch[1-2000]: metric = 15.04% * 2000;
 Minibatch[   1- 100]: loss = 0.201378 * 100, metric = 6.24% * 100;
 Minibatch[ 101- 200]: loss = 0.205372 * 100, metric = 6.44% * 100;
 Minibatch[ 201- 300]: loss = 0.200678 * 100, metric = 6.29% * 100;
 Minibatch[ 301- 400]: loss = 0.199903 * 100, metric = 6.23% * 100;
 Minibatch[ 401- 500]: loss = 0.198883 * 100, metric = 6.11% * 100;
 Minibatch[ 501- 600]: loss = 0.192752 * 100, metric = 6.09% * 100;
 Minibatch[ 601- 700]: loss = 0.198691 * 100, metric = 6.22% * 100;
 Minibatch[ 701- 800]: loss = 0.210450 * 100, metric = 6.64% * 100;
 Minibatch[ 801- 900]: loss = 0.200011 * 100, metric = 6.22% * 100;
 Minibatch[ 901-1000]: loss = 0.188093 * 100, metric = 5.66% * 100;
 Minibatch[1001-1100]: loss = 0.194751 * 100, metric = 6.14% * 100;
 Minibatch[1101-1200]: loss = 0.213171 * 100, metric = 6.82% * 100;
 Minibatch[1201-1300]: loss = 0.208145 * 100, metric = 6.48% * 100;
 Minibatch[1301-1400]: loss = 0.199866 * 100, metric = 6.34% * 100;
 Minibatch[1401-1500]: loss = 0.202062 * 100, metric = 6.36% * 100;
 Minibatch[1501-1600]: loss = 0.194489 * 100, metric = 5.93% * 100;
 Minibatch[1601-1700]: loss = 0.198309 * 100, metric = 6.23% * 100;
 Minibatch[1701-1800]: loss = 0.196481 * 100, metric = 6.06% * 100;
 Minibatch[1801-1900]: loss = 0.200090 * 100, metric = 6.37% * 100;
 Minibatch[1901-2000]: loss = 0.199397 * 100, metric = 6.13% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.200149 * 2000, metric = 6.25% * 2000 802.552s (  2.5 samples/s);
Finished Evaluation [37]: Minibatch[1-2000]: metric = 14.37% * 2000;
 Minibatch[   1- 100]: loss = 0.209598 * 100, metric = 6.65% * 100;
 Minibatch[ 101- 200]: loss = 0.201752 * 100, metric = 6.36% * 100;
 Minibatch[ 201- 300]: loss = 0.183579 * 100, metric = 5.68% * 100;
 Minibatch[ 301- 400]: loss = 0.194002 * 100, metric = 6.06% * 100;
 Minibatch[ 401- 500]: loss = 0.198451 * 100, metric = 6.18% * 100;
 Minibatch[ 501- 600]: loss = 0.200084 * 100, metric = 6.17% * 100;
 Minibatch[ 601- 700]: loss = 0.201326 * 100, metric = 6.25% * 100;
 Minibatch[ 701- 800]: loss = 0.196749 * 100, metric = 6.12% * 100;
 Minibatch[ 801- 900]: loss = 0.196224 * 100, metric = 6.13% * 100;
 Minibatch[ 901-1000]: loss = 0.197108 * 100, metric = 6.07% * 100;
 Minibatch[1001-1100]: loss = 0.207766 * 100, metric = 6.52% * 100;
 Minibatch[1101-1200]: loss = 0.191203 * 100, metric = 5.88% * 100;
 Minibatch[1201-1300]: loss = 0.201225 * 100, metric = 6.41% * 100;
 Minibatch[1301-1400]: loss = 0.201076 * 100, metric = 6.24% * 100;
 Minibatch[1401-1500]: loss = 0.201701 * 100, metric = 6.30% * 100;
 Minibatch[1501-1600]: loss = 0.205078 * 100, metric = 6.46% * 100;
 Minibatch[1601-1700]: loss = 0.198127 * 100, metric = 6.15% * 100;
 Minibatch[1701-1800]: loss = 0.198839 * 100, metric = 6.18% * 100;
 Minibatch[1801-1900]: loss = 0.201695 * 100, metric = 6.38% * 100;
 Minibatch[1901-2000]: loss = 0.201367 * 100, metric = 6.26% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.199347 * 2000, metric = 6.22% * 2000 802.336s (  2.5 samples/s);
Finished Evaluation [38]: Minibatch[1-2000]: metric = 14.07% * 2000;
 Minibatch[   1- 100]: loss = 0.195625 * 100, metric = 6.20% * 100;
 Minibatch[ 101- 200]: loss = 0.204932 * 100, metric = 6.39% * 100;
 Minibatch[ 201- 300]: loss = 0.191835 * 100, metric = 5.97% * 100;
 Minibatch[ 301- 400]: loss = 0.196034 * 100, metric = 6.17% * 100;
 Minibatch[ 401- 500]: loss = 0.195150 * 100, metric = 6.22% * 100;
 Minibatch[ 501- 600]: loss = 0.200668 * 100, metric = 6.31% * 100;
 Minibatch[ 601- 700]: loss = 0.199256 * 100, metric = 6.20% * 100;
 Minibatch[ 701- 800]: loss = 0.204262 * 100, metric = 6.42% * 100;
 Minibatch[ 801- 900]: loss = 0.187656 * 100, metric = 5.91% * 100;
 Minibatch[ 901-1000]: loss = 0.187626 * 100, metric = 5.81% * 100;
 Minibatch[1001-1100]: loss = 0.199697 * 100, metric = 6.13% * 100;
 Minibatch[1101-1200]: loss = 0.199469 * 100, metric = 6.23% * 100;
 Minibatch[1201-1300]: loss = 0.195891 * 100, metric = 6.11% * 100;
 Minibatch[1301-1400]: loss = 0.204125 * 100, metric = 6.14% * 100;
 Minibatch[1401-1500]: loss = 0.198093 * 100, metric = 6.23% * 100;
 Minibatch[1501-1600]: loss = 0.201104 * 100, metric = 6.09% * 100;
 Minibatch[1601-1700]: loss = 0.188750 * 100, metric = 5.84% * 100;
 Minibatch[1701-1800]: loss = 0.205991 * 100, metric = 6.44% * 100;
 Minibatch[1801-1900]: loss = 0.196455 * 100, metric = 6.06% * 100;
 Minibatch[1901-2000]: loss = 0.189003 * 100, metric = 5.75% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.197081 * 2000, metric = 6.13% * 2000 794.532s (  2.5 samples/s);
Finished Evaluation [39]: Minibatch[1-2000]: metric = 13.63% * 2000;
0.44272489071637394
 Minibatch[   1- 100]: loss = 0.191997 * 100, metric = 6.07% * 100;
 Minibatch[ 101- 200]: loss = 0.188542 * 100, metric = 5.77% * 100;
 Minibatch[ 201- 300]: loss = 0.197311 * 100, metric = 6.12% * 100;
 Minibatch[ 301- 400]: loss = 0.196085 * 100, metric = 6.17% * 100;
 Minibatch[ 401- 500]: loss = 0.191917 * 100, metric = 6.07% * 100;
 Minibatch[ 501- 600]: loss = 0.196507 * 100, metric = 6.02% * 100;
 Minibatch[ 601- 700]: loss = 0.201709 * 100, metric = 6.53% * 100;
 Minibatch[ 701- 800]: loss = 0.191787 * 100, metric = 5.95% * 100;
 Minibatch[ 801- 900]: loss = 0.192147 * 100, metric = 5.84% * 100;
 Minibatch[ 901-1000]: loss = 0.192758 * 100, metric = 6.07% * 100;
 Minibatch[1001-1100]: loss = 0.204669 * 100, metric = 6.44% * 100;
 Minibatch[1101-1200]: loss = 0.196615 * 100, metric = 6.16% * 100;
 Minibatch[1201-1300]: loss = 0.194639 * 100, metric = 6.06% * 100;
 Minibatch[1301-1400]: loss = 0.196894 * 100, metric = 6.12% * 100;
 Minibatch[1401-1500]: loss = 0.191214 * 100, metric = 5.98% * 100;
 Minibatch[1501-1600]: loss = 0.196722 * 100, metric = 6.12% * 100;
 Minibatch[1601-1700]: loss = 0.192204 * 100, metric = 5.91% * 100;
 Minibatch[1701-1800]: loss = 0.189901 * 100, metric = 5.88% * 100;
 Minibatch[1801-1900]: loss = 0.192268 * 100, metric = 5.97% * 100;
 Minibatch[1901-2000]: loss = 0.198996 * 100, metric = 6.14% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.194744 * 2000, metric = 6.07% * 2000 789.902s (  2.5 samples/s);
Finished Evaluation [40]: Minibatch[1-2000]: metric = 14.59% * 2000;
 Minibatch[   1- 100]: loss = 0.198389 * 100, metric = 6.34% * 100;
 Minibatch[ 101- 200]: loss = 0.190556 * 100, metric = 5.77% * 100;
 Minibatch[ 201- 300]: loss = 0.202018 * 100, metric = 6.18% * 100;
 Minibatch[ 301- 400]: loss = 0.202366 * 100, metric = 6.39% * 100;
 Minibatch[ 401- 500]: loss = 0.198657 * 100, metric = 6.27% * 100;
 Minibatch[ 501- 600]: loss = 0.190428 * 100, metric = 5.85% * 100;
 Minibatch[ 601- 700]: loss = 0.196963 * 100, metric = 6.17% * 100;
 Minibatch[ 701- 800]: loss = 0.194141 * 100, metric = 6.12% * 100;
 Minibatch[ 801- 900]: loss = 0.188293 * 100, metric = 5.89% * 100;
 Minibatch[ 901-1000]: loss = 0.198364 * 100, metric = 6.20% * 100;
 Minibatch[1001-1100]: loss = 0.193613 * 100, metric = 6.04% * 100;
 Minibatch[1101-1200]: loss = 0.201109 * 100, metric = 6.32% * 100;
 Minibatch[1201-1300]: loss = 0.197115 * 100, metric = 6.15% * 100;
 Minibatch[1301-1400]: loss = 0.184102 * 100, metric = 5.68% * 100;
 Minibatch[1401-1500]: loss = 0.183424 * 100, metric = 5.66% * 100;
 Minibatch[1501-1600]: loss = 0.188242 * 100, metric = 5.93% * 100;
 Minibatch[1601-1700]: loss = 0.195325 * 100, metric = 6.06% * 100;
 Minibatch[1701-1800]: loss = 0.191649 * 100, metric = 6.06% * 100;
 Minibatch[1801-1900]: loss = 0.194165 * 100, metric = 6.03% * 100;
 Minibatch[1901-2000]: loss = 0.185453 * 100, metric = 5.71% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.193719 * 2000, metric = 6.04% * 2000 795.649s (  2.5 samples/s);
Finished Evaluation [41]: Minibatch[1-2000]: metric = 15.22% * 2000;
 Minibatch[   1- 100]: loss = 0.188598 * 100, metric = 6.01% * 100;
 Minibatch[ 101- 200]: loss = 0.186901 * 100, metric = 5.93% * 100;
 Minibatch[ 201- 300]: loss = 0.188158 * 100, metric = 5.84% * 100;
 Minibatch[ 301- 400]: loss = 0.187107 * 100, metric = 5.80% * 100;
 Minibatch[ 401- 500]: loss = 0.188692 * 100, metric = 5.97% * 100;
 Minibatch[ 501- 600]: loss = 0.194373 * 100, metric = 6.10% * 100;
 Minibatch[ 601- 700]: loss = 0.188156 * 100, metric = 5.97% * 100;
 Minibatch[ 701- 800]: loss = 0.192576 * 100, metric = 6.11% * 100;
 Minibatch[ 801- 900]: loss = 0.189247 * 100, metric = 5.93% * 100;
 Minibatch[ 901-1000]: loss = 0.194649 * 100, metric = 6.12% * 100;
 Minibatch[1001-1100]: loss = 0.189312 * 100, metric = 5.98% * 100;
 Minibatch[1101-1200]: loss = 0.188074 * 100, metric = 5.88% * 100;
 Minibatch[1201-1300]: loss = 0.187761 * 100, metric = 5.93% * 100;
 Minibatch[1301-1400]: loss = 0.190085 * 100, metric = 6.05% * 100;
 Minibatch[1401-1500]: loss = 0.180394 * 100, metric = 5.59% * 100;
 Minibatch[1501-1600]: loss = 0.185100 * 100, metric = 5.77% * 100;
 Minibatch[1601-1700]: loss = 0.189519 * 100, metric = 5.77% * 100;
 Minibatch[1701-1800]: loss = 0.187246 * 100, metric = 5.86% * 100;
 Minibatch[1801-1900]: loss = 0.194860 * 100, metric = 6.17% * 100;
 Minibatch[1901-2000]: loss = 0.186196 * 100, metric = 5.79% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.188850 * 2000, metric = 5.93% * 2000 790.775s (  2.5 samples/s);
Finished Evaluation [42]: Minibatch[1-2000]: metric = 14.26% * 2000;
 Minibatch[   1- 100]: loss = 0.202268 * 100, metric = 6.28% * 100;
 Minibatch[ 101- 200]: loss = 0.178752 * 100, metric = 5.48% * 100;
 Minibatch[ 201- 300]: loss = 0.188712 * 100, metric = 5.75% * 100;
 Minibatch[ 301- 400]: loss = 0.190582 * 100, metric = 5.97% * 100;
 Minibatch[ 401- 500]: loss = 0.188356 * 100, metric = 5.78% * 100;
 Minibatch[ 501- 600]: loss = 0.184860 * 100, metric = 5.83% * 100;
 Minibatch[ 601- 700]: loss = 0.197212 * 100, metric = 6.17% * 100;
 Minibatch[ 701- 800]: loss = 0.183325 * 100, metric = 5.80% * 100;
 Minibatch[ 801- 900]: loss = 0.184443 * 100, metric = 5.79% * 100;
 Minibatch[ 901-1000]: loss = 0.185736 * 100, metric = 5.75% * 100;
 Minibatch[1001-1100]: loss = 0.182828 * 100, metric = 5.73% * 100;
 Minibatch[1101-1200]: loss = 0.181910 * 100, metric = 5.77% * 100;
 Minibatch[1201-1300]: loss = 0.196752 * 100, metric = 6.29% * 100;
 Minibatch[1301-1400]: loss = 0.190834 * 100, metric = 5.98% * 100;
 Minibatch[1401-1500]: loss = 0.174313 * 100, metric = 5.28% * 100;
 Minibatch[1501-1600]: loss = 0.190924 * 100, metric = 5.89% * 100;
 Minibatch[1601-1700]: loss = 0.188836 * 100, metric = 5.87% * 100;
 Minibatch[1701-1800]: loss = 0.185814 * 100, metric = 5.81% * 100;
 Minibatch[1801-1900]: loss = 0.192935 * 100, metric = 6.08% * 100;
 Minibatch[1901-2000]: loss = 0.182573 * 100, metric = 5.70% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.187598 * 2000, metric = 5.85% * 2000 789.894s (  2.5 samples/s);
Finished Evaluation [43]: Minibatch[1-2000]: metric = 13.89% * 2000;
 Minibatch[   1- 100]: loss = 0.180997 * 100, metric = 5.65% * 100;
 Minibatch[ 101- 200]: loss = 0.185725 * 100, metric = 5.77% * 100;
 Minibatch[ 201- 300]: loss = 0.187686 * 100, metric = 5.68% * 100;
 Minibatch[ 301- 400]: loss = 0.189046 * 100, metric = 6.00% * 100;
 Minibatch[ 401- 500]: loss = 0.180150 * 100, metric = 5.55% * 100;
 Minibatch[ 501- 600]: loss = 0.182534 * 100, metric = 5.74% * 100;
 Minibatch[ 601- 700]: loss = 0.194849 * 100, metric = 6.09% * 100;
 Minibatch[ 701- 800]: loss = 0.169539 * 100, metric = 5.21% * 100;
 Minibatch[ 801- 900]: loss = 0.178254 * 100, metric = 5.48% * 100;
 Minibatch[ 901-1000]: loss = 0.176847 * 100, metric = 5.35% * 100;
 Minibatch[1001-1100]: loss = 0.175330 * 100, metric = 5.27% * 100;
 Minibatch[1101-1200]: loss = 0.175876 * 100, metric = 5.49% * 100;
 Minibatch[1201-1300]: loss = 0.188867 * 100, metric = 5.98% * 100;
 Minibatch[1301-1400]: loss = 0.179648 * 100, metric = 5.62% * 100;
 Minibatch[1401-1500]: loss = 0.166579 * 100, metric = 5.08% * 100;
 Minibatch[1501-1600]: loss = 0.170515 * 100, metric = 5.28% * 100;
 Minibatch[1601-1700]: loss = 0.182460 * 100, metric = 5.59% * 100;
 Minibatch[1701-1800]: loss = 0.192047 * 100, metric = 6.06% * 100;
 Minibatch[1801-1900]: loss = 0.184585 * 100, metric = 5.63% * 100;
 Minibatch[1901-2000]: loss = 0.177544 * 100, metric = 5.55% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.180954 * 2000, metric = 5.60% * 2000 793.534s (  2.5 samples/s);
Finished Evaluation [44]: Minibatch[1-2000]: metric = 14.55% * 2000;
 Minibatch[   1- 100]: loss = 0.182980 * 100, metric = 5.66% * 100;
 Minibatch[ 101- 200]: loss = 0.175524 * 100, metric = 5.24% * 100;
 Minibatch[ 201- 300]: loss = 0.177805 * 100, metric = 5.46% * 100;
 Minibatch[ 301- 400]: loss = 0.190846 * 100, metric = 5.96% * 100;
 Minibatch[ 401- 500]: loss = 0.174089 * 100, metric = 5.36% * 100;
 Minibatch[ 501- 600]: loss = 0.172674 * 100, metric = 5.23% * 100;
 Minibatch[ 601- 700]: loss = 0.175570 * 100, metric = 5.56% * 100;
 Minibatch[ 701- 800]: loss = 0.176224 * 100, metric = 5.51% * 100;
 Minibatch[ 801- 900]: loss = 0.188530 * 100, metric = 5.88% * 100;
 Minibatch[ 901-1000]: loss = 0.178636 * 100, metric = 5.54% * 100;
 Minibatch[1001-1100]: loss = 0.171890 * 100, metric = 5.27% * 100;
 Minibatch[1101-1200]: loss = 0.187491 * 100, metric = 5.56% * 100;
 Minibatch[1201-1300]: loss = 0.182571 * 100, metric = 5.65% * 100;
 Minibatch[1301-1400]: loss = 0.174545 * 100, metric = 5.49% * 100;
 Minibatch[1401-1500]: loss = 0.182598 * 100, metric = 5.81% * 100;
 Minibatch[1501-1600]: loss = 0.174673 * 100, metric = 5.40% * 100;
 Minibatch[1601-1700]: loss = 0.172503 * 100, metric = 5.31% * 100;
 Minibatch[1701-1800]: loss = 0.181828 * 100, metric = 5.62% * 100;
 Minibatch[1801-1900]: loss = 0.186351 * 100, metric = 5.85% * 100;
 Minibatch[1901-2000]: loss = 0.185195 * 100, metric = 5.76% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.179626 * 2000, metric = 5.56% * 2000 789.227s (  2.5 samples/s);
Finished Evaluation [45]: Minibatch[1-2000]: metric = 14.83% * 2000;
 Minibatch[   1- 100]: loss = 0.177470 * 100, metric = 5.60% * 100;
 Minibatch[ 101- 200]: loss = 0.186949 * 100, metric = 5.75% * 100;
 Minibatch[ 201- 300]: loss = 0.178498 * 100, metric = 5.56% * 100;
 Minibatch[ 301- 400]: loss = 0.190917 * 100, metric = 5.89% * 100;
 Minibatch[ 401- 500]: loss = 0.175395 * 100, metric = 5.39% * 100;
 Minibatch[ 501- 600]: loss = 0.176288 * 100, metric = 5.47% * 100;
 Minibatch[ 601- 700]: loss = 0.172524 * 100, metric = 5.29% * 100;
 Minibatch[ 701- 800]: loss = 0.168996 * 100, metric = 5.26% * 100;
 Minibatch[ 801- 900]: loss = 0.172547 * 100, metric = 5.36% * 100;
 Minibatch[ 901-1000]: loss = 0.176997 * 100, metric = 5.45% * 100;
 Minibatch[1001-1100]: loss = 0.171900 * 100, metric = 5.19% * 100;
 Minibatch[1101-1200]: loss = 0.186054 * 100, metric = 5.92% * 100;
 Minibatch[1201-1300]: loss = 0.183800 * 100, metric = 5.63% * 100;
 Minibatch[1301-1400]: loss = 0.183786 * 100, metric = 5.70% * 100;
 Minibatch[1401-1500]: loss = 0.179320 * 100, metric = 5.68% * 100;
 Minibatch[1501-1600]: loss = 0.183509 * 100, metric = 5.82% * 100;
 Minibatch[1601-1700]: loss = 0.174355 * 100, metric = 5.46% * 100;
 Minibatch[1701-1800]: loss = 0.189890 * 100, metric = 5.89% * 100;
 Minibatch[1801-1900]: loss = 0.176439 * 100, metric = 5.41% * 100;
 Minibatch[1901-2000]: loss = 0.173941 * 100, metric = 5.40% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.178979 * 2000, metric = 5.56% * 2000 780.735s (  2.6 samples/s);
Finished Evaluation [46]: Minibatch[1-2000]: metric = 13.54% * 2000;
0.442445176076144
 Minibatch[   1- 100]: loss = 0.175949 * 100, metric = 5.34% * 100;
 Minibatch[ 101- 200]: loss = 0.177492 * 100, metric = 5.49% * 100;
 Minibatch[ 201- 300]: loss = 0.180461 * 100, metric = 5.54% * 100;
 Minibatch[ 301- 400]: loss = 0.174873 * 100, metric = 5.39% * 100;
 Minibatch[ 401- 500]: loss = 0.174728 * 100, metric = 5.40% * 100;
 Minibatch[ 501- 600]: loss = 0.178477 * 100, metric = 5.56% * 100;
 Minibatch[ 601- 700]: loss = 0.181871 * 100, metric = 5.68% * 100;
 Minibatch[ 701- 800]: loss = 0.187308 * 100, metric = 5.89% * 100;
 Minibatch[ 801- 900]: loss = 0.177279 * 100, metric = 5.45% * 100;
 Minibatch[ 901-1000]: loss = 0.177661 * 100, metric = 5.55% * 100;
 Minibatch[1001-1100]: loss = 0.189772 * 100, metric = 5.89% * 100;
 Minibatch[1101-1200]: loss = 0.177803 * 100, metric = 5.52% * 100;
 Minibatch[1201-1300]: loss = 0.164700 * 100, metric = 5.03% * 100;
 Minibatch[1301-1400]: loss = 0.172006 * 100, metric = 5.35% * 100;
 Minibatch[1401-1500]: loss = 0.178351 * 100, metric = 5.60% * 100;
 Minibatch[1501-1600]: loss = 0.179045 * 100, metric = 5.65% * 100;
 Minibatch[1601-1700]: loss = 0.175921 * 100, metric = 5.52% * 100;
 Minibatch[1701-1800]: loss = 0.180932 * 100, metric = 5.64% * 100;
 Minibatch[1801-1900]: loss = 0.178748 * 100, metric = 5.58% * 100;
 Minibatch[1901-2000]: loss = 0.178158 * 100, metric = 5.55% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.178077 * 2000, metric = 5.53% * 2000 783.425s (  2.6 samples/s);
Finished Evaluation [47]: Minibatch[1-2000]: metric = 13.80% * 2000;
 Minibatch[   1- 100]: loss = 0.175992 * 100, metric = 5.44% * 100;
 Minibatch[ 101- 200]: loss = 0.172910 * 100, metric = 5.39% * 100;
 Minibatch[ 201- 300]: loss = 0.177405 * 100, metric = 5.39% * 100;
 Minibatch[ 301- 400]: loss = 0.175412 * 100, metric = 5.50% * 100;
 Minibatch[ 401- 500]: loss = 0.186011 * 100, metric = 5.78% * 100;
 Minibatch[ 501- 600]: loss = 0.192481 * 100, metric = 5.90% * 100;
 Minibatch[ 601- 700]: loss = 0.187194 * 100, metric = 5.79% * 100;
 Minibatch[ 701- 800]: loss = 0.167638 * 100, metric = 4.98% * 100;
 Minibatch[ 801- 900]: loss = 0.168183 * 100, metric = 5.17% * 100;
 Minibatch[ 901-1000]: loss = 0.183008 * 100, metric = 5.85% * 100;
 Minibatch[1001-1100]: loss = 0.173025 * 100, metric = 5.49% * 100;
 Minibatch[1101-1200]: loss = 0.175594 * 100, metric = 5.37% * 100;
 Minibatch[1201-1300]: loss = 0.171605 * 100, metric = 5.32% * 100;
 Minibatch[1301-1400]: loss = 0.171149 * 100, metric = 5.30% * 100;
 Minibatch[1401-1500]: loss = 0.174320 * 100, metric = 5.47% * 100;
 Minibatch[1501-1600]: loss = 0.174603 * 100, metric = 5.46% * 100;
 Minibatch[1601-1700]: loss = 0.167018 * 100, metric = 5.31% * 100;
 Minibatch[1701-1800]: loss = 0.170973 * 100, metric = 5.18% * 100;
 Minibatch[1801-1900]: loss = 0.171891 * 100, metric = 5.28% * 100;
 Minibatch[1901-2000]: loss = 0.162190 * 100, metric = 4.95% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.174930 * 2000, metric = 5.42% * 2000 775.432s (  2.6 samples/s);
Finished Evaluation [48]: Minibatch[1-2000]: metric = 14.71% * 2000;
 Minibatch[   1- 100]: loss = 0.176967 * 100, metric = 5.31% * 100;
 Minibatch[ 101- 200]: loss = 0.174650 * 100, metric = 5.39% * 100;
 Minibatch[ 201- 300]: loss = 0.182758 * 100, metric = 5.74% * 100;
 Minibatch[ 301- 400]: loss = 0.175407 * 100, metric = 5.45% * 100;
 Minibatch[ 401- 500]: loss = 0.181198 * 100, metric = 5.66% * 100;
 Minibatch[ 501- 600]: loss = 0.173008 * 100, metric = 5.34% * 100;
 Minibatch[ 601- 700]: loss = 0.169736 * 100, metric = 5.25% * 100;
 Minibatch[ 701- 800]: loss = 0.172458 * 100, metric = 5.45% * 100;
 Minibatch[ 801- 900]: loss = 0.167766 * 100, metric = 5.20% * 100;
 Minibatch[ 901-1000]: loss = 0.178571 * 100, metric = 5.62% * 100;
 Minibatch[1001-1100]: loss = 0.185513 * 100, metric = 5.83% * 100;
 Minibatch[1101-1200]: loss = 0.182417 * 100, metric = 5.80% * 100;
 Minibatch[1201-1300]: loss = 0.166071 * 100, metric = 5.04% * 100;
 Minibatch[1301-1400]: loss = 0.177659 * 100, metric = 5.49% * 100;
 Minibatch[1401-1500]: loss = 0.179812 * 100, metric = 5.71% * 100;
 Minibatch[1501-1600]: loss = 0.160143 * 100, metric = 4.67% * 100;
 Minibatch[1601-1700]: loss = 0.188488 * 100, metric = 5.92% * 100;
 Minibatch[1701-1800]: loss = 0.177567 * 100, metric = 5.44% * 100;
 Minibatch[1801-1900]: loss = 0.174581 * 100, metric = 5.45% * 100;
 Minibatch[1901-2000]: loss = 0.175163 * 100, metric = 5.48% * 100;
Finished Epoch[49 of 200]: [Training] loss = 0.175997 * 2000, metric = 5.46% * 2000 787.454s (  2.5 samples/s);
Finished Evaluation [49]: Minibatch[1-2000]: metric = 12.93% * 2000;
 Minibatch[   1- 100]: loss = 0.179624 * 100, metric = 5.59% * 100;
 Minibatch[ 101- 200]: loss = 0.170191 * 100, metric = 5.24% * 100;
 Minibatch[ 201- 300]: loss = 0.169634 * 100, metric = 5.23% * 100;
 Minibatch[ 301- 400]: loss = 0.172757 * 100, metric = 5.39% * 100;
 Minibatch[ 401- 500]: loss = 0.184071 * 100, metric = 5.72% * 100;
 Minibatch[ 501- 600]: loss = 0.184943 * 100, metric = 5.76% * 100;
 Minibatch[ 601- 700]: loss = 0.169084 * 100, metric = 5.18% * 100;
 Minibatch[ 701- 800]: loss = 0.171550 * 100, metric = 5.39% * 100;
 Minibatch[ 801- 900]: loss = 0.173315 * 100, metric = 5.47% * 100;
 Minibatch[ 901-1000]: loss = 0.175444 * 100, metric = 5.35% * 100;
 Minibatch[1001-1100]: loss = 0.169281 * 100, metric = 5.38% * 100;
 Minibatch[1101-1200]: loss = 0.172701 * 100, metric = 5.35% * 100;
 Minibatch[1201-1300]: loss = 0.172326 * 100, metric = 5.37% * 100;
 Minibatch[1301-1400]: loss = 0.165903 * 100, metric = 5.03% * 100;
 Minibatch[1401-1500]: loss = 0.176979 * 100, metric = 5.51% * 100;
 Minibatch[1501-1600]: loss = 0.172411 * 100, metric = 5.37% * 100;
 Minibatch[1601-1700]: loss = 0.167917 * 100, metric = 5.22% * 100;
 Minibatch[1701-1800]: loss = 0.177441 * 100, metric = 5.63% * 100;
 Minibatch[1801-1900]: loss = 0.177430 * 100, metric = 5.43% * 100;
 Minibatch[1901-2000]: loss = 0.173411 * 100, metric = 5.38% * 100;
Finished Epoch[50 of 200]: [Training] loss = 0.173821 * 2000, metric = 5.40% * 2000 804.469s (  2.5 samples/s);
Finished Evaluation [50]: Minibatch[1-2000]: metric = 13.25% * 2000;
 Minibatch[   1- 100]: loss = 0.164269 * 100, metric = 5.00% * 100;
 Minibatch[ 101- 200]: loss = 0.174352 * 100, metric = 5.42% * 100;
 Minibatch[ 201- 300]: loss = 0.177532 * 100, metric = 5.46% * 100;
 Minibatch[ 301- 400]: loss = 0.172002 * 100, metric = 5.39% * 100;
 Minibatch[ 401- 500]: loss = 0.167370 * 100, metric = 5.11% * 100;
 Minibatch[ 501- 600]: loss = 0.180327 * 100, metric = 5.58% * 100;
 Minibatch[ 601- 700]: loss = 0.167509 * 100, metric = 5.24% * 100;
 Minibatch[ 701- 800]: loss = 0.173614 * 100, metric = 5.39% * 100;
 Minibatch[ 801- 900]: loss = 0.169660 * 100, metric = 5.17% * 100;
 Minibatch[ 901-1000]: loss = 0.171463 * 100, metric = 5.26% * 100;
 Minibatch[1001-1100]: loss = 0.173075 * 100, metric = 5.42% * 100;
 Minibatch[1101-1200]: loss = 0.173010 * 100, metric = 5.34% * 100;
 Minibatch[1201-1300]: loss = 0.179582 * 100, metric = 5.40% * 100;
 Minibatch[1301-1400]: loss = 0.173148 * 100, metric = 5.25% * 100;
 Minibatch[1401-1500]: loss = 0.164354 * 100, metric = 4.94% * 100;
 Minibatch[1501-1600]: loss = 0.179136 * 100, metric = 5.47% * 100;
 Minibatch[1601-1700]: loss = 0.173103 * 100, metric = 5.46% * 100;
 Minibatch[1701-1800]: loss = 0.175471 * 100, metric = 5.47% * 100;
 Minibatch[1801-1900]: loss = 0.159052 * 100, metric = 4.90% * 100;
 Minibatch[1901-2000]: loss = 0.170633 * 100, metric = 5.18% * 100;
Finished Epoch[51 of 200]: [Training] loss = 0.171933 * 2000, metric = 5.29% * 2000 753.768s (  2.7 samples/s);
Finished Evaluation [51]: Minibatch[1-2000]: metric = 14.68% * 2000;
 Minibatch[   1- 100]: loss = 0.167786 * 100, metric = 5.29% * 100;
 Minibatch[ 101- 200]: loss = 0.166801 * 100, metric = 5.20% * 100;
 Minibatch[ 201- 300]: loss = 0.176974 * 100, metric = 5.54% * 100;
 Minibatch[ 301- 400]: loss = 0.172434 * 100, metric = 5.39% * 100;
 Minibatch[ 401- 500]: loss = 0.172423 * 100, metric = 5.31% * 100;
 Minibatch[ 501- 600]: loss = 0.170347 * 100, metric = 5.21% * 100;
 Minibatch[ 601- 700]: loss = 0.168741 * 100, metric = 5.08% * 100;
 Minibatch[ 701- 800]: loss = 0.178193 * 100, metric = 5.51% * 100;
 Minibatch[ 801- 900]: loss = 0.174670 * 100, metric = 5.50% * 100;
 Minibatch[ 901-1000]: loss = 0.177177 * 100, metric = 5.52% * 100;
 Minibatch[1001-1100]: loss = 0.171190 * 100, metric = 5.36% * 100;
 Minibatch[1101-1200]: loss = 0.164128 * 100, metric = 5.07% * 100;
 Minibatch[1201-1300]: loss = 0.160046 * 100, metric = 4.85% * 100;
 Minibatch[1301-1400]: loss = 0.173009 * 100, metric = 4.94% * 100;
 Minibatch[1401-1500]: loss = 0.159038 * 100, metric = 4.67% * 100;
 Minibatch[1501-1600]: loss = 0.159666 * 100, metric = 4.95% * 100;
 Minibatch[1601-1700]: loss = 0.173893 * 100, metric = 5.32% * 100;
 Minibatch[1701-1800]: loss = 0.167143 * 100, metric = 5.19% * 100;
 Minibatch[1801-1900]: loss = 0.159473 * 100, metric = 4.84% * 100;
 Minibatch[1901-2000]: loss = 0.167396 * 100, metric = 5.29% * 100;
Finished Epoch[52 of 200]: [Training] loss = 0.169026 * 2000, metric = 5.20% * 2000 752.247s (  2.7 samples/s);
Finished Evaluation [52]: Minibatch[1-2000]: metric = 14.35% * 2000;
 Minibatch[   1- 100]: loss = 0.165731 * 100, metric = 5.03% * 100;
 Minibatch[ 101- 200]: loss = 0.158856 * 100, metric = 4.87% * 100;
 Minibatch[ 201- 300]: loss = 0.167131 * 100, metric = 5.19% * 100;
 Minibatch[ 301- 400]: loss = 0.166604 * 100, metric = 5.18% * 100;
 Minibatch[ 401- 500]: loss = 0.172746 * 100, metric = 5.32% * 100;
 Minibatch[ 501- 600]: loss = 0.165125 * 100, metric = 5.05% * 100;
 Minibatch[ 601- 700]: loss = 0.164535 * 100, metric = 5.05% * 100;
 Minibatch[ 701- 800]: loss = 0.166772 * 100, metric = 5.08% * 100;
 Minibatch[ 801- 900]: loss = 0.169213 * 100, metric = 5.28% * 100;
 Minibatch[ 901-1000]: loss = 0.164464 * 100, metric = 5.17% * 100;
 Minibatch[1001-1100]: loss = 0.171548 * 100, metric = 5.35% * 100;
 Minibatch[1101-1200]: loss = 0.164312 * 100, metric = 5.07% * 100;
 Minibatch[1201-1300]: loss = 0.165155 * 100, metric = 5.12% * 100;
 Minibatch[1301-1400]: loss = 0.170480 * 100, metric = 5.12% * 100;
 Minibatch[1401-1500]: loss = 0.168989 * 100, metric = 5.27% * 100;
 Minibatch[1501-1600]: loss = 0.163127 * 100, metric = 5.14% * 100;
 Minibatch[1601-1700]: loss = 0.160490 * 100, metric = 4.97% * 100;
 Minibatch[1701-1800]: loss = 0.176530 * 100, metric = 5.54% * 100;
 Minibatch[1801-1900]: loss = 0.175923 * 100, metric = 5.43% * 100;
 Minibatch[1901-2000]: loss = 0.155828 * 100, metric = 4.82% * 100;
Finished Epoch[53 of 200]: [Training] loss = 0.166678 * 2000, metric = 5.15% * 2000 757.923s (  2.6 samples/s);
Finished Evaluation [53]: Minibatch[1-2000]: metric = 13.80% * 2000;
 Minibatch[   1- 100]: loss = 0.162325 * 100, metric = 5.01% * 100;
 Minibatch[ 101- 200]: loss = 0.163899 * 100, metric = 5.02% * 100;
 Minibatch[ 201- 300]: loss = 0.163199 * 100, metric = 5.05% * 100;
 Minibatch[ 301- 400]: loss = 0.159170 * 100, metric = 4.95% * 100;
 Minibatch[ 401- 500]: loss = 0.167668 * 100, metric = 5.24% * 100;
 Minibatch[ 501- 600]: loss = 0.159190 * 100, metric = 4.79% * 100;
 Minibatch[ 601- 700]: loss = 0.169043 * 100, metric = 5.25% * 100;
 Minibatch[ 701- 800]: loss = 0.165887 * 100, metric = 5.14% * 100;
 Minibatch[ 801- 900]: loss = 0.153512 * 100, metric = 4.69% * 100;
 Minibatch[ 901-1000]: loss = 0.166877 * 100, metric = 5.15% * 100;
 Minibatch[1001-1100]: loss = 0.159244 * 100, metric = 4.81% * 100;
 Minibatch[1101-1200]: loss = 0.159445 * 100, metric = 5.00% * 100;
 Minibatch[1201-1300]: loss = 0.164859 * 100, metric = 5.19% * 100;
 Minibatch[1301-1400]: loss = 0.163457 * 100, metric = 5.13% * 100;
 Minibatch[1401-1500]: loss = 0.169806 * 100, metric = 5.17% * 100;
 Minibatch[1501-1600]: loss = 0.166290 * 100, metric = 5.07% * 100;
 Minibatch[1601-1700]: loss = 0.167666 * 100, metric = 5.26% * 100;
 Minibatch[1701-1800]: loss = 0.171909 * 100, metric = 5.33% * 100;
 Minibatch[1801-1900]: loss = 0.171175 * 100, metric = 5.28% * 100;
 Minibatch[1901-2000]: loss = 0.172371 * 100, metric = 5.41% * 100;
Finished Epoch[54 of 200]: [Training] loss = 0.164850 * 2000, metric = 5.10% * 2000 752.829s (  2.7 samples/s);
Finished Evaluation [54]: Minibatch[1-2000]: metric = 12.92% * 2000;
 Minibatch[   1- 100]: loss = 0.167573 * 100, metric = 5.06% * 100;
 Minibatch[ 101- 200]: loss = 0.172889 * 100, metric = 5.34% * 100;
 Minibatch[ 201- 300]: loss = 0.168544 * 100, metric = 5.37% * 100;
 Minibatch[ 301- 400]: loss = 0.160910 * 100, metric = 5.00% * 100;
 Minibatch[ 401- 500]: loss = 0.169645 * 100, metric = 5.22% * 100;
 Minibatch[ 501- 600]: loss = 0.165779 * 100, metric = 4.96% * 100;
 Minibatch[ 601- 700]: loss = 0.167435 * 100, metric = 5.34% * 100;
 Minibatch[ 701- 800]: loss = 0.173497 * 100, metric = 5.40% * 100;
 Minibatch[ 801- 900]: loss = 0.166766 * 100, metric = 5.12% * 100;
 Minibatch[ 901-1000]: loss = 0.163440 * 100, metric = 4.99% * 100;
 Minibatch[1001-1100]: loss = 0.165386 * 100, metric = 5.07% * 100;
 Minibatch[1101-1200]: loss = 0.166994 * 100, metric = 5.19% * 100;
 Minibatch[1201-1300]: loss = 0.166966 * 100, metric = 5.11% * 100;
 Minibatch[1301-1400]: loss = 0.153872 * 100, metric = 4.67% * 100;
 Minibatch[1401-1500]: loss = 0.161957 * 100, metric = 4.95% * 100;
 Minibatch[1501-1600]: loss = 0.166215 * 100, metric = 5.14% * 100;
 Minibatch[1601-1700]: loss = 0.159541 * 100, metric = 5.02% * 100;
 Minibatch[1701-1800]: loss = 0.170039 * 100, metric = 5.37% * 100;
 Minibatch[1801-1900]: loss = 0.157930 * 100, metric = 4.80% * 100;
 Minibatch[1901-2000]: loss = 0.166622 * 100, metric = 5.19% * 100;
Finished Epoch[55 of 200]: [Training] loss = 0.165600 * 2000, metric = 5.12% * 2000 751.236s (  2.7 samples/s);
Finished Evaluation [55]: Minibatch[1-2000]: metric = 13.26% * 2000;
 Minibatch[   1- 100]: loss = 0.174886 * 100, metric = 5.47% * 100;
 Minibatch[ 101- 200]: loss = 0.165701 * 100, metric = 5.17% * 100;
 Minibatch[ 201- 300]: loss = 0.173985 * 100, metric = 5.40% * 100;
 Minibatch[ 301- 400]: loss = 0.172326 * 100, metric = 5.28% * 100;
 Minibatch[ 401- 500]: loss = 0.176391 * 100, metric = 5.54% * 100;
 Minibatch[ 501- 600]: loss = 0.177034 * 100, metric = 5.51% * 100;
 Minibatch[ 601- 700]: loss = 0.168225 * 100, metric = 5.24% * 100;
 Minibatch[ 701- 800]: loss = 0.168905 * 100, metric = 5.19% * 100;
 Minibatch[ 801- 900]: loss = 0.164545 * 100, metric = 5.04% * 100;
 Minibatch[ 901-1000]: loss = 0.164106 * 100, metric = 5.16% * 100;
 Minibatch[1001-1100]: loss = 0.173891 * 100, metric = 5.35% * 100;
 Minibatch[1101-1200]: loss = 0.174305 * 100, metric = 5.43% * 100;
 Minibatch[1201-1300]: loss = 0.163044 * 100, metric = 4.81% * 100;
 Minibatch[1301-1400]: loss = 0.157936 * 100, metric = 4.87% * 100;
 Minibatch[1401-1500]: loss = 0.170938 * 100, metric = 5.29% * 100;
 Minibatch[1501-1600]: loss = 0.163269 * 100, metric = 4.90% * 100;
 Minibatch[1601-1700]: loss = 0.164593 * 100, metric = 4.87% * 100;
 Minibatch[1701-1800]: loss = 0.161825 * 100, metric = 5.04% * 100;
 Minibatch[1801-1900]: loss = 0.152026 * 100, metric = 4.60% * 100;
 Minibatch[1901-2000]: loss = 0.176530 * 100, metric = 5.41% * 100;
Finished Epoch[56 of 200]: [Training] loss = 0.168223 * 2000, metric = 5.18% * 2000 756.329s (  2.6 samples/s);
Finished Evaluation [56]: Minibatch[1-2000]: metric = 12.79% * 2000;
 Minibatch[   1- 100]: loss = 0.160232 * 100, metric = 4.98% * 100;
 Minibatch[ 101- 200]: loss = 0.160880 * 100, metric = 4.89% * 100;
 Minibatch[ 201- 300]: loss = 0.164773 * 100, metric = 5.09% * 100;
 Minibatch[ 301- 400]: loss = 0.165033 * 100, metric = 5.00% * 100;
 Minibatch[ 401- 500]: loss = 0.161971 * 100, metric = 4.91% * 100;
 Minibatch[ 501- 600]: loss = 0.157598 * 100, metric = 4.85% * 100;
 Minibatch[ 601- 700]: loss = 0.164033 * 100, metric = 5.01% * 100;
 Minibatch[ 701- 800]: loss = 0.159770 * 100, metric = 4.95% * 100;
 Minibatch[ 801- 900]: loss = 0.160510 * 100, metric = 4.86% * 100;
 Minibatch[ 901-1000]: loss = 0.155797 * 100, metric = 4.78% * 100;
 Minibatch[1001-1100]: loss = 0.170618 * 100, metric = 5.34% * 100;
 Minibatch[1101-1200]: loss = 0.156287 * 100, metric = 4.71% * 100;
 Minibatch[1201-1300]: loss = 0.162647 * 100, metric = 5.11% * 100;
 Minibatch[1301-1400]: loss = 0.160618 * 100, metric = 5.00% * 100;
 Minibatch[1401-1500]: loss = 0.166383 * 100, metric = 5.19% * 100;
 Minibatch[1501-1600]: loss = 0.162693 * 100, metric = 4.97% * 100;
 Minibatch[1601-1700]: loss = 0.156596 * 100, metric = 4.73% * 100;
 Minibatch[1701-1800]: loss = 0.167953 * 100, metric = 5.18% * 100;
 Minibatch[1801-1900]: loss = 0.163822 * 100, metric = 5.05% * 100;
 Minibatch[1901-2000]: loss = 0.168782 * 100, metric = 5.39% * 100;
Finished Epoch[57 of 200]: [Training] loss = 0.162350 * 2000, metric = 5.00% * 2000 751.924s (  2.7 samples/s);
Finished Evaluation [57]: Minibatch[1-2000]: metric = 12.81% * 2000;
 Minibatch[   1- 100]: loss = 0.159943 * 100, metric = 4.89% * 100;
 Minibatch[ 101- 200]: loss = 0.160072 * 100, metric = 4.94% * 100;
 Minibatch[ 201- 300]: loss = 0.160527 * 100, metric = 4.98% * 100;
 Minibatch[ 301- 400]: loss = 0.162222 * 100, metric = 5.00% * 100;
 Minibatch[ 401- 500]: loss = 0.174276 * 100, metric = 5.43% * 100;
 Minibatch[ 501- 600]: loss = 0.160629 * 100, metric = 4.96% * 100;
 Minibatch[ 601- 700]: loss = 0.168483 * 100, metric = 5.27% * 100;
 Minibatch[ 701- 800]: loss = 0.164872 * 100, metric = 5.02% * 100;
 Minibatch[ 801- 900]: loss = 0.162056 * 100, metric = 5.20% * 100;
 Minibatch[ 901-1000]: loss = 0.159498 * 100, metric = 5.06% * 100;
 Minibatch[1001-1100]: loss = 0.165813 * 100, metric = 5.18% * 100;
 Minibatch[1101-1200]: loss = 0.168155 * 100, metric = 5.16% * 100;
 Minibatch[1201-1300]: loss = 0.162833 * 100, metric = 5.02% * 100;
 Minibatch[1301-1400]: loss = 0.161255 * 100, metric = 5.04% * 100;
 Minibatch[1401-1500]: loss = 0.157284 * 100, metric = 4.82% * 100;
 Minibatch[1501-1600]: loss = 0.164295 * 100, metric = 5.04% * 100;
 Minibatch[1601-1700]: loss = 0.163048 * 100, metric = 4.95% * 100;
 Minibatch[1701-1800]: loss = 0.167031 * 100, metric = 5.13% * 100;
 Minibatch[1801-1900]: loss = 0.164637 * 100, metric = 5.08% * 100;
 Minibatch[1901-2000]: loss = 0.151206 * 100, metric = 4.64% * 100;
Finished Epoch[58 of 200]: [Training] loss = 0.162907 * 2000, metric = 5.04% * 2000 755.070s (  2.6 samples/s);
Finished Evaluation [58]: Minibatch[1-2000]: metric = 12.58% * 2000;
 Minibatch[   1- 100]: loss = 0.171289 * 100, metric = 5.30% * 100;
 Minibatch[ 101- 200]: loss = 0.173800 * 100, metric = 5.51% * 100;
 Minibatch[ 201- 300]: loss = 0.160204 * 100, metric = 4.74% * 100;
 Minibatch[ 301- 400]: loss = 0.156937 * 100, metric = 4.60% * 100;
 Minibatch[ 401- 500]: loss = 0.159852 * 100, metric = 4.88% * 100;
 Minibatch[ 501- 600]: loss = 0.158449 * 100, metric = 4.84% * 100;
 Minibatch[ 601- 700]: loss = 0.161546 * 100, metric = 4.96% * 100;
 Minibatch[ 701- 800]: loss = 0.160229 * 100, metric = 5.00% * 100;
 Minibatch[ 801- 900]: loss = 0.158388 * 100, metric = 4.84% * 100;
 Minibatch[ 901-1000]: loss = 0.157816 * 100, metric = 4.90% * 100;
 Minibatch[1001-1100]: loss = 0.157000 * 100, metric = 4.82% * 100;
 Minibatch[1101-1200]: loss = 0.161481 * 100, metric = 5.01% * 100;
 Minibatch[1201-1300]: loss = 0.163871 * 100, metric = 5.13% * 100;
 Minibatch[1301-1400]: loss = 0.159170 * 100, metric = 4.86% * 100;
 Minibatch[1401-1500]: loss = 0.161807 * 100, metric = 5.07% * 100;
 Minibatch[1501-1600]: loss = 0.158809 * 100, metric = 4.93% * 100;
 Minibatch[1601-1700]: loss = 0.157986 * 100, metric = 4.89% * 100;
 Minibatch[1701-1800]: loss = 0.154394 * 100, metric = 4.76% * 100;
 Minibatch[1801-1900]: loss = 0.156294 * 100, metric = 4.84% * 100;
 Minibatch[1901-2000]: loss = 0.159581 * 100, metric = 4.97% * 100;
Finished Epoch[59 of 200]: [Training] loss = 0.160445 * 2000, metric = 4.94% * 2000 750.483s (  2.7 samples/s);
Finished Evaluation [59]: Minibatch[1-2000]: metric = 13.37% * 2000;
 Minibatch[   1- 100]: loss = 0.154773 * 100, metric = 4.78% * 100;
 Minibatch[ 101- 200]: loss = 0.149804 * 100, metric = 4.69% * 100;
 Minibatch[ 201- 300]: loss = 0.147861 * 100, metric = 4.29% * 100;
 Minibatch[ 301- 400]: loss = 0.161018 * 100, metric = 5.01% * 100;
 Minibatch[ 401- 500]: loss = 0.156552 * 100, metric = 4.95% * 100;
 Minibatch[ 501- 600]: loss = 0.160631 * 100, metric = 5.09% * 100;
 Minibatch[ 601- 700]: loss = 0.149791 * 100, metric = 4.70% * 100;
 Minibatch[ 701- 800]: loss = 0.153149 * 100, metric = 4.75% * 100;
 Minibatch[ 801- 900]: loss = 0.155656 * 100, metric = 4.87% * 100;
 Minibatch[ 901-1000]: loss = 0.158438 * 100, metric = 5.00% * 100;
 Minibatch[1001-1100]: loss = 0.163263 * 100, metric = 5.02% * 100;
 Minibatch[1101-1200]: loss = 0.151055 * 100, metric = 4.71% * 100;
 Minibatch[1201-1300]: loss = 0.158391 * 100, metric = 4.93% * 100;
 Minibatch[1301-1400]: loss = 0.155627 * 100, metric = 4.83% * 100;
 Minibatch[1401-1500]: loss = 0.145995 * 100, metric = 4.46% * 100;
 Minibatch[1501-1600]: loss = 0.154972 * 100, metric = 4.72% * 100;
 Minibatch[1601-1700]: loss = 0.157935 * 100, metric = 4.89% * 100;
 Minibatch[1701-1800]: loss = 0.161930 * 100, metric = 5.01% * 100;
 Minibatch[1801-1900]: loss = 0.161219 * 100, metric = 5.04% * 100;
 Minibatch[1901-2000]: loss = 0.151010 * 100, metric = 4.67% * 100;
Finished Epoch[60 of 200]: [Training] loss = 0.155453 * 2000, metric = 4.82% * 2000 755.026s (  2.6 samples/s);
Finished Evaluation [60]: Minibatch[1-2000]: metric = 13.93% * 2000;
 Minibatch[   1- 100]: loss = 0.162418 * 100, metric = 5.16% * 100;
 Minibatch[ 101- 200]: loss = 0.143399 * 100, metric = 4.45% * 100;
 Minibatch[ 201- 300]: loss = 0.154542 * 100, metric = 4.80% * 100;
 Minibatch[ 301- 400]: loss = 0.157232 * 100, metric = 4.95% * 100;
 Minibatch[ 401- 500]: loss = 0.152020 * 100, metric = 4.65% * 100;
 Minibatch[ 501- 600]: loss = 0.139222 * 100, metric = 4.17% * 100;
 Minibatch[ 601- 700]: loss = 0.151256 * 100, metric = 4.68% * 100;
 Minibatch[ 701- 800]: loss = 0.156912 * 100, metric = 4.90% * 100;
 Minibatch[ 801- 900]: loss = 0.147923 * 100, metric = 4.53% * 100;
 Minibatch[ 901-1000]: loss = 0.148998 * 100, metric = 4.48% * 100;
 Minibatch[1001-1100]: loss = 0.153106 * 100, metric = 4.71% * 100;
 Minibatch[1101-1200]: loss = 0.153157 * 100, metric = 4.79% * 100;
 Minibatch[1201-1300]: loss = 0.147324 * 100, metric = 4.48% * 100;
 Minibatch[1301-1400]: loss = 0.141638 * 100, metric = 4.13% * 100;
 Minibatch[1401-1500]: loss = 0.157168 * 100, metric = 4.89% * 100;
 Minibatch[1501-1600]: loss = 0.162247 * 100, metric = 4.87% * 100;
 Minibatch[1601-1700]: loss = 0.162652 * 100, metric = 4.83% * 100;
 Minibatch[1701-1800]: loss = 0.151107 * 100, metric = 4.54% * 100;
 Minibatch[1801-1900]: loss = 0.156611 * 100, metric = 4.79% * 100;
 Minibatch[1901-2000]: loss = 0.152047 * 100, metric = 4.69% * 100;
Finished Epoch[61 of 200]: [Training] loss = 0.152549 * 2000, metric = 4.67% * 2000 750.777s (  2.7 samples/s);
Finished Evaluation [61]: Minibatch[1-2000]: metric = 13.45% * 2000;
 Minibatch[   1- 100]: loss = 0.150066 * 100, metric = 4.58% * 100;
 Minibatch[ 101- 200]: loss = 0.147987 * 100, metric = 4.54% * 100;
 Minibatch[ 201- 300]: loss = 0.153459 * 100, metric = 4.66% * 100;
 Minibatch[ 301- 400]: loss = 0.149292 * 100, metric = 4.71% * 100;
 Minibatch[ 401- 500]: loss = 0.155581 * 100, metric = 4.75% * 100;
 Minibatch[ 501- 600]: loss = 0.155320 * 100, metric = 4.71% * 100;
 Minibatch[ 601- 700]: loss = 0.163369 * 100, metric = 5.09% * 100;
 Minibatch[ 701- 800]: loss = 0.152937 * 100, metric = 4.63% * 100;
 Minibatch[ 801- 900]: loss = 0.153036 * 100, metric = 4.69% * 100;
 Minibatch[ 901-1000]: loss = 0.158813 * 100, metric = 4.84% * 100;
 Minibatch[1001-1100]: loss = 0.144358 * 100, metric = 4.51% * 100;
 Minibatch[1101-1200]: loss = 0.154833 * 100, metric = 4.76% * 100;
 Minibatch[1201-1300]: loss = 0.147676 * 100, metric = 4.50% * 100;
 Minibatch[1301-1400]: loss = 0.161884 * 100, metric = 4.91% * 100;
 Minibatch[1401-1500]: loss = 0.150330 * 100, metric = 4.69% * 100;
 Minibatch[1501-1600]: loss = 0.147013 * 100, metric = 4.50% * 100;
 Minibatch[1601-1700]: loss = 0.151905 * 100, metric = 4.59% * 100;
 Minibatch[1701-1800]: loss = 0.154921 * 100, metric = 4.79% * 100;
 Minibatch[1801-1900]: loss = 0.154482 * 100, metric = 4.86% * 100;
 Minibatch[1901-2000]: loss = 0.153211 * 100, metric = 4.74% * 100;
Finished Epoch[62 of 200]: [Training] loss = 0.153024 * 2000, metric = 4.70% * 2000 749.824s (  2.7 samples/s);
Finished Evaluation [62]: Minibatch[1-2000]: metric = 14.39% * 2000;
 Minibatch[   1- 100]: loss = 0.154012 * 100, metric = 4.65% * 100;
 Minibatch[ 101- 200]: loss = 0.142694 * 100, metric = 4.39% * 100;
 Minibatch[ 201- 300]: loss = 0.158042 * 100, metric = 4.84% * 100;
 Minibatch[ 301- 400]: loss = 0.141401 * 100, metric = 4.19% * 100;
 Minibatch[ 401- 500]: loss = 0.143755 * 100, metric = 4.49% * 100;
 Minibatch[ 501- 600]: loss = 0.143756 * 100, metric = 4.40% * 100;
 Minibatch[ 601- 700]: loss = 0.153023 * 100, metric = 4.77% * 100;
 Minibatch[ 701- 800]: loss = 0.154776 * 100, metric = 4.90% * 100;
 Minibatch[ 801- 900]: loss = 0.155526 * 100, metric = 4.83% * 100;
 Minibatch[ 901-1000]: loss = 0.142575 * 100, metric = 4.40% * 100;
 Minibatch[1001-1100]: loss = 0.159257 * 100, metric = 4.79% * 100;
 Minibatch[1101-1200]: loss = 0.147500 * 100, metric = 4.65% * 100;
 Minibatch[1201-1300]: loss = 0.150235 * 100, metric = 4.67% * 100;
 Minibatch[1301-1400]: loss = 0.147052 * 100, metric = 4.50% * 100;
 Minibatch[1401-1500]: loss = 0.143974 * 100, metric = 4.47% * 100;
 Minibatch[1501-1600]: loss = 0.148863 * 100, metric = 4.63% * 100;
 Minibatch[1601-1700]: loss = 0.149546 * 100, metric = 4.58% * 100;
 Minibatch[1701-1800]: loss = 0.143890 * 100, metric = 4.41% * 100;
 Minibatch[1801-1900]: loss = 0.150466 * 100, metric = 4.55% * 100;
 Minibatch[1901-2000]: loss = 0.155595 * 100, metric = 4.87% * 100;
Finished Epoch[63 of 200]: [Training] loss = 0.149297 * 2000, metric = 4.60% * 2000 745.777s (  2.7 samples/s);
Finished Evaluation [63]: Minibatch[1-2000]: metric = 13.14% * 2000;
 Minibatch[   1- 100]: loss = 0.150380 * 100, metric = 4.64% * 100;
 Minibatch[ 101- 200]: loss = 0.151491 * 100, metric = 4.71% * 100;
 Minibatch[ 201- 300]: loss = 0.150864 * 100, metric = 4.65% * 100;
 Minibatch[ 301- 400]: loss = 0.154141 * 100, metric = 4.76% * 100;
 Minibatch[ 401- 500]: loss = 0.152094 * 100, metric = 4.69% * 100;
 Minibatch[ 501- 600]: loss = 0.148553 * 100, metric = 4.57% * 100;
 Minibatch[ 601- 700]: loss = 0.145211 * 100, metric = 4.38% * 100;
 Minibatch[ 701- 800]: loss = 0.156408 * 100, metric = 4.91% * 100;
 Minibatch[ 801- 900]: loss = 0.153789 * 100, metric = 4.73% * 100;
 Minibatch[ 901-1000]: loss = 0.147395 * 100, metric = 4.62% * 100;
 Minibatch[1001-1100]: loss = 0.155538 * 100, metric = 4.80% * 100;
 Minibatch[1101-1200]: loss = 0.150892 * 100, metric = 4.72% * 100;
 Minibatch[1201-1300]: loss = 0.144983 * 100, metric = 4.51% * 100;
 Minibatch[1301-1400]: loss = 0.156139 * 100, metric = 4.95% * 100;
 Minibatch[1401-1500]: loss = 0.155222 * 100, metric = 4.94% * 100;
 Minibatch[1501-1600]: loss = 0.157486 * 100, metric = 5.01% * 100;
 Minibatch[1601-1700]: loss = 0.140850 * 100, metric = 4.35% * 100;
 Minibatch[1701-1800]: loss = 0.148906 * 100, metric = 4.57% * 100;
 Minibatch[1801-1900]: loss = 0.157058 * 100, metric = 4.99% * 100;
 Minibatch[1901-2000]: loss = 0.149439 * 100, metric = 4.56% * 100;
Finished Epoch[64 of 200]: [Training] loss = 0.151342 * 2000, metric = 4.70% * 2000 743.534s (  2.7 samples/s);
Finished Evaluation [64]: Minibatch[1-2000]: metric = 17.42% * 2000;
 Minibatch[   1- 100]: loss = 0.144517 * 100, metric = 4.56% * 100;
 Minibatch[ 101- 200]: loss = 0.142881 * 100, metric = 4.42% * 100;
 Minibatch[ 201- 300]: loss = 0.148080 * 100, metric = 4.64% * 100;
 Minibatch[ 301- 400]: loss = 0.151209 * 100, metric = 4.71% * 100;
 Minibatch[ 401- 500]: loss = 0.146053 * 100, metric = 4.46% * 100;
 Minibatch[ 501- 600]: loss = 0.146429 * 100, metric = 4.64% * 100;
 Minibatch[ 601- 700]: loss = 0.154162 * 100, metric = 4.62% * 100;
 Minibatch[ 701- 800]: loss = 0.162945 * 100, metric = 5.22% * 100;
 Minibatch[ 801- 900]: loss = 0.150564 * 100, metric = 4.63% * 100;
 Minibatch[ 901-1000]: loss = 0.152903 * 100, metric = 4.79% * 100;
 Minibatch[1001-1100]: loss = 0.144322 * 100, metric = 4.50% * 100;
 Minibatch[1101-1200]: loss = 0.149674 * 100, metric = 4.67% * 100;
 Minibatch[1201-1300]: loss = 0.159696 * 100, metric = 4.87% * 100;
 Minibatch[1301-1400]: loss = 0.149958 * 100, metric = 4.61% * 100;
 Minibatch[1401-1500]: loss = 0.146035 * 100, metric = 4.55% * 100;
 Minibatch[1501-1600]: loss = 0.148194 * 100, metric = 4.57% * 100;
 Minibatch[1601-1700]: loss = 0.147994 * 100, metric = 4.55% * 100;
 Minibatch[1701-1800]: loss = 0.152107 * 100, metric = 4.69% * 100;
 Minibatch[1801-1900]: loss = 0.147704 * 100, metric = 4.61% * 100;
 Minibatch[1901-2000]: loss = 0.144872 * 100, metric = 4.45% * 100;
Finished Epoch[65 of 200]: [Training] loss = 0.149515 * 2000, metric = 4.64% * 2000 752.282s (  2.7 samples/s);
Finished Evaluation [65]: Minibatch[1-2000]: metric = 12.77% * 2000;
 Minibatch[   1- 100]: loss = 0.144955 * 100, metric = 4.50% * 100;
 Minibatch[ 101- 200]: loss = 0.152501 * 100, metric = 4.77% * 100;
 Minibatch[ 201- 300]: loss = 0.148997 * 100, metric = 4.66% * 100;
 Minibatch[ 301- 400]: loss = 0.146202 * 100, metric = 4.60% * 100;
 Minibatch[ 401- 500]: loss = 0.150318 * 100, metric = 4.67% * 100;
 Minibatch[ 501- 600]: loss = 0.139798 * 100, metric = 4.26% * 100;
 Minibatch[ 601- 700]: loss = 0.137828 * 100, metric = 4.22% * 100;
 Minibatch[ 701- 800]: loss = 0.142550 * 100, metric = 4.35% * 100;
 Minibatch[ 801- 900]: loss = 0.131917 * 100, metric = 4.08% * 100;
 Minibatch[ 901-1000]: loss = 0.142579 * 100, metric = 4.31% * 100;
 Minibatch[1001-1100]: loss = 0.150098 * 100, metric = 4.71% * 100;
 Minibatch[1101-1200]: loss = 0.146219 * 100, metric = 4.43% * 100;
 Minibatch[1201-1300]: loss = 0.151620 * 100, metric = 4.69% * 100;
 Minibatch[1301-1400]: loss = 0.141454 * 100, metric = 4.35% * 100;
 Minibatch[1401-1500]: loss = 0.141278 * 100, metric = 4.37% * 100;
 Minibatch[1501-1600]: loss = 0.146928 * 100, metric = 4.58% * 100;
 Minibatch[1601-1700]: loss = 0.142208 * 100, metric = 4.24% * 100;
 Minibatch[1701-1800]: loss = 0.149045 * 100, metric = 4.64% * 100;
 Minibatch[1801-1900]: loss = 0.148600 * 100, metric = 4.63% * 100;
 Minibatch[1901-2000]: loss = 0.143583 * 100, metric = 4.46% * 100;
Finished Epoch[66 of 200]: [Training] loss = 0.144934 * 2000, metric = 4.48% * 2000 745.606s (  2.7 samples/s);
Finished Evaluation [66]: Minibatch[1-2000]: metric = 13.43% * 2000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
