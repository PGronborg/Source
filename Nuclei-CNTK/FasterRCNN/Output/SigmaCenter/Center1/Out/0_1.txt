Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.072836 * 100, metric = 21.82% * 100;
 Minibatch[ 101- 200]: loss = 0.908679 * 100, metric = 20.82% * 100;
 Minibatch[ 201- 300]: loss = 0.795176 * 100, metric = 18.99% * 100;
 Minibatch[ 301- 400]: loss = 0.786298 * 100, metric = 18.18% * 100;
 Minibatch[ 401- 500]: loss = 0.730135 * 100, metric = 16.78% * 100;
 Minibatch[ 501- 600]: loss = 0.729703 * 100, metric = 16.38% * 100;
 Minibatch[ 601- 700]: loss = 0.697089 * 100, metric = 15.04% * 100;
 Minibatch[ 701- 800]: loss = 0.657477 * 100, metric = 14.39% * 100;
 Minibatch[ 801- 900]: loss = 0.700765 * 100, metric = 15.31% * 100;
 Minibatch[ 901-1000]: loss = 0.700742 * 100, metric = 15.64% * 100;
 Minibatch[1001-1100]: loss = 0.695626 * 100, metric = 15.32% * 100;
 Minibatch[1101-1200]: loss = 0.677057 * 100, metric = 14.71% * 100;
 Minibatch[1201-1300]: loss = 0.685974 * 100, metric = 15.52% * 100;
 Minibatch[1301-1400]: loss = 0.637662 * 100, metric = 14.45% * 100;
 Minibatch[1401-1500]: loss = 0.667031 * 100, metric = 15.13% * 100;
 Minibatch[1501-1600]: loss = 0.629381 * 100, metric = 14.64% * 100;
 Minibatch[1601-1700]: loss = 0.634792 * 100, metric = 14.36% * 100;
 Minibatch[1701-1800]: loss = 0.630289 * 100, metric = 14.06% * 100;
 Minibatch[1801-1900]: loss = 0.634750 * 100, metric = 14.55% * 100;
 Minibatch[1901-2000]: loss = 0.624493 * 100, metric = 13.89% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.714798 * 2000, metric = 16.00% * 2000 722.280s (  2.8 samples/s);
Finished Evaluation [1]: Minibatch[1-1000]: metric = 19.20% * 1000;
0.6271753527522087
 Minibatch[   1- 100]: loss = 0.599633 * 100, metric = 13.63% * 100;
 Minibatch[ 101- 200]: loss = 0.637079 * 100, metric = 14.69% * 100;
 Minibatch[ 201- 300]: loss = 0.609435 * 100, metric = 13.43% * 100;
 Minibatch[ 301- 400]: loss = 0.623725 * 100, metric = 14.01% * 100;
 Minibatch[ 401- 500]: loss = 0.607274 * 100, metric = 13.72% * 100;
 Minibatch[ 501- 600]: loss = 0.632120 * 100, metric = 13.89% * 100;
 Minibatch[ 601- 700]: loss = 0.598467 * 100, metric = 13.56% * 100;
 Minibatch[ 701- 800]: loss = 0.610229 * 100, metric = 14.03% * 100;
 Minibatch[ 801- 900]: loss = 0.588789 * 100, metric = 13.30% * 100;
 Minibatch[ 901-1000]: loss = 0.573323 * 100, metric = 12.71% * 100;
 Minibatch[1001-1100]: loss = 0.597725 * 100, metric = 13.65% * 100;
 Minibatch[1101-1200]: loss = 0.583124 * 100, metric = 13.11% * 100;
 Minibatch[1201-1300]: loss = 0.590199 * 100, metric = 13.64% * 100;
 Minibatch[1301-1400]: loss = 0.588278 * 100, metric = 13.15% * 100;
 Minibatch[1401-1500]: loss = 0.576466 * 100, metric = 13.08% * 100;
 Minibatch[1501-1600]: loss = 0.565717 * 100, metric = 12.73% * 100;
 Minibatch[1601-1700]: loss = 0.568486 * 100, metric = 12.97% * 100;
 Minibatch[1701-1800]: loss = 0.599070 * 100, metric = 13.66% * 100;
 Minibatch[1801-1900]: loss = 0.583494 * 100, metric = 13.33% * 100;
 Minibatch[1901-2000]: loss = 0.554281 * 100, metric = 12.49% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.594346 * 2000, metric = 13.44% * 2000 640.943s (  3.1 samples/s);
Finished Evaluation [2]: Minibatch[1-1000]: metric = 16.58% * 1000;
0.5653075945451855
 Minibatch[   1- 100]: loss = 0.573430 * 100, metric = 13.09% * 100;
 Minibatch[ 101- 200]: loss = 0.575287 * 100, metric = 13.16% * 100;
 Minibatch[ 201- 300]: loss = 0.569057 * 100, metric = 12.77% * 100;
 Minibatch[ 301- 400]: loss = 0.581672 * 100, metric = 13.22% * 100;
 Minibatch[ 401- 500]: loss = 0.588346 * 100, metric = 13.60% * 100;
 Minibatch[ 501- 600]: loss = 0.579525 * 100, metric = 13.34% * 100;
 Minibatch[ 601- 700]: loss = 0.595272 * 100, metric = 13.38% * 100;
 Minibatch[ 701- 800]: loss = 0.550463 * 100, metric = 12.34% * 100;
 Minibatch[ 801- 900]: loss = 0.579980 * 100, metric = 13.48% * 100;
 Minibatch[ 901-1000]: loss = 0.552637 * 100, metric = 12.83% * 100;
 Minibatch[1001-1100]: loss = 0.571310 * 100, metric = 13.31% * 100;
 Minibatch[1101-1200]: loss = 0.558564 * 100, metric = 12.96% * 100;
 Minibatch[1201-1300]: loss = 0.551909 * 100, metric = 12.86% * 100;
 Minibatch[1301-1400]: loss = 0.574729 * 100, metric = 13.14% * 100;
 Minibatch[1401-1500]: loss = 0.566300 * 100, metric = 12.97% * 100;
 Minibatch[1501-1600]: loss = 0.554936 * 100, metric = 12.68% * 100;
 Minibatch[1601-1700]: loss = 0.548514 * 100, metric = 12.38% * 100;
 Minibatch[1701-1800]: loss = 0.559536 * 100, metric = 12.73% * 100;
 Minibatch[1801-1900]: loss = 0.541126 * 100, metric = 12.32% * 100;
 Minibatch[1901-2000]: loss = 0.556639 * 100, metric = 12.73% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.566462 * 2000, metric = 12.96% * 2000 636.908s (  3.1 samples/s);
Finished Evaluation [3]: Minibatch[1-1000]: metric = 15.58% * 1000;
0.529774841889739
 Minibatch[   1- 100]: loss = 0.553697 * 100, metric = 12.26% * 100;
 Minibatch[ 101- 200]: loss = 0.525889 * 100, metric = 11.86% * 100;
 Minibatch[ 201- 300]: loss = 0.545966 * 100, metric = 12.63% * 100;
 Minibatch[ 301- 400]: loss = 0.506439 * 100, metric = 11.39% * 100;
 Minibatch[ 401- 500]: loss = 0.549823 * 100, metric = 12.42% * 100;
 Minibatch[ 501- 600]: loss = 0.517670 * 100, metric = 11.65% * 100;
 Minibatch[ 601- 700]: loss = 0.533999 * 100, metric = 12.23% * 100;
 Minibatch[ 701- 800]: loss = 0.538797 * 100, metric = 12.32% * 100;
 Minibatch[ 801- 900]: loss = 0.541958 * 100, metric = 12.45% * 100;
 Minibatch[ 901-1000]: loss = 0.535434 * 100, metric = 12.29% * 100;
 Minibatch[1001-1100]: loss = 0.554813 * 100, metric = 12.81% * 100;
 Minibatch[1101-1200]: loss = 0.531643 * 100, metric = 12.29% * 100;
 Minibatch[1201-1300]: loss = 0.535241 * 100, metric = 12.29% * 100;
 Minibatch[1301-1400]: loss = 0.550571 * 100, metric = 12.57% * 100;
 Minibatch[1401-1500]: loss = 0.555736 * 100, metric = 12.78% * 100;
 Minibatch[1501-1600]: loss = 0.506790 * 100, metric = 11.50% * 100;
 Minibatch[1601-1700]: loss = 0.537247 * 100, metric = 12.43% * 100;
 Minibatch[1701-1800]: loss = 0.551469 * 100, metric = 12.53% * 100;
 Minibatch[1801-1900]: loss = 0.529511 * 100, metric = 12.04% * 100;
 Minibatch[1901-2000]: loss = 0.531687 * 100, metric = 11.95% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.536719 * 2000, metric = 12.24% * 2000 638.196s (  3.1 samples/s);
Finished Evaluation [4]: Minibatch[1-1000]: metric = 19.63% * 1000;
 Minibatch[   1- 100]: loss = 0.550083 * 100, metric = 12.65% * 100;
 Minibatch[ 101- 200]: loss = 0.527336 * 100, metric = 12.14% * 100;
 Minibatch[ 201- 300]: loss = 0.517264 * 100, metric = 11.96% * 100;
 Minibatch[ 301- 400]: loss = 0.562194 * 100, metric = 12.77% * 100;
 Minibatch[ 401- 500]: loss = 0.500841 * 100, metric = 11.28% * 100;
 Minibatch[ 501- 600]: loss = 0.514491 * 100, metric = 11.49% * 100;
 Minibatch[ 601- 700]: loss = 0.527032 * 100, metric = 11.77% * 100;
 Minibatch[ 701- 800]: loss = 0.536970 * 100, metric = 12.06% * 100;
 Minibatch[ 801- 900]: loss = 0.508895 * 100, metric = 11.75% * 100;
 Minibatch[ 901-1000]: loss = 0.515233 * 100, metric = 11.60% * 100;
 Minibatch[1001-1100]: loss = 0.525017 * 100, metric = 12.06% * 100;
 Minibatch[1101-1200]: loss = 0.517095 * 100, metric = 11.48% * 100;
 Minibatch[1201-1300]: loss = 0.536578 * 100, metric = 12.20% * 100;
 Minibatch[1301-1400]: loss = 0.567502 * 100, metric = 12.96% * 100;
 Minibatch[1401-1500]: loss = 0.530192 * 100, metric = 12.21% * 100;
 Minibatch[1501-1600]: loss = 0.527715 * 100, metric = 12.15% * 100;
 Minibatch[1601-1700]: loss = 0.558000 * 100, metric = 12.92% * 100;
 Minibatch[1701-1800]: loss = 0.567964 * 100, metric = 13.21% * 100;
 Minibatch[1801-1900]: loss = 0.547294 * 100, metric = 12.52% * 100;
 Minibatch[1901-2000]: loss = 0.530901 * 100, metric = 12.16% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.533430 * 2000, metric = 12.17% * 2000 639.974s (  3.1 samples/s);
Finished Evaluation [5]: Minibatch[1-1000]: metric = 19.57% * 1000;
 Minibatch[   1- 100]: loss = 0.531747 * 100, metric = 12.35% * 100;
 Minibatch[ 101- 200]: loss = 0.521872 * 100, metric = 11.91% * 100;
 Minibatch[ 201- 300]: loss = 0.536211 * 100, metric = 12.41% * 100;
 Minibatch[ 301- 400]: loss = 0.531903 * 100, metric = 12.22% * 100;
 Minibatch[ 401- 500]: loss = 0.507811 * 100, metric = 11.89% * 100;
 Minibatch[ 501- 600]: loss = 0.532761 * 100, metric = 12.32% * 100;
 Minibatch[ 601- 700]: loss = 0.525859 * 100, metric = 12.01% * 100;
 Minibatch[ 701- 800]: loss = 0.537681 * 100, metric = 12.27% * 100;
 Minibatch[ 801- 900]: loss = 0.528346 * 100, metric = 12.27% * 100;
 Minibatch[ 901-1000]: loss = 0.523476 * 100, metric = 12.06% * 100;
 Minibatch[1001-1100]: loss = 0.539185 * 100, metric = 12.21% * 100;
 Minibatch[1101-1200]: loss = 0.546653 * 100, metric = 12.64% * 100;
 Minibatch[1201-1300]: loss = 0.556379 * 100, metric = 12.90% * 100;
 Minibatch[1301-1400]: loss = 0.536541 * 100, metric = 12.35% * 100;
 Minibatch[1401-1500]: loss = 0.546934 * 100, metric = 12.67% * 100;
 Minibatch[1501-1600]: loss = 0.521584 * 100, metric = 11.78% * 100;
 Minibatch[1601-1700]: loss = 0.529430 * 100, metric = 12.24% * 100;
 Minibatch[1701-1800]: loss = 0.522183 * 100, metric = 11.89% * 100;
 Minibatch[1801-1900]: loss = 0.540491 * 100, metric = 12.47% * 100;
 Minibatch[1901-2000]: loss = 0.526616 * 100, metric = 12.35% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.532183 * 2000, metric = 12.26% * 2000 661.148s (  3.0 samples/s);
Finished Evaluation [6]: Minibatch[1-1000]: metric = 19.14% * 1000;
 Minibatch[   1- 100]: loss = 0.530875 * 100, metric = 12.34% * 100;
 Minibatch[ 101- 200]: loss = 0.537573 * 100, metric = 12.42% * 100;
 Minibatch[ 201- 300]: loss = 0.540498 * 100, metric = 12.48% * 100;
 Minibatch[ 301- 400]: loss = 0.519305 * 100, metric = 11.91% * 100;
 Minibatch[ 401- 500]: loss = 0.535025 * 100, metric = 12.14% * 100;
 Minibatch[ 501- 600]: loss = 0.496872 * 100, metric = 11.34% * 100;
 Minibatch[ 601- 700]: loss = 0.529043 * 100, metric = 12.01% * 100;
 Minibatch[ 701- 800]: loss = 0.539397 * 100, metric = 12.13% * 100;
 Minibatch[ 801- 900]: loss = 0.543939 * 100, metric = 12.41% * 100;
 Minibatch[ 901-1000]: loss = 0.534962 * 100, metric = 12.06% * 100;
 Minibatch[1001-1100]: loss = 0.541395 * 100, metric = 12.47% * 100;
 Minibatch[1101-1200]: loss = 0.520873 * 100, metric = 11.97% * 100;
 Minibatch[1201-1300]: loss = 0.530411 * 100, metric = 12.45% * 100;
 Minibatch[1301-1400]: loss = 0.527516 * 100, metric = 12.06% * 100;
 Minibatch[1401-1500]: loss = 0.517831 * 100, metric = 11.67% * 100;
 Minibatch[1501-1600]: loss = 0.529009 * 100, metric = 12.03% * 100;
 Minibatch[1601-1700]: loss = 0.535774 * 100, metric = 12.40% * 100;
 Minibatch[1701-1800]: loss = 0.513666 * 100, metric = 11.92% * 100;
 Minibatch[1801-1900]: loss = 0.527096 * 100, metric = 12.14% * 100;
 Minibatch[1901-2000]: loss = 0.529521 * 100, metric = 12.33% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.529029 * 2000, metric = 12.13% * 2000 651.763s (  3.1 samples/s);
Finished Evaluation [7]: Minibatch[1-1000]: metric = 16.53% * 1000;
 Minibatch[   1- 100]: loss = 0.529387 * 100, metric = 12.30% * 100;
 Minibatch[ 101- 200]: loss = 0.526765 * 100, metric = 12.30% * 100;
 Minibatch[ 201- 300]: loss = 0.510198 * 100, metric = 11.65% * 100;
 Minibatch[ 301- 400]: loss = 0.505617 * 100, metric = 11.72% * 100;
 Minibatch[ 401- 500]: loss = 0.534942 * 100, metric = 12.30% * 100;
 Minibatch[ 501- 600]: loss = 0.555976 * 100, metric = 12.99% * 100;
 Minibatch[ 601- 700]: loss = 0.515048 * 100, metric = 12.15% * 100;
 Minibatch[ 701- 800]: loss = 0.536079 * 100, metric = 12.34% * 100;
 Minibatch[ 801- 900]: loss = 0.498934 * 100, metric = 11.15% * 100;
 Minibatch[ 901-1000]: loss = 0.498314 * 100, metric = 11.36% * 100;
 Minibatch[1001-1100]: loss = 0.502931 * 100, metric = 11.72% * 100;
 Minibatch[1101-1200]: loss = 0.497507 * 100, metric = 11.42% * 100;
 Minibatch[1201-1300]: loss = 0.522991 * 100, metric = 12.04% * 100;
 Minibatch[1301-1400]: loss = 0.523398 * 100, metric = 12.24% * 100;
 Minibatch[1401-1500]: loss = 0.506619 * 100, metric = 11.62% * 100;
 Minibatch[1501-1600]: loss = 0.512521 * 100, metric = 11.73% * 100;
 Minibatch[1601-1700]: loss = 0.496909 * 100, metric = 11.18% * 100;
 Minibatch[1701-1800]: loss = 0.499861 * 100, metric = 11.38% * 100;
 Minibatch[1801-1900]: loss = 0.513060 * 100, metric = 11.67% * 100;
 Minibatch[1901-2000]: loss = 0.507401 * 100, metric = 11.57% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.514723 * 2000, metric = 11.84% * 2000 652.736s (  3.1 samples/s);
Finished Evaluation [8]: Minibatch[1-1000]: metric = 17.24% * 1000;
 Minibatch[   1- 100]: loss = 0.488571 * 100, metric = 11.13% * 100;
 Minibatch[ 101- 200]: loss = 0.528729 * 100, metric = 11.87% * 100;
 Minibatch[ 201- 300]: loss = 0.507227 * 100, metric = 11.34% * 100;
 Minibatch[ 301- 400]: loss = 0.524261 * 100, metric = 11.79% * 100;
 Minibatch[ 401- 500]: loss = 0.515283 * 100, metric = 11.73% * 100;
 Minibatch[ 501- 600]: loss = 0.511457 * 100, metric = 11.66% * 100;
 Minibatch[ 601- 700]: loss = 0.508358 * 100, metric = 11.57% * 100;
 Minibatch[ 701- 800]: loss = 0.492325 * 100, metric = 11.18% * 100;
 Minibatch[ 801- 900]: loss = 0.483850 * 100, metric = 11.03% * 100;
 Minibatch[ 901-1000]: loss = 0.506335 * 100, metric = 11.70% * 100;
 Minibatch[1001-1100]: loss = 0.477421 * 100, metric = 10.64% * 100;
 Minibatch[1101-1200]: loss = 0.509758 * 100, metric = 11.42% * 100;
 Minibatch[1201-1300]: loss = 0.504664 * 100, metric = 11.73% * 100;
 Minibatch[1301-1400]: loss = 0.494862 * 100, metric = 10.96% * 100;
 Minibatch[1401-1500]: loss = 0.511092 * 100, metric = 11.60% * 100;
 Minibatch[1501-1600]: loss = 0.513903 * 100, metric = 11.35% * 100;
 Minibatch[1601-1700]: loss = 0.502060 * 100, metric = 11.39% * 100;
 Minibatch[1701-1800]: loss = 0.483663 * 100, metric = 10.76% * 100;
 Minibatch[1801-1900]: loss = 0.489539 * 100, metric = 11.07% * 100;
 Minibatch[1901-2000]: loss = 0.513157 * 100, metric = 11.64% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.503326 * 2000, metric = 11.38% * 2000 651.752s (  3.1 samples/s);
Finished Evaluation [9]: Minibatch[1-1000]: metric = 15.04% * 1000;
0.5276392725408077
 Minibatch[   1- 100]: loss = 0.529309 * 100, metric = 12.30% * 100;
 Minibatch[ 101- 200]: loss = 0.495714 * 100, metric = 11.31% * 100;
 Minibatch[ 201- 300]: loss = 0.508213 * 100, metric = 11.51% * 100;
 Minibatch[ 301- 400]: loss = 0.501401 * 100, metric = 11.36% * 100;
 Minibatch[ 401- 500]: loss = 0.517907 * 100, metric = 11.95% * 100;
 Minibatch[ 501- 600]: loss = 0.488272 * 100, metric = 10.95% * 100;
 Minibatch[ 601- 700]: loss = 0.485996 * 100, metric = 10.95% * 100;
 Minibatch[ 701- 800]: loss = 0.482982 * 100, metric = 10.68% * 100;
 Minibatch[ 801- 900]: loss = 0.508651 * 100, metric = 11.32% * 100;
 Minibatch[ 901-1000]: loss = 0.517129 * 100, metric = 11.66% * 100;
 Minibatch[1001-1100]: loss = 0.508609 * 100, metric = 11.70% * 100;
 Minibatch[1101-1200]: loss = 0.504489 * 100, metric = 11.52% * 100;
 Minibatch[1201-1300]: loss = 0.503664 * 100, metric = 11.66% * 100;
 Minibatch[1301-1400]: loss = 0.505912 * 100, metric = 11.45% * 100;
 Minibatch[1401-1500]: loss = 0.482385 * 100, metric = 10.95% * 100;
 Minibatch[1501-1600]: loss = 0.495861 * 100, metric = 11.32% * 100;
 Minibatch[1601-1700]: loss = 0.495612 * 100, metric = 10.96% * 100;
 Minibatch[1701-1800]: loss = 0.511403 * 100, metric = 11.47% * 100;
 Minibatch[1801-1900]: loss = 0.512183 * 100, metric = 11.97% * 100;
 Minibatch[1901-2000]: loss = 0.494489 * 100, metric = 11.51% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.502509 * 2000, metric = 11.43% * 2000 653.437s (  3.1 samples/s);
Finished Evaluation [10]: Minibatch[1-1000]: metric = 15.86% * 1000;
 Minibatch[   1- 100]: loss = 0.475277 * 100, metric = 10.62% * 100;
 Minibatch[ 101- 200]: loss = 0.491222 * 100, metric = 11.13% * 100;
 Minibatch[ 201- 300]: loss = 0.505125 * 100, metric = 11.55% * 100;
 Minibatch[ 301- 400]: loss = 0.493187 * 100, metric = 11.26% * 100;
 Minibatch[ 401- 500]: loss = 0.488623 * 100, metric = 10.97% * 100;
 Minibatch[ 501- 600]: loss = 0.509520 * 100, metric = 11.72% * 100;
 Minibatch[ 601- 700]: loss = 0.487312 * 100, metric = 11.08% * 100;
 Minibatch[ 701- 800]: loss = 0.505598 * 100, metric = 11.71% * 100;
 Minibatch[ 801- 900]: loss = 0.488225 * 100, metric = 11.03% * 100;
 Minibatch[ 901-1000]: loss = 0.505355 * 100, metric = 11.38% * 100;
 Minibatch[1001-1100]: loss = 0.498346 * 100, metric = 11.04% * 100;
 Minibatch[1101-1200]: loss = 0.505371 * 100, metric = 11.58% * 100;
 Minibatch[1201-1300]: loss = 0.496068 * 100, metric = 11.05% * 100;
 Minibatch[1301-1400]: loss = 0.484915 * 100, metric = 11.05% * 100;
 Minibatch[1401-1500]: loss = 0.497509 * 100, metric = 11.32% * 100;
 Minibatch[1501-1600]: loss = 0.484622 * 100, metric = 10.97% * 100;
 Minibatch[1601-1700]: loss = 0.489501 * 100, metric = 10.96% * 100;
 Minibatch[1701-1800]: loss = 0.496533 * 100, metric = 11.30% * 100;
 Minibatch[1801-1900]: loss = 0.500422 * 100, metric = 11.49% * 100;
 Minibatch[1901-2000]: loss = 0.492344 * 100, metric = 11.41% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.494754 * 2000, metric = 11.23% * 2000 653.662s (  3.1 samples/s);
Finished Evaluation [11]: Minibatch[1-1000]: metric = 16.68% * 1000;
 Minibatch[   1- 100]: loss = 0.477405 * 100, metric = 10.86% * 100;
 Minibatch[ 101- 200]: loss = 0.483054 * 100, metric = 10.63% * 100;
 Minibatch[ 201- 300]: loss = 0.483870 * 100, metric = 10.97% * 100;
 Minibatch[ 301- 400]: loss = 0.522919 * 100, metric = 12.26% * 100;
 Minibatch[ 401- 500]: loss = 0.487601 * 100, metric = 11.01% * 100;
 Minibatch[ 501- 600]: loss = 0.480587 * 100, metric = 10.65% * 100;
 Minibatch[ 601- 700]: loss = 0.488914 * 100, metric = 10.89% * 100;
 Minibatch[ 701- 800]: loss = 0.495242 * 100, metric = 11.22% * 100;
 Minibatch[ 801- 900]: loss = 0.492839 * 100, metric = 10.98% * 100;
 Minibatch[ 901-1000]: loss = 0.506084 * 100, metric = 11.38% * 100;
 Minibatch[1001-1100]: loss = 0.500667 * 100, metric = 11.67% * 100;
 Minibatch[1101-1200]: loss = 0.491946 * 100, metric = 11.16% * 100;
 Minibatch[1201-1300]: loss = 0.499424 * 100, metric = 11.31% * 100;
 Minibatch[1301-1400]: loss = 0.488225 * 100, metric = 11.01% * 100;
 Minibatch[1401-1500]: loss = 0.504141 * 100, metric = 11.79% * 100;
 Minibatch[1501-1600]: loss = 0.466384 * 100, metric = 10.48% * 100;
 Minibatch[1601-1700]: loss = 0.497377 * 100, metric = 11.21% * 100;
 Minibatch[1701-1800]: loss = 0.479205 * 100, metric = 10.86% * 100;
 Minibatch[1801-1900]: loss = 0.480605 * 100, metric = 11.14% * 100;
 Minibatch[1901-2000]: loss = 0.497963 * 100, metric = 11.33% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.491223 * 2000, metric = 11.14% * 2000 657.392s (  3.0 samples/s);
Finished Evaluation [12]: Minibatch[1-1000]: metric = 17.79% * 1000;
 Minibatch[   1- 100]: loss = 0.494042 * 100, metric = 11.17% * 100;
 Minibatch[ 101- 200]: loss = 0.492747 * 100, metric = 11.35% * 100;
 Minibatch[ 201- 300]: loss = 0.478551 * 100, metric = 10.87% * 100;
 Minibatch[ 301- 400]: loss = 0.494184 * 100, metric = 11.05% * 100;
 Minibatch[ 401- 500]: loss = 0.496038 * 100, metric = 11.44% * 100;
 Minibatch[ 501- 600]: loss = 0.504420 * 100, metric = 11.78% * 100;
 Minibatch[ 601- 700]: loss = 0.476342 * 100, metric = 10.55% * 100;
 Minibatch[ 701- 800]: loss = 0.481557 * 100, metric = 10.96% * 100;
 Minibatch[ 801- 900]: loss = 0.491993 * 100, metric = 11.10% * 100;
 Minibatch[ 901-1000]: loss = 0.505363 * 100, metric = 11.55% * 100;
 Minibatch[1001-1100]: loss = 0.491076 * 100, metric = 11.08% * 100;
 Minibatch[1101-1200]: loss = 0.486504 * 100, metric = 11.51% * 100;
 Minibatch[1201-1300]: loss = 0.496678 * 100, metric = 11.63% * 100;
 Minibatch[1301-1400]: loss = 0.485151 * 100, metric = 11.14% * 100;
 Minibatch[1401-1500]: loss = 0.473235 * 100, metric = 10.85% * 100;
 Minibatch[1501-1600]: loss = 0.471989 * 100, metric = 10.62% * 100;
 Minibatch[1601-1700]: loss = 0.466565 * 100, metric = 10.60% * 100;
 Minibatch[1701-1800]: loss = 0.482947 * 100, metric = 10.88% * 100;
 Minibatch[1801-1900]: loss = 0.472266 * 100, metric = 10.64% * 100;
 Minibatch[1901-2000]: loss = 0.488439 * 100, metric = 11.45% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.486504 * 2000, metric = 11.11% * 2000 656.390s (  3.0 samples/s);
Finished Evaluation [13]: Minibatch[1-1000]: metric = 19.89% * 1000;
 Minibatch[   1- 100]: loss = 0.475058 * 100, metric = 10.67% * 100;
 Minibatch[ 101- 200]: loss = 0.470840 * 100, metric = 10.91% * 100;
 Minibatch[ 201- 300]: loss = 0.489736 * 100, metric = 11.12% * 100;
 Minibatch[ 301- 400]: loss = 0.484141 * 100, metric = 11.26% * 100;
 Minibatch[ 401- 500]: loss = 0.481042 * 100, metric = 10.90% * 100;
 Minibatch[ 501- 600]: loss = 0.484079 * 100, metric = 10.96% * 100;
 Minibatch[ 601- 700]: loss = 0.482912 * 100, metric = 11.13% * 100;
 Minibatch[ 701- 800]: loss = 0.507940 * 100, metric = 11.42% * 100;
 Minibatch[ 801- 900]: loss = 0.501483 * 100, metric = 11.64% * 100;
 Minibatch[ 901-1000]: loss = 0.493953 * 100, metric = 11.32% * 100;
 Minibatch[1001-1100]: loss = 0.504631 * 100, metric = 11.64% * 100;
 Minibatch[1101-1200]: loss = 0.494371 * 100, metric = 11.03% * 100;
 Minibatch[1201-1300]: loss = 0.464738 * 100, metric = 10.66% * 100;
 Minibatch[1301-1400]: loss = 0.494024 * 100, metric = 11.43% * 100;
 Minibatch[1401-1500]: loss = 0.483160 * 100, metric = 11.21% * 100;
 Minibatch[1501-1600]: loss = 0.466515 * 100, metric = 10.84% * 100;
 Minibatch[1601-1700]: loss = 0.478296 * 100, metric = 11.06% * 100;
 Minibatch[1701-1800]: loss = 0.463956 * 100, metric = 10.49% * 100;
 Minibatch[1801-1900]: loss = 0.487621 * 100, metric = 11.36% * 100;
 Minibatch[1901-2000]: loss = 0.490065 * 100, metric = 11.15% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.484928 * 2000, metric = 11.11% * 2000 655.984s (  3.0 samples/s);
Finished Evaluation [14]: Minibatch[1-1000]: metric = 17.77% * 1000;
 Minibatch[   1- 100]: loss = 0.478060 * 100, metric = 10.82% * 100;
 Minibatch[ 101- 200]: loss = 0.485776 * 100, metric = 11.14% * 100;
 Minibatch[ 201- 300]: loss = 0.479561 * 100, metric = 10.99% * 100;
 Minibatch[ 301- 400]: loss = 0.462860 * 100, metric = 10.56% * 100;
 Minibatch[ 401- 500]: loss = 0.473500 * 100, metric = 10.77% * 100;
 Minibatch[ 501- 600]: loss = 0.461498 * 100, metric = 10.53% * 100;
 Minibatch[ 601- 700]: loss = 0.447645 * 100, metric = 10.39% * 100;
 Minibatch[ 701- 800]: loss = 0.484995 * 100, metric = 11.02% * 100;
 Minibatch[ 801- 900]: loss = 0.500006 * 100, metric = 11.48% * 100;
 Minibatch[ 901-1000]: loss = 0.481456 * 100, metric = 10.95% * 100;
 Minibatch[1001-1100]: loss = 0.487682 * 100, metric = 11.26% * 100;
 Minibatch[1101-1200]: loss = 0.467323 * 100, metric = 10.71% * 100;
 Minibatch[1201-1300]: loss = 0.464858 * 100, metric = 10.58% * 100;
 Minibatch[1301-1400]: loss = 0.493727 * 100, metric = 11.58% * 100;
 Minibatch[1401-1500]: loss = 0.452005 * 100, metric = 10.11% * 100;
 Minibatch[1501-1600]: loss = 0.465344 * 100, metric = 10.64% * 100;
 Minibatch[1601-1700]: loss = 0.476617 * 100, metric = 10.74% * 100;
 Minibatch[1701-1800]: loss = 0.459307 * 100, metric = 10.12% * 100;
 Minibatch[1801-1900]: loss = 0.468541 * 100, metric = 10.74% * 100;
 Minibatch[1901-2000]: loss = 0.466742 * 100, metric = 10.48% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.472875 * 2000, metric = 10.78% * 2000 655.657s (  3.1 samples/s);
Finished Evaluation [15]: Minibatch[1-1000]: metric = 16.79% * 1000;
 Minibatch[   1- 100]: loss = 0.490683 * 100, metric = 11.45% * 100;
 Minibatch[ 101- 200]: loss = 0.485398 * 100, metric = 11.09% * 100;
 Minibatch[ 201- 300]: loss = 0.470412 * 100, metric = 10.85% * 100;
 Minibatch[ 301- 400]: loss = 0.485582 * 100, metric = 11.10% * 100;
 Minibatch[ 401- 500]: loss = 0.459451 * 100, metric = 10.34% * 100;
 Minibatch[ 501- 600]: loss = 0.467541 * 100, metric = 10.60% * 100;
 Minibatch[ 601- 700]: loss = 0.475901 * 100, metric = 10.75% * 100;
 Minibatch[ 701- 800]: loss = 0.470568 * 100, metric = 10.58% * 100;
 Minibatch[ 801- 900]: loss = 0.460127 * 100, metric = 10.44% * 100;
 Minibatch[ 901-1000]: loss = 0.479619 * 100, metric = 11.11% * 100;
 Minibatch[1001-1100]: loss = 0.456704 * 100, metric = 10.40% * 100;
 Minibatch[1101-1200]: loss = 0.471223 * 100, metric = 10.70% * 100;
 Minibatch[1201-1300]: loss = 0.457859 * 100, metric = 10.41% * 100;
 Minibatch[1301-1400]: loss = 0.470494 * 100, metric = 10.66% * 100;
 Minibatch[1401-1500]: loss = 0.460798 * 100, metric = 10.49% * 100;
 Minibatch[1501-1600]: loss = 0.467107 * 100, metric = 10.78% * 100;
 Minibatch[1601-1700]: loss = 0.473890 * 100, metric = 10.96% * 100;
 Minibatch[1701-1800]: loss = 0.484155 * 100, metric = 10.79% * 100;
 Minibatch[1801-1900]: loss = 0.477101 * 100, metric = 10.95% * 100;
 Minibatch[1901-2000]: loss = 0.456753 * 100, metric = 10.36% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.471068 * 2000, metric = 10.74% * 2000 658.256s (  3.0 samples/s);
Finished Evaluation [16]: Minibatch[1-1000]: metric = 16.64% * 1000;
 Minibatch[   1- 100]: loss = 0.450872 * 100, metric = 10.24% * 100;
 Minibatch[ 101- 200]: loss = 0.473247 * 100, metric = 10.76% * 100;
 Minibatch[ 201- 300]: loss = 0.483986 * 100, metric = 11.07% * 100;
 Minibatch[ 301- 400]: loss = 0.467956 * 100, metric = 10.50% * 100;
 Minibatch[ 401- 500]: loss = 0.482010 * 100, metric = 10.88% * 100;
 Minibatch[ 501- 600]: loss = 0.465201 * 100, metric = 10.37% * 100;
 Minibatch[ 601- 700]: loss = 0.449116 * 100, metric = 10.05% * 100;
 Minibatch[ 701- 800]: loss = 0.465266 * 100, metric = 10.45% * 100;
 Minibatch[ 801- 900]: loss = 0.475389 * 100, metric = 10.68% * 100;
 Minibatch[ 901-1000]: loss = 0.463714 * 100, metric = 10.49% * 100;
 Minibatch[1001-1100]: loss = 0.459081 * 100, metric = 10.21% * 100;
 Minibatch[1101-1200]: loss = 0.483922 * 100, metric = 10.80% * 100;
 Minibatch[1201-1300]: loss = 0.472491 * 100, metric = 10.98% * 100;
 Minibatch[1301-1400]: loss = 0.453627 * 100, metric = 10.38% * 100;
 Minibatch[1401-1500]: loss = 0.459865 * 100, metric = 10.41% * 100;
 Minibatch[1501-1600]: loss = 0.464106 * 100, metric = 10.73% * 100;
 Minibatch[1601-1700]: loss = 0.474440 * 100, metric = 10.62% * 100;
 Minibatch[1701-1800]: loss = 0.452518 * 100, metric = 10.11% * 100;
 Minibatch[1801-1900]: loss = 0.483036 * 100, metric = 10.98% * 100;
 Minibatch[1901-2000]: loss = 0.483563 * 100, metric = 11.16% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.468170 * 2000, metric = 10.59% * 2000 657.506s (  3.0 samples/s);
Finished Evaluation [17]: Minibatch[1-1000]: metric = 16.89% * 1000;
 Minibatch[   1- 100]: loss = 0.449459 * 100, metric = 10.00% * 100;
 Minibatch[ 101- 200]: loss = 0.473818 * 100, metric = 10.72% * 100;
 Minibatch[ 201- 300]: loss = 0.460310 * 100, metric = 10.54% * 100;
 Minibatch[ 301- 400]: loss = 0.468337 * 100, metric = 10.53% * 100;
 Minibatch[ 401- 500]: loss = 0.446402 * 100, metric = 10.22% * 100;
 Minibatch[ 501- 600]: loss = 0.446546 * 100, metric = 9.95% * 100;
 Minibatch[ 601- 700]: loss = 0.468403 * 100, metric = 10.69% * 100;
 Minibatch[ 701- 800]: loss = 0.454457 * 100, metric = 10.48% * 100;
 Minibatch[ 801- 900]: loss = 0.473794 * 100, metric = 10.75% * 100;
 Minibatch[ 901-1000]: loss = 0.469395 * 100, metric = 10.34% * 100;
 Minibatch[1001-1100]: loss = 0.481208 * 100, metric = 10.92% * 100;
 Minibatch[1101-1200]: loss = 0.475331 * 100, metric = 10.86% * 100;
 Minibatch[1201-1300]: loss = 0.479783 * 100, metric = 10.88% * 100;
 Minibatch[1301-1400]: loss = 0.481093 * 100, metric = 10.95% * 100;
 Minibatch[1401-1500]: loss = 0.457581 * 100, metric = 10.21% * 100;
 Minibatch[1501-1600]: loss = 0.467131 * 100, metric = 10.64% * 100;
 Minibatch[1601-1700]: loss = 0.436716 * 100, metric = 9.70% * 100;
 Minibatch[1701-1800]: loss = 0.456032 * 100, metric = 10.14% * 100;
 Minibatch[1801-1900]: loss = 0.445322 * 100, metric = 10.20% * 100;
 Minibatch[1901-2000]: loss = 0.451630 * 100, metric = 9.98% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.462138 * 2000, metric = 10.43% * 2000 661.968s (  3.0 samples/s);
Finished Evaluation [18]: Minibatch[1-1000]: metric = 19.08% * 1000;
 Minibatch[   1- 100]: loss = 0.474482 * 100, metric = 10.64% * 100;
 Minibatch[ 101- 200]: loss = 0.482518 * 100, metric = 10.92% * 100;
 Minibatch[ 201- 300]: loss = 0.446801 * 100, metric = 9.90% * 100;
 Minibatch[ 301- 400]: loss = 0.463750 * 100, metric = 10.38% * 100;
 Minibatch[ 401- 500]: loss = 0.460673 * 100, metric = 10.40% * 100;
 Minibatch[ 501- 600]: loss = 0.449912 * 100, metric = 9.96% * 100;
 Minibatch[ 601- 700]: loss = 0.468661 * 100, metric = 10.45% * 100;
 Minibatch[ 701- 800]: loss = 0.450182 * 100, metric = 9.96% * 100;
 Minibatch[ 801- 900]: loss = 0.489073 * 100, metric = 11.24% * 100;
 Minibatch[ 901-1000]: loss = 0.453213 * 100, metric = 10.04% * 100;
 Minibatch[1001-1100]: loss = 0.466307 * 100, metric = 10.40% * 100;
 Minibatch[1101-1200]: loss = 0.470569 * 100, metric = 10.82% * 100;
 Minibatch[1201-1300]: loss = 0.464974 * 100, metric = 10.34% * 100;
 Minibatch[1301-1400]: loss = 0.452879 * 100, metric = 10.40% * 100;
 Minibatch[1401-1500]: loss = 0.469902 * 100, metric = 10.81% * 100;
 Minibatch[1501-1600]: loss = 0.473703 * 100, metric = 10.97% * 100;
 Minibatch[1601-1700]: loss = 0.455014 * 100, metric = 10.40% * 100;
 Minibatch[1701-1800]: loss = 0.433956 * 100, metric = 9.75% * 100;
 Minibatch[1801-1900]: loss = 0.454142 * 100, metric = 10.47% * 100;
 Minibatch[1901-2000]: loss = 0.441392 * 100, metric = 10.11% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.461105 * 2000, metric = 10.42% * 2000 658.009s (  3.0 samples/s);
Finished Evaluation [19]: Minibatch[1-1000]: metric = 18.53% * 1000;
 Minibatch[   1- 100]: loss = 0.445381 * 100, metric = 10.02% * 100;
 Minibatch[ 101- 200]: loss = 0.455271 * 100, metric = 10.23% * 100;
 Minibatch[ 201- 300]: loss = 0.448626 * 100, metric = 10.14% * 100;
 Minibatch[ 301- 400]: loss = 0.465913 * 100, metric = 10.20% * 100;
 Minibatch[ 401- 500]: loss = 0.465773 * 100, metric = 10.41% * 100;
 Minibatch[ 501- 600]: loss = 0.462524 * 100, metric = 10.52% * 100;
 Minibatch[ 601- 700]: loss = 0.465264 * 100, metric = 10.65% * 100;
 Minibatch[ 701- 800]: loss = 0.462660 * 100, metric = 10.44% * 100;
 Minibatch[ 801- 900]: loss = 0.467070 * 100, metric = 10.77% * 100;
 Minibatch[ 901-1000]: loss = 0.471088 * 100, metric = 10.55% * 100;
 Minibatch[1001-1100]: loss = 0.443903 * 100, metric = 9.89% * 100;
 Minibatch[1101-1200]: loss = 0.456651 * 100, metric = 10.07% * 100;
 Minibatch[1201-1300]: loss = 0.461710 * 100, metric = 10.31% * 100;
 Minibatch[1301-1400]: loss = 0.464806 * 100, metric = 10.55% * 100;
 Minibatch[1401-1500]: loss = 0.449437 * 100, metric = 10.28% * 100;
 Minibatch[1501-1600]: loss = 0.469543 * 100, metric = 10.46% * 100;
 Minibatch[1601-1700]: loss = 0.451559 * 100, metric = 10.08% * 100;
 Minibatch[1701-1800]: loss = 0.466039 * 100, metric = 10.79% * 100;
 Minibatch[1801-1900]: loss = 0.456680 * 100, metric = 10.22% * 100;
 Minibatch[1901-2000]: loss = 0.454391 * 100, metric = 10.27% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.459215 * 2000, metric = 10.34% * 2000 659.141s (  3.0 samples/s);
Finished Evaluation [20]: Minibatch[1-1000]: metric = 17.76% * 1000;
 Minibatch[   1- 100]: loss = 0.460859 * 100, metric = 10.55% * 100;
 Minibatch[ 101- 200]: loss = 0.457252 * 100, metric = 10.21% * 100;
 Minibatch[ 201- 300]: loss = 0.464940 * 100, metric = 10.26% * 100;
 Minibatch[ 301- 400]: loss = 0.469920 * 100, metric = 10.58% * 100;
 Minibatch[ 401- 500]: loss = 0.447883 * 100, metric = 10.17% * 100;
 Minibatch[ 501- 600]: loss = 0.446992 * 100, metric = 10.11% * 100;
 Minibatch[ 601- 700]: loss = 0.456748 * 100, metric = 10.14% * 100;
 Minibatch[ 701- 800]: loss = 0.429950 * 100, metric = 9.72% * 100;
 Minibatch[ 801- 900]: loss = 0.461107 * 100, metric = 10.34% * 100;
 Minibatch[ 901-1000]: loss = 0.444034 * 100, metric = 10.01% * 100;
 Minibatch[1001-1100]: loss = 0.454374 * 100, metric = 10.14% * 100;
 Minibatch[1101-1200]: loss = 0.440699 * 100, metric = 9.99% * 100;
 Minibatch[1201-1300]: loss = 0.453234 * 100, metric = 10.19% * 100;
 Minibatch[1301-1400]: loss = 0.439241 * 100, metric = 9.74% * 100;
 Minibatch[1401-1500]: loss = 0.462744 * 100, metric = 10.25% * 100;
 Minibatch[1501-1600]: loss = 0.469286 * 100, metric = 10.65% * 100;
 Minibatch[1601-1700]: loss = 0.452489 * 100, metric = 10.02% * 100;
 Minibatch[1701-1800]: loss = 0.443074 * 100, metric = 9.82% * 100;
 Minibatch[1801-1900]: loss = 0.468953 * 100, metric = 10.73% * 100;
 Minibatch[1901-2000]: loss = 0.433920 * 100, metric = 9.50% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.452885 * 2000, metric = 10.16% * 2000 657.496s (  3.0 samples/s);
Finished Evaluation [21]: Minibatch[1-1000]: metric = 16.96% * 1000;
 Minibatch[   1- 100]: loss = 0.456611 * 100, metric = 10.38% * 100;
 Minibatch[ 101- 200]: loss = 0.449599 * 100, metric = 10.14% * 100;
 Minibatch[ 201- 300]: loss = 0.464401 * 100, metric = 10.53% * 100;
 Minibatch[ 301- 400]: loss = 0.448153 * 100, metric = 10.11% * 100;
 Minibatch[ 401- 500]: loss = 0.445956 * 100, metric = 10.02% * 100;
 Minibatch[ 501- 600]: loss = 0.461231 * 100, metric = 10.33% * 100;
 Minibatch[ 601- 700]: loss = 0.448535 * 100, metric = 10.26% * 100;
 Minibatch[ 701- 800]: loss = 0.437540 * 100, metric = 9.99% * 100;
 Minibatch[ 801- 900]: loss = 0.453314 * 100, metric = 10.18% * 100;
 Minibatch[ 901-1000]: loss = 0.458103 * 100, metric = 10.46% * 100;
 Minibatch[1001-1100]: loss = 0.436749 * 100, metric = 9.90% * 100;
 Minibatch[1101-1200]: loss = 0.424954 * 100, metric = 9.40% * 100;
 Minibatch[1201-1300]: loss = 0.442697 * 100, metric = 9.99% * 100;
 Minibatch[1301-1400]: loss = 0.452134 * 100, metric = 10.12% * 100;
 Minibatch[1401-1500]: loss = 0.444652 * 100, metric = 10.00% * 100;
 Minibatch[1501-1600]: loss = 0.439395 * 100, metric = 9.81% * 100;
 Minibatch[1601-1700]: loss = 0.445850 * 100, metric = 9.84% * 100;
 Minibatch[1701-1800]: loss = 0.451094 * 100, metric = 10.18% * 100;
 Minibatch[1801-1900]: loss = 0.439787 * 100, metric = 10.06% * 100;
 Minibatch[1901-2000]: loss = 0.447949 * 100, metric = 9.81% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.447435 * 2000, metric = 10.08% * 2000 658.882s (  3.0 samples/s);
Finished Evaluation [22]: Minibatch[1-1000]: metric = 19.24% * 1000;
 Minibatch[   1- 100]: loss = 0.456876 * 100, metric = 10.33% * 100;
 Minibatch[ 101- 200]: loss = 0.461129 * 100, metric = 10.49% * 100;
 Minibatch[ 201- 300]: loss = 0.444731 * 100, metric = 9.88% * 100;
 Minibatch[ 301- 400]: loss = 0.462889 * 100, metric = 10.42% * 100;
 Minibatch[ 401- 500]: loss = 0.464971 * 100, metric = 10.53% * 100;
 Minibatch[ 501- 600]: loss = 0.451814 * 100, metric = 10.19% * 100;
 Minibatch[ 601- 700]: loss = 0.446096 * 100, metric = 10.04% * 100;
 Minibatch[ 701- 800]: loss = 0.435691 * 100, metric = 9.70% * 100;
 Minibatch[ 801- 900]: loss = 0.436260 * 100, metric = 10.12% * 100;
 Minibatch[ 901-1000]: loss = 0.452303 * 100, metric = 10.09% * 100;
 Minibatch[1001-1100]: loss = 0.442024 * 100, metric = 9.84% * 100;
 Minibatch[1101-1200]: loss = 0.450073 * 100, metric = 10.17% * 100;
 Minibatch[1201-1300]: loss = 0.452656 * 100, metric = 10.38% * 100;
 Minibatch[1301-1400]: loss = 0.455375 * 100, metric = 10.28% * 100;
 Minibatch[1401-1500]: loss = 0.437390 * 100, metric = 9.83% * 100;
 Minibatch[1501-1600]: loss = 0.450090 * 100, metric = 10.19% * 100;
 Minibatch[1601-1700]: loss = 0.448219 * 100, metric = 10.00% * 100;
 Minibatch[1701-1800]: loss = 0.457139 * 100, metric = 10.33% * 100;
 Minibatch[1801-1900]: loss = 0.455966 * 100, metric = 10.33% * 100;
 Minibatch[1901-2000]: loss = 0.461153 * 100, metric = 10.49% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.451142 * 2000, metric = 10.18% * 2000 655.466s (  3.1 samples/s);
Finished Evaluation [23]: Minibatch[1-1000]: metric = 17.99% * 1000;
 Minibatch[   1- 100]: loss = 0.443716 * 100, metric = 10.02% * 100;
 Minibatch[ 101- 200]: loss = 0.459390 * 100, metric = 10.58% * 100;
 Minibatch[ 201- 300]: loss = 0.442973 * 100, metric = 10.14% * 100;
 Minibatch[ 301- 400]: loss = 0.444191 * 100, metric = 10.09% * 100;
 Minibatch[ 401- 500]: loss = 0.449787 * 100, metric = 10.16% * 100;
 Minibatch[ 501- 600]: loss = 0.442179 * 100, metric = 9.74% * 100;
 Minibatch[ 601- 700]: loss = 0.451507 * 100, metric = 9.97% * 100;
 Minibatch[ 701- 800]: loss = 0.434421 * 100, metric = 9.81% * 100;
 Minibatch[ 801- 900]: loss = 0.461212 * 100, metric = 10.45% * 100;
 Minibatch[ 901-1000]: loss = 0.451078 * 100, metric = 10.29% * 100;
 Minibatch[1001-1100]: loss = 0.448454 * 100, metric = 10.22% * 100;
 Minibatch[1101-1200]: loss = 0.457163 * 100, metric = 10.48% * 100;
 Minibatch[1201-1300]: loss = 0.448593 * 100, metric = 10.28% * 100;
 Minibatch[1301-1400]: loss = 0.436098 * 100, metric = 9.68% * 100;
 Minibatch[1401-1500]: loss = 0.446406 * 100, metric = 10.00% * 100;
 Minibatch[1501-1600]: loss = 0.453786 * 100, metric = 10.07% * 100;
 Minibatch[1601-1700]: loss = 0.431236 * 100, metric = 9.66% * 100;
 Minibatch[1701-1800]: loss = 0.438345 * 100, metric = 9.80% * 100;
 Minibatch[1801-1900]: loss = 0.455071 * 100, metric = 10.45% * 100;
 Minibatch[1901-2000]: loss = 0.454248 * 100, metric = 10.39% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.447493 * 2000, metric = 10.11% * 2000 659.494s (  3.0 samples/s);
Finished Evaluation [24]: Minibatch[1-1000]: metric = 17.07% * 1000;
 Minibatch[   1- 100]: loss = 0.456211 * 100, metric = 10.33% * 100;
 Minibatch[ 101- 200]: loss = 0.446008 * 100, metric = 10.21% * 100;
 Minibatch[ 201- 300]: loss = 0.450509 * 100, metric = 10.60% * 100;
 Minibatch[ 301- 400]: loss = 0.454685 * 100, metric = 10.11% * 100;
 Minibatch[ 401- 500]: loss = 0.445376 * 100, metric = 10.10% * 100;
 Minibatch[ 501- 600]: loss = 0.441989 * 100, metric = 10.09% * 100;
 Minibatch[ 601- 700]: loss = 0.441083 * 100, metric = 9.78% * 100;
 Minibatch[ 701- 800]: loss = 0.430897 * 100, metric = 9.56% * 100;
 Minibatch[ 801- 900]: loss = 0.430619 * 100, metric = 9.66% * 100;
 Minibatch[ 901-1000]: loss = 0.445097 * 100, metric = 10.14% * 100;
 Minibatch[1001-1100]: loss = 0.445262 * 100, metric = 10.18% * 100;
 Minibatch[1101-1200]: loss = 0.442298 * 100, metric = 10.18% * 100;
 Minibatch[1201-1300]: loss = 0.469703 * 100, metric = 10.55% * 100;
 Minibatch[1301-1400]: loss = 0.438127 * 100, metric = 9.89% * 100;
 Minibatch[1401-1500]: loss = 0.429209 * 100, metric = 9.60% * 100;
 Minibatch[1501-1600]: loss = 0.458296 * 100, metric = 10.47% * 100;
 Minibatch[1601-1700]: loss = 0.440228 * 100, metric = 9.96% * 100;
 Minibatch[1701-1800]: loss = 0.449556 * 100, metric = 10.15% * 100;
 Minibatch[1801-1900]: loss = 0.435062 * 100, metric = 9.85% * 100;
 Minibatch[1901-2000]: loss = 0.421855 * 100, metric = 9.44% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.443604 * 2000, metric = 10.04% * 2000 676.380s (  3.0 samples/s);
Finished Evaluation [25]: Minibatch[1-1000]: metric = 17.95% * 1000;
 Minibatch[   1- 100]: loss = 0.438692 * 100, metric = 9.89% * 100;
 Minibatch[ 101- 200]: loss = 0.412664 * 100, metric = 9.30% * 100;
 Minibatch[ 201- 300]: loss = 0.443627 * 100, metric = 10.20% * 100;
 Minibatch[ 301- 400]: loss = 0.430744 * 100, metric = 9.66% * 100;
 Minibatch[ 401- 500]: loss = 0.435777 * 100, metric = 9.90% * 100;
 Minibatch[ 501- 600]: loss = 0.438011 * 100, metric = 9.68% * 100;
 Minibatch[ 601- 700]: loss = 0.458002 * 100, metric = 10.25% * 100;
 Minibatch[ 701- 800]: loss = 0.430338 * 100, metric = 9.56% * 100;
 Minibatch[ 801- 900]: loss = 0.426096 * 100, metric = 9.46% * 100;
 Minibatch[ 901-1000]: loss = 0.431192 * 100, metric = 9.62% * 100;
 Minibatch[1001-1100]: loss = 0.452374 * 100, metric = 10.32% * 100;
 Minibatch[1101-1200]: loss = 0.459844 * 100, metric = 10.42% * 100;
 Minibatch[1201-1300]: loss = 0.435750 * 100, metric = 9.62% * 100;
 Minibatch[1301-1400]: loss = 0.425173 * 100, metric = 9.30% * 100;
 Minibatch[1401-1500]: loss = 0.439260 * 100, metric = 9.77% * 100;
 Minibatch[1501-1600]: loss = 0.440677 * 100, metric = 9.79% * 100;
 Minibatch[1601-1700]: loss = 0.449429 * 100, metric = 10.46% * 100;
 Minibatch[1701-1800]: loss = 0.448062 * 100, metric = 10.07% * 100;
 Minibatch[1801-1900]: loss = 0.435066 * 100, metric = 9.81% * 100;
 Minibatch[1901-2000]: loss = 0.445746 * 100, metric = 10.03% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.438826 * 2000, metric = 9.85% * 2000 679.143s (  2.9 samples/s);
Finished Evaluation [26]: Minibatch[1-1000]: metric = 18.81% * 1000;
 Minibatch[   1- 100]: loss = 0.442244 * 100, metric = 10.02% * 100;
 Minibatch[ 101- 200]: loss = 0.452694 * 100, metric = 10.17% * 100;
 Minibatch[ 201- 300]: loss = 0.434044 * 100, metric = 9.96% * 100;
 Minibatch[ 301- 400]: loss = 0.430137 * 100, metric = 9.57% * 100;
 Minibatch[ 401- 500]: loss = 0.439651 * 100, metric = 10.18% * 100;
 Minibatch[ 501- 600]: loss = 0.434818 * 100, metric = 9.98% * 100;
 Minibatch[ 601- 700]: loss = 0.432704 * 100, metric = 9.73% * 100;
 Minibatch[ 701- 800]: loss = 0.437392 * 100, metric = 9.92% * 100;
 Minibatch[ 801- 900]: loss = 0.442094 * 100, metric = 9.88% * 100;
 Minibatch[ 901-1000]: loss = 0.436289 * 100, metric = 10.03% * 100;
 Minibatch[1001-1100]: loss = 0.423303 * 100, metric = 9.30% * 100;
 Minibatch[1101-1200]: loss = 0.444371 * 100, metric = 9.93% * 100;
 Minibatch[1201-1300]: loss = 0.429796 * 100, metric = 9.56% * 100;
 Minibatch[1301-1400]: loss = 0.446836 * 100, metric = 10.19% * 100;
 Minibatch[1401-1500]: loss = 0.428867 * 100, metric = 9.89% * 100;
 Minibatch[1501-1600]: loss = 0.424589 * 100, metric = 9.54% * 100;
 Minibatch[1601-1700]: loss = 0.412286 * 100, metric = 9.07% * 100;
 Minibatch[1701-1800]: loss = 0.427728 * 100, metric = 9.46% * 100;
 Minibatch[1801-1900]: loss = 0.428397 * 100, metric = 9.72% * 100;
 Minibatch[1901-2000]: loss = 0.433771 * 100, metric = 9.58% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.434100 * 2000, metric = 9.78% * 2000 652.508s (  3.1 samples/s);
Finished Evaluation [27]: Minibatch[1-1000]: metric = 17.54% * 1000;
 Minibatch[   1- 100]: loss = 0.436018 * 100, metric = 10.06% * 100;
 Minibatch[ 101- 200]: loss = 0.425411 * 100, metric = 9.60% * 100;
 Minibatch[ 201- 300]: loss = 0.430117 * 100, metric = 9.83% * 100;
 Minibatch[ 301- 400]: loss = 0.434685 * 100, metric = 9.82% * 100;
 Minibatch[ 401- 500]: loss = 0.429959 * 100, metric = 9.69% * 100;
 Minibatch[ 501- 600]: loss = 0.446575 * 100, metric = 10.31% * 100;
 Minibatch[ 601- 700]: loss = 0.427568 * 100, metric = 9.46% * 100;
 Minibatch[ 701- 800]: loss = 0.414138 * 100, metric = 9.32% * 100;
 Minibatch[ 801- 900]: loss = 0.425999 * 100, metric = 9.79% * 100;
 Minibatch[ 901-1000]: loss = 0.438129 * 100, metric = 10.46% * 100;
 Minibatch[1001-1100]: loss = 0.428283 * 100, metric = 9.79% * 100;
 Minibatch[1101-1200]: loss = 0.426120 * 100, metric = 9.66% * 100;
 Minibatch[1201-1300]: loss = 0.439312 * 100, metric = 9.80% * 100;
 Minibatch[1301-1400]: loss = 0.429456 * 100, metric = 9.81% * 100;
 Minibatch[1401-1500]: loss = 0.437171 * 100, metric = 10.06% * 100;
 Minibatch[1501-1600]: loss = 0.422473 * 100, metric = 9.66% * 100;
 Minibatch[1601-1700]: loss = 0.429542 * 100, metric = 9.43% * 100;
 Minibatch[1701-1800]: loss = 0.416868 * 100, metric = 9.42% * 100;
 Minibatch[1801-1900]: loss = 0.431920 * 100, metric = 9.83% * 100;
 Minibatch[1901-2000]: loss = 0.425267 * 100, metric = 9.64% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.429750 * 2000, metric = 9.77% * 2000 652.746s (  3.1 samples/s);
Finished Evaluation [28]: Minibatch[1-1000]: metric = 16.47% * 1000;
 Minibatch[   1- 100]: loss = 0.415908 * 100, metric = 9.30% * 100;
 Minibatch[ 101- 200]: loss = 0.424838 * 100, metric = 9.99% * 100;
 Minibatch[ 201- 300]: loss = 0.434292 * 100, metric = 10.14% * 100;
 Minibatch[ 301- 400]: loss = 0.447085 * 100, metric = 10.31% * 100;
 Minibatch[ 401- 500]: loss = 0.419875 * 100, metric = 9.48% * 100;
 Minibatch[ 501- 600]: loss = 0.432510 * 100, metric = 9.84% * 100;
 Minibatch[ 601- 700]: loss = 0.428162 * 100, metric = 9.73% * 100;
 Minibatch[ 701- 800]: loss = 0.441166 * 100, metric = 9.93% * 100;
 Minibatch[ 801- 900]: loss = 0.429402 * 100, metric = 9.75% * 100;
 Minibatch[ 901-1000]: loss = 0.433979 * 100, metric = 10.03% * 100;
 Minibatch[1001-1100]: loss = 0.424034 * 100, metric = 9.91% * 100;
 Minibatch[1101-1200]: loss = 0.418255 * 100, metric = 9.60% * 100;
 Minibatch[1201-1300]: loss = 0.429963 * 100, metric = 9.69% * 100;
 Minibatch[1301-1400]: loss = 0.422230 * 100, metric = 9.52% * 100;
 Minibatch[1401-1500]: loss = 0.442053 * 100, metric = 9.95% * 100;
 Minibatch[1501-1600]: loss = 0.418890 * 100, metric = 9.61% * 100;
 Minibatch[1601-1700]: loss = 0.439626 * 100, metric = 10.02% * 100;
 Minibatch[1701-1800]: loss = 0.420501 * 100, metric = 9.47% * 100;
 Minibatch[1801-1900]: loss = 0.441616 * 100, metric = 10.00% * 100;
 Minibatch[1901-2000]: loss = 0.434707 * 100, metric = 9.83% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.429955 * 2000, metric = 9.80% * 2000 648.107s (  3.1 samples/s);
Finished Evaluation [29]: Minibatch[1-1000]: metric = 18.32% * 1000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
Evaluating Faster R-CNN model for 30200 images.
Processed 100 samples
Processed 200 samples
Processed 300 samples
Processed 400 samples
Processed 500 samples
Processed 600 samples
Processed 700 samples
Processed 800 samples
Processed 900 samples
Processed 1000 samples
Processed 1100 samples
Processed 1200 samples
Processed 1300 samples
Processed 1400 samples
Processed 1500 samples
Processed 1600 samples
Processed 1700 samples
Processed 1800 samples
Processed 1900 samples
Processed 2000 samples
Processed 2100 samples
Processed 2200 samples
Processed 2300 samples
Processed 2400 samples
Processed 2500 samples
Processed 2600 samples
Processed 2700 samples
Processed 2800 samples
Processed 2900 samples
Processed 3000 samples
Processed 3100 samples
Processed 3200 samples
Processed 3300 samples
Processed 3400 samples
Processed 3500 samples
Processed 3600 samples
Processed 3700 samples
Processed 3800 samples
Processed 3900 samples
Processed 4000 samples
Processed 4100 samples
Processed 4200 samples
Processed 4300 samples
Processed 4400 samples
Processed 4500 samples
Processed 4600 samples
Processed 4700 samples
Processed 4800 samples
Processed 4900 samples
Processed 5000 samples
Processed 5100 samples
Processed 5200 samples
Processed 5300 samples
Processed 5400 samples
Processed 5500 samples
Processed 5600 samples
Processed 5700 samples
Processed 5800 samples
Processed 5900 samples
Processed 6000 samples
Processed 6100 samples
Processed 6200 samples
Processed 6300 samples
Processed 6400 samples
Processed 6500 samples
Processed 6600 samples
Processed 6700 samples
Processed 6800 samples
Processed 6900 samples
Processed 7000 samples
Processed 7100 samples
Processed 7200 samples
Processed 7300 samples
Processed 7400 samples
Processed 7500 samples
Processed 7600 samples
Processed 7700 samples
Processed 7800 samples
Processed 7900 samples
Processed 8000 samples
Processed 8100 samples
Processed 8200 samples
Processed 8300 samples
Processed 8400 samples
Processed 8500 samples
Processed 8600 samples
Processed 8700 samples
Processed 8800 samples
Processed 8900 samples
Processed 9000 samples
Processed 9100 samples
Processed 9200 samples
Processed 9300 samples
Processed 9400 samples
Processed 9500 samples
Processed 9600 samples
Processed 9700 samples
Processed 9800 samples
Processed 9900 samples
Processed 10000 samples
Processed 10100 samples
Processed 10200 samples
Processed 10300 samples
Processed 10400 samples
Processed 10500 samples
Processed 10600 samples
Processed 10700 samples
Processed 10800 samples
Processed 10900 samples
Processed 11000 samples
Processed 11100 samples
Processed 11200 samples
Processed 11300 samples
Processed 11400 samples
Processed 11500 samples
Processed 11600 samples
Processed 11700 samples
Processed 11800 samples
Processed 11900 samples
Processed 12000 samples
Processed 12100 samples
Processed 12200 samples
Processed 12300 samples
Processed 12400 samples
Processed 12500 samples
Processed 12600 samples
Processed 12700 samples
Processed 12800 samples
Processed 12900 samples
Processed 13000 samples
Processed 13100 samples
Processed 13200 samples
Processed 13300 samples
Processed 13400 samples
Processed 13500 samples
Processed 13600 samples
Processed 13700 samples
Processed 13800 samples
Processed 13900 samples
Processed 14000 samples
Processed 14100 samples
Processed 14200 samples
Processed 14300 samples
Processed 14400 samples
Processed 14500 samples
Processed 14600 samples
Processed 14700 samples
Processed 14800 samples
Processed 14900 samples
Processed 15000 samples
Processed 15100 samples
Processed 15200 samples
Processed 15300 samples
Processed 15400 samples
Processed 15500 samples
Processed 15600 samples
Processed 15700 samples
Processed 15800 samples
Processed 15900 samples
Processed 16000 samples
Processed 16100 samples
Processed 16200 samples
Processed 16300 samples
Processed 16400 samples
Processed 16500 samples
Processed 16600 samples
Processed 16700 samples
Processed 16800 samples
Processed 16900 samples
Processed 17000 samples
Processed 17100 samples
Processed 17200 samples
Processed 17300 samples
Processed 17400 samples
Processed 17500 samples
Processed 17600 samples
Processed 17700 samples
Processed 17800 samples
Processed 17900 samples
Processed 18000 samples
Processed 18100 samples
Processed 18200 samples
Processed 18300 samples
Processed 18400 samples
Processed 18500 samples
Processed 18600 samples
Processed 18700 samples
Processed 18800 samples
Processed 18900 samples
Processed 19000 samples
Processed 19100 samples
Processed 19200 samples
Processed 19300 samples
Processed 19400 samples
Processed 19500 samples
Processed 19600 samples
Processed 19700 samples
Processed 19800 samples
Processed 19900 samples
Processed 20000 samples
Processed 20100 samples
Processed 20200 samples
Processed 20300 samples
Processed 20400 samples
Processed 20500 samples
Processed 20600 samples
Processed 20700 samples
Processed 20800 samples
Processed 20900 samples
Processed 21000 samples
Processed 21100 samples
Processed 21200 samples
Processed 21300 samples
Processed 21400 samples
Processed 21500 samples
Processed 21600 samples
Processed 21700 samples
Processed 21800 samples
Processed 21900 samples
Processed 22000 samples
Processed 22100 samples
Processed 22200 samples
Processed 22300 samples
Processed 22400 samples
Processed 22500 samples
Processed 22600 samples
Processed 22700 samples
Processed 22800 samples
Processed 22900 samples
Processed 23000 samples
Processed 23100 samples
Processed 23200 samples
Processed 23300 samples
Processed 23400 samples
Processed 23500 samples
Processed 23600 samples
Processed 23700 samples
Processed 23800 samples
Processed 23900 samples
Processed 24000 samples
Processed 24100 samples
Processed 24200 samples
Processed 24300 samples
Processed 24400 samples
Processed 24500 samples
Processed 24600 samples
Processed 24700 samples
Processed 24800 samples
Processed 24900 samples
Processed 25000 samples
Processed 25100 samples
Processed 25200 samples
Processed 25300 samples
Processed 25400 samples
Processed 25500 samples
Processed 25600 samples
Processed 25700 samples
Processed 25800 samples
Processed 25900 samples
Processed 26000 samples
Processed 26100 samples
Processed 26200 samples
Processed 26300 samples
Processed 26400 samples
Processed 26500 samples
Processed 26600 samples
Processed 26700 samples
Processed 26800 samples
Processed 26900 samples
Processed 27000 samples
Processed 27100 samples
Processed 27200 samples
Processed 27300 samples
Processed 27400 samples
Processed 27500 samples
Processed 27600 samples
Processed 27700 samples
Processed 27800 samples
Processed 27900 samples
Processed 28000 samples
Processed 28100 samples
Processed 28200 samples
Processed 28300 samples
Processed 28400 samples
Processed 28500 samples
Processed 28600 samples
Processed 28700 samples
Processed 28800 samples
Processed 28900 samples
Processed 29000 samples
Processed 29100 samples
Processed 29200 samples
Processed 29300 samples
Processed 29400 samples
Processed 29500 samples
Processed 29600 samples
Processed 29700 samples
Processed 29800 samples
Processed 29900 samples
Processed 30000 samples
Processed 30100 samples
Processed 30200 samples
Number of rois before non-maximum suppression: 4598955
Number of rois  after non-maximum suppression: 2538281
AP for        Negative = 0.4493
AP for        Positive = 0.4530
Mean AP = 0.4512
