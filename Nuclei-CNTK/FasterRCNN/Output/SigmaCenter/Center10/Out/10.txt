Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = nan * 100, metric = 22.13% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 17.77% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 19.19% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 17.90% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 14.46% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 19.25% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 19.59% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 15.52% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 16.94% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 19.14% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 20.05% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 16.98% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 17.21% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 16.08% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 18.24% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 18.94% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 17.76% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 15.56% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 19.50% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 14.25% * 100;
Finished Epoch[1 of 200]: [Training] loss = nan * 2000, metric = 17.82% * 2000 541.285s (  3.7 samples/s);
Finished Evaluation [1]: Minibatch[1-1000]: metric = 10.31% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 11.98% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 18.48% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 14.36% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 14.70% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 14.64% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 14.62% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 14.38% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 15.67% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 16.43% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 13.81% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 18.45% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 15.43% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 16.15% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 19.59% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 14.23% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 10.93% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 10.74% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 15.30% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 13.47% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 13.17% * 100;
Finished Epoch[2 of 200]: [Training] loss = nan * 2000, metric = 14.83% * 2000 459.538s (  4.4 samples/s);
Finished Evaluation [2]: Minibatch[1-1000]: metric = 10.56% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 15.84% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 11.01% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 14.84% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 13.63% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 15.48% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 15.40% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 12.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 10.87% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 16.53% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 13.66% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 19.52% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 15.14% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 11.34% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 11.68% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 12.50% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 14.45% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 13.09% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 15.23% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 12.28% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 19.34% * 100;
Finished Epoch[3 of 200]: [Training] loss = nan * 2000, metric = 14.19% * 2000 460.612s (  4.3 samples/s);
Finished Evaluation [3]: Minibatch[1-1000]: metric = 10.34% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 17.51% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 15.53% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 15.77% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 12.89% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 14.61% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 15.13% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 17.60% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 12.77% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 16.71% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 17.20% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 12.11% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 16.40% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 17.51% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 14.67% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 14.74% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 16.50% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 14.50% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 19.09% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 12.71% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 13.25% * 100;
Finished Epoch[4 of 200]: [Training] loss = nan * 2000, metric = 15.36% * 2000 459.166s (  4.4 samples/s);
Finished Evaluation [4]: Minibatch[1-1000]: metric = 10.14% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 12.23% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 17.88% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 14.11% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 14.41% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 12.26% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 11.13% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 14.55% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 13.12% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 13.10% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 16.92% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 12.40% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 12.72% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 12.67% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 13.90% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 13.19% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 12.70% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 14.90% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 15.99% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 14.81% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 10.94% * 100;
Finished Epoch[5 of 200]: [Training] loss = nan * 2000, metric = 13.70% * 2000 458.145s (  4.4 samples/s);
Finished Evaluation [5]: Minibatch[1-1000]: metric = 10.48% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 13.63% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 11.96% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 11.50% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 15.29% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 12.97% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 15.06% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 13.12% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 15.01% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 11.77% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 12.85% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 14.50% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 13.52% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 14.74% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 15.92% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 12.49% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 10.96% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 10.91% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 11.31% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 11.82% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 11.71% * 100;
Finished Epoch[6 of 200]: [Training] loss = nan * 2000, metric = 13.05% * 2000 455.531s (  4.4 samples/s);
Finished Evaluation [6]: Minibatch[1-1000]: metric = 10.46% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 10.97% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 11.08% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 11.15% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 10.44% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 11.71% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 10.83% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 11.06% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 11.62% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 11.99% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 11.32% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 11.63% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 10.98% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 12.05% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 11.86% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 10.87% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 11.69% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 11.72% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 11.49% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 11.51% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 11.86% * 100;
Finished Epoch[7 of 200]: [Training] loss = nan * 2000, metric = 11.39% * 2000 455.609s (  4.4 samples/s);
Finished Evaluation [7]: Minibatch[1-1000]: metric = 10.46% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 11.12% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 11.65% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 11.22% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 11.25% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 11.94% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 12.34% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 11.58% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 11.32% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 10.35% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 10.51% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 10.84% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 10.35% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 12.01% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 12.29% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 11.09% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 11.26% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 11.04% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 10.88% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 11.61% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 10.95% * 100;
Finished Epoch[8 of 200]: [Training] loss = nan * 2000, metric = 11.28% * 2000 455.593s (  4.4 samples/s);
Finished Evaluation [8]: Minibatch[1-1000]: metric = 10.44% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 10.51% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 11.81% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 11.40% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 12.07% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 11.28% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 11.53% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 11.09% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 10.55% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 10.70% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 11.81% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 10.05% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 11.54% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 11.12% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 10.65% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 11.41% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 11.31% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 11.14% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 10.64% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 10.81% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 11.28% * 100;
Finished Epoch[9 of 200]: [Training] loss = nan * 2000, metric = 11.14% * 2000 455.682s (  4.4 samples/s);
Finished Evaluation [9]: Minibatch[1-1000]: metric = 10.21% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 12.58% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 10.75% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 11.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 11.12% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 12.08% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 10.55% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 10.40% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 9.63% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 11.46% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 11.53% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 11.73% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 10.83% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 11.37% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 11.71% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 10.31% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 11.29% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 10.80% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 11.47% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 11.19% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 11.29% * 100;
Finished Epoch[10 of 200]: [Training] loss = nan * 2000, metric = 11.15% * 2000 465.010s (  4.3 samples/s);
Finished Evaluation [10]: Minibatch[1-1000]: metric = 10.42% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 9.93% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 10.79% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 11.58% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 11.49% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 11.02% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 12.09% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 10.52% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 11.01% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 10.70% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 10.99% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 10.58% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 11.40% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 11.50% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 10.95% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 11.12% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 11.04% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 10.95% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 11.39% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 11.30% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 11.99% * 100;
Finished Epoch[11 of 200]: [Training] loss = nan * 2000, metric = 11.12% * 2000 456.219s (  4.4 samples/s);
Finished Evaluation [11]: Minibatch[1-1000]: metric = 10.27% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 10.64% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 10.16% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 11.31% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 12.36% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 10.89% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 10.19% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 10.93% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 11.05% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 10.19% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 11.59% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 11.54% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 10.98% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 11.29% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 10.85% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 11.68% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 10.43% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 11.89% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 10.17% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 10.88% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 11.03% * 100;
Finished Epoch[12 of 200]: [Training] loss = nan * 2000, metric = 11.00% * 2000 456.176s (  4.4 samples/s);
Finished Evaluation [12]: Minibatch[1-1000]: metric = 10.46% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 11.57% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 11.36% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 11.37% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 11.57% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 12.42% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 12.34% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 10.68% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 10.96% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 11.33% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 11.96% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 11.44% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 11.07% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 11.67% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 11.23% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 11.48% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 10.97% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 11.01% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 10.95% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 10.84% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 11.35% * 100;
Finished Epoch[13 of 200]: [Training] loss = nan * 2000, metric = 11.38% * 2000 455.976s (  4.4 samples/s);
Finished Evaluation [13]: Minibatch[1-1000]: metric = 10.29% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 10.89% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 10.92% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 11.15% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 11.46% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 11.16% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 11.43% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 10.92% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 11.84% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 12.07% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 12.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 12.01% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 11.29% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 9.96% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 12.09% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 11.20% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 11.11% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 11.13% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 10.60% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 11.32% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 11.04% * 100;
Finished Epoch[14 of 200]: [Training] loss = nan * 2000, metric = 11.28% * 2000 459.852s (  4.3 samples/s);
Finished Evaluation [14]: Minibatch[1-1000]: metric = 10.02% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 11.22% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 11.69% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 11.30% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 10.63% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 11.78% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 9.94% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 10.81% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 11.83% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 12.72% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 11.64% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 11.87% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 11.12% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 10.08% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 12.17% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 10.77% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 11.19% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 11.10% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 10.06% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 11.23% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 11.15% * 100;
Finished Epoch[15 of 200]: [Training] loss = nan * 2000, metric = 11.22% * 2000 456.352s (  4.4 samples/s);
Finished Evaluation [15]: Minibatch[1-1000]: metric = 10.34% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 12.67% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 11.62% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 11.21% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 11.76% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 10.55% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 10.53% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 10.90% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 10.75% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 10.56% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 11.82% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 11.12% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 11.01% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 10.21% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 10.93% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 11.12% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 11.89% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 11.63% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 11.35% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 11.77% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 11.46% * 100;
Finished Epoch[16 of 200]: [Training] loss = nan * 2000, metric = 11.24% * 2000 461.495s (  4.3 samples/s);
Finished Evaluation [16]: Minibatch[1-1000]: metric = 10.10% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 10.79% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 11.33% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 11.54% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 11.65% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 11.44% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 10.92% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 10.38% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 11.28% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 10.67% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 10.94% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 10.92% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 11.97% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 11.80% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 10.61% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 11.19% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 10.92% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 11.19% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 10.78% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 11.83% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 12.29% * 100;
Finished Epoch[17 of 200]: [Training] loss = nan * 2000, metric = 11.22% * 2000 458.500s (  4.4 samples/s);
Finished Evaluation [17]: Minibatch[1-1000]: metric = 10.35% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 10.27% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 11.56% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 10.98% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 11.04% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 10.59% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 10.04% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 11.49% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 10.67% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 11.04% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 11.10% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 11.59% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 11.47% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 11.74% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 11.27% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 10.79% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 11.50% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 10.17% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 10.75% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 10.89% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 10.46% * 100;
Finished Epoch[18 of 200]: [Training] loss = nan * 2000, metric = 10.97% * 2000 456.328s (  4.4 samples/s);
Finished Evaluation [18]: Minibatch[1-1000]: metric = 10.10% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 11.88% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 11.49% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 10.15% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 11.30% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 10.87% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 10.29% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 11.24% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 11.30% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 12.29% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 10.69% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 11.63% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 11.84% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 11.59% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 10.96% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 11.89% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 11.61% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 11.29% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 10.51% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 11.10% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 10.11% * 100;
Finished Epoch[19 of 200]: [Training] loss = nan * 2000, metric = 11.20% * 2000 456.155s (  4.4 samples/s);
Finished Evaluation [19]: Minibatch[1-1000]: metric = 10.38% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 10.80% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 11.10% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 10.59% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 11.28% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 11.40% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 11.20% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 11.31% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 11.19% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 11.50% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 11.49% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 10.29% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 10.89% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 11.84% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 11.44% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 10.89% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 11.32% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 10.74% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 11.53% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 11.23% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 11.16% * 100;
Finished Epoch[20 of 200]: [Training] loss = nan * 2000, metric = 11.16% * 2000 462.016s (  4.3 samples/s);
Finished Evaluation [20]: Minibatch[1-1000]: metric = 10.31% * 1000;
