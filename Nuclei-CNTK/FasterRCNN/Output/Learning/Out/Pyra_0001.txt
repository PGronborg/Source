Using base model:   VGG16
lr_per_sample:      [0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-07]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.0001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.0002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.394125 * 100, metric = 24.94% * 100;
 Minibatch[ 101- 200]: loss = 1.084411 * 100, metric = 23.76% * 100;
 Minibatch[ 201- 300]: loss = 1.017566 * 100, metric = 23.20% * 100;
 Minibatch[ 301- 400]: loss = 1.037741 * 100, metric = 23.74% * 100;
 Minibatch[ 401- 500]: loss = 0.954081 * 100, metric = 22.51% * 100;
 Minibatch[ 501- 600]: loss = 0.956440 * 100, metric = 22.68% * 100;
 Minibatch[ 601- 700]: loss = 0.933531 * 100, metric = 22.44% * 100;
 Minibatch[ 701- 800]: loss = 0.900469 * 100, metric = 21.43% * 100;
 Minibatch[ 801- 900]: loss = 0.929531 * 100, metric = 21.88% * 100;
 Minibatch[ 901-1000]: loss = 0.918812 * 100, metric = 22.52% * 100;
 Minibatch[1001-1100]: loss = 0.903560 * 100, metric = 22.00% * 100;
 Minibatch[1101-1200]: loss = 0.891893 * 100, metric = 21.16% * 100;
 Minibatch[1201-1300]: loss = 0.885341 * 100, metric = 21.28% * 100;
 Minibatch[1301-1400]: loss = 0.859969 * 100, metric = 20.43% * 100;
 Minibatch[1401-1500]: loss = 0.867952 * 100, metric = 20.36% * 100;
 Minibatch[1501-1600]: loss = 0.848030 * 100, metric = 20.91% * 100;
 Minibatch[1601-1700]: loss = 0.842273 * 100, metric = 19.99% * 100;
 Minibatch[1701-1800]: loss = 0.850347 * 100, metric = 20.25% * 100;
 Minibatch[1801-1900]: loss = 0.840061 * 100, metric = 20.00% * 100;
 Minibatch[1901-2000]: loss = 0.819972 * 100, metric = 19.79% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.936805 * 2000, metric = 21.76% * 2000 737.658s (  2.7 samples/s);
Finished Evaluation [1]: Minibatch[1-1000]: metric = 31.84% * 1000;
0.926763023674488
 Minibatch[   1- 100]: loss = 0.818504 * 100, metric = 19.46% * 100;
 Minibatch[ 101- 200]: loss = 0.837429 * 100, metric = 20.06% * 100;
 Minibatch[ 201- 300]: loss = 0.808316 * 100, metric = 18.83% * 100;
 Minibatch[ 301- 400]: loss = 0.817012 * 100, metric = 19.21% * 100;
 Minibatch[ 401- 500]: loss = 0.815131 * 100, metric = 19.29% * 100;
 Minibatch[ 501- 600]: loss = 0.826832 * 100, metric = 19.30% * 100;
 Minibatch[ 601- 700]: loss = 0.775406 * 100, metric = 18.01% * 100;
 Minibatch[ 701- 800]: loss = 0.807173 * 100, metric = 18.92% * 100;
 Minibatch[ 801- 900]: loss = 0.772643 * 100, metric = 18.31% * 100;
 Minibatch[ 901-1000]: loss = 0.761093 * 100, metric = 17.70% * 100;
 Minibatch[1001-1100]: loss = 0.785621 * 100, metric = 18.60% * 100;
 Minibatch[1101-1200]: loss = 0.787509 * 100, metric = 18.42% * 100;
 Minibatch[1201-1300]: loss = 0.762658 * 100, metric = 18.13% * 100;
 Minibatch[1301-1400]: loss = 0.786270 * 100, metric = 18.27% * 100;
 Minibatch[1401-1500]: loss = 0.751641 * 100, metric = 17.03% * 100;
 Minibatch[1501-1600]: loss = 0.739469 * 100, metric = 17.33% * 100;
 Minibatch[1601-1700]: loss = 0.755985 * 100, metric = 17.70% * 100;
 Minibatch[1701-1800]: loss = 0.758138 * 100, metric = 17.50% * 100;
 Minibatch[1801-1900]: loss = 0.759166 * 100, metric = 17.96% * 100;
 Minibatch[1901-2000]: loss = 0.721721 * 100, metric = 17.09% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.782386 * 2000, metric = 18.36% * 2000 661.738s (  3.0 samples/s);
Finished Evaluation [2]: Minibatch[1-1000]: metric = 24.92% * 1000;
0.8085492910146713
 Minibatch[   1- 100]: loss = 0.740398 * 100, metric = 17.08% * 100;
 Minibatch[ 101- 200]: loss = 0.750050 * 100, metric = 17.59% * 100;
 Minibatch[ 201- 300]: loss = 0.736152 * 100, metric = 16.85% * 100;
 Minibatch[ 301- 400]: loss = 0.757155 * 100, metric = 17.63% * 100;
 Minibatch[ 401- 500]: loss = 0.759626 * 100, metric = 17.67% * 100;
 Minibatch[ 501- 600]: loss = 0.744678 * 100, metric = 17.36% * 100;
 Minibatch[ 601- 700]: loss = 0.746528 * 100, metric = 17.51% * 100;
 Minibatch[ 701- 800]: loss = 0.710566 * 100, metric = 16.26% * 100;
 Minibatch[ 801- 900]: loss = 0.743738 * 100, metric = 17.56% * 100;
 Minibatch[ 901-1000]: loss = 0.716156 * 100, metric = 16.84% * 100;
 Minibatch[1001-1100]: loss = 0.732298 * 100, metric = 17.21% * 100;
 Minibatch[1101-1200]: loss = 0.718090 * 100, metric = 16.60% * 100;
 Minibatch[1201-1300]: loss = 0.708299 * 100, metric = 16.22% * 100;
 Minibatch[1301-1400]: loss = 0.719916 * 100, metric = 16.42% * 100;
 Minibatch[1401-1500]: loss = 0.729242 * 100, metric = 16.93% * 100;
 Minibatch[1501-1600]: loss = 0.709258 * 100, metric = 16.14% * 100;
 Minibatch[1601-1700]: loss = 0.695352 * 100, metric = 15.88% * 100;
 Minibatch[1701-1800]: loss = 0.727430 * 100, metric = 16.85% * 100;
 Minibatch[1801-1900]: loss = 0.703303 * 100, metric = 16.12% * 100;
 Minibatch[1901-2000]: loss = 0.698661 * 100, metric = 15.88% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.727345 * 2000, metric = 16.83% * 2000 662.105s (  3.0 samples/s);
Finished Evaluation [3]: Minibatch[1-1000]: metric = 22.23% * 1000;
0.774241620182991
 Minibatch[   1- 100]: loss = 0.720039 * 100, metric = 16.41% * 100;
 Minibatch[ 101- 200]: loss = 0.681680 * 100, metric = 15.75% * 100;
 Minibatch[ 201- 300]: loss = 0.703981 * 100, metric = 16.26% * 100;
 Minibatch[ 301- 400]: loss = 0.666260 * 100, metric = 15.20% * 100;
 Minibatch[ 401- 500]: loss = 0.700922 * 100, metric = 16.36% * 100;
 Minibatch[ 501- 600]: loss = 0.680919 * 100, metric = 15.42% * 100;
 Minibatch[ 601- 700]: loss = 0.684376 * 100, metric = 15.91% * 100;
 Minibatch[ 701- 800]: loss = 0.699718 * 100, metric = 16.25% * 100;
 Minibatch[ 801- 900]: loss = 0.697700 * 100, metric = 16.00% * 100;
 Minibatch[ 901-1000]: loss = 0.693007 * 100, metric = 15.92% * 100;
 Minibatch[1001-1100]: loss = 0.702664 * 100, metric = 16.20% * 100;
 Minibatch[1101-1200]: loss = 0.672673 * 100, metric = 15.21% * 100;
 Minibatch[1201-1300]: loss = 0.678600 * 100, metric = 15.48% * 100;
 Minibatch[1301-1400]: loss = 0.703704 * 100, metric = 16.17% * 100;
 Minibatch[1401-1500]: loss = 0.703963 * 100, metric = 16.27% * 100;
 Minibatch[1501-1600]: loss = 0.653240 * 100, metric = 14.99% * 100;
 Minibatch[1601-1700]: loss = 0.682308 * 100, metric = 16.07% * 100;
 Minibatch[1701-1800]: loss = 0.690242 * 100, metric = 15.91% * 100;
 Minibatch[1801-1900]: loss = 0.674762 * 100, metric = 15.38% * 100;
 Minibatch[1901-2000]: loss = 0.675668 * 100, metric = 15.28% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.688321 * 2000, metric = 15.82% * 2000 662.357s (  3.0 samples/s);
Finished Evaluation [4]: Minibatch[1-1000]: metric = 23.25% * 1000;
 Minibatch[   1- 100]: loss = 0.692985 * 100, metric = 15.79% * 100;
 Minibatch[ 101- 200]: loss = 0.675339 * 100, metric = 15.45% * 100;
 Minibatch[ 201- 300]: loss = 0.668776 * 100, metric = 15.21% * 100;
 Minibatch[ 301- 400]: loss = 0.706066 * 100, metric = 16.45% * 100;
 Minibatch[ 401- 500]: loss = 0.645547 * 100, metric = 14.24% * 100;
 Minibatch[ 501- 600]: loss = 0.649906 * 100, metric = 14.24% * 100;
 Minibatch[ 601- 700]: loss = 0.664146 * 100, metric = 14.56% * 100;
 Minibatch[ 701- 800]: loss = 0.679026 * 100, metric = 15.41% * 100;
 Minibatch[ 801- 900]: loss = 0.653259 * 100, metric = 14.68% * 100;
 Minibatch[ 901-1000]: loss = 0.655775 * 100, metric = 14.92% * 100;
 Minibatch[1001-1100]: loss = 0.663578 * 100, metric = 14.88% * 100;
 Minibatch[1101-1200]: loss = 0.644139 * 100, metric = 14.63% * 100;
 Minibatch[1201-1300]: loss = 0.659593 * 100, metric = 15.03% * 100;
 Minibatch[1301-1400]: loss = 0.685180 * 100, metric = 15.78% * 100;
 Minibatch[1401-1500]: loss = 0.661394 * 100, metric = 14.99% * 100;
 Minibatch[1501-1600]: loss = 0.659000 * 100, metric = 14.87% * 100;
 Minibatch[1601-1700]: loss = 0.670642 * 100, metric = 15.50% * 100;
 Minibatch[1701-1800]: loss = 0.680901 * 100, metric = 15.77% * 100;
 Minibatch[1801-1900]: loss = 0.669897 * 100, metric = 15.36% * 100;
 Minibatch[1901-2000]: loss = 0.655028 * 100, metric = 14.92% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.667009 * 2000, metric = 15.13% * 2000 661.697s (  3.0 samples/s);
Finished Evaluation [5]: Minibatch[1-1000]: metric = 22.73% * 1000;
0.754221871227026
 Minibatch[   1- 100]: loss = 0.643570 * 100, metric = 14.40% * 100;
 Minibatch[ 101- 200]: loss = 0.640212 * 100, metric = 14.74% * 100;
 Minibatch[ 201- 300]: loss = 0.652401 * 100, metric = 14.94% * 100;
 Minibatch[ 301- 400]: loss = 0.651863 * 100, metric = 14.67% * 100;
 Minibatch[ 401- 500]: loss = 0.635546 * 100, metric = 14.41% * 100;
 Minibatch[ 501- 600]: loss = 0.645801 * 100, metric = 14.60% * 100;
 Minibatch[ 601- 700]: loss = 0.641056 * 100, metric = 14.37% * 100;
 Minibatch[ 701- 800]: loss = 0.648373 * 100, metric = 14.73% * 100;
 Minibatch[ 801- 900]: loss = 0.643343 * 100, metric = 14.36% * 100;
 Minibatch[ 901-1000]: loss = 0.637321 * 100, metric = 14.37% * 100;
 Minibatch[1001-1100]: loss = 0.645881 * 100, metric = 14.29% * 100;
 Minibatch[1101-1200]: loss = 0.659302 * 100, metric = 15.03% * 100;
 Minibatch[1201-1300]: loss = 0.668726 * 100, metric = 15.15% * 100;
 Minibatch[1301-1400]: loss = 0.638844 * 100, metric = 14.52% * 100;
 Minibatch[1401-1500]: loss = 0.648600 * 100, metric = 14.81% * 100;
 Minibatch[1501-1600]: loss = 0.627541 * 100, metric = 13.79% * 100;
 Minibatch[1601-1700]: loss = 0.631997 * 100, metric = 14.26% * 100;
 Minibatch[1701-1800]: loss = 0.618336 * 100, metric = 13.73% * 100;
 Minibatch[1801-1900]: loss = 0.651827 * 100, metric = 14.94% * 100;
 Minibatch[1901-2000]: loss = 0.631433 * 100, metric = 14.20% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.643099 * 2000, metric = 14.52% * 2000 654.008s (  3.1 samples/s);
Finished Evaluation [6]: Minibatch[1-1000]: metric = 23.70% * 1000;
 Minibatch[   1- 100]: loss = 0.630434 * 100, metric = 14.17% * 100;
 Minibatch[ 101- 200]: loss = 0.649064 * 100, metric = 14.62% * 100;
 Minibatch[ 201- 300]: loss = 0.648114 * 100, metric = 14.49% * 100;
 Minibatch[ 301- 400]: loss = 0.630731 * 100, metric = 14.06% * 100;
 Minibatch[ 401- 500]: loss = 0.645295 * 100, metric = 14.62% * 100;
 Minibatch[ 501- 600]: loss = 0.622614 * 100, metric = 13.95% * 100;
 Minibatch[ 601- 700]: loss = 0.647887 * 100, metric = 14.40% * 100;
 Minibatch[ 701- 800]: loss = 0.660129 * 100, metric = 14.85% * 100;
 Minibatch[ 801- 900]: loss = 0.654583 * 100, metric = 14.94% * 100;
 Minibatch[ 901-1000]: loss = 0.645731 * 100, metric = 14.30% * 100;
 Minibatch[1001-1100]: loss = 0.648900 * 100, metric = 14.74% * 100;
 Minibatch[1101-1200]: loss = 0.625562 * 100, metric = 14.05% * 100;
 Minibatch[1201-1300]: loss = 0.647287 * 100, metric = 15.01% * 100;
 Minibatch[1301-1400]: loss = 0.630425 * 100, metric = 14.10% * 100;
 Minibatch[1401-1500]: loss = 0.623409 * 100, metric = 13.90% * 100;
 Minibatch[1501-1600]: loss = 0.634088 * 100, metric = 14.29% * 100;
 Minibatch[1601-1700]: loss = 0.649771 * 100, metric = 14.79% * 100;
 Minibatch[1701-1800]: loss = 0.619580 * 100, metric = 13.70% * 100;
 Minibatch[1801-1900]: loss = 0.635950 * 100, metric = 14.57% * 100;
 Minibatch[1901-2000]: loss = 0.632750 * 100, metric = 14.44% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.639115 * 2000, metric = 14.40% * 2000 656.161s (  3.0 samples/s);
Finished Evaluation [7]: Minibatch[1-1000]: metric = 19.99% * 1000;
0.6963430642187596
 Minibatch[   1- 100]: loss = 0.636228 * 100, metric = 14.11% * 100;
 Minibatch[ 101- 200]: loss = 0.625684 * 100, metric = 14.15% * 100;
 Minibatch[ 201- 300]: loss = 0.620295 * 100, metric = 13.80% * 100;
 Minibatch[ 301- 400]: loss = 0.629241 * 100, metric = 14.14% * 100;
 Minibatch[ 401- 500]: loss = 0.642866 * 100, metric = 14.62% * 100;
 Minibatch[ 501- 600]: loss = 0.656411 * 100, metric = 15.01% * 100;
 Minibatch[ 601- 700]: loss = 0.617686 * 100, metric = 13.92% * 100;
 Minibatch[ 701- 800]: loss = 0.634309 * 100, metric = 13.71% * 100;
 Minibatch[ 801- 900]: loss = 0.612723 * 100, metric = 13.23% * 100;
 Minibatch[ 901-1000]: loss = 0.595086 * 100, metric = 13.18% * 100;
 Minibatch[1001-1100]: loss = 0.602240 * 100, metric = 13.29% * 100;
 Minibatch[1101-1200]: loss = 0.599354 * 100, metric = 13.05% * 100;
 Minibatch[1201-1300]: loss = 0.621882 * 100, metric = 13.84% * 100;
 Minibatch[1301-1400]: loss = 0.637650 * 100, metric = 14.19% * 100;
 Minibatch[1401-1500]: loss = 0.616180 * 100, metric = 13.63% * 100;
 Minibatch[1501-1600]: loss = 0.620069 * 100, metric = 13.41% * 100;
 Minibatch[1601-1700]: loss = 0.612419 * 100, metric = 13.40% * 100;
 Minibatch[1701-1800]: loss = 0.618137 * 100, metric = 13.62% * 100;
 Minibatch[1801-1900]: loss = 0.613424 * 100, metric = 13.48% * 100;
 Minibatch[1901-2000]: loss = 0.614366 * 100, metric = 13.37% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.621313 * 2000, metric = 13.76% * 2000 651.678s (  3.1 samples/s);
Finished Evaluation [8]: Minibatch[1-1000]: metric = 19.69% * 1000;
0.6756120536029339
 Minibatch[   1- 100]: loss = 0.586953 * 100, metric = 12.72% * 100;
 Minibatch[ 101- 200]: loss = 0.631567 * 100, metric = 14.02% * 100;
 Minibatch[ 201- 300]: loss = 0.615609 * 100, metric = 13.64% * 100;
 Minibatch[ 301- 400]: loss = 0.632862 * 100, metric = 14.12% * 100;
 Minibatch[ 401- 500]: loss = 0.614606 * 100, metric = 13.55% * 100;
 Minibatch[ 501- 600]: loss = 0.604863 * 100, metric = 13.29% * 100;
 Minibatch[ 601- 700]: loss = 0.604753 * 100, metric = 13.45% * 100;
 Minibatch[ 701- 800]: loss = 0.599007 * 100, metric = 13.03% * 100;
 Minibatch[ 801- 900]: loss = 0.593311 * 100, metric = 13.22% * 100;
 Minibatch[ 901-1000]: loss = 0.619075 * 100, metric = 13.94% * 100;
 Minibatch[1001-1100]: loss = 0.579050 * 100, metric = 12.40% * 100;
 Minibatch[1101-1200]: loss = 0.606592 * 100, metric = 13.29% * 100;
 Minibatch[1201-1300]: loss = 0.608121 * 100, metric = 13.50% * 100;
 Minibatch[1301-1400]: loss = 0.595419 * 100, metric = 12.73% * 100;
 Minibatch[1401-1500]: loss = 0.615994 * 100, metric = 13.48% * 100;
 Minibatch[1501-1600]: loss = 0.603204 * 100, metric = 13.22% * 100;
 Minibatch[1601-1700]: loss = 0.613420 * 100, metric = 13.42% * 100;
 Minibatch[1701-1800]: loss = 0.600690 * 100, metric = 13.09% * 100;
 Minibatch[1801-1900]: loss = 0.598033 * 100, metric = 13.23% * 100;
 Minibatch[1901-2000]: loss = 0.612727 * 100, metric = 13.36% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.606793 * 2000, metric = 13.34% * 2000 652.431s (  3.1 samples/s);
Finished Evaluation [9]: Minibatch[1-1000]: metric = 18.28% * 1000;
0.6407916133999825
 Minibatch[   1- 100]: loss = 0.629079 * 100, metric = 14.36% * 100;
 Minibatch[ 101- 200]: loss = 0.594128 * 100, metric = 13.15% * 100;
 Minibatch[ 201- 300]: loss = 0.610199 * 100, metric = 13.44% * 100;
 Minibatch[ 301- 400]: loss = 0.595073 * 100, metric = 12.99% * 100;
 Minibatch[ 401- 500]: loss = 0.616497 * 100, metric = 13.75% * 100;
 Minibatch[ 501- 600]: loss = 0.583901 * 100, metric = 12.62% * 100;
 Minibatch[ 601- 700]: loss = 0.579599 * 100, metric = 12.90% * 100;
 Minibatch[ 701- 800]: loss = 0.570995 * 100, metric = 12.29% * 100;
 Minibatch[ 801- 900]: loss = 0.592010 * 100, metric = 12.79% * 100;
 Minibatch[ 901-1000]: loss = 0.603507 * 100, metric = 13.18% * 100;
 Minibatch[1001-1100]: loss = 0.608019 * 100, metric = 13.63% * 100;
 Minibatch[1101-1200]: loss = 0.601898 * 100, metric = 13.15% * 100;
 Minibatch[1201-1300]: loss = 0.602188 * 100, metric = 13.36% * 100;
 Minibatch[1301-1400]: loss = 0.603328 * 100, metric = 13.30% * 100;
 Minibatch[1401-1500]: loss = 0.591167 * 100, metric = 12.64% * 100;
 Minibatch[1501-1600]: loss = 0.592816 * 100, metric = 13.30% * 100;
 Minibatch[1601-1700]: loss = 0.596251 * 100, metric = 12.93% * 100;
 Minibatch[1701-1800]: loss = 0.605211 * 100, metric = 13.22% * 100;
 Minibatch[1801-1900]: loss = 0.605898 * 100, metric = 13.31% * 100;
 Minibatch[1901-2000]: loss = 0.595386 * 100, metric = 13.09% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.598858 * 2000, metric = 13.17% * 2000 653.861s (  3.1 samples/s);
Finished Evaluation [10]: Minibatch[1-1000]: metric = 17.37% * 1000;
0.624242826089263
 Minibatch[   1- 100]: loss = 0.571871 * 100, metric = 12.27% * 100;
 Minibatch[ 101- 200]: loss = 0.594879 * 100, metric = 12.79% * 100;
 Minibatch[ 201- 300]: loss = 0.608421 * 100, metric = 13.51% * 100;
 Minibatch[ 301- 400]: loss = 0.605164 * 100, metric = 13.24% * 100;
 Minibatch[ 401- 500]: loss = 0.584996 * 100, metric = 12.82% * 100;
 Minibatch[ 501- 600]: loss = 0.607646 * 100, metric = 13.39% * 100;
 Minibatch[ 601- 700]: loss = 0.582478 * 100, metric = 12.51% * 100;
 Minibatch[ 701- 800]: loss = 0.599725 * 100, metric = 13.30% * 100;
 Minibatch[ 801- 900]: loss = 0.592256 * 100, metric = 12.82% * 100;
 Minibatch[ 901-1000]: loss = 0.599933 * 100, metric = 12.99% * 100;
 Minibatch[1001-1100]: loss = 0.591390 * 100, metric = 12.93% * 100;
 Minibatch[1101-1200]: loss = 0.600294 * 100, metric = 13.29% * 100;
 Minibatch[1201-1300]: loss = 0.581160 * 100, metric = 12.69% * 100;
 Minibatch[1301-1400]: loss = 0.569657 * 100, metric = 12.37% * 100;
 Minibatch[1401-1500]: loss = 0.605565 * 100, metric = 13.58% * 100;
 Minibatch[1501-1600]: loss = 0.585799 * 100, metric = 12.91% * 100;
 Minibatch[1601-1700]: loss = 0.584176 * 100, metric = 12.99% * 100;
 Minibatch[1701-1800]: loss = 0.601896 * 100, metric = 13.19% * 100;
 Minibatch[1801-1900]: loss = 0.590100 * 100, metric = 12.96% * 100;
 Minibatch[1901-2000]: loss = 0.578995 * 100, metric = 12.76% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.591820 * 2000, metric = 12.97% * 2000 647.668s (  3.1 samples/s);
Finished Evaluation [11]: Minibatch[1-1000]: metric = 19.05% * 1000;
 Minibatch[   1- 100]: loss = 0.573196 * 100, metric = 12.43% * 100;
 Minibatch[ 101- 200]: loss = 0.568974 * 100, metric = 11.99% * 100;
 Minibatch[ 201- 300]: loss = 0.578579 * 100, metric = 12.57% * 100;
 Minibatch[ 301- 400]: loss = 0.614569 * 100, metric = 13.71% * 100;
 Minibatch[ 401- 500]: loss = 0.584664 * 100, metric = 12.67% * 100;
 Minibatch[ 501- 600]: loss = 0.558849 * 100, metric = 11.92% * 100;
 Minibatch[ 601- 700]: loss = 0.569723 * 100, metric = 12.32% * 100;
 Minibatch[ 701- 800]: loss = 0.581180 * 100, metric = 12.50% * 100;
 Minibatch[ 801- 900]: loss = 0.570891 * 100, metric = 12.31% * 100;
 Minibatch[ 901-1000]: loss = 0.581482 * 100, metric = 12.69% * 100;
 Minibatch[1001-1100]: loss = 0.587408 * 100, metric = 13.00% * 100;
 Minibatch[1101-1200]: loss = 0.592354 * 100, metric = 12.71% * 100;
 Minibatch[1201-1300]: loss = 0.591924 * 100, metric = 12.84% * 100;
 Minibatch[1301-1400]: loss = 0.575101 * 100, metric = 12.49% * 100;
 Minibatch[1401-1500]: loss = 0.590159 * 100, metric = 13.08% * 100;
 Minibatch[1501-1600]: loss = 0.555505 * 100, metric = 12.03% * 100;
 Minibatch[1601-1700]: loss = 0.589436 * 100, metric = 12.93% * 100;
 Minibatch[1701-1800]: loss = 0.560355 * 100, metric = 11.82% * 100;
 Minibatch[1801-1900]: loss = 0.561179 * 100, metric = 12.13% * 100;
 Minibatch[1901-2000]: loss = 0.596510 * 100, metric = 13.18% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.579102 * 2000, metric = 12.57% * 2000 641.961s (  3.1 samples/s);
Finished Evaluation [12]: Minibatch[1-1000]: metric = 20.63% * 1000;
 Minibatch[   1- 100]: loss = 0.595086 * 100, metric = 13.02% * 100;
 Minibatch[ 101- 200]: loss = 0.578322 * 100, metric = 12.84% * 100;
 Minibatch[ 201- 300]: loss = 0.580219 * 100, metric = 12.66% * 100;
 Minibatch[ 301- 400]: loss = 0.586286 * 100, metric = 12.72% * 100;
 Minibatch[ 401- 500]: loss = 0.593977 * 100, metric = 13.14% * 100;
 Minibatch[ 501- 600]: loss = 0.599576 * 100, metric = 13.56% * 100;
 Minibatch[ 601- 700]: loss = 0.564406 * 100, metric = 11.94% * 100;
 Minibatch[ 701- 800]: loss = 0.563858 * 100, metric = 11.98% * 100;
 Minibatch[ 801- 900]: loss = 0.563402 * 100, metric = 12.16% * 100;
 Minibatch[ 901-1000]: loss = 0.587105 * 100, metric = 12.85% * 100;
 Minibatch[1001-1100]: loss = 0.579323 * 100, metric = 12.64% * 100;
 Minibatch[1101-1200]: loss = 0.575640 * 100, metric = 12.34% * 100;
 Minibatch[1201-1300]: loss = 0.578772 * 100, metric = 12.71% * 100;
 Minibatch[1301-1400]: loss = 0.576050 * 100, metric = 12.31% * 100;
 Minibatch[1401-1500]: loss = 0.563447 * 100, metric = 12.12% * 100;
 Minibatch[1501-1600]: loss = 0.565104 * 100, metric = 12.01% * 100;
 Minibatch[1601-1700]: loss = 0.554028 * 100, metric = 11.88% * 100;
 Minibatch[1701-1800]: loss = 0.569149 * 100, metric = 12.07% * 100;
 Minibatch[1801-1900]: loss = 0.562021 * 100, metric = 12.06% * 100;
 Minibatch[1901-2000]: loss = 0.581167 * 100, metric = 12.62% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.575847 * 2000, metric = 12.48% * 2000 637.711s (  3.1 samples/s);
Finished Evaluation [13]: Minibatch[1-1000]: metric = 18.78% * 1000;
 Minibatch[   1- 100]: loss = 0.567596 * 100, metric = 12.17% * 100;
 Minibatch[ 101- 200]: loss = 0.560466 * 100, metric = 12.12% * 100;
 Minibatch[ 201- 300]: loss = 0.584981 * 100, metric = 12.66% * 100;
 Minibatch[ 301- 400]: loss = 0.573379 * 100, metric = 12.70% * 100;
 Minibatch[ 401- 500]: loss = 0.572593 * 100, metric = 12.51% * 100;
 Minibatch[ 501- 600]: loss = 0.576665 * 100, metric = 12.56% * 100;
 Minibatch[ 601- 700]: loss = 0.572195 * 100, metric = 12.47% * 100;
 Minibatch[ 701- 800]: loss = 0.596604 * 100, metric = 13.13% * 100;
 Minibatch[ 801- 900]: loss = 0.599403 * 100, metric = 13.27% * 100;
 Minibatch[ 901-1000]: loss = 0.585495 * 100, metric = 12.77% * 100;
 Minibatch[1001-1100]: loss = 0.583644 * 100, metric = 12.65% * 100;
 Minibatch[1101-1200]: loss = 0.566062 * 100, metric = 12.11% * 100;
 Minibatch[1201-1300]: loss = 0.550275 * 100, metric = 11.73% * 100;
 Minibatch[1301-1400]: loss = 0.581882 * 100, metric = 12.77% * 100;
 Minibatch[1401-1500]: loss = 0.570651 * 100, metric = 12.66% * 100;
 Minibatch[1501-1600]: loss = 0.557131 * 100, metric = 12.14% * 100;
 Minibatch[1601-1700]: loss = 0.563583 * 100, metric = 11.86% * 100;
 Minibatch[1701-1800]: loss = 0.558747 * 100, metric = 11.93% * 100;
 Minibatch[1801-1900]: loss = 0.570269 * 100, metric = 12.30% * 100;
 Minibatch[1901-2000]: loss = 0.582128 * 100, metric = 12.40% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.573687 * 2000, metric = 12.44% * 2000 634.297s (  3.2 samples/s);
Finished Evaluation [14]: Minibatch[1-1000]: metric = 19.70% * 1000;
 Minibatch[   1- 100]: loss = 0.562867 * 100, metric = 11.99% * 100;
 Minibatch[ 101- 200]: loss = 0.576583 * 100, metric = 12.69% * 100;
 Minibatch[ 201- 300]: loss = 0.577741 * 100, metric = 12.40% * 100;
 Minibatch[ 301- 400]: loss = 0.550356 * 100, metric = 11.57% * 100;
 Minibatch[ 401- 500]: loss = 0.565735 * 100, metric = 12.31% * 100;
 Minibatch[ 501- 600]: loss = 0.544594 * 100, metric = 11.36% * 100;
 Minibatch[ 601- 700]: loss = 0.543857 * 100, metric = 11.56% * 100;
 Minibatch[ 701- 800]: loss = 0.583567 * 100, metric = 12.90% * 100;
 Minibatch[ 801- 900]: loss = 0.597398 * 100, metric = 13.16% * 100;
 Minibatch[ 901-1000]: loss = 0.568674 * 100, metric = 12.50% * 100;
 Minibatch[1001-1100]: loss = 0.571558 * 100, metric = 12.15% * 100;
 Minibatch[1101-1200]: loss = 0.567312 * 100, metric = 12.40% * 100;
 Minibatch[1201-1300]: loss = 0.547810 * 100, metric = 11.62% * 100;
 Minibatch[1301-1400]: loss = 0.585569 * 100, metric = 12.89% * 100;
 Minibatch[1401-1500]: loss = 0.537053 * 100, metric = 11.55% * 100;
 Minibatch[1501-1600]: loss = 0.565159 * 100, metric = 12.22% * 100;
 Minibatch[1601-1700]: loss = 0.566112 * 100, metric = 12.14% * 100;
 Minibatch[1701-1800]: loss = 0.543652 * 100, metric = 11.33% * 100;
 Minibatch[1801-1900]: loss = 0.557179 * 100, metric = 12.04% * 100;
 Minibatch[1901-2000]: loss = 0.547708 * 100, metric = 11.83% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.563024 * 2000, metric = 12.13% * 2000 629.481s (  3.2 samples/s);
Finished Evaluation [15]: Minibatch[1-1000]: metric = 17.33% * 1000;
0.6035886601805687
 Minibatch[   1- 100]: loss = 0.578412 * 100, metric = 12.89% * 100;
 Minibatch[ 101- 200]: loss = 0.573964 * 100, metric = 12.34% * 100;
 Minibatch[ 201- 300]: loss = 0.564274 * 100, metric = 12.08% * 100;
 Minibatch[ 301- 400]: loss = 0.578232 * 100, metric = 12.42% * 100;
 Minibatch[ 401- 500]: loss = 0.545618 * 100, metric = 11.68% * 100;
 Minibatch[ 501- 600]: loss = 0.559624 * 100, metric = 12.01% * 100;
 Minibatch[ 601- 700]: loss = 0.557024 * 100, metric = 11.96% * 100;
 Minibatch[ 701- 800]: loss = 0.543094 * 100, metric = 11.64% * 100;
 Minibatch[ 801- 900]: loss = 0.544733 * 100, metric = 11.55% * 100;
 Minibatch[ 901-1000]: loss = 0.567793 * 100, metric = 12.29% * 100;
 Minibatch[1001-1100]: loss = 0.544146 * 100, metric = 11.76% * 100;
 Minibatch[1101-1200]: loss = 0.548431 * 100, metric = 11.81% * 100;
 Minibatch[1201-1300]: loss = 0.540482 * 100, metric = 11.26% * 100;
 Minibatch[1301-1400]: loss = 0.553712 * 100, metric = 11.89% * 100;
 Minibatch[1401-1500]: loss = 0.551572 * 100, metric = 12.14% * 100;
 Minibatch[1501-1600]: loss = 0.556863 * 100, metric = 12.13% * 100;
 Minibatch[1601-1700]: loss = 0.559976 * 100, metric = 12.15% * 100;
 Minibatch[1701-1800]: loss = 0.582198 * 100, metric = 12.56% * 100;
 Minibatch[1801-1900]: loss = 0.567766 * 100, metric = 12.41% * 100;
 Minibatch[1901-2000]: loss = 0.544509 * 100, metric = 11.69% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.558121 * 2000, metric = 12.03% * 2000 638.320s (  3.1 samples/s);
Finished Evaluation [16]: Minibatch[1-1000]: metric = 17.11% * 1000;
0.6025835510343314
 Minibatch[   1- 100]: loss = 0.538654 * 100, metric = 11.64% * 100;
 Minibatch[ 101- 200]: loss = 0.564516 * 100, metric = 11.96% * 100;
 Minibatch[ 201- 300]: loss = 0.570323 * 100, metric = 12.26% * 100;
 Minibatch[ 301- 400]: loss = 0.558717 * 100, metric = 11.85% * 100;
 Minibatch[ 401- 500]: loss = 0.558016 * 100, metric = 11.98% * 100;
 Minibatch[ 501- 600]: loss = 0.545218 * 100, metric = 11.82% * 100;
 Minibatch[ 601- 700]: loss = 0.532841 * 100, metric = 11.06% * 100;
 Minibatch[ 701- 800]: loss = 0.554150 * 100, metric = 11.63% * 100;
 Minibatch[ 801- 900]: loss = 0.554756 * 100, metric = 11.54% * 100;
 Minibatch[ 901-1000]: loss = 0.539835 * 100, metric = 11.43% * 100;
 Minibatch[1001-1100]: loss = 0.541187 * 100, metric = 11.38% * 100;
 Minibatch[1101-1200]: loss = 0.562380 * 100, metric = 11.93% * 100;
 Minibatch[1201-1300]: loss = 0.556105 * 100, metric = 12.15% * 100;
 Minibatch[1301-1400]: loss = 0.527829 * 100, metric = 11.34% * 100;
 Minibatch[1401-1500]: loss = 0.550291 * 100, metric = 11.86% * 100;
 Minibatch[1501-1600]: loss = 0.546752 * 100, metric = 11.72% * 100;
 Minibatch[1601-1700]: loss = 0.556108 * 100, metric = 11.65% * 100;
 Minibatch[1701-1800]: loss = 0.530175 * 100, metric = 11.29% * 100;
 Minibatch[1801-1900]: loss = 0.567924 * 100, metric = 12.17% * 100;
 Minibatch[1901-2000]: loss = 0.570240 * 100, metric = 12.39% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.551301 * 2000, metric = 11.75% * 2000 636.467s (  3.1 samples/s);
Finished Evaluation [17]: Minibatch[1-1000]: metric = 17.52% * 1000;
 Minibatch[   1- 100]: loss = 0.535975 * 100, metric = 11.48% * 100;
 Minibatch[ 101- 200]: loss = 0.562072 * 100, metric = 12.02% * 100;
 Minibatch[ 201- 300]: loss = 0.534810 * 100, metric = 11.62% * 100;
 Minibatch[ 301- 400]: loss = 0.553511 * 100, metric = 11.90% * 100;
 Minibatch[ 401- 500]: loss = 0.519301 * 100, metric = 10.87% * 100;
 Minibatch[ 501- 600]: loss = 0.540076 * 100, metric = 11.34% * 100;
 Minibatch[ 601- 700]: loss = 0.552794 * 100, metric = 11.77% * 100;
 Minibatch[ 701- 800]: loss = 0.538469 * 100, metric = 11.45% * 100;
 Minibatch[ 801- 900]: loss = 0.558198 * 100, metric = 12.00% * 100;
 Minibatch[ 901-1000]: loss = 0.561218 * 100, metric = 12.15% * 100;
 Minibatch[1001-1100]: loss = 0.565521 * 100, metric = 12.29% * 100;
 Minibatch[1101-1200]: loss = 0.550370 * 100, metric = 11.66% * 100;
 Minibatch[1201-1300]: loss = 0.564316 * 100, metric = 12.19% * 100;
 Minibatch[1301-1400]: loss = 0.565236 * 100, metric = 12.05% * 100;
 Minibatch[1401-1500]: loss = 0.530943 * 100, metric = 11.17% * 100;
 Minibatch[1501-1600]: loss = 0.548220 * 100, metric = 11.49% * 100;
 Minibatch[1601-1700]: loss = 0.516157 * 100, metric = 10.65% * 100;
 Minibatch[1701-1800]: loss = 0.536440 * 100, metric = 11.42% * 100;
 Minibatch[1801-1900]: loss = 0.526441 * 100, metric = 11.34% * 100;
 Minibatch[1901-2000]: loss = 0.531830 * 100, metric = 11.09% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.544595 * 2000, metric = 11.60% * 2000 649.772s (  3.1 samples/s);
Finished Evaluation [18]: Minibatch[1-1000]: metric = 18.39% * 1000;
 Minibatch[   1- 100]: loss = 0.551112 * 100, metric = 12.13% * 100;
 Minibatch[ 101- 200]: loss = 0.566922 * 100, metric = 12.04% * 100;
 Minibatch[ 201- 300]: loss = 0.531036 * 100, metric = 11.12% * 100;
 Minibatch[ 301- 400]: loss = 0.554928 * 100, metric = 11.80% * 100;
 Minibatch[ 401- 500]: loss = 0.542779 * 100, metric = 11.45% * 100;
 Minibatch[ 501- 600]: loss = 0.526605 * 100, metric = 11.11% * 100;
 Minibatch[ 601- 700]: loss = 0.560850 * 100, metric = 12.14% * 100;
 Minibatch[ 701- 800]: loss = 0.521120 * 100, metric = 11.09% * 100;
 Minibatch[ 801- 900]: loss = 0.577729 * 100, metric = 12.37% * 100;
 Minibatch[ 901-1000]: loss = 0.533126 * 100, metric = 11.22% * 100;
 Minibatch[1001-1100]: loss = 0.554116 * 100, metric = 11.72% * 100;
 Minibatch[1101-1200]: loss = 0.543251 * 100, metric = 11.70% * 100;
 Minibatch[1201-1300]: loss = 0.541927 * 100, metric = 11.66% * 100;
 Minibatch[1301-1400]: loss = 0.543402 * 100, metric = 11.61% * 100;
 Minibatch[1401-1500]: loss = 0.549774 * 100, metric = 11.78% * 100;
 Minibatch[1501-1600]: loss = 0.551246 * 100, metric = 11.70% * 100;
 Minibatch[1601-1700]: loss = 0.534872 * 100, metric = 11.82% * 100;
 Minibatch[1701-1800]: loss = 0.527559 * 100, metric = 11.47% * 100;
 Minibatch[1801-1900]: loss = 0.537258 * 100, metric = 11.53% * 100;
 Minibatch[1901-2000]: loss = 0.526605 * 100, metric = 11.12% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.543811 * 2000, metric = 11.63% * 2000 641.955s (  3.1 samples/s);
Finished Evaluation [19]: Minibatch[1-1000]: metric = 18.41% * 1000;
 Minibatch[   1- 100]: loss = 0.528739 * 100, metric = 11.30% * 100;
 Minibatch[ 101- 200]: loss = 0.538110 * 100, metric = 11.46% * 100;
 Minibatch[ 201- 300]: loss = 0.530768 * 100, metric = 11.17% * 100;
 Minibatch[ 301- 400]: loss = 0.560904 * 100, metric = 11.87% * 100;
 Minibatch[ 401- 500]: loss = 0.535669 * 100, metric = 11.56% * 100;
 Minibatch[ 501- 600]: loss = 0.543827 * 100, metric = 11.70% * 100;
 Minibatch[ 601- 700]: loss = 0.549197 * 100, metric = 11.92% * 100;
 Minibatch[ 701- 800]: loss = 0.547693 * 100, metric = 11.48% * 100;
 Minibatch[ 801- 900]: loss = 0.565717 * 100, metric = 12.06% * 100;
 Minibatch[ 901-1000]: loss = 0.564032 * 100, metric = 12.11% * 100;
 Minibatch[1001-1100]: loss = 0.518123 * 100, metric = 10.96% * 100;
 Minibatch[1101-1200]: loss = 0.544935 * 100, metric = 11.63% * 100;
 Minibatch[1201-1300]: loss = 0.558947 * 100, metric = 12.01% * 100;
 Minibatch[1301-1400]: loss = 0.549343 * 100, metric = 11.91% * 100;
 Minibatch[1401-1500]: loss = 0.537593 * 100, metric = 11.69% * 100;
 Minibatch[1501-1600]: loss = 0.560708 * 100, metric = 11.88% * 100;
 Minibatch[1601-1700]: loss = 0.543820 * 100, metric = 11.67% * 100;
 Minibatch[1701-1800]: loss = 0.545702 * 100, metric = 12.10% * 100;
 Minibatch[1801-1900]: loss = 0.530743 * 100, metric = 11.16% * 100;
 Minibatch[1901-2000]: loss = 0.534545 * 100, metric = 11.27% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.544456 * 2000, metric = 11.65% * 2000 637.767s (  3.1 samples/s);
Finished Evaluation [20]: Minibatch[1-1000]: metric = 17.83% * 1000;
 Minibatch[   1- 100]: loss = 0.544811 * 100, metric = 11.56% * 100;
 Minibatch[ 101- 200]: loss = 0.545162 * 100, metric = 11.90% * 100;
 Minibatch[ 201- 300]: loss = 0.541608 * 100, metric = 11.64% * 100;
 Minibatch[ 301- 400]: loss = 0.550318 * 100, metric = 11.92% * 100;
 Minibatch[ 401- 500]: loss = 0.523161 * 100, metric = 11.17% * 100;
 Minibatch[ 501- 600]: loss = 0.528844 * 100, metric = 11.31% * 100;
 Minibatch[ 601- 700]: loss = 0.533827 * 100, metric = 11.26% * 100;
 Minibatch[ 701- 800]: loss = 0.499141 * 100, metric = 10.38% * 100;
 Minibatch[ 801- 900]: loss = 0.539153 * 100, metric = 11.17% * 100;
 Minibatch[ 901-1000]: loss = 0.525955 * 100, metric = 11.33% * 100;
 Minibatch[1001-1100]: loss = 0.536646 * 100, metric = 11.36% * 100;
 Minibatch[1101-1200]: loss = 0.522150 * 100, metric = 10.71% * 100;
 Minibatch[1201-1300]: loss = 0.531057 * 100, metric = 11.27% * 100;
 Minibatch[1301-1400]: loss = 0.519661 * 100, metric = 10.99% * 100;
 Minibatch[1401-1500]: loss = 0.546990 * 100, metric = 11.62% * 100;
 Minibatch[1501-1600]: loss = 0.556369 * 100, metric = 12.32% * 100;
 Minibatch[1601-1700]: loss = 0.541929 * 100, metric = 11.52% * 100;
 Minibatch[1701-1800]: loss = 0.523239 * 100, metric = 10.81% * 100;
 Minibatch[1801-1900]: loss = 0.555396 * 100, metric = 11.87% * 100;
 Minibatch[1901-2000]: loss = 0.519919 * 100, metric = 10.76% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.534267 * 2000, metric = 11.34% * 2000 644.830s (  3.1 samples/s);
Finished Evaluation [21]: Minibatch[1-1000]: metric = 16.49% * 1000;
0.5857998199760914
 Minibatch[   1- 100]: loss = 0.547528 * 100, metric = 11.78% * 100;
 Minibatch[ 101- 200]: loss = 0.534922 * 100, metric = 11.08% * 100;
 Minibatch[ 201- 300]: loss = 0.548072 * 100, metric = 11.72% * 100;
 Minibatch[ 301- 400]: loss = 0.532842 * 100, metric = 11.48% * 100;
 Minibatch[ 401- 500]: loss = 0.539741 * 100, metric = 11.56% * 100;
 Minibatch[ 501- 600]: loss = 0.538854 * 100, metric = 11.38% * 100;
 Minibatch[ 601- 700]: loss = 0.524975 * 100, metric = 11.10% * 100;
 Minibatch[ 701- 800]: loss = 0.531503 * 100, metric = 11.31% * 100;
 Minibatch[ 801- 900]: loss = 0.543761 * 100, metric = 11.77% * 100;
 Minibatch[ 901-1000]: loss = 0.548647 * 100, metric = 11.74% * 100;
 Minibatch[1001-1100]: loss = 0.515817 * 100, metric = 10.88% * 100;
 Minibatch[1101-1200]: loss = 0.510507 * 100, metric = 10.58% * 100;
 Minibatch[1201-1300]: loss = 0.520219 * 100, metric = 10.92% * 100;
 Minibatch[1301-1400]: loss = 0.530591 * 100, metric = 11.08% * 100;
 Minibatch[1401-1500]: loss = 0.523444 * 100, metric = 11.15% * 100;
 Minibatch[1501-1600]: loss = 0.523757 * 100, metric = 11.00% * 100;
 Minibatch[1601-1700]: loss = 0.524877 * 100, metric = 11.08% * 100;
 Minibatch[1701-1800]: loss = 0.529149 * 100, metric = 11.10% * 100;
 Minibatch[1801-1900]: loss = 0.517778 * 100, metric = 10.98% * 100;
 Minibatch[1901-2000]: loss = 0.531468 * 100, metric = 11.00% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.530922 * 2000, metric = 11.23% * 2000 621.537s (  3.2 samples/s);
Finished Evaluation [22]: Minibatch[1-1000]: metric = 17.29% * 1000;
 Minibatch[   1- 100]: loss = 0.540778 * 100, metric = 11.53% * 100;
 Minibatch[ 101- 200]: loss = 0.552185 * 100, metric = 12.01% * 100;
 Minibatch[ 201- 300]: loss = 0.525984 * 100, metric = 11.06% * 100;
 Minibatch[ 301- 400]: loss = 0.549402 * 100, metric = 11.77% * 100;
 Minibatch[ 401- 500]: loss = 0.547057 * 100, metric = 11.69% * 100;
 Minibatch[ 501- 600]: loss = 0.543892 * 100, metric = 11.55% * 100;
 Minibatch[ 601- 700]: loss = 0.540090 * 100, metric = 11.45% * 100;
 Minibatch[ 701- 800]: loss = 0.507125 * 100, metric = 10.43% * 100;
 Minibatch[ 801- 900]: loss = 0.515766 * 100, metric = 11.10% * 100;
 Minibatch[ 901-1000]: loss = 0.540512 * 100, metric = 11.62% * 100;
 Minibatch[1001-1100]: loss = 0.525661 * 100, metric = 11.02% * 100;
 Minibatch[1101-1200]: loss = 0.530554 * 100, metric = 11.18% * 100;
 Minibatch[1201-1300]: loss = 0.531655 * 100, metric = 11.15% * 100;
 Minibatch[1301-1400]: loss = 0.541085 * 100, metric = 11.44% * 100;
 Minibatch[1401-1500]: loss = 0.513738 * 100, metric = 10.76% * 100;
 Minibatch[1501-1600]: loss = 0.519520 * 100, metric = 10.96% * 100;
 Minibatch[1601-1700]: loss = 0.526959 * 100, metric = 11.12% * 100;
 Minibatch[1701-1800]: loss = 0.545180 * 100, metric = 11.63% * 100;
 Minibatch[1801-1900]: loss = 0.527621 * 100, metric = 11.17% * 100;
 Minibatch[1901-2000]: loss = 0.528517 * 100, metric = 11.27% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.532664 * 2000, metric = 11.29% * 2000 622.863s (  3.2 samples/s);
Finished Evaluation [23]: Minibatch[1-1000]: metric = 17.12% * 1000;
 Minibatch[   1- 100]: loss = 0.509886 * 100, metric = 10.89% * 100;
 Minibatch[ 101- 200]: loss = 0.535637 * 100, metric = 11.54% * 100;
 Minibatch[ 201- 300]: loss = 0.524337 * 100, metric = 10.97% * 100;
 Minibatch[ 301- 400]: loss = 0.524639 * 100, metric = 11.08% * 100;
 Minibatch[ 401- 500]: loss = 0.534044 * 100, metric = 11.26% * 100;
 Minibatch[ 501- 600]: loss = 0.509200 * 100, metric = 10.71% * 100;
 Minibatch[ 601- 700]: loss = 0.535940 * 100, metric = 11.28% * 100;
 Minibatch[ 701- 800]: loss = 0.520830 * 100, metric = 11.14% * 100;
 Minibatch[ 801- 900]: loss = 0.532438 * 100, metric = 11.37% * 100;
 Minibatch[ 901-1000]: loss = 0.532387 * 100, metric = 11.29% * 100;
 Minibatch[1001-1100]: loss = 0.532908 * 100, metric = 11.42% * 100;
 Minibatch[1101-1200]: loss = 0.551484 * 100, metric = 11.70% * 100;
 Minibatch[1201-1300]: loss = 0.543738 * 100, metric = 11.74% * 100;
 Minibatch[1301-1400]: loss = 0.516255 * 100, metric = 10.74% * 100;
 Minibatch[1401-1500]: loss = 0.516010 * 100, metric = 10.71% * 100;
 Minibatch[1501-1600]: loss = 0.533418 * 100, metric = 11.39% * 100;
 Minibatch[1601-1700]: loss = 0.511321 * 100, metric = 10.56% * 100;
 Minibatch[1701-1800]: loss = 0.512007 * 100, metric = 10.78% * 100;
 Minibatch[1801-1900]: loss = 0.532122 * 100, metric = 11.36% * 100;
 Minibatch[1901-2000]: loss = 0.532010 * 100, metric = 11.55% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.527031 * 2000, metric = 11.17% * 2000 619.163s (  3.2 samples/s);
Finished Evaluation [24]: Minibatch[1-1000]: metric = 16.23% * 1000;
0.5706853345781565
 Minibatch[   1- 100]: loss = 0.530361 * 100, metric = 11.22% * 100;
 Minibatch[ 101- 200]: loss = 0.531325 * 100, metric = 11.27% * 100;
 Minibatch[ 201- 300]: loss = 0.527052 * 100, metric = 11.32% * 100;
 Minibatch[ 301- 400]: loss = 0.536345 * 100, metric = 11.63% * 100;
 Minibatch[ 401- 500]: loss = 0.532457 * 100, metric = 11.37% * 100;
 Minibatch[ 501- 600]: loss = 0.527527 * 100, metric = 11.16% * 100;
 Minibatch[ 601- 700]: loss = 0.525208 * 100, metric = 11.03% * 100;
 Minibatch[ 701- 800]: loss = 0.516167 * 100, metric = 10.64% * 100;
 Minibatch[ 801- 900]: loss = 0.515609 * 100, metric = 10.77% * 100;
 Minibatch[ 901-1000]: loss = 0.527703 * 100, metric = 11.43% * 100;
 Minibatch[1001-1100]: loss = 0.533485 * 100, metric = 11.53% * 100;
 Minibatch[1101-1200]: loss = 0.540544 * 100, metric = 11.58% * 100;
 Minibatch[1201-1300]: loss = 0.551993 * 100, metric = 11.69% * 100;
 Minibatch[1301-1400]: loss = 0.517211 * 100, metric = 10.78% * 100;
 Minibatch[1401-1500]: loss = 0.515504 * 100, metric = 10.82% * 100;
 Minibatch[1501-1600]: loss = 0.541819 * 100, metric = 11.49% * 100;
 Minibatch[1601-1700]: loss = 0.521019 * 100, metric = 10.93% * 100;
 Minibatch[1701-1800]: loss = 0.536915 * 100, metric = 11.41% * 100;
 Minibatch[1801-1900]: loss = 0.515756 * 100, metric = 10.91% * 100;
 Minibatch[1901-2000]: loss = 0.506511 * 100, metric = 10.67% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.527526 * 2000, metric = 11.18% * 2000 623.994s (  3.2 samples/s);
Finished Evaluation [25]: Minibatch[1-1000]: metric = 16.98% * 1000;
 Minibatch[   1- 100]: loss = 0.528113 * 100, metric = 11.25% * 100;
 Minibatch[ 101- 200]: loss = 0.502820 * 100, metric = 10.58% * 100;
 Minibatch[ 201- 300]: loss = 0.527107 * 100, metric = 11.29% * 100;
 Minibatch[ 301- 400]: loss = 0.514811 * 100, metric = 10.72% * 100;
 Minibatch[ 401- 500]: loss = 0.526265 * 100, metric = 11.07% * 100;
 Minibatch[ 501- 600]: loss = 0.523456 * 100, metric = 10.88% * 100;
 Minibatch[ 601- 700]: loss = 0.539451 * 100, metric = 11.38% * 100;
 Minibatch[ 701- 800]: loss = 0.519155 * 100, metric = 11.34% * 100;
 Minibatch[ 801- 900]: loss = 0.513655 * 100, metric = 10.69% * 100;
 Minibatch[ 901-1000]: loss = 0.508848 * 100, metric = 10.75% * 100;
 Minibatch[1001-1100]: loss = 0.535117 * 100, metric = 11.56% * 100;
 Minibatch[1101-1200]: loss = 0.546113 * 100, metric = 11.60% * 100;
 Minibatch[1201-1300]: loss = 0.520010 * 100, metric = 11.05% * 100;
 Minibatch[1301-1400]: loss = 0.509729 * 100, metric = 10.51% * 100;
 Minibatch[1401-1500]: loss = 0.524256 * 100, metric = 11.10% * 100;
 Minibatch[1501-1600]: loss = 0.513238 * 100, metric = 10.77% * 100;
 Minibatch[1601-1700]: loss = 0.544113 * 100, metric = 11.43% * 100;
 Minibatch[1701-1800]: loss = 0.532210 * 100, metric = 11.27% * 100;
 Minibatch[1801-1900]: loss = 0.527221 * 100, metric = 11.15% * 100;
 Minibatch[1901-2000]: loss = 0.523685 * 100, metric = 11.22% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.523969 * 2000, metric = 11.08% * 2000 616.200s (  3.2 samples/s);
Finished Evaluation [26]: Minibatch[1-1000]: metric = 16.76% * 1000;
 Minibatch[   1- 100]: loss = 0.520939 * 100, metric = 10.81% * 100;
 Minibatch[ 101- 200]: loss = 0.533961 * 100, metric = 11.07% * 100;
 Minibatch[ 201- 300]: loss = 0.517682 * 100, metric = 10.98% * 100;
 Minibatch[ 301- 400]: loss = 0.507157 * 100, metric = 10.77% * 100;
 Minibatch[ 401- 500]: loss = 0.516826 * 100, metric = 10.81% * 100;
 Minibatch[ 501- 600]: loss = 0.510520 * 100, metric = 10.69% * 100;
 Minibatch[ 601- 700]: loss = 0.508642 * 100, metric = 10.76% * 100;
 Minibatch[ 701- 800]: loss = 0.522385 * 100, metric = 11.07% * 100;
 Minibatch[ 801- 900]: loss = 0.533036 * 100, metric = 11.24% * 100;
 Minibatch[ 901-1000]: loss = 0.529641 * 100, metric = 11.43% * 100;
 Minibatch[1001-1100]: loss = 0.514020 * 100, metric = 10.81% * 100;
 Minibatch[1101-1200]: loss = 0.532133 * 100, metric = 11.28% * 100;
 Minibatch[1201-1300]: loss = 0.523291 * 100, metric = 11.24% * 100;
 Minibatch[1301-1400]: loss = 0.529203 * 100, metric = 11.21% * 100;
 Minibatch[1401-1500]: loss = 0.507244 * 100, metric = 10.85% * 100;
 Minibatch[1501-1600]: loss = 0.519978 * 100, metric = 10.81% * 100;
 Minibatch[1601-1700]: loss = 0.492131 * 100, metric = 10.04% * 100;
 Minibatch[1701-1800]: loss = 0.511288 * 100, metric = 10.44% * 100;
 Minibatch[1801-1900]: loss = 0.509451 * 100, metric = 10.51% * 100;
 Minibatch[1901-2000]: loss = 0.521694 * 100, metric = 10.98% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.518061 * 2000, metric = 10.89% * 2000 616.727s (  3.2 samples/s);
Finished Evaluation [27]: Minibatch[1-1000]: metric = 16.32% * 1000;
 Minibatch[   1- 100]: loss = 0.517512 * 100, metric = 10.98% * 100;
 Minibatch[ 101- 200]: loss = 0.504927 * 100, metric = 10.56% * 100;
 Minibatch[ 201- 300]: loss = 0.516866 * 100, metric = 11.03% * 100;
 Minibatch[ 301- 400]: loss = 0.523323 * 100, metric = 11.03% * 100;
 Minibatch[ 401- 500]: loss = 0.516764 * 100, metric = 11.04% * 100;
 Minibatch[ 501- 600]: loss = 0.542360 * 100, metric = 11.76% * 100;
 Minibatch[ 601- 700]: loss = 0.509785 * 100, metric = 10.69% * 100;
 Minibatch[ 701- 800]: loss = 0.507122 * 100, metric = 10.70% * 100;
 Minibatch[ 801- 900]: loss = 0.527463 * 100, metric = 11.34% * 100;
 Minibatch[ 901-1000]: loss = 0.530813 * 100, metric = 11.31% * 100;
 Minibatch[1001-1100]: loss = 0.512100 * 100, metric = 10.79% * 100;
 Minibatch[1101-1200]: loss = 0.508173 * 100, metric = 10.63% * 100;
 Minibatch[1201-1300]: loss = 0.527359 * 100, metric = 11.13% * 100;
 Minibatch[1301-1400]: loss = 0.510673 * 100, metric = 10.83% * 100;
 Minibatch[1401-1500]: loss = 0.530468 * 100, metric = 11.06% * 100;
 Minibatch[1501-1600]: loss = 0.521234 * 100, metric = 10.95% * 100;
 Minibatch[1601-1700]: loss = 0.519974 * 100, metric = 10.82% * 100;
 Minibatch[1701-1800]: loss = 0.509125 * 100, metric = 10.51% * 100;
 Minibatch[1801-1900]: loss = 0.522661 * 100, metric = 11.23% * 100;
 Minibatch[1901-2000]: loss = 0.523627 * 100, metric = 10.94% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.519116 * 2000, metric = 10.97% * 2000 618.344s (  3.2 samples/s);
Finished Evaluation [28]: Minibatch[1-1000]: metric = 14.85% * 1000;
0.5473031989112497
 Minibatch[   1- 100]: loss = 0.509509 * 100, metric = 10.70% * 100;
 Minibatch[ 101- 200]: loss = 0.510755 * 100, metric = 10.92% * 100;
 Minibatch[ 201- 300]: loss = 0.525449 * 100, metric = 11.24% * 100;
 Minibatch[ 301- 400]: loss = 0.547828 * 100, metric = 11.78% * 100;
 Minibatch[ 401- 500]: loss = 0.505968 * 100, metric = 10.53% * 100;
 Minibatch[ 501- 600]: loss = 0.513509 * 100, metric = 10.76% * 100;
 Minibatch[ 601- 700]: loss = 0.507172 * 100, metric = 11.01% * 100;
 Minibatch[ 701- 800]: loss = 0.522015 * 100, metric = 11.17% * 100;
 Minibatch[ 801- 900]: loss = 0.517390 * 100, metric = 11.08% * 100;
 Minibatch[ 901-1000]: loss = 0.523515 * 100, metric = 11.24% * 100;
 Minibatch[1001-1100]: loss = 0.523774 * 100, metric = 11.18% * 100;
 Minibatch[1101-1200]: loss = 0.510807 * 100, metric = 10.82% * 100;
 Minibatch[1201-1300]: loss = 0.521193 * 100, metric = 11.02% * 100;
 Minibatch[1301-1400]: loss = 0.496910 * 100, metric = 10.57% * 100;
 Minibatch[1401-1500]: loss = 0.526624 * 100, metric = 10.98% * 100;
 Minibatch[1501-1600]: loss = 0.495433 * 100, metric = 10.48% * 100;
 Minibatch[1601-1700]: loss = 0.527931 * 100, metric = 11.21% * 100;
 Minibatch[1701-1800]: loss = 0.493879 * 100, metric = 10.28% * 100;
 Minibatch[1801-1900]: loss = 0.525667 * 100, metric = 11.32% * 100;
 Minibatch[1901-2000]: loss = 0.512023 * 100, metric = 11.06% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.515867 * 2000, metric = 10.97% * 2000 614.887s (  3.3 samples/s);
Finished Evaluation [29]: Minibatch[1-1000]: metric = 17.67% * 1000;
 Minibatch[   1- 100]: loss = 0.534147 * 100, metric = 11.39% * 100;
 Minibatch[ 101- 200]: loss = 0.488986 * 100, metric = 10.30% * 100;
 Minibatch[ 201- 300]: loss = 0.498413 * 100, metric = 10.41% * 100;
 Minibatch[ 301- 400]: loss = 0.520583 * 100, metric = 11.16% * 100;
 Minibatch[ 401- 500]: loss = 0.514453 * 100, metric = 10.69% * 100;
 Minibatch[ 501- 600]: loss = 0.482248 * 100, metric = 9.78% * 100;
 Minibatch[ 601- 700]: loss = 0.515206 * 100, metric = 10.97% * 100;
 Minibatch[ 701- 800]: loss = 0.507293 * 100, metric = 10.56% * 100;
 Minibatch[ 801- 900]: loss = 0.520590 * 100, metric = 10.80% * 100;
 Minibatch[ 901-1000]: loss = 0.482977 * 100, metric = 10.01% * 100;
 Minibatch[1001-1100]: loss = 0.514013 * 100, metric = 10.63% * 100;
 Minibatch[1101-1200]: loss = 0.522521 * 100, metric = 11.08% * 100;
 Minibatch[1201-1300]: loss = 0.498525 * 100, metric = 10.16% * 100;
 Minibatch[1301-1400]: loss = 0.504117 * 100, metric = 10.49% * 100;
 Minibatch[1401-1500]: loss = 0.517076 * 100, metric = 11.06% * 100;
 Minibatch[1501-1600]: loss = 0.519302 * 100, metric = 11.00% * 100;
 Minibatch[1601-1700]: loss = 0.515198 * 100, metric = 10.71% * 100;
 Minibatch[1701-1800]: loss = 0.515786 * 100, metric = 10.86% * 100;
 Minibatch[1801-1900]: loss = 0.508018 * 100, metric = 10.79% * 100;
 Minibatch[1901-2000]: loss = 0.533705 * 100, metric = 11.22% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.510658 * 2000, metric = 10.70% * 2000 622.026s (  3.2 samples/s);
Finished Evaluation [30]: Minibatch[1-1000]: metric = 16.29% * 1000;
 Minibatch[   1- 100]: loss = 0.504205 * 100, metric = 10.48% * 100;
 Minibatch[ 101- 200]: loss = 0.524853 * 100, metric = 11.19% * 100;
 Minibatch[ 201- 300]: loss = 0.513745 * 100, metric = 10.71% * 100;
 Minibatch[ 301- 400]: loss = 0.507890 * 100, metric = 10.74% * 100;
 Minibatch[ 401- 500]: loss = 0.509766 * 100, metric = 10.78% * 100;
 Minibatch[ 501- 600]: loss = 0.499592 * 100, metric = 10.51% * 100;
 Minibatch[ 601- 700]: loss = 0.524973 * 100, metric = 11.21% * 100;
 Minibatch[ 701- 800]: loss = 0.521555 * 100, metric = 10.94% * 100;
 Minibatch[ 801- 900]: loss = 0.513901 * 100, metric = 10.73% * 100;
 Minibatch[ 901-1000]: loss = 0.501595 * 100, metric = 10.37% * 100;
 Minibatch[1001-1100]: loss = 0.500522 * 100, metric = 10.56% * 100;
 Minibatch[1101-1200]: loss = 0.510308 * 100, metric = 10.87% * 100;
 Minibatch[1201-1300]: loss = 0.514284 * 100, metric = 10.88% * 100;
 Minibatch[1301-1400]: loss = 0.516857 * 100, metric = 11.05% * 100;
 Minibatch[1401-1500]: loss = 0.515272 * 100, metric = 10.58% * 100;
 Minibatch[1501-1600]: loss = 0.493602 * 100, metric = 10.65% * 100;
 Minibatch[1601-1700]: loss = 0.512149 * 100, metric = 11.11% * 100;
 Minibatch[1701-1800]: loss = 0.501540 * 100, metric = 10.69% * 100;
 Minibatch[1801-1900]: loss = 0.511463 * 100, metric = 10.96% * 100;
 Minibatch[1901-2000]: loss = 0.521054 * 100, metric = 11.01% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.510956 * 2000, metric = 10.80% * 2000 628.804s (  3.2 samples/s);
Finished Evaluation [31]: Minibatch[1-1000]: metric = 16.40% * 1000;
 Minibatch[   1- 100]: loss = 0.504633 * 100, metric = 10.69% * 100;
 Minibatch[ 101- 200]: loss = 0.507520 * 100, metric = 10.53% * 100;
 Minibatch[ 201- 300]: loss = 0.520670 * 100, metric = 11.10% * 100;
 Minibatch[ 301- 400]: loss = 0.532579 * 100, metric = 11.10% * 100;
 Minibatch[ 401- 500]: loss = 0.526141 * 100, metric = 11.25% * 100;
 Minibatch[ 501- 600]: loss = 0.515291 * 100, metric = 10.95% * 100;
 Minibatch[ 601- 700]: loss = 0.503290 * 100, metric = 10.39% * 100;
 Minibatch[ 701- 800]: loss = 0.502538 * 100, metric = 10.48% * 100;
 Minibatch[ 801- 900]: loss = 0.503250 * 100, metric = 10.51% * 100;
 Minibatch[ 901-1000]: loss = 0.490383 * 100, metric = 10.22% * 100;
 Minibatch[1001-1100]: loss = 0.502355 * 100, metric = 10.69% * 100;
 Minibatch[1101-1200]: loss = 0.503500 * 100, metric = 10.59% * 100;
 Minibatch[1201-1300]: loss = 0.523401 * 100, metric = 11.08% * 100;
 Minibatch[1301-1400]: loss = 0.511718 * 100, metric = 10.85% * 100;
 Minibatch[1401-1500]: loss = 0.510359 * 100, metric = 11.03% * 100;
 Minibatch[1501-1600]: loss = 0.513305 * 100, metric = 10.68% * 100;
 Minibatch[1601-1700]: loss = 0.499315 * 100, metric = 10.38% * 100;
 Minibatch[1701-1800]: loss = 0.520033 * 100, metric = 10.93% * 100;
 Minibatch[1801-1900]: loss = 0.496022 * 100, metric = 10.37% * 100;
 Minibatch[1901-2000]: loss = 0.516155 * 100, metric = 11.03% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.510123 * 2000, metric = 10.74% * 2000 624.541s (  3.2 samples/s);
Finished Evaluation [32]: Minibatch[1-1000]: metric = 15.45% * 1000;
 Minibatch[   1- 100]: loss = 0.537664 * 100, metric = 11.42% * 100;
 Minibatch[ 101- 200]: loss = 0.501923 * 100, metric = 10.43% * 100;
 Minibatch[ 201- 300]: loss = 0.495302 * 100, metric = 10.45% * 100;
 Minibatch[ 301- 400]: loss = 0.507274 * 100, metric = 10.75% * 100;
 Minibatch[ 401- 500]: loss = 0.502710 * 100, metric = 10.36% * 100;
 Minibatch[ 501- 600]: loss = 0.511526 * 100, metric = 10.83% * 100;
 Minibatch[ 601- 700]: loss = 0.508330 * 100, metric = 10.84% * 100;
 Minibatch[ 701- 800]: loss = 0.505160 * 100, metric = 10.64% * 100;
 Minibatch[ 801- 900]: loss = 0.503973 * 100, metric = 10.42% * 100;
 Minibatch[ 901-1000]: loss = 0.493058 * 100, metric = 10.39% * 100;
 Minibatch[1001-1100]: loss = 0.503361 * 100, metric = 10.76% * 100;
 Minibatch[1101-1200]: loss = 0.488001 * 100, metric = 10.17% * 100;
 Minibatch[1201-1300]: loss = 0.512923 * 100, metric = 10.51% * 100;
 Minibatch[1301-1400]: loss = 0.492378 * 100, metric = 9.93% * 100;
 Minibatch[1401-1500]: loss = 0.521296 * 100, metric = 10.90% * 100;
 Minibatch[1501-1600]: loss = 0.513901 * 100, metric = 10.85% * 100;
 Minibatch[1601-1700]: loss = 0.493779 * 100, metric = 10.13% * 100;
 Minibatch[1701-1800]: loss = 0.502245 * 100, metric = 10.45% * 100;
 Minibatch[1801-1900]: loss = 0.498606 * 100, metric = 10.32% * 100;
 Minibatch[1901-2000]: loss = 0.521519 * 100, metric = 11.15% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.505747 * 2000, metric = 10.58% * 2000 627.254s (  3.2 samples/s);
Finished Evaluation [33]: Minibatch[1-1000]: metric = 15.18% * 1000;
 Minibatch[   1- 100]: loss = 0.501238 * 100, metric = 10.38% * 100;
 Minibatch[ 101- 200]: loss = 0.507405 * 100, metric = 10.69% * 100;
 Minibatch[ 201- 300]: loss = 0.491000 * 100, metric = 10.39% * 100;
 Minibatch[ 301- 400]: loss = 0.510845 * 100, metric = 10.66% * 100;
 Minibatch[ 401- 500]: loss = 0.490139 * 100, metric = 9.98% * 100;
 Minibatch[ 501- 600]: loss = 0.505923 * 100, metric = 10.47% * 100;
 Minibatch[ 601- 700]: loss = 0.511744 * 100, metric = 10.65% * 100;
 Minibatch[ 701- 800]: loss = 0.505108 * 100, metric = 10.61% * 100;
 Minibatch[ 801- 900]: loss = 0.490995 * 100, metric = 9.98% * 100;
 Minibatch[ 901-1000]: loss = 0.492730 * 100, metric = 10.14% * 100;
 Minibatch[1001-1100]: loss = 0.507433 * 100, metric = 10.65% * 100;
 Minibatch[1101-1200]: loss = 0.501428 * 100, metric = 10.54% * 100;
 Minibatch[1201-1300]: loss = 0.508134 * 100, metric = 10.61% * 100;
 Minibatch[1301-1400]: loss = 0.501022 * 100, metric = 10.64% * 100;
 Minibatch[1401-1500]: loss = 0.516265 * 100, metric = 10.97% * 100;
 Minibatch[1501-1600]: loss = 0.512934 * 100, metric = 10.62% * 100;
 Minibatch[1601-1700]: loss = 0.527983 * 100, metric = 11.11% * 100;
 Minibatch[1701-1800]: loss = 0.505226 * 100, metric = 10.56% * 100;
 Minibatch[1801-1900]: loss = 0.496144 * 100, metric = 10.42% * 100;
 Minibatch[1901-2000]: loss = 0.502369 * 100, metric = 10.47% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.504303 * 2000, metric = 10.53% * 2000 623.993s (  3.2 samples/s);
Finished Evaluation [34]: Minibatch[1-1000]: metric = 15.63% * 1000;
 Minibatch[   1- 100]: loss = 0.484542 * 100, metric = 9.96% * 100;
 Minibatch[ 101- 200]: loss = 0.506445 * 100, metric = 10.87% * 100;
 Minibatch[ 201- 300]: loss = 0.512441 * 100, metric = 10.77% * 100;
 Minibatch[ 301- 400]: loss = 0.480129 * 100, metric = 10.01% * 100;
 Minibatch[ 401- 500]: loss = 0.503622 * 100, metric = 10.46% * 100;
 Minibatch[ 501- 600]: loss = 0.470300 * 100, metric = 9.67% * 100;
 Minibatch[ 601- 700]: loss = 0.508680 * 100, metric = 10.71% * 100;
 Minibatch[ 701- 800]: loss = 0.470804 * 100, metric = 9.55% * 100;
 Minibatch[ 801- 900]: loss = 0.515091 * 100, metric = 10.82% * 100;
 Minibatch[ 901-1000]: loss = 0.486796 * 100, metric = 10.07% * 100;
 Minibatch[1001-1100]: loss = 0.516259 * 100, metric = 10.87% * 100;
 Minibatch[1101-1200]: loss = 0.490746 * 100, metric = 10.37% * 100;
 Minibatch[1201-1300]: loss = 0.505757 * 100, metric = 10.62% * 100;
 Minibatch[1301-1400]: loss = 0.506094 * 100, metric = 10.91% * 100;
 Minibatch[1401-1500]: loss = 0.488167 * 100, metric = 9.83% * 100;
 Minibatch[1501-1600]: loss = 0.497838 * 100, metric = 10.54% * 100;
 Minibatch[1601-1700]: loss = 0.495969 * 100, metric = 10.43% * 100;
 Minibatch[1701-1800]: loss = 0.494806 * 100, metric = 10.24% * 100;
 Minibatch[1801-1900]: loss = 0.517361 * 100, metric = 10.78% * 100;
 Minibatch[1901-2000]: loss = 0.495693 * 100, metric = 10.19% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.497377 * 2000, metric = 10.38% * 2000 620.906s (  3.2 samples/s);
Finished Evaluation [35]: Minibatch[1-1000]: metric = 15.40% * 1000;
 Minibatch[   1- 100]: loss = 0.485371 * 100, metric = 9.95% * 100;
 Minibatch[ 101- 200]: loss = 0.476007 * 100, metric = 9.89% * 100;
 Minibatch[ 201- 300]: loss = 0.516439 * 100, metric = 10.88% * 100;
 Minibatch[ 301- 400]: loss = 0.492188 * 100, metric = 9.88% * 100;
 Minibatch[ 401- 500]: loss = 0.499161 * 100, metric = 10.19% * 100;
 Minibatch[ 501- 600]: loss = 0.491903 * 100, metric = 9.97% * 100;
 Minibatch[ 601- 700]: loss = 0.500255 * 100, metric = 10.23% * 100;
 Minibatch[ 701- 800]: loss = 0.472903 * 100, metric = 9.76% * 100;
 Minibatch[ 801- 900]: loss = 0.485018 * 100, metric = 10.28% * 100;
 Minibatch[ 901-1000]: loss = 0.506291 * 100, metric = 10.56% * 100;
 Minibatch[1001-1100]: loss = 0.520242 * 100, metric = 10.89% * 100;
 Minibatch[1101-1200]: loss = 0.497062 * 100, metric = 10.38% * 100;
 Minibatch[1201-1300]: loss = 0.495498 * 100, metric = 10.43% * 100;
 Minibatch[1301-1400]: loss = 0.474568 * 100, metric = 9.74% * 100;
 Minibatch[1401-1500]: loss = 0.487365 * 100, metric = 9.85% * 100;
 Minibatch[1501-1600]: loss = 0.499578 * 100, metric = 10.70% * 100;
 Minibatch[1601-1700]: loss = 0.511107 * 100, metric = 11.05% * 100;
 Minibatch[1701-1800]: loss = 0.502205 * 100, metric = 10.59% * 100;
 Minibatch[1801-1900]: loss = 0.502492 * 100, metric = 10.42% * 100;
 Minibatch[1901-2000]: loss = 0.494419 * 100, metric = 10.22% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.495504 * 2000, metric = 10.29% * 2000 619.259s (  3.2 samples/s);
Finished Evaluation [36]: Minibatch[1-1000]: metric = 14.81% * 1000;
0.5297251003831625
 Minibatch[   1- 100]: loss = 0.498548 * 100, metric = 10.50% * 100;
 Minibatch[ 101- 200]: loss = 0.506407 * 100, metric = 10.60% * 100;
 Minibatch[ 201- 300]: loss = 0.496863 * 100, metric = 10.35% * 100;
 Minibatch[ 301- 400]: loss = 0.499083 * 100, metric = 10.51% * 100;
 Minibatch[ 401- 500]: loss = 0.504436 * 100, metric = 10.57% * 100;
 Minibatch[ 501- 600]: loss = 0.480403 * 100, metric = 9.91% * 100;
 Minibatch[ 601- 700]: loss = 0.493642 * 100, metric = 10.04% * 100;
 Minibatch[ 701- 800]: loss = 0.511082 * 100, metric = 10.86% * 100;