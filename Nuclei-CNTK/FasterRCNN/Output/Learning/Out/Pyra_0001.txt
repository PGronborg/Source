Using base model:   VGG16
lr_per_sample:      [0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-07]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.0001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.0002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.394125 * 100, metric = 24.94% * 100;
 Minibatch[ 101- 200]: loss = 1.084411 * 100, metric = 23.76% * 100;
 Minibatch[ 201- 300]: loss = 1.017566 * 100, metric = 23.20% * 100;
 Minibatch[ 301- 400]: loss = 1.037741 * 100, metric = 23.74% * 100;
 Minibatch[ 401- 500]: loss = 0.954081 * 100, metric = 22.51% * 100;
 Minibatch[ 501- 600]: loss = 0.956440 * 100, metric = 22.68% * 100;
 Minibatch[ 601- 700]: loss = 0.933531 * 100, metric = 22.44% * 100;
 Minibatch[ 701- 800]: loss = 0.900469 * 100, metric = 21.43% * 100;
 Minibatch[ 801- 900]: loss = 0.929531 * 100, metric = 21.88% * 100;
 Minibatch[ 901-1000]: loss = 0.918812 * 100, metric = 22.52% * 100;
 Minibatch[1001-1100]: loss = 0.903560 * 100, metric = 22.00% * 100;
 Minibatch[1101-1200]: loss = 0.891893 * 100, metric = 21.16% * 100;
 Minibatch[1201-1300]: loss = 0.885341 * 100, metric = 21.28% * 100;
 Minibatch[1301-1400]: loss = 0.859969 * 100, metric = 20.43% * 100;
 Minibatch[1401-1500]: loss = 0.867952 * 100, metric = 20.36% * 100;
 Minibatch[1501-1600]: loss = 0.848030 * 100, metric = 20.91% * 100;
 Minibatch[1601-1700]: loss = 0.842273 * 100, metric = 19.99% * 100;
 Minibatch[1701-1800]: loss = 0.850347 * 100, metric = 20.25% * 100;
 Minibatch[1801-1900]: loss = 0.840061 * 100, metric = 20.00% * 100;
 Minibatch[1901-2000]: loss = 0.819972 * 100, metric = 19.79% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.936805 * 2000, metric = 21.76% * 2000 737.658s (  2.7 samples/s);
Finished Evaluation [1]: Minibatch[1-1000]: metric = 31.84% * 1000;
0.926763023674488
 Minibatch[   1- 100]: loss = 0.818504 * 100, metric = 19.46% * 100;
 Minibatch[ 101- 200]: loss = 0.837429 * 100, metric = 20.06% * 100;
 Minibatch[ 201- 300]: loss = 0.808316 * 100, metric = 18.83% * 100;
 Minibatch[ 301- 400]: loss = 0.817012 * 100, metric = 19.21% * 100;
 Minibatch[ 401- 500]: loss = 0.815131 * 100, metric = 19.29% * 100;
 Minibatch[ 501- 600]: loss = 0.826832 * 100, metric = 19.30% * 100;
 Minibatch[ 601- 700]: loss = 0.775406 * 100, metric = 18.01% * 100;
 Minibatch[ 701- 800]: loss = 0.807173 * 100, metric = 18.92% * 100;
 Minibatch[ 801- 900]: loss = 0.772643 * 100, metric = 18.31% * 100;
 Minibatch[ 901-1000]: loss = 0.761093 * 100, metric = 17.70% * 100;
 Minibatch[1001-1100]: loss = 0.785621 * 100, metric = 18.60% * 100;
 Minibatch[1101-1200]: loss = 0.787509 * 100, metric = 18.42% * 100;
 Minibatch[1201-1300]: loss = 0.762658 * 100, metric = 18.13% * 100;
 Minibatch[1301-1400]: loss = 0.786270 * 100, metric = 18.27% * 100;
 Minibatch[1401-1500]: loss = 0.751641 * 100, metric = 17.03% * 100;
 Minibatch[1501-1600]: loss = 0.739469 * 100, metric = 17.33% * 100;
 Minibatch[1601-1700]: loss = 0.755985 * 100, metric = 17.70% * 100;
 Minibatch[1701-1800]: loss = 0.758138 * 100, metric = 17.50% * 100;
 Minibatch[1801-1900]: loss = 0.759166 * 100, metric = 17.96% * 100;
 Minibatch[1901-2000]: loss = 0.721721 * 100, metric = 17.09% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.782386 * 2000, metric = 18.36% * 2000 661.738s (  3.0 samples/s);
Finished Evaluation [2]: Minibatch[1-1000]: metric = 24.92% * 1000;
0.8085492910146713
 Minibatch[   1- 100]: loss = 0.740398 * 100, metric = 17.08% * 100;
 Minibatch[ 101- 200]: loss = 0.750050 * 100, metric = 17.59% * 100;
 Minibatch[ 201- 300]: loss = 0.736152 * 100, metric = 16.85% * 100;
 Minibatch[ 301- 400]: loss = 0.757155 * 100, metric = 17.63% * 100;
 Minibatch[ 401- 500]: loss = 0.759626 * 100, metric = 17.67% * 100;
 Minibatch[ 501- 600]: loss = 0.744678 * 100, metric = 17.36% * 100;
 Minibatch[ 601- 700]: loss = 0.746528 * 100, metric = 17.51% * 100;
 Minibatch[ 701- 800]: loss = 0.710566 * 100, metric = 16.26% * 100;
 Minibatch[ 801- 900]: loss = 0.743738 * 100, metric = 17.56% * 100;
 Minibatch[ 901-1000]: loss = 0.716156 * 100, metric = 16.84% * 100;
 Minibatch[1001-1100]: loss = 0.732298 * 100, metric = 17.21% * 100;
 Minibatch[1101-1200]: loss = 0.718090 * 100, metric = 16.60% * 100;
 Minibatch[1201-1300]: loss = 0.708299 * 100, metric = 16.22% * 100;
 Minibatch[1301-1400]: loss = 0.719916 * 100, metric = 16.42% * 100;
 Minibatch[1401-1500]: loss = 0.729242 * 100, metric = 16.93% * 100;
 Minibatch[1501-1600]: loss = 0.709258 * 100, metric = 16.14% * 100;
 Minibatch[1601-1700]: loss = 0.695352 * 100, metric = 15.88% * 100;
 Minibatch[1701-1800]: loss = 0.727430 * 100, metric = 16.85% * 100;
 Minibatch[1801-1900]: loss = 0.703303 * 100, metric = 16.12% * 100;
 Minibatch[1901-2000]: loss = 0.698661 * 100, metric = 15.88% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.727345 * 2000, metric = 16.83% * 2000 662.105s (  3.0 samples/s);
Finished Evaluation [3]: Minibatch[1-1000]: metric = 22.23% * 1000;
0.774241620182991
 Minibatch[   1- 100]: loss = 0.720039 * 100, metric = 16.41% * 100;
 Minibatch[ 101- 200]: loss = 0.681680 * 100, metric = 15.75% * 100;
 Minibatch[ 201- 300]: loss = 0.703981 * 100, metric = 16.26% * 100;
 Minibatch[ 301- 400]: loss = 0.666260 * 100, metric = 15.20% * 100;
 Minibatch[ 401- 500]: loss = 0.700922 * 100, metric = 16.36% * 100;
 Minibatch[ 501- 600]: loss = 0.680919 * 100, metric = 15.42% * 100;
 Minibatch[ 601- 700]: loss = 0.684376 * 100, metric = 15.91% * 100;
 Minibatch[ 701- 800]: loss = 0.699718 * 100, metric = 16.25% * 100;
 Minibatch[ 801- 900]: loss = 0.697700 * 100, metric = 16.00% * 100;
 Minibatch[ 901-1000]: loss = 0.693007 * 100, metric = 15.92% * 100;
 Minibatch[1001-1100]: loss = 0.702664 * 100, metric = 16.20% * 100;
 Minibatch[1101-1200]: loss = 0.672673 * 100, metric = 15.21% * 100;
 Minibatch[1201-1300]: loss = 0.678600 * 100, metric = 15.48% * 100;
 Minibatch[1301-1400]: loss = 0.703704 * 100, metric = 16.17% * 100;
 Minibatch[1401-1500]: loss = 0.703963 * 100, metric = 16.27% * 100;
 Minibatch[1501-1600]: loss = 0.653240 * 100, metric = 14.99% * 100;
 Minibatch[1601-1700]: loss = 0.682308 * 100, metric = 16.07% * 100;
 Minibatch[1701-1800]: loss = 0.690242 * 100, metric = 15.91% * 100;
 Minibatch[1801-1900]: loss = 0.674762 * 100, metric = 15.38% * 100;
 Minibatch[1901-2000]: loss = 0.675668 * 100, metric = 15.28% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.688321 * 2000, metric = 15.82% * 2000 662.357s (  3.0 samples/s);
Finished Evaluation [4]: Minibatch[1-1000]: metric = 23.25% * 1000;
 Minibatch[   1- 100]: loss = 0.692985 * 100, metric = 15.79% * 100;
 Minibatch[ 101- 200]: loss = 0.675339 * 100, metric = 15.45% * 100;
 Minibatch[ 201- 300]: loss = 0.668776 * 100, metric = 15.21% * 100;
 Minibatch[ 301- 400]: loss = 0.706066 * 100, metric = 16.45% * 100;
 Minibatch[ 401- 500]: loss = 0.645547 * 100, metric = 14.24% * 100;
 Minibatch[ 501- 600]: loss = 0.649906 * 100, metric = 14.24% * 100;
 Minibatch[ 601- 700]: loss = 0.664146 * 100, metric = 14.56% * 100;
 Minibatch[ 701- 800]: loss = 0.679026 * 100, metric = 15.41% * 100;
 Minibatch[ 801- 900]: loss = 0.653259 * 100, metric = 14.68% * 100;
 Minibatch[ 901-1000]: loss = 0.655775 * 100, metric = 14.92% * 100;
 Minibatch[1001-1100]: loss = 0.663578 * 100, metric = 14.88% * 100;
 Minibatch[1101-1200]: loss = 0.644139 * 100, metric = 14.63% * 100;
 Minibatch[1201-1300]: loss = 0.659593 * 100, metric = 15.03% * 100;
 Minibatch[1301-1400]: loss = 0.685180 * 100, metric = 15.78% * 100;
 Minibatch[1401-1500]: loss = 0.661394 * 100, metric = 14.99% * 100;
 Minibatch[1501-1600]: loss = 0.659000 * 100, metric = 14.87% * 100;
 Minibatch[1601-1700]: loss = 0.670642 * 100, metric = 15.50% * 100;
 Minibatch[1701-1800]: loss = 0.680901 * 100, metric = 15.77% * 100;
 Minibatch[1801-1900]: loss = 0.669897 * 100, metric = 15.36% * 100;
 Minibatch[1901-2000]: loss = 0.655028 * 100, metric = 14.92% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.667009 * 2000, metric = 15.13% * 2000 661.697s (  3.0 samples/s);
Finished Evaluation [5]: Minibatch[1-1000]: metric = 22.73% * 1000;
0.754221871227026
 Minibatch[   1- 100]: loss = 0.643570 * 100, metric = 14.40% * 100;
 Minibatch[ 101- 200]: loss = 0.640212 * 100, metric = 14.74% * 100;
 Minibatch[ 201- 300]: loss = 0.652401 * 100, metric = 14.94% * 100;
 Minibatch[ 301- 400]: loss = 0.651863 * 100, metric = 14.67% * 100;
 Minibatch[ 401- 500]: loss = 0.635546 * 100, metric = 14.41% * 100;
 Minibatch[ 501- 600]: loss = 0.645801 * 100, metric = 14.60% * 100;
 Minibatch[ 601- 700]: loss = 0.641056 * 100, metric = 14.37% * 100;
 Minibatch[ 701- 800]: loss = 0.648373 * 100, metric = 14.73% * 100;
 Minibatch[ 801- 900]: loss = 0.643343 * 100, metric = 14.36% * 100;
 Minibatch[ 901-1000]: loss = 0.637321 * 100, metric = 14.37% * 100;
 Minibatch[1001-1100]: loss = 0.645881 * 100, metric = 14.29% * 100;
 Minibatch[1101-1200]: loss = 0.659302 * 100, metric = 15.03% * 100;
 Minibatch[1201-1300]: loss = 0.668726 * 100, metric = 15.15% * 100;
 Minibatch[1301-1400]: loss = 0.638844 * 100, metric = 14.52% * 100;
 Minibatch[1401-1500]: loss = 0.648600 * 100, metric = 14.81% * 100;
 Minibatch[1501-1600]: loss = 0.627541 * 100, metric = 13.79% * 100;
 Minibatch[1601-1700]: loss = 0.631997 * 100, metric = 14.26% * 100;
 Minibatch[1701-1800]: loss = 0.618336 * 100, metric = 13.73% * 100;
 Minibatch[1801-1900]: loss = 0.651827 * 100, metric = 14.94% * 100;
 Minibatch[1901-2000]: loss = 0.631433 * 100, metric = 14.20% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.643099 * 2000, metric = 14.52% * 2000 654.008s (  3.1 samples/s);
Finished Evaluation [6]: Minibatch[1-1000]: metric = 23.70% * 1000;
 Minibatch[   1- 100]: loss = 0.630434 * 100, metric = 14.17% * 100;
 Minibatch[ 101- 200]: loss = 0.649064 * 100, metric = 14.62% * 100;
 Minibatch[ 201- 300]: loss = 0.648114 * 100, metric = 14.49% * 100;
 Minibatch[ 301- 400]: loss = 0.630731 * 100, metric = 14.06% * 100;
 Minibatch[ 401- 500]: loss = 0.645295 * 100, metric = 14.62% * 100;
 Minibatch[ 501- 600]: loss = 0.622614 * 100, metric = 13.95% * 100;
 Minibatch[ 601- 700]: loss = 0.647887 * 100, metric = 14.40% * 100;
 Minibatch[ 701- 800]: loss = 0.660129 * 100, metric = 14.85% * 100;
 Minibatch[ 801- 900]: loss = 0.654583 * 100, metric = 14.94% * 100;
 Minibatch[ 901-1000]: loss = 0.645731 * 100, metric = 14.30% * 100;
 Minibatch[1001-1100]: loss = 0.648900 * 100, metric = 14.74% * 100;
 Minibatch[1101-1200]: loss = 0.625562 * 100, metric = 14.05% * 100;
 Minibatch[1201-1300]: loss = 0.647287 * 100, metric = 15.01% * 100;
 Minibatch[1301-1400]: loss = 0.630425 * 100, metric = 14.10% * 100;
 Minibatch[1401-1500]: loss = 0.623409 * 100, metric = 13.90% * 100;
 Minibatch[1501-1600]: loss = 0.634088 * 100, metric = 14.29% * 100;
 Minibatch[1601-1700]: loss = 0.649771 * 100, metric = 14.79% * 100;
 Minibatch[1701-1800]: loss = 0.619580 * 100, metric = 13.70% * 100;
 Minibatch[1801-1900]: loss = 0.635950 * 100, metric = 14.57% * 100;
 Minibatch[1901-2000]: loss = 0.632750 * 100, metric = 14.44% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.639115 * 2000, metric = 14.40% * 2000 656.161s (  3.0 samples/s);
Finished Evaluation [7]: Minibatch[1-1000]: metric = 19.99% * 1000;
0.6963430642187596
 Minibatch[   1- 100]: loss = 0.636228 * 100, metric = 14.11% * 100;
 Minibatch[ 101- 200]: loss = 0.625684 * 100, metric = 14.15% * 100;
 Minibatch[ 201- 300]: loss = 0.620295 * 100, metric = 13.80% * 100;
 Minibatch[ 301- 400]: loss = 0.629241 * 100, metric = 14.14% * 100;
 Minibatch[ 401- 500]: loss = 0.642866 * 100, metric = 14.62% * 100;
 Minibatch[ 501- 600]: loss = 0.656411 * 100, metric = 15.01% * 100;
 Minibatch[ 601- 700]: loss = 0.617686 * 100, metric = 13.92% * 100;
 Minibatch[ 701- 800]: loss = 0.634309 * 100, metric = 13.71% * 100;
 Minibatch[ 801- 900]: loss = 0.612723 * 100, metric = 13.23% * 100;
 Minibatch[ 901-1000]: loss = 0.595086 * 100, metric = 13.18% * 100;
 Minibatch[1001-1100]: loss = 0.602240 * 100, metric = 13.29% * 100;
 Minibatch[1101-1200]: loss = 0.599354 * 100, metric = 13.05% * 100;
 Minibatch[1201-1300]: loss = 0.621882 * 100, metric = 13.84% * 100;
 Minibatch[1301-1400]: loss = 0.637650 * 100, metric = 14.19% * 100;
 Minibatch[1401-1500]: loss = 0.616180 * 100, metric = 13.63% * 100;
 Minibatch[1501-1600]: loss = 0.620069 * 100, metric = 13.41% * 100;
 Minibatch[1601-1700]: loss = 0.612419 * 100, metric = 13.40% * 100;
 Minibatch[1701-1800]: loss = 0.618137 * 100, metric = 13.62% * 100;
 Minibatch[1801-1900]: loss = 0.613424 * 100, metric = 13.48% * 100;
 Minibatch[1901-2000]: loss = 0.614366 * 100, metric = 13.37% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.621313 * 2000, metric = 13.76% * 2000 651.678s (  3.1 samples/s);
Finished Evaluation [8]: Minibatch[1-1000]: metric = 19.69% * 1000;
0.6756120536029339
 Minibatch[   1- 100]: loss = 0.586953 * 100, metric = 12.72% * 100;
 Minibatch[ 101- 200]: loss = 0.631567 * 100, metric = 14.02% * 100;
 Minibatch[ 201- 300]: loss = 0.615609 * 100, metric = 13.64% * 100;
 Minibatch[ 301- 400]: loss = 0.632862 * 100, metric = 14.12% * 100;
 Minibatch[ 401- 500]: loss = 0.614606 * 100, metric = 13.55% * 100;
 Minibatch[ 501- 600]: loss = 0.604863 * 100, metric = 13.29% * 100;
 Minibatch[ 601- 700]: loss = 0.604753 * 100, metric = 13.45% * 100;
 Minibatch[ 701- 800]: loss = 0.599007 * 100, metric = 13.03% * 100;
 Minibatch[ 801- 900]: loss = 0.593311 * 100, metric = 13.22% * 100;
 Minibatch[ 901-1000]: loss = 0.619075 * 100, metric = 13.94% * 100;
 Minibatch[1001-1100]: loss = 0.579050 * 100, metric = 12.40% * 100;
 Minibatch[1101-1200]: loss = 0.606592 * 100, metric = 13.29% * 100;
 Minibatch[1201-1300]: loss = 0.608121 * 100, metric = 13.50% * 100;
 Minibatch[1301-1400]: loss = 0.595419 * 100, metric = 12.73% * 100;
 Minibatch[1401-1500]: loss = 0.615994 * 100, metric = 13.48% * 100;
 Minibatch[1501-1600]: loss = 0.603204 * 100, metric = 13.22% * 100;
 Minibatch[1601-1700]: loss = 0.613420 * 100, metric = 13.42% * 100;
 Minibatch[1701-1800]: loss = 0.600690 * 100, metric = 13.09% * 100;
 Minibatch[1801-1900]: loss = 0.598033 * 100, metric = 13.23% * 100;
 Minibatch[1901-2000]: loss = 0.612727 * 100, metric = 13.36% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.606793 * 2000, metric = 13.34% * 2000 652.431s (  3.1 samples/s);
Finished Evaluation [9]: Minibatch[1-1000]: metric = 18.28% * 1000;
0.6407916133999825
 Minibatch[   1- 100]: loss = 0.629079 * 100, metric = 14.36% * 100;
 Minibatch[ 101- 200]: loss = 0.594128 * 100, metric = 13.15% * 100;
 Minibatch[ 201- 300]: loss = 0.610199 * 100, metric = 13.44% * 100;
 Minibatch[ 301- 400]: loss = 0.595073 * 100, metric = 12.99% * 100;
 Minibatch[ 401- 500]: loss = 0.616497 * 100, metric = 13.75% * 100;
 Minibatch[ 501- 600]: loss = 0.583901 * 100, metric = 12.62% * 100;
 Minibatch[ 601- 700]: loss = 0.579599 * 100, metric = 12.90% * 100;
 Minibatch[ 701- 800]: loss = 0.570995 * 100, metric = 12.29% * 100;
 Minibatch[ 801- 900]: loss = 0.592010 * 100, metric = 12.79% * 100;
 Minibatch[ 901-1000]: loss = 0.603507 * 100, metric = 13.18% * 100;
 Minibatch[1001-1100]: loss = 0.608019 * 100, metric = 13.63% * 100;
 Minibatch[1101-1200]: loss = 0.601898 * 100, metric = 13.15% * 100;
 Minibatch[1201-1300]: loss = 0.602188 * 100, metric = 13.36% * 100;
 Minibatch[1301-1400]: loss = 0.603328 * 100, metric = 13.30% * 100;
 Minibatch[1401-1500]: loss = 0.591167 * 100, metric = 12.64% * 100;
 Minibatch[1501-1600]: loss = 0.592816 * 100, metric = 13.30% * 100;
 Minibatch[1601-1700]: loss = 0.596251 * 100, metric = 12.93% * 100;
 Minibatch[1701-1800]: loss = 0.605211 * 100, metric = 13.22% * 100;
 Minibatch[1801-1900]: loss = 0.605898 * 100, metric = 13.31% * 100;
 Minibatch[1901-2000]: loss = 0.595386 * 100, metric = 13.09% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.598858 * 2000, metric = 13.17% * 2000 653.861s (  3.1 samples/s);
Finished Evaluation [10]: Minibatch[1-1000]: metric = 17.37% * 1000;
0.624242826089263
 Minibatch[   1- 100]: loss = 0.571871 * 100, metric = 12.27% * 100;
 Minibatch[ 101- 200]: loss = 0.594879 * 100, metric = 12.79% * 100;
 Minibatch[ 201- 300]: loss = 0.608421 * 100, metric = 13.51% * 100;
 Minibatch[ 301- 400]: loss = 0.605164 * 100, metric = 13.24% * 100;
 Minibatch[ 401- 500]: loss = 0.584996 * 100, metric = 12.82% * 100;
 Minibatch[ 501- 600]: loss = 0.607646 * 100, metric = 13.39% * 100;
 Minibatch[ 601- 700]: loss = 0.582478 * 100, metric = 12.51% * 100;
 Minibatch[ 701- 800]: loss = 0.599725 * 100, metric = 13.30% * 100;
 Minibatch[ 801- 900]: loss = 0.592256 * 100, metric = 12.82% * 100;
 Minibatch[ 901-1000]: loss = 0.599933 * 100, metric = 12.99% * 100;
 Minibatch[1001-1100]: loss = 0.591390 * 100, metric = 12.93% * 100;
 Minibatch[1101-1200]: loss = 0.600294 * 100, metric = 13.29% * 100;
 Minibatch[1201-1300]: loss = 0.581160 * 100, metric = 12.69% * 100;
 Minibatch[1301-1400]: loss = 0.569657 * 100, metric = 12.37% * 100;
 Minibatch[1401-1500]: loss = 0.605565 * 100, metric = 13.58% * 100;
 Minibatch[1501-1600]: loss = 0.585799 * 100, metric = 12.91% * 100;
 Minibatch[1601-1700]: loss = 0.584176 * 100, metric = 12.99% * 100;
 Minibatch[1701-1800]: loss = 0.601896 * 100, metric = 13.19% * 100;
 Minibatch[1801-1900]: loss = 0.590100 * 100, metric = 12.96% * 100;
 Minibatch[1901-2000]: loss = 0.578995 * 100, metric = 12.76% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.591820 * 2000, metric = 12.97% * 2000 647.668s (  3.1 samples/s);
Finished Evaluation [11]: Minibatch[1-1000]: metric = 19.05% * 1000;
 Minibatch[   1- 100]: loss = 0.573196 * 100, metric = 12.43% * 100;
 Minibatch[ 101- 200]: loss = 0.568974 * 100, metric = 11.99% * 100;
 Minibatch[ 201- 300]: loss = 0.578579 * 100, metric = 12.57% * 100;
 Minibatch[ 301- 400]: loss = 0.614569 * 100, metric = 13.71% * 100;
 Minibatch[ 401- 500]: loss = 0.584664 * 100, metric = 12.67% * 100;
 Minibatch[ 501- 600]: loss = 0.558849 * 100, metric = 11.92% * 100;
 Minibatch[ 601- 700]: loss = 0.569723 * 100, metric = 12.32% * 100;
 Minibatch[ 701- 800]: loss = 0.581180 * 100, metric = 12.50% * 100;
 Minibatch[ 801- 900]: loss = 0.570891 * 100, metric = 12.31% * 100;
 Minibatch[ 901-1000]: loss = 0.581482 * 100, metric = 12.69% * 100;
 Minibatch[1001-1100]: loss = 0.587408 * 100, metric = 13.00% * 100;
 Minibatch[1101-1200]: loss = 0.592354 * 100, metric = 12.71% * 100;
 Minibatch[1201-1300]: loss = 0.591924 * 100, metric = 12.84% * 100;
 Minibatch[1301-1400]: loss = 0.575101 * 100, metric = 12.49% * 100;
 Minibatch[1401-1500]: loss = 0.590159 * 100, metric = 13.08% * 100;
 Minibatch[1501-1600]: loss = 0.555505 * 100, metric = 12.03% * 100;
 Minibatch[1601-1700]: loss = 0.589436 * 100, metric = 12.93% * 100;
 Minibatch[1701-1800]: loss = 0.560355 * 100, metric = 11.82% * 100;
 Minibatch[1801-1900]: loss = 0.561179 * 100, metric = 12.13% * 100;
 Minibatch[1901-2000]: loss = 0.596510 * 100, metric = 13.18% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.579102 * 2000, metric = 12.57% * 2000 641.961s (  3.1 samples/s);
Finished Evaluation [12]: Minibatch[1-1000]: metric = 20.63% * 1000;
 Minibatch[   1- 100]: loss = 0.595086 * 100, metric = 13.02% * 100;
 Minibatch[ 101- 200]: loss = 0.578322 * 100, metric = 12.84% * 100;
 Minibatch[ 201- 300]: loss = 0.580219 * 100, metric = 12.66% * 100;
 Minibatch[ 301- 400]: loss = 0.586286 * 100, metric = 12.72% * 100;
 Minibatch[ 401- 500]: loss = 0.593977 * 100, metric = 13.14% * 100;
 Minibatch[ 501- 600]: loss = 0.599576 * 100, metric = 13.56% * 100;
 Minibatch[ 601- 700]: loss = 0.564406 * 100, metric = 11.94% * 100;
 Minibatch[ 701- 800]: loss = 0.563858 * 100, metric = 11.98% * 100;
 Minibatch[ 801- 900]: loss = 0.563402 * 100, metric = 12.16% * 100;
 Minibatch[ 901-1000]: loss = 0.587105 * 100, metric = 12.85% * 100;
 Minibatch[1001-1100]: loss = 0.579323 * 100, metric = 12.64% * 100;
 Minibatch[1101-1200]: loss = 0.575640 * 100, metric = 12.34% * 100;
 Minibatch[1201-1300]: loss = 0.578772 * 100, metric = 12.71% * 100;
 Minibatch[1301-1400]: loss = 0.576050 * 100, metric = 12.31% * 100;
 Minibatch[1401-1500]: loss = 0.563447 * 100, metric = 12.12% * 100;
 Minibatch[1501-1600]: loss = 0.565104 * 100, metric = 12.01% * 100;
 Minibatch[1601-1700]: loss = 0.554028 * 100, metric = 11.88% * 100;
 Minibatch[1701-1800]: loss = 0.569149 * 100, metric = 12.07% * 100;
 Minibatch[1801-1900]: loss = 0.562021 * 100, metric = 12.06% * 100;
 Minibatch[1901-2000]: loss = 0.581167 * 100, metric = 12.62% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.575847 * 2000, metric = 12.48% * 2000 637.711s (  3.1 samples/s);
Finished Evaluation [13]: Minibatch[1-1000]: metric = 18.78% * 1000;
 Minibatch[   1- 100]: loss = 0.567596 * 100, metric = 12.17% * 100;
 Minibatch[ 101- 200]: loss = 0.560466 * 100, metric = 12.12% * 100;
 Minibatch[ 201- 300]: loss = 0.584981 * 100, metric = 12.66% * 100;
 Minibatch[ 301- 400]: loss = 0.573379 * 100, metric = 12.70% * 100;
 Minibatch[ 401- 500]: loss = 0.572593 * 100, metric = 12.51% * 100;
 Minibatch[ 501- 600]: loss = 0.576665 * 100, metric = 12.56% * 100;
 Minibatch[ 601- 700]: loss = 0.572195 * 100, metric = 12.47% * 100;
 Minibatch[ 701- 800]: loss = 0.596604 * 100, metric = 13.13% * 100;
 Minibatch[ 801- 900]: loss = 0.599403 * 100, metric = 13.27% * 100;
 Minibatch[ 901-1000]: loss = 0.585495 * 100, metric = 12.77% * 100;
 Minibatch[1001-1100]: loss = 0.583644 * 100, metric = 12.65% * 100;
 Minibatch[1101-1200]: loss = 0.566062 * 100, metric = 12.11% * 100;
 Minibatch[1201-1300]: loss = 0.550275 * 100, metric = 11.73% * 100;
 Minibatch[1301-1400]: loss = 0.581882 * 100, metric = 12.77% * 100;
 Minibatch[1401-1500]: loss = 0.570651 * 100, metric = 12.66% * 100;
 Minibatch[1501-1600]: loss = 0.557131 * 100, metric = 12.14% * 100;
 Minibatch[1601-1700]: loss = 0.563583 * 100, metric = 11.86% * 100;
 Minibatch[1701-1800]: loss = 0.558747 * 100, metric = 11.93% * 100;
 Minibatch[1801-1900]: loss = 0.570269 * 100, metric = 12.30% * 100;
 Minibatch[1901-2000]: loss = 0.582128 * 100, metric = 12.40% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.573687 * 2000, metric = 12.44% * 2000 634.297s (  3.2 samples/s);
Finished Evaluation [14]: Minibatch[1-1000]: metric = 19.70% * 1000;
 Minibatch[   1- 100]: loss = 0.562867 * 100, metric = 11.99% * 100;
 Minibatch[ 101- 200]: loss = 0.576583 * 100, metric = 12.69% * 100;
 Minibatch[ 201- 300]: loss = 0.577741 * 100, metric = 12.40% * 100;
 Minibatch[ 301- 400]: loss = 0.550356 * 100, metric = 11.57% * 100;
 Minibatch[ 401- 500]: loss = 0.565735 * 100, metric = 12.31% * 100;
 Minibatch[ 501- 600]: loss = 0.544594 * 100, metric = 11.36% * 100;
 Minibatch[ 601- 700]: loss = 0.543857 * 100, metric = 11.56% * 100;
 Minibatch[ 701- 800]: loss = 0.583567 * 100, metric = 12.90% * 100;
 Minibatch[ 801- 900]: loss = 0.597398 * 100, metric = 13.16% * 100;
 Minibatch[ 901-1000]: loss = 0.568674 * 100, metric = 12.50% * 100;
 Minibatch[1001-1100]: loss = 0.571558 * 100, metric = 12.15% * 100;
 Minibatch[1101-1200]: loss = 0.567312 * 100, metric = 12.40% * 100;
 Minibatch[1201-1300]: loss = 0.547810 * 100, metric = 11.62% * 100;
 Minibatch[1301-1400]: loss = 0.585569 * 100, metric = 12.89% * 100;
 Minibatch[1401-1500]: loss = 0.537053 * 100, metric = 11.55% * 100;
 Minibatch[1501-1600]: loss = 0.565159 * 100, metric = 12.22% * 100;
 Minibatch[1601-1700]: loss = 0.566112 * 100, metric = 12.14% * 100;
 Minibatch[1701-1800]: loss = 0.543652 * 100, metric = 11.33% * 100;
 Minibatch[1801-1900]: loss = 0.557179 * 100, metric = 12.04% * 100;
 Minibatch[1901-2000]: loss = 0.547708 * 100, metric = 11.83% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.563024 * 2000, metric = 12.13% * 2000 629.481s (  3.2 samples/s);
Finished Evaluation [15]: Minibatch[1-1000]: metric = 17.33% * 1000;
0.6035886601805687
 Minibatch[   1- 100]: loss = 0.578412 * 100, metric = 12.89% * 100;
 Minibatch[ 101- 200]: loss = 0.573964 * 100, metric = 12.34% * 100;
 Minibatch[ 201- 300]: loss = 0.564274 * 100, metric = 12.08% * 100;
 Minibatch[ 301- 400]: loss = 0.578232 * 100, metric = 12.42% * 100;
 Minibatch[ 401- 500]: loss = 0.545618 * 100, metric = 11.68% * 100;
 Minibatch[ 501- 600]: loss = 0.559624 * 100, metric = 12.01% * 100;
 Minibatch[ 601- 700]: loss = 0.557024 * 100, metric = 11.96% * 100;
 Minibatch[ 701- 800]: loss = 0.543094 * 100, metric = 11.64% * 100;
 Minibatch[ 801- 900]: loss = 0.544733 * 100, metric = 11.55% * 100;
 Minibatch[ 901-1000]: loss = 0.567793 * 100, metric = 12.29% * 100;
 Minibatch[1001-1100]: loss = 0.544146 * 100, metric = 11.76% * 100;
 Minibatch[1101-1200]: loss = 0.548431 * 100, metric = 11.81% * 100;
 Minibatch[1201-1300]: loss = 0.540482 * 100, metric = 11.26% * 100;
 Minibatch[1301-1400]: loss = 0.553712 * 100, metric = 11.89% * 100;
 Minibatch[1401-1500]: loss = 0.551572 * 100, metric = 12.14% * 100;
 Minibatch[1501-1600]: loss = 0.556863 * 100, metric = 12.13% * 100;
 Minibatch[1601-1700]: loss = 0.559976 * 100, metric = 12.15% * 100;
 Minibatch[1701-1800]: loss = 0.582198 * 100, metric = 12.56% * 100;
 Minibatch[1801-1900]: loss = 0.567766 * 100, metric = 12.41% * 100;
 Minibatch[1901-2000]: loss = 0.544509 * 100, metric = 11.69% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.558121 * 2000, metric = 12.03% * 2000 638.320s (  3.1 samples/s);
Finished Evaluation [16]: Minibatch[1-1000]: metric = 17.11% * 1000;
0.6025835510343314
 Minibatch[   1- 100]: loss = 0.538654 * 100, metric = 11.64% * 100;
 Minibatch[ 101- 200]: loss = 0.564516 * 100, metric = 11.96% * 100;
 Minibatch[ 201- 300]: loss = 0.570323 * 100, metric = 12.26% * 100;
 Minibatch[ 301- 400]: loss = 0.558717 * 100, metric = 11.85% * 100;
 Minibatch[ 401- 500]: loss = 0.558016 * 100, metric = 11.98% * 100;
 Minibatch[ 501- 600]: loss = 0.545218 * 100, metric = 11.82% * 100;
 Minibatch[ 601- 700]: loss = 0.532841 * 100, metric = 11.06% * 100;
 Minibatch[ 701- 800]: loss = 0.554150 * 100, metric = 11.63% * 100;
 Minibatch[ 801- 900]: loss = 0.554756 * 100, metric = 11.54% * 100;
 Minibatch[ 901-1000]: loss = 0.539835 * 100, metric = 11.43% * 100;
 Minibatch[1001-1100]: loss = 0.541187 * 100, metric = 11.38% * 100;
 Minibatch[1101-1200]: loss = 0.562380 * 100, metric = 11.93% * 100;
 Minibatch[1201-1300]: loss = 0.556105 * 100, metric = 12.15% * 100;
 Minibatch[1301-1400]: loss = 0.527829 * 100, metric = 11.34% * 100;
 Minibatch[1401-1500]: loss = 0.550291 * 100, metric = 11.86% * 100;
 Minibatch[1501-1600]: loss = 0.546752 * 100, metric = 11.72% * 100;
 Minibatch[1601-1700]: loss = 0.556108 * 100, metric = 11.65% * 100;
 Minibatch[1701-1800]: loss = 0.530175 * 100, metric = 11.29% * 100;
 Minibatch[1801-1900]: loss = 0.567924 * 100, metric = 12.17% * 100;
 Minibatch[1901-2000]: loss = 0.570240 * 100, metric = 12.39% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.551301 * 2000, metric = 11.75% * 2000 636.467s (  3.1 samples/s);
Finished Evaluation [17]: Minibatch[1-1000]: metric = 17.52% * 1000;
 Minibatch[   1- 100]: loss = 0.535975 * 100, metric = 11.48% * 100;
 Minibatch[ 101- 200]: loss = 0.562072 * 100, metric = 12.02% * 100;
 Minibatch[ 201- 300]: loss = 0.534810 * 100, metric = 11.62% * 100;
 Minibatch[ 301- 400]: loss = 0.553511 * 100, metric = 11.90% * 100;
 Minibatch[ 401- 500]: loss = 0.519301 * 100, metric = 10.87% * 100;
 Minibatch[ 501- 600]: loss = 0.540076 * 100, metric = 11.34% * 100;
 Minibatch[ 601- 700]: loss = 0.552794 * 100, metric = 11.77% * 100;
 Minibatch[ 701- 800]: loss = 0.538469 * 100, metric = 11.45% * 100;
 Minibatch[ 801- 900]: loss = 0.558198 * 100, metric = 12.00% * 100;
 Minibatch[ 901-1000]: loss = 0.561218 * 100, metric = 12.15% * 100;
 Minibatch[1001-1100]: loss = 0.565521 * 100, metric = 12.29% * 100;
 Minibatch[1101-1200]: loss = 0.550370 * 100, metric = 11.66% * 100;
 Minibatch[1201-1300]: loss = 0.564316 * 100, metric = 12.19% * 100;
 Minibatch[1301-1400]: loss = 0.565236 * 100, metric = 12.05% * 100;
 Minibatch[1401-1500]: loss = 0.530943 * 100, metric = 11.17% * 100;
 Minibatch[1501-1600]: loss = 0.548220 * 100, metric = 11.49% * 100;
 Minibatch[1601-1700]: loss = 0.516157 * 100, metric = 10.65% * 100;
 Minibatch[1701-1800]: loss = 0.536440 * 100, metric = 11.42% * 100;
 Minibatch[1801-1900]: loss = 0.526441 * 100, metric = 11.34% * 100;
 Minibatch[1901-2000]: loss = 0.531830 * 100, metric = 11.09% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.544595 * 2000, metric = 11.60% * 2000 649.772s (  3.1 samples/s);
Finished Evaluation [18]: Minibatch[1-1000]: metric = 18.39% * 1000;
 Minibatch[   1- 100]: loss = 0.551112 * 100, metric = 12.13% * 100;
 Minibatch[ 101- 200]: loss = 0.566922 * 100, metric = 12.04% * 100;
 Minibatch[ 201- 300]: loss = 0.531036 * 100, metric = 11.12% * 100;
 Minibatch[ 301- 400]: loss = 0.554928 * 100, metric = 11.80% * 100;
 Minibatch[ 401- 500]: loss = 0.542779 * 100, metric = 11.45% * 100;
 Minibatch[ 501- 600]: loss = 0.526605 * 100, metric = 11.11% * 100;
 Minibatch[ 601- 700]: loss = 0.560850 * 100, metric = 12.14% * 100;
 Minibatch[ 701- 800]: loss = 0.521120 * 100, metric = 11.09% * 100;
 Minibatch[ 801- 900]: loss = 0.577729 * 100, metric = 12.37% * 100;
 Minibatch[ 901-1000]: loss = 0.533126 * 100, metric = 11.22% * 100;
 Minibatch[1001-1100]: loss = 0.554116 * 100, metric = 11.72% * 100;
 Minibatch[1101-1200]: loss = 0.543251 * 100, metric = 11.70% * 100;
 Minibatch[1201-1300]: loss = 0.541927 * 100, metric = 11.66% * 100;
 Minibatch[1301-1400]: loss = 0.543402 * 100, metric = 11.61% * 100;
 Minibatch[1401-1500]: loss = 0.549774 * 100, metric = 11.78% * 100;
 Minibatch[1501-1600]: loss = 0.551246 * 100, metric = 11.70% * 100;
 Minibatch[1601-1700]: loss = 0.534872 * 100, metric = 11.82% * 100;
 Minibatch[1701-1800]: loss = 0.527559 * 100, metric = 11.47% * 100;
 Minibatch[1801-1900]: loss = 0.537258 * 100, metric = 11.53% * 100;
 Minibatch[1901-2000]: loss = 0.526605 * 100, metric = 11.12% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.543811 * 2000, metric = 11.63% * 2000 641.955s (  3.1 samples/s);
Finished Evaluation [19]: Minibatch[1-1000]: metric = 18.41% * 1000;
 Minibatch[   1- 100]: loss = 0.528739 * 100, metric = 11.30% * 100;
 Minibatch[ 101- 200]: loss = 0.538110 * 100, metric = 11.46% * 100;
 Minibatch[ 201- 300]: loss = 0.530768 * 100, metric = 11.17% * 100;
 Minibatch[ 301- 400]: loss = 0.560904 * 100, metric = 11.87% * 100;
 Minibatch[ 401- 500]: loss = 0.535669 * 100, metric = 11.56% * 100;
 Minibatch[ 501- 600]: loss = 0.543827 * 100, metric = 11.70% * 100;
 Minibatch[ 601- 700]: loss = 0.549197 * 100, metric = 11.92% * 100;
 Minibatch[ 701- 800]: loss = 0.547693 * 100, metric = 11.48% * 100;
 Minibatch[ 801- 900]: loss = 0.565717 * 100, metric = 12.06% * 100;
 Minibatch[ 901-1000]: loss = 0.564032 * 100, metric = 12.11% * 100;
 Minibatch[1001-1100]: loss = 0.518123 * 100, metric = 10.96% * 100;
 Minibatch[1101-1200]: loss = 0.544935 * 100, metric = 11.63% * 100;
 Minibatch[1201-1300]: loss = 0.558947 * 100, metric = 12.01% * 100;
 Minibatch[1301-1400]: loss = 0.549343 * 100, metric = 11.91% * 100;
 Minibatch[1401-1500]: loss = 0.537593 * 100, metric = 11.69% * 100;
 Minibatch[1501-1600]: loss = 0.560708 * 100, metric = 11.88% * 100;
 Minibatch[1601-1700]: loss = 0.543820 * 100, metric = 11.67% * 100;
 Minibatch[1701-1800]: loss = 0.545702 * 100, metric = 12.10% * 100;
 Minibatch[1801-1900]: loss = 0.530743 * 100, metric = 11.16% * 100;
 Minibatch[1901-2000]: loss = 0.534545 * 100, metric = 11.27% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.544456 * 2000, metric = 11.65% * 2000 637.767s (  3.1 samples/s);
Finished Evaluation [20]: Minibatch[1-1000]: metric = 17.83% * 1000;
 Minibatch[   1- 100]: loss = 0.544811 * 100, metric = 11.56% * 100;
 Minibatch[ 101- 200]: loss = 0.545162 * 100, metric = 11.90% * 100;
 Minibatch[ 201- 300]: loss = 0.541608 * 100, metric = 11.64% * 100;
 Minibatch[ 301- 400]: loss = 0.550318 * 100, metric = 11.92% * 100;
 Minibatch[ 401- 500]: loss = 0.523161 * 100, metric = 11.17% * 100;
 Minibatch[ 501- 600]: loss = 0.528844 * 100, metric = 11.31% * 100;
 Minibatch[ 601- 700]: loss = 0.533827 * 100, metric = 11.26% * 100;
 Minibatch[ 701- 800]: loss = 0.499141 * 100, metric = 10.38% * 100;
 Minibatch[ 801- 900]: loss = 0.539153 * 100, metric = 11.17% * 100;
 Minibatch[ 901-1000]: loss = 0.525955 * 100, metric = 11.33% * 100;
 Minibatch[1001-1100]: loss = 0.536646 * 100, metric = 11.36% * 100;
 Minibatch[1101-1200]: loss = 0.522150 * 100, metric = 10.71% * 100;
 Minibatch[1201-1300]: loss = 0.531057 * 100, metric = 11.27% * 100;
 Minibatch[1301-1400]: loss = 0.519661 * 100, metric = 10.99% * 100;
 Minibatch[1401-1500]: loss = 0.546990 * 100, metric = 11.62% * 100;
 Minibatch[1501-1600]: loss = 0.556369 * 100, metric = 12.32% * 100;
 Minibatch[1601-1700]: loss = 0.541929 * 100, metric = 11.52% * 100;
 Minibatch[1701-1800]: loss = 0.523239 * 100, metric = 10.81% * 100;
 Minibatch[1801-1900]: loss = 0.555396 * 100, metric = 11.87% * 100;
 Minibatch[1901-2000]: loss = 0.519919 * 100, metric = 10.76% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.534267 * 2000, metric = 11.34% * 2000 644.830s (  3.1 samples/s);
Finished Evaluation [21]: Minibatch[1-1000]: metric = 16.49% * 1000;
0.5857998199760914
 Minibatch[   1- 100]: loss = 0.547528 * 100, metric = 11.78% * 100;
 Minibatch[ 101- 200]: loss = 0.534922 * 100, metric = 11.08% * 100;
 Minibatch[ 201- 300]: loss = 0.548072 * 100, metric = 11.72% * 100;
 Minibatch[ 301- 400]: loss = 0.532842 * 100, metric = 11.48% * 100;
 Minibatch[ 401- 500]: loss = 0.539741 * 100, metric = 11.56% * 100;
 Minibatch[ 501- 600]: loss = 0.538854 * 100, metric = 11.38% * 100;
 Minibatch[ 601- 700]: loss = 0.524975 * 100, metric = 11.10% * 100;
 Minibatch[ 701- 800]: loss = 0.531503 * 100, metric = 11.31% * 100;
 Minibatch[ 801- 900]: loss = 0.543761 * 100, metric = 11.77% * 100;
 Minibatch[ 901-1000]: loss = 0.548647 * 100, metric = 11.74% * 100;
 Minibatch[1001-1100]: loss = 0.515817 * 100, metric = 10.88% * 100;
 Minibatch[1101-1200]: loss = 0.510507 * 100, metric = 10.58% * 100;
 Minibatch[1201-1300]: loss = 0.520219 * 100, metric = 10.92% * 100;
 Minibatch[1301-1400]: loss = 0.530591 * 100, metric = 11.08% * 100;
 Minibatch[1401-1500]: loss = 0.523444 * 100, metric = 11.15% * 100;
 Minibatch[1501-1600]: loss = 0.523757 * 100, metric = 11.00% * 100;
 Minibatch[1601-1700]: loss = 0.524877 * 100, metric = 11.08% * 100;
 Minibatch[1701-1800]: loss = 0.529149 * 100, metric = 11.10% * 100;
 Minibatch[1801-1900]: loss = 0.517778 * 100, metric = 10.98% * 100;
 Minibatch[1901-2000]: loss = 0.531468 * 100, metric = 11.00% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.530922 * 2000, metric = 11.23% * 2000 621.537s (  3.2 samples/s);
Finished Evaluation [22]: Minibatch[1-1000]: metric = 17.29% * 1000;
 Minibatch[   1- 100]: loss = 0.540778 * 100, metric = 11.53% * 100;
 Minibatch[ 101- 200]: loss = 0.552185 * 100, metric = 12.01% * 100;
 Minibatch[ 201- 300]: loss = 0.525984 * 100, metric = 11.06% * 100;
 Minibatch[ 301- 400]: loss = 0.549402 * 100, metric = 11.77% * 100;
 Minibatch[ 401- 500]: loss = 0.547057 * 100, metric = 11.69% * 100;
 Minibatch[ 501- 600]: loss = 0.543892 * 100, metric = 11.55% * 100;
 Minibatch[ 601- 700]: loss = 0.540090 * 100, metric = 11.45% * 100;
 Minibatch[ 701- 800]: loss = 0.507125 * 100, metric = 10.43% * 100;
 Minibatch[ 801- 900]: loss = 0.515766 * 100, metric = 11.10% * 100;
 Minibatch[ 901-1000]: loss = 0.540512 * 100, metric = 11.62% * 100;
 Minibatch[1001-1100]: loss = 0.525661 * 100, metric = 11.02% * 100;
 Minibatch[1101-1200]: loss = 0.530554 * 100, metric = 11.18% * 100;
 Minibatch[1201-1300]: loss = 0.531655 * 100, metric = 11.15% * 100;
 Minibatch[1301-1400]: loss = 0.541085 * 100, metric = 11.44% * 100;
 Minibatch[1401-1500]: loss = 0.513738 * 100, metric = 10.76% * 100;
 Minibatch[1501-1600]: loss = 0.519520 * 100, metric = 10.96% * 100;
 Minibatch[1601-1700]: loss = 0.526959 * 100, metric = 11.12% * 100;
 Minibatch[1701-1800]: loss = 0.545180 * 100, metric = 11.63% * 100;
 Minibatch[1801-1900]: loss = 0.527621 * 100, metric = 11.17% * 100;
 Minibatch[1901-2000]: loss = 0.528517 * 100, metric = 11.27% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.532664 * 2000, metric = 11.29% * 2000 622.863s (  3.2 samples/s);
Finished Evaluation [23]: Minibatch[1-1000]: metric = 17.12% * 1000;
 Minibatch[   1- 100]: loss = 0.509886 * 100, metric = 10.89% * 100;
 Minibatch[ 101- 200]: loss = 0.535637 * 100, metric = 11.54% * 100;
 Minibatch[ 201- 300]: loss = 0.524337 * 100, metric = 10.97% * 100;
 Minibatch[ 301- 400]: loss = 0.524639 * 100, metric = 11.08% * 100;
 Minibatch[ 401- 500]: loss = 0.534044 * 100, metric = 11.26% * 100;
 Minibatch[ 501- 600]: loss = 0.509200 * 100, metric = 10.71% * 100;
 Minibatch[ 601- 700]: loss = 0.535940 * 100, metric = 11.28% * 100;
 Minibatch[ 701- 800]: loss = 0.520830 * 100, metric = 11.14% * 100;
 Minibatch[ 801- 900]: loss = 0.532438 * 100, metric = 11.37% * 100;
 Minibatch[ 901-1000]: loss = 0.532387 * 100, metric = 11.29% * 100;
 Minibatch[1001-1100]: loss = 0.532908 * 100, metric = 11.42% * 100;
 Minibatch[1101-1200]: loss = 0.551484 * 100, metric = 11.70% * 100;
 Minibatch[1201-1300]: loss = 0.543738 * 100, metric = 11.74% * 100;
 Minibatch[1301-1400]: loss = 0.516255 * 100, metric = 10.74% * 100;
 Minibatch[1401-1500]: loss = 0.516010 * 100, metric = 10.71% * 100;
 Minibatch[1501-1600]: loss = 0.533418 * 100, metric = 11.39% * 100;
 Minibatch[1601-1700]: loss = 0.511321 * 100, metric = 10.56% * 100;
 Minibatch[1701-1800]: loss = 0.512007 * 100, metric = 10.78% * 100;
 Minibatch[1801-1900]: loss = 0.532122 * 100, metric = 11.36% * 100;
 Minibatch[1901-2000]: loss = 0.532010 * 100, metric = 11.55% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.527031 * 2000, metric = 11.17% * 2000 619.163s (  3.2 samples/s);
Finished Evaluation [24]: Minibatch[1-1000]: metric = 16.23% * 1000;
0.5706853345781565
 Minibatch[   1- 100]: loss = 0.530361 * 100, metric = 11.22% * 100;
 Minibatch[ 101- 200]: loss = 0.531325 * 100, metric = 11.27% * 100;
 Minibatch[ 201- 300]: loss = 0.527052 * 100, metric = 11.32% * 100;
 Minibatch[ 301- 400]: loss = 0.536345 * 100, metric = 11.63% * 100;
 Minibatch[ 401- 500]: loss = 0.532457 * 100, metric = 11.37% * 100;
 Minibatch[ 501- 600]: loss = 0.527527 * 100, metric = 11.16% * 100;
 Minibatch[ 601- 700]: loss = 0.525208 * 100, metric = 11.03% * 100;
 Minibatch[ 701- 800]: loss = 0.516167 * 100, metric = 10.64% * 100;
 Minibatch[ 801- 900]: loss = 0.515609 * 100, metric = 10.77% * 100;
 Minibatch[ 901-1000]: loss = 0.527703 * 100, metric = 11.43% * 100;
 Minibatch[1001-1100]: loss = 0.533485 * 100, metric = 11.53% * 100;
 Minibatch[1101-1200]: loss = 0.540544 * 100, metric = 11.58% * 100;
 Minibatch[1201-1300]: loss = 0.551993 * 100, metric = 11.69% * 100;
 Minibatch[1301-1400]: loss = 0.517211 * 100, metric = 10.78% * 100;
 Minibatch[1401-1500]: loss = 0.515504 * 100, metric = 10.82% * 100;
 Minibatch[1501-1600]: loss = 0.541819 * 100, metric = 11.49% * 100;
 Minibatch[1601-1700]: loss = 0.521019 * 100, metric = 10.93% * 100;
 Minibatch[1701-1800]: loss = 0.536915 * 100, metric = 11.41% * 100;
 Minibatch[1801-1900]: loss = 0.515756 * 100, metric = 10.91% * 100;
 Minibatch[1901-2000]: loss = 0.506511 * 100, metric = 10.67% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.527526 * 2000, metric = 11.18% * 2000 623.994s (  3.2 samples/s);
Finished Evaluation [25]: Minibatch[1-1000]: metric = 16.98% * 1000;
 Minibatch[   1- 100]: loss = 0.528113 * 100, metric = 11.25% * 100;
 Minibatch[ 101- 200]: loss = 0.502820 * 100, metric = 10.58% * 100;
 Minibatch[ 201- 300]: loss = 0.527107 * 100, metric = 11.29% * 100;
 Minibatch[ 301- 400]: loss = 0.514811 * 100, metric = 10.72% * 100;
 Minibatch[ 401- 500]: loss = 0.526265 * 100, metric = 11.07% * 100;
 Minibatch[ 501- 600]: loss = 0.523456 * 100, metric = 10.88% * 100;
 Minibatch[ 601- 700]: loss = 0.539451 * 100, metric = 11.38% * 100;
 Minibatch[ 701- 800]: loss = 0.519155 * 100, metric = 11.34% * 100;
 Minibatch[ 801- 900]: loss = 0.513655 * 100, metric = 10.69% * 100;
 Minibatch[ 901-1000]: loss = 0.508848 * 100, metric = 10.75% * 100;
 Minibatch[1001-1100]: loss = 0.535117 * 100, metric = 11.56% * 100;
 Minibatch[1101-1200]: loss = 0.546113 * 100, metric = 11.60% * 100;
 Minibatch[1201-1300]: loss = 0.520010 * 100, metric = 11.05% * 100;
 Minibatch[1301-1400]: loss = 0.509729 * 100, metric = 10.51% * 100;
 Minibatch[1401-1500]: loss = 0.524256 * 100, metric = 11.10% * 100;
 Minibatch[1501-1600]: loss = 0.513238 * 100, metric = 10.77% * 100;
 Minibatch[1601-1700]: loss = 0.544113 * 100, metric = 11.43% * 100;
 Minibatch[1701-1800]: loss = 0.532210 * 100, metric = 11.27% * 100;
 Minibatch[1801-1900]: loss = 0.527221 * 100, metric = 11.15% * 100;
 Minibatch[1901-2000]: loss = 0.523685 * 100, metric = 11.22% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.523969 * 2000, metric = 11.08% * 2000 616.200s (  3.2 samples/s);
Finished Evaluation [26]: Minibatch[1-1000]: metric = 16.76% * 1000;
 Minibatch[   1- 100]: loss = 0.520939 * 100, metric = 10.81% * 100;
 Minibatch[ 101- 200]: loss = 0.533961 * 100, metric = 11.07% * 100;
 Minibatch[ 201- 300]: loss = 0.517682 * 100, metric = 10.98% * 100;
 Minibatch[ 301- 400]: loss = 0.507157 * 100, metric = 10.77% * 100;
 Minibatch[ 401- 500]: loss = 0.516826 * 100, metric = 10.81% * 100;
 Minibatch[ 501- 600]: loss = 0.510520 * 100, metric = 10.69% * 100;
 Minibatch[ 601- 700]: loss = 0.508642 * 100, metric = 10.76% * 100;
 Minibatch[ 701- 800]: loss = 0.522385 * 100, metric = 11.07% * 100;
 Minibatch[ 801- 900]: loss = 0.533036 * 100, metric = 11.24% * 100;
 Minibatch[ 901-1000]: loss = 0.529641 * 100, metric = 11.43% * 100;
 Minibatch[1001-1100]: loss = 0.514020 * 100, metric = 10.81% * 100;
 Minibatch[1101-1200]: loss = 0.532133 * 100, metric = 11.28% * 100;
 Minibatch[1201-1300]: loss = 0.523291 * 100, metric = 11.24% * 100;
 Minibatch[1301-1400]: loss = 0.529203 * 100, metric = 11.21% * 100;
 Minibatch[1401-1500]: loss = 0.507244 * 100, metric = 10.85% * 100;
 Minibatch[1501-1600]: loss = 0.519978 * 100, metric = 10.81% * 100;
 Minibatch[1601-1700]: loss = 0.492131 * 100, metric = 10.04% * 100;
 Minibatch[1701-1800]: loss = 0.511288 * 100, metric = 10.44% * 100;
 Minibatch[1801-1900]: loss = 0.509451 * 100, metric = 10.51% * 100;
 Minibatch[1901-2000]: loss = 0.521694 * 100, metric = 10.98% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.518061 * 2000, metric = 10.89% * 2000 616.727s (  3.2 samples/s);
Finished Evaluation [27]: Minibatch[1-1000]: metric = 16.32% * 1000;
 Minibatch[   1- 100]: loss = 0.517512 * 100, metric = 10.98% * 100;
 Minibatch[ 101- 200]: loss = 0.504927 * 100, metric = 10.56% * 100;
 Minibatch[ 201- 300]: loss = 0.516866 * 100, metric = 11.03% * 100;
 Minibatch[ 301- 400]: loss = 0.523323 * 100, metric = 11.03% * 100;
 Minibatch[ 401- 500]: loss = 0.516764 * 100, metric = 11.04% * 100;
 Minibatch[ 501- 600]: loss = 0.542360 * 100, metric = 11.76% * 100;
 Minibatch[ 601- 700]: loss = 0.509785 * 100, metric = 10.69% * 100;
 Minibatch[ 701- 800]: loss = 0.507122 * 100, metric = 10.70% * 100;
 Minibatch[ 801- 900]: loss = 0.527463 * 100, metric = 11.34% * 100;
 Minibatch[ 901-1000]: loss = 0.530813 * 100, metric = 11.31% * 100;
 Minibatch[1001-1100]: loss = 0.512100 * 100, metric = 10.79% * 100;
 Minibatch[1101-1200]: loss = 0.508173 * 100, metric = 10.63% * 100;
 Minibatch[1201-1300]: loss = 0.527359 * 100, metric = 11.13% * 100;
 Minibatch[1301-1400]: loss = 0.510673 * 100, metric = 10.83% * 100;
 Minibatch[1401-1500]: loss = 0.530468 * 100, metric = 11.06% * 100;
 Minibatch[1501-1600]: loss = 0.521234 * 100, metric = 10.95% * 100;
 Minibatch[1601-1700]: loss = 0.519974 * 100, metric = 10.82% * 100;
 Minibatch[1701-1800]: loss = 0.509125 * 100, metric = 10.51% * 100;
 Minibatch[1801-1900]: loss = 0.522661 * 100, metric = 11.23% * 100;
 Minibatch[1901-2000]: loss = 0.523627 * 100, metric = 10.94% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.519116 * 2000, metric = 10.97% * 2000 618.344s (  3.2 samples/s);
Finished Evaluation [28]: Minibatch[1-1000]: metric = 14.85% * 1000;
0.5473031989112497
 Minibatch[   1- 100]: loss = 0.509509 * 100, metric = 10.70% * 100;
 Minibatch[ 101- 200]: loss = 0.510755 * 100, metric = 10.92% * 100;
 Minibatch[ 201- 300]: loss = 0.525449 * 100, metric = 11.24% * 100;
 Minibatch[ 301- 400]: loss = 0.547828 * 100, metric = 11.78% * 100;
 Minibatch[ 401- 500]: loss = 0.505968 * 100, metric = 10.53% * 100;
 Minibatch[ 501- 600]: loss = 0.513509 * 100, metric = 10.76% * 100;
 Minibatch[ 601- 700]: loss = 0.507172 * 100, metric = 11.01% * 100;
 Minibatch[ 701- 800]: loss = 0.522015 * 100, metric = 11.17% * 100;
 Minibatch[ 801- 900]: loss = 0.517390 * 100, metric = 11.08% * 100;
 Minibatch[ 901-1000]: loss = 0.523515 * 100, metric = 11.24% * 100;
 Minibatch[1001-1100]: loss = 0.523774 * 100, metric = 11.18% * 100;
 Minibatch[1101-1200]: loss = 0.510807 * 100, metric = 10.82% * 100;
 Minibatch[1201-1300]: loss = 0.521193 * 100, metric = 11.02% * 100;
 Minibatch[1301-1400]: loss = 0.496910 * 100, metric = 10.57% * 100;
 Minibatch[1401-1500]: loss = 0.526624 * 100, metric = 10.98% * 100;
 Minibatch[1501-1600]: loss = 0.495433 * 100, metric = 10.48% * 100;
 Minibatch[1601-1700]: loss = 0.527931 * 100, metric = 11.21% * 100;
 Minibatch[1701-1800]: loss = 0.493879 * 100, metric = 10.28% * 100;
 Minibatch[1801-1900]: loss = 0.525667 * 100, metric = 11.32% * 100;
 Minibatch[1901-2000]: loss = 0.512023 * 100, metric = 11.06% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.515867 * 2000, metric = 10.97% * 2000 614.887s (  3.3 samples/s);
Finished Evaluation [29]: Minibatch[1-1000]: metric = 17.67% * 1000;
 Minibatch[   1- 100]: loss = 0.534147 * 100, metric = 11.39% * 100;
 Minibatch[ 101- 200]: loss = 0.488986 * 100, metric = 10.30% * 100;
 Minibatch[ 201- 300]: loss = 0.498413 * 100, metric = 10.41% * 100;
 Minibatch[ 301- 400]: loss = 0.520583 * 100, metric = 11.16% * 100;
 Minibatch[ 401- 500]: loss = 0.514453 * 100, metric = 10.69% * 100;
 Minibatch[ 501- 600]: loss = 0.482248 * 100, metric = 9.78% * 100;
 Minibatch[ 601- 700]: loss = 0.515206 * 100, metric = 10.97% * 100;
 Minibatch[ 701- 800]: loss = 0.507293 * 100, metric = 10.56% * 100;
 Minibatch[ 801- 900]: loss = 0.520590 * 100, metric = 10.80% * 100;
 Minibatch[ 901-1000]: loss = 0.482977 * 100, metric = 10.01% * 100;
 Minibatch[1001-1100]: loss = 0.514013 * 100, metric = 10.63% * 100;
 Minibatch[1101-1200]: loss = 0.522521 * 100, metric = 11.08% * 100;
 Minibatch[1201-1300]: loss = 0.498525 * 100, metric = 10.16% * 100;
 Minibatch[1301-1400]: loss = 0.504117 * 100, metric = 10.49% * 100;
 Minibatch[1401-1500]: loss = 0.517076 * 100, metric = 11.06% * 100;
 Minibatch[1501-1600]: loss = 0.519302 * 100, metric = 11.00% * 100;
 Minibatch[1601-1700]: loss = 0.515198 * 100, metric = 10.71% * 100;
 Minibatch[1701-1800]: loss = 0.515786 * 100, metric = 10.86% * 100;
 Minibatch[1801-1900]: loss = 0.508018 * 100, metric = 10.79% * 100;
 Minibatch[1901-2000]: loss = 0.533705 * 100, metric = 11.22% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.510658 * 2000, metric = 10.70% * 2000 622.026s (  3.2 samples/s);
Finished Evaluation [30]: Minibatch[1-1000]: metric = 16.29% * 1000;
 Minibatch[   1- 100]: loss = 0.504205 * 100, metric = 10.48% * 100;
 Minibatch[ 101- 200]: loss = 0.524853 * 100, metric = 11.19% * 100;
 Minibatch[ 201- 300]: loss = 0.513745 * 100, metric = 10.71% * 100;
 Minibatch[ 301- 400]: loss = 0.507890 * 100, metric = 10.74% * 100;
 Minibatch[ 401- 500]: loss = 0.509766 * 100, metric = 10.78% * 100;
 Minibatch[ 501- 600]: loss = 0.499592 * 100, metric = 10.51% * 100;
 Minibatch[ 601- 700]: loss = 0.524973 * 100, metric = 11.21% * 100;
 Minibatch[ 701- 800]: loss = 0.521555 * 100, metric = 10.94% * 100;
 Minibatch[ 801- 900]: loss = 0.513901 * 100, metric = 10.73% * 100;
 Minibatch[ 901-1000]: loss = 0.501595 * 100, metric = 10.37% * 100;
 Minibatch[1001-1100]: loss = 0.500522 * 100, metric = 10.56% * 100;
 Minibatch[1101-1200]: loss = 0.510308 * 100, metric = 10.87% * 100;
 Minibatch[1201-1300]: loss = 0.514284 * 100, metric = 10.88% * 100;
 Minibatch[1301-1400]: loss = 0.516857 * 100, metric = 11.05% * 100;
 Minibatch[1401-1500]: loss = 0.515272 * 100, metric = 10.58% * 100;
 Minibatch[1501-1600]: loss = 0.493602 * 100, metric = 10.65% * 100;
 Minibatch[1601-1700]: loss = 0.512149 * 100, metric = 11.11% * 100;
 Minibatch[1701-1800]: loss = 0.501540 * 100, metric = 10.69% * 100;
 Minibatch[1801-1900]: loss = 0.511463 * 100, metric = 10.96% * 100;
 Minibatch[1901-2000]: loss = 0.521054 * 100, metric = 11.01% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.510956 * 2000, metric = 10.80% * 2000 628.804s (  3.2 samples/s);
Finished Evaluation [31]: Minibatch[1-1000]: metric = 16.40% * 1000;
 Minibatch[   1- 100]: loss = 0.504633 * 100, metric = 10.69% * 100;
 Minibatch[ 101- 200]: loss = 0.507520 * 100, metric = 10.53% * 100;
 Minibatch[ 201- 300]: loss = 0.520670 * 100, metric = 11.10% * 100;
 Minibatch[ 301- 400]: loss = 0.532579 * 100, metric = 11.10% * 100;
 Minibatch[ 401- 500]: loss = 0.526141 * 100, metric = 11.25% * 100;
 Minibatch[ 501- 600]: loss = 0.515291 * 100, metric = 10.95% * 100;
 Minibatch[ 601- 700]: loss = 0.503290 * 100, metric = 10.39% * 100;
 Minibatch[ 701- 800]: loss = 0.502538 * 100, metric = 10.48% * 100;
 Minibatch[ 801- 900]: loss = 0.503250 * 100, metric = 10.51% * 100;
 Minibatch[ 901-1000]: loss = 0.490383 * 100, metric = 10.22% * 100;
 Minibatch[1001-1100]: loss = 0.502355 * 100, metric = 10.69% * 100;
 Minibatch[1101-1200]: loss = 0.503500 * 100, metric = 10.59% * 100;
 Minibatch[1201-1300]: loss = 0.523401 * 100, metric = 11.08% * 100;
 Minibatch[1301-1400]: loss = 0.511718 * 100, metric = 10.85% * 100;
 Minibatch[1401-1500]: loss = 0.510359 * 100, metric = 11.03% * 100;
 Minibatch[1501-1600]: loss = 0.513305 * 100, metric = 10.68% * 100;
 Minibatch[1601-1700]: loss = 0.499315 * 100, metric = 10.38% * 100;
 Minibatch[1701-1800]: loss = 0.520033 * 100, metric = 10.93% * 100;
 Minibatch[1801-1900]: loss = 0.496022 * 100, metric = 10.37% * 100;
 Minibatch[1901-2000]: loss = 0.516155 * 100, metric = 11.03% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.510123 * 2000, metric = 10.74% * 2000 624.541s (  3.2 samples/s);
Finished Evaluation [32]: Minibatch[1-1000]: metric = 15.45% * 1000;
 Minibatch[   1- 100]: loss = 0.537664 * 100, metric = 11.42% * 100;
 Minibatch[ 101- 200]: loss = 0.501923 * 100, metric = 10.43% * 100;
 Minibatch[ 201- 300]: loss = 0.495302 * 100, metric = 10.45% * 100;
 Minibatch[ 301- 400]: loss = 0.507274 * 100, metric = 10.75% * 100;
 Minibatch[ 401- 500]: loss = 0.502710 * 100, metric = 10.36% * 100;
 Minibatch[ 501- 600]: loss = 0.511526 * 100, metric = 10.83% * 100;
 Minibatch[ 601- 700]: loss = 0.508330 * 100, metric = 10.84% * 100;
 Minibatch[ 701- 800]: loss = 0.505160 * 100, metric = 10.64% * 100;
 Minibatch[ 801- 900]: loss = 0.503973 * 100, metric = 10.42% * 100;
 Minibatch[ 901-1000]: loss = 0.493058 * 100, metric = 10.39% * 100;
 Minibatch[1001-1100]: loss = 0.503361 * 100, metric = 10.76% * 100;
 Minibatch[1101-1200]: loss = 0.488001 * 100, metric = 10.17% * 100;
 Minibatch[1201-1300]: loss = 0.512923 * 100, metric = 10.51% * 100;
 Minibatch[1301-1400]: loss = 0.492378 * 100, metric = 9.93% * 100;
 Minibatch[1401-1500]: loss = 0.521296 * 100, metric = 10.90% * 100;
 Minibatch[1501-1600]: loss = 0.513901 * 100, metric = 10.85% * 100;
 Minibatch[1601-1700]: loss = 0.493779 * 100, metric = 10.13% * 100;
 Minibatch[1701-1800]: loss = 0.502245 * 100, metric = 10.45% * 100;
 Minibatch[1801-1900]: loss = 0.498606 * 100, metric = 10.32% * 100;
 Minibatch[1901-2000]: loss = 0.521519 * 100, metric = 11.15% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.505747 * 2000, metric = 10.58% * 2000 627.254s (  3.2 samples/s);
Finished Evaluation [33]: Minibatch[1-1000]: metric = 15.18% * 1000;
 Minibatch[   1- 100]: loss = 0.501238 * 100, metric = 10.38% * 100;
 Minibatch[ 101- 200]: loss = 0.507405 * 100, metric = 10.69% * 100;
 Minibatch[ 201- 300]: loss = 0.491000 * 100, metric = 10.39% * 100;
 Minibatch[ 301- 400]: loss = 0.510845 * 100, metric = 10.66% * 100;
 Minibatch[ 401- 500]: loss = 0.490139 * 100, metric = 9.98% * 100;
 Minibatch[ 501- 600]: loss = 0.505923 * 100, metric = 10.47% * 100;
 Minibatch[ 601- 700]: loss = 0.511744 * 100, metric = 10.65% * 100;
 Minibatch[ 701- 800]: loss = 0.505108 * 100, metric = 10.61% * 100;
 Minibatch[ 801- 900]: loss = 0.490995 * 100, metric = 9.98% * 100;
 Minibatch[ 901-1000]: loss = 0.492730 * 100, metric = 10.14% * 100;
 Minibatch[1001-1100]: loss = 0.507433 * 100, metric = 10.65% * 100;
 Minibatch[1101-1200]: loss = 0.501428 * 100, metric = 10.54% * 100;
 Minibatch[1201-1300]: loss = 0.508134 * 100, metric = 10.61% * 100;
 Minibatch[1301-1400]: loss = 0.501022 * 100, metric = 10.64% * 100;
 Minibatch[1401-1500]: loss = 0.516265 * 100, metric = 10.97% * 100;
 Minibatch[1501-1600]: loss = 0.512934 * 100, metric = 10.62% * 100;
 Minibatch[1601-1700]: loss = 0.527983 * 100, metric = 11.11% * 100;
 Minibatch[1701-1800]: loss = 0.505226 * 100, metric = 10.56% * 100;
 Minibatch[1801-1900]: loss = 0.496144 * 100, metric = 10.42% * 100;
 Minibatch[1901-2000]: loss = 0.502369 * 100, metric = 10.47% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.504303 * 2000, metric = 10.53% * 2000 623.993s (  3.2 samples/s);
Finished Evaluation [34]: Minibatch[1-1000]: metric = 15.63% * 1000;
 Minibatch[   1- 100]: loss = 0.484542 * 100, metric = 9.96% * 100;
 Minibatch[ 101- 200]: loss = 0.506445 * 100, metric = 10.87% * 100;
 Minibatch[ 201- 300]: loss = 0.512441 * 100, metric = 10.77% * 100;
 Minibatch[ 301- 400]: loss = 0.480129 * 100, metric = 10.01% * 100;
 Minibatch[ 401- 500]: loss = 0.503622 * 100, metric = 10.46% * 100;
 Minibatch[ 501- 600]: loss = 0.470300 * 100, metric = 9.67% * 100;
 Minibatch[ 601- 700]: loss = 0.508680 * 100, metric = 10.71% * 100;
 Minibatch[ 701- 800]: loss = 0.470804 * 100, metric = 9.55% * 100;
 Minibatch[ 801- 900]: loss = 0.515091 * 100, metric = 10.82% * 100;
 Minibatch[ 901-1000]: loss = 0.486796 * 100, metric = 10.07% * 100;
 Minibatch[1001-1100]: loss = 0.516259 * 100, metric = 10.87% * 100;
 Minibatch[1101-1200]: loss = 0.490746 * 100, metric = 10.37% * 100;
 Minibatch[1201-1300]: loss = 0.505757 * 100, metric = 10.62% * 100;
 Minibatch[1301-1400]: loss = 0.506094 * 100, metric = 10.91% * 100;
 Minibatch[1401-1500]: loss = 0.488167 * 100, metric = 9.83% * 100;
 Minibatch[1501-1600]: loss = 0.497838 * 100, metric = 10.54% * 100;
 Minibatch[1601-1700]: loss = 0.495969 * 100, metric = 10.43% * 100;
 Minibatch[1701-1800]: loss = 0.494806 * 100, metric = 10.24% * 100;
 Minibatch[1801-1900]: loss = 0.517361 * 100, metric = 10.78% * 100;
 Minibatch[1901-2000]: loss = 0.495693 * 100, metric = 10.19% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.497377 * 2000, metric = 10.38% * 2000 620.906s (  3.2 samples/s);
Finished Evaluation [35]: Minibatch[1-1000]: metric = 15.40% * 1000;
 Minibatch[   1- 100]: loss = 0.485371 * 100, metric = 9.95% * 100;
 Minibatch[ 101- 200]: loss = 0.476007 * 100, metric = 9.89% * 100;
 Minibatch[ 201- 300]: loss = 0.516439 * 100, metric = 10.88% * 100;
 Minibatch[ 301- 400]: loss = 0.492188 * 100, metric = 9.88% * 100;
 Minibatch[ 401- 500]: loss = 0.499161 * 100, metric = 10.19% * 100;
 Minibatch[ 501- 600]: loss = 0.491903 * 100, metric = 9.97% * 100;
 Minibatch[ 601- 700]: loss = 0.500255 * 100, metric = 10.23% * 100;
 Minibatch[ 701- 800]: loss = 0.472903 * 100, metric = 9.76% * 100;
 Minibatch[ 801- 900]: loss = 0.485018 * 100, metric = 10.28% * 100;
 Minibatch[ 901-1000]: loss = 0.506291 * 100, metric = 10.56% * 100;
 Minibatch[1001-1100]: loss = 0.520242 * 100, metric = 10.89% * 100;
 Minibatch[1101-1200]: loss = 0.497062 * 100, metric = 10.38% * 100;
 Minibatch[1201-1300]: loss = 0.495498 * 100, metric = 10.43% * 100;
 Minibatch[1301-1400]: loss = 0.474568 * 100, metric = 9.74% * 100;
 Minibatch[1401-1500]: loss = 0.487365 * 100, metric = 9.85% * 100;
 Minibatch[1501-1600]: loss = 0.499578 * 100, metric = 10.70% * 100;
 Minibatch[1601-1700]: loss = 0.511107 * 100, metric = 11.05% * 100;
 Minibatch[1701-1800]: loss = 0.502205 * 100, metric = 10.59% * 100;
 Minibatch[1801-1900]: loss = 0.502492 * 100, metric = 10.42% * 100;
 Minibatch[1901-2000]: loss = 0.494419 * 100, metric = 10.22% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.495504 * 2000, metric = 10.29% * 2000 619.259s (  3.2 samples/s);
Finished Evaluation [36]: Minibatch[1-1000]: metric = 14.81% * 1000;
0.5297251003831625
 Minibatch[   1- 100]: loss = 0.498548 * 100, metric = 10.50% * 100;
 Minibatch[ 101- 200]: loss = 0.506407 * 100, metric = 10.60% * 100;
 Minibatch[ 201- 300]: loss = 0.496863 * 100, metric = 10.35% * 100;
 Minibatch[ 301- 400]: loss = 0.499083 * 100, metric = 10.51% * 100;
 Minibatch[ 401- 500]: loss = 0.504436 * 100, metric = 10.57% * 100;
 Minibatch[ 501- 600]: loss = 0.480403 * 100, metric = 9.91% * 100;
 Minibatch[ 601- 700]: loss = 0.493642 * 100, metric = 10.04% * 100;
 Minibatch[ 701- 800]: loss = 0.511082 * 100, metric = 10.86% * 100;
 Minibatch[ 801- 900]: loss = 0.505793 * 100, metric = 10.44% * 100;
 Minibatch[ 901-1000]: loss = 0.485999 * 100, metric = 9.84% * 100;
 Minibatch[1001-1100]: loss = 0.491526 * 100, metric = 10.38% * 100;
 Minibatch[1101-1200]: loss = 0.520074 * 100, metric = 10.81% * 100;
 Minibatch[1201-1300]: loss = 0.514641 * 100, metric = 10.67% * 100;
 Minibatch[1301-1400]: loss = 0.492468 * 100, metric = 10.07% * 100;
 Minibatch[1401-1500]: loss = 0.505205 * 100, metric = 10.63% * 100;
 Minibatch[1501-1600]: loss = 0.484461 * 100, metric = 9.91% * 100;
 Minibatch[1601-1700]: loss = 0.494637 * 100, metric = 10.24% * 100;
 Minibatch[1701-1800]: loss = 0.502065 * 100, metric = 10.47% * 100;
 Minibatch[1801-1900]: loss = 0.509091 * 100, metric = 11.01% * 100;
 Minibatch[1901-2000]: loss = 0.492921 * 100, metric = 10.17% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.499467 * 2000, metric = 10.40% * 2000 619.912s (  3.2 samples/s);
Finished Evaluation [37]: Minibatch[1-1000]: metric = 16.47% * 1000;
 Minibatch[   1- 100]: loss = 0.493638 * 100, metric = 10.48% * 100;
 Minibatch[ 101- 200]: loss = 0.506330 * 100, metric = 10.79% * 100;
 Minibatch[ 201- 300]: loss = 0.478796 * 100, metric = 9.67% * 100;
 Minibatch[ 301- 400]: loss = 0.490136 * 100, metric = 10.23% * 100;
 Minibatch[ 401- 500]: loss = 0.495013 * 100, metric = 10.19% * 100;
 Minibatch[ 501- 600]: loss = 0.489186 * 100, metric = 10.06% * 100;
 Minibatch[ 601- 700]: loss = 0.498221 * 100, metric = 10.40% * 100;
 Minibatch[ 701- 800]: loss = 0.491224 * 100, metric = 10.10% * 100;
 Minibatch[ 801- 900]: loss = 0.491024 * 100, metric = 10.11% * 100;
 Minibatch[ 901-1000]: loss = 0.494607 * 100, metric = 10.15% * 100;
 Minibatch[1001-1100]: loss = 0.498912 * 100, metric = 10.40% * 100;
 Minibatch[1101-1200]: loss = 0.479077 * 100, metric = 9.84% * 100;
 Minibatch[1201-1300]: loss = 0.495826 * 100, metric = 10.40% * 100;
 Minibatch[1301-1400]: loss = 0.499719 * 100, metric = 10.39% * 100;
 Minibatch[1401-1500]: loss = 0.501443 * 100, metric = 10.55% * 100;
 Minibatch[1501-1600]: loss = 0.500562 * 100, metric = 10.60% * 100;
 Minibatch[1601-1700]: loss = 0.476951 * 100, metric = 9.83% * 100;
 Minibatch[1701-1800]: loss = 0.492712 * 100, metric = 10.37% * 100;
 Minibatch[1801-1900]: loss = 0.487877 * 100, metric = 10.05% * 100;
 Minibatch[1901-2000]: loss = 0.498506 * 100, metric = 10.19% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.492988 * 2000, metric = 10.24% * 2000 617.806s (  3.2 samples/s);
Finished Evaluation [38]: Minibatch[1-1000]: metric = 14.87% * 1000;
 Minibatch[   1- 100]: loss = 0.494104 * 100, metric = 10.26% * 100;
 Minibatch[ 101- 200]: loss = 0.500953 * 100, metric = 10.34% * 100;
 Minibatch[ 201- 300]: loss = 0.492508 * 100, metric = 10.23% * 100;
 Minibatch[ 301- 400]: loss = 0.489021 * 100, metric = 10.33% * 100;
 Minibatch[ 401- 500]: loss = 0.486899 * 100, metric = 10.20% * 100;
 Minibatch[ 501- 600]: loss = 0.504066 * 100, metric = 10.56% * 100;
 Minibatch[ 601- 700]: loss = 0.497144 * 100, metric = 10.59% * 100;
 Minibatch[ 701- 800]: loss = 0.494834 * 100, metric = 10.53% * 100;
 Minibatch[ 801- 900]: loss = 0.464698 * 100, metric = 9.70% * 100;
 Minibatch[ 901-1000]: loss = 0.484927 * 100, metric = 10.04% * 100;
 Minibatch[1001-1100]: loss = 0.505668 * 100, metric = 10.68% * 100;
 Minibatch[1101-1200]: loss = 0.491636 * 100, metric = 10.32% * 100;
 Minibatch[1201-1300]: loss = 0.493068 * 100, metric = 10.01% * 100;
 Minibatch[1301-1400]: loss = 0.512640 * 100, metric = 10.61% * 100;
 Minibatch[1401-1500]: loss = 0.507830 * 100, metric = 10.75% * 100;
 Minibatch[1501-1600]: loss = 0.490458 * 100, metric = 10.22% * 100;
 Minibatch[1601-1700]: loss = 0.489925 * 100, metric = 10.22% * 100;
 Minibatch[1701-1800]: loss = 0.502576 * 100, metric = 10.57% * 100;
 Minibatch[1801-1900]: loss = 0.488719 * 100, metric = 9.97% * 100;
 Minibatch[1901-2000]: loss = 0.496425 * 100, metric = 10.00% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.494405 * 2000, metric = 10.31% * 2000 620.266s (  3.2 samples/s);
Finished Evaluation [39]: Minibatch[1-1000]: metric = 14.91% * 1000;
 Minibatch[   1- 100]: loss = 0.480699 * 100, metric = 9.96% * 100;
 Minibatch[ 101- 200]: loss = 0.478338 * 100, metric = 9.84% * 100;
 Minibatch[ 201- 300]: loss = 0.505221 * 100, metric = 10.30% * 100;
 Minibatch[ 301- 400]: loss = 0.500411 * 100, metric = 10.49% * 100;
 Minibatch[ 401- 500]: loss = 0.490902 * 100, metric = 10.17% * 100;
 Minibatch[ 501- 600]: loss = 0.484690 * 100, metric = 9.96% * 100;
 Minibatch[ 601- 700]: loss = 0.503862 * 100, metric = 10.43% * 100;
 Minibatch[ 701- 800]: loss = 0.489801 * 100, metric = 10.21% * 100;
 Minibatch[ 801- 900]: loss = 0.495623 * 100, metric = 10.33% * 100;
 Minibatch[ 901-1000]: loss = 0.489846 * 100, metric = 9.97% * 100;
 Minibatch[1001-1100]: loss = 0.504019 * 100, metric = 10.54% * 100;
 Minibatch[1101-1200]: loss = 0.502505 * 100, metric = 10.56% * 100;
 Minibatch[1201-1300]: loss = 0.490232 * 100, metric = 10.07% * 100;
 Minibatch[1301-1400]: loss = 0.496939 * 100, metric = 10.50% * 100;
 Minibatch[1401-1500]: loss = 0.485505 * 100, metric = 9.82% * 100;
 Minibatch[1501-1600]: loss = 0.500035 * 100, metric = 10.28% * 100;
 Minibatch[1601-1700]: loss = 0.498690 * 100, metric = 10.35% * 100;
 Minibatch[1701-1800]: loss = 0.478297 * 100, metric = 9.88% * 100;
 Minibatch[1801-1900]: loss = 0.483992 * 100, metric = 9.97% * 100;
 Minibatch[1901-2000]: loss = 0.500032 * 100, metric = 10.46% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.492982 * 2000, metric = 10.20% * 2000 602.980s (  3.3 samples/s);
Finished Evaluation [40]: Minibatch[1-1000]: metric = 15.12% * 1000;
 Minibatch[   1- 100]: loss = 0.494053 * 100, metric = 10.24% * 100;
 Minibatch[ 101- 200]: loss = 0.484151 * 100, metric = 9.82% * 100;
 Minibatch[ 201- 300]: loss = 0.495835 * 100, metric = 10.38% * 100;
 Minibatch[ 301- 400]: loss = 0.501127 * 100, metric = 10.44% * 100;
 Minibatch[ 401- 500]: loss = 0.493865 * 100, metric = 10.34% * 100;
 Minibatch[ 501- 600]: loss = 0.483985 * 100, metric = 9.77% * 100;
 Minibatch[ 601- 700]: loss = 0.507159 * 100, metric = 10.57% * 100;
 Minibatch[ 701- 800]: loss = 0.486021 * 100, metric = 10.05% * 100;
 Minibatch[ 801- 900]: loss = 0.477414 * 100, metric = 9.81% * 100;
 Minibatch[ 901-1000]: loss = 0.493763 * 100, metric = 10.42% * 100;
 Minibatch[1001-1100]: loss = 0.490075 * 100, metric = 10.03% * 100;
 Minibatch[1101-1200]: loss = 0.507684 * 100, metric = 10.60% * 100;
 Minibatch[1201-1300]: loss = 0.503389 * 100, metric = 10.44% * 100;
 Minibatch[1301-1400]: loss = 0.475855 * 100, metric = 9.88% * 100;
 Minibatch[1401-1500]: loss = 0.491424 * 100, metric = 10.22% * 100;
 Minibatch[1501-1600]: loss = 0.487732 * 100, metric = 10.10% * 100;
 Minibatch[1601-1700]: loss = 0.492435 * 100, metric = 10.42% * 100;
 Minibatch[1701-1800]: loss = 0.498015 * 100, metric = 10.70% * 100;
 Minibatch[1801-1900]: loss = 0.499274 * 100, metric = 10.45% * 100;
 Minibatch[1901-2000]: loss = 0.483103 * 100, metric = 10.00% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.492318 * 2000, metric = 10.23% * 2000 575.337s (  3.5 samples/s);
Finished Evaluation [41]: Minibatch[1-1000]: metric = 16.49% * 1000;
 Minibatch[   1- 100]: loss = 0.485688 * 100, metric = 9.92% * 100;
 Minibatch[ 101- 200]: loss = 0.488213 * 100, metric = 10.27% * 100;
 Minibatch[ 201- 300]: loss = 0.483971 * 100, metric = 10.01% * 100;
 Minibatch[ 301- 400]: loss = 0.476185 * 100, metric = 9.77% * 100;
 Minibatch[ 401- 500]: loss = 0.479962 * 100, metric = 9.88% * 100;
 Minibatch[ 501- 600]: loss = 0.492443 * 100, metric = 10.09% * 100;
 Minibatch[ 601- 700]: loss = 0.482559 * 100, metric = 9.95% * 100;
 Minibatch[ 701- 800]: loss = 0.482308 * 100, metric = 10.20% * 100;
 Minibatch[ 801- 900]: loss = 0.474414 * 100, metric = 9.82% * 100;
 Minibatch[ 901-1000]: loss = 0.494231 * 100, metric = 10.38% * 100;
 Minibatch[1001-1100]: loss = 0.481467 * 100, metric = 9.99% * 100;
 Minibatch[1101-1200]: loss = 0.484358 * 100, metric = 10.18% * 100;
 Minibatch[1201-1300]: loss = 0.482658 * 100, metric = 10.05% * 100;
 Minibatch[1301-1400]: loss = 0.483925 * 100, metric = 10.18% * 100;
 Minibatch[1401-1500]: loss = 0.476019 * 100, metric = 9.60% * 100;
 Minibatch[1501-1600]: loss = 0.481450 * 100, metric = 9.95% * 100;
 Minibatch[1601-1700]: loss = 0.486540 * 100, metric = 10.10% * 100;
 Minibatch[1701-1800]: loss = 0.486513 * 100, metric = 10.14% * 100;
 Minibatch[1801-1900]: loss = 0.491093 * 100, metric = 10.46% * 100;
 Minibatch[1901-2000]: loss = 0.485700 * 100, metric = 10.04% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.483985 * 2000, metric = 10.05% * 2000 575.358s (  3.5 samples/s);
Finished Evaluation [42]: Minibatch[1-1000]: metric = 14.64% * 1000;
0.5284295312911272
 Minibatch[   1- 100]: loss = 0.504507 * 100, metric = 10.62% * 100;
 Minibatch[ 101- 200]: loss = 0.461797 * 100, metric = 9.25% * 100;
 Minibatch[ 201- 300]: loss = 0.495527 * 100, metric = 10.15% * 100;
 Minibatch[ 301- 400]: loss = 0.490993 * 100, metric = 10.26% * 100;
 Minibatch[ 401- 500]: loss = 0.477364 * 100, metric = 9.82% * 100;
 Minibatch[ 501- 600]: loss = 0.473175 * 100, metric = 9.80% * 100;
 Minibatch[ 601- 700]: loss = 0.498130 * 100, metric = 10.39% * 100;
 Minibatch[ 701- 800]: loss = 0.481447 * 100, metric = 10.07% * 100;
 Minibatch[ 801- 900]: loss = 0.480675 * 100, metric = 9.94% * 100;
 Minibatch[ 901-1000]: loss = 0.485089 * 100, metric = 10.02% * 100;
 Minibatch[1001-1100]: loss = 0.489822 * 100, metric = 10.22% * 100;
 Minibatch[1101-1200]: loss = 0.474319 * 100, metric = 9.84% * 100;
 Minibatch[1201-1300]: loss = 0.492012 * 100, metric = 10.65% * 100;
 Minibatch[1301-1400]: loss = 0.492359 * 100, metric = 10.32% * 100;
 Minibatch[1401-1500]: loss = 0.467744 * 100, metric = 9.85% * 100;
 Minibatch[1501-1600]: loss = 0.497838 * 100, metric = 10.03% * 100;
 Minibatch[1601-1700]: loss = 0.483099 * 100, metric = 9.97% * 100;
 Minibatch[1701-1800]: loss = 0.479030 * 100, metric = 10.29% * 100;
 Minibatch[1801-1900]: loss = 0.483694 * 100, metric = 10.03% * 100;
 Minibatch[1901-2000]: loss = 0.476339 * 100, metric = 9.62% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.484248 * 2000, metric = 10.06% * 2000 576.280s (  3.5 samples/s);
Finished Evaluation [43]: Minibatch[1-1000]: metric = 14.68% * 1000;
 Minibatch[   1- 100]: loss = 0.484136 * 100, metric = 10.12% * 100;
 Minibatch[ 101- 200]: loss = 0.485912 * 100, metric = 10.14% * 100;
 Minibatch[ 201- 300]: loss = 0.483389 * 100, metric = 9.95% * 100;
 Minibatch[ 301- 400]: loss = 0.491391 * 100, metric = 10.20% * 100;
 Minibatch[ 401- 500]: loss = 0.481674 * 100, metric = 9.74% * 100;
 Minibatch[ 501- 600]: loss = 0.476982 * 100, metric = 9.95% * 100;
 Minibatch[ 601- 700]: loss = 0.494902 * 100, metric = 10.40% * 100;
 Minibatch[ 701- 800]: loss = 0.462569 * 100, metric = 9.40% * 100;
 Minibatch[ 801- 900]: loss = 0.475095 * 100, metric = 9.62% * 100;
 Minibatch[ 901-1000]: loss = 0.479509 * 100, metric = 9.71% * 100;
 Minibatch[1001-1100]: loss = 0.471019 * 100, metric = 9.29% * 100;
 Minibatch[1101-1200]: loss = 0.456669 * 100, metric = 9.31% * 100;
 Minibatch[1201-1300]: loss = 0.475703 * 100, metric = 10.05% * 100;
 Minibatch[1301-1400]: loss = 0.468199 * 100, metric = 9.71% * 100;
 Minibatch[1401-1500]: loss = 0.473515 * 100, metric = 9.78% * 100;
 Minibatch[1501-1600]: loss = 0.463570 * 100, metric = 9.50% * 100;
 Minibatch[1601-1700]: loss = 0.465229 * 100, metric = 9.34% * 100;
 Minibatch[1701-1800]: loss = 0.488878 * 100, metric = 10.29% * 100;
 Minibatch[1801-1900]: loss = 0.477540 * 100, metric = 9.89% * 100;
 Minibatch[1901-2000]: loss = 0.466959 * 100, metric = 9.61% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.476142 * 2000, metric = 9.80% * 2000 577.160s (  3.5 samples/s);
Finished Evaluation [44]: Minibatch[1-1000]: metric = 14.56% * 1000;
0.5257685480564833
 Minibatch[   1- 100]: loss = 0.485793 * 100, metric = 9.88% * 100;
 Minibatch[ 101- 200]: loss = 0.476680 * 100, metric = 9.60% * 100;
 Minibatch[ 201- 300]: loss = 0.480471 * 100, metric = 10.00% * 100;
 Minibatch[ 301- 400]: loss = 0.491399 * 100, metric = 10.52% * 100;
 Minibatch[ 401- 500]: loss = 0.479872 * 100, metric = 9.81% * 100;
 Minibatch[ 501- 600]: loss = 0.461591 * 100, metric = 9.32% * 100;
 Minibatch[ 601- 700]: loss = 0.466148 * 100, metric = 9.67% * 100;
 Minibatch[ 701- 800]: loss = 0.472874 * 100, metric = 9.79% * 100;
 Minibatch[ 801- 900]: loss = 0.496523 * 100, metric = 10.45% * 100;
 Minibatch[ 901-1000]: loss = 0.467615 * 100, metric = 9.48% * 100;
 Minibatch[1001-1100]: loss = 0.463095 * 100, metric = 9.59% * 100;
 Minibatch[1101-1200]: loss = 0.485031 * 100, metric = 10.01% * 100;
 Minibatch[1201-1300]: loss = 0.480533 * 100, metric = 9.81% * 100;
 Minibatch[1301-1400]: loss = 0.463716 * 100, metric = 9.30% * 100;
 Minibatch[1401-1500]: loss = 0.476137 * 100, metric = 9.78% * 100;
 Minibatch[1501-1600]: loss = 0.485601 * 100, metric = 10.00% * 100;
 Minibatch[1601-1700]: loss = 0.461960 * 100, metric = 9.78% * 100;
 Minibatch[1701-1800]: loss = 0.485261 * 100, metric = 9.90% * 100;
 Minibatch[1801-1900]: loss = 0.490911 * 100, metric = 9.98% * 100;
 Minibatch[1901-2000]: loss = 0.476727 * 100, metric = 9.75% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.477397 * 2000, metric = 9.82% * 2000 584.875s (  3.4 samples/s);
Finished Evaluation [45]: Minibatch[1-1000]: metric = 15.68% * 1000;
 Minibatch[   1- 100]: loss = 0.471024 * 100, metric = 9.89% * 100;
 Minibatch[ 101- 200]: loss = 0.488672 * 100, metric = 10.07% * 100;
 Minibatch[ 201- 300]: loss = 0.474230 * 100, metric = 9.73% * 100;
 Minibatch[ 301- 400]: loss = 0.492296 * 100, metric = 10.14% * 100;
 Minibatch[ 401- 500]: loss = 0.467893 * 100, metric = 9.58% * 100;
 Minibatch[ 501- 600]: loss = 0.468964 * 100, metric = 9.82% * 100;
 Minibatch[ 601- 700]: loss = 0.452638 * 100, metric = 9.14% * 100;
 Minibatch[ 701- 800]: loss = 0.467382 * 100, metric = 9.81% * 100;
 Minibatch[ 801- 900]: loss = 0.468974 * 100, metric = 9.66% * 100;
 Minibatch[ 901-1000]: loss = 0.479909 * 100, metric = 10.00% * 100;
 Minibatch[1001-1100]: loss = 0.479316 * 100, metric = 9.60% * 100;
 Minibatch[1101-1200]: loss = 0.486198 * 100, metric = 10.14% * 100;
 Minibatch[1201-1300]: loss = 0.483307 * 100, metric = 9.87% * 100;
 Minibatch[1301-1400]: loss = 0.477272 * 100, metric = 9.79% * 100;
 Minibatch[1401-1500]: loss = 0.467597 * 100, metric = 9.50% * 100;
 Minibatch[1501-1600]: loss = 0.483627 * 100, metric = 9.93% * 100;
 Minibatch[1601-1700]: loss = 0.470837 * 100, metric = 9.60% * 100;
 Minibatch[1701-1800]: loss = 0.484731 * 100, metric = 10.03% * 100;
 Minibatch[1801-1900]: loss = 0.454667 * 100, metric = 8.98% * 100;
 Minibatch[1901-2000]: loss = 0.472015 * 100, metric = 9.55% * 100;
Finished Epoch[46 of 200]: [Training] loss = 0.474577 * 2000, metric = 9.74% * 2000 610.264s (  3.3 samples/s);
Finished Evaluation [46]: Minibatch[1-1000]: metric = 14.60% * 1000;
 Minibatch[   1- 100]: loss = 0.470373 * 100, metric = 9.58% * 100;
 Minibatch[ 101- 200]: loss = 0.455585 * 100, metric = 9.32% * 100;
 Minibatch[ 201- 300]: loss = 0.473166 * 100, metric = 9.69% * 100;
 Minibatch[ 301- 400]: loss = 0.467171 * 100, metric = 9.62% * 100;
 Minibatch[ 401- 500]: loss = 0.466533 * 100, metric = 9.45% * 100;
 Minibatch[ 501- 600]: loss = 0.472759 * 100, metric = 9.81% * 100;
 Minibatch[ 601- 700]: loss = 0.485760 * 100, metric = 9.97% * 100;
 Minibatch[ 701- 800]: loss = 0.485001 * 100, metric = 10.04% * 100;
 Minibatch[ 801- 900]: loss = 0.470264 * 100, metric = 9.45% * 100;
 Minibatch[ 901-1000]: loss = 0.476925 * 100, metric = 9.94% * 100;
 Minibatch[1001-1100]: loss = 0.496028 * 100, metric = 10.20% * 100;
 Minibatch[1101-1200]: loss = 0.465413 * 100, metric = 9.36% * 100;
 Minibatch[1201-1300]: loss = 0.456275 * 100, metric = 9.35% * 100;
 Minibatch[1301-1400]: loss = 0.464806 * 100, metric = 9.61% * 100;
 Minibatch[1401-1500]: loss = 0.475982 * 100, metric = 9.79% * 100;
 Minibatch[1501-1600]: loss = 0.471790 * 100, metric = 9.52% * 100;
 Minibatch[1601-1700]: loss = 0.470018 * 100, metric = 9.87% * 100;
 Minibatch[1701-1800]: loss = 0.489953 * 100, metric = 10.07% * 100;
 Minibatch[1801-1900]: loss = 0.477604 * 100, metric = 9.89% * 100;
 Minibatch[1901-2000]: loss = 0.485760 * 100, metric = 10.09% * 100;
Finished Epoch[47 of 200]: [Training] loss = 0.473858 * 2000, metric = 9.73% * 2000 642.423s (  3.1 samples/s);
Finished Evaluation [47]: Minibatch[1-1000]: metric = 14.59% * 1000;
 Minibatch[   1- 100]: loss = 0.476963 * 100, metric = 9.63% * 100;
 Minibatch[ 101- 200]: loss = 0.476309 * 100, metric = 9.87% * 100;
 Minibatch[ 201- 300]: loss = 0.471562 * 100, metric = 9.73% * 100;
 Minibatch[ 301- 400]: loss = 0.464007 * 100, metric = 9.46% * 100;
 Minibatch[ 401- 500]: loss = 0.481550 * 100, metric = 9.98% * 100;
 Minibatch[ 501- 600]: loss = 0.491677 * 100, metric = 10.14% * 100;
 Minibatch[ 601- 700]: loss = 0.489524 * 100, metric = 9.82% * 100;
 Minibatch[ 701- 800]: loss = 0.468617 * 100, metric = 9.42% * 100;
 Minibatch[ 801- 900]: loss = 0.466101 * 100, metric = 9.27% * 100;
 Minibatch[ 901-1000]: loss = 0.477734 * 100, metric = 9.81% * 100;
 Minibatch[1001-1100]: loss = 0.476810 * 100, metric = 9.89% * 100;
 Minibatch[1101-1200]: loss = 0.473207 * 100, metric = 9.71% * 100;
 Minibatch[1201-1300]: loss = 0.470005 * 100, metric = 9.61% * 100;
 Minibatch[1301-1400]: loss = 0.465548 * 100, metric = 9.52% * 100;
 Minibatch[1401-1500]: loss = 0.465745 * 100, metric = 9.61% * 100;
 Minibatch[1501-1600]: loss = 0.474800 * 100, metric = 9.69% * 100;
 Minibatch[1601-1700]: loss = 0.456066 * 100, metric = 9.38% * 100;
 Minibatch[1701-1800]: loss = 0.470029 * 100, metric = 9.31% * 100;
 Minibatch[1801-1900]: loss = 0.478687 * 100, metric = 9.69% * 100;
 Minibatch[1901-2000]: loss = 0.455426 * 100, metric = 9.19% * 100;
Finished Epoch[48 of 200]: [Training] loss = 0.472518 * 2000, metric = 9.64% * 2000 642.046s (  3.1 samples/s);
Finished Evaluation [48]: Minibatch[1-1000]: metric = 15.42% * 1000;
 Minibatch[   1- 100]: loss = 0.480321 * 100, metric = 9.63% * 100;
 Minibatch[ 101- 200]: loss = 0.468909 * 100, metric = 9.43% * 100;
 Minibatch[ 201- 300]: loss = 0.477672 * 100, metric = 9.85% * 100;
 Minibatch[ 301- 400]: loss = 0.476358 * 100, metric = 9.81% * 100;
 Minibatch[ 401- 500]: loss = 0.492206 * 100, metric = 10.21% * 100;
 Minibatch[ 501- 600]: loss = 0.467969 * 100, metric = 9.64% * 100;
 Minibatch[ 601- 700]: loss = 0.473312 * 100, metric = 9.59% * 100;
 Minibatch[ 701- 800]: loss = 0.473074 * 100, metric = 9.58% * 100;
 Minibatch[ 801- 900]: loss = 0.464442 * 100, metric = 9.38% * 100;
 Minibatch[ 901-1000]: loss = 0.489175 * 100, metric = 10.00% * 100;
 Minibatch[1001-1100]: loss = 0.473810 * 100, metric = 9.71% * 100;
 Minibatch[1101-1200]: loss = 0.480046 * 100, metric = 9.74% * 100;
 Minibatch[1201-1300]: loss = 0.447103 * 100, metric = 8.85% * 100;
 Minibatch[1301-1400]: loss = 0.479689 * 100, metric = 9.78% * 100;
 Minibatch[1401-1500]: loss = 0.472106 * 100, metric = 9.93% * 100;
 Minibatch[1501-1600]: loss = 0.441649 * 100, metric = 8.96% * 100;
 Minibatch[1601-1700]: loss = 0.491754 * 100, metric = 10.66% * 100;
 Minibatch[1701-1800]: loss = 0.475999 * 100, metric = 9.89% * 100;
 Minibatch[1801-1900]: loss = 0.476195 * 100, metric = 9.73% * 100;
 Minibatch[1901-2000]: loss = 0.464294 * 100, metric = 9.48% * 100;
Finished Epoch[49 of 200]: [Training] loss = 0.473304 * 2000, metric = 9.69% * 2000 646.837s (  3.1 samples/s);
Finished Evaluation [49]: Minibatch[1-1000]: metric = 14.05% * 1000;
0.5206923451423645
 Minibatch[   1- 100]: loss = 0.471924 * 100, metric = 9.80% * 100;
 Minibatch[ 101- 200]: loss = 0.458656 * 100, metric = 9.30% * 100;
 Minibatch[ 201- 300]: loss = 0.456855 * 100, metric = 9.07% * 100;
 Minibatch[ 301- 400]: loss = 0.464654 * 100, metric = 9.42% * 100;
 Minibatch[ 401- 500]: loss = 0.479689 * 100, metric = 10.02% * 100;
 Minibatch[ 501- 600]: loss = 0.493305 * 100, metric = 10.25% * 100;
 Minibatch[ 601- 700]: loss = 0.457363 * 100, metric = 9.31% * 100;
 Minibatch[ 701- 800]: loss = 0.455012 * 100, metric = 9.21% * 100;
 Minibatch[ 801- 900]: loss = 0.465593 * 100, metric = 9.57% * 100;
 Minibatch[ 901-1000]: loss = 0.460779 * 100, metric = 9.40% * 100;
 Minibatch[1001-1100]: loss = 0.463184 * 100, metric = 9.32% * 100;
 Minibatch[1101-1200]: loss = 0.473456 * 100, metric = 9.71% * 100;
 Minibatch[1201-1300]: loss = 0.472864 * 100, metric = 9.97% * 100;
 Minibatch[1301-1400]: loss = 0.453255 * 100, metric = 9.28% * 100;
 Minibatch[1401-1500]: loss = 0.464021 * 100, metric = 9.68% * 100;
 Minibatch[1501-1600]: loss = 0.458273 * 100, metric = 9.44% * 100;
 Minibatch[1601-1700]: loss = 0.456715 * 100, metric = 9.29% * 100;
 Minibatch[1701-1800]: loss = 0.471941 * 100, metric = 9.63% * 100;
 Minibatch[1801-1900]: loss = 0.478769 * 100, metric = 9.98% * 100;
 Minibatch[1901-2000]: loss = 0.475298 * 100, metric = 9.89% * 100;
Finished Epoch[50 of 200]: [Training] loss = 0.466580 * 2000, metric = 9.58% * 2000 643.880s (  3.1 samples/s);
Finished Evaluation [50]: Minibatch[1-1000]: metric = 15.68% * 1000;
 Minibatch[   1- 100]: loss = 0.449923 * 100, metric = 9.16% * 100;
 Minibatch[ 101- 200]: loss = 0.481408 * 100, metric = 10.04% * 100;
 Minibatch[ 201- 300]: loss = 0.475845 * 100, metric = 9.75% * 100;
 Minibatch[ 301- 400]: loss = 0.464845 * 100, metric = 9.37% * 100;
 Minibatch[ 401- 500]: loss = 0.469259 * 100, metric = 9.73% * 100;
 Minibatch[ 501- 600]: loss = 0.478418 * 100, metric = 9.92% * 100;
 Minibatch[ 601- 700]: loss = 0.459497 * 100, metric = 9.43% * 100;
 Minibatch[ 701- 800]: loss = 0.455277 * 100, metric = 9.42% * 100;
 Minibatch[ 801- 900]: loss = 0.470925 * 100, metric = 9.57% * 100;
 Minibatch[ 901-1000]: loss = 0.462930 * 100, metric = 9.47% * 100;
 Minibatch[1001-1100]: loss = 0.465036 * 100, metric = 9.48% * 100;
 Minibatch[1101-1200]: loss = 0.472108 * 100, metric = 9.75% * 100;
 Minibatch[1201-1300]: loss = 0.482828 * 100, metric = 9.76% * 100;
 Minibatch[1301-1400]: loss = 0.477839 * 100, metric = 9.75% * 100;
 Minibatch[1401-1500]: loss = 0.465213 * 100, metric = 9.53% * 100;
 Minibatch[1501-1600]: loss = 0.473627 * 100, metric = 9.68% * 100;
 Minibatch[1601-1700]: loss = 0.456922 * 100, metric = 9.39% * 100;
 Minibatch[1701-1800]: loss = 0.476924 * 100, metric = 9.83% * 100;
 Minibatch[1801-1900]: loss = 0.451970 * 100, metric = 9.00% * 100;
 Minibatch[1901-2000]: loss = 0.470768 * 100, metric = 9.75% * 100;
Finished Epoch[51 of 200]: [Training] loss = 0.468078 * 2000, metric = 9.59% * 2000 648.062s (  3.1 samples/s);
Finished Evaluation [51]: Minibatch[1-1000]: metric = 14.30% * 1000;
0.5184091876596212
 Minibatch[   1- 100]: loss = 0.459965 * 100, metric = 9.56% * 100;
 Minibatch[ 101- 200]: loss = 0.464431 * 100, metric = 9.62% * 100;
 Minibatch[ 201- 300]: loss = 0.479545 * 100, metric = 10.06% * 100;
 Minibatch[ 301- 400]: loss = 0.455825 * 100, metric = 9.39% * 100;
 Minibatch[ 401- 500]: loss = 0.482841 * 100, metric = 9.96% * 100;
 Minibatch[ 501- 600]: loss = 0.463764 * 100, metric = 9.67% * 100;
 Minibatch[ 601- 700]: loss = 0.471232 * 100, metric = 9.38% * 100;
 Minibatch[ 701- 800]: loss = 0.471706 * 100, metric = 9.69% * 100;
 Minibatch[ 801- 900]: loss = 0.472830 * 100, metric = 9.90% * 100;
 Minibatch[ 901-1000]: loss = 0.477875 * 100, metric = 9.88% * 100;
 Minibatch[1001-1100]: loss = 0.466605 * 100, metric = 9.75% * 100;
 Minibatch[1101-1200]: loss = 0.454246 * 100, metric = 9.12% * 100;
 Minibatch[1201-1300]: loss = 0.458256 * 100, metric = 9.05% * 100;
 Minibatch[1301-1400]: loss = 0.461265 * 100, metric = 9.20% * 100;
 Minibatch[1401-1500]: loss = 0.451517 * 100, metric = 8.88% * 100;
 Minibatch[1501-1600]: loss = 0.455107 * 100, metric = 9.23% * 100;
 Minibatch[1601-1700]: loss = 0.471603 * 100, metric = 9.70% * 100;
 Minibatch[1701-1800]: loss = 0.452745 * 100, metric = 9.40% * 100;
 Minibatch[1801-1900]: loss = 0.460956 * 100, metric = 9.29% * 100;
 Minibatch[1901-2000]: loss = 0.477271 * 100, metric = 9.74% * 100;
Finished Epoch[52 of 200]: [Training] loss = 0.465479 * 2000, metric = 9.52% * 2000 649.910s (  3.1 samples/s);
Finished Evaluation [52]: Minibatch[1-1000]: metric = 15.59% * 1000;
 Minibatch[   1- 100]: loss = 0.474009 * 100, metric = 9.74% * 100;
 Minibatch[ 101- 200]: loss = 0.453447 * 100, metric = 9.09% * 100;
 Minibatch[ 201- 300]: loss = 0.460979 * 100, metric = 9.45% * 100;
 Minibatch[ 301- 400]: loss = 0.470719 * 100, metric = 9.75% * 100;
 Minibatch[ 401- 500]: loss = 0.468262 * 100, metric = 9.67% * 100;
 Minibatch[ 501- 600]: loss = 0.460194 * 100, metric = 9.18% * 100;
 Minibatch[ 601- 700]: loss = 0.458277 * 100, metric = 9.34% * 100;
 Minibatch[ 701- 800]: loss = 0.469670 * 100, metric = 9.47% * 100;
 Minibatch[ 801- 900]: loss = 0.463745 * 100, metric = 9.57% * 100;
 Minibatch[ 901-1000]: loss = 0.455721 * 100, metric = 9.38% * 100;
 Minibatch[1001-1100]: loss = 0.463532 * 100, metric = 9.37% * 100;
 Minibatch[1101-1200]: loss = 0.457722 * 100, metric = 9.24% * 100;
 Minibatch[1201-1300]: loss = 0.452046 * 100, metric = 9.20% * 100;
 Minibatch[1301-1400]: loss = 0.468381 * 100, metric = 9.40% * 100;
 Minibatch[1401-1500]: loss = 0.463851 * 100, metric = 9.52% * 100;
 Minibatch[1501-1600]: loss = 0.472071 * 100, metric = 9.97% * 100;
 Minibatch[1601-1700]: loss = 0.457800 * 100, metric = 9.21% * 100;
 Minibatch[1701-1800]: loss = 0.470197 * 100, metric = 9.81% * 100;
 Minibatch[1801-1900]: loss = 0.486874 * 100, metric = 10.03% * 100;
 Minibatch[1901-2000]: loss = 0.454996 * 100, metric = 9.01% * 100;
Finished Epoch[53 of 200]: [Training] loss = 0.464125 * 2000, metric = 9.47% * 2000 649.332s (  3.1 samples/s);
Finished Evaluation [53]: Minibatch[1-1000]: metric = 14.33% * 1000;
 Minibatch[   1- 100]: loss = 0.466521 * 100, metric = 9.56% * 100;
 Minibatch[ 101- 200]: loss = 0.470032 * 100, metric = 9.88% * 100;
 Minibatch[ 201- 300]: loss = 0.468776 * 100, metric = 9.72% * 100;
 Minibatch[ 301- 400]: loss = 0.460407 * 100, metric = 9.22% * 100;
 Minibatch[ 401- 500]: loss = 0.463059 * 100, metric = 9.41% * 100;
 Minibatch[ 501- 600]: loss = 0.453947 * 100, metric = 9.26% * 100;
 Minibatch[ 601- 700]: loss = 0.467546 * 100, metric = 9.54% * 100;
 Minibatch[ 701- 800]: loss = 0.460331 * 100, metric = 9.43% * 100;
 Minibatch[ 801- 900]: loss = 0.447277 * 100, metric = 9.06% * 100;
 Minibatch[ 901-1000]: loss = 0.468093 * 100, metric = 9.33% * 100;
 Minibatch[1001-1100]: loss = 0.446524 * 100, metric = 8.94% * 100;
 Minibatch[1101-1200]: loss = 0.451348 * 100, metric = 9.14% * 100;
 Minibatch[1201-1300]: loss = 0.460645 * 100, metric = 9.57% * 100;
 Minibatch[1301-1400]: loss = 0.455002 * 100, metric = 9.50% * 100;
 Minibatch[1401-1500]: loss = 0.465482 * 100, metric = 9.50% * 100;
 Minibatch[1501-1600]: loss = 0.466917 * 100, metric = 9.42% * 100;
 Minibatch[1601-1700]: loss = 0.459974 * 100, metric = 9.42% * 100;
 Minibatch[1701-1800]: loss = 0.461153 * 100, metric = 9.42% * 100;
 Minibatch[1801-1900]: loss = 0.466955 * 100, metric = 9.83% * 100;
 Minibatch[1901-2000]: loss = 0.469383 * 100, metric = 9.50% * 100;
Finished Epoch[54 of 200]: [Training] loss = 0.461469 * 2000, metric = 9.43% * 2000 648.060s (  3.1 samples/s);
Finished Evaluation [54]: Minibatch[1-1000]: metric = 13.76% * 1000;
0.5107040352672338
 Minibatch[   1- 100]: loss = 0.462251 * 100, metric = 9.25% * 100;
 Minibatch[ 101- 200]: loss = 0.466773 * 100, metric = 9.65% * 100;
 Minibatch[ 201- 300]: loss = 0.462428 * 100, metric = 9.46% * 100;
 Minibatch[ 301- 400]: loss = 0.440656 * 100, metric = 8.87% * 100;
 Minibatch[ 401- 500]: loss = 0.459223 * 100, metric = 9.46% * 100;
 Minibatch[ 501- 600]: loss = 0.476688 * 100, metric = 9.61% * 100;
 Minibatch[ 601- 700]: loss = 0.470735 * 100, metric = 9.79% * 100;
 Minibatch[ 701- 800]: loss = 0.474586 * 100, metric = 9.87% * 100;
 Minibatch[ 801- 900]: loss = 0.464836 * 100, metric = 9.72% * 100;
 Minibatch[ 901-1000]: loss = 0.456783 * 100, metric = 9.42% * 100;
 Minibatch[1001-1100]: loss = 0.468757 * 100, metric = 9.56% * 100;
 Minibatch[1101-1200]: loss = 0.467360 * 100, metric = 9.56% * 100;
 Minibatch[1201-1300]: loss = 0.459303 * 100, metric = 9.18% * 100;
 Minibatch[1301-1400]: loss = 0.447993 * 100, metric = 8.90% * 100;
 Minibatch[1401-1500]: loss = 0.450433 * 100, metric = 8.98% * 100;
 Minibatch[1501-1600]: loss = 0.462332 * 100, metric = 9.39% * 100;
 Minibatch[1601-1700]: loss = 0.457104 * 100, metric = 9.45% * 100;
 Minibatch[1701-1800]: loss = 0.473881 * 100, metric = 9.70% * 100;
 Minibatch[1801-1900]: loss = 0.443254 * 100, metric = 8.86% * 100;
 Minibatch[1901-2000]: loss = 0.464233 * 100, metric = 9.26% * 100;
Finished Epoch[55 of 200]: [Training] loss = 0.461480 * 2000, metric = 9.40% * 2000 648.830s (  3.1 samples/s);
Finished Evaluation [55]: Minibatch[1-1000]: metric = 15.29% * 1000;
 Minibatch[   1- 100]: loss = 0.474611 * 100, metric = 9.66% * 100;
 Minibatch[ 101- 200]: loss = 0.452592 * 100, metric = 9.22% * 100;
 Minibatch[ 201- 300]: loss = 0.467431 * 100, metric = 9.61% * 100;
 Minibatch[ 301- 400]: loss = 0.461820 * 100, metric = 9.50% * 100;
 Minibatch[ 401- 500]: loss = 0.476070 * 100, metric = 9.69% * 100;
 Minibatch[ 501- 600]: loss = 0.469352 * 100, metric = 9.68% * 100;
 Minibatch[ 601- 700]: loss = 0.464418 * 100, metric = 9.52% * 100;
 Minibatch[ 701- 800]: loss = 0.448236 * 100, metric = 9.21% * 100;
 Minibatch[ 801- 900]: loss = 0.452034 * 100, metric = 9.11% * 100;
 Minibatch[ 901-1000]: loss = 0.462058 * 100, metric = 9.59% * 100;
 Minibatch[1001-1100]: loss = 0.468006 * 100, metric = 9.60% * 100;
 Minibatch[1101-1200]: loss = 0.462373 * 100, metric = 9.36% * 100;
 Minibatch[1201-1300]: loss = 0.461484 * 100, metric = 9.35% * 100;
 Minibatch[1301-1400]: loss = 0.439313 * 100, metric = 8.76% * 100;
 Minibatch[1401-1500]: loss = 0.458583 * 100, metric = 9.21% * 100;
 Minibatch[1501-1600]: loss = 0.450600 * 100, metric = 9.17% * 100;
 Minibatch[1601-1700]: loss = 0.446537 * 100, metric = 8.60% * 100;
 Minibatch[1701-1800]: loss = 0.456855 * 100, metric = 9.38% * 100;
 Minibatch[1801-1900]: loss = 0.447060 * 100, metric = 9.01% * 100;
 Minibatch[1901-2000]: loss = 0.460873 * 100, metric = 9.61% * 100;
Finished Epoch[56 of 200]: [Training] loss = 0.459015 * 2000, metric = 9.34% * 2000 649.758s (  3.1 samples/s);
Finished Evaluation [56]: Minibatch[1-1000]: metric = 14.74% * 1000;
 Minibatch[   1- 100]: loss = 0.460652 * 100, metric = 9.29% * 100;
 Minibatch[ 101- 200]: loss = 0.449386 * 100, metric = 9.21% * 100;
 Minibatch[ 201- 300]: loss = 0.454229 * 100, metric = 9.27% * 100;
 Minibatch[ 301- 400]: loss = 0.457545 * 100, metric = 9.19% * 100;
 Minibatch[ 401- 500]: loss = 0.451201 * 100, metric = 9.18% * 100;
 Minibatch[ 501- 600]: loss = 0.443384 * 100, metric = 9.07% * 100;
 Minibatch[ 601- 700]: loss = 0.464641 * 100, metric = 9.36% * 100;
 Minibatch[ 701- 800]: loss = 0.446312 * 100, metric = 8.90% * 100;
 Minibatch[ 801- 900]: loss = 0.460060 * 100, metric = 9.24% * 100;
 Minibatch[ 901-1000]: loss = 0.463322 * 100, metric = 9.49% * 100;
 Minibatch[1001-1100]: loss = 0.466876 * 100, metric = 9.51% * 100;
 Minibatch[1101-1200]: loss = 0.453800 * 100, metric = 8.99% * 100;
 Minibatch[1201-1300]: loss = 0.460273 * 100, metric = 9.50% * 100;
 Minibatch[1301-1400]: loss = 0.452854 * 100, metric = 9.34% * 100;
 Minibatch[1401-1500]: loss = 0.454549 * 100, metric = 9.15% * 100;
 Minibatch[1501-1600]: loss = 0.447545 * 100, metric = 8.98% * 100;
 Minibatch[1601-1700]: loss = 0.458328 * 100, metric = 9.17% * 100;
 Minibatch[1701-1800]: loss = 0.461093 * 100, metric = 9.35% * 100;
 Minibatch[1801-1900]: loss = 0.462004 * 100, metric = 9.06% * 100;
 Minibatch[1901-2000]: loss = 0.454757 * 100, metric = 9.37% * 100;
Finished Epoch[57 of 200]: [Training] loss = 0.456140 * 2000, metric = 9.23% * 2000 641.336s (  3.1 samples/s);
Finished Evaluation [57]: Minibatch[1-1000]: metric = 15.03% * 1000;
 Minibatch[   1- 100]: loss = 0.446992 * 100, metric = 8.87% * 100;
 Minibatch[ 101- 200]: loss = 0.464883 * 100, metric = 9.59% * 100;
 Minibatch[ 201- 300]: loss = 0.457234 * 100, metric = 9.40% * 100;
 Minibatch[ 301- 400]: loss = 0.464263 * 100, metric = 9.44% * 100;
 Minibatch[ 401- 500]: loss = 0.475407 * 100, metric = 9.74% * 100;
 Minibatch[ 501- 600]: loss = 0.454386 * 100, metric = 9.38% * 100;
 Minibatch[ 601- 700]: loss = 0.462109 * 100, metric = 9.29% * 100;
 Minibatch[ 701- 800]: loss = 0.463393 * 100, metric = 9.54% * 100;
 Minibatch[ 801- 900]: loss = 0.456883 * 100, metric = 9.52% * 100;
 Minibatch[ 901-1000]: loss = 0.454860 * 100, metric = 9.23% * 100;
 Minibatch[1001-1100]: loss = 0.462018 * 100, metric = 9.39% * 100;
 Minibatch[1101-1200]: loss = 0.474141 * 100, metric = 9.81% * 100;
 Minibatch[1201-1300]: loss = 0.455964 * 100, metric = 9.38% * 100;
 Minibatch[1301-1400]: loss = 0.465286 * 100, metric = 9.45% * 100;
 Minibatch[1401-1500]: loss = 0.448000 * 100, metric = 9.05% * 100;
 Minibatch[1501-1600]: loss = 0.455325 * 100, metric = 9.19% * 100;
 Minibatch[1601-1700]: loss = 0.464378 * 100, metric = 9.29% * 100;
 Minibatch[1701-1800]: loss = 0.457145 * 100, metric = 9.31% * 100;
 Minibatch[1801-1900]: loss = 0.453708 * 100, metric = 9.33% * 100;
 Minibatch[1901-2000]: loss = 0.439720 * 100, metric = 8.83% * 100;
Finished Epoch[58 of 200]: [Training] loss = 0.458805 * 2000, metric = 9.35% * 2000 643.855s (  3.1 samples/s);
Finished Evaluation [58]: Minibatch[1-1000]: metric = 14.15% * 1000;
 Minibatch[   1- 100]: loss = 0.474511 * 100, metric = 10.02% * 100;
 Minibatch[ 101- 200]: loss = 0.475639 * 100, metric = 9.93% * 100;
 Minibatch[ 201- 300]: loss = 0.457238 * 100, metric = 9.12% * 100;
 Minibatch[ 301- 400]: loss = 0.450565 * 100, metric = 9.20% * 100;
 Minibatch[ 401- 500]: loss = 0.456036 * 100, metric = 9.35% * 100;
 Minibatch[ 501- 600]: loss = 0.453378 * 100, metric = 9.18% * 100;
 Minibatch[ 601- 700]: loss = 0.459521 * 100, metric = 9.36% * 100;
 Minibatch[ 701- 800]: loss = 0.452427 * 100, metric = 9.13% * 100;
 Minibatch[ 801- 900]: loss = 0.448520 * 100, metric = 9.09% * 100;
 Minibatch[ 901-1000]: loss = 0.457982 * 100, metric = 9.57% * 100;
 Minibatch[1001-1100]: loss = 0.456280 * 100, metric = 9.12% * 100;
 Minibatch[1101-1200]: loss = 0.464996 * 100, metric = 9.44% * 100;
 Minibatch[1201-1300]: loss = 0.461072 * 100, metric = 9.26% * 100;
 Minibatch[1301-1400]: loss = 0.450359 * 100, metric = 8.86% * 100;
 Minibatch[1401-1500]: loss = 0.460984 * 100, metric = 9.34% * 100;
 Minibatch[1501-1600]: loss = 0.460458 * 100, metric = 9.71% * 100;
 Minibatch[1601-1700]: loss = 0.453036 * 100, metric = 9.17% * 100;
 Minibatch[1701-1800]: loss = 0.458047 * 100, metric = 9.39% * 100;
 Minibatch[1801-1900]: loss = 0.458547 * 100, metric = 9.19% * 100;
 Minibatch[1901-2000]: loss = 0.462878 * 100, metric = 9.42% * 100;
Finished Epoch[59 of 200]: [Training] loss = 0.458624 * 2000, metric = 9.34% * 2000 628.746s (  3.2 samples/s);
Finished Evaluation [59]: Minibatch[1-1000]: metric = 15.68% * 1000;
 Minibatch[   1- 100]: loss = 0.463115 * 100, metric = 9.52% * 100;
 Minibatch[ 101- 200]: loss = 0.436042 * 100, metric = 8.71% * 100;
 Minibatch[ 201- 300]: loss = 0.431000 * 100, metric = 8.31% * 100;
 Minibatch[ 301- 400]: loss = 0.467126 * 100, metric = 9.25% * 100;
 Minibatch[ 401- 500]: loss = 0.462230 * 100, metric = 9.52% * 100;
 Minibatch[ 501- 600]: loss = 0.454143 * 100, metric = 9.49% * 100;
 Minibatch[ 601- 700]: loss = 0.438991 * 100, metric = 8.69% * 100;
 Minibatch[ 701- 800]: loss = 0.467314 * 100, metric = 9.72% * 100;
 Minibatch[ 801- 900]: loss = 0.456583 * 100, metric = 9.33% * 100;
 Minibatch[ 901-1000]: loss = 0.457623 * 100, metric = 9.20% * 100;
 Minibatch[1001-1100]: loss = 0.463867 * 100, metric = 9.62% * 100;
 Minibatch[1101-1200]: loss = 0.461568 * 100, metric = 9.54% * 100;
 Minibatch[1201-1300]: loss = 0.457540 * 100, metric = 9.30% * 100;
 Minibatch[1301-1400]: loss = 0.457385 * 100, metric = 9.28% * 100;
 Minibatch[1401-1500]: loss = 0.444626 * 100, metric = 9.23% * 100;
 Minibatch[1501-1600]: loss = 0.456328 * 100, metric = 9.15% * 100;
 Minibatch[1601-1700]: loss = 0.456827 * 100, metric = 9.21% * 100;
 Minibatch[1701-1800]: loss = 0.456011 * 100, metric = 9.22% * 100;
 Minibatch[1801-1900]: loss = 0.468878 * 100, metric = 9.86% * 100;
 Minibatch[1901-2000]: loss = 0.451731 * 100, metric = 9.27% * 100;
Finished Epoch[60 of 200]: [Training] loss = 0.455446 * 2000, metric = 9.27% * 2000 629.991s (  3.2 samples/s);
Finished Evaluation [60]: Minibatch[1-1000]: metric = 15.18% * 1000;
 Minibatch[   1- 100]: loss = 0.462006 * 100, metric = 9.44% * 100;
 Minibatch[ 101- 200]: loss = 0.447586 * 100, metric = 8.95% * 100;
 Minibatch[ 201- 300]: loss = 0.450095 * 100, metric = 9.07% * 100;
 Minibatch[ 301- 400]: loss = 0.462453 * 100, metric = 9.46% * 100;
 Minibatch[ 401- 500]: loss = 0.451388 * 100, metric = 9.26% * 100;
 Minibatch[ 501- 600]: loss = 0.430406 * 100, metric = 8.66% * 100;
 Minibatch[ 601- 700]: loss = 0.449641 * 100, metric = 8.84% * 100;
 Minibatch[ 701- 800]: loss = 0.459973 * 100, metric = 9.41% * 100;
 Minibatch[ 801- 900]: loss = 0.445728 * 100, metric = 8.74% * 100;
 Minibatch[ 901-1000]: loss = 0.450945 * 100, metric = 9.31% * 100;
 Minibatch[1001-1100]: loss = 0.451819 * 100, metric = 9.26% * 100;
 Minibatch[1101-1200]: loss = 0.462172 * 100, metric = 9.42% * 100;
 Minibatch[1201-1300]: loss = 0.439296 * 100, metric = 8.81% * 100;
 Minibatch[1301-1400]: loss = 0.431038 * 100, metric = 8.30% * 100;
 Minibatch[1401-1500]: loss = 0.458073 * 100, metric = 9.26% * 100;
 Minibatch[1501-1600]: loss = 0.471645 * 100, metric = 9.66% * 100;
 Minibatch[1601-1700]: loss = 0.468974 * 100, metric = 9.53% * 100;
 Minibatch[1701-1800]: loss = 0.441342 * 100, metric = 8.69% * 100;
 Minibatch[1801-1900]: loss = 0.456105 * 100, metric = 9.05% * 100;
 Minibatch[1901-2000]: loss = 0.445005 * 100, metric = 8.92% * 100;
Finished Epoch[61 of 200]: [Training] loss = 0.451784 * 2000, metric = 9.10% * 2000 636.446s (  3.1 samples/s);
Finished Evaluation [61]: Minibatch[1-1000]: metric = 15.17% * 1000;
 Minibatch[   1- 100]: loss = 0.446479 * 100, metric = 8.87% * 100;
 Minibatch[ 101- 200]: loss = 0.443133 * 100, metric = 8.77% * 100;
 Minibatch[ 201- 300]: loss = 0.440206 * 100, metric = 8.97% * 100;
 Minibatch[ 301- 400]: loss = 0.456795 * 100, metric = 9.23% * 100;
 Minibatch[ 401- 500]: loss = 0.449049 * 100, metric = 8.98% * 100;
 Minibatch[ 501- 600]: loss = 0.451415 * 100, metric = 8.98% * 100;
 Minibatch[ 601- 700]: loss = 0.458214 * 100, metric = 9.09% * 100;
 Minibatch[ 701- 800]: loss = 0.441449 * 100, metric = 8.97% * 100;
 Minibatch[ 801- 900]: loss = 0.459521 * 100, metric = 9.31% * 100;
 Minibatch[ 901-1000]: loss = 0.456117 * 100, metric = 9.27% * 100;
 Minibatch[1001-1100]: loss = 0.423042 * 100, metric = 8.37% * 100;
 Minibatch[1101-1200]: loss = 0.470073 * 100, metric = 9.63% * 100;
 Minibatch[1201-1300]: loss = 0.448583 * 100, metric = 9.05% * 100;
 Minibatch[1301-1400]: loss = 0.469228 * 100, metric = 9.36% * 100;
 Minibatch[1401-1500]: loss = 0.441423 * 100, metric = 8.79% * 100;
 Minibatch[1501-1600]: loss = 0.441317 * 100, metric = 8.69% * 100;
 Minibatch[1601-1700]: loss = 0.454697 * 100, metric = 9.05% * 100;
 Minibatch[1701-1800]: loss = 0.457303 * 100, metric = 9.29% * 100;
 Minibatch[1801-1900]: loss = 0.465408 * 100, metric = 9.34% * 100;
 Minibatch[1901-2000]: loss = 0.456706 * 100, metric = 9.39% * 100;
Finished Epoch[62 of 200]: [Training] loss = 0.451508 * 2000, metric = 9.07% * 2000 640.805s (  3.1 samples/s);
Finished Evaluation [62]: Minibatch[1-1000]: metric = 14.93% * 1000;
 Minibatch[   1- 100]: loss = 0.447733 * 100, metric = 9.23% * 100;
 Minibatch[ 101- 200]: loss = 0.438382 * 100, metric = 8.74% * 100;
 Minibatch[ 201- 300]: loss = 0.465712 * 100, metric = 9.44% * 100;
 Minibatch[ 301- 400]: loss = 0.433781 * 100, metric = 8.87% * 100;
 Minibatch[ 401- 500]: loss = 0.436383 * 100, metric = 8.67% * 100;
 Minibatch[ 501- 600]: loss = 0.442033 * 100, metric = 8.73% * 100;
 Minibatch[ 601- 700]: loss = 0.449957 * 100, metric = 9.12% * 100;
 Minibatch[ 701- 800]: loss = 0.443167 * 100, metric = 9.19% * 100;
 Minibatch[ 801- 900]: loss = 0.447107 * 100, metric = 9.02% * 100;
 Minibatch[ 901-1000]: loss = 0.429772 * 100, metric = 8.61% * 100;
 Minibatch[1001-1100]: loss = 0.461958 * 100, metric = 9.39% * 100;
 Minibatch[1101-1200]: loss = 0.436754 * 100, metric = 8.77% * 100;
 Minibatch[1201-1300]: loss = 0.453190 * 100, metric = 9.11% * 100;
 Minibatch[1301-1400]: loss = 0.455039 * 100, metric = 9.13% * 100;
 Minibatch[1401-1500]: loss = 0.434684 * 100, metric = 8.79% * 100;
 Minibatch[1501-1600]: loss = 0.453968 * 100, metric = 9.35% * 100;
 Minibatch[1601-1700]: loss = 0.452471 * 100, metric = 9.20% * 100;
 Minibatch[1701-1800]: loss = 0.447863 * 100, metric = 9.00% * 100;
 Minibatch[1801-1900]: loss = 0.447239 * 100, metric = 8.71% * 100;
 Minibatch[1901-2000]: loss = 0.457361 * 100, metric = 9.34% * 100;
Finished Epoch[63 of 200]: [Training] loss = 0.446728 * 2000, metric = 9.02% * 2000 650.820s (  3.1 samples/s);
Finished Evaluation [63]: Minibatch[1-1000]: metric = 14.82% * 1000;
 Minibatch[   1- 100]: loss = 0.449661 * 100, metric = 8.93% * 100;
 Minibatch[ 101- 200]: loss = 0.451340 * 100, metric = 9.20% * 100;
 Minibatch[ 201- 300]: loss = 0.459511 * 100, metric = 9.42% * 100;
 Minibatch[ 301- 400]: loss = 0.455383 * 100, metric = 9.21% * 100;
 Minibatch[ 401- 500]: loss = 0.448386 * 100, metric = 8.97% * 100;
 Minibatch[ 501- 600]: loss = 0.445335 * 100, metric = 8.84% * 100;
 Minibatch[ 601- 700]: loss = 0.441429 * 100, metric = 8.68% * 100;
 Minibatch[ 701- 800]: loss = 0.469741 * 100, metric = 9.37% * 100;
 Minibatch[ 801- 900]: loss = 0.454827 * 100, metric = 9.27% * 100;
 Minibatch[ 901-1000]: loss = 0.452300 * 100, metric = 9.01% * 100;
 Minibatch[1001-1100]: loss = 0.447322 * 100, metric = 8.86% * 100;
 Minibatch[1101-1200]: loss = 0.453679 * 100, metric = 9.22% * 100;
 Minibatch[1201-1300]: loss = 0.436945 * 100, metric = 8.65% * 100;
 Minibatch[1301-1400]: loss = 0.459167 * 100, metric = 9.47% * 100;
 Minibatch[1401-1500]: loss = 0.456234 * 100, metric = 9.31% * 100;
 Minibatch[1501-1600]: loss = 0.461371 * 100, metric = 9.42% * 100;
 Minibatch[1601-1700]: loss = 0.438168 * 100, metric = 8.79% * 100;
 Minibatch[1701-1800]: loss = 0.449885 * 100, metric = 8.97% * 100;
 Minibatch[1801-1900]: loss = 0.461075 * 100, metric = 9.46% * 100;
 Minibatch[1901-2000]: loss = 0.453553 * 100, metric = 9.25% * 100;
Finished Epoch[64 of 200]: [Training] loss = 0.452266 * 2000, metric = 9.11% * 2000 652.101s (  3.1 samples/s);
Finished Evaluation [64]: Minibatch[1-1000]: metric = 15.76% * 1000;
 Minibatch[   1- 100]: loss = 0.436095 * 100, metric = 8.94% * 100;
 Minibatch[ 101- 200]: loss = 0.439431 * 100, metric = 8.77% * 100;
 Minibatch[ 201- 300]: loss = 0.451781 * 100, metric = 9.18% * 100;
 Minibatch[ 301- 400]: loss = 0.452907 * 100, metric = 9.41% * 100;
 Minibatch[ 401- 500]: loss = 0.449329 * 100, metric = 8.75% * 100;
 Minibatch[ 501- 600]: loss = 0.452900 * 100, metric = 9.14% * 100;
 Minibatch[ 601- 700]: loss = 0.460822 * 100, metric = 9.47% * 100;
 Minibatch[ 701- 800]: loss = 0.467833 * 100, metric = 9.66% * 100;
 Minibatch[ 801- 900]: loss = 0.446098 * 100, metric = 9.25% * 100;
 Minibatch[ 901-1000]: loss = 0.449094 * 100, metric = 9.16% * 100;
 Minibatch[1001-1100]: loss = 0.459578 * 100, metric = 9.51% * 100;
 Minibatch[1101-1200]: loss = 0.458871 * 100, metric = 9.38% * 100;
 Minibatch[1201-1300]: loss = 0.460714 * 100, metric = 9.17% * 100;
 Minibatch[1301-1400]: loss = 0.450475 * 100, metric = 9.18% * 100;
 Minibatch[1401-1500]: loss = 0.448927 * 100, metric = 8.97% * 100;
 Minibatch[1501-1600]: loss = 0.438279 * 100, metric = 8.98% * 100;
 Minibatch[1601-1700]: loss = 0.463215 * 100, metric = 9.31% * 100;
 Minibatch[1701-1800]: loss = 0.455797 * 100, metric = 9.30% * 100;
 Minibatch[1801-1900]: loss = 0.462593 * 100, metric = 9.43% * 100;
 Minibatch[1901-2000]: loss = 0.452781 * 100, metric = 9.12% * 100;
Finished Epoch[65 of 200]: [Training] loss = 0.452876 * 2000, metric = 9.20% * 2000 650.552s (  3.1 samples/s);
Finished Evaluation [65]: Minibatch[1-1000]: metric = 14.50% * 1000;
 Minibatch[   1- 100]: loss = 0.449971 * 100, metric = 9.00% * 100;
 Minibatch[ 101- 200]: loss = 0.456111 * 100, metric = 9.20% * 100;
 Minibatch[ 201- 300]: loss = 0.450374 * 100, metric = 9.07% * 100;
 Minibatch[ 301- 400]: loss = 0.446217 * 100, metric = 9.04% * 100;
 Minibatch[ 401- 500]: loss = 0.450847 * 100, metric = 9.09% * 100;
 Minibatch[ 501- 600]: loss = 0.435004 * 100, metric = 8.83% * 100;
 Minibatch[ 601- 700]: loss = 0.436957 * 100, metric = 8.70% * 100;
 Minibatch[ 701- 800]: loss = 0.457404 * 100, metric = 9.39% * 100;
 Minibatch[ 801- 900]: loss = 0.414488 * 100, metric = 8.08% * 100;
 Minibatch[ 901-1000]: loss = 0.429236 * 100, metric = 8.43% * 100;
 Minibatch[1001-1100]: loss = 0.449883 * 100, metric = 9.28% * 100;
 Minibatch[1101-1200]: loss = 0.454400 * 100, metric = 9.24% * 100;
 Minibatch[1201-1300]: loss = 0.454889 * 100, metric = 9.39% * 100;
 Minibatch[1301-1400]: loss = 0.448743 * 100, metric = 9.01% * 100;
 Minibatch[1401-1500]: loss = 0.439772 * 100, metric = 8.75% * 100;
 Minibatch[1501-1600]: loss = 0.450164 * 100, metric = 9.22% * 100;
 Minibatch[1601-1700]: loss = 0.458531 * 100, metric = 9.23% * 100;
 Minibatch[1701-1800]: loss = 0.454735 * 100, metric = 9.19% * 100;
 Minibatch[1801-1900]: loss = 0.447378 * 100, metric = 9.13% * 100;
 Minibatch[1901-2000]: loss = 0.450007 * 100, metric = 8.95% * 100;
Finished Epoch[66 of 200]: [Training] loss = 0.446756 * 2000, metric = 9.01% * 2000 646.065s (  3.1 samples/s);
Finished Evaluation [66]: Minibatch[1-1000]: metric = 14.82% * 1000;
 Minibatch[   1- 100]: loss = 0.455077 * 100, metric = 9.10% * 100;
 Minibatch[ 101- 200]: loss = 0.444715 * 100, metric = 8.91% * 100;
 Minibatch[ 201- 300]: loss = 0.446520 * 100, metric = 9.17% * 100;
 Minibatch[ 301- 400]: loss = 0.460952 * 100, metric = 9.74% * 100;
 Minibatch[ 401- 500]: loss = 0.450609 * 100, metric = 9.20% * 100;
 Minibatch[ 501- 600]: loss = 0.452858 * 100, metric = 9.29% * 100;
 Minibatch[ 601- 700]: loss = 0.445872 * 100, metric = 9.04% * 100;
 Minibatch[ 701- 800]: loss = 0.466227 * 100, metric = 9.59% * 100;
 Minibatch[ 801- 900]: loss = 0.449414 * 100, metric = 9.11% * 100;
 Minibatch[ 901-1000]: loss = 0.453546 * 100, metric = 9.11% * 100;
 Minibatch[1001-1100]: loss = 0.443285 * 100, metric = 9.11% * 100;
 Minibatch[1101-1200]: loss = 0.446719 * 100, metric = 8.75% * 100;
 Minibatch[1201-1300]: loss = 0.450688 * 100, metric = 9.15% * 100;
 Minibatch[1301-1400]: loss = 0.456608 * 100, metric = 9.23% * 100;
 Minibatch[1401-1500]: loss = 0.434722 * 100, metric = 8.48% * 100;
 Minibatch[1501-1600]: loss = 0.442458 * 100, metric = 8.97% * 100;
 Minibatch[1601-1700]: loss = 0.441835 * 100, metric = 8.88% * 100;
 Minibatch[1701-1800]: loss = 0.461454 * 100, metric = 9.61% * 100;
 Minibatch[1801-1900]: loss = 0.441163 * 100, metric = 9.02% * 100;
 Minibatch[1901-2000]: loss = 0.465422 * 100, metric = 9.64% * 100;
Finished Epoch[67 of 200]: [Training] loss = 0.450507 * 2000, metric = 9.15% * 2000 648.364s (  3.1 samples/s);
Finished Evaluation [67]: Minibatch[1-1000]: metric = 15.08% * 1000;
 Minibatch[   1- 100]: loss = 0.436517 * 100, metric = 8.54% * 100;
 Minibatch[ 101- 200]: loss = 0.455378 * 100, metric = 9.17% * 100;
 Minibatch[ 201- 300]: loss = 0.454216 * 100, metric = 9.34% * 100;
 Minibatch[ 301- 400]: loss = 0.449930 * 100, metric = 9.13% * 100;
 Minibatch[ 401- 500]: loss = 0.452198 * 100, metric = 8.92% * 100;
 Minibatch[ 501- 600]: loss = 0.447410 * 100, metric = 9.28% * 100;
 Minibatch[ 601- 700]: loss = 0.444149 * 100, metric = 8.99% * 100;
 Minibatch[ 701- 800]: loss = 0.449778 * 100, metric = 9.07% * 100;
 Minibatch[ 801- 900]: loss = 0.428798 * 100, metric = 8.37% * 100;
 Minibatch[ 901-1000]: loss = 0.435737 * 100, metric = 8.65% * 100;
 Minibatch[1001-1100]: loss = 0.458774 * 100, metric = 9.17% * 100;
 Minibatch[1101-1200]: loss = 0.461869 * 100, metric = 9.37% * 100;
 Minibatch[1201-1300]: loss = 0.444673 * 100, metric = 8.84% * 100;
 Minibatch[1301-1400]: loss = 0.423054 * 100, metric = 8.64% * 100;
 Minibatch[1401-1500]: loss = 0.428804 * 100, metric = 8.82% * 100;
 Minibatch[1501-1600]: loss = 0.442418 * 100, metric = 8.89% * 100;
 Minibatch[1601-1700]: loss = 0.440483 * 100, metric = 8.82% * 100;
 Minibatch[1701-1800]: loss = 0.450233 * 100, metric = 9.03% * 100;
 Minibatch[1801-1900]: loss = 0.446803 * 100, metric = 9.19% * 100;
 Minibatch[1901-2000]: loss = 0.434757 * 100, metric = 8.76% * 100;
Finished Epoch[68 of 200]: [Training] loss = 0.444299 * 2000, metric = 8.95% * 2000 639.553s (  3.1 samples/s);
Finished Evaluation [68]: Minibatch[1-1000]: metric = 14.06% * 1000;
 Minibatch[   1- 100]: loss = 0.437580 * 100, metric = 8.95% * 100;
 Minibatch[ 101- 200]: loss = 0.453393 * 100, metric = 9.40% * 100;
 Minibatch[ 201- 300]: loss = 0.432908 * 100, metric = 8.73% * 100;
 Minibatch[ 301- 400]: loss = 0.450294 * 100, metric = 9.35% * 100;
 Minibatch[ 401- 500]: loss = 0.454687 * 100, metric = 9.21% * 100;
 Minibatch[ 501- 600]: loss = 0.449993 * 100, metric = 9.30% * 100;
 Minibatch[ 601- 700]: loss = 0.440882 * 100, metric = 8.90% * 100;
 Minibatch[ 701- 800]: loss = 0.451797 * 100, metric = 9.32% * 100;
 Minibatch[ 801- 900]: loss = 0.434807 * 100, metric = 8.96% * 100;
 Minibatch[ 901-1000]: loss = 0.448515 * 100, metric = 8.92% * 100;
 Minibatch[1001-1100]: loss = 0.440921 * 100, metric = 8.81% * 100;
 Minibatch[1101-1200]: loss = 0.423943 * 100, metric = 8.11% * 100;
 Minibatch[1201-1300]: loss = 0.462874 * 100, metric = 9.46% * 100;
 Minibatch[1301-1400]: loss = 0.455228 * 100, metric = 9.37% * 100;
 Minibatch[1401-1500]: loss = 0.452905 * 100, metric = 9.11% * 100;
 Minibatch[1501-1600]: loss = 0.437439 * 100, metric = 8.67% * 100;
 Minibatch[1601-1700]: loss = 0.451821 * 100, metric = 9.21% * 100;
 Minibatch[1701-1800]: loss = 0.454109 * 100, metric = 9.35% * 100;
 Minibatch[1801-1900]: loss = 0.435891 * 100, metric = 8.62% * 100;
 Minibatch[1901-2000]: loss = 0.440108 * 100, metric = 8.89% * 100;
Finished Epoch[69 of 200]: [Training] loss = 0.445505 * 2000, metric = 9.03% * 2000 632.392s (  3.2 samples/s);
Finished Evaluation [69]: Minibatch[1-1000]: metric = 14.27% * 1000;
 Minibatch[   1- 100]: loss = 0.442193 * 100, metric = 8.99% * 100;
 Minibatch[ 101- 200]: loss = 0.424247 * 100, metric = 8.56% * 100;
 Minibatch[ 201- 300]: loss = 0.443192 * 100, metric = 8.86% * 100;
 Minibatch[ 301- 400]: loss = 0.435697 * 100, metric = 8.87% * 100;
 Minibatch[ 401- 500]: loss = 0.443776 * 100, metric = 9.08% * 100;
 Minibatch[ 501- 600]: loss = 0.458730 * 100, metric = 9.30% * 100;
 Minibatch[ 601- 700]: loss = 0.442215 * 100, metric = 8.72% * 100;
 Minibatch[ 701- 800]: loss = 0.450154 * 100, metric = 9.19% * 100;
 Minibatch[ 801- 900]: loss = 0.436958 * 100, metric = 8.70% * 100;
 Minibatch[ 901-1000]: loss = 0.447080 * 100, metric = 9.18% * 100;
 Minibatch[1001-1100]: loss = 0.432699 * 100, metric = 8.56% * 100;
 Minibatch[1101-1200]: loss = 0.431013 * 100, metric = 8.78% * 100;
 Minibatch[1201-1300]: loss = 0.442188 * 100, metric = 9.03% * 100;
 Minibatch[1301-1400]: loss = 0.457739 * 100, metric = 9.17% * 100;
 Minibatch[1401-1500]: loss = 0.436295 * 100, metric = 8.72% * 100;
 Minibatch[1501-1600]: loss = 0.451910 * 100, metric = 9.07% * 100;
 Minibatch[1601-1700]: loss = 0.461111 * 100, metric = 9.41% * 100;
 Minibatch[1701-1800]: loss = 0.448850 * 100, metric = 9.12% * 100;
 Minibatch[1801-1900]: loss = 0.433306 * 100, metric = 8.66% * 100;
 Minibatch[1901-2000]: loss = 0.447341 * 100, metric = 9.21% * 100;
Finished Epoch[70 of 200]: [Training] loss = 0.443335 * 2000, metric = 8.96% * 2000 638.020s (  3.1 samples/s);
Finished Evaluation [70]: Minibatch[1-1000]: metric = 14.27% * 1000;
 Minibatch[   1- 100]: loss = 0.459506 * 100, metric = 9.46% * 100;
 Minibatch[ 101- 200]: loss = 0.442020 * 100, metric = 8.75% * 100;
 Minibatch[ 201- 300]: loss = 0.445559 * 100, metric = 9.18% * 100;
 Minibatch[ 301- 400]: loss = 0.443317 * 100, metric = 8.75% * 100;
 Minibatch[ 401- 500]: loss = 0.436026 * 100, metric = 9.07% * 100;
 Minibatch[ 501- 600]: loss = 0.441408 * 100, metric = 8.69% * 100;
 Minibatch[ 601- 700]: loss = 0.422889 * 100, metric = 8.26% * 100;
 Minibatch[ 701- 800]: loss = 0.447243 * 100, metric = 9.07% * 100;
 Minibatch[ 801- 900]: loss = 0.444099 * 100, metric = 8.97% * 100;
 Minibatch[ 901-1000]: loss = 0.440705 * 100, metric = 8.69% * 100;
 Minibatch[1001-1100]: loss = 0.443881 * 100, metric = 8.96% * 100;
 Minibatch[1101-1200]: loss = 0.436931 * 100, metric = 8.69% * 100;
 Minibatch[1201-1300]: loss = 0.431463 * 100, metric = 8.68% * 100;
 Minibatch[1301-1400]: loss = 0.432610 * 100, metric = 8.79% * 100;
 Minibatch[1401-1500]: loss = 0.449169 * 100, metric = 9.16% * 100;
 Minibatch[1501-1600]: loss = 0.462128 * 100, metric = 9.44% * 100;
 Minibatch[1601-1700]: loss = 0.441994 * 100, metric = 8.86% * 100;
 Minibatch[1701-1800]: loss = 0.448171 * 100, metric = 8.90% * 100;
 Minibatch[1801-1900]: loss = 0.437177 * 100, metric = 8.69% * 100;
 Minibatch[1901-2000]: loss = 0.448224 * 100, metric = 8.94% * 100;
Finished Epoch[71 of 200]: [Training] loss = 0.442726 * 2000, metric = 8.90% * 2000 634.298s (  3.2 samples/s);
Finished Evaluation [71]: Minibatch[1-1000]: metric = 13.78% * 1000;
0.5090592189580202
 Minibatch[   1- 100]: loss = 0.450200 * 100, metric = 9.28% * 100;
 Minibatch[ 101- 200]: loss = 0.447649 * 100, metric = 8.92% * 100;
 Minibatch[ 201- 300]: loss = 0.433654 * 100, metric = 8.65% * 100;
 Minibatch[ 301- 400]: loss = 0.438973 * 100, metric = 9.00% * 100;
 Minibatch[ 401- 500]: loss = 0.437103 * 100, metric = 8.93% * 100;
 Minibatch[ 501- 600]: loss = 0.434500 * 100, metric = 8.72% * 100;
 Minibatch[ 601- 700]: loss = 0.438649 * 100, metric = 8.92% * 100;
 Minibatch[ 701- 800]: loss = 0.448948 * 100, metric = 9.24% * 100;
 Minibatch[ 801- 900]: loss = 0.431255 * 100, metric = 8.79% * 100;
 Minibatch[ 901-1000]: loss = 0.430480 * 100, metric = 8.84% * 100;
 Minibatch[1001-1100]: loss = 0.445072 * 100, metric = 9.04% * 100;
 Minibatch[1101-1200]: loss = 0.433227 * 100, metric = 8.68% * 100;
 Minibatch[1201-1300]: loss = 0.430933 * 100, metric = 8.49% * 100;
 Minibatch[1301-1400]: loss = 0.441317 * 100, metric = 8.93% * 100;
 Minibatch[1401-1500]: loss = 0.445574 * 100, metric = 8.79% * 100;
 Minibatch[1501-1600]: loss = 0.445319 * 100, metric = 8.96% * 100;
 Minibatch[1601-1700]: loss = 0.443279 * 100, metric = 8.92% * 100;
 Minibatch[1701-1800]: loss = 0.433217 * 100, metric = 8.62% * 100;
 Minibatch[1801-1900]: loss = 0.434075 * 100, metric = 8.69% * 100;
 Minibatch[1901-2000]: loss = 0.439705 * 100, metric = 8.78% * 100;
Finished Epoch[72 of 200]: [Training] loss = 0.439156 * 2000, metric = 8.86% * 2000 647.918s (  3.1 samples/s);
Finished Evaluation [72]: Minibatch[1-1000]: metric = 14.96% * 1000;
 Minibatch[   1- 100]: loss = 0.440059 * 100, metric = 8.95% * 100;
 Minibatch[ 101- 200]: loss = 0.435450 * 100, metric = 8.56% * 100;
 Minibatch[ 201- 300]: loss = 0.430651 * 100, metric = 8.59% * 100;
 Minibatch[ 301- 400]: loss = 0.443545 * 100, metric = 8.89% * 100;
 Minibatch[ 401- 500]: loss = 0.431700 * 100, metric = 8.54% * 100;
 Minibatch[ 501- 600]: loss = 0.433702 * 100, metric = 8.77% * 100;
 Minibatch[ 601- 700]: loss = 0.417202 * 100, metric = 8.16% * 100;
 Minibatch[ 701- 800]: loss = 0.426519 * 100, metric = 8.61% * 100;
 Minibatch[ 801- 900]: loss = 0.441289 * 100, metric = 8.73% * 100;
 Minibatch[ 901-1000]: loss = 0.442228 * 100, metric = 8.79% * 100;
 Minibatch[1001-1100]: loss = 0.432476 * 100, metric = 8.53% * 100;
 Minibatch[1101-1200]: loss = 0.424224 * 100, metric = 8.48% * 100;
 Minibatch[1201-1300]: loss = 0.456142 * 100, metric = 9.21% * 100;
 Minibatch[1301-1400]: loss = 0.441777 * 100, metric = 8.89% * 100;
 Minibatch[1401-1500]: loss = 0.444677 * 100, metric = 9.10% * 100;
 Minibatch[1501-1600]: loss = 0.442538 * 100, metric = 9.05% * 100;
 Minibatch[1601-1700]: loss = 0.451943 * 100, metric = 9.10% * 100;
 Minibatch[1701-1800]: loss = 0.435101 * 100, metric = 8.82% * 100;
 Minibatch[1801-1900]: loss = 0.433947 * 100, metric = 8.78% * 100;
 Minibatch[1901-2000]: loss = 0.449083 * 100, metric = 9.20% * 100;
Finished Epoch[73 of 200]: [Training] loss = 0.437713 * 2000, metric = 8.79% * 2000 653.041s (  3.1 samples/s);
Finished Evaluation [73]: Minibatch[1-1000]: metric = 13.57% * 1000;
0.5081803754046559
 Minibatch[   1- 100]: loss = 0.419216 * 100, metric = 8.60% * 100;
 Minibatch[ 101- 200]: loss = 0.439984 * 100, metric = 8.99% * 100;
 Minibatch[ 201- 300]: loss = 0.428653 * 100, metric = 8.52% * 100;
 Minibatch[ 301- 400]: loss = 0.437638 * 100, metric = 8.86% * 100;
 Minibatch[ 401- 500]: loss = 0.438271 * 100, metric = 9.10% * 100;
 Minibatch[ 501- 600]: loss = 0.443604 * 100, metric = 9.03% * 100;
 Minibatch[ 601- 700]: loss = 0.436962 * 100, metric = 8.83% * 100;
 Minibatch[ 701- 800]: loss = 0.429708 * 100, metric = 8.62% * 100;
 Minibatch[ 801- 900]: loss = 0.449641 * 100, metric = 9.25% * 100;
 Minibatch[ 901-1000]: loss = 0.456129 * 100, metric = 9.34% * 100;
 Minibatch[1001-1100]: loss = 0.443588 * 100, metric = 9.01% * 100;
 Minibatch[1101-1200]: loss = 0.456884 * 100, metric = 9.45% * 100;
 Minibatch[1201-1300]: loss = 0.426127 * 100, metric = 8.63% * 100;
 Minibatch[1301-1400]: loss = 0.429103 * 100, metric = 8.54% * 100;
 Minibatch[1401-1500]: loss = 0.415950 * 100, metric = 8.23% * 100;
 Minibatch[1501-1600]: loss = 0.448290 * 100, metric = 9.09% * 100;
 Minibatch[1601-1700]: loss = 0.421603 * 100, metric = 8.40% * 100;
 Minibatch[1701-1800]: loss = 0.431420 * 100, metric = 8.44% * 100;
 Minibatch[1801-1900]: loss = 0.423020 * 100, metric = 8.42% * 100;
 Minibatch[1901-2000]: loss = 0.454394 * 100, metric = 9.38% * 100;
Finished Epoch[74 of 200]: [Training] loss = 0.436509 * 2000, metric = 8.84% * 2000 654.583s (  3.1 samples/s);
Finished Evaluation [74]: Minibatch[1-1000]: metric = 14.14% * 1000;
 Minibatch[   1- 100]: loss = 0.428594 * 100, metric = 8.47% * 100;
 Minibatch[ 101- 200]: loss = 0.448676 * 100, metric = 9.28% * 100;
 Minibatch[ 201- 300]: loss = 0.430508 * 100, metric = 8.61% * 100;
 Minibatch[ 301- 400]: loss = 0.428291 * 100, metric = 8.57% * 100;
 Minibatch[ 401- 500]: loss = 0.434212 * 100, metric = 8.58% * 100;
 Minibatch[ 501- 600]: loss = 0.431617 * 100, metric = 8.54% * 100;
 Minibatch[ 601- 700]: loss = 0.446411 * 100, metric = 8.97% * 100;
 Minibatch[ 701- 800]: loss = 0.443894 * 100, metric = 8.90% * 100;
 Minibatch[ 801- 900]: loss = 0.428296 * 100, metric = 8.70% * 100;
 Minibatch[ 901-1000]: loss = 0.428765 * 100, metric = 8.36% * 100;
 Minibatch[1001-1100]: loss = 0.432805 * 100, metric = 8.66% * 100;
 Minibatch[1101-1200]: loss = 0.431428 * 100, metric = 8.82% * 100;
 Minibatch[1201-1300]: loss = 0.438361 * 100, metric = 9.15% * 100;
 Minibatch[1301-1400]: loss = 0.420716 * 100, metric = 8.35% * 100;
 Minibatch[1401-1500]: loss = 0.420703 * 100, metric = 8.50% * 100;
 Minibatch[1501-1600]: loss = 0.430021 * 100, metric = 8.49% * 100;
 Minibatch[1601-1700]: loss = 0.436846 * 100, metric = 9.06% * 100;
 Minibatch[1701-1800]: loss = 0.434692 * 100, metric = 8.90% * 100;
 Minibatch[1801-1900]: loss = 0.430283 * 100, metric = 8.59% * 100;
 Minibatch[1901-2000]: loss = 0.433706 * 100, metric = 8.63% * 100;
Finished Epoch[75 of 200]: [Training] loss = 0.432941 * 2000, metric = 8.71% * 2000 655.777s (  3.0 samples/s);
Finished Evaluation [75]: Minibatch[1-1000]: metric = 14.07% * 1000;
 Minibatch[   1- 100]: loss = 0.421375 * 100, metric = 8.30% * 100;
 Minibatch[ 101- 200]: loss = 0.444529 * 100, metric = 8.86% * 100;
 Minibatch[ 201- 300]: loss = 0.444874 * 100, metric = 9.03% * 100;
 Minibatch[ 301- 400]: loss = 0.431245 * 100, metric = 8.61% * 100;
 Minibatch[ 401- 500]: loss = 0.427845 * 100, metric = 8.54% * 100;
 Minibatch[ 501- 600]: loss = 0.409906 * 100, metric = 8.01% * 100;
 Minibatch[ 601- 700]: loss = 0.423138 * 100, metric = 8.43% * 100;
 Minibatch[ 701- 800]: loss = 0.411343 * 100, metric = 8.01% * 100;
 Minibatch[ 801- 900]: loss = 0.448353 * 100, metric = 9.22% * 100;
 Minibatch[ 901-1000]: loss = 0.442405 * 100, metric = 8.91% * 100;
 Minibatch[1001-1100]: loss = 0.435715 * 100, metric = 8.91% * 100;
 Minibatch[1101-1200]: loss = 0.431707 * 100, metric = 8.46% * 100;
 Minibatch[1201-1300]: loss = 0.429528 * 100, metric = 8.75% * 100;
 Minibatch[1301-1400]: loss = 0.444581 * 100, metric = 9.07% * 100;
 Minibatch[1401-1500]: loss = 0.439696 * 100, metric = 8.68% * 100;
 Minibatch[1501-1600]: loss = 0.431642 * 100, metric = 8.54% * 100;
 Minibatch[1601-1700]: loss = 0.434333 * 100, metric = 8.52% * 100;
 Minibatch[1701-1800]: loss = 0.415497 * 100, metric = 8.31% * 100;
 Minibatch[1801-1900]: loss = 0.438862 * 100, metric = 8.89% * 100;
 Minibatch[1901-2000]: loss = 0.423434 * 100, metric = 8.42% * 100;
Finished Epoch[76 of 200]: [Training] loss = 0.431501 * 2000, metric = 8.62% * 2000 654.631s (  3.1 samples/s);
Finished Evaluation [76]: Minibatch[1-1000]: metric = 14.06% * 1000;
 Minibatch[   1- 100]: loss = 0.436884 * 100, metric = 8.71% * 100;
 Minibatch[ 101- 200]: loss = 0.434800 * 100, metric = 8.58% * 100;
 Minibatch[ 201- 300]: loss = 0.416589 * 100, metric = 8.33% * 100;
 Minibatch[ 301- 400]: loss = 0.441199 * 100, metric = 8.88% * 100;
 Minibatch[ 401- 500]: loss = 0.436454 * 100, metric = 8.86% * 100;
 Minibatch[ 501- 600]: loss = 0.419667 * 100, metric = 8.31% * 100;
 Minibatch[ 601- 700]: loss = 0.443139 * 100, metric = 8.93% * 100;
 Minibatch[ 701- 800]: loss = 0.433536 * 100, metric = 8.59% * 100;
 Minibatch[ 801- 900]: loss = 0.421216 * 100, metric = 8.50% * 100;
 Minibatch[ 901-1000]: loss = 0.436308 * 100, metric = 8.84% * 100;
 Minibatch[1001-1100]: loss = 0.428872 * 100, metric = 8.40% * 100;
 Minibatch[1101-1200]: loss = 0.428594 * 100, metric = 8.42% * 100;
 Minibatch[1201-1300]: loss = 0.444010 * 100, metric = 9.13% * 100;
 Minibatch[1301-1400]: loss = 0.424413 * 100, metric = 8.60% * 100;
 Minibatch[1401-1500]: loss = 0.444986 * 100, metric = 8.99% * 100;
 Minibatch[1501-1600]: loss = 0.440189 * 100, metric = 8.99% * 100;
 Minibatch[1601-1700]: loss = 0.424677 * 100, metric = 8.53% * 100;
 Minibatch[1701-1800]: loss = 0.416947 * 100, metric = 8.29% * 100;
 Minibatch[1801-1900]: loss = 0.440649 * 100, metric = 8.99% * 100;
 Minibatch[1901-2000]: loss = 0.433312 * 100, metric = 8.92% * 100;
Finished Epoch[77 of 200]: [Training] loss = 0.432322 * 2000, metric = 8.69% * 2000 656.630s (  3.0 samples/s);
Finished Evaluation [77]: Minibatch[1-1000]: metric = 13.76% * 1000;
 Minibatch[   1- 100]: loss = 0.427122 * 100, metric = 8.68% * 100;
 Minibatch[ 101- 200]: loss = 0.422618 * 100, metric = 8.45% * 100;
 Minibatch[ 201- 300]: loss = 0.406553 * 100, metric = 8.12% * 100;
 Minibatch[ 301- 400]: loss = 0.427784 * 100, metric = 8.54% * 100;
 Minibatch[ 401- 500]: loss = 0.448881 * 100, metric = 8.87% * 100;
 Minibatch[ 501- 600]: loss = 0.436343 * 100, metric = 9.02% * 100;
 Minibatch[ 601- 700]: loss = 0.426886 * 100, metric = 8.61% * 100;
 Minibatch[ 701- 800]: loss = 0.437735 * 100, metric = 8.55% * 100;
 Minibatch[ 801- 900]: loss = 0.418848 * 100, metric = 8.34% * 100;
 Minibatch[ 901-1000]: loss = 0.438835 * 100, metric = 8.92% * 100;
 Minibatch[1001-1100]: loss = 0.439867 * 100, metric = 8.95% * 100;
 Minibatch[1101-1200]: loss = 0.433055 * 100, metric = 8.62% * 100;
 Minibatch[1201-1300]: loss = 0.449963 * 100, metric = 9.22% * 100;
 Minibatch[1301-1400]: loss = 0.423071 * 100, metric = 8.53% * 100;
 Minibatch[1401-1500]: loss = 0.438076 * 100, metric = 8.79% * 100;
 Minibatch[1501-1600]: loss = 0.433223 * 100, metric = 8.85% * 100;
 Minibatch[1601-1700]: loss = 0.433177 * 100, metric = 8.51% * 100;
 Minibatch[1701-1800]: loss = 0.430054 * 100, metric = 8.53% * 100;
 Minibatch[1801-1900]: loss = 0.444728 * 100, metric = 9.20% * 100;
 Minibatch[1901-2000]: loss = 0.449641 * 100, metric = 9.40% * 100;
Finished Epoch[78 of 200]: [Training] loss = 0.433323 * 2000, metric = 8.73% * 2000 651.683s (  3.1 samples/s);
Finished Evaluation [78]: Minibatch[1-1000]: metric = 15.30% * 1000;
 Minibatch[   1- 100]: loss = 0.435782 * 100, metric = 8.89% * 100;
 Minibatch[ 101- 200]: loss = 0.436837 * 100, metric = 8.87% * 100;
 Minibatch[ 201- 300]: loss = 0.437797 * 100, metric = 8.77% * 100;
 Minibatch[ 301- 400]: loss = 0.418515 * 100, metric = 8.19% * 100;
 Minibatch[ 401- 500]: loss = 0.442209 * 100, metric = 8.89% * 100;
 Minibatch[ 501- 600]: loss = 0.433935 * 100, metric = 8.79% * 100;
 Minibatch[ 601- 700]: loss = 0.432623 * 100, metric = 8.82% * 100;
 Minibatch[ 701- 800]: loss = 0.431963 * 100, metric = 8.65% * 100;
 Minibatch[ 801- 900]: loss = 0.440937 * 100, metric = 8.96% * 100;
 Minibatch[ 901-1000]: loss = 0.442657 * 100, metric = 9.03% * 100;
 Minibatch[1001-1100]: loss = 0.435887 * 100, metric = 8.71% * 100;
 Minibatch[1101-1200]: loss = 0.405793 * 100, metric = 7.91% * 100;
 Minibatch[1201-1300]: loss = 0.451650 * 100, metric = 9.23% * 100;
 Minibatch[1301-1400]: loss = 0.429464 * 100, metric = 8.55% * 100;
 Minibatch[1401-1500]: loss = 0.433667 * 100, metric = 8.92% * 100;
 Minibatch[1501-1600]: loss = 0.440375 * 100, metric = 8.91% * 100;
 Minibatch[1601-1700]: loss = 0.434891 * 100, metric = 8.58% * 100;
 Minibatch[1701-1800]: loss = 0.431192 * 100, metric = 8.75% * 100;
 Minibatch[1801-1900]: loss = 0.420658 * 100, metric = 8.49% * 100;
 Minibatch[1901-2000]: loss = 0.449894 * 100, metric = 9.20% * 100;
Finished Epoch[79 of 200]: [Training] loss = 0.434336 * 2000, metric = 8.76% * 2000 652.604s (  3.1 samples/s);
Finished Evaluation [79]: Minibatch[1-1000]: metric = 13.73% * 1000;
 Minibatch[   1- 100]: loss = 0.420416 * 100, metric = 8.29% * 100;
 Minibatch[ 101- 200]: loss = 0.431199 * 100, metric = 8.76% * 100;
 Minibatch[ 201- 300]: loss = 0.426291 * 100, metric = 8.53% * 100;
 Minibatch[ 301- 400]: loss = 0.417531 * 100, metric = 8.46% * 100;
 Minibatch[ 401- 500]: loss = 0.440490 * 100, metric = 8.87% * 100;
 Minibatch[ 501- 600]: loss = 0.434306 * 100, metric = 8.57% * 100;
 Minibatch[ 601- 700]: loss = 0.432677 * 100, metric = 8.74% * 100;
 Minibatch[ 701- 800]: loss = 0.431014 * 100, metric = 8.54% * 100;
 Minibatch[ 801- 900]: loss = 0.431609 * 100, metric = 8.59% * 100;
 Minibatch[ 901-1000]: loss = 0.418930 * 100, metric = 8.29% * 100;
 Minibatch[1001-1100]: loss = 0.425696 * 100, metric = 8.47% * 100;
 Minibatch[1101-1200]: loss = 0.425025 * 100, metric = 8.35% * 100;
 Minibatch[1201-1300]: loss = 0.417377 * 100, metric = 8.25% * 100;
 Minibatch[1301-1400]: loss = 0.426218 * 100, metric = 8.44% * 100;
 Minibatch[1401-1500]: loss = 0.415841 * 100, metric = 8.23% * 100;
 Minibatch[1501-1600]: loss = 0.427748 * 100, metric = 8.66% * 100;
 Minibatch[1601-1700]: loss = 0.438466 * 100, metric = 9.12% * 100;
 Minibatch[1701-1800]: loss = 0.426097 * 100, metric = 8.46% * 100;
 Minibatch[1801-1900]: loss = 0.434070 * 100, metric = 8.69% * 100;
 Minibatch[1901-2000]: loss = 0.427099 * 100, metric = 8.49% * 100;
Finished Epoch[80 of 200]: [Training] loss = 0.427405 * 2000, metric = 8.54% * 2000 661.597s (  3.0 samples/s);
Finished Evaluation [80]: Minibatch[1-1000]: metric = 14.53% * 1000;
 Minibatch[   1- 100]: loss = 0.423966 * 100, metric = 8.41% * 100;
 Minibatch[ 101- 200]: loss = 0.428576 * 100, metric = 8.53% * 100;
 Minibatch[ 201- 300]: loss = 0.432961 * 100, metric = 8.59% * 100;
 Minibatch[ 301- 400]: loss = 0.435866 * 100, metric = 8.76% * 100;
 Minibatch[ 401- 500]: loss = 0.423076 * 100, metric = 8.33% * 100;
 Minibatch[ 501- 600]: loss = 0.426549 * 100, metric = 8.37% * 100;
 Minibatch[ 601- 700]: loss = 0.445652 * 100, metric = 9.12% * 100;
 Minibatch[ 701- 800]: loss = 0.414952 * 100, metric = 8.19% * 100;
 Minibatch[ 801- 900]: loss = 0.439652 * 100, metric = 8.76% * 100;
 Minibatch[ 901-1000]: loss = 0.424117 * 100, metric = 8.45% * 100;
 Minibatch[1001-1100]: loss = 0.431486 * 100, metric = 8.77% * 100;
 Minibatch[1101-1200]: loss = 0.432171 * 100, metric = 8.80% * 100;
 Minibatch[1201-1300]: loss = 0.429656 * 100, metric = 8.65% * 100;
 Minibatch[1301-1400]: loss = 0.439915 * 100, metric = 8.92% * 100;
 Minibatch[1401-1500]: loss = 0.433551 * 100, metric = 8.51% * 100;
 Minibatch[1501-1600]: loss = 0.429889 * 100, metric = 8.46% * 100;
 Minibatch[1601-1700]: loss = 0.427843 * 100, metric = 8.65% * 100;
 Minibatch[1701-1800]: loss = 0.428635 * 100, metric = 8.62% * 100;
 Minibatch[1801-1900]: loss = 0.430109 * 100, metric = 8.48% * 100;
 Minibatch[1901-2000]: loss = 0.443042 * 100, metric = 9.00% * 100;
Finished Epoch[81 of 200]: [Training] loss = 0.431083 * 2000, metric = 8.62% * 2000 645.138s (  3.1 samples/s);
Finished Evaluation [81]: Minibatch[1-1000]: metric = 14.76% * 1000;
 Minibatch[   1- 100]: loss = 0.428116 * 100, metric = 8.85% * 100;
 Minibatch[ 101- 200]: loss = 0.426978 * 100, metric = 8.40% * 100;
 Minibatch[ 201- 300]: loss = 0.433961 * 100, metric = 8.67% * 100;
 Minibatch[ 301- 400]: loss = 0.438881 * 100, metric = 8.89% * 100;
 Minibatch[ 401- 500]: loss = 0.423466 * 100, metric = 8.43% * 100;
 Minibatch[ 501- 600]: loss = 0.421709 * 100, metric = 8.34% * 100;
 Minibatch[ 601- 700]: loss = 0.413957 * 100, metric = 8.15% * 100;
 Minibatch[ 701- 800]: loss = 0.422935 * 100, metric = 8.40% * 100;
 Minibatch[ 801- 900]: loss = 0.434708 * 100, metric = 8.81% * 100;
 Minibatch[ 901-1000]: loss = 0.415164 * 100, metric = 8.50% * 100;
 Minibatch[1001-1100]: loss = 0.452134 * 100, metric = 9.06% * 100;
 Minibatch[1101-1200]: loss = 0.437932 * 100, metric = 8.68% * 100;
 Minibatch[1201-1300]: loss = 0.430734 * 100, metric = 8.57% * 100;
 Minibatch[1301-1400]: loss = 0.440815 * 100, metric = 8.81% * 100;
 Minibatch[1401-1500]: loss = 0.426074 * 100, metric = 8.43% * 100;
 Minibatch[1501-1600]: loss = 0.437197 * 100, metric = 8.94% * 100;
 Minibatch[1601-1700]: loss = 0.433890 * 100, metric = 8.61% * 100;
 Minibatch[1701-1800]: loss = 0.439563 * 100, metric = 8.95% * 100;
 Minibatch[1801-1900]: loss = 0.428965 * 100, metric = 8.52% * 100;
 Minibatch[1901-2000]: loss = 0.426817 * 100, metric = 8.53% * 100;
Finished Epoch[82 of 200]: [Training] loss = 0.430700 * 2000, metric = 8.63% * 2000 643.747s (  3.1 samples/s);
Finished Evaluation [82]: Minibatch[1-1000]: metric = 14.29% * 1000;
 Minibatch[   1- 100]: loss = 0.426290 * 100, metric = 8.51% * 100;
 Minibatch[ 101- 200]: loss = 0.436353 * 100, metric = 8.78% * 100;
 Minibatch[ 201- 300]: loss = 0.405564 * 100, metric = 7.73% * 100;
 Minibatch[ 301- 400]: loss = 0.434181 * 100, metric = 8.88% * 100;
 Minibatch[ 401- 500]: loss = 0.417351 * 100, metric = 8.52% * 100;
 Minibatch[ 501- 600]: loss = 0.427946 * 100, metric = 8.80% * 100;
 Minibatch[ 601- 700]: loss = 0.432902 * 100, metric = 8.69% * 100;
 Minibatch[ 701- 800]: loss = 0.419587 * 100, metric = 8.25% * 100;
 Minibatch[ 801- 900]: loss = 0.444657 * 100, metric = 8.93% * 100;
 Minibatch[ 901-1000]: loss = 0.435746 * 100, metric = 8.73% * 100;
 Minibatch[1001-1100]: loss = 0.426938 * 100, metric = 8.40% * 100;
 Minibatch[1101-1200]: loss = 0.436888 * 100, metric = 9.04% * 100;
 Minibatch[1201-1300]: loss = 0.432237 * 100, metric = 8.78% * 100;
 Minibatch[1301-1400]: loss = 0.399648 * 100, metric = 7.92% * 100;
 Minibatch[1401-1500]: loss = 0.422394 * 100, metric = 8.43% * 100;
 Minibatch[1501-1600]: loss = 0.430486 * 100, metric = 8.76% * 100;
 Minibatch[1601-1700]: loss = 0.415118 * 100, metric = 8.17% * 100;
 Minibatch[1701-1800]: loss = 0.413275 * 100, metric = 8.24% * 100;
 Minibatch[1801-1900]: loss = 0.434034 * 100, metric = 8.98% * 100;
 Minibatch[1901-2000]: loss = 0.432437 * 100, metric = 8.80% * 100;
Finished Epoch[83 of 200]: [Training] loss = 0.426202 * 2000, metric = 8.57% * 2000 644.940s (  3.1 samples/s);
Finished Evaluation [83]: Minibatch[1-1000]: metric = 15.10% * 1000;
 Minibatch[   1- 100]: loss = 0.423941 * 100, metric = 8.45% * 100;
 Minibatch[ 101- 200]: loss = 0.428101 * 100, metric = 8.76% * 100;
 Minibatch[ 201- 300]: loss = 0.425517 * 100, metric = 8.65% * 100;
 Minibatch[ 301- 400]: loss = 0.424698 * 100, metric = 8.57% * 100;
 Minibatch[ 401- 500]: loss = 0.424545 * 100, metric = 8.38% * 100;
 Minibatch[ 501- 600]: loss = 0.430497 * 100, metric = 8.59% * 100;
 Minibatch[ 601- 700]: loss = 0.440173 * 100, metric = 8.96% * 100;
 Minibatch[ 701- 800]: loss = 0.424297 * 100, metric = 8.67% * 100;
 Minibatch[ 801- 900]: loss = 0.421621 * 100, metric = 8.46% * 100;
 Minibatch[ 901-1000]: loss = 0.433951 * 100, metric = 8.75% * 100;
 Minibatch[1001-1100]: loss = 0.435798 * 100, metric = 8.94% * 100;
 Minibatch[1101-1200]: loss = 0.427473 * 100, metric = 8.57% * 100;
 Minibatch[1201-1300]: loss = 0.415907 * 100, metric = 8.30% * 100;
 Minibatch[1301-1400]: loss = 0.437842 * 100, metric = 8.86% * 100;
 Minibatch[1401-1500]: loss = 0.423881 * 100, metric = 8.63% * 100;
 Minibatch[1501-1600]: loss = 0.418911 * 100, metric = 8.53% * 100;
 Minibatch[1601-1700]: loss = 0.430345 * 100, metric = 8.88% * 100;
 Minibatch[1701-1800]: loss = 0.428880 * 100, metric = 8.59% * 100;
 Minibatch[1801-1900]: loss = 0.429786 * 100, metric = 8.70% * 100;
 Minibatch[1901-2000]: loss = 0.442709 * 100, metric = 9.01% * 100;
Finished Epoch[84 of 200]: [Training] loss = 0.428444 * 2000, metric = 8.66% * 2000 649.287s (  3.1 samples/s);
Finished Evaluation [84]: Minibatch[1-1000]: metric = 14.99% * 1000;
 Minibatch[   1- 100]: loss = 0.435477 * 100, metric = 8.82% * 100;
 Minibatch[ 101- 200]: loss = 0.424070 * 100, metric = 8.36% * 100;
 Minibatch[ 201- 300]: loss = 0.433490 * 100, metric = 8.78% * 100;
 Minibatch[ 301- 400]: loss = 0.440984 * 100, metric = 8.97% * 100;
 Minibatch[ 401- 500]: loss = 0.419522 * 100, metric = 8.51% * 100;
 Minibatch[ 501- 600]: loss = 0.440011 * 100, metric = 9.12% * 100;
 Minibatch[ 601- 700]: loss = 0.427986 * 100, metric = 8.67% * 100;
 Minibatch[ 701- 800]: loss = 0.420626 * 100, metric = 8.37% * 100;
 Minibatch[ 801- 900]: loss = 0.429077 * 100, metric = 8.68% * 100;
 Minibatch[ 901-1000]: loss = 0.436894 * 100, metric = 8.82% * 100;
 Minibatch[1001-1100]: loss = 0.440250 * 100, metric = 8.77% * 100;
 Minibatch[1101-1200]: loss = 0.435757 * 100, metric = 8.81% * 100;
 Minibatch[1201-1300]: loss = 0.420935 * 100, metric = 8.50% * 100;
 Minibatch[1301-1400]: loss = 0.423502 * 100, metric = 8.37% * 100;
 Minibatch[1401-1500]: loss = 0.430806 * 100, metric = 8.60% * 100;
 Minibatch[1501-1600]: loss = 0.431334 * 100, metric = 8.38% * 100;
 Minibatch[1601-1700]: loss = 0.435650 * 100, metric = 8.95% * 100;
 Minibatch[1701-1800]: loss = 0.431680 * 100, metric = 8.51% * 100;
 Minibatch[1801-1900]: loss = 0.429263 * 100, metric = 8.77% * 100;
 Minibatch[1901-2000]: loss = 0.422436 * 100, metric = 8.37% * 100;
Finished Epoch[85 of 200]: [Training] loss = 0.430487 * 2000, metric = 8.66% * 2000 649.232s (  3.1 samples/s);
Finished Evaluation [85]: Minibatch[1-1000]: metric = 14.47% * 1000;
 Minibatch[   1- 100]: loss = 0.434764 * 100, metric = 8.81% * 100;
 Minibatch[ 101- 200]: loss = 0.412581 * 100, metric = 8.13% * 100;
 Minibatch[ 201- 300]: loss = 0.430926 * 100, metric = 8.57% * 100;
 Minibatch[ 301- 400]: loss = 0.435493 * 100, metric = 8.68% * 100;
 Minibatch[ 401- 500]: loss = 0.437023 * 100, metric = 8.80% * 100;
 Minibatch[ 501- 600]: loss = 0.427228 * 100, metric = 8.56% * 100;
 Minibatch[ 601- 700]: loss = 0.436498 * 100, metric = 8.59% * 100;
 Minibatch[ 701- 800]: loss = 0.425815 * 100, metric = 8.59% * 100;
 Minibatch[ 801- 900]: loss = 0.409155 * 100, metric = 8.08% * 100;
 Minibatch[ 901-1000]: loss = 0.417025 * 100, metric = 8.41% * 100;
 Minibatch[1001-1100]: loss = 0.416835 * 100, metric = 8.28% * 100;
 Minibatch[1101-1200]: loss = 0.427067 * 100, metric = 8.70% * 100;
 Minibatch[1201-1300]: loss = 0.424657 * 100, metric = 8.64% * 100;
 Minibatch[1301-1400]: loss = 0.424966 * 100, metric = 8.33% * 100;
 Minibatch[1401-1500]: loss = 0.420767 * 100, metric = 8.62% * 100;
 Minibatch[1501-1600]: loss = 0.406196 * 100, metric = 8.00% * 100;
 Minibatch[1601-1700]: loss = 0.439800 * 100, metric = 8.90% * 100;
 Minibatch[1701-1800]: loss = 0.439681 * 100, metric = 8.85% * 100;
 Minibatch[1801-1900]: loss = 0.441013 * 100, metric = 8.89% * 100;
 Minibatch[1901-2000]: loss = 0.435656 * 100, metric = 8.78% * 100;
Finished Epoch[86 of 200]: [Training] loss = 0.427157 * 2000, metric = 8.56% * 2000 650.487s (  3.1 samples/s);
Finished Evaluation [86]: Minibatch[1-1000]: metric = 13.96% * 1000;
 Minibatch[   1- 100]: loss = 0.416147 * 100, metric = 8.50% * 100;
 Minibatch[ 101- 200]: loss = 0.422161 * 100, metric = 8.67% * 100;
 Minibatch[ 201- 300]: loss = 0.424540 * 100, metric = 8.47% * 100;
 Minibatch[ 301- 400]: loss = 0.437751 * 100, metric = 8.94% * 100;
 Minibatch[ 401- 500]: loss = 0.420318 * 100, metric = 8.65% * 100;
 Minibatch[ 501- 600]: loss = 0.432229 * 100, metric = 8.84% * 100;
 Minibatch[ 601- 700]: loss = 0.439270 * 100, metric = 9.07% * 100;
 Minibatch[ 701- 800]: loss = 0.433432 * 100, metric = 8.66% * 100;
 Minibatch[ 801- 900]: loss = 0.411647 * 100, metric = 8.26% * 100;
 Minibatch[ 901-1000]: loss = 0.425554 * 100, metric = 8.98% * 100;
 Minibatch[1001-1100]: loss = 0.442191 * 100, metric = 8.86% * 100;
 Minibatch[1101-1200]: loss = 0.401506 * 100, metric = 7.92% * 100;
 Minibatch[1201-1300]: loss = 0.429798 * 100, metric = 8.71% * 100;
 Minibatch[1301-1400]: loss = 0.425006 * 100, metric = 8.77% * 100;
 Minibatch[1401-1500]: loss = 0.430367 * 100, metric = 8.87% * 100;
 Minibatch[1501-1600]: loss = 0.424017 * 100, metric = 8.32% * 100;
 Minibatch[1601-1700]: loss = 0.439901 * 100, metric = 9.16% * 100;
 Minibatch[1701-1800]: loss = 0.419619 * 100, metric = 8.56% * 100;
 Minibatch[1801-1900]: loss = 0.430538 * 100, metric = 8.88% * 100;
 Minibatch[1901-2000]: loss = 0.445322 * 100, metric = 9.07% * 100;
Finished Epoch[87 of 200]: [Training] loss = 0.427566 * 2000, metric = 8.71% * 2000 648.208s (  3.1 samples/s);
Finished Evaluation [87]: Minibatch[1-1000]: metric = 14.54% * 1000;
 Minibatch[   1- 100]: loss = 0.434108 * 100, metric = 8.76% * 100;
 Minibatch[ 101- 200]: loss = 0.429539 * 100, metric = 8.73% * 100;
 Minibatch[ 201- 300]: loss = 0.426274 * 100, metric = 8.59% * 100;
 Minibatch[ 301- 400]: loss = 0.432469 * 100, metric = 8.96% * 100;
 Minibatch[ 401- 500]: loss = 0.432116 * 100, metric = 8.63% * 100;
 Minibatch[ 501- 600]: loss = 0.420939 * 100, metric = 8.39% * 100;
 Minibatch[ 601- 700]: loss = 0.413469 * 100, metric = 8.09% * 100;
 Minibatch[ 701- 800]: loss = 0.432259 * 100, metric = 8.71% * 100;
 Minibatch[ 801- 900]: loss = 0.442848 * 100, metric = 9.12% * 100;
 Minibatch[ 901-1000]: loss = 0.427385 * 100, metric = 8.83% * 100;
 Minibatch[1001-1100]: loss = 0.428863 * 100, metric = 8.52% * 100;
 Minibatch[1101-1200]: loss = 0.426938 * 100, metric = 8.59% * 100;
 Minibatch[1201-1300]: loss = 0.413596 * 100, metric = 7.90% * 100;
 Minibatch[1301-1400]: loss = 0.417688 * 100, metric = 8.32% * 100;
 Minibatch[1401-1500]: loss = 0.430512 * 100, metric = 8.89% * 100;
 Minibatch[1501-1600]: loss = 0.403278 * 100, metric = 8.16% * 100;
 Minibatch[1601-1700]: loss = 0.419478 * 100, metric = 8.51% * 100;
 Minibatch[1701-1800]: loss = 0.426456 * 100, metric = 8.80% * 100;
 Minibatch[1801-1900]: loss = 0.443416 * 100, metric = 9.41% * 100;
 Minibatch[1901-2000]: loss = 0.401769 * 100, metric = 7.87% * 100;
Finished Epoch[88 of 200]: [Training] loss = 0.425170 * 2000, metric = 8.59% * 2000 653.234s (  3.1 samples/s);
Finished Evaluation [88]: Minibatch[1-1000]: metric = 13.77% * 1000;
 Minibatch[   1- 100]: loss = 0.435546 * 100, metric = 8.77% * 100;
 Minibatch[ 101- 200]: loss = 0.432092 * 100, metric = 8.89% * 100;
 Minibatch[ 201- 300]: loss = 0.413610 * 100, metric = 8.21% * 100;
 Minibatch[ 301- 400]: loss = 0.424447 * 100, metric = 8.83% * 100;
 Minibatch[ 401- 500]: loss = 0.428807 * 100, metric = 8.69% * 100;
 Minibatch[ 501- 600]: loss = 0.429593 * 100, metric = 8.63% * 100;
 Minibatch[ 601- 700]: loss = 0.437031 * 100, metric = 9.15% * 100;
 Minibatch[ 701- 800]: loss = 0.424197 * 100, metric = 8.43% * 100;
 Minibatch[ 801- 900]: loss = 0.421690 * 100, metric = 8.58% * 100;
 Minibatch[ 901-1000]: loss = 0.440796 * 100, metric = 8.89% * 100;
 Minibatch[1001-1100]: loss = 0.432214 * 100, metric = 8.76% * 100;
 Minibatch[1101-1200]: loss = 0.438210 * 100, metric = 9.12% * 100;
 Minibatch[1201-1300]: loss = 0.437359 * 100, metric = 9.01% * 100;
 Minibatch[1301-1400]: loss = 0.420666 * 100, metric = 8.62% * 100;
 Minibatch[1401-1500]: loss = 0.445792 * 100, metric = 9.03% * 100;
 Minibatch[1501-1600]: loss = 0.426315 * 100, metric = 8.62% * 100;
 Minibatch[1601-1700]: loss = 0.435186 * 100, metric = 8.94% * 100;
 Minibatch[1701-1800]: loss = 0.438139 * 100, metric = 8.86% * 100;
 Minibatch[1801-1900]: loss = 0.431830 * 100, metric = 8.81% * 100;
 Minibatch[1901-2000]: loss = 0.427656 * 100, metric = 8.58% * 100;
Finished Epoch[89 of 200]: [Training] loss = 0.431059 * 2000, metric = 8.77% * 2000 660.073s (  3.0 samples/s);
Finished Evaluation [89]: Minibatch[1-1000]: metric = 13.65% * 1000;
 Minibatch[   1- 100]: loss = 0.431154 * 100, metric = 8.77% * 100;
 Minibatch[ 101- 200]: loss = 0.419339 * 100, metric = 8.38% * 100;
 Minibatch[ 201- 300]: loss = 0.446516 * 100, metric = 9.06% * 100;
 Minibatch[ 301- 400]: loss = 0.432917 * 100, metric = 8.66% * 100;
 Minibatch[ 401- 500]: loss = 0.434176 * 100, metric = 8.75% * 100;
 Minibatch[ 501- 600]: loss = 0.444776 * 100, metric = 8.82% * 100;
 Minibatch[ 601- 700]: loss = 0.430223 * 100, metric = 8.98% * 100;
 Minibatch[ 701- 800]: loss = 0.423741 * 100, metric = 8.38% * 100;
 Minibatch[ 801- 900]: loss = 0.436816 * 100, metric = 8.89% * 100;
 Minibatch[ 901-1000]: loss = 0.441176 * 100, metric = 8.78% * 100;
 Minibatch[1001-1100]: loss = 0.414338 * 100, metric = 8.55% * 100;
 Minibatch[1101-1200]: loss = 0.414019 * 100, metric = 8.38% * 100;
 Minibatch[1201-1300]: loss = 0.408882 * 100, metric = 8.15% * 100;
 Minibatch[1301-1400]: loss = 0.431142 * 100, metric = 8.55% * 100;
 Minibatch[1401-1500]: loss = 0.426428 * 100, metric = 8.75% * 100;
 Minibatch[1501-1600]: loss = 0.406612 * 100, metric = 8.08% * 100;
 Minibatch[1601-1700]: loss = 0.407643 * 100, metric = 8.05% * 100;
 Minibatch[1701-1800]: loss = 0.424567 * 100, metric = 8.62% * 100;
 Minibatch[1801-1900]: loss = 0.426094 * 100, metric = 8.77% * 100;
 Minibatch[1901-2000]: loss = 0.429390 * 100, metric = 8.76% * 100;
Finished Epoch[90 of 200]: [Training] loss = 0.426497 * 2000, metric = 8.61% * 2000 654.154s (  3.1 samples/s);
Finished Evaluation [90]: Minibatch[1-1000]: metric = 14.53% * 1000;
 Minibatch[   1- 100]: loss = 0.427105 * 100, metric = 8.56% * 100;
 Minibatch[ 101- 200]: loss = 0.443467 * 100, metric = 9.13% * 100;
 Minibatch[ 201- 300]: loss = 0.428225 * 100, metric = 8.69% * 100;
 Minibatch[ 301- 400]: loss = 0.422909 * 100, metric = 8.25% * 100;
 Minibatch[ 401- 500]: loss = 0.421685 * 100, metric = 8.61% * 100;
 Minibatch[ 501- 600]: loss = 0.434511 * 100, metric = 8.88% * 100;
 Minibatch[ 601- 700]: loss = 0.433715 * 100, metric = 8.90% * 100;
 Minibatch[ 701- 800]: loss = 0.448696 * 100, metric = 9.33% * 100;
 Minibatch[ 801- 900]: loss = 0.414099 * 100, metric = 8.48% * 100;
 Minibatch[ 901-1000]: loss = 0.420936 * 100, metric = 8.52% * 100;
 Minibatch[1001-1100]: loss = 0.423085 * 100, metric = 8.60% * 100;
 Minibatch[1101-1200]: loss = 0.442281 * 100, metric = 9.10% * 100;
 Minibatch[1201-1300]: loss = 0.421439 * 100, metric = 8.58% * 100;
 Minibatch[1301-1400]: loss = 0.432237 * 100, metric = 8.78% * 100;
 Minibatch[1401-1500]: loss = 0.413932 * 100, metric = 8.29% * 100;
 Minibatch[1501-1600]: loss = 0.415962 * 100, metric = 8.38% * 100;
 Minibatch[1601-1700]: loss = 0.412859 * 100, metric = 8.20% * 100;
 Minibatch[1701-1800]: loss = 0.440984 * 100, metric = 8.89% * 100;
 Minibatch[1801-1900]: loss = 0.424518 * 100, metric = 8.50% * 100;
 Minibatch[1901-2000]: loss = 0.419510 * 100, metric = 8.41% * 100;
Finished Epoch[91 of 200]: [Training] loss = 0.427108 * 2000, metric = 8.65% * 2000 653.653s (  3.1 samples/s);
Finished Evaluation [91]: Minibatch[1-1000]: metric = 13.73% * 1000;
 Minibatch[   1- 100]: loss = 0.430816 * 100, metric = 8.66% * 100;
 Minibatch[ 101- 200]: loss = 0.425966 * 100, metric = 8.66% * 100;
 Minibatch[ 201- 300]: loss = 0.435540 * 100, metric = 8.75% * 100;
 Minibatch[ 301- 400]: loss = 0.415753 * 100, metric = 8.20% * 100;
 Minibatch[ 401- 500]: loss = 0.430138 * 100, metric = 8.69% * 100;
 Minibatch[ 501- 600]: loss = 0.443601 * 100, metric = 9.17% * 100;
 Minibatch[ 601- 700]: loss = 0.432399 * 100, metric = 8.86% * 100;
 Minibatch[ 701- 800]: loss = 0.425686 * 100, metric = 8.32% * 100;
 Minibatch[ 801- 900]: loss = 0.427952 * 100, metric = 8.75% * 100;
 Minibatch[ 901-1000]: loss = 0.424731 * 100, metric = 8.67% * 100;
 Minibatch[1001-1100]: loss = 0.408216 * 100, metric = 8.28% * 100;
 Minibatch[1101-1200]: loss = 0.420136 * 100, metric = 8.46% * 100;
 Minibatch[1201-1300]: loss = 0.422091 * 100, metric = 8.58% * 100;
 Minibatch[1301-1400]: loss = 0.421548 * 100, metric = 8.71% * 100;
 Minibatch[1401-1500]: loss = 0.408859 * 100, metric = 8.31% * 100;
 Minibatch[1501-1600]: loss = 0.425916 * 100, metric = 8.63% * 100;
 Minibatch[1601-1700]: loss = 0.410831 * 100, metric = 8.15% * 100;
 Minibatch[1701-1800]: loss = 0.412911 * 100, metric = 8.33% * 100;
 Minibatch[1801-1900]: loss = 0.420089 * 100, metric = 8.55% * 100;
 Minibatch[1901-2000]: loss = 0.432676 * 100, metric = 8.80% * 100;
Finished Epoch[92 of 200]: [Training] loss = 0.423793 * 2000, metric = 8.58% * 2000 636.401s (  3.1 samples/s);
Finished Evaluation [92]: Minibatch[1-1000]: metric = 13.73% * 1000;
 Minibatch[   1- 100]: loss = 0.425308 * 100, metric = 8.50% * 100;
 Minibatch[ 101- 200]: loss = 0.424192 * 100, metric = 8.61% * 100;
 Minibatch[ 201- 300]: loss = 0.434475 * 100, metric = 8.78% * 100;
 Minibatch[ 301- 400]: loss = 0.418876 * 100, metric = 8.38% * 100;
 Minibatch[ 401- 500]: loss = 0.418515 * 100, metric = 8.25% * 100;
 Minibatch[ 501- 600]: loss = 0.428436 * 100, metric = 8.67% * 100;
 Minibatch[ 601- 700]: loss = 0.417516 * 100, metric = 8.55% * 100;
 Minibatch[ 701- 800]: loss = 0.425786 * 100, metric = 8.53% * 100;
 Minibatch[ 801- 900]: loss = 0.423410 * 100, metric = 8.52% * 100;
 Minibatch[ 901-1000]: loss = 0.409063 * 100, metric = 8.12% * 100;
 Minibatch[1001-1100]: loss = 0.427076 * 100, metric = 8.31% * 100;
 Minibatch[1101-1200]: loss = 0.410320 * 100, metric = 8.18% * 100;
 Minibatch[1201-1300]: loss = 0.427131 * 100, metric = 8.55% * 100;
 Minibatch[1301-1400]: loss = 0.416843 * 100, metric = 8.33% * 100;
 Minibatch[1401-1500]: loss = 0.425837 * 100, metric = 8.39% * 100;
 Minibatch[1501-1600]: loss = 0.411682 * 100, metric = 8.05% * 100;
 Minibatch[1601-1700]: loss = 0.420338 * 100, metric = 8.53% * 100;
 Minibatch[1701-1800]: loss = 0.424408 * 100, metric = 8.31% * 100;
 Minibatch[1801-1900]: loss = 0.406477 * 100, metric = 7.97% * 100;
 Minibatch[1901-2000]: loss = 0.419648 * 100, metric = 8.49% * 100;
Finished Epoch[93 of 200]: [Training] loss = 0.420767 * 2000, metric = 8.40% * 2000 611.356s (  3.3 samples/s);
Finished Evaluation [93]: Minibatch[1-1000]: metric = 14.68% * 1000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
Evaluating Faster R-CNN model for 30200 images.
Processed 100 samples
Processed 200 samples
Processed 300 samples
Processed 400 samples
Processed 500 samples
Processed 600 samples
Processed 700 samples
Processed 800 samples
Processed 900 samples
Processed 1000 samples
Processed 1100 samples
Processed 1200 samples
Processed 1300 samples
Processed 1400 samples
Processed 1500 samples
Processed 1600 samples
Processed 1700 samples
Processed 1800 samples
Processed 1900 samples
Processed 2000 samples
Processed 2100 samples
Processed 2200 samples
Processed 2300 samples
Processed 2400 samples
Processed 2500 samples
Processed 2600 samples
Processed 2700 samples
Processed 2800 samples
Processed 2900 samples
Processed 3000 samples
Processed 3100 samples
Processed 3200 samples
Processed 3300 samples
Processed 3400 samples
Processed 3500 samples
Processed 3600 samples
Processed 3700 samples
Processed 3800 samples
Processed 3900 samples
Processed 4000 samples
Processed 4100 samples
Processed 4200 samples
Processed 4300 samples
Processed 4400 samples
Processed 4500 samples
Processed 4600 samples
Processed 4700 samples
Processed 4800 samples
Processed 4900 samples
Processed 5000 samples
Processed 5100 samples
Processed 5200 samples
Processed 5300 samples
Processed 5400 samples
Processed 5500 samples
Processed 5600 samples
Processed 5700 samples
Processed 5800 samples
Processed 5900 samples
Processed 6000 samples
Processed 6100 samples
Processed 6200 samples
Processed 6300 samples
Processed 6400 samples
Processed 6500 samples
Processed 6600 samples
Processed 6700 samples
Processed 6800 samples
Processed 6900 samples
Processed 7000 samples
Processed 7100 samples
Processed 7200 samples
Processed 7300 samples
Processed 7400 samples
Processed 7500 samples
Processed 7600 samples
Processed 7700 samples
Processed 7800 samples
Processed 7900 samples
Processed 8000 samples
Processed 8100 samples
Processed 8200 samples
Processed 8300 samples
Processed 8400 samples
Processed 8500 samples
Processed 8600 samples
Processed 8700 samples
Processed 8800 samples
Processed 8900 samples
Processed 9000 samples
Processed 9100 samples
Processed 9200 samples
Processed 9300 samples
Processed 9400 samples
Processed 9500 samples
Processed 9600 samples
Processed 9700 samples
Processed 9800 samples
Processed 9900 samples
Processed 10000 samples
Processed 10100 samples
Processed 10200 samples
Processed 10300 samples
Processed 10400 samples
Processed 10500 samples
Processed 10600 samples
Processed 10700 samples
Processed 10800 samples
Processed 10900 samples
Processed 11000 samples
Processed 11100 samples
Processed 11200 samples
Processed 11300 samples
Processed 11400 samples
Processed 11500 samples
Processed 11600 samples
Processed 11700 samples
Processed 11800 samples
Processed 11900 samples
Processed 12000 samples
Processed 12100 samples
Processed 12200 samples
Processed 12300 samples
Processed 12400 samples
Processed 12500 samples
Processed 12600 samples
Processed 12700 samples
Processed 12800 samples
Processed 12900 samples
Processed 13000 samples
Processed 13100 samples
Processed 13200 samples
Processed 13300 samples
Processed 13400 samples
Processed 13500 samples
Processed 13600 samples
Processed 13700 samples
Processed 13800 samples
Processed 13900 samples
Processed 14000 samples
Processed 14100 samples
Processed 14200 samples
Processed 14300 samples
Processed 14400 samples
Processed 14500 samples
Processed 14600 samples
Processed 14700 samples
Processed 14800 samples
Processed 14900 samples
Processed 15000 samples
Processed 15100 samples
Processed 15200 samples
Processed 15300 samples
Processed 15400 samples
Processed 15500 samples
Processed 15600 samples
Processed 15700 samples
Processed 15800 samples
Processed 15900 samples
Processed 16000 samples
Processed 16100 samples
Processed 16200 samples
Processed 16300 samples
Processed 16400 samples
Processed 16500 samples
Processed 16600 samples
Processed 16700 samples
Processed 16800 samples
Processed 16900 samples
Processed 17000 samples
Processed 17100 samples
Processed 17200 samples
Processed 17300 samples
Processed 17400 samples
Processed 17500 samples
Processed 17600 samples
Processed 17700 samples
Processed 17800 samples
Processed 17900 samples
Processed 18000 samples
Processed 18100 samples
Processed 18200 samples
Processed 18300 samples
Processed 18400 samples
Processed 18500 samples
Processed 18600 samples
Processed 18700 samples
Processed 18800 samples
Processed 18900 samples
Processed 19000 samples
Processed 19100 samples
Processed 19200 samples
Processed 19300 samples
Processed 19400 samples
Processed 19500 samples
Processed 19600 samples
Processed 19700 samples
Processed 19800 samples
Processed 19900 samples
Processed 20000 samples
Processed 20100 samples
Processed 20200 samples
Processed 20300 samples
Processed 20400 samples
Processed 20500 samples
Processed 20600 samples
Processed 20700 samples
Processed 20800 samples
Processed 20900 samples
Processed 21000 samples
Processed 21100 samples
Processed 21200 samples
Processed 21300 samples
Processed 21400 samples
Processed 21500 samples
Processed 21600 samples
Processed 21700 samples
Processed 21800 samples
Processed 21900 samples
Processed 22000 samples
Processed 22100 samples
Processed 22200 samples
Processed 22300 samples
Processed 22400 samples
Processed 22500 samples
Processed 22600 samples
Processed 22700 samples
Processed 22800 samples
Processed 22900 samples
Processed 23000 samples
Processed 23100 samples
Processed 23200 samples
Processed 23300 samples
Processed 23400 samples
Processed 23500 samples
Processed 23600 samples
Processed 23700 samples
Processed 23800 samples
Processed 23900 samples
Processed 24000 samples
Processed 24100 samples
Processed 24200 samples
Processed 24300 samples
Processed 24400 samples
Processed 24500 samples
Processed 24600 samples
Processed 24700 samples
Processed 24800 samples
Processed 24900 samples
Processed 25000 samples
Processed 25100 samples
Processed 25200 samples
Processed 25300 samples
Processed 25400 samples
Processed 25500 samples
Processed 25600 samples
Processed 25700 samples
Processed 25800 samples
Processed 25900 samples
Processed 26000 samples
Processed 26100 samples
Processed 26200 samples
Processed 26300 samples
Processed 26400 samples
Processed 26500 samples
Processed 26600 samples
Processed 26700 samples
Processed 26800 samples
Processed 26900 samples
Processed 27000 samples
Processed 27100 samples
Processed 27200 samples
Processed 27300 samples
Processed 27400 samples
Processed 27500 samples
Processed 27600 samples
Processed 27700 samples
Processed 27800 samples
Processed 27900 samples
Processed 28000 samples
Processed 28100 samples
Processed 28200 samples
Processed 28300 samples
Processed 28400 samples
Processed 28500 samples
Processed 28600 samples
Processed 28700 samples
Processed 28800 samples
Processed 28900 samples
Processed 29000 samples
Processed 29100 samples
Processed 29200 samples
Processed 29300 samples
Processed 29400 samples
Processed 29500 samples
Processed 29600 samples
Processed 29700 samples
Processed 29800 samples
Processed 29900 samples
Processed 30000 samples
Processed 30100 samples
Processed 30200 samples
Number of rois before non-maximum suppression: 4660370
Number of rois  after non-maximum suppression: 2558398
AP for        Negative = 0.5684
AP for        Positive = 0.5510
Mean AP = 0.5597
