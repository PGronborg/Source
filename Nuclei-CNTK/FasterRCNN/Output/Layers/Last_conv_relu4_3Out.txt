Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 129369925 parameters in 26 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = nan * 100, metric = 89.30% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[1 of 200]: [Training] loss = nan * 2000, metric = 99.47% * 2000 847.641s (  2.4 samples/s);
Finished Evaluation [1]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[2 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 764.788s (  2.6 samples/s);
Finished Evaluation [2]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[3 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 761.613s (  2.6 samples/s);
Finished Evaluation [3]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[4 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 760.388s (  2.6 samples/s);
Finished Evaluation [4]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[5 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 760.428s (  2.6 samples/s);
Finished Evaluation [5]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[6 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 759.805s (  2.6 samples/s);
Finished Evaluation [6]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[7 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 760.005s (  2.6 samples/s);
Finished Evaluation [7]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[8 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 760.409s (  2.6 samples/s);
Finished Evaluation [8]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[9 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 760.255s (  2.6 samples/s);
Finished Evaluation [9]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[10 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 777.609s (  2.6 samples/s);
Finished Evaluation [10]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[11 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 767.286s (  2.6 samples/s);
Finished Evaluation [11]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[12 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 765.619s (  2.6 samples/s);
Finished Evaluation [12]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[13 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 767.334s (  2.6 samples/s);
Finished Evaluation [13]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[14 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 769.821s (  2.6 samples/s);
Finished Evaluation [14]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[15 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 791.160s (  2.5 samples/s);
Finished Evaluation [15]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[16 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 802.757s (  2.5 samples/s);
Finished Evaluation [16]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[17 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 799.881s (  2.5 samples/s);
Finished Evaluation [17]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[18 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 811.445s (  2.5 samples/s);
Finished Evaluation [18]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[19 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 807.726s (  2.5 samples/s);
Finished Evaluation [19]: Minibatch[1-1000]: metric = 100.00% * 1000;
 Minibatch[   1- 100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 101- 200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 201- 300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 301- 400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 401- 500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 501- 600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 601- 700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 701- 800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 801- 900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[ 901-1000]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1001-1100]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1101-1200]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1201-1300]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1301-1400]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1401-1500]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1501-1600]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1601-1700]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1701-1800]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1801-1900]: loss = nan * 100, metric = 100.00% * 100;
 Minibatch[1901-2000]: loss = nan * 100, metric = 100.00% * 100;
Finished Epoch[20 of 200]: [Training] loss = nan * 2000, metric = 100.00% * 2000 807.359s (  2.5 samples/s);
Finished Evaluation [20]: Minibatch[1-1000]: metric = 100.00% * 1000;
