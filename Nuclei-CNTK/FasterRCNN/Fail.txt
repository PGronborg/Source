Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 20 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.228701 * 100, metric = 25.29% * 100;
 Minibatch[ 101- 200]: loss = 1.003874 * 100, metric = 22.83% * 100;
 Minibatch[ 201- 300]: loss = 0.897666 * 100, metric = 21.13% * 100;
 Minibatch[ 301- 400]: loss = 0.860340 * 100, metric = 19.56% * 100;
 Minibatch[ 401- 500]: loss = 0.785125 * 100, metric = 18.18% * 100;
Finished Epoch[1 of 20]: [Training] loss = 0.955141 * 500, metric = 21.40% * 500 334.812s (  1.5 samples/s);
Finished Evaluation [1]: Minibatch[1-500]: metric = 26.46% * 500;
0.8751782439947128
 Minibatch[   1- 100]: loss = 0.770949 * 100, metric = 17.13% * 100;
 Minibatch[ 101- 200]: loss = 0.743577 * 100, metric = 16.61% * 100;
 Minibatch[ 201- 300]: loss = 0.689566 * 100, metric = 15.38% * 100;
 Minibatch[ 301- 400]: loss = 0.713011 * 100, metric = 15.67% * 100;
 Minibatch[ 401- 500]: loss = 0.722662 * 100, metric = 15.93% * 100;
Finished Epoch[2 of 20]: [Training] loss = 0.727953 * 500, metric = 16.15% * 500 270.947s (  1.8 samples/s);
Finished Evaluation [2]: Minibatch[1-500]: metric = 29.02% * 500;
0.8480623553693295
 Minibatch[   1- 100]: loss = 0.721826 * 100, metric = 16.20% * 100;
 Minibatch[ 101- 200]: loss = 0.701211 * 100, metric = 15.36% * 100;
 Minibatch[ 201- 300]: loss = 0.683597 * 100, metric = 15.22% * 100;
 Minibatch[ 301- 400]: loss = 0.669001 * 100, metric = 14.59% * 100;
 Minibatch[ 401- 500]: loss = 0.678533 * 100, metric = 14.89% * 100;
Finished Epoch[3 of 20]: [Training] loss = 0.690834 * 500, metric = 15.25% * 500 266.081s (  1.9 samples/s);
Finished Evaluation [3]: Minibatch[1-500]: metric = 22.72% * 500;
0.737473074376583
 Minibatch[   1- 100]: loss = 0.651793 * 100, metric = 14.44% * 100;
 Minibatch[ 101- 200]: loss = 0.641797 * 100, metric = 14.02% * 100;
 Minibatch[ 201- 300]: loss = 0.644299 * 100, metric = 13.93% * 100;
 Minibatch[ 301- 400]: loss = 0.647727 * 100, metric = 14.13% * 100;
 Minibatch[ 401- 500]: loss = 0.639937 * 100, metric = 14.06% * 100;
Finished Epoch[4 of 20]: [Training] loss = 0.645111 * 500, metric = 14.12% * 500 263.326s (  1.9 samples/s);
Finished Evaluation [4]: Minibatch[1-500]: metric = 23.66% * 500;
 Minibatch[   1- 100]: loss = 0.624495 * 100, metric = 13.40% * 100;
 Minibatch[ 101- 200]: loss = 0.630302 * 100, metric = 13.84% * 100;
 Minibatch[ 201- 300]: loss = 0.613588 * 100, metric = 12.90% * 100;
 Minibatch[ 301- 400]: loss = 0.626625 * 100, metric = 13.54% * 100;
 Minibatch[ 401- 500]: loss = 0.615125 * 100, metric = 13.14% * 100;
Finished Epoch[5 of 20]: [Training] loss = 0.622027 * 500, metric = 13.36% * 500 261.589s (  1.9 samples/s);
Finished Evaluation [5]: Minibatch[1-500]: metric = 21.76% * 500;
0.721189891308546
 Minibatch[   1- 100]: loss = 0.618271 * 100, metric = 12.81% * 100;
 Minibatch[ 101- 200]: loss = 0.599369 * 100, metric = 12.96% * 100;
 Minibatch[ 201- 300]: loss = 0.614321 * 100, metric = 13.48% * 100;
 Minibatch[ 301- 400]: loss = 0.585636 * 100, metric = 12.52% * 100;
 Minibatch[ 401- 500]: loss = 0.582142 * 100, metric = 12.49% * 100;
Finished Epoch[6 of 20]: [Training] loss = 0.599948 * 500, metric = 12.85% * 500 260.783s (  1.9 samples/s);
Finished Evaluation [6]: Minibatch[1-500]: metric = 19.82% * 500;
0.6660417569875717
 Minibatch[   1- 100]: loss = 0.591181 * 100, metric = 12.66% * 100;
 Minibatch[ 101- 200]: loss = 0.587095 * 100, metric = 12.45% * 100;
 Minibatch[ 201- 300]: loss = 0.575178 * 100, metric = 12.46% * 100;
 Minibatch[ 301- 400]: loss = 0.591514 * 100, metric = 12.68% * 100;
 Minibatch[ 401- 500]: loss = 0.570866 * 100, metric = 12.00% * 100;
Finished Epoch[7 of 20]: [Training] loss = 0.583167 * 500, metric = 12.45% * 500 262.137s (  1.9 samples/s);
Finished Evaluation [7]: Minibatch[1-500]: metric = 20.63% * 500;
 Minibatch[   1- 100]: loss = 0.569943 * 100, metric = 12.00% * 100;
 Minibatch[ 101- 200]: loss = 0.585778 * 100, metric = 12.38% * 100;
 Minibatch[ 201- 300]: loss = 0.585539 * 100, metric = 12.51% * 100;
 Minibatch[ 301- 400]: loss = 0.575881 * 100, metric = 12.12% * 100;
 Minibatch[ 401- 500]: loss = 0.549197 * 100, metric = 11.57% * 100;
Finished Epoch[8 of 20]: [Training] loss = 0.573267 * 500, metric = 12.12% * 500 257.384s (  1.9 samples/s);
Finished Evaluation [8]: Minibatch[1-500]: metric = 19.87% * 500;
0.6496001323759556
 Minibatch[   1- 100]: loss = 0.579278 * 100, metric = 12.51% * 100;
 Minibatch[ 101- 200]: loss = 0.567888 * 100, metric = 12.07% * 100;
 Minibatch[ 201- 300]: loss = 0.551697 * 100, metric = 11.91% * 100;
 Minibatch[ 301- 400]: loss = 0.563760 * 100, metric = 12.02% * 100;
 Minibatch[ 401- 500]: loss = 0.568975 * 100, metric = 12.23% * 100;
Finished Epoch[9 of 20]: [Training] loss = 0.566320 * 500, metric = 12.15% * 500 256.869s (  1.9 samples/s);
Finished Evaluation [9]: Minibatch[1-500]: metric = 19.06% * 500;
0.6436921049952506
 Minibatch[   1- 100]: loss = 0.571372 * 100, metric = 12.12% * 100;
 Minibatch[ 101- 200]: loss = 0.566230 * 100, metric = 11.96% * 100;
 Minibatch[ 201- 300]: loss = 0.536374 * 100, metric = 11.14% * 100;
 Minibatch[ 301- 400]: loss = 0.566301 * 100, metric = 11.91% * 100;
 Minibatch[ 401- 500]: loss = 0.537263 * 100, metric = 11.68% * 100;
Finished Epoch[10 of 20]: [Training] loss = 0.555508 * 500, metric = 11.76% * 500 252.386s (  2.0 samples/s);
Finished Evaluation [10]: Minibatch[1-500]: metric = 18.10% * 500;
0.6210554011762143
 Minibatch[   1- 100]: loss = 0.550788 * 100, metric = 11.62% * 100;
 Minibatch[ 101- 200]: loss = 0.532034 * 100, metric = 11.31% * 100;
 Minibatch[ 201- 300]: loss = 0.538041 * 100, metric = 11.64% * 100;
 Minibatch[ 301- 400]: loss = 0.537778 * 100, metric = 11.57% * 100;
 Minibatch[ 401- 500]: loss = 0.542582 * 100, metric = 11.37% * 100;
Finished Epoch[11 of 20]: [Training] loss = 0.540245 * 500, metric = 11.50% * 500 250.373s (  2.0 samples/s);
Finished Evaluation [11]: Minibatch[1-500]: metric = 20.57% * 500;
 Minibatch[   1- 100]: loss = 0.534159 * 100, metric = 11.24% * 100;
 Minibatch[ 101- 200]: loss = 0.513612 * 100, metric = 10.67% * 100;
 Minibatch[ 201- 300]: loss = 0.547749 * 100, metric = 11.70% * 100;
 Minibatch[ 301- 400]: loss = 0.525285 * 100, metric = 10.93% * 100;
 Minibatch[ 401- 500]: loss = 0.524349 * 100, metric = 11.03% * 100;
Finished Epoch[12 of 20]: [Training] loss = 0.529031 * 500, metric = 11.11% * 500 253.180s (  2.0 samples/s);
Finished Evaluation [12]: Minibatch[1-500]: metric = 18.33% * 500;
 Minibatch[   1- 100]: loss = 0.543075 * 100, metric = 11.29% * 100;
 Minibatch[ 101- 200]: loss = 0.517252 * 100, metric = 10.75% * 100;
 Minibatch[ 201- 300]: loss = 0.528695 * 100, metric = 11.21% * 100;
 Minibatch[ 301- 400]: loss = 0.497383 * 100, metric = 10.26% * 100;
 Minibatch[ 401- 500]: loss = 0.524420 * 100, metric = 10.73% * 100;
Finished Epoch[13 of 20]: [Training] loss = 0.522165 * 500, metric = 10.85% * 500 251.736s (  2.0 samples/s);
Finished Evaluation [13]: Minibatch[1-500]: metric = 16.28% * 500;
0.5783025465905667
 Minibatch[   1- 100]: loss = 0.503070 * 100, metric = 10.31% * 100;
 Minibatch[ 101- 200]: loss = 0.503180 * 100, metric = 10.14% * 100;
 Minibatch[ 201- 300]: loss = 0.518995 * 100, metric = 10.84% * 100;
 Minibatch[ 301- 400]: loss = 0.516443 * 100, metric = 10.57% * 100;
 Minibatch[ 401- 500]: loss = 0.524646 * 100, metric = 10.87% * 100;
Finished Epoch[14 of 20]: [Training] loss = 0.513267 * 500, metric = 10.54% * 500 253.885s (  2.0 samples/s);
Finished Evaluation [14]: Minibatch[1-500]: metric = 17.84% * 500;
 Minibatch[   1- 100]: loss = 0.535247 * 100, metric = 11.26% * 100;
 Minibatch[ 101- 200]: loss = 0.501237 * 100, metric = 10.37% * 100;
 Minibatch[ 201- 300]: loss = 0.509805 * 100, metric = 10.51% * 100;
 Minibatch[ 301- 400]: loss = 0.526380 * 100, metric = 10.88% * 100;
 Minibatch[ 401- 500]: loss = 0.519206 * 100, metric = 10.89% * 100;
Finished Epoch[15 of 20]: [Training] loss = 0.518375 * 500, metric = 10.78% * 500 254.650s (  2.0 samples/s);
Finished Evaluation [15]: Minibatch[1-500]: metric = 19.46% * 500;
 Minibatch[   1- 100]: loss = 0.486412 * 100, metric = 9.88% * 100;
 Minibatch[ 101- 200]: loss = 0.511090 * 100, metric = 10.70% * 100;
 Minibatch[ 201- 300]: loss = 0.514041 * 100, metric = 10.66% * 100;
 Minibatch[ 301- 400]: loss = 0.499358 * 100, metric = 10.27% * 100;
 Minibatch[ 401- 500]: loss = 0.492058 * 100, metric = 9.91% * 100;
Finished Epoch[16 of 20]: [Training] loss = 0.500592 * 500, metric = 10.28% * 500 254.423s (  2.0 samples/s);
Finished Evaluation [16]: Minibatch[1-500]: metric = 18.53% * 500;
 Minibatch[   1- 100]: loss = 0.515020 * 100, metric = 10.74% * 100;
 Minibatch[ 101- 200]: loss = 0.494213 * 100, metric = 10.10% * 100;
 Minibatch[ 201- 300]: loss = 0.482730 * 100, metric = 9.77% * 100;
 Minibatch[ 301- 400]: loss = 0.511953 * 100, metric = 10.64% * 100;
 Minibatch[ 401- 500]: loss = 0.475282 * 100, metric = 9.44% * 100;
Finished Epoch[17 of 20]: [Training] loss = 0.495840 * 500, metric = 10.14% * 500 252.139s (  2.0 samples/s);
Finished Evaluation [17]: Minibatch[1-500]: metric = 16.99% * 500;
 Minibatch[   1- 100]: loss = 0.478503 * 100, metric = 9.71% * 100;
 Minibatch[ 101- 200]: loss = 0.488575 * 100, metric = 9.81% * 100;
 Minibatch[ 201- 300]: loss = 0.494459 * 100, metric = 10.12% * 100;
 Minibatch[ 301- 400]: loss = 0.475785 * 100, metric = 9.60% * 100;
 Minibatch[ 401- 500]: loss = 0.488242 * 100, metric = 9.84% * 100;
Finished Epoch[18 of 20]: [Training] loss = 0.485113 * 500, metric = 9.82% * 500 250.253s (  2.0 samples/s);
Finished Evaluation [18]: Minibatch[1-500]: metric = 16.44% * 500;
0.5714712044894695
 Minibatch[   1- 100]: loss = 0.494200 * 100, metric = 10.21% * 100;
 Minibatch[ 101- 200]: loss = 0.477372 * 100, metric = 9.59% * 100;
 Minibatch[ 201- 300]: loss = 0.484746 * 100, metric = 9.65% * 100;
 Minibatch[ 301- 400]: loss = 0.506366 * 100, metric = 10.45% * 100;
 Minibatch[ 401- 500]: loss = 0.486864 * 100, metric = 10.00% * 100;
Finished Epoch[19 of 20]: [Training] loss = 0.489909 * 500, metric = 9.98% * 500 254.783s (  2.0 samples/s);
Finished Evaluation [19]: Minibatch[1-500]: metric = 20.89% * 500;
 Minibatch[   1- 100]: loss = 0.485590 * 100, metric = 9.82% * 100;
 Minibatch[ 101- 200]: loss = 0.495568 * 100, metric = 10.22% * 100;
 Minibatch[ 201- 300]: loss = 0.498607 * 100, metric = 10.20% * 100;
 Minibatch[ 301- 400]: loss = 0.487324 * 100, metric = 10.07% * 100;
 Minibatch[ 401- 500]: loss = 0.474703 * 100, metric = 9.53% * 100;
Finished Epoch[20 of 20]: [Training] loss = 0.488358 * 500, metric = 9.97% * 500 252.271s (  2.0 samples/s);
Finished Evaluation [20]: Minibatch[1-500]: metric = 16.78% * 500;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
