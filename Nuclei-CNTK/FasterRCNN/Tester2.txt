Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 200 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.193063 * 100, metric = 23.69% * 100;
 Minibatch[ 101- 200]: loss = 0.955140 * 100, metric = 22.45% * 100;
 Minibatch[ 201- 300]: loss = 0.855668 * 100, metric = 21.16% * 100;
 Minibatch[ 301- 400]: loss = 0.827573 * 100, metric = 19.16% * 100;
 Minibatch[ 401- 500]: loss = 0.760172 * 100, metric = 17.23% * 100;
 Minibatch[ 501- 600]: loss = 0.748624 * 100, metric = 16.89% * 100;
 Minibatch[ 601- 700]: loss = 0.719063 * 100, metric = 15.99% * 100;
 Minibatch[ 701- 800]: loss = 0.675799 * 100, metric = 14.87% * 100;
 Minibatch[ 801- 900]: loss = 0.701783 * 100, metric = 15.54% * 100;
 Minibatch[ 901-1000]: loss = 0.701377 * 100, metric = 15.92% * 100;
 Minibatch[1001-1100]: loss = 0.685190 * 100, metric = 15.37% * 100;
 Minibatch[1101-1200]: loss = 0.680079 * 100, metric = 15.29% * 100;
 Minibatch[1201-1300]: loss = 0.684067 * 100, metric = 15.59% * 100;
 Minibatch[1301-1400]: loss = 0.641780 * 100, metric = 13.94% * 100;
 Minibatch[1401-1500]: loss = 0.657430 * 100, metric = 14.40% * 100;
 Minibatch[1501-1600]: loss = 0.619756 * 100, metric = 13.26% * 100;
 Minibatch[1601-1700]: loss = 0.621708 * 100, metric = 13.34% * 100;
 Minibatch[1701-1800]: loss = 0.626370 * 100, metric = 13.70% * 100;
 Minibatch[1801-1900]: loss = 0.622369 * 100, metric = 13.54% * 100;
 Minibatch[1901-2000]: loss = 0.600458 * 100, metric = 12.97% * 100;
Finished Epoch[1 of 200]: [Training] loss = 0.728874 * 2000, metric = 16.21% * 2000 1370.023s (  1.5 samples/s);
Finished Evaluation [1]: Minibatch[1-5000]: metric = 23.90% * 5000;
0.7658888839364052
 Minibatch[   1- 100]: loss = 0.602718 * 100, metric = 12.90% * 100;
 Minibatch[ 101- 200]: loss = 0.624256 * 100, metric = 13.83% * 100;
 Minibatch[ 201- 300]: loss = 0.596979 * 100, metric = 12.42% * 100;
 Minibatch[ 301- 400]: loss = 0.607411 * 100, metric = 12.63% * 100;
 Minibatch[ 401- 500]: loss = 0.592726 * 100, metric = 12.63% * 100;
 Minibatch[ 501- 600]: loss = 0.608966 * 100, metric = 12.59% * 100;
 Minibatch[ 601- 700]: loss = 0.580326 * 100, metric = 12.42% * 100;
 Minibatch[ 701- 800]: loss = 0.598249 * 100, metric = 12.69% * 100;
 Minibatch[ 801- 900]: loss = 0.567184 * 100, metric = 12.15% * 100;
 Minibatch[ 901-1000]: loss = 0.558453 * 100, metric = 11.85% * 100;
 Minibatch[1001-1100]: loss = 0.587661 * 100, metric = 12.66% * 100;
 Minibatch[1101-1200]: loss = 0.571807 * 100, metric = 11.97% * 100;
 Minibatch[1201-1300]: loss = 0.573480 * 100, metric = 12.21% * 100;
 Minibatch[1301-1400]: loss = 0.574437 * 100, metric = 11.76% * 100;
 Minibatch[1401-1500]: loss = 0.553917 * 100, metric = 11.43% * 100;
 Minibatch[1501-1600]: loss = 0.546732 * 100, metric = 11.23% * 100;
 Minibatch[1601-1700]: loss = 0.561452 * 100, metric = 11.77% * 100;
 Minibatch[1701-1800]: loss = 0.572971 * 100, metric = 12.09% * 100;
 Minibatch[1801-1900]: loss = 0.563497 * 100, metric = 11.80% * 100;
 Minibatch[1901-2000]: loss = 0.535461 * 100, metric = 11.03% * 100;
Finished Epoch[2 of 200]: [Training] loss = 0.578934 * 2000, metric = 12.20% * 2000 1368.867s (  1.5 samples/s);
Finished Evaluation [2]: Minibatch[1-5000]: metric = 20.53% * 5000;
0.6743498768895865
 Minibatch[   1- 100]: loss = 0.552976 * 100, metric = 11.73% * 100;
 Minibatch[ 101- 200]: loss = 0.557552 * 100, metric = 11.42% * 100;
 Minibatch[ 201- 300]: loss = 0.550450 * 100, metric = 11.52% * 100;
 Minibatch[ 301- 400]: loss = 0.559009 * 100, metric = 11.79% * 100;
 Minibatch[ 401- 500]: loss = 0.559817 * 100, metric = 11.72% * 100;
 Minibatch[ 501- 600]: loss = 0.561934 * 100, metric = 11.86% * 100;
 Minibatch[ 601- 700]: loss = 0.552249 * 100, metric = 11.34% * 100;
 Minibatch[ 701- 800]: loss = 0.531121 * 100, metric = 11.04% * 100;
 Minibatch[ 801- 900]: loss = 0.549081 * 100, metric = 11.34% * 100;
 Minibatch[ 901-1000]: loss = 0.523876 * 100, metric = 10.97% * 100;
 Minibatch[1001-1100]: loss = 0.542394 * 100, metric = 11.16% * 100;
 Minibatch[1101-1200]: loss = 0.524516 * 100, metric = 10.90% * 100;
 Minibatch[1201-1300]: loss = 0.516002 * 100, metric = 10.59% * 100;
 Minibatch[1301-1400]: loss = 0.541633 * 100, metric = 11.40% * 100;
 Minibatch[1401-1500]: loss = 0.540579 * 100, metric = 11.28% * 100;
 Minibatch[1501-1600]: loss = 0.524106 * 100, metric = 10.49% * 100;
 Minibatch[1601-1700]: loss = 0.508714 * 100, metric = 10.28% * 100;
 Minibatch[1701-1800]: loss = 0.541431 * 100, metric = 11.35% * 100;
 Minibatch[1801-1900]: loss = 0.524774 * 100, metric = 10.82% * 100;
 Minibatch[1901-2000]: loss = 0.517537 * 100, metric = 10.69% * 100;
Finished Epoch[3 of 200]: [Training] loss = 0.538987 * 2000, metric = 11.18% * 2000 1316.006s (  1.5 samples/s);
Finished Evaluation [3]: Minibatch[1-5000]: metric = 19.08% * 5000;
0.6407382179051637
 Minibatch[   1- 100]: loss = 0.536437 * 100, metric = 10.96% * 100;
 Minibatch[ 101- 200]: loss = 0.506041 * 100, metric = 10.24% * 100;
 Minibatch[ 201- 300]: loss = 0.530231 * 100, metric = 11.47% * 100;
 Minibatch[ 301- 400]: loss = 0.489914 * 100, metric = 10.03% * 100;
 Minibatch[ 401- 500]: loss = 0.525366 * 100, metric = 10.84% * 100;
 Minibatch[ 501- 600]: loss = 0.501295 * 100, metric = 10.28% * 100;
 Minibatch[ 601- 700]: loss = 0.509600 * 100, metric = 10.28% * 100;
 Minibatch[ 701- 800]: loss = 0.517720 * 100, metric = 10.56% * 100;
 Minibatch[ 801- 900]: loss = 0.519072 * 100, metric = 10.88% * 100;
 Minibatch[ 901-1000]: loss = 0.517322 * 100, metric = 10.97% * 100;
 Minibatch[1001-1100]: loss = 0.521105 * 100, metric = 10.88% * 100;
 Minibatch[1101-1200]: loss = 0.497581 * 100, metric = 10.30% * 100;
 Minibatch[1201-1300]: loss = 0.504208 * 100, metric = 10.46% * 100;
 Minibatch[1301-1400]: loss = 0.529432 * 100, metric = 11.02% * 100;
 Minibatch[1401-1500]: loss = 0.526283 * 100, metric = 10.84% * 100;
 Minibatch[1501-1600]: loss = 0.491523 * 100, metric = 10.00% * 100;
 Minibatch[1601-1700]: loss = 0.517089 * 100, metric = 10.79% * 100;
 Minibatch[1701-1800]: loss = 0.516458 * 100, metric = 10.83% * 100;
 Minibatch[1801-1900]: loss = 0.500850 * 100, metric = 10.28% * 100;
 Minibatch[1901-2000]: loss = 0.496627 * 100, metric = 9.90% * 100;
Finished Epoch[4 of 200]: [Training] loss = 0.512708 * 2000, metric = 10.59% * 2000 1386.900s (  1.4 samples/s);
Finished Evaluation [4]: Minibatch[1-5000]: metric = 19.93% * 5000;
 Minibatch[   1- 100]: loss = 0.512801 * 100, metric = 10.38% * 100;
 Minibatch[ 101- 200]: loss = 0.500693 * 100, metric = 10.37% * 100;
 Minibatch[ 201- 300]: loss = 0.495676 * 100, metric = 10.14% * 100;
 Minibatch[ 301- 400]: loss = 0.517305 * 100, metric = 10.79% * 100;
 Minibatch[ 401- 500]: loss = 0.477562 * 100, metric = 9.67% * 100;
 Minibatch[ 501- 600]: loss = 0.483660 * 100, metric = 9.64% * 100;
 Minibatch[ 601- 700]: loss = 0.481348 * 100, metric = 9.54% * 100;
 Minibatch[ 701- 800]: loss = 0.490168 * 100, metric = 9.89% * 100;
 Minibatch[ 801- 900]: loss = 0.480017 * 100, metric = 9.69% * 100;
 Minibatch[ 901-1000]: loss = 0.478323 * 100, metric = 9.80% * 100;
 Minibatch[1001-1100]: loss = 0.482645 * 100, metric = 9.72% * 100;
 Minibatch[1101-1200]: loss = 0.461332 * 100, metric = 9.33% * 100;
 Minibatch[1201-1300]: loss = 0.491915 * 100, metric = 9.77% * 100;
 Minibatch[1301-1400]: loss = 0.500118 * 100, metric = 10.33% * 100;
 Minibatch[1401-1500]: loss = 0.482496 * 100, metric = 9.92% * 100;
 Minibatch[1501-1600]: loss = 0.485982 * 100, metric = 9.78% * 100;
 Minibatch[1601-1700]: loss = 0.490116 * 100, metric = 10.09% * 100;
 Minibatch[1701-1800]: loss = 0.493009 * 100, metric = 10.07% * 100;
 Minibatch[1801-1900]: loss = 0.486885 * 100, metric = 10.01% * 100;
 Minibatch[1901-2000]: loss = 0.474175 * 100, metric = 9.59% * 100;
Finished Epoch[5 of 200]: [Training] loss = 0.488311 * 2000, metric = 9.93% * 2000 1279.830s (  1.6 samples/s);
Finished Evaluation [5]: Minibatch[1-5000]: metric = 17.45% * 5000;
0.6070765072345734
 Minibatch[   1- 100]: loss = 0.469060 * 100, metric = 9.57% * 100;
 Minibatch[ 101- 200]: loss = 0.464191 * 100, metric = 9.51% * 100;
 Minibatch[ 201- 300]: loss = 0.479991 * 100, metric = 9.75% * 100;
 Minibatch[ 301- 400]: loss = 0.470251 * 100, metric = 9.25% * 100;
 Minibatch[ 401- 500]: loss = 0.454728 * 100, metric = 9.25% * 100;
 Minibatch[ 501- 600]: loss = 0.464960 * 100, metric = 9.53% * 100;
 Minibatch[ 601- 700]: loss = 0.466305 * 100, metric = 9.55% * 100;
 Minibatch[ 701- 800]: loss = 0.467192 * 100, metric = 9.25% * 100;
 Minibatch[ 801- 900]: loss = 0.473177 * 100, metric = 9.70% * 100;
 Minibatch[ 901-1000]: loss = 0.471699 * 100, metric = 9.62% * 100;
 Minibatch[1001-1100]: loss = 0.468143 * 100, metric = 9.26% * 100;
 Minibatch[1101-1200]: loss = 0.482082 * 100, metric = 9.82% * 100;
 Minibatch[1201-1300]: loss = 0.487639 * 100, metric = 9.86% * 100;
 Minibatch[1301-1400]: loss = 0.462961 * 100, metric = 9.35% * 100;
 Minibatch[1401-1500]: loss = 0.475161 * 100, metric = 9.77% * 100;
 Minibatch[1501-1600]: loss = 0.451458 * 100, metric = 9.04% * 100;
 Minibatch[1601-1700]: loss = 0.458302 * 100, metric = 9.08% * 100;
 Minibatch[1701-1800]: loss = 0.457466 * 100, metric = 9.24% * 100;
 Minibatch[1801-1900]: loss = 0.474896 * 100, metric = 9.50% * 100;
 Minibatch[1901-2000]: loss = 0.456029 * 100, metric = 9.04% * 100;
Finished Epoch[6 of 200]: [Training] loss = 0.467784 * 2000, metric = 9.45% * 2000 1294.027s (  1.5 samples/s);
Finished Evaluation [6]: Minibatch[1-5000]: metric = 19.61% * 5000;
 Minibatch[   1- 100]: loss = 0.463250 * 100, metric = 9.33% * 100;
 Minibatch[ 101- 200]: loss = 0.473448 * 100, metric = 9.49% * 100;
 Minibatch[ 201- 300]: loss = 0.482238 * 100, metric = 9.96% * 100;
 Minibatch[ 301- 400]: loss = 0.461202 * 100, metric = 9.05% * 100;
 Minibatch[ 401- 500]: loss = 0.469212 * 100, metric = 9.25% * 100;
 Minibatch[ 501- 600]: loss = 0.452331 * 100, metric = 8.97% * 100;
 Minibatch[ 601- 700]: loss = 0.465295 * 100, metric = 8.94% * 100;
 Minibatch[ 701- 800]: loss = 0.466827 * 100, metric = 9.36% * 100;
 Minibatch[ 801- 900]: loss = 0.470388 * 100, metric = 9.68% * 100;
 Minibatch[ 901-1000]: loss = 0.463336 * 100, metric = 9.47% * 100;
 Minibatch[1001-1100]: loss = 0.475569 * 100, metric = 9.71% * 100;
 Minibatch[1101-1200]: loss = 0.452747 * 100, metric = 9.02% * 100;
 Minibatch[1201-1300]: loss = 0.474238 * 100, metric = 9.79% * 100;
 Minibatch[1301-1400]: loss = 0.455687 * 100, metric = 9.06% * 100;
 Minibatch[1401-1500]: loss = 0.459227 * 100, metric = 9.26% * 100;
 Minibatch[1501-1600]: loss = 0.459426 * 100, metric = 9.33% * 100;
 Minibatch[1601-1700]: loss = 0.462381 * 100, metric = 9.25% * 100;
 Minibatch[1701-1800]: loss = 0.453960 * 100, metric = 9.02% * 100;
 Minibatch[1801-1900]: loss = 0.458734 * 100, metric = 9.44% * 100;
 Minibatch[1901-2000]: loss = 0.461372 * 100, metric = 9.27% * 100;
Finished Epoch[7 of 200]: [Training] loss = 0.464043 * 2000, metric = 9.33% * 2000 1271.694s (  1.6 samples/s);
Finished Evaluation [7]: Minibatch[1-5000]: metric = 15.97% * 5000;
0.567981885445118
 Minibatch[   1- 100]: loss = 0.467002 * 100, metric = 9.46% * 100;
 Minibatch[ 101- 200]: loss = 0.452262 * 100, metric = 9.12% * 100;
 Minibatch[ 201- 300]: loss = 0.448591 * 100, metric = 9.10% * 100;
 Minibatch[ 301- 400]: loss = 0.454108 * 100, metric = 9.29% * 100;
 Minibatch[ 401- 500]: loss = 0.458080 * 100, metric = 9.32% * 100;
 Minibatch[ 501- 600]: loss = 0.476425 * 100, metric = 9.70% * 100;
 Minibatch[ 601- 700]: loss = 0.441528 * 100, metric = 8.81% * 100;
 Minibatch[ 701- 800]: loss = 0.458717 * 100, metric = 9.06% * 100;
 Minibatch[ 801- 900]: loss = 0.438694 * 100, metric = 8.46% * 100;
 Minibatch[ 901-1000]: loss = 0.426522 * 100, metric = 8.32% * 100;
 Minibatch[1001-1100]: loss = 0.440118 * 100, metric = 8.75% * 100;
 Minibatch[1101-1200]: loss = 0.439913 * 100, metric = 8.78% * 100;
 Minibatch[1201-1300]: loss = 0.445947 * 100, metric = 9.05% * 100;
 Minibatch[1301-1400]: loss = 0.451188 * 100, metric = 9.11% * 100;
 Minibatch[1401-1500]: loss = 0.442524 * 100, metric = 8.71% * 100;
 Minibatch[1501-1600]: loss = 0.448654 * 100, metric = 8.98% * 100;
 Minibatch[1601-1700]: loss = 0.436960 * 100, metric = 8.58% * 100;
 Minibatch[1701-1800]: loss = 0.437826 * 100, metric = 8.48% * 100;
 Minibatch[1801-1900]: loss = 0.439338 * 100, metric = 8.69% * 100;
 Minibatch[1901-2000]: loss = 0.448203 * 100, metric = 8.82% * 100;
Finished Epoch[8 of 200]: [Training] loss = 0.447630 * 2000, metric = 8.93% * 2000 1312.461s (  1.5 samples/s);
Finished Evaluation [8]: Minibatch[1-5000]: metric = 15.52% * 5000;
0.544146025633812
 Minibatch[   1- 100]: loss = 0.422998 * 100, metric = 8.41% * 100;
 Minibatch[ 101- 200]: loss = 0.448216 * 100, metric = 8.96% * 100;
 Minibatch[ 201- 300]: loss = 0.435976 * 100, metric = 8.45% * 100;
 Minibatch[ 301- 400]: loss = 0.450488 * 100, metric = 8.84% * 100;
 Minibatch[ 401- 500]: loss = 0.439166 * 100, metric = 8.53% * 100;
 Minibatch[ 501- 600]: loss = 0.434706 * 100, metric = 8.60% * 100;
 Minibatch[ 601- 700]: loss = 0.431451 * 100, metric = 8.43% * 100;
 Minibatch[ 701- 800]: loss = 0.413977 * 100, metric = 8.13% * 100;
 Minibatch[ 801- 900]: loss = 0.422349 * 100, metric = 8.17% * 100;
 Minibatch[ 901-1000]: loss = 0.432725 * 100, metric = 8.69% * 100;
 Minibatch[1001-1100]: loss = 0.403992 * 100, metric = 7.73% * 100;
 Minibatch[1101-1200]: loss = 0.435285 * 100, metric = 8.46% * 100;
 Minibatch[1201-1300]: loss = 0.418364 * 100, metric = 8.30% * 100;
 Minibatch[1301-1400]: loss = 0.422615 * 100, metric = 8.44% * 100;
 Minibatch[1401-1500]: loss = 0.440839 * 100, metric = 8.85% * 100;
 Minibatch[1501-1600]: loss = 0.434669 * 100, metric = 8.53% * 100;
 Minibatch[1601-1700]: loss = 0.437025 * 100, metric = 8.79% * 100;
 Minibatch[1701-1800]: loss = 0.423906 * 100, metric = 8.21% * 100;
 Minibatch[1801-1900]: loss = 0.422867 * 100, metric = 8.37% * 100;
 Minibatch[1901-2000]: loss = 0.438153 * 100, metric = 8.69% * 100;
Finished Epoch[9 of 200]: [Training] loss = 0.430488 * 2000, metric = 8.48% * 2000 1468.993s (  1.4 samples/s);
Finished Evaluation [9]: Minibatch[1-5000]: metric = 14.90% * 5000;
0.5360866124927998
 Minibatch[   1- 100]: loss = 0.444667 * 100, metric = 9.19% * 100;
 Minibatch[ 101- 200]: loss = 0.429276 * 100, metric = 8.60% * 100;
 Minibatch[ 201- 300]: loss = 0.435734 * 100, metric = 8.51% * 100;
 Minibatch[ 301- 400]: loss = 0.424571 * 100, metric = 8.29% * 100;
 Minibatch[ 401- 500]: loss = 0.431107 * 100, metric = 8.38% * 100;
 Minibatch[ 501- 600]: loss = 0.410565 * 100, metric = 8.26% * 100;
 Minibatch[ 601- 700]: loss = 0.406350 * 100, metric = 7.97% * 100;
 Minibatch[ 701- 800]: loss = 0.403326 * 100, metric = 7.62% * 100;
 Minibatch[ 801- 900]: loss = 0.422781 * 100, metric = 8.27% * 100;
 Minibatch[ 901-1000]: loss = 0.424698 * 100, metric = 8.17% * 100;
 Minibatch[1001-1100]: loss = 0.430842 * 100, metric = 8.57% * 100;
 Minibatch[1101-1200]: loss = 0.427078 * 100, metric = 8.28% * 100;
 Minibatch[1201-1300]: loss = 0.424409 * 100, metric = 8.51% * 100;
 Minibatch[1301-1400]: loss = 0.423863 * 100, metric = 8.42% * 100;
 Minibatch[1401-1500]: loss = 0.413460 * 100, metric = 8.00% * 100;
 Minibatch[1501-1600]: loss = 0.429962 * 100, metric = 8.59% * 100;
 Minibatch[1601-1700]: loss = 0.421013 * 100, metric = 7.96% * 100;
 Minibatch[1701-1800]: loss = 0.430322 * 100, metric = 8.34% * 100;
 Minibatch[1801-1900]: loss = 0.430271 * 100, metric = 8.58% * 100;
 Minibatch[1901-2000]: loss = 0.419700 * 100, metric = 8.16% * 100;
Finished Epoch[10 of 200]: [Training] loss = 0.424200 * 2000, metric = 8.33% * 2000 1289.748s (  1.6 samples/s);
Finished Evaluation [10]: Minibatch[1-5000]: metric = 14.30% * 5000;
0.5290518198341131
 Minibatch[   1- 100]: loss = 0.405209 * 100, metric = 7.79% * 100;
 Minibatch[ 101- 200]: loss = 0.419444 * 100, metric = 8.12% * 100;
 Minibatch[ 201- 300]: loss = 0.431553 * 100, metric = 8.61% * 100;
 Minibatch[ 301- 400]: loss = 0.420942 * 100, metric = 8.14% * 100;
 Minibatch[ 401- 500]: loss = 0.410891 * 100, metric = 7.83% * 100;
 Minibatch[ 501- 600]: loss = 0.425817 * 100, metric = 8.28% * 100;
 Minibatch[ 601- 700]: loss = 0.412065 * 100, metric = 8.19% * 100;
 Minibatch[ 701- 800]: loss = 0.415762 * 100, metric = 8.18% * 100;
 Minibatch[ 801- 900]: loss = 0.414392 * 100, metric = 7.99% * 100;
 Minibatch[ 901-1000]: loss = 0.428307 * 100, metric = 8.20% * 100;
 Minibatch[1001-1100]: loss = 0.414436 * 100, metric = 8.18% * 100;
 Minibatch[1101-1200]: loss = 0.424582 * 100, metric = 8.35% * 100;
 Minibatch[1201-1300]: loss = 0.410305 * 100, metric = 7.96% * 100;
 Minibatch[1301-1400]: loss = 0.400261 * 100, metric = 7.73% * 100;
 Minibatch[1401-1500]: loss = 0.420320 * 100, metric = 8.26% * 100;
 Minibatch[1501-1600]: loss = 0.409464 * 100, metric = 7.81% * 100;
 Minibatch[1601-1700]: loss = 0.411650 * 100, metric = 7.85% * 100;
 Minibatch[1701-1800]: loss = 0.423843 * 100, metric = 8.39% * 100;
 Minibatch[1801-1900]: loss = 0.412231 * 100, metric = 7.88% * 100;
 Minibatch[1901-2000]: loss = 0.401865 * 100, metric = 7.79% * 100;
Finished Epoch[11 of 200]: [Training] loss = 0.415667 * 2000, metric = 8.08% * 2000 1213.236s (  1.6 samples/s);
Finished Evaluation [11]: Minibatch[1-5000]: metric = 14.80% * 5000;
 Minibatch[   1- 100]: loss = 0.387893 * 100, metric = 7.45% * 100;
 Minibatch[ 101- 200]: loss = 0.397226 * 100, metric = 7.45% * 100;
 Minibatch[ 201- 300]: loss = 0.398105 * 100, metric = 7.63% * 100;
 Minibatch[ 301- 400]: loss = 0.434002 * 100, metric = 8.59% * 100;
 Minibatch[ 401- 500]: loss = 0.405754 * 100, metric = 7.93% * 100;
 Minibatch[ 501- 600]: loss = 0.389892 * 100, metric = 7.36% * 100;
 Minibatch[ 601- 700]: loss = 0.397194 * 100, metric = 7.70% * 100;
 Minibatch[ 701- 800]: loss = 0.398928 * 100, metric = 7.65% * 100;
 Minibatch[ 801- 900]: loss = 0.398428 * 100, metric = 7.67% * 100;
 Minibatch[ 901-1000]: loss = 0.411479 * 100, metric = 8.09% * 100;
 Minibatch[1001-1100]: loss = 0.409874 * 100, metric = 8.06% * 100;
 Minibatch[1101-1200]: loss = 0.406144 * 100, metric = 7.83% * 100;
 Minibatch[1201-1300]: loss = 0.408943 * 100, metric = 8.05% * 100;
 Minibatch[1301-1400]: loss = 0.398493 * 100, metric = 7.77% * 100;
 Minibatch[1401-1500]: loss = 0.408820 * 100, metric = 8.00% * 100;
 Minibatch[1501-1600]: loss = 0.389520 * 100, metric = 7.47% * 100;
 Minibatch[1601-1700]: loss = 0.410242 * 100, metric = 8.11% * 100;
 Minibatch[1701-1800]: loss = 0.396401 * 100, metric = 7.54% * 100;
 Minibatch[1801-1900]: loss = 0.400363 * 100, metric = 7.86% * 100;
 Minibatch[1901-2000]: loss = 0.416064 * 100, metric = 8.05% * 100;
Finished Epoch[12 of 200]: [Training] loss = 0.403188 * 2000, metric = 7.81% * 2000 1259.371s (  1.6 samples/s);
Finished Evaluation [12]: Minibatch[1-5000]: metric = 15.11% * 5000;
 Minibatch[   1- 100]: loss = 0.405402 * 100, metric = 7.82% * 100;
 Minibatch[ 101- 200]: loss = 0.405724 * 100, metric = 7.97% * 100;
 Minibatch[ 201- 300]: loss = 0.403317 * 100, metric = 7.69% * 100;
 Minibatch[ 301- 400]: loss = 0.408709 * 100, metric = 7.85% * 100;
 Minibatch[ 401- 500]: loss = 0.409339 * 100, metric = 8.15% * 100;
 Minibatch[ 501- 600]: loss = 0.415825 * 100, metric = 8.22% * 100;
 Minibatch[ 601- 700]: loss = 0.393363 * 100, metric = 7.54% * 100;
 Minibatch[ 701- 800]: loss = 0.392850 * 100, metric = 7.38% * 100;
 Minibatch[ 801- 900]: loss = 0.389572 * 100, metric = 7.32% * 100;
 Minibatch[ 901-1000]: loss = 0.396223 * 100, metric = 7.70% * 100;
 Minibatch[1001-1100]: loss = 0.408800 * 100, metric = 7.94% * 100;
 Minibatch[1101-1200]: loss = 0.393464 * 100, metric = 7.70% * 100;
 Minibatch[1201-1300]: loss = 0.397762 * 100, metric = 7.70% * 100;
 Minibatch[1301-1400]: loss = 0.392555 * 100, metric = 7.47% * 100;
 Minibatch[1401-1500]: loss = 0.392183 * 100, metric = 7.45% * 100;
 Minibatch[1501-1600]: loss = 0.389501 * 100, metric = 7.31% * 100;
 Minibatch[1601-1700]: loss = 0.386767 * 100, metric = 7.41% * 100;
 Minibatch[1701-1800]: loss = 0.398347 * 100, metric = 7.67% * 100;
 Minibatch[1801-1900]: loss = 0.386510 * 100, metric = 7.37% * 100;
 Minibatch[1901-2000]: loss = 0.399767 * 100, metric = 7.70% * 100;
Finished Epoch[13 of 200]: [Training] loss = 0.398299 * 2000, metric = 7.67% * 2000 1573.449s (  1.3 samples/s);
Finished Evaluation [13]: Minibatch[1-5000]: metric = 16.11% * 5000;
 Minibatch[   1- 100]: loss = 0.392904 * 100, metric = 7.41% * 100;
 Minibatch[ 101- 200]: loss = 0.387735 * 100, metric = 7.34% * 100;
 Minibatch[ 201- 300]: loss = 0.394100 * 100, metric = 7.72% * 100;
 Minibatch[ 301- 400]: loss = 0.393761 * 100, metric = 7.49% * 100;
 Minibatch[ 401- 500]: loss = 0.396116 * 100, metric = 7.70% * 100;
 Minibatch[ 501- 600]: loss = 0.391574 * 100, metric = 7.51% * 100;
 Minibatch[ 601- 700]: loss = 0.390328 * 100, metric = 7.49% * 100;
 Minibatch[ 701- 800]: loss = 0.403652 * 100, metric = 7.84% * 100;
 Minibatch[ 801- 900]: loss = 0.405600 * 100, metric = 8.04% * 100;
 Minibatch[ 901-1000]: loss = 0.391504 * 100, metric = 7.47% * 100;
 Minibatch[1001-1100]: loss = 0.395526 * 100, metric = 7.73% * 100;
 Minibatch[1101-1200]: loss = 0.387034 * 100, metric = 7.29% * 100;
 Minibatch[1201-1300]: loss = 0.373509 * 100, metric = 6.99% * 100;
 Minibatch[1301-1400]: loss = 0.396473 * 100, metric = 7.61% * 100;
 Minibatch[1401-1500]: loss = 0.390584 * 100, metric = 7.62% * 100;
 Minibatch[1501-1600]: loss = 0.377323 * 100, metric = 7.38% * 100;
 Minibatch[1601-1700]: loss = 0.386420 * 100, metric = 7.33% * 100;
 Minibatch[1701-1800]: loss = 0.392418 * 100, metric = 7.38% * 100;
 Minibatch[1801-1900]: loss = 0.395600 * 100, metric = 7.64% * 100;
 Minibatch[1901-2000]: loss = 0.402792 * 100, metric = 7.79% * 100;
Finished Epoch[14 of 200]: [Training] loss = 0.392248 * 2000, metric = 7.54% * 2000 1561.591s (  1.3 samples/s);
Finished Evaluation [14]: Minibatch[1-5000]: metric = 17.13% * 5000;
 Minibatch[   1- 100]: loss = 0.389625 * 100, metric = 7.54% * 100;
 Minibatch[ 101- 200]: loss = 0.390854 * 100, metric = 7.52% * 100;
 Minibatch[ 201- 300]: loss = 0.397144 * 100, metric = 7.71% * 100;
 Minibatch[ 301- 400]: loss = 0.385085 * 100, metric = 7.17% * 100;
 Minibatch[ 401- 500]: loss = 0.389770 * 100, metric = 7.43% * 100;
 Minibatch[ 501- 600]: loss = 0.377427 * 100, metric = 7.07% * 100;
 Minibatch[ 601- 700]: loss = 0.366691 * 100, metric = 6.93% * 100;
 Minibatch[ 701- 800]: loss = 0.397492 * 100, metric = 7.45% * 100;
 Minibatch[ 801- 900]: loss = 0.406070 * 100, metric = 8.05% * 100;
 Minibatch[ 901-1000]: loss = 0.393438 * 100, metric = 7.58% * 100;
 Minibatch[1001-1100]: loss = 0.394038 * 100, metric = 7.48% * 100;
 Minibatch[1101-1200]: loss = 0.386400 * 100, metric = 7.24% * 100;
 Minibatch[1201-1300]: loss = 0.376609 * 100, metric = 7.01% * 100;
 Minibatch[1301-1400]: loss = 0.403853 * 100, metric = 7.84% * 100;
 Minibatch[1401-1500]: loss = 0.362297 * 100, metric = 6.88% * 100;
 Minibatch[1501-1600]: loss = 0.369948 * 100, metric = 7.07% * 100;
 Minibatch[1601-1700]: loss = 0.379357 * 100, metric = 7.21% * 100;
 Minibatch[1701-1800]: loss = 0.368066 * 100, metric = 6.79% * 100;
 Minibatch[1801-1900]: loss = 0.380735 * 100, metric = 7.23% * 100;
 Minibatch[1901-2000]: loss = 0.370242 * 100, metric = 7.00% * 100;
Finished Epoch[15 of 200]: [Training] loss = 0.384257 * 2000, metric = 7.31% * 2000 1575.039s (  1.3 samples/s);
Finished Evaluation [15]: Minibatch[1-5000]: metric = 13.89% * 5000;
0.5255330811470748
 Minibatch[   1- 100]: loss = 0.390550 * 100, metric = 7.65% * 100;
 Minibatch[ 101- 200]: loss = 0.382269 * 100, metric = 7.27% * 100;
 Minibatch[ 201- 300]: loss = 0.386091 * 100, metric = 7.44% * 100;
 Minibatch[ 301- 400]: loss = 0.388481 * 100, metric = 7.46% * 100;
 Minibatch[ 401- 500]: loss = 0.370578 * 100, metric = 6.99% * 100;
 Minibatch[ 501- 600]: loss = 0.376132 * 100, metric = 7.16% * 100;
 Minibatch[ 601- 700]: loss = 0.377134 * 100, metric = 7.24% * 100;
 Minibatch[ 701- 800]: loss = 0.366020 * 100, metric = 6.86% * 100;
 Minibatch[ 801- 900]: loss = 0.372597 * 100, metric = 6.95% * 100;
 Minibatch[ 901-1000]: loss = 0.376507 * 100, metric = 7.11% * 100;
 Minibatch[1001-1100]: loss = 0.361411 * 100, metric = 6.85% * 100;
 Minibatch[1101-1200]: loss = 0.363617 * 100, metric = 6.89% * 100;
 Minibatch[1201-1300]: loss = 0.363073 * 100, metric = 6.76% * 100;
 Minibatch[1301-1400]: loss = 0.365196 * 100, metric = 6.68% * 100;
 Minibatch[1401-1500]: loss = 0.376627 * 100, metric = 7.12% * 100;
 Minibatch[1501-1600]: loss = 0.375831 * 100, metric = 7.20% * 100;
 Minibatch[1601-1700]: loss = 0.381354 * 100, metric = 7.37% * 100;
 Minibatch[1701-1800]: loss = 0.393329 * 100, metric = 7.38% * 100;
 Minibatch[1801-1900]: loss = 0.382341 * 100, metric = 7.27% * 100;
 Minibatch[1901-2000]: loss = 0.371791 * 100, metric = 7.16% * 100;
Finished Epoch[16 of 200]: [Training] loss = 0.376047 * 2000, metric = 7.14% * 2000 1518.526s (  1.3 samples/s);
Finished Evaluation [16]: Minibatch[1-5000]: metric = 14.54% * 5000;
 Minibatch[   1- 100]: loss = 0.367902 * 100, metric = 7.05% * 100;
 Minibatch[ 101- 200]: loss = 0.381079 * 100, metric = 7.22% * 100;
 Minibatch[ 201- 300]: loss = 0.378707 * 100, metric = 7.36% * 100;
 Minibatch[ 301- 400]: loss = 0.369437 * 100, metric = 6.84% * 100;
 Minibatch[ 401- 500]: loss = 0.376687 * 100, metric = 6.97% * 100;
 Minibatch[ 501- 600]: loss = 0.367063 * 100, metric = 6.86% * 100;
 Minibatch[ 601- 700]: loss = 0.358832 * 100, metric = 6.71% * 100;
 Minibatch[ 701- 800]: loss = 0.377673 * 100, metric = 7.11% * 100;
 Minibatch[ 801- 900]: loss = 0.378922 * 100, metric = 7.21% * 100;
 Minibatch[ 901-1000]: loss = 0.366582 * 100, metric = 6.92% * 100;
 Minibatch[1001-1100]: loss = 0.362692 * 100, metric = 6.84% * 100;
 Minibatch[1101-1200]: loss = 0.383454 * 100, metric = 7.27% * 100;
 Minibatch[1201-1300]: loss = 0.377257 * 100, metric = 7.07% * 100;
 Minibatch[1301-1400]: loss = 0.363637 * 100, metric = 6.80% * 100;
 Minibatch[1401-1500]: loss = 0.371184 * 100, metric = 7.26% * 100;
 Minibatch[1501-1600]: loss = 0.367746 * 100, metric = 6.92% * 100;
 Minibatch[1601-1700]: loss = 0.374262 * 100, metric = 6.97% * 100;
 Minibatch[1701-1800]: loss = 0.358538 * 100, metric = 6.72% * 100;
 Minibatch[1801-1900]: loss = 0.386591 * 100, metric = 7.36% * 100;
 Minibatch[1901-2000]: loss = 0.386704 * 100, metric = 7.39% * 100;
Finished Epoch[17 of 200]: [Training] loss = 0.372748 * 2000, metric = 7.04% * 2000 1479.575s (  1.4 samples/s);
Finished Evaluation [17]: Minibatch[1-5000]: metric = 14.03% * 5000;
 Minibatch[   1- 100]: loss = 0.359351 * 100, metric = 6.55% * 100;
 Minibatch[ 101- 200]: loss = 0.383096 * 100, metric = 7.27% * 100;
 Minibatch[ 201- 300]: loss = 0.360199 * 100, metric = 6.89% * 100;
 Minibatch[ 301- 400]: loss = 0.372937 * 100, metric = 7.01% * 100;
 Minibatch[ 401- 500]: loss = 0.357211 * 100, metric = 6.57% * 100;
 Minibatch[ 501- 600]: loss = 0.366495 * 100, metric = 6.99% * 100;
 Minibatch[ 601- 700]: loss = 0.367421 * 100, metric = 6.89% * 100;
 Minibatch[ 701- 800]: loss = 0.356805 * 100, metric = 6.61% * 100;
 Minibatch[ 801- 900]: loss = 0.370539 * 100, metric = 7.03% * 100;
 Minibatch[ 901-1000]: loss = 0.372935 * 100, metric = 7.04% * 100;
 Minibatch[1001-1100]: loss = 0.377904 * 100, metric = 7.26% * 100;
 Minibatch[1101-1200]: loss = 0.366918 * 100, metric = 6.89% * 100;
 Minibatch[1201-1300]: loss = 0.380822 * 100, metric = 7.34% * 100;
 Minibatch[1301-1400]: loss = 0.379342 * 100, metric = 7.09% * 100;
 Minibatch[1401-1500]: loss = 0.350861 * 100, metric = 6.29% * 100;
 Minibatch[1501-1600]: loss = 0.365404 * 100, metric = 6.70% * 100;
 Minibatch[1601-1700]: loss = 0.345573 * 100, metric = 6.29% * 100;
 Minibatch[1701-1800]: loss = 0.354251 * 100, metric = 6.51% * 100;
 Minibatch[1801-1900]: loss = 0.350245 * 100, metric = 6.56% * 100;
 Minibatch[1901-2000]: loss = 0.351318 * 100, metric = 6.32% * 100;
Finished Epoch[18 of 200]: [Training] loss = 0.364481 * 2000, metric = 6.81% * 2000 1493.570s (  1.3 samples/s);
Finished Evaluation [18]: Minibatch[1-5000]: metric = 15.09% * 5000;
 Minibatch[   1- 100]: loss = 0.374176 * 100, metric = 7.17% * 100;
 Minibatch[ 101- 200]: loss = 0.378895 * 100, metric = 7.10% * 100;
 Minibatch[ 201- 300]: loss = 0.356772 * 100, metric = 6.56% * 100;
 Minibatch[ 301- 400]: loss = 0.367470 * 100, metric = 6.91% * 100;
 Minibatch[ 401- 500]: loss = 0.364865 * 100, metric = 6.74% * 100;
 Minibatch[ 501- 600]: loss = 0.357244 * 100, metric = 6.62% * 100;
 Minibatch[ 601- 700]: loss = 0.366715 * 100, metric = 6.98% * 100;
 Minibatch[ 701- 800]: loss = 0.356895 * 100, metric = 6.62% * 100;
 Minibatch[ 801- 900]: loss = 0.382947 * 100, metric = 7.38% * 100;
 Minibatch[ 901-1000]: loss = 0.357268 * 100, metric = 6.62% * 100;
 Minibatch[1001-1100]: loss = 0.366842 * 100, metric = 6.95% * 100;
 Minibatch[1101-1200]: loss = 0.364988 * 100, metric = 6.85% * 100;
 Minibatch[1201-1300]: loss = 0.361939 * 100, metric = 7.16% * 100;
 Minibatch[1301-1400]: loss = 0.351559 * 100, metric = 6.73% * 100;
 Minibatch[1401-1500]: loss = 0.364722 * 100, metric = 6.95% * 100;
 Minibatch[1501-1600]: loss = 0.364794 * 100, metric = 6.97% * 100;
 Minibatch[1601-1700]: loss = 0.350318 * 100, metric = 6.75% * 100;
 Minibatch[1701-1800]: loss = 0.345159 * 100, metric = 6.58% * 100;
 Minibatch[1801-1900]: loss = 0.346349 * 100, metric = 6.43% * 100;
 Minibatch[1901-2000]: loss = 0.342792 * 100, metric = 6.26% * 100;
Finished Epoch[19 of 200]: [Training] loss = 0.361136 * 2000, metric = 6.82% * 2000 1730.304s (  1.2 samples/s);
Finished Evaluation [19]: Minibatch[1-5000]: metric = 14.53% * 5000;
 Minibatch[   1- 100]: loss = 0.352713 * 100, metric = 6.45% * 100;
 Minibatch[ 101- 200]: loss = 0.354237 * 100, metric = 6.62% * 100;
 Minibatch[ 201- 300]: loss = 0.344559 * 100, metric = 6.54% * 100;
 Minibatch[ 301- 400]: loss = 0.361462 * 100, metric = 6.62% * 100;
 Minibatch[ 401- 500]: loss = 0.354125 * 100, metric = 6.58% * 100;
 Minibatch[ 501- 600]: loss = 0.360475 * 100, metric = 6.85% * 100;
 Minibatch[ 601- 700]: loss = 0.372824 * 100, metric = 7.01% * 100;
 Minibatch[ 701- 800]: loss = 0.353436 * 100, metric = 6.81% * 100;
 Minibatch[ 801- 900]: loss = 0.362362 * 100, metric = 6.84% * 100;
 Minibatch[ 901-1000]: loss = 0.353531 * 100, metric = 6.65% * 100;
 Minibatch[1001-1100]: loss = 0.344544 * 100, metric = 6.52% * 100;
 Minibatch[1101-1200]: loss = 0.356455 * 100, metric = 6.66% * 100;
 Minibatch[1201-1300]: loss = 0.359223 * 100, metric = 6.78% * 100;
 Minibatch[1301-1400]: loss = 0.364720 * 100, metric = 7.16% * 100;
 Minibatch[1401-1500]: loss = 0.348068 * 100, metric = 6.58% * 100;
 Minibatch[1501-1600]: loss = 0.367681 * 100, metric = 6.73% * 100;
 Minibatch[1601-1700]: loss = 0.362792 * 100, metric = 6.89% * 100;
 Minibatch[1701-1800]: loss = 0.361731 * 100, metric = 6.87% * 100;
 Minibatch[1801-1900]: loss = 0.352587 * 100, metric = 6.70% * 100;
 Minibatch[1901-2000]: loss = 0.354902 * 100, metric = 6.78% * 100;
Finished Epoch[20 of 200]: [Training] loss = 0.357121 * 2000, metric = 6.73% * 2000 1732.300s (  1.2 samples/s);
Finished Evaluation [20]: Minibatch[1-5000]: metric = 14.51% * 5000;
 Minibatch[   1- 100]: loss = 0.361124 * 100, metric = 6.87% * 100;
 Minibatch[ 101- 200]: loss = 0.355461 * 100, metric = 6.66% * 100;
 Minibatch[ 201- 300]: loss = 0.355556 * 100, metric = 6.83% * 100;
 Minibatch[ 301- 400]: loss = 0.360295 * 100, metric = 6.94% * 100;
 Minibatch[ 401- 500]: loss = 0.347218 * 100, metric = 6.71% * 100;
 Minibatch[ 501- 600]: loss = 0.348661 * 100, metric = 6.44% * 100;
 Minibatch[ 601- 700]: loss = 0.349553 * 100, metric = 6.81% * 100;
 Minibatch[ 701- 800]: loss = 0.332160 * 100, metric = 6.19% * 100;
 Minibatch[ 801- 900]: loss = 0.356347 * 100, metric = 6.72% * 100;
 Minibatch[ 901-1000]: loss = 0.347018 * 100, metric = 6.46% * 100;
 Minibatch[1001-1100]: loss = 0.347012 * 100, metric = 6.55% * 100;
 Minibatch[1101-1200]: loss = 0.344407 * 100, metric = 6.33% * 100;
 Minibatch[1201-1300]: loss = 0.348601 * 100, metric = 6.42% * 100;
 Minibatch[1301-1400]: loss = 0.346386 * 100, metric = 6.48% * 100;
 Minibatch[1401-1500]: loss = 0.357938 * 100, metric = 6.73% * 100;
 Minibatch[1501-1600]: loss = 0.364783 * 100, metric = 6.99% * 100;
 Minibatch[1601-1700]: loss = 0.350113 * 100, metric = 6.59% * 100;
 Minibatch[1701-1800]: loss = 0.346569 * 100, metric = 6.43% * 100;
 Minibatch[1801-1900]: loss = 0.366829 * 100, metric = 6.97% * 100;
 Minibatch[1901-2000]: loss = 0.342276 * 100, metric = 6.25% * 100;
Finished Epoch[21 of 200]: [Training] loss = 0.351415 * 2000, metric = 6.62% * 2000 1738.182s (  1.2 samples/s);
Finished Evaluation [21]: Minibatch[1-5000]: metric = 13.52% * 5000;
 Minibatch[   1- 100]: loss = 0.357319 * 100, metric = 6.75% * 100;
 Minibatch[ 101- 200]: loss = 0.356592 * 100, metric = 6.63% * 100;
 Minibatch[ 201- 300]: loss = 0.360320 * 100, metric = 6.79% * 100;
 Minibatch[ 301- 400]: loss = 0.350406 * 100, metric = 6.63% * 100;
 Minibatch[ 401- 500]: loss = 0.346991 * 100, metric = 6.38% * 100;
 Minibatch[ 501- 600]: loss = 0.364919 * 100, metric = 6.78% * 100;
 Minibatch[ 601- 700]: loss = 0.348608 * 100, metric = 6.48% * 100;
 Minibatch[ 701- 800]: loss = 0.351666 * 100, metric = 6.73% * 100;
 Minibatch[ 801- 900]: loss = 0.360108 * 100, metric = 6.77% * 100;
 Minibatch[ 901-1000]: loss = 0.362926 * 100, metric = 6.84% * 100;
 Minibatch[1001-1100]: loss = 0.337829 * 100, metric = 6.17% * 100;
 Minibatch[1101-1200]: loss = 0.329410 * 100, metric = 6.03% * 100;
 Minibatch[1201-1300]: loss = 0.343159 * 100, metric = 6.29% * 100;
 Minibatch[1301-1400]: loss = 0.343250 * 100, metric = 6.32% * 100;
 Minibatch[1401-1500]: loss = 0.340365 * 100, metric = 6.36% * 100;
 Minibatch[1501-1600]: loss = 0.340609 * 100, metric = 6.18% * 100;
 Minibatch[1601-1700]: loss = 0.343412 * 100, metric = 6.50% * 100;
 Minibatch[1701-1800]: loss = 0.338925 * 100, metric = 6.05% * 100;
 Minibatch[1801-1900]: loss = 0.342401 * 100, metric = 6.23% * 100;
 Minibatch[1901-2000]: loss = 0.349728 * 100, metric = 6.60% * 100;
Finished Epoch[22 of 200]: [Training] loss = 0.348447 * 2000, metric = 6.48% * 2000 1640.117s (  1.2 samples/s);
Finished Evaluation [22]: Minibatch[1-5000]: metric = 14.38% * 5000;
 Minibatch[   1- 100]: loss = 0.361279 * 100, metric = 6.84% * 100;
 Minibatch[ 101- 200]: loss = 0.355372 * 100, metric = 6.78% * 100;
 Minibatch[ 201- 300]: loss = 0.345419 * 100, metric = 6.26% * 100;
 Minibatch[ 301- 400]: loss = 0.355518 * 100, metric = 6.74% * 100;
 Minibatch[ 401- 500]: loss = 0.352620 * 100, metric = 6.80% * 100;
 Minibatch[ 501- 600]: loss = 0.354072 * 100, metric = 6.61% * 100;
 Minibatch[ 601- 700]: loss = 0.348454 * 100, metric = 6.44% * 100;
 Minibatch[ 701- 800]: loss = 0.333457 * 100, metric = 6.12% * 100;
 Minibatch[ 801- 900]: loss = 0.338119 * 100, metric = 6.34% * 100;
 Minibatch[ 901-1000]: loss = 0.357138 * 100, metric = 6.73% * 100;
 Minibatch[1001-1100]: loss = 0.339651 * 100, metric = 6.20% * 100;
 Minibatch[1101-1200]: loss = 0.345535 * 100, metric = 6.58% * 100;
 Minibatch[1201-1300]: loss = 0.347834 * 100, metric = 6.47% * 100;
 Minibatch[1301-1400]: loss = 0.357287 * 100, metric = 6.73% * 100;
 Minibatch[1401-1500]: loss = 0.339407 * 100, metric = 6.51% * 100;
 Minibatch[1501-1600]: loss = 0.342283 * 100, metric = 6.17% * 100;
 Minibatch[1601-1700]: loss = 0.345917 * 100, metric = 6.42% * 100;
 Minibatch[1701-1800]: loss = 0.345917 * 100, metric = 6.60% * 100;
 Minibatch[1801-1900]: loss = 0.351761 * 100, metric = 6.87% * 100;
 Minibatch[1901-2000]: loss = 0.353920 * 100, metric = 6.54% * 100;
Finished Epoch[23 of 200]: [Training] loss = 0.348548 * 2000, metric = 6.54% * 2000 1600.299s (  1.2 samples/s);
Finished Evaluation [23]: Minibatch[1-5000]: metric = 14.91% * 5000;
 Minibatch[   1- 100]: loss = 0.331606 * 100, metric = 6.27% * 100;
 Minibatch[ 101- 200]: loss = 0.350378 * 100, metric = 6.64% * 100;
 Minibatch[ 201- 300]: loss = 0.344340 * 100, metric = 6.69% * 100;
 Minibatch[ 301- 400]: loss = 0.349348 * 100, metric = 6.51% * 100;
 Minibatch[ 401- 500]: loss = 0.346816 * 100, metric = 6.53% * 100;
 Minibatch[ 501- 600]: loss = 0.332043 * 100, metric = 6.16% * 100;
 Minibatch[ 601- 700]: loss = 0.343970 * 100, metric = 6.38% * 100;
 Minibatch[ 701- 800]: loss = 0.331589 * 100, metric = 6.21% * 100;
 Minibatch[ 801- 900]: loss = 0.345739 * 100, metric = 6.54% * 100;
 Minibatch[ 901-1000]: loss = 0.345398 * 100, metric = 6.42% * 100;
 Minibatch[1001-1100]: loss = 0.334677 * 100, metric = 6.21% * 100;
 Minibatch[1101-1200]: loss = 0.352290 * 100, metric = 6.65% * 100;
 Minibatch[1201-1300]: loss = 0.354955 * 100, metric = 6.75% * 100;
 Minibatch[1301-1400]: loss = 0.339545 * 100, metric = 6.24% * 100;
 Minibatch[1401-1500]: loss = 0.337443 * 100, metric = 6.23% * 100;
 Minibatch[1501-1600]: loss = 0.344875 * 100, metric = 6.53% * 100;
 Minibatch[1601-1700]: loss = 0.326852 * 100, metric = 6.00% * 100;
 Minibatch[1701-1800]: loss = 0.338776 * 100, metric = 6.40% * 100;
 Minibatch[1801-1900]: loss = 0.340070 * 100, metric = 6.60% * 100;
 Minibatch[1901-2000]: loss = 0.343947 * 100, metric = 6.38% * 100;
Finished Epoch[24 of 200]: [Training] loss = 0.341733 * 2000, metric = 6.42% * 2000 1579.818s (  1.3 samples/s);
Finished Evaluation [24]: Minibatch[1-5000]: metric = 13.63% * 5000;
 Minibatch[   1- 100]: loss = 0.339342 * 100, metric = 6.42% * 100;
 Minibatch[ 101- 200]: loss = 0.338883 * 100, metric = 6.28% * 100;
 Minibatch[ 201- 300]: loss = 0.344202 * 100, metric = 6.59% * 100;
 Minibatch[ 301- 400]: loss = 0.340214 * 100, metric = 6.25% * 100;
 Minibatch[ 401- 500]: loss = 0.339511 * 100, metric = 6.45% * 100;
 Minibatch[ 501- 600]: loss = 0.337491 * 100, metric = 6.41% * 100;
 Minibatch[ 601- 700]: loss = 0.346130 * 100, metric = 6.48% * 100;
 Minibatch[ 701- 800]: loss = 0.332423 * 100, metric = 6.14% * 100;
 Minibatch[ 801- 900]: loss = 0.327284 * 100, metric = 6.08% * 100;
 Minibatch[ 901-1000]: loss = 0.335854 * 100, metric = 6.27% * 100;
 Minibatch[1001-1100]: loss = 0.337554 * 100, metric = 6.30% * 100;
 Minibatch[1101-1200]: loss = 0.343295 * 100, metric = 6.29% * 100;
 Minibatch[1201-1300]: loss = 0.354101 * 100, metric = 6.75% * 100;
 Minibatch[1301-1400]: loss = 0.329625 * 100, metric = 6.09% * 100;
 Minibatch[1401-1500]: loss = 0.336505 * 100, metric = 6.02% * 100;
 Minibatch[1501-1600]: loss = 0.343213 * 100, metric = 6.67% * 100;
 Minibatch[1601-1700]: loss = 0.335200 * 100, metric = 6.26% * 100;
 Minibatch[1701-1800]: loss = 0.334214 * 100, metric = 6.25% * 100;
 Minibatch[1801-1900]: loss = 0.327816 * 100, metric = 5.97% * 100;
 Minibatch[1901-2000]: loss = 0.323951 * 100, metric = 5.96% * 100;
Finished Epoch[25 of 200]: [Training] loss = 0.337340 * 2000, metric = 6.30% * 2000 1599.249s (  1.3 samples/s);
Finished Evaluation [25]: Minibatch[1-5000]: metric = 14.75% * 5000;
 Minibatch[   1- 100]: loss = 0.334350 * 100, metric = 6.07% * 100;
 Minibatch[ 101- 200]: loss = 0.318563 * 100, metric = 5.89% * 100;
 Minibatch[ 201- 300]: loss = 0.338804 * 100, metric = 6.39% * 100;
 Minibatch[ 301- 400]: loss = 0.326280 * 100, metric = 5.98% * 100;
 Minibatch[ 401- 500]: loss = 0.330625 * 100, metric = 6.20% * 100;
 Minibatch[ 501- 600]: loss = 0.328748 * 100, metric = 5.96% * 100;
 Minibatch[ 601- 700]: loss = 0.348605 * 100, metric = 6.52% * 100;
 Minibatch[ 701- 800]: loss = 0.330772 * 100, metric = 6.23% * 100;
 Minibatch[ 801- 900]: loss = 0.320431 * 100, metric = 6.06% * 100;
 Minibatch[ 901-1000]: loss = 0.322065 * 100, metric = 5.95% * 100;
 Minibatch[1001-1100]: loss = 0.338513 * 100, metric = 6.51% * 100;
 Minibatch[1101-1200]: loss = 0.344460 * 100, metric = 6.54% * 100;
 Minibatch[1201-1300]: loss = 0.329805 * 100, metric = 6.29% * 100;
 Minibatch[1301-1400]: loss = 0.321889 * 100, metric = 5.88% * 100;
 Minibatch[1401-1500]: loss = 0.332923 * 100, metric = 6.46% * 100;
 Minibatch[1501-1600]: loss = 0.322472 * 100, metric = 5.76% * 100;
 Minibatch[1601-1700]: loss = 0.346234 * 100, metric = 6.53% * 100;
 Minibatch[1701-1800]: loss = 0.346575 * 100, metric = 6.65% * 100;
 Minibatch[1801-1900]: loss = 0.336234 * 100, metric = 6.34% * 100;
 Minibatch[1901-2000]: loss = 0.329354 * 100, metric = 6.25% * 100;
Finished Epoch[26 of 200]: [Training] loss = 0.332385 * 2000, metric = 6.22% * 2000 1577.021s (  1.3 samples/s);
Finished Evaluation [26]: Minibatch[1-5000]: metric = 14.93% * 5000;
 Minibatch[   1- 100]: loss = 0.331602 * 100, metric = 6.29% * 100;
 Minibatch[ 101- 200]: loss = 0.344817 * 100, metric = 6.42% * 100;
 Minibatch[ 201- 300]: loss = 0.329894 * 100, metric = 6.14% * 100;
 Minibatch[ 301- 400]: loss = 0.331751 * 100, metric = 6.21% * 100;
 Minibatch[ 401- 500]: loss = 0.327775 * 100, metric = 6.05% * 100;
 Minibatch[ 501- 600]: loss = 0.327124 * 100, metric = 6.28% * 100;
 Minibatch[ 601- 700]: loss = 0.327907 * 100, metric = 6.02% * 100;
 Minibatch[ 701- 800]: loss = 0.330749 * 100, metric = 6.22% * 100;
 Minibatch[ 801- 900]: loss = 0.333315 * 100, metric = 6.40% * 100;
 Minibatch[ 901-1000]: loss = 0.334000 * 100, metric = 6.36% * 100;
 Minibatch[1001-1100]: loss = 0.321223 * 100, metric = 5.85% * 100;
 Minibatch[1101-1200]: loss = 0.333864 * 100, metric = 6.12% * 100;
 Minibatch[1201-1300]: loss = 0.326750 * 100, metric = 6.14% * 100;
 Minibatch[1301-1400]: loss = 0.332354 * 100, metric = 6.32% * 100;
 Minibatch[1401-1500]: loss = 0.326100 * 100, metric = 6.17% * 100;
 Minibatch[1501-1600]: loss = 0.323636 * 100, metric = 5.98% * 100;
 Minibatch[1601-1700]: loss = 0.316605 * 100, metric = 5.86% * 100;
 Minibatch[1701-1800]: loss = 0.319233 * 100, metric = 5.74% * 100;
 Minibatch[1801-1900]: loss = 0.326271 * 100, metric = 6.14% * 100;
 Minibatch[1901-2000]: loss = 0.325214 * 100, metric = 5.83% * 100;
Finished Epoch[27 of 200]: [Training] loss = 0.328509 * 2000, metric = 6.13% * 2000 1589.933s (  1.3 samples/s);
Finished Evaluation [27]: Minibatch[1-5000]: metric = 14.13% * 5000;
 Minibatch[   1- 100]: loss = 0.327404 * 100, metric = 6.11% * 100;
 Minibatch[ 101- 200]: loss = 0.312375 * 100, metric = 5.68% * 100;
 Minibatch[ 201- 300]: loss = 0.327063 * 100, metric = 6.20% * 100;
 Minibatch[ 301- 400]: loss = 0.323398 * 100, metric = 5.90% * 100;
 Minibatch[ 401- 500]: loss = 0.321614 * 100, metric = 6.01% * 100;
 Minibatch[ 501- 600]: loss = 0.340469 * 100, metric = 6.27% * 100;
 Minibatch[ 601- 700]: loss = 0.316411 * 100, metric = 5.75% * 100;
 Minibatch[ 701- 800]: loss = 0.315152 * 100, metric = 5.78% * 100;
 Minibatch[ 801- 900]: loss = 0.327401 * 100, metric = 6.23% * 100;
 Minibatch[ 901-1000]: loss = 0.324717 * 100, metric = 6.03% * 100;
 Minibatch[1001-1100]: loss = 0.329859 * 100, metric = 6.00% * 100;
 Minibatch[1101-1200]: loss = 0.319232 * 100, metric = 5.80% * 100;
 Minibatch[1201-1300]: loss = 0.329409 * 100, metric = 6.28% * 100;
 Minibatch[1301-1400]: loss = 0.322869 * 100, metric = 6.05% * 100;
 Minibatch[1401-1500]: loss = 0.327809 * 100, metric = 6.02% * 100;
 Minibatch[1501-1600]: loss = 0.325910 * 100, metric = 6.00% * 100;
 Minibatch[1601-1700]: loss = 0.325864 * 100, metric = 5.99% * 100;
 Minibatch[1701-1800]: loss = 0.317833 * 100, metric = 5.76% * 100;
 Minibatch[1801-1900]: loss = 0.328057 * 100, metric = 6.24% * 100;
 Minibatch[1901-2000]: loss = 0.332087 * 100, metric = 6.09% * 100;
Finished Epoch[28 of 200]: [Training] loss = 0.324747 * 2000, metric = 6.01% * 2000 1568.035s (  1.3 samples/s);
Finished Evaluation [28]: Minibatch[1-5000]: metric = 13.69% * 5000;
 Minibatch[   1- 100]: loss = 0.314213 * 100, metric = 5.59% * 100;
 Minibatch[ 101- 200]: loss = 0.327038 * 100, metric = 6.17% * 100;
 Minibatch[ 201- 300]: loss = 0.328168 * 100, metric = 6.33% * 100;
 Minibatch[ 301- 400]: loss = 0.347892 * 100, metric = 6.54% * 100;
 Minibatch[ 401- 500]: loss = 0.316496 * 100, metric = 5.67% * 100;
 Minibatch[ 501- 600]: loss = 0.328436 * 100, metric = 6.03% * 100;
 Minibatch[ 601- 700]: loss = 0.317929 * 100, metric = 5.93% * 100;
 Minibatch[ 701- 800]: loss = 0.330143 * 100, metric = 6.28% * 100;
 Minibatch[ 801- 900]: loss = 0.323846 * 100, metric = 6.16% * 100;
 Minibatch[ 901-1000]: loss = 0.337761 * 100, metric = 6.33% * 100;
 Minibatch[1001-1100]: loss = 0.327271 * 100, metric = 6.01% * 100;
 Minibatch[1101-1200]: loss = 0.319941 * 100, metric = 5.93% * 100;
 Minibatch[1201-1300]: loss = 0.327002 * 100, metric = 6.20% * 100;
 Minibatch[1301-1400]: loss = 0.319244 * 100, metric = 5.81% * 100;
 Minibatch[1401-1500]: loss = 0.330189 * 100, metric = 5.98% * 100;
 Minibatch[1501-1600]: loss = 0.311158 * 100, metric = 5.64% * 100;
 Minibatch[1601-1700]: loss = 0.327872 * 100, metric = 6.22% * 100;
 Minibatch[1701-1800]: loss = 0.313611 * 100, metric = 5.78% * 100;
 Minibatch[1801-1900]: loss = 0.337037 * 100, metric = 6.29% * 100;
 Minibatch[1901-2000]: loss = 0.326483 * 100, metric = 6.07% * 100;
Finished Epoch[29 of 200]: [Training] loss = 0.325586 * 2000, metric = 6.05% * 2000 1595.666s (  1.3 samples/s);
Finished Evaluation [29]: Minibatch[1-5000]: metric = 15.02% * 5000;
 Minibatch[   1- 100]: loss = 0.340592 * 100, metric = 6.34% * 100;
 Minibatch[ 101- 200]: loss = 0.309933 * 100, metric = 5.53% * 100;
 Minibatch[ 201- 300]: loss = 0.316187 * 100, metric = 5.99% * 100;
 Minibatch[ 301- 400]: loss = 0.331467 * 100, metric = 6.30% * 100;
 Minibatch[ 401- 500]: loss = 0.324580 * 100, metric = 5.95% * 100;
 Minibatch[ 501- 600]: loss = 0.311772 * 100, metric = 5.65% * 100;
 Minibatch[ 601- 700]: loss = 0.329775 * 100, metric = 6.23% * 100;
 Minibatch[ 701- 800]: loss = 0.318485 * 100, metric = 5.69% * 100;
 Minibatch[ 801- 900]: loss = 0.333727 * 100, metric = 6.26% * 100;
 Minibatch[ 901-1000]: loss = 0.315169 * 100, metric = 5.88% * 100;
 Minibatch[1001-1100]: loss = 0.327212 * 100, metric = 6.12% * 100;
 Minibatch[1101-1200]: loss = 0.335442 * 100, metric = 6.42% * 100;
 Minibatch[1201-1300]: loss = 0.323719 * 100, metric = 6.11% * 100;
 Minibatch[1301-1400]: loss = 0.325730 * 100, metric = 6.14% * 100;
 Minibatch[1401-1500]: loss = 0.328620 * 100, metric = 6.12% * 100;
 Minibatch[1501-1600]: loss = 0.336899 * 100, metric = 6.58% * 100;
 Minibatch[1601-1700]: loss = 0.328262 * 100, metric = 6.28% * 100;
 Minibatch[1701-1800]: loss = 0.332432 * 100, metric = 6.40% * 100;
 Minibatch[1801-1900]: loss = 0.331511 * 100, metric = 6.46% * 100;
 Minibatch[1901-2000]: loss = 0.336569 * 100, metric = 6.38% * 100;
Finished Epoch[30 of 200]: [Training] loss = 0.326904 * 2000, metric = 6.14% * 2000 1584.212s (  1.3 samples/s);
Finished Evaluation [30]: Minibatch[1-5000]: metric = 14.69% * 5000;
 Minibatch[   1- 100]: loss = 0.326517 * 100, metric = 6.08% * 100;
 Minibatch[ 101- 200]: loss = 0.330818 * 100, metric = 6.38% * 100;
 Minibatch[ 201- 300]: loss = 0.331746 * 100, metric = 6.31% * 100;
 Minibatch[ 301- 400]: loss = 0.323932 * 100, metric = 6.08% * 100;
 Minibatch[ 401- 500]: loss = 0.322593 * 100, metric = 6.08% * 100;
 Minibatch[ 501- 600]: loss = 0.322911 * 100, metric = 6.19% * 100;
 Minibatch[ 601- 700]: loss = 0.344599 * 100, metric = 6.64% * 100;
 Minibatch[ 701- 800]: loss = 0.338026 * 100, metric = 6.66% * 100;
 Minibatch[ 801- 900]: loss = 0.333659 * 100, metric = 6.43% * 100;
 Minibatch[ 901-1000]: loss = 0.319682 * 100, metric = 5.91% * 100;
 Minibatch[1001-1100]: loss = 0.318499 * 100, metric = 6.00% * 100;
 Minibatch[1101-1200]: loss = 0.324291 * 100, metric = 6.19% * 100;
 Minibatch[1201-1300]: loss = 0.324560 * 100, metric = 6.17% * 100;
 Minibatch[1301-1400]: loss = 0.323119 * 100, metric = 6.08% * 100;
 Minibatch[1401-1500]: loss = 0.331044 * 100, metric = 6.23% * 100;
 Minibatch[1501-1600]: loss = 0.318344 * 100, metric = 6.04% * 100;
 Minibatch[1601-1700]: loss = 0.320082 * 100, metric = 6.07% * 100;
 Minibatch[1701-1800]: loss = 0.320225 * 100, metric = 6.15% * 100;
 Minibatch[1801-1900]: loss = 0.326589 * 100, metric = 6.28% * 100;
 Minibatch[1901-2000]: loss = 0.320522 * 100, metric = 6.15% * 100;
Finished Epoch[31 of 200]: [Training] loss = 0.326088 * 2000, metric = 6.21% * 2000 1589.885s (  1.3 samples/s);
Finished Evaluation [31]: Minibatch[1-5000]: metric = 15.19% * 5000;
 Minibatch[   1- 100]: loss = 0.318526 * 100, metric = 5.93% * 100;
 Minibatch[ 101- 200]: loss = 0.332199 * 100, metric = 6.21% * 100;
 Minibatch[ 201- 300]: loss = 0.332643 * 100, metric = 6.46% * 100;
 Minibatch[ 301- 400]: loss = 0.332321 * 100, metric = 6.39% * 100;
 Minibatch[ 401- 500]: loss = 0.328636 * 100, metric = 6.39% * 100;
 Minibatch[ 501- 600]: loss = 0.325578 * 100, metric = 6.53% * 100;
 Minibatch[ 601- 700]: loss = 0.314850 * 100, metric = 5.85% * 100;
 Minibatch[ 701- 800]: loss = 0.316796 * 100, metric = 5.91% * 100;
 Minibatch[ 801- 900]: loss = 0.321612 * 100, metric = 6.04% * 100;
 Minibatch[ 901-1000]: loss = 0.311476 * 100, metric = 5.78% * 100;
 Minibatch[1001-1100]: loss = 0.322955 * 100, metric = 6.12% * 100;
 Minibatch[1101-1200]: loss = 0.325033 * 100, metric = 6.38% * 100;
 Minibatch[1201-1300]: loss = 0.333159 * 100, metric = 6.55% * 100;
 Minibatch[1301-1400]: loss = 0.319227 * 100, metric = 6.15% * 100;
 Minibatch[1401-1500]: loss = 0.319695 * 100, metric = 6.39% * 100;
 Minibatch[1501-1600]: loss = 0.329863 * 100, metric = 6.29% * 100;
 Minibatch[1601-1700]: loss = 0.318024 * 100, metric = 6.06% * 100;
 Minibatch[1701-1800]: loss = 0.333491 * 100, metric = 6.33% * 100;
 Minibatch[1801-1900]: loss = 0.319684 * 100, metric = 6.03% * 100;
 Minibatch[1901-2000]: loss = 0.329752 * 100, metric = 6.37% * 100;
Finished Epoch[32 of 200]: [Training] loss = 0.324276 * 2000, metric = 6.21% * 2000 1581.738s (  1.3 samples/s);
Finished Evaluation [32]: Minibatch[1-5000]: metric = 13.91% * 5000;
 Minibatch[   1- 100]: loss = 0.338109 * 100, metric = 6.65% * 100;
 Minibatch[ 101- 200]: loss = 0.322531 * 100, metric = 6.30% * 100;
 Minibatch[ 201- 300]: loss = 0.323861 * 100, metric = 6.18% * 100;
 Minibatch[ 301- 400]: loss = 0.331737 * 100, metric = 6.51% * 100;
 Minibatch[ 401- 500]: loss = 0.321483 * 100, metric = 6.31% * 100;
 Minibatch[ 501- 600]: loss = 0.328432 * 100, metric = 6.21% * 100;
 Minibatch[ 601- 700]: loss = 0.324938 * 100, metric = 6.29% * 100;
 Minibatch[ 701- 800]: loss = 0.330795 * 100, metric = 6.32% * 100;
 Minibatch[ 801- 900]: loss = 0.320518 * 100, metric = 5.91% * 100;
 Minibatch[ 901-1000]: loss = 0.310011 * 100, metric = 5.75% * 100;
 Minibatch[1001-1100]: loss = 0.318560 * 100, metric = 6.02% * 100;
 Minibatch[1101-1200]: loss = 0.307032 * 100, metric = 5.77% * 100;
 Minibatch[1201-1300]: loss = 0.330213 * 100, metric = 6.22% * 100;
 Minibatch[1301-1400]: loss = 0.313294 * 100, metric = 5.63% * 100;
 Minibatch[1401-1500]: loss = 0.330937 * 100, metric = 6.12% * 100;
 Minibatch[1501-1600]: loss = 0.329531 * 100, metric = 6.27% * 100;
 Minibatch[1601-1700]: loss = 0.317516 * 100, metric = 5.81% * 100;
 Minibatch[1701-1800]: loss = 0.316288 * 100, metric = 5.94% * 100;
 Minibatch[1801-1900]: loss = 0.313143 * 100, metric = 5.82% * 100;
 Minibatch[1901-2000]: loss = 0.327347 * 100, metric = 6.30% * 100;
Finished Epoch[33 of 200]: [Training] loss = 0.322814 * 2000, metric = 6.12% * 2000 1565.790s (  1.3 samples/s);
Finished Evaluation [33]: Minibatch[1-5000]: metric = 13.52% * 5000;
 Minibatch[   1- 100]: loss = 0.314491 * 100, metric = 5.92% * 100;
 Minibatch[ 101- 200]: loss = 0.323317 * 100, metric = 5.96% * 100;
 Minibatch[ 201- 300]: loss = 0.315372 * 100, metric = 5.79% * 100;
 Minibatch[ 301- 400]: loss = 0.320924 * 100, metric = 6.04% * 100;
 Minibatch[ 401- 500]: loss = 0.312544 * 100, metric = 5.74% * 100;
 Minibatch[ 501- 600]: loss = 0.315446 * 100, metric = 5.96% * 100;
 Minibatch[ 601- 700]: loss = 0.317996 * 100, metric = 6.11% * 100;
 Minibatch[ 701- 800]: loss = 0.316621 * 100, metric = 6.03% * 100;
 Minibatch[ 801- 900]: loss = 0.306668 * 100, metric = 5.53% * 100;
 Minibatch[ 901-1000]: loss = 0.307751 * 100, metric = 5.87% * 100;
 Minibatch[1001-1100]: loss = 0.323029 * 100, metric = 6.09% * 100;
 Minibatch[1101-1200]: loss = 0.314957 * 100, metric = 6.10% * 100;
 Minibatch[1201-1300]: loss = 0.325730 * 100, metric = 6.20% * 100;
 Minibatch[1301-1400]: loss = 0.313782 * 100, metric = 6.04% * 100;
 Minibatch[1401-1500]: loss = 0.325287 * 100, metric = 6.19% * 100;
 Minibatch[1501-1600]: loss = 0.317643 * 100, metric = 5.88% * 100;
 Minibatch[1601-1700]: loss = 0.331372 * 100, metric = 6.52% * 100;
 Minibatch[1701-1800]: loss = 0.322219 * 100, metric = 5.99% * 100;
 Minibatch[1801-1900]: loss = 0.316444 * 100, metric = 5.95% * 100;
 Minibatch[1901-2000]: loss = 0.320562 * 100, metric = 5.90% * 100;
Finished Epoch[34 of 200]: [Training] loss = 0.318108 * 2000, metric = 5.99% * 2000 1599.620s (  1.3 samples/s);
Finished Evaluation [34]: Minibatch[1-5000]: metric = 14.91% * 5000;
 Minibatch[   1- 100]: loss = 0.302904 * 100, metric = 5.63% * 100;
 Minibatch[ 101- 200]: loss = 0.323388 * 100, metric = 6.12% * 100;
 Minibatch[ 201- 300]: loss = 0.318539 * 100, metric = 6.04% * 100;
 Minibatch[ 301- 400]: loss = 0.306421 * 100, metric = 5.70% * 100;
 Minibatch[ 401- 500]: loss = 0.310435 * 100, metric = 5.70% * 100;
 Minibatch[ 501- 600]: loss = 0.293610 * 100, metric = 5.23% * 100;
 Minibatch[ 601- 700]: loss = 0.322618 * 100, metric = 6.25% * 100;
 Minibatch[ 701- 800]: loss = 0.307850 * 100, metric = 5.84% * 100;
 Minibatch[ 801- 900]: loss = 0.316557 * 100, metric = 5.91% * 100;
 Minibatch[ 901-1000]: loss = 0.302009 * 100, metric = 5.64% * 100;
 Minibatch[1001-1100]: loss = 0.319235 * 100, metric = 6.08% * 100;
 Minibatch[1101-1200]: loss = 0.305173 * 100, metric = 5.52% * 100;
 Minibatch[1201-1300]: loss = 0.313425 * 100, metric = 5.97% * 100;
 Minibatch[1301-1400]: loss = 0.313181 * 100, metric = 6.00% * 100;
 Minibatch[1401-1500]: loss = 0.306446 * 100, metric = 5.74% * 100;
 Minibatch[1501-1600]: loss = 0.309405 * 100, metric = 5.91% * 100;
 Minibatch[1601-1700]: loss = 0.313235 * 100, metric = 5.92% * 100;
 Minibatch[1701-1800]: loss = 0.309610 * 100, metric = 5.86% * 100;
 Minibatch[1801-1900]: loss = 0.318269 * 100, metric = 6.01% * 100;
 Minibatch[1901-2000]: loss = 0.306968 * 100, metric = 5.79% * 100;
Finished Epoch[35 of 200]: [Training] loss = 0.310964 * 2000, metric = 5.84% * 2000 1588.156s (  1.3 samples/s);
Finished Evaluation [35]: Minibatch[1-5000]: metric = 14.43% * 5000;
 Minibatch[   1- 100]: loss = 0.310287 * 100, metric = 5.68% * 100;
 Minibatch[ 101- 200]: loss = 0.298773 * 100, metric = 5.57% * 100;
 Minibatch[ 201- 300]: loss = 0.323492 * 100, metric = 6.18% * 100;
 Minibatch[ 301- 400]: loss = 0.308472 * 100, metric = 5.76% * 100;
 Minibatch[ 401- 500]: loss = 0.306983 * 100, metric = 5.65% * 100;
 Minibatch[ 501- 600]: loss = 0.313795 * 100, metric = 5.85% * 100;
 Minibatch[ 601- 700]: loss = 0.322428 * 100, metric = 6.05% * 100;
 Minibatch[ 701- 800]: loss = 0.306197 * 100, metric = 5.87% * 100;
 Minibatch[ 801- 900]: loss = 0.307142 * 100, metric = 5.85% * 100;
 Minibatch[ 901-1000]: loss = 0.317279 * 100, metric = 6.17% * 100;
 Minibatch[1001-1100]: loss = 0.323363 * 100, metric = 6.32% * 100;
 Minibatch[1101-1200]: loss = 0.313832 * 100, metric = 5.95% * 100;
 Minibatch[1201-1300]: loss = 0.313485 * 100, metric = 5.94% * 100;
 Minibatch[1301-1400]: loss = 0.293914 * 100, metric = 5.49% * 100;
 Minibatch[1401-1500]: loss = 0.307623 * 100, metric = 5.83% * 100;
 Minibatch[1501-1600]: loss = 0.308394 * 100, metric = 5.77% * 100;
 Minibatch[1601-1700]: loss = 0.323159 * 100, metric = 6.23% * 100;
 Minibatch[1701-1800]: loss = 0.315817 * 100, metric = 5.86% * 100;
 Minibatch[1801-1900]: loss = 0.314592 * 100, metric = 6.06% * 100;
 Minibatch[1901-2000]: loss = 0.314063 * 100, metric = 5.74% * 100;
Finished Epoch[36 of 200]: [Training] loss = 0.312155 * 2000, metric = 5.89% * 2000 1596.208s (  1.3 samples/s);
Finished Evaluation [36]: Minibatch[1-5000]: metric = 14.12% * 5000;
 Minibatch[   1- 100]: loss = 0.308676 * 100, metric = 5.72% * 100;
 Minibatch[ 101- 200]: loss = 0.313852 * 100, metric = 6.01% * 100;
 Minibatch[ 201- 300]: loss = 0.317588 * 100, metric = 6.01% * 100;
 Minibatch[ 301- 400]: loss = 0.312750 * 100, metric = 5.88% * 100;
 Minibatch[ 401- 500]: loss = 0.313531 * 100, metric = 6.12% * 100;
 Minibatch[ 501- 600]: loss = 0.306755 * 100, metric = 5.73% * 100;
 Minibatch[ 601- 700]: loss = 0.313599 * 100, metric = 5.94% * 100;
 Minibatch[ 701- 800]: loss = 0.323027 * 100, metric = 6.33% * 100;
 Minibatch[ 801- 900]: loss = 0.317187 * 100, metric = 6.07% * 100;
 Minibatch[ 901-1000]: loss = 0.299400 * 100, metric = 5.46% * 100;
 Minibatch[1001-1100]: loss = 0.312521 * 100, metric = 6.05% * 100;
 Minibatch[1101-1200]: loss = 0.325566 * 100, metric = 6.54% * 100;
 Minibatch[1201-1300]: loss = 0.318781 * 100, metric = 6.10% * 100;
 Minibatch[1301-1400]: loss = 0.307611 * 100, metric = 5.77% * 100;
 Minibatch[1401-1500]: loss = 0.311657 * 100, metric = 5.96% * 100;
 Minibatch[1501-1600]: loss = 0.304892 * 100, metric = 5.58% * 100;
 Minibatch[1601-1700]: loss = 0.308344 * 100, metric = 5.82% * 100;
 Minibatch[1701-1800]: loss = 0.308621 * 100, metric = 5.71% * 100;
 Minibatch[1801-1900]: loss = 0.308547 * 100, metric = 5.97% * 100;
 Minibatch[1901-2000]: loss = 0.316598 * 100, metric = 5.92% * 100;
Finished Epoch[37 of 200]: [Training] loss = 0.312475 * 2000, metric = 5.93% * 2000 1578.638s (  1.3 samples/s);
Finished Evaluation [37]: Minibatch[1-5000]: metric = 14.49% * 5000;
 Minibatch[   1- 100]: loss = 0.318646 * 100, metric = 6.21% * 100;
 Minibatch[ 101- 200]: loss = 0.315892 * 100, metric = 6.04% * 100;
 Minibatch[ 201- 300]: loss = 0.300977 * 100, metric = 5.51% * 100;
 Minibatch[ 301- 400]: loss = 0.306403 * 100, metric = 5.82% * 100;
 Minibatch[ 401- 500]: loss = 0.315108 * 100, metric = 6.02% * 100;
 Minibatch[ 501- 600]: loss = 0.316181 * 100, metric = 5.90% * 100;
 Minibatch[ 601- 700]: loss = 0.315110 * 100, metric = 6.01% * 100;
 Minibatch[ 701- 800]: loss = 0.308236 * 100, metric = 5.83% * 100;
 Minibatch[ 801- 900]: loss = 0.309521 * 100, metric = 5.87% * 100;
 Minibatch[ 901-1000]: loss = 0.309080 * 100, metric = 5.65% * 100;
 Minibatch[1001-1100]: loss = 0.317243 * 100, metric = 5.97% * 100;
 Minibatch[1101-1200]: loss = 0.304432 * 100, metric = 5.82% * 100;
 Minibatch[1201-1300]: loss = 0.312488 * 100, metric = 6.03% * 100;
 Minibatch[1301-1400]: loss = 0.320782 * 100, metric = 6.22% * 100;
 Minibatch[1401-1500]: loss = 0.315946 * 100, metric = 6.16% * 100;
 Minibatch[1501-1600]: loss = 0.318693 * 100, metric = 6.16% * 100;
 Minibatch[1601-1700]: loss = 0.306283 * 100, metric = 5.82% * 100;
 Minibatch[1701-1800]: loss = 0.309868 * 100, metric = 5.92% * 100;
 Minibatch[1801-1900]: loss = 0.315419 * 100, metric = 6.21% * 100;
 Minibatch[1901-2000]: loss = 0.314452 * 100, metric = 6.01% * 100;
Finished Epoch[38 of 200]: [Training] loss = 0.312538 * 2000, metric = 5.96% * 2000 1599.688s (  1.3 samples/s);
Finished Evaluation [38]: Minibatch[1-5000]: metric = 13.87% * 5000;
 Minibatch[   1- 100]: loss = 0.305505 * 100, metric = 5.76% * 100;
 Minibatch[ 101- 200]: loss = 0.314131 * 100, metric = 6.02% * 100;
 Minibatch[ 201- 300]: loss = 0.312307 * 100, metric = 5.80% * 100;
 Minibatch[ 301- 400]: loss = 0.304329 * 100, metric = 5.66% * 100;
 Minibatch[ 401- 500]: loss = 0.301132 * 100, metric = 5.65% * 100;
 Minibatch[ 501- 600]: loss = 0.315539 * 100, metric = 5.93% * 100;
 Minibatch[ 601- 700]: loss = 0.308051 * 100, metric = 5.86% * 100;
 Minibatch[ 701- 800]: loss = 0.310362 * 100, metric = 5.90% * 100;
 Minibatch[ 801- 900]: loss = 0.296976 * 100, metric = 5.54% * 100;
 Minibatch[ 901-1000]: loss = 0.303209 * 100, metric = 5.67% * 100;
 Minibatch[1001-1100]: loss = 0.314713 * 100, metric = 6.08% * 100;
 Minibatch[1101-1200]: loss = 0.311400 * 100, metric = 6.00% * 100;
 Minibatch[1201-1300]: loss = 0.309030 * 100, metric = 5.69% * 100;
 Minibatch[1301-1400]: loss = 0.319499 * 100, metric = 6.08% * 100;
 Minibatch[1401-1500]: loss = 0.313376 * 100, metric = 5.89% * 100;
 Minibatch[1501-1600]: loss = 0.316712 * 100, metric = 5.78% * 100;
 Minibatch[1601-1700]: loss = 0.303385 * 100, metric = 5.66% * 100;
 Minibatch[1701-1800]: loss = 0.311781 * 100, metric = 5.93% * 100;
 Minibatch[1801-1900]: loss = 0.306259 * 100, metric = 5.80% * 100;
 Minibatch[1901-2000]: loss = 0.305601 * 100, metric = 5.83% * 100;
Finished Epoch[39 of 200]: [Training] loss = 0.309165 * 2000, metric = 5.83% * 2000 1575.123s (  1.3 samples/s);
Finished Evaluation [39]: Minibatch[1-5000]: metric = 13.69% * 5000;
 Minibatch[   1- 100]: loss = 0.306741 * 100, metric = 5.77% * 100;
 Minibatch[ 101- 200]: loss = 0.305895 * 100, metric = 5.83% * 100;
 Minibatch[ 201- 300]: loss = 0.318768 * 100, metric = 6.05% * 100;
 Minibatch[ 301- 400]: loss = 0.310561 * 100, metric = 5.93% * 100;
 Minibatch[ 401- 500]: loss = 0.305946 * 100, metric = 5.80% * 100;
 Minibatch[ 501- 600]: loss = 0.306263 * 100, metric = 5.87% * 100;
 Minibatch[ 601- 700]: loss = 0.317247 * 100, metric = 5.93% * 100;
 Minibatch[ 701- 800]: loss = 0.309269 * 100, metric = 5.65% * 100;
 Minibatch[ 801- 900]: loss = 0.310218 * 100, metric = 5.96% * 100;
 Minibatch[ 901-1000]: loss = 0.313302 * 100, metric = 6.07% * 100;
 Minibatch[1001-1100]: loss = 0.324110 * 100, metric = 6.33% * 100;
 Minibatch[1101-1200]: loss = 0.319356 * 100, metric = 6.29% * 100;
 Minibatch[1201-1300]: loss = 0.313205 * 100, metric = 6.01% * 100;
 Minibatch[1301-1400]: loss = 0.312693 * 100, metric = 5.98% * 100;
 Minibatch[1401-1500]: loss = 0.307773 * 100, metric = 5.89% * 100;
 Minibatch[1501-1600]: loss = 0.318770 * 100, metric = 6.09% * 100;
 Minibatch[1601-1700]: loss = 0.315431 * 100, metric = 6.02% * 100;
 Minibatch[1701-1800]: loss = 0.305052 * 100, metric = 5.65% * 100;
 Minibatch[1801-1900]: loss = 0.311080 * 100, metric = 5.80% * 100;
 Minibatch[1901-2000]: loss = 0.308779 * 100, metric = 5.95% * 100;
Finished Epoch[40 of 200]: [Training] loss = 0.312023 * 2000, metric = 5.94% * 2000 1583.671s (  1.3 samples/s);
Finished Evaluation [40]: Minibatch[1-5000]: metric = 13.80% * 5000;
 Minibatch[   1- 100]: loss = 0.309805 * 100, metric = 5.93% * 100;
 Minibatch[ 101- 200]: loss = 0.304692 * 100, metric = 5.70% * 100;
 Minibatch[ 201- 300]: loss = 0.313244 * 100, metric = 5.92% * 100;
 Minibatch[ 301- 400]: loss = 0.321262 * 100, metric = 6.26% * 100;
 Minibatch[ 401- 500]: loss = 0.318015 * 100, metric = 6.45% * 100;
 Minibatch[ 501- 600]: loss = 0.308312 * 100, metric = 5.81% * 100;
 Minibatch[ 601- 700]: loss = 0.320332 * 100, metric = 6.14% * 100;
 Minibatch[ 701- 800]: loss = 0.311702 * 100, metric = 5.98% * 100;
 Minibatch[ 801- 900]: loss = 0.302896 * 100, metric = 5.80% * 100;
 Minibatch[ 901-1000]: loss = 0.313268 * 100, metric = 6.16% * 100;
 Minibatch[1001-1100]: loss = 0.314552 * 100, metric = 6.04% * 100;
 Minibatch[1101-1200]: loss = 0.318690 * 100, metric = 6.13% * 100;
 Minibatch[1201-1300]: loss = 0.322657 * 100, metric = 6.30% * 100;
 Minibatch[1301-1400]: loss = 0.304096 * 100, metric = 5.76% * 100;
 Minibatch[1401-1500]: loss = 0.310609 * 100, metric = 5.90% * 100;
 Minibatch[1501-1600]: loss = 0.306898 * 100, metric = 5.81% * 100;
 Minibatch[1601-1700]: loss = 0.314464 * 100, metric = 6.08% * 100;
 Minibatch[1701-1800]: loss = 0.314620 * 100, metric = 6.13% * 100;
 Minibatch[1801-1900]: loss = 0.308250 * 100, metric = 5.70% * 100;
 Minibatch[1901-2000]: loss = 0.306172 * 100, metric = 5.73% * 100;
Finished Epoch[41 of 200]: [Training] loss = 0.312227 * 2000, metric = 5.99% * 2000 1600.618s (  1.2 samples/s);
Finished Evaluation [41]: Minibatch[1-5000]: metric = 15.11% * 5000;
 Minibatch[   1- 100]: loss = 0.305259 * 100, metric = 5.71% * 100;
 Minibatch[ 101- 200]: loss = 0.308815 * 100, metric = 6.00% * 100;
 Minibatch[ 201- 300]: loss = 0.307800 * 100, metric = 5.89% * 100;
 Minibatch[ 301- 400]: loss = 0.304188 * 100, metric = 5.69% * 100;
 Minibatch[ 401- 500]: loss = 0.304926 * 100, metric = 5.60% * 100;
 Minibatch[ 501- 600]: loss = 0.307131 * 100, metric = 5.99% * 100;
 Minibatch[ 601- 700]: loss = 0.307804 * 100, metric = 5.87% * 100;
 Minibatch[ 701- 800]: loss = 0.298120 * 100, metric = 5.61% * 100;
 Minibatch[ 801- 900]: loss = 0.298367 * 100, metric = 5.62% * 100;
 Minibatch[ 901-1000]: loss = 0.315860 * 100, metric = 6.09% * 100;
 Minibatch[1001-1100]: loss = 0.304633 * 100, metric = 5.73% * 100;
 Minibatch[1101-1200]: loss = 0.298930 * 100, metric = 5.61% * 100;
 Minibatch[1201-1300]: loss = 0.298597 * 100, metric = 5.57% * 100;
 Minibatch[1301-1400]: loss = 0.305767 * 100, metric = 5.88% * 100;
 Minibatch[1401-1500]: loss = 0.306521 * 100, metric = 5.82% * 100;
 Minibatch[1501-1600]: loss = 0.308851 * 100, metric = 5.88% * 100;
 Minibatch[1601-1700]: loss = 0.310932 * 100, metric = 5.86% * 100;
 Minibatch[1701-1800]: loss = 0.310147 * 100, metric = 5.88% * 100;
 Minibatch[1801-1900]: loss = 0.306455 * 100, metric = 5.94% * 100;
 Minibatch[1901-2000]: loss = 0.304662 * 100, metric = 5.70% * 100;
Finished Epoch[42 of 200]: [Training] loss = 0.305688 * 2000, metric = 5.80% * 2000 1588.569s (  1.3 samples/s);
Finished Evaluation [42]: Minibatch[1-5000]: metric = 13.84% * 5000;
 Minibatch[   1- 100]: loss = 0.309332 * 100, metric = 5.95% * 100;
 Minibatch[ 101- 200]: loss = 0.291824 * 100, metric = 5.30% * 100;
 Minibatch[ 201- 300]: loss = 0.302982 * 100, metric = 5.73% * 100;
 Minibatch[ 301- 400]: loss = 0.306581 * 100, metric = 6.08% * 100;
 Minibatch[ 401- 500]: loss = 0.301443 * 100, metric = 5.70% * 100;
 Minibatch[ 501- 600]: loss = 0.299222 * 100, metric = 5.81% * 100;
 Minibatch[ 601- 700]: loss = 0.313709 * 100, metric = 5.98% * 100;
 Minibatch[ 701- 800]: loss = 0.299860 * 100, metric = 5.85% * 100;
 Minibatch[ 801- 900]: loss = 0.306477 * 100, metric = 5.89% * 100;
 Minibatch[ 901-1000]: loss = 0.307035 * 100, metric = 5.86% * 100;
 Minibatch[1001-1100]: loss = 0.309788 * 100, metric = 6.06% * 100;
 Minibatch[1101-1200]: loss = 0.301150 * 100, metric = 5.86% * 100;
 Minibatch[1201-1300]: loss = 0.311225 * 100, metric = 6.26% * 100;
 Minibatch[1301-1400]: loss = 0.311633 * 100, metric = 5.86% * 100;
 Minibatch[1401-1500]: loss = 0.290762 * 100, metric = 5.46% * 100;
 Minibatch[1501-1600]: loss = 0.311445 * 100, metric = 5.77% * 100;
 Minibatch[1601-1700]: loss = 0.301783 * 100, metric = 5.80% * 100;
 Minibatch[1701-1800]: loss = 0.302534 * 100, metric = 5.94% * 100;
 Minibatch[1801-1900]: loss = 0.308198 * 100, metric = 6.01% * 100;
 Minibatch[1901-2000]: loss = 0.303326 * 100, metric = 5.78% * 100;
Finished Epoch[43 of 200]: [Training] loss = 0.304515 * 2000, metric = 5.85% * 2000 1611.505s (  1.2 samples/s);
Finished Evaluation [43]: Minibatch[1-5000]: metric = 14.51% * 5000;
 Minibatch[   1- 100]: loss = 0.302712 * 100, metric = 5.85% * 100;
 Minibatch[ 101- 200]: loss = 0.298689 * 100, metric = 5.70% * 100;
 Minibatch[ 201- 300]: loss = 0.296117 * 100, metric = 5.55% * 100;
 Minibatch[ 301- 400]: loss = 0.306547 * 100, metric = 5.89% * 100;
 Minibatch[ 401- 500]: loss = 0.298792 * 100, metric = 5.46% * 100;
 Minibatch[ 501- 600]: loss = 0.297467 * 100, metric = 5.61% * 100;
 Minibatch[ 601- 700]: loss = 0.310024 * 100, metric = 6.09% * 100;
 Minibatch[ 701- 800]: loss = 0.290390 * 100, metric = 5.39% * 100;
 Minibatch[ 801- 900]: loss = 0.302654 * 100, metric = 5.59% * 100;
 Minibatch[ 901-1000]: loss = 0.300842 * 100, metric = 5.69% * 100;
 Minibatch[1001-1100]: loss = 0.301437 * 100, metric = 5.62% * 100;
 Minibatch[1101-1200]: loss = 0.287625 * 100, metric = 5.48% * 100;
 Minibatch[1201-1300]: loss = 0.295289 * 100, metric = 5.70% * 100;
 Minibatch[1301-1400]: loss = 0.294327 * 100, metric = 5.55% * 100;
 Minibatch[1401-1500]: loss = 0.296310 * 100, metric = 5.53% * 100;
 Minibatch[1501-1600]: loss = 0.286681 * 100, metric = 5.35% * 100;
 Minibatch[1601-1700]: loss = 0.297089 * 100, metric = 5.48% * 100;
 Minibatch[1701-1800]: loss = 0.308106 * 100, metric = 6.11% * 100;
 Minibatch[1801-1900]: loss = 0.305132 * 100, metric = 5.67% * 100;
 Minibatch[1901-2000]: loss = 0.298625 * 100, metric = 5.60% * 100;
Finished Epoch[44 of 200]: [Training] loss = 0.298743 * 2000, metric = 5.65% * 2000 1599.181s (  1.3 samples/s);
Finished Evaluation [44]: Minibatch[1-5000]: metric = 13.82% * 5000;
 Minibatch[   1- 100]: loss = 0.300742 * 100, metric = 5.66% * 100;
 Minibatch[ 101- 200]: loss = 0.294182 * 100, metric = 5.51% * 100;
 Minibatch[ 201- 300]: loss = 0.300393 * 100, metric = 5.77% * 100;
 Minibatch[ 301- 400]: loss = 0.305448 * 100, metric = 5.93% * 100;
 Minibatch[ 401- 500]: loss = 0.295032 * 100, metric = 5.68% * 100;
 Minibatch[ 501- 600]: loss = 0.286002 * 100, metric = 5.22% * 100;
 Minibatch[ 601- 700]: loss = 0.286756 * 100, metric = 5.20% * 100;
 Minibatch[ 701- 800]: loss = 0.284690 * 100, metric = 5.49% * 100;
 Minibatch[ 801- 900]: loss = 0.306924 * 100, metric = 5.96% * 100;
 Minibatch[ 901-1000]: loss = 0.292870 * 100, metric = 5.65% * 100;
 Minibatch[1001-1100]: loss = 0.291060 * 100, metric = 5.62% * 100;
 Minibatch[1101-1200]: loss = 0.308972 * 100, metric = 5.70% * 100;
 Minibatch[1201-1300]: loss = 0.300866 * 100, metric = 5.85% * 100;
 Minibatch[1301-1400]: loss = 0.292559 * 100, metric = 5.51% * 100;
 Minibatch[1401-1500]: loss = 0.302845 * 100, metric = 5.74% * 100;
 Minibatch[1501-1600]: loss = 0.291677 * 100, metric = 5.44% * 100;
 Minibatch[1601-1700]: loss = 0.289866 * 100, metric = 5.45% * 100;
 Minibatch[1701-1800]: loss = 0.297197 * 100, metric = 5.71% * 100;
 Minibatch[1801-1900]: loss = 0.296550 * 100, metric = 5.71% * 100;
 Minibatch[1901-2000]: loss = 0.300587 * 100, metric = 5.65% * 100;
Finished Epoch[45 of 200]: [Training] loss = 0.296261 * 2000, metric = 5.62% * 2000 1622.625s (  1.2 samples/s);
Finished Evaluation [45]: Minibatch[1-5000]: metric = 13.75% * 5000;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
