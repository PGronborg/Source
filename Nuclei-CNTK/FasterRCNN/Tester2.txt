Using base model:   VGG16
lr_per_sample:      [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-06]
Training model for 2 epochs.
Training 136449349 parameters in 32 parameter tensors.
Learning rate per minibatch: 0.001
Momentum per minibatch: 0.9
Learning rate per minibatch: 0.002
Momentum per minibatch: 0.9
 Minibatch[   1- 100]: loss = 1.225790 * 100, metric = 24.18% * 100;
 Minibatch[ 101- 200]: loss = 1.024805 * 100, metric = 23.03% * 100;
 Minibatch[ 201- 300]: loss = 0.886036 * 100, metric = 21.15% * 100;
 Minibatch[ 301- 400]: loss = 0.866250 * 100, metric = 20.21% * 100;
 Minibatch[ 401- 500]: loss = 0.818069 * 100, metric = 19.15% * 100;
Finished Epoch[1 of 2]: [Training] loss = 0.964190 * 500, metric = 21.54% * 500 233.633s (  2.1 samples/s);
Finished Evaluation [1]: Minibatch[1-500]: metric = 27.95% * 500;
 Minibatch[   1- 100]: loss = 0.791247 * 100, metric = 18.47% * 100;
 Minibatch[ 101- 200]: loss = 0.759830 * 100, metric = 16.92% * 100;
 Minibatch[ 201- 300]: loss = 0.716958 * 100, metric = 16.29% * 100;
 Minibatch[ 301- 400]: loss = 0.743843 * 100, metric = 16.83% * 100;
 Minibatch[ 401- 500]: loss = 0.741956 * 100, metric = 16.91% * 100;
Finished Epoch[2 of 2]: [Training] loss = 0.750767 * 500, metric = 17.09% * 500 212.690s (  2.4 samples/s);
Finished Evaluation [2]: Minibatch[1-500]: metric = 26.32% * 500;
creating eval model
Stored eval model at /home/s124262/Source/Nuclei-CNTK/FasterRCNN/Output/faster_rcnn_eval_VGG16_e2e.model
